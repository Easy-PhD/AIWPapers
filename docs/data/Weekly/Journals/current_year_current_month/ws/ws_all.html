<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ws</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="iet">IET - 40</h2>
<ul>
<li><details>
<summary>
(2025). Two-stage AI model for endometrial cancer staging: YOLOv4 localization and deep learning classification. <em>IET</em>, <em>12</em>, 2550034. (<a href='https://doi.org/10.1142/S2737599425500343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in artificial intelligence (AI) have increasingly transformed the healthcare sector, promoting the development of models aimed at improving the efficiency and accuracy of diagnostic processes, with significant applications in medical imaging. Specifically, in the diagnosis of endometrial cancer, accurate staging typically requires pathological examination. This study aims to develop and evaluate an AI-based approach for automating this process, utilizing a combination of object detection and image classification models. The YOLOv4 model was employed to localize the endometrium in medical images, followed by image classification using Inceptionv3, EfficientNet-b0, and MobileNetv2 for performance comparison. The YOLOv4 algorithm achieved an Intersection over Union (IoU) score > 0 . 9 , indicating high localization accuracy. In the classification task, all three models achieved training accuracies > 9 0 % and test accuracies > 7 5 % . The proposed approach, combining YOLOv4 for localization and Inceptionv3 for classification, achieved a test accuracy of 77.64%. This study presents an AI-driven method for automated endometrial cancer staging, integrating YOLOv4-based localization with deep learning-based classification. The model demonstrates potential for assisting obstetricians and gynecologists in the early identification of endometrial cancer, improving diagnostic efficiency and accuracy in clinical settings.},
  archive      = {J_IET},
  author       = {Ming-Ju Chen and Ying-Lin Hsu and Jia-Lang Xu},
  doi          = {10.1142/S2737599425500343},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550034},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Two-stage AI model for endometrial cancer staging: YOLOv4 localization and deep learning classification},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visible light positioning system design for healthcare applications using a modified deep gaussian process. <em>IET</em>, <em>12</em>, 2550033. (<a href='https://doi.org/10.1142/S2737599425500331'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible Light Positioning (VLP) is a promising technology for indoor applications. The utilization of light-emitting diodes (LEDs) as transmitters within the VLP framework offers several benefits compared to radio frequency (RF) beacons, rendering the system particularly advantageous for healthcare applications. In this research, we have introduced a VLP system tailored to align with the hospital setting. We have developed the power delay profile for the received signal and subsequently assessed the presence of the line-of-sight (LoS) link by extracting the root mean square (RMS) delay spread. Following this, we presented a modified deep Gaussian process (MDGP) that employs multiple kernels to accurately estimate user locations in scenarios where the LoS link is not available. The simulation outcomes affirm the effectiveness of our proposed method relative to conventional techniques.},
  archive      = {J_IET},
  author       = {Hamed Alizadeh Ghazijahani and Mahmoud Atashbar and Hossein Nejati},
  doi          = {10.1142/S2737599425500331},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550033},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Visible light positioning system design for healthcare applications using a modified deep gaussian process},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fractional optimal control and cost-effective analysis of community-acquired pneumonia. <em>IET</em>, <em>12</em>, 2550032. (<a href='https://doi.org/10.1142/S273759942550032X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community-acquired pneumonia (CAP) is a common respiratory infection that happens outside of hospitals, and it is caused by bacteria, viruses, or fungus. It remains a serious threat to the world, particularly affecting children, the elderly, and immunocompromised individuals. The fractional-order pneumonia model has been developed in this study to determine the disease dynamics in the system. The model stability is proved for the existing equilibrium points. Global sensitivity analysis was carried out utilizing Latin hypercube sampling (LHS) and partial rank correlation coefficient (PRCC) to find the key parameters influencing disease transmission. Control analysis is considered as an effective strategy for preventing the spread of the disease pneumonia. It is often necessary to combine timely treatment, immunization, and boosting immunity. However, eliminating this disease in the population will be challenging if control strategies aren’t given at the appropriate time and in sufficient quantity. We conduct a cost-effectiveness analysis of four optimal control strategies utilizing numerical methods. Our findings indicate that vaccination is the most cost-effective and efficient control intervention among the strategies compared.},
  archive      = {J_IET},
  author       = {Vijaya Prabha Saravanan and Rajivganthi Chinnathambi},
  doi          = {10.1142/S273759942550032X},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550032},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Fractional optimal control and cost-effective analysis of community-acquired pneumonia},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using deep learning to construct microcalcification clusters in a mammography prediction model. <em>IET</em>, <em>12</em>, 2550030. (<a href='https://doi.org/10.1142/S2737599425500306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is one of the leading causes of cancer death among women in Taiwan, and it is also the type of cancer with the largest incidence worldwide. Early detection and treatment can effectively reduce mortality. In Taiwan, mammography is widely used to screen for microcalcifications in early breast cancer lesions. However, the characteristics of microcalcifications are difficult to observe, and helping radiologists more quickly and effectively identify microcalcifications is an important challenge. This article proposes a method for automatic lesion prediction and image segmentation using microcalcification cluster labeling data. U-Net and V-Net, two convolutional network architectures, are used for comparison, combining the standardized convolutional network architectures dropout and binary cross-entropy (BCE) with Dice as a loss function to detect microcalcification groups. Other preprocessing methods are used to optimize detection results, including window adjustment, image preprocessing, and data augmentation. Finally, the trained model is applied to mammography images to predict lesions through the image segmentation of microcalcification groups, thereby assisting radiologists in making diagnoses. The experimental results on the private dataset show that U-Net outperforms V-Net with an accuracy rate of 72% when using the original images for training, rising to 81% for training using preprocessed images, and 85% when applying the composite method to preprocessed images. V-Net training with preprocessed images only achieves 70% accuracy, rising to 72% by applying the composite method to preprocessed images.},
  archive      = {J_IET},
  author       = {Po-Yen Hsu and Jia-Lang Xu and Li-Lun Chen and Mu-Yen Chen},
  doi          = {10.1142/S2737599425500306},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550030},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Using deep learning to construct microcalcification clusters in a mammography prediction model},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancements in sepsis detection: A review of supervised and unsupervised machine learning methods versus traditional approaches. <em>IET</em>, <em>12</em>, 2550029. (<a href='https://doi.org/10.1142/S273759942550029X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sepsis remains one of the most common causes of mortality globally, demonstrating the urgent need for rapid and accurate diagnosis to improve patient outcomes. Recent advances in sepsis prediction have attempted to incorporate machine learning (ML) methods and traditional clinical diagnosis to identify and intervene early in the care process. This review compares supervised learning approaches, such as decision trees and support vector machines, with unsupervised approaches, including clustering and anomaly detection, to identify sepsis in complex, multimodal, real-time clinical datasets. Supervised learning approaches generally yield higher predictive accuracy when trained on labeled datasets. However, unsupervised learning approaches have the utility of identifying new patterns and subtle physiological changes without labeled training data, resulting in improved sensitivity of the system. Given the acute and time-sensitive nature of sepsis, sensitivity is the most critical performance measure, as missing a valid case can be deadly. Overall accuracy is also essential, as is model interoperability (the ability for various systems to integrate, likely due to the heterogeneous nature of health systems). These elements are crucial for scalability and trust in the clinical workspace. In this review, we further compare and contrast these ML approaches to traditional scoring/boundary biomarker approaches, discuss the difficulties of integration, and suggest ways for developing clinically deployable, interpretable, and sensitive sepsis detection systems.},
  archive      = {J_IET},
  author       = {Kanthavel R and Dhaya R},
  doi          = {10.1142/S273759942550029X},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550029},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Advancements in sepsis detection: A review of supervised and unsupervised machine learning methods versus traditional approaches},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A compact, integrated system for maximizing efficiency and minimizing contamination in cell and microbial cultures. <em>IET</em>, <em>12</em>, 2550027. (<a href='https://doi.org/10.1142/S2737599425500276'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emerging bacterial and viral diseases require rigorous testing of patient samples to ensure the safety of laboratory and healthcare workers. The current open testing environment relies on two distinct technologies—an incubator and a cell culture hood—which necessitate the use of full personal protective equipment (PPE). However, prolonged exposure to potentially infectious materials increases the risk to healthcare workers during sample handling. To address this, we developed a novel Mini-Cult System that integrates both an incubator and a fume hood into a single compact unit. This system revolutionizes laboratory workflows by providing a sterile, contamination-free environment for both cell culture and microbiological applications. It supports essential parameters such as CO 2 concentration, temperature, and humidity, ensuring optimal conditions for cell growth while enabling rapid sample processing. By combining these functions, the Mini-Cult eliminates the need for culture transfers between devices—one of the primary sources of contamination. Its space-saving design enhances laboratory efficiency, and the integrated fume hood offers continuous protection against airborne contaminants. With a user-friendly interface for real-time monitoring and environmental control, the Mini-Cult improves both healthcare worker safety and the reliability of biomedical research.},
  archive      = {J_IET},
  author       = {Siva Prasath Ramasamy and Hema Brindha Masanam and Nivas Kumar Sekar and Rahul Harikumar Lathakumari and Narendiran Thiyagarajan and Ashwin Kumar Narasimhan},
  doi          = {10.1142/S2737599425500276},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550027},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {A compact, integrated system for maximizing efficiency and minimizing contamination in cell and microbial cultures},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated learning (FL)-driven real-time decision support for intraoperative cardiovascular surgery: A privacy-preserving AI framework. <em>IET</em>, <em>12</em>, 2550025. (<a href='https://doi.org/10.1142/S2737599425500252'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intraoperative cardiovascular surgery demands fast and precise decision-making utilizing patient data in real time. Unfortunately, centralized artificial intelligence (AI) models have inherent drawbacks, including high latency, scalability such as low scalability, and privacy related to sharing raw patient data. This study outlines a federated learning (FL)-powered real-time decision support system (FDSS) capable of functioning over multiple distributed surgical nodes while ensuring the privacy of patient information. We developed a federated real-time surgical decision support (FRSDS) algorithm, which embodies the operational logic of the FDSS framework. The FDSS includes individual model training at the edge, differentially private updates, secure aggregation using Federated Averaging (FedAvg), and real-time inference at the surgical site. The framework was evaluated under multicenter cardiovascular datasets. We assess performance through accuracy, sensitivity, specificity, precision, F1-score, and area under the receiver operating characteristic curve (AUC-ROC), and system performance is assessed through latency and communication overhead. FDSS achieved 95.4% accuracy, 94.6% sensitivity, 95.0% specificity, 93.2% precision, and an AUC-ROC of 0.98. The averages exceeded those of centralized and baseline FL benchmark models. The average inference latency in real time was 120 ms, which is appropriate for intraoperative use. The expected convergence was very strong; communication overhead was lessened with top-k gradient compression, and differential privacy was maintained with ( ∈ = 1 . 2 , δ = 1 0 − 5 ) protection. The system proposed with the FDSS framework is an inoperative cardiovascular care option for supporting surgical performance that preserves patient privacy. And, because no raw patient data is transferred internally with the system, the FRSDS algorithm provides rapid inference and enables real-time, scalable decision-support policymaking capability even in intraoperative circumstances poised with patient risk.},
  archive      = {J_IET},
  author       = {R. R. Kanthavel and R. Dhaya},
  doi          = {10.1142/S2737599425500252},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550025},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Federated learning (FL)-driven real-time decision support for intraoperative cardiovascular surgery: A privacy-preserving AI framework},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-objective evolutionary algorithm for improving the iterative search of MAFFT. <em>IET</em>, <em>12</em>, 2550024. (<a href='https://doi.org/10.1142/S2737599425500240'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multiple sequence alignment (MSA) problem is a central issue in bioinformatics, with significant applications in the evolutionary analysis of biological sequences, identification of conserved regions, protein structure prediction, gene annotation, and function prediction. MAFFT is currently one of the most widely used tools for solving the MSA problem. This article aims to improve the limitations of MAFFT in solving the MSA problem by using a multi-objective evolutionary algorithm (MOEA) to enhance the quality of the iterative search. To this end, a new three-objective model is defined, and a novel MOEA is proposed to optimize this model. Four mutation and two crossover operators are designed to generate promising offspring individuals during the evolutionary process. To evaluate the effectiveness of the proposed method, computational experiments are conducted on 60 instances randomly selected from the BAliBASE 3.0 database. The results show that the proposed method can improve the quality of the iterative search and output alignment of MAFFT in terms of the Q and TC metric scores. This study provides new insights into how to better utilize existing tools to solve the MSA problem and offers a promising direction for improving the quality of their output alignments in future research.},
  archive      = {J_IET},
  author       = {Mengxi Gu and Xinyue Zhang and Zhengxin Huang and Demin Cao and Xiaoxue Zhang and Parvaiz Ahmad Naik},
  doi          = {10.1142/S2737599425500240},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550024},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {A multi-objective evolutionary algorithm for improving the iterative search of MAFFT},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BrainAdaptNet: A few-shot learning model for brain tumor segmentation in low-quality MRI. <em>IET</em>, <em>12</em>, 2550023. (<a href='https://doi.org/10.1142/S2737599425500239'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmentation of brain tumors in low-quality magnetic resonance imaging (MRI) remains a challenge, especially in resource-limited regions such as sub-Saharan Africa. Variations in MRI data quality lead to poor model generalization, and low-quality data is difficult to acquire and annotate. To address these issues, this article proposes a few-shot cross-domain segmentation model, BrainAdaptNet, aimed at improving segmentation performance from high-quality to low-quality MRI. BrainAdaptNet uses DinoV2 as a self-supervised feature extraction backbone, enhancing dataset adaptability through contrastive learning and simulating image quality degradation with wavelet transform style transfer to improve the model’s robustness to changes in image distribution. In the data preprocessing phase, CutMix augmentation is introduced for feature fusion, reducing the distribution gap between source and target data. Additionally, a task-adaptive cross-attention (TACA) feature transformation module is designed to further enhance the interaction and alignment of features between the support and query sets, optimizing segmentation performance under few-shot conditions. To rigorously evaluate the proposed method, fivefold cross-validation was conducted on data migration tasks with BraTS 2021 and BraTS 2020 as the source domains and BraTS Africa as the target domain. Experimental results show that, compared to the baseline model PATNet, BrainAdaptNet achieved a 1.5–2.0 percentage point improvement in the dice similarity coefficient (DSC) and a 4.8–5.2 percentage point reduction in Hausdorff distance (HD95) in cross-dataset segmentation tasks, demonstrating the effectiveness of BrainAdaptNet on low-quality MRI data.},
  archive      = {J_IET},
  author       = {Li Liu and Khairunnisa Hasikin and Yizhang Jiang and Kaijian Xia and Khin Wee Lai},
  doi          = {10.1142/S2737599425500239},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550023},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {BrainAdaptNet: A few-shot learning model for brain tumor segmentation in low-quality MRI},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bibliometric research of hydro turbine blades through CiteSpace analyzing methods: An evaluation between 2015 and 2024. <em>IET</em>, <em>12</em>, 2550020. (<a href='https://doi.org/10.1142/S2737599425500203'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Turbine blades are the core components of a water turbine, which directly affects the conversion efficiency from water energy to mechanical energy. To understand current research hotspots as well as future research directions, this article provides an overview of the progress of research on hydraulic turbines and turbine blades using CiteSpace 6.4, and analyses the future direction of research on hydraulic turbine blades in terms of the research trends of countries, institutions, and authors. From the three institutions with the highest number of papers, Jiangsu University, Tsinghua University, and Xihua University, it can be seen that the hotspot of hydraulic turbine blade research is the calculation of different quantities by numerical simulation. Fatigue, cracking, wear, stress state, and blade corrosion of turbine blades of different shapes in different environments. The research results show that the working mechanism, material properties, and damage research of hydraulic turbine blades are cutting-edge hotspots.},
  archive      = {J_IET},
  author       = {Han Hu and Hancong Liu and Minjie Duan and Aojie Li and Yi Liu and Tao Guo},
  doi          = {10.1142/S2737599425500203},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550020},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Bibliometric research of hydro turbine blades through CiteSpace analyzing methods: An evaluation between 2015 and 2024},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of an agricultural innovation system in shandong province: Exploring stakeholders and policy frameworks as starting points. <em>IET</em>, <em>12</em>, 2550019. (<a href='https://doi.org/10.1142/S2737599425500197'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of agricultural innovation systems is crucial for modernizing agricultural practices, particularly in regions such as Shandong Province, China. This paper investigates the development of such a system, explicitly outlining the distinct roles of key stakeholders, including farmers, researchers, policymakers, and industry representatives. Farmers serve as the primary adopters of innovative practices, providing essential feedback to researchers who develop new technologies tailored to local needs. Policymakers play a pivotal role in establishing supportive regulatory frameworks and funding initiatives that incentivize innovation and facilitate knowledge exchange. Industry representatives contribute by bridging the gap between research outputs and practical applications, ensuring that new technologies reach the market effectively. This study employs a multifaceted analysis to elucidate the driving mechanisms behind agricultural innovation in the region, including collaborative efforts in knowledge generation, technology adoption, and market integration. It also examines how government policies and initiatives shape the direction and momentum of innovation, emphasizing the importance of effective stakeholder engagement in this process. By highlighting the interplay between stakeholders and policies, this paper offers valuable insights into the mechanisms that foster agricultural innovation ecosystems in Shandong. These findings underscore the necessity of nurturing vibrant agricultural innovation ecosystems to address contemporary challenges and capitalize on emerging opportunities in the agricultural sector. These insights can also guide other regions in building effective agricultural innovation systems to drive sustainable development.},
  archive      = {J_IET},
  author       = {Farooq Muhammad Sabil and Feroze Nazia and Fu Xin and Sun Xueying and Feroze Faisal},
  doi          = {10.1142/S2737599425500197},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550019},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Development of an agricultural innovation system in shandong province: Exploring stakeholders and policy frameworks as starting points},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A mathematical model for evaluating drug efficacy in multiple myeloma. <em>IET</em>, <em>12</em>, 2550016. (<a href='https://doi.org/10.1142/S2737599425500161'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background and Objectives: Multiple myeloma (MM) is a prevalent malignant hematologic tumor with no current cure, highlighting the pressing need for novel drug development. Biochemical approaches to drug development involve extensive and costly biological experiments, underscoring the urgency to integrate new technologies for enhanced efficiency. Materials and Methods: This article presents a mathematical model to assess MM drug efficacy, aiming to guide drug development strategies and improve drug development efficiency. The model employs ordinary differential equations to simulate interactions among osteoblasts, osteoclasts, and MM cells within the bone microenvironment, as well as changes in the NF- κ B and c-Jun N-terminal kinase (JNK) signaling pathways post-MM invasion. Our study investigates the role of the first-line drugs denosumab and bisphosphonates, which are clinical treatments for bone-related complications caused by MM, and compares the effects of the drugs DTP3 and Japonicone A (JA), currently under development for the treatment of MM. Results: Our findings regarding denosumab align with existing experimental data, thus validating the model. Furthermore, our study demonstrates that denosumab exhibits the same anti-MM effect as bisphosphonates but reveals that denosumab acts more quickly due to its direct action on RANKL through monoclonal antibodies, whereas bisphosphonates act more slowly by targeting osteoclasts. Additionally, both DTP3 and JA effectively inhibit MM cell proliferation, positioning them as potential therapeutic agents, with DTP3 displaying superior efficacy compared to JA. Conclusions: We utilize mathematical models as alternatives to biological models to investigate the effects of drugs. These models not only elucidate the mechanisms of action of clinically used medications but also enhance our understanding of drug utilization, providing valuable guidance for physicians in their decision-making. Additionally, for drugs in development, these models can assess both efficacy and side effects, informing the drug development process. They also facilitate comparisons between different drugs to identify less effective options, thereby reducing costs. For example, in the case of DTP3 and JA, where DTP3 proves superior, the models help reduce research and development (R&D) costs associated with JA, saving both resources and time.},
  archive      = {J_IET},
  author       = {Qing Yang and Rui Wang and Yuhao Qiao and Changqing Zhen and Bing Ji},
  doi          = {10.1142/S2737599425500161},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550016},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {A mathematical model for evaluating drug efficacy in multiple myeloma},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging artificial intelligence for sustainable healthcare transformation: Socioeconomic impacts and ethical implications. <em>IET</em>, <em>12</em>, 2550015. (<a href='https://doi.org/10.1142/S273759942550015X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of artificial intelligence (AI) into healthcare systems holds transformative potential to redefine healthcare delivery and accelerate progress toward Sustainable Development Goals (SDGs). However, the socioeconomic and ethical implications of AI adoption remain underexplored, particularly in real-world deployment contexts. This study aims to bridge this gap by examining AI’s impact on healthcare efficiency, cost savings, and workforce dynamics while addressing barriers to equitable access and ethical concerns such as data privacy, transparency, and algorithmic bias. A mixed-methods approach, including statistical modeling, economic analysis, and stakeholder interviews, was employed to evaluate AI’s potential to enhance healthcare delivery and mitigate disparities. Key findings demonstrate AI’s capacity to improve health outcomes, drive economic growth, and optimize resource allocation but underscore the need for robust governance frameworks to ensure ethical and inclusive AI adoption. These insights offer actionable recommendations for policymakers, healthcare professionals, and technology developers seeking to harness AI for sustainable healthcare transformation.},
  archive      = {J_IET},
  author       = {Abdullah Alsaleh},
  doi          = {10.1142/S273759942550015X},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550015},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Leveraging artificial intelligence for sustainable healthcare transformation: Socioeconomic impacts and ethical implications},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling shows that painting with organophosphate microcapsules would be a highly efficient strategy for triatoma infestans control. <em>IET</em>, <em>12</em>, 2550014. (<a href='https://doi.org/10.1142/S2737599425500148'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The eradication of Triatoma infestans and similar vector species has been the focus of the fight against Chagas disease for several decades. The standard control method continues to be the fumigation with pyrethroids, which has led to the emergence of resistant bug populations in many regions of South America and, especially, in the Gran Chaco. It is therefore essential to develop alternative methods of T. infestans control. Paint with microcapsules containing organophosphate substances has been shown to have a positive impact on the reduction of house infestation. In this study, we investigate the effects of the application of organophosphate-based insecticidal paints on a T. infestans population in a chicken coop, the recovery of this population, and the frequencies of application required to control the insect under realistic conditions. We extended a recently proposed model of all stages of T. infestans populations in chicken coops to include paint-induced mortality. Considering climate and bug migration variations, we find the paint application frequencies that guarantee low levels of infestation. A strong and stable decrease in the triatomine population can be achieved by paint applications separated by 4 years or more. This work, taken together with previous experimental results, strongly suggests that painting with organophosphate microcapsules would be a highly efficient method to control T. infestans in regions where it has developed immunity to pyrethroids.},
  archive      = {J_IET},
  author       = {Sergio Agustín Ferrieres and Carlos Alberto Condat},
  doi          = {10.1142/S2737599425500148},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550014},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Modeling shows that painting with organophosphate microcapsules would be a highly efficient strategy for triatoma infestans control},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancements in laser hybrid manufacturing techniques and their impact on biomedical applications. <em>IET</em>, <em>12</em>, 2550013. (<a href='https://doi.org/10.1142/S2737599425500136'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in laser hybrid manufacturing (LHM) techniques have revolutionized the biomedical sector by integrating additive and subtractive processes to create complex structures with enhanced accuracy and efficiency. These emerging methods leverage the power of laser technology to improve material properties, reduce production time, and enable the creation of complex geometries needed for most biomedical applications, including implants, prostheses, and tissue engineering scaffolds. When laser processing is used alongside traditional production methods, it improves the surface features and structure of materials, ensuring that medical devices are stronger and safe for use in the body. The most recent developments in LHM technologies, their working principles, and their influence on improving the usability and effectiveness of biomedical goods are all covered in this overview.},
  archive      = {J_IET},
  author       = {Zahra Al Timim and Donia Mohsen Diwan},
  doi          = {10.1142/S2737599425500136},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550013},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Advancements in laser hybrid manufacturing techniques and their impact on biomedical applications},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weaving health: The innovative applications of natural silk in pharmaceutical capsules. <em>IET</em>, <em>12</em>, 2550011. (<a href='https://doi.org/10.1142/S2737599425500112'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The novel application of natural silk as an automobile for a drug delivery system (DDS) for pharmaceutical capsules forecasts its ability to revolutionize drug delivery. Silk fibroin and silkworms’ sericin have emerged as possessing a greater biocompatibility, degradability, and mechanical activity compared to manmade materials that possess desirable encapsulating properties when the APIs are considered. The structure is novel based on the silkworm-derived protein, in such a manner as to render its controlled release possible, increasing efficacy and consistency for drugs. Besides, the addition of silk-derived materials in drug formulation can address crucial problems such as drug solubility and site-specific delivery. This review provides various methods for silk application in capsule development, including its use in improving patient compliance by reducing side effects and optimizing therapeutic effects. By integrating health into pharmaceutical innovation, natural silk provides an environmentally friendly, effective alternative to conventional materials used in DDSs.},
  archive      = {J_IET},
  author       = {Ahmed K. Kodeary and Zahra AL Timim},
  doi          = {10.1142/S2737599425500112},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550011},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Weaving health: The innovative applications of natural silk in pharmaceutical capsules},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Macrophage-targeted (1EGI) doxycycline chitosan/alginate nanoengineering to alleviate brucella melitensis biovar3 (RihA protein) relapse with effective bactericidal activity: In silico study. <em>IET</em>, <em>12</em>, 2550010. (<a href='https://doi.org/10.1142/S2737599425500100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brucellosis is a prevalent zoonotic infection, primarily in the developing world. Treatment regimens for brucellosis involve multiple medications, including doxycycline (DOX), which regulates the immune system and macrophage activity. Nevertheless, the treatment of Brucella infection is constrained by its presence within macrophages, which exhibit unique anti-immune mechanisms. The internal pathway for DOX against Brucella melitensis and its molecular docking is crucial for targeting macrophages, for enhancing efficacy, and decreasing the dose and time of treatment. Method: This research aimed to accurately predict the targeting efficiency of doxycycline-loaded chitosan alginate (DOX-N) nanoparticles to macrophages. Mannose-decorated chitosan–sodium alginate nanoparticles were chosen for this purpose. In silico analysis was performed to predict the targeting efficacy of the nanocarrier. Result: The study found that Nano DOX and macrophage mannose receptors exhibited binding interactions on their surfaces. The ligand DOX interacted with hydrogen bonds to the macrophage target receptor with a −7.5 kcal/mol interaction and four hydrogen bonds on the mannose receptor of the macrophage. Similarly, sodium alginate exhibited a (−6.2 kcal/mol) docking score, while conventional DOX was (−5.1 kcal/mol). The computational study confirmed that DOX-N has the potential to be a promising lead molecule for regulating the incidence of brucellosis infections. The binding affinity and efficacy of DOX-N loaded on chitosan and sodium alginate were designed and assessed. Conclusion: The results indicated that Nano DOX had a strong affinity for the specific macrophage receptor and specific protein site in B. melitensis .},
  archive      = {J_IET},
  author       = {Fatma I. Abo El-Ela and Walid Hamdy Hassan and Mahmoud Hamdy Abdel-Raheem and Ahmed G. Soliman},
  doi          = {10.1142/S2737599425500100},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550010},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Macrophage-targeted (1EGI) doxycycline chitosan/alginate nanoengineering to alleviate brucella melitensis biovar3 (RihA protein) relapse with effective bactericidal activity: In silico study},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Statistical shape modeling of carpal tunnel cross section. <em>IET</em>, <em>12</em>, 2550009. (<a href='https://doi.org/10.1142/S2737599425500094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carpal tunnel shape variation has implications for hand and wrist musculoskeletal health. Analyzing this variation can improve understanding of carpal tunnel morphological characteristics. Ultrasound images of the distal carpal tunnel were taken of healthy participants ( n = 9 5 ). A point-distribution statistical shape model and principal component analysis were used to analyze tunnel shape variation. Feature point location, ellipse axes length, and area were correlated with each principal component ( α = 0 . 0 5 ). Principal components 1, 2, and 3 were most strongly correlated with the radial–ulnar location of the thenar muscle ulnar attachment point ( r = 0 . 9 9 7 , p < 0 . 0 0 1 ), the radial–ulnar location of the ridge of trapezium ( r = − 0 . 9 8 8 , p = 0 . 0 0 2 ), and the volar–dorsal location of the hook of hamate ( r = − 0 . 9 3 5 , p = 0 . 0 1 9 6 ). Principal components 2 and 3 were strongly correlated with minor axis length ( r = − 0 . 9 8 6 , p = 0 . 0 0 1 9 ) and area ( r = − 0 . 9 9 4 , p < 0 . 0 0 1 ). Statistical shape modeling identifies prominent features underlying healthy carpal tunnel shape variation.},
  archive      = {J_IET},
  author       = {David B. Jordan and Mary N. Henderson and Zong-Ming Li},
  doi          = {10.1142/S2737599425500094},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550009},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Statistical shape modeling of carpal tunnel cross section},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Some new aspects on COVID-19 transmission dynamics applicable to other epidemics: Insights from mathematical modeling and numerical simulations. <em>IET</em>, <em>12</em>, 2550008. (<a href='https://doi.org/10.1142/S2737599425500082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a mathematical model is constructed, analyzed, and numerically simulated to investigate the effects of vaccination rates and efficacy on the incidence of COVID-19. The model subdivides the infectious class into symptomatic, asymptomatic, and hospitalized individuals, enabling us to explore questions inadequately addressed by prior models. First, the existence of a region where the model is epidemiologically feasible is established. Then a thorough qualitative analysis is carried out in order to characterize the long-term dynamics of the model solutions, and the model is calibrated using South Africa-reported data from the beginning of the epidemic until July 2022. In addition, different numerical scenarios with different transmission rates, non-pharmaceutical interventions (NPIs), and vaccination parameters were investigated. The model, analysis, and results of this study can be adapted to study the dynamics of other epidemics.},
  archive      = {J_IET},
  author       = {Victor Ogesa Juma and Chinwendu Emilian Madubueze and Godwin Nwachukwu Nkem and John Mwaonanji and Joseph Malinzi},
  doi          = {10.1142/S2737599425500082},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550008},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Some new aspects on COVID-19 transmission dynamics applicable to other epidemics: Insights from mathematical modeling and numerical simulations},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advances, trends, and hotspots in sport for sustainable development: A bibliometric analysis using CiteSpace and VOSviewer. <em>IET</em>, <em>12</em>, 2550007. (<a href='https://doi.org/10.1142/S2737599425500070'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The contribution of sports in promoting sustainable development has been widely recognized by the international community. Sustainable development has become the core concept of sports development. In order to systematically review the evolution trend, hot spots, and future research directions of sports promotion sustainable development, this article adopts a bibliometrics method and is based on the Web of Science database. CiteSpace (version 6.2.R3) software and VOSviewer (version 1.6.20) software were applied to perform a visual analysis of 565 relevant articles published between 2003 and 2024. Those obtained results show that the research of sports promoting sustainable development is growing in stages, and an interdisciplinary research system has been initially formed. The current research focuses on institutions of higher learning. The UK and the University of California System are the most influential countries and institutions in this field; China has the largest number of publications, but the international cooperation is relatively weak; Sustainability is the journal with the largest number of publications in this field. Keyword analysis shows that sports events, sports tourism, health promotion, social inclusion and equality, green sports, environmental awareness, physical education, and sustainable development are current research hotspots. Interdisciplinary research from the perspective of globalization, adaptation, and action of sport in the context of world turbulence and climate change, long cycle and longitudinal research, digital sport, and evaluation of progress of Sustainable Development Goals (SDGs) will be the future research directions. This study provides an important reference for academics and practitioners in the sports industry and aims to enhance the awareness of the potential of sport to promote sustainable development and promote the realization of SDGs.},
  archive      = {J_IET},
  author       = {Defeng Dong and Bing He and Chen Dong},
  doi          = {10.1142/S2737599425500070},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550007},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Advances, trends, and hotspots in sport for sustainable development: A bibliometric analysis using CiteSpace and VOSviewer},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging engineering education and local innovation ecosystems in africa through the invention education model. <em>IET</em>, <em>12</em>, 2550006. (<a href='https://doi.org/10.1142/S2737599425500069'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article shares lessons and impacts of solving engineering problems through Invention Education (IvE) in Africa. IvE is a transdisciplinary approach to engineering education that cultivates an ecosystem for fostering technical innovation to solve local and global challenges. The article shares a model of IvE, which includes the establishment and expansion of design studios as hands-on prototyping spaces for technology design, curricular integration of active learning and problem-based learning across engineering departments, and establishment of innovation ecosystem partnerships. Invention Education is a novel, transdisciplinary approach to engineering education that fosters technical innovation, improves health outcomes, and reduces poverty. While global evidence of IvE’s impact in high-income settings is well-documented, few successful models have been developed by and collaboratively created with universities in Africa. Our multi-institutional team, representing institutions from Malawi, Nigeria, Tanzania, the United States, and Ethiopia, has developed a scalable IvE model designed to empower engineering students in sub-Saharan Africa to solve real-world challenges. This article presents key outcomes of the IvE model, including the establishment of design studios as hubs for innovation, curricular integration of active learning methodologies, and the strengthening of partnerships within local innovation ecosystems. Drawing on 8 years of implementation, this work provides critical insights into the advancement of engineering education and innovation ecosystems in a geographical region that has untapped potential for these models. Finally, the discussion outlines a forward-looking plan to assess the sustainability of the model and its potential for broader scaling across diverse regional contexts.},
  archive      = {J_IET},
  author       = {Theresa Mkandawire and Ashley Taylor and Matthew Wettergreen and Ann Saterbak and Padraic Casserly and Williams Baah and Will Moyo and Julia Jenjezwa and Hillary Lodzanyama and John Msumba and Address Malata and Gregory Gamula and Akinwale Coker and Ademola Dare and Dawit Assefa and Akinniyi Osuntoki and Olawale Ajibola and Theophilus Fashanu and Jennifer Chimwaza and Toyin Popoola and Sade Ogunsola and Rebecca Richards-Kortum and Z. Maria Oden},
  doi          = {10.1142/S2737599425500069},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550006},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Bridging engineering education and local innovation ecosystems in africa through the invention education model},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review of emerging technologies in wireless communication systems. <em>IET</em>, <em>12</em>, 2550005. (<a href='https://doi.org/10.1142/S2737599425500057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article reviews emerging technologies in wireless communication systems, focusing on their key concepts, principles, use cases, and challenges. It examines relevant studies in the telecommunication sector, with a focus on technologies that enhance connectivity, performance, and innovative applications across industries. The review highlights advancements such as fifth-generation (5G) networks, which offer faster data speeds, lower latency, and increased network capacity, enabling the development of applications like autonomous vehicles, smart cities, and Internet of Things (IoT) devices. IoT devices are increasingly connecting physical objects, driving innovation in sectors such as healthcare, agriculture, transportation, and manufacturing. Edge computing, by enabling real-time processing and reducing latency, supports IoT applications requiring immediate responses. Artificial intelligence (AI) and machine learning (ML) are being integrated to optimize network resources, improve spectrum management, and facilitate intelligent decision-making. Technologies such as massive multiple input, multiple output (MIMO) enhance spectral efficiency, network capacity, and interference reduction. Millimeter wave (mmWave) frequencies are being explored for high-speed wireless communication, enabling multi-gigabit data rates and applications in 5G, wireless backhaul, and ultra-high-definition video streaming. Software-defined networking (SDN) and network function virtualization (NFV) enable centralized management and greater network flexibility, while beam steering improves signal quality and coverage by directing wireless signals toward specific receivers. Quantum communication, leveraging quantum principles, provides secure communication channels, while quantum key distribution (QKD) ensures data confidentiality. Visible light communication (VLC) utilizes visible light for high-speed data transfer in environments where RF-based communication is not feasible. Despite the potential of these technologies, the article identifies challenges such as limited practical implementation, standardization issues, resource constraints, security and privacy concerns, and sustainability challenges. It concludes by discussing the practical implications of these emerging technologies, including enhanced data transfer speeds, improved network capacity, low-latency communication, IoT connectivity, ubiquitous coverage, industry transformation, and the security and privacy considerations that accompany these advancements.},
  archive      = {J_IET},
  author       = {Promise Elechi and Solomon Malcolm Ekolama and Ela Okowa and Shadrack Kukuchuku},
  doi          = {10.1142/S2737599425500057},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550005},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {A review of emerging technologies in wireless communication systems},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Climate change and health: The role of artificial intelligence in predictive surgical treatment. <em>IET</em>, <em>12</em>, 2550004. (<a href='https://doi.org/10.1142/S2737599425500045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article explores the development of incorporating climate variables into artificial intelligence (AI) predictive models and their applications in surgical procedures within the context of escalating global warming. The increasing frequency of extreme weather events, changes in infectious disease patterns, and declines in environmental quality pose unprecedented challenges to public health. Healthcare systems must address current health crises while preparing for potential future public health issues. AI technology shows significant potential in this process: it can assist physicians in achieving more precise diagnoses and treatment planning and help healthcare institutions through advanced predictive modeling to anticipate and mitigate the impacts of climate change. This article analyzes how integrating climate factors into AI algorithms can improve predictions regarding the impact on health outcomes, particularly in surgery, and underscores the importance of leveraging these insights to optimize resource allocation, enhance patient care pathways, and improve clinical outcomes.},
  archive      = {J_IET},
  author       = {Jingyang Sun and Li Xu and Chenxi Huang and Eddie Yin Kwee Ng},
  doi          = {10.1142/S2737599425500045},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550004},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Climate change and health: The role of artificial intelligence in predictive surgical treatment},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-driven healthcare systems: A personalized symptom-based disease prognosis tool using RF, GNB, and SVC techniques. <em>IET</em>, <em>12</em>, 2550003. (<a href='https://doi.org/10.1142/S2737599425500033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) technology is being leveraged for multiple tasks in the healthcare sector, such as improving the diagnosis of disease, streamlining management services, and tailoring treatment procedures. Applying predictive analysis and performing robotic surgery helps patients in a way that reduces the burden on their caregivers. This study uses a healthcare disease prediction dataset using three robust machine learning algorithms: random forest (RF), Gaussian Naïve Bayes (GNB), and support vector classifier (SVC). The models learn to use other symptoms to detect the presence of various diseases. In model evaluation, cross-validation is done on the training set after data preprocessing is performed to ensure none of the groups is overrepresented in the final model. In both the training and the testing of each model, which were respectively 100%, the model was able to make perfect predictions. A vote of three classifiers reached the 100% precision mark over a test dataset on an ensemble model that combined all the classifiers. This research integrates the advances in AI technology into the healthcare setting in a bid to enhance healthcare delivery. Additionally, we created such a straightforward tool in the case of input symptoms and proposed a possible disease diagnosis. This study also adds to the expanding corpus of research on AI in healthcare by providing a practical method for symptom-based diagnosis.},
  archive      = {J_IET},
  author       = {Massoud Massoudi and Ruchika Malhotra},
  doi          = {10.1142/S2737599425500033},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550003},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {AI-driven healthcare systems: A personalized symptom-based disease prognosis tool using RF, GNB, and SVC techniques},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scrap steel price predictions for southwest china via machine learning. <em>IET</em>, <em>12</em>, 2550002. (<a href='https://doi.org/10.1142/S2737599425500021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasts of prices for a wide range of commodities have been a source of confidence for governments and investors throughout history. This study examines the difficult task of forecasting scrap steel prices, which are released every day for the southwest China market, leveraging time-series data spanning August 23, 2013 to April 15, 2021. Estimates have not been fully considered in previous studies for this important commodity price assessment. In this case, cross-validation procedures and Bayesian optimization techniques are used to develop Gaussian process regression strategies, and consequent price projections are built. Arriving at a relative root mean square error of 0.4691%, this empirical prediction approach yields fairly precise price projections throughout the out-of-sample stage spanning September 17, 2019 to April 15, 2021. Through the use of price research models, governments and investors may make well-informed judgments on regional markets of scrap steel.},
  archive      = {J_IET},
  author       = {Bingzi Jin and Xiaojie Xu},
  doi          = {10.1142/S2737599425500021},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550002},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Scrap steel price predictions for southwest china via machine learning},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research of ultra-low concentration ion implantation on chip substrates using film delamination method combined with semiconductor simulation technology. <em>IET</em>, <em>12</em>, 2550001. (<a href='https://doi.org/10.1142/S273759942550001X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research proposes a novel ion implantation technique that combines the film delamination method with semiconductor simulation technology to achieve low-dose, high-uniformity semiconductor doping. The method involves depositing a protective layer on the substrate, implanting ions into the layer, performing high-temperature pre-diffusion, delaminating the protective layer, and completing the diffusion process. By integrating semiconductor simulation software, such as Silvaco TCAD, the research aims to optimize parameters for the protective layer and achieve precise control of doping concentrations. This innovative approach addresses the challenges of uniformity and cost in traditional ion implantation equipment.},
  archive      = {J_IET},
  author       = {Zhiwei Yang and Asim Abas and Yuanxun Cao},
  doi          = {10.1142/S273759942550001X},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550001},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Research of ultra-low concentration ion implantation on chip substrates using film delamination method combined with semiconductor simulation technology},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling the enablers of ergonomic design with karakuri automation for special purpose machine manufacturing industry using the DEMATEL approach. <em>IET</em>, <em>12</em>, 2540003. (<a href='https://doi.org/10.1142/S2737599425400031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The special purpose machine (SPM) manufacturing industry plays a pivotal role in enhancing production efficiency and meeting the specific demands of various industrial sectors. However, the pursuit of efficiency should not compromise the health and well-being of the workers involved in these processes. Ergonomic design is essential in ensuring that SPMs are designed and operated in a manner that minimizes physical strain and optimizes performance. The application of Karakuri automation, an integration of lean manufacturing techniques initiated by Japan, further enhances the efficiency of the SPM manufacturing shop floor. This research article presents a comprehensive analysis of the enablers of ergonomic design with Karakuri automation for the SPM manufacturing industry using the Decision-Making Trial and Evaluation Laboratory (DEMATEL) approach. The study aims to identify the key factors influencing ergonomic design decisions and their interrelationships, ultimately aiding in the development of more ergonomic and efficient SPM manufacturing.},
  archive      = {J_IET},
  author       = {Bhupendra Prakash Sharma and Shyam Sunder Sharma and Ashu Yadav and Rahul Khatri and Manoj Kumar and Kamal Jaafar},
  doi          = {10.1142/S2737599425400031},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2540003},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Modeling the enablers of ergonomic design with karakuri automation for special purpose machine manufacturing industry using the DEMATEL approach},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MXenes in biomedical applications: Comprehensive review of properties, synthesis methods, and advances in biodegradable implants. <em>IET</em>, <em>12</em>, 2540002. (<a href='https://doi.org/10.1142/S273759942540002X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, MXenes have emerged as a promising class of two-dimensional materials with unique properties, capturing significant attention in the field of biomedical implantation. This review provides a focused exploration of MXene’s synthesis methodologies, distinctive properties, and their specific applications in the realm of biomedical implants. The historical evolution of MXenes is traced, emphasizing their adaptation to biomedical contexts. A detailed examination of synthesis approaches is presented, with a particular emphasis on methods conducive to biomedical compatibility. The distinctive properties of MXenes, such as biocompatibility, mechanical strength, and surface chemistry, are scrutinized in the context of their suitability for biomedical implants. The discussion extends to the applications of MXenes in various biomedical implantation scenarios, including but not limited to orthopedic implants, cardiovascular devices, and neural interfaces. Furthermore, the review outlines current trends and future prospects for MXene-based biomaterials in biomedical implantation. Challenges and opportunities are discussed, offering a comprehensive overview for researchers and practitioners in the field. This review aims to serve as a valuable resource, shedding light on the synthesis, properties, and potential applications of MXenes in the exciting and rapidly evolving landscape of biomedical implantation.},
  archive      = {J_IET},
  author       = {Venkata Satya Prasad Somayajula and Priyadarsini Morampudi and P. Prasanna Kumari and Guttula Anusha and Venturi Gunavathi Rao},
  doi          = {10.1142/S273759942540002X},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2540002},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {MXenes in biomedical applications: Comprehensive review of properties, synthesis methods, and advances in biodegradable implants},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Smart MedDB chain—An intelligent approach for data sharing in medical systems. <em>IET</em>, <em>12</em>, 2540001. (<a href='https://doi.org/10.1142/S2737599425400018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid growth of medical data in both hospitals and healthcare industries has made data handling increasingly challenging. Fast access to relevant medical information in an emergency is essential, but the huge data in databases makes this difficult. The management of data in the public domain is made more difficult by privacy and security concerns, which calls for the creation of a safe data handling system. The primary objective of this research is to propose and implement an intelligent framework, Smart MedDB, for real-time tracking of medical records. The framework highlights privacy and security considerations while addressing the difficulties of managing massive medical databases effectively and providing prompt access to individual patient information. The platform also aims to make e-Token booking with healthcare providers easier and simplify the process of filing health insurance claims. The proposed methodology involves the development and implementation of Smart MedDB, an intelligent framework that employs advanced data handling techniques to ensure quick and secure access to medical records. Patient databases can only be handled or shared by authorized personnel thanks to the integration of authentication measures. Smart MedDB makes use of state-of-the-art protocols and technology to automate the health insurance claim procedure. User experience and system responsiveness are taken into consideration while evaluating the framework’s qualitative capacity to offer rapid and secure access to medical records. The quantity of medical records increased five times, and then the responsiveness and bandwidth of the present medical data handling system increased to 60 seconds and 1,200 KB. However, the proposed system maintains almost the same level throughout the entire operation since it is stream-based. Metrics including data processing speed, security precautions, and retrieval time are quantified and contrasted with current systems. This framework presents an effective way to expedite medical data access by resolving privacy, security, and efficiency concerns. It ensures prompt and safe retrieval during emergencies and automates associated activities for improved healthcare services.},
  archive      = {J_IET},
  author       = {Parimala Devi Muthusamy and Boopathi Raja Govindasamy and Sathya Thandavan and Gowrishankar V and Nithya Savarimuthu},
  doi          = {10.1142/S2737599425400018},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2540001},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Smart MedDB chain—An intelligent approach for data sharing in medical systems},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data science: Healing with algorithms. <em>IET</em>, <em>12</em>, 2530009. (<a href='https://doi.org/10.1142/S2737599425300090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mining data, saving lives. As articulated by Nate Silver, “The most pivotal competency for any data scientist is comprehending the essence of the data,” a tenet that holds particular significance in the healthcare domain. Complementing this, Andrew Ng’s declaration that “Data is the new oil” underscores its critical role in propelling data-driven paradigms, while DJ Patil’s assertion that “Data is the new currency” amplifies its escalating significance in enhancing patient outcomes. The advancement of business intelligence (BI) tools has constituted a robust framework for sophisticated analytics; however, conventional systems frequently falter in extracting actionable intelligence from the burgeoning complexity and voluminous nature of healthcare data. Innovative methodologies in healthcare data science are emerging, encompassing predictive analytics models that utilize historical patient data to prognosticate health trajectories alongside natural language processing (NLP) techniques designed to distill salient insights from unstructured clinical narratives. Moreover, machine learning algorithms, including decision trees and neural networks, are fundamentally transforming diagnostic precision by unearthing intricate patterns embedded within patient datasets. As of 2021, the United States dominated the big data and business analytics (BDA) landscape, commanding 51% of the global market share—an indicator of the sector’s strategic prioritization of data governance and analytics. This trajectory accentuates the indispensable nature of data science in sculpting the future of healthcare, enhancing operational efficacy, optimizing clinical workflows, and cultivating patient-centric care. As the healthcare sector perpetually generates vast data reservoirs, incorporating advanced analytics is not merely advantageous but essential for catalyzing sustainable innovation, advancing population health management, and ensuring superior patient outcomes.},
  archive      = {J_IET},
  author       = {Tulip Saikia and Tania Acharjee and Dinesh Bhatia},
  doi          = {10.1142/S2737599425300090},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2530009},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Data science: Healing with algorithms},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-powered precision population health – Optimising health demand and capacity with predictive intelligence analytics in an england case study. <em>IET</em>, <em>12</em>, 2530008. (<a href='https://doi.org/10.1142/S2737599425300089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The National Health Service is under increasing pressure due to mismatches between workforce capacity, infrastructure and the evolving needs of population health. These issues have led to rising inefficiencies, structural imbalances and service misalignments relative to actual health demand. Addressing these challenges requires an integrated, data-driven planning approach that enables better resource alignment, targeted investment in critical areas and productivity optimisation through a whole-of-system lens. A phased strategy – combining immediate recovery of service capacity with a long-term transformation plan – is essential. By leveraging artificial intelligence (AI)-enabled system intelligence and predictive analytics, this article presents a detailed case study analysis to support sustainable, value-based healthcare tailored to population needs.},
  archive      = {J_IET},
  author       = {Mark Gordon and Andy Poh and Lindsay Sales and Rosalind Baker and David Moore},
  doi          = {10.1142/S2737599425300089},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2530008},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {AI-powered precision population health – Optimising health demand and capacity with predictive intelligence analytics in an england case study},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thermally sprayed hydroxyapatite coatings on surgical-grade stainless steel for biomedical implant surfaces—A review. <em>IET</em>, <em>12</em>, 2530007. (<a href='https://doi.org/10.1142/S2737599425300077'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This review examines advancements in thermally sprayed hydroxyapatite (HA) coatings on surgical-grade stainless steel for biomedical implant surfaces, focusing on their mechanical properties, biocompatibility, and corrosion resistance. However, its limited mechanical strength and tendency to degrade in physiological environments present significant challenges. Plasma spraying, a well-established surface modification technique, has been extensively studied for its ability to enhance coating uniformity, adhesion strength, and overall stability. The review explores the influence of key characteristics on the wear performance of HA coatings, including mechanical integrity, adhesion strength, fracture toughness, hardness, elastic modulus, porosity, and crystallinity. Incorporating reinforcements such as alumina and zirconia has been shown to significantly enhance these properties, improving the load-bearing capability of HA coatings.},
  archive      = {J_IET},
  author       = {Praveen Kumar Verma and Hitesh Vasudev and Gurbhej Singh},
  doi          = {10.1142/S2737599425300077},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2530007},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Thermally sprayed hydroxyapatite coatings on surgical-grade stainless steel for biomedical implant surfaces—A review},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ‘From birthing to dreaming’: Introducing the orange aboriginal medical service (OAMS) as a benchmark for rural integrated care. <em>IET</em>, <em>12</em>, 2530006. (<a href='https://doi.org/10.1142/S2737599425300065'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has long been recognised that the Indigenous population of Australia faces significant health disparities. Despite various policy strategies to close the gap, communities remain disadvantaged, with health and community services struggling to meet population needs. Our case study presents an innovative and holistic response to integrated care for the Aboriginal and Torres Strait Islander population. We present how the Orange Aboriginal Medical Service (OAMS) provides a benchmark in the delivery of services for indigenous populations in a rural setting. OAMS has adopted an approach that veers away from mainstream general practice, and our case study presents the key observational learning points of our experience. We argue that this learning can be applied to other communities with characteristics similar to the Aboriginal and Torres Strait Islander population in Orange. It is envisaged that our experience will be the launching pad for further research which may benefit not only First Nations people but also the wider non-Indigenous community.},
  archive      = {J_IET},
  author       = {Genie Poh and Andy Poh and Ross Millar and Jamie Newman and Anne-Marie Mepham},
  doi          = {10.1142/S2737599425300065},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2530006},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {‘From birthing to dreaming’: Introducing the orange aboriginal medical service (OAMS) as a benchmark for rural integrated care},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review of the effect of environmental factors on COVID-19 disease. <em>IET</em>, <em>12</em>, 2530005. (<a href='https://doi.org/10.1142/S2737599425300053'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The continued destruction brought on by severe acute respiratory syndrome (SARS)-CoV-2 has highlighted the urgent requirement for region-specific prevention strategies based on climatic and geographic factors. Epidemiological and regression models indicate that particulate matter (PM) is primarily linked to coronavirus disease (COVID-19), but additional environmental factors, such as ammonia (NH 3 ) and relative humidity (RH), must also be taken into account to get a firm conclusion. Hot spots of airborne PM2.5, PM10, NH 3 , and RH concentrations, as well as COVID-19 cases and fatalities, were mapped using extensive datasets from Delhi and other areas. The study discovered a correlation between RH and NH 3 as well as a substantial association between COVID-19 instances and mortalities and PM2.5 and PM10, respectively. According to the study, these environmental factors may have had a significant impact on the SARS-CoV-2 outbreak. The results also point to geographical and temporal variations in COVID-19 severity linked to environmental risk factors. To stop the spread of COVID-19, this study offers a strong foundation for developing and putting into practice regulatory solutions, as well as suitable urban and traffic planning.},
  archive      = {J_IET},
  author       = {Deepak Choudhary and Mellachervu Naga Srinivas and Buddana Surya Narayana Murthy and Parvaiz Ahmad Naik},
  doi          = {10.1142/S2737599425300053},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2530005},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {A review of the effect of environmental factors on COVID-19 disease},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Potential for use of lignin in drug release. <em>IET</em>, <em>12</em>, 2530004. (<a href='https://doi.org/10.1142/S2737599425300041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, it was examined how lignin, one of the raw materials of hemp, has been used in drug release so far. The lignin in the review is given examples of its use in drug release. The study is a narrative review study. The research question is “How is lignin used in drug release?” Within the scope of the study, Web of Science, Scopus, Google Research, PubMed, Google Scholar, etc., the principal accepted indexes in the literature, were used. As a result of scanning these indexes, only 13 out of approximately 30-studies were selected. Keywords chosen as selection criteria: Lignin, extraction methods of lignin, place of lignin in drug release, use of lignin in drug release, materials produced with lignin in drug release. After the selection, the relevant studies were grouped and classified. Even lignin, which is used in different forms for drug release, has also been mentioned. This is a mini-review about the potential for use of lignin in drug release. As a result of the examination, it was understood that there are restrictions on the drug release use of lignin due to the problem of water dissolution. However, it is understood that it is a very suitable material for drug release due to its large amount, easy availability, and biocompatibility. Therefore, at the end of the study, it was recommended that the water-dissolved form of lignin and even the nano-sized form would benefit drug release for researchers who want to work in this field. In this respect, studies on lignin as a natural drug release product will accelerate. It will also be more beneficial for drug release of lignin in nanosize. These suggestions will guide researchers who want to work in this field. In the future, the researchers will study lignin for drug release.},
  archive      = {J_IET},
  author       = {Huseyin Uşan and S. Esra Bolsu Kariper and I. Afşin Kariper},
  doi          = {10.1142/S2737599425300041},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2530004},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Potential for use of lignin in drug release},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Review — Artificial intelligence in breast surgery for older women with breast cancer: A scoping review of the past ten years. <em>IET</em>, <em>12</em>, 2530003. (<a href='https://doi.org/10.1142/S273759942530003X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite older women comprising a significant proportion of breast cancer cases, they remain underrepresented in clinical trials and research. This scoping review examines how artificial intelligence (AI) has been applied in breast surgery for older women with breast cancer over the past decade. A systematic search of PubMed, Scopus, Web of Science, and IEEE Xplore databases was conducted for studies published between January 2015 and February 2025. Studies were included if they investigated AI applications in breast surgery and provided age-stratified analysis for women aged 65 and above. The findings were thematically analyzed to identify trends and gaps in the field. Six studies met the inclusion criteria and were categorized into two themes: AI-Driven Diagnostics and Risk Prediction (two studies) and AI-Guided Treatment and Decision Support (four studies). Deep learning (DL)- and radiomics-based models demonstrated superior accuracy in predicting axillary lymph node (ALN) metastasis (area under curve [AUC] 0.906) compared to traditional clinical models. AI-guided treatment decision support tools showed improved survival outcomes, with one study reporting a 12% lower mortality rate for patients following AI recommendations. However, no studies specifically addressed AI applications in intraoperative decision-making for older women. While AI shows promise in improving diagnostic accuracy and treatment planning for older women with breast cancer, significant gaps exist, particularly in intraoperative applications. Future research should focus on prospective validation of AI models, standardization of AI development, and investigation of AI’s potential in real-time surgical decision-making for this vulnerable population.},
  archive      = {J_IET},
  author       = {Cheow Jun Wei and Shakthee Sivakumar and Clement Chia Luck Khng},
  doi          = {10.1142/S273759942530003X},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2530003},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Review — Artificial intelligence in breast surgery for older women with breast cancer: A scoping review of the past ten years},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An overview of graphene-based sensors for organ-on-a-chip systems. <em>IET</em>, <em>12</em>, 2530002. (<a href='https://doi.org/10.1142/S2737599425300028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This literature review provides a concise overview of graphene-based sensors and their diverse applications. Various types of graphene sensors and their working principles are discussed, including field-effect transistors (FETs), resistive sensors, optical sensors, electrochemical sensors, surface-enhanced Raman spectroscopy (SERS) sensors, strain sensors, and thermal sensors. Each sensor type is described with relevant examples and potential applications. The review highlights significant advancements in graphene sensors, such as their healthcare applications in DNA sequencing and disease biomarker detection, real-time monitoring of air pollutants and water quality assessment, integration into wearable devices for vital sign monitoring and gesture recognition, and their role in energy harvesting systems. The advantages of graphene sensors, including exceptional sensitivity, rapid response time, wide analyte detection range, and compatibility with different substrates, are discussed. However, challenges such as large-scale graphene fabrication, sensitivity to environmental factors, and sensor-to-sensor variability persist. Additionally, the review delves into organ-on-a-chip (OOC) systems, microphysiological platforms that mimic human organs’ structure and function. The advantages of OOC systems, including physiologically relevant drug discovery, disease modeling, personalized medicine, and toxicity testing, are highlighted. The challenges and limitations of traditional in vitro and in vivo models are discussed, leading to the potential of OOC systems to address these limitations. The role of graphene in OOC systems as biosensors, electrodes, scaffolds, barriers, and membranes is examined, showcasing its contributions to enhanced functionality and physiological relevance. Overall, graphene-based sensors and OOC systems offer promising avenues for advanced sensing, drug discovery, disease modeling, and personalized medicine.},
  archive      = {J_IET},
  author       = {Lionel Jean Gabriel Ouedraogo and McKayla Kling and Nicole N. Hashemi},
  doi          = {10.1142/S2737599425300028},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2530002},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {An overview of graphene-based sensors for organ-on-a-chip systems},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robotics in healthcare: A review. <em>IET</em>, <em>12</em>, 2530001. (<a href='https://doi.org/10.1142/S2737599425300016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From early industrial prototypes in the 1960s and 1970s to sophisticated systems integrated into contemporary medical practice, healthcare robotics has come a long way in the last 10 years. Human potential has been enhanced by robotics in many ways, most notably in the areas of safety, accuracy, and repeatability. When paired with artificial intelligence (AI), these developments have enormous potential for the healthcare industry in the 21st century. These days, robots help in various places, such as healthcare facilities, assisted living apartments, and rehabilitation centers. For example, Aethon’s TUG robots carry supplies throughout hospitals effectively and lessen the effort of hospital staff. The main applications of healthcare robotics, including telepresence, rehabilitation, and operating rooms, are outlined in this chapter. Giraff and other telepresence robots allow doctors to observe patients from a distance. Hugo TM RAS system from Medtronic has recently garnered notice because of its availability as a modular minimally invasive surgery solution that directly competes with the Da Vinci System in hospitals across the globe. Taking a focus on surgery rooms, telemedicine, and assistive care, this manuscript offers a broad review of the most recent advancements in healthcare robotics. It highlights the difficulties in properly integrating these technologies into the medical field.},
  archive      = {J_IET},
  author       = {Dinesh Bhatia and Tania Acharjee and Agnila Sengupta},
  doi          = {10.1142/S2737599425300016},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2530001},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Robotics in healthcare: A review},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The organ-on-a-chip mirage: Animal replacement, plastic channels, and plastic claims: The false narrative behind the war on animal research. <em>IET</em>, <em>12</em>, 2520001. (<a href='https://doi.org/10.1142/S2737599425200014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Organ-on-a-chip platforms have been widely promoted as imminent replacements for animal research, a theme prominently featured in Science (August 14, 2025, pp. 676–679). This commentary critically examines these claims in light of the current evidence base. While microphysiological systems provide useful adjunctive data, their predictive scope is limited by selective validation, material sorption effects, reliance on nonspecific endpoints, and unverified assumptions about metabolic competence. Economic projections of industry-wide savings rest on optimistic modeling rather than empirical demonstration. Moreover, premature policy initiatives to phase out animal studies risk undermining patient safety. This article argues for cautious integration of new approach methodologies (NAMs) alongside, rather than instead of established animal research, with emphasis on independent multisite validation and global regulatory harmonization.},
  archive      = {J_IET},
  author       = {Martin L. Yarmush},
  doi          = {10.1142/S2737599425200014},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2520001},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {The organ-on-a-chip mirage: Animal replacement, plastic channels, and plastic claims: The false narrative behind the war on animal research},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effect of wear and frictional force on al6063-t6 with magnesium and zinc oxide nanoparticles. <em>IET</em>, <em>12</em>, 2440016. (<a href='https://doi.org/10.1142/S2737599424400164'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current investigation is to study the experimental analysis of wear and frictional force behavior on Al6063-T6 with zinc oxide (ZnO) and magnesium (Mg) nanoparticles. ZnO nanoparticles were extracted using Punica granatum peels by a green synthesis process. The extraction process of the nanoparticles was monitored with special temperature, time duration, and care of the extraction of the peels. This technique served as a representation of surface stabilization and a reducing agent for the fabrication of spherical ZnO nanoparticles. The aluminum (6063-T6) was combined with the optimized zinc (Zn) nanoparticles that had been produced. In general, aluminum has a low density and is lightweight, which increases its bearing strength and heat conductivity. The weight fractions of the Mg (1%, 1.5%, and 2.0%) and Zn (1.0%, 2.0%, and 3.0%) nanoparticles were mixed with aluminum. The mechanical properties of aluminum (Al6063-T6) with ZnO and Mg nanoparticles were determined experimentally at various volume fractions. Comparisons were made between the experimental outcomes with and without the addition of nanoparticles to the aluminum. The experimental findings show that Al6063-T6 with Zn and Mg nanoparticles can be employed in applications requiring wear resistance.},
  archive      = {J_IET},
  author       = {M. Bala Chennaiah and G. Dilli Babu and K. Dilip Kumar and Reddy Sreenivasulu and Tarunika Sharma and A. Somaiah and R. Meenakshi Reddy and Nishant Kumar},
  doi          = {10.1142/S2737599424400164},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2440016},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Effect of wear and frictional force on al6063-t6 with magnesium and zinc oxide nanoparticles},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijairr">IJAIRR - 4</h2>
<ul>
<li><details>
<summary>
(2025). Morpheus: A neural-driven animatronic face with hybrid actuation and diverse emotion control. <em>IJAIRR</em>, <em>2</em>, 2550004. (<a href='https://doi.org/10.1142/S2972335325500048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous animatronic faces struggle to express emotions effectively due to hardware and software limitations. On the hardware side, earlier approaches either used rigid-driven mechanisms, which provided precise control but were difficult to design within constrained spaces, or tendon-driven mechanisms, which are more space-efficient but challenging to control. In contrast, we propose a hybrid actuation approach that combines the best of both worlds. The eyes and mouth– key areas for emotional expression — are controlled using rigid mechanisms for precise movement, while the nose and cheek, which convey subtle facial microexpressions, are driven by strings. This design allows us to build a compact yet versatile hardware platform capable of expressing a wide range of emotions. On the algorithmic side, our method introduces a self-modeling network that maps motor actions to facial landmarks, allowing us to automatically establish the relationship between blendshape coefficients for different facial expressions and the corresponding motor control signals through gradient backpropagation. We then train a neural network to map speech input to corresponding blendshape controls. With our method, we can generate distinct emotional expressions such as happiness, fear, disgust, and anger, from any given sentence, each with nuanced, emotion-specific control signals — a feature that has not been demonstrated in earlier systems. We release the hardware design and code at https://github.com/ZZongzheng0918/Morpheus-Hardware and https://github.com/ZZongzheng0918/Morpheus-Software .},
  archive      = {J_IJAIRR},
  author       = {Zongzheng Zhang and Jiawen Yang and Ziqiao Peng and Meng Yang and Jianzhu Ma and Lin Cheng and Huazhe Xu and Hang Zhao and Hao Zhao},
  doi          = {10.1142/S2972335325500048},
  journal      = {International Journal of Artificial Intelligence and Robotics Research},
  pages        = {2550004},
  shortjournal = {Int. J. Artif. Intell. Robot. Res.},
  title        = {Morpheus: A neural-driven animatronic face with hybrid actuation and diverse emotion control},
  volume       = {2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A spontaneously emerging intelligence in a toroidal artificial world. <em>IJAIRR</em>, <em>2</em>, 2550003. (<a href='https://doi.org/10.1142/S2972335325500036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent operating mechanisms have so far emerged spontaneously in biology. At the beginning of life on Earth, completely ignorant beings gradually became able to understand their environment by building a knowledge base from their own experiences. In this paper, we attempt to outline the above process by observing the operation of artificial beings in an artificial world. The shape of this experimental world is a torus where squared fields are on the surface. The size can be changed, and any number of beings can be launched into it. There are energy sources and energy sinks in it. The creatures require energy and thus step from field to field to get energy. At the beginning of the process, beings are ignorant. They have no experience, but remember everything that happened to them. During the simulation, we observe the progress, destruction, or rise of the creatures. We examined their knowledge base, and the boom, or extinction of groups, families, and clans. In a completely hostile world, it is impossible to survive, but in a slightly hostile or friendly world, viable populations will certainly develop, that can use their knowledge base to assert themselves. The intelligence appears always if the circumstances are not too hostile and the existing entities can remember events that happened to them. The spontaneous emergence of intelligence is not exceptional, but natural.},
  archive      = {J_IJAIRR},
  author       = {Istvan Elek},
  doi          = {10.1142/S2972335325500036},
  journal      = {International Journal of Artificial Intelligence and Robotics Research},
  pages        = {2550003},
  shortjournal = {Int. J. Artif. Intell. Robot. Res.},
  title        = {A spontaneously emerging intelligence in a toroidal artificial world},
  volume       = {2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting scrap steel prices via machine learning for the central chinese market. <em>IJAIRR</em>, <em>2</em>, 2550002. (<a href='https://doi.org/10.1142/S2972335325500024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimates of price series for a wide variety of commodities have historically been depended on by investors and governments. This research examines the complex task of projecting scrap steel prices, which are released for the central China market upon a daily basis, using time-series data spanning 08/23/2013–04/15/2021. Prior studies have not adequately considered forecasts for this important commodity price indicator. In this case, cross-validation procedures and Bayesian optimization techniques are used to construct Gaussian process regression strategies, which are then used to provide price projections. With the relative root mean square error being 0.3211%, this empirical prediction framework offers rather precise price projections throughout the out-of-sample time frame extending from 09/17/2019 to 04/15/2021. Using price research models, governments and investors may make educated judgments about local scrap steel markets.},
  archive      = {J_IJAIRR},
  author       = {Bingzi Jin and Xiaojie Xu},
  doi          = {10.1142/S2972335325500024},
  journal      = {International Journal of Artificial Intelligence and Robotics Research},
  pages        = {2550002},
  shortjournal = {Int. J. Artif. Intell. Robot. Res.},
  title        = {Forecasting scrap steel prices via machine learning for the central chinese market},
  volume       = {2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models and prompt-based learning: Frontiers and challenges in cross-disciplinary applications. <em>IJAIRR</em>, <em>2</em>, 2530001. (<a href='https://doi.org/10.1142/S2972335325300019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) and prompt-based learning as transformative tools have been widely used across both academic and industrial domains. This paper reviews the current landscape of LLM applications, examining their principles, methodologies, strengths, and limitations. Beginning with an overview of the evolution from traditional feature engineering to prompt-based approaches, it highlights the applications of LLMs in diverse fields, including bioinformatics, materials science, and drug discovery. The review further examines the technical intricacies of prompt-based learning, contrasting hard and soft prompt techniques and their respective contributions to optimizing model performance. Real-world implementations are analyzed, with a focus on applications in bioinformatics and financial technology, alongside a discussion of pressing challenges related to data security and privacy. This paper also investigates the economic value generated by LLMs and their potential societal and workforce impacts, such as industry disruption and new job creation. The anticipated trajectory of LLMs and their broader societal implications are discussed, emphasizing the need for continued research and policy to guide its responsible development.},
  archive      = {J_IJAIRR},
  author       = {Yibo Chen and Gangqing Hu and Chun Xia and Lihua Yu and Mihail Popescu and Dong Xu},
  doi          = {10.1142/S2972335325300019},
  journal      = {International Journal of Artificial Intelligence and Robotics Research},
  pages        = {2530001},
  shortjournal = {Int. J. Artif. Intell. Robot. Res.},
  title        = {Large language models and prompt-based learning: Frontiers and challenges in cross-disciplinary applications},
  volume       = {2},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijait">IJAIT - 9</h2>
<ul>
<li><details>
<summary>
(2025). Edge computing-based signal processing for optimized-communication and anomaly detection in IoUT using TM-TCO and HMC-FRL. <em>IJAIT</em>, <em>34</em>(02n03), 2550012. (<a href='https://doi.org/10.1142/S0218213025500125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection and monitoring of anomalies in the underwater ecosystem are necessary to mitigate disasters. None of the traditional works concentrated on detecting the underwater anomalies regarding boundaries of the tectonic plates. Therefore, anomaly detection in the underwater ecosystem, particularly in relation to tectonic plate boundaries, is proposed. Using Dynamic Bit Permutation-SHA (DBP-SHA) hashing, Internet of Underwater Things (IoUT) devices are registered in a Multi-Hop Network. Tent Map Termite Colony Optimization (TM-TCO) optimizes pathways, whereas Terahertz Quantum Resistant Cryptographic Algorithm (Te-QRCA) guarantees secure data transfer. Density-Based Spatial Clustering of Applications with Noise (DB-SCAN) balances workload, while edge servers use the Exponential Gaussian Peak (EGP)-Fuzzy model to train local models that assess less sensor data, spot disaster trends, and produce labels. Then, the Hierarchical Meta-Curiosity-based Federated Reinforcement Learning (HMC-FRL) classifier is used for anomaly detection. The trained local model is updated on the cloud server. Thus, the communication is optimized and the anomaly is detected effectively in the IoUT with an accuracy of 98.671%.},
  archive      = {J_IJAIT},
  author       = {Rajababu Budda and Kannan Srinivasan and Rahul Jadon and Guman Singh Chauhan and Venkata Surya Teja Gollapalli and Joseph Bamidele Awotunde},
  doi          = {10.1142/S0218213025500125},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {02n03},
  pages        = {2550012},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Edge computing-based signal processing for optimized-communication and anomaly detection in IoUT using TM-TCO and HMC-FRL},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Edge AI-driven system for silkworm pupae gender classification and process control. <em>IJAIT</em>, <em>34</em>(02n03), 2550011. (<a href='https://doi.org/10.1142/S0218213025500113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In India, silkworms are essential to the production of silk. Silkworms have a 6–8 week life cycles. The process of turning a silkworm into a mature Bombyx mori moth yields peace of silk. Silkworms are more valuable because of their nutritional makeup, which includes vitamins, oils, proteins, minerals, and other beneficial elements. Silkworm diseases constitute a significant threat to the sericulture industry, causing substantial economic losses. However, there were research gaps in the areas of environmental factors and disease outbreaks. Existing diagnostic tools are limited in understanding complex disease interactions related to silkworm rearing. Addressing these research gaps is essential for improving silkworm disease prevention, control, and overall sericulture sustainability. Visual and time-consuming classification methods lead to errors, and it reduces productivity. Transfer learning was implemented for image classification. Gender classification of silkworm pupae using ResNetV2 architecture achieved 97% accuracy. The development of an automated system is done by employing a robotic arm integrated with a camera, Raspberry Pi, and Arduino Uno. A camera coupled with a Raspberry Pi captures high-resolution images of the pupae, subsequently processed for classification. Arduino Uno controls the robotic arm’s movements to classify each silkworm pupa by the category, like male, female or diseased. This automated AI based embedded hardware efficiently classifies the gender of silkworm pupa and hence reduces human intervention. The quality of silk production will be improved.},
  archive      = {J_IJAIT},
  author       = {V. Mekala and K. S. Tamilselvan},
  doi          = {10.1142/S0218213025500113},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {02n03},
  pages        = {2550011},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Edge AI-driven system for silkworm pupae gender classification and process control},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging multi-modal generative adversarial networks (GANs) for synthetic crime data simulation. <em>IJAIT</em>, <em>34</em>(02n03), 2550010. (<a href='https://doi.org/10.1142/S0218213025500101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crime analysis and predictive modeling in criminology face challenges due to data scarcity and privacy limitations. This happens due to a lack of comprehensive datasets that capture the complex aspects of crime. This research aims to develop a Multi-modal Generative Adversarial Network (MM-GAN) framework to accurately model complicated synthetic crime data. The goal of MM-GAN, which integrates several GAN architectures, is to provide varied and high-fidelity data depicting many crime elements in a unified model. These features include geographical distribution, temporal patterns, and category information. MM-GAN uses Conditional GANs (cGANs) to regulate the kinds of data produced according to crime characteristics like time, place, and kind. To further enhance the usability of the produced data for model training and guarantee that it properly represents real-world classifications, Auxiliary Classifier GANs (AC-GANs) are included to classify synthetic data. As a data format bridge, CycleGAN allows MM-GAN to represent various sources by facilitating cross-domain conversions between structured and unstructured. The model’s capacity to simulate seasonality and trends is enhanced by adding temporal GAN layers, which allow the model to capture sequential crime patterns. A strong resource for predictive analysis, risk assessment, and simulation training, MM-GAN-generated synthetic data closely matches real crime patterns, according to experiments. This framework provides a user-friendly and privacy-protecting tool for creating enhanced datasets, which is useful for criminology academics and law enforcement authorities. MM-GAN provides a scalable solution via synthetic data simulation to empower secure environments with Artificial Intelligence (AI)-driven insights and models.},
  archive      = {J_IJAIT},
  author       = {Tianyu Fan and Xiangyang Hu and Yuanhao Shi},
  doi          = {10.1142/S0218213025500101},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {02n03},
  pages        = {2550010},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Leveraging multi-modal generative adversarial networks (GANs) for synthetic crime data simulation},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A federated graph-based multimodal AI framework for privacy-preserving and explainable osteoporosis detection. <em>IJAIT</em>, <em>34</em>(02n03), 2550009. (<a href='https://doi.org/10.1142/S0218213025500095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Osteoporosis is a progressive skeletal disorder characterized by decreased Bone Mineral Density (BMD) and structural deterioration, leading to an increased risk of fractures. Traditional diagnostic methods, such as Dual-Energy X-ray Absorptiometry (DXA) and the Fracture Risk Assessment Tool (FRAX), often fail to detect osteoporosis at an early stage due to their limited sensitivity and accessibility. Recent advancements in Artificial Intelligence (AI), Deep Learning (DL), and Machine Learning (ML) have shown significant potential in improving osteoporosis detection. However, existing models face challenges related to data privacy, explainability, computational complexity, and generalizability across diverse populations. This study introduces Federated Graph-based Multimodal Osteoporosis Diagnosis (FGMOD), a novel AI-driven framework that integrates Federated Learning (FL) and Graph Neural Networks (GNNs) for enhanced osteoporosis risk assessment. Unlike traditional DL models that rely on centralized training, FL ensures privacy-preserving learning across multiple hospitals and institutions. Simultaneously, GNNs model trabecular bone connectivity, offering deeper insights into microarchitectural changes in osteoporotic bones. Multimodal data fusion, incorporating structured clinical data, DXA scans, and biochemical markers, significantly improves prediction accuracy and interpretability. The proposed FGMOD model was validated on a real-world dataset comprising 10 000 patient records, 5000 DXA scans, and biochemical profiles. Comparative evaluation with state-of-the-art AI models demonstrated superior performance, achieving 94.2% accuracy, 93.4% precision, 93.1% recall, and a ROC-AUC score of 0.96. Unlike CNN-based models, which rely heavily on high-resolution images, FGMOD effectively extracts clinically relevant features from graph-based bone connectivity analysis, ensuring robust and interpretable predictions. Furthermore, the use of SHAP-based feature importance analysis provides clinicians with an explainable AI decision-making process, enhancing trust in the model’s recommendations. Performance comparisons against CNN, Gradient Boosting, Random Forest, and Transfer Learning models revealed that FGMOD outperformed all baselines, particularly in privacy-aware federated training, osteoporosis risk stratification, and real-time inference on edge AI devices. Additionally, FGMOD reduced inference latency to 45 ms per sample, making it suitable for real-time clinical deployment. FGMOD represents a significant advancement in AI-powered osteoporosis detection, addressing key challenges such as privacy, generalizability, and interpretability. Future research should focus on expanding FL collaborations across global hospitals, integrating wearable sensor data for continuous bone health monitoring, and enhancing GNN-based osteoporosis modeling for faster inference on mobile healthcare platforms. This study paves the way for clinically reliable, privacy-preserving, and scalable AI solutions in osteoporosis risk assessment and early detection.},
  archive      = {J_IJAIT},
  author       = {O. Venkata Siva and M. S. Anbarasi},
  doi          = {10.1142/S0218213025500095},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {02n03},
  pages        = {2550009},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A federated graph-based multimodal AI framework for privacy-preserving and explainable osteoporosis detection},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chip detection based on improved RetinaNet and subpixel edge. <em>IJAIT</em>, <em>34</em>(1), 2550008. (<a href='https://doi.org/10.1142/S0218213025500083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection and positioning of surface mounted chips is a key step in achieving precise chip placement. Traditional formed chip detection methods can only detect one or more chips with similar characteristics and do not have universality, resulting in low chip detection efficiency. We studied the pin characteristics of surface mounted shape chips and proposed improved RetinaNet and Canny Franklin moment subpixel edge detection methods for coarse and precise positioning of chip pins, respectively. A lightweight attention mechanism combining space and channel was designed based on RetinaNet, which makes the network pay more attention to pin regions and improve feature utilization. The combination of K-Means and differential evolution algorithm is used to derive anchor ratio, reduce anchor box search time, and improve detection efficiency. By improving the Canny Franklin moment and performing subpixel edge detection on pins, the chip pins are positioned more accurately while ensuring efficiency. The experiment shows that our method maintains a detection accuracy of over 98.5%.},
  archive      = {J_IJAIT},
  author       = {Hongwei Liang and Yanli Zhao and Lingling Kan and Weifeng Qian and Wenhao Su},
  doi          = {10.1142/S0218213025500083},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {1},
  pages        = {2550008},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Chip detection based on improved RetinaNet and subpixel edge},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlocking seamless gesture-based interfaces: Hand gesture recognition with 3DCNN and LSTM. <em>IJAIT</em>, <em>34</em>(1), 2550007. (<a href='https://doi.org/10.1142/S0218213025500071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the symphony of human communication, the fusion of words and gestures creates a nuanced expression that transcends mere verbal exchange. Replicating this intricate dance in the realm of Artificial Intelligence (AI) has become a compelling challenge, with innovations aiming to make digital experiences more human-centric. This work addresses the challenge of gesture recognition by leveraging 3D Convolutional Neural Networks (3DCNN) and Long Short-Term Memory (LSTM) to analyze hand gestures, focusing on time-series data derived from human pose detection. While both 3DCNN and LSTM have been used separately in related fields, their combination for gesture recognition has not been widely explored. The proposed model effectively extracts spatial features using 3DCNN and captures temporal dynamics with LSTM, leading to a 94% accuracy in ten-class classification using a five-fold cross-validation on 400 videos from four participants. Consequently, this work potentially marks a transformative era in gesture recognition, enabling contactless operation of hardware devices for more interactive experiences.},
  archive      = {J_IJAIT},
  author       = {Jun-Wei Tsai and Sze-Teng Liong and Y. S. Gan},
  doi          = {10.1142/S0218213025500071},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {1},
  pages        = {2550007},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Unlocking seamless gesture-based interfaces: Hand gesture recognition with 3DCNN and LSTM},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GA-RISE: Posthoc model agnostic explanations of black-box classifiers using genetic algorithm-based optimized masks — A case study on chest X-ray images. <em>IJAIT</em>, <em>34</em>(1), 2550006. (<a href='https://doi.org/10.1142/S021821302550006X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intricate and recursive nature of deep learning models often obscures their inner workings, limiting their applications in high-risk domains like medical image analysis. The development of Explainable AI (XAI) methods has addressed this limitation by providing human-readable insights into these black-box models, which are widely used in image-based tasks such as classification, segmentation, and localization. One popular and effective XAI technique is Randomized Input Sampling for Explanation (RISE), which uses a large number of random masks to visualize model behavior. However, RISE’s requirement for numerous masks leads to high space complexity. In this paper, we propose a modified RISE technique that optimizes the use of a relatively small number of masks through a Genetic Algorithm to enhance comprehensibility. Experiments with state-of-the-art classifier models on a publicly available Chest X-ray dataset demonstrate that our approach outperforms other commonly used post hoc model-agnostic and non-model-agnostic techniques in terms of explanation quality and faithfulness metrics.},
  archive      = {J_IJAIT},
  author       = {Somenath Kuiry and Dibyasree Guha and Alaka Das and Kasturi Das and Mita Nasipuri and Nibaran Das},
  doi          = {10.1142/S021821302550006X},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {1},
  pages        = {2550006},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {GA-RISE: Posthoc model agnostic explanations of black-box classifiers using genetic algorithm-based optimized masks — A case study on chest X-ray images},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Empirical analysis on machine translation possibilities for low-resource santali language. <em>IJAIT</em>, <em>34</em>(1), 2550005. (<a href='https://doi.org/10.1142/S0218213025500058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-resource Indian language development is a crucial and challenging task due to the linguistic diversity within India. This paper overviews the work and the importance of creating technologies and resources for these languages. India has about 19,500 languages, yet only 122 are considered significant. Many languages lack comprehensive linguistic resources, such as linguistic tools, well-annotated corpora, and natural language processing (NLP) models. These essential resources are missing for numerous languages, hindering the development of NLP systems. Of the approximately 1.4 billion people in India, only 20% are proficient in English, which is the dominant language of many online resources. Therefore, translating content into local languages is crucial for improving communication. For several reasons, it is crucial to develop technologies and resources for underrepresented Indian languages. This review focuses on (1) A comprehensive analysis of machine translation systems, (2) Key challenges in interface-equipped machine translation systems, (3) The application of automated machine translation, (4) Difficulties with automated machine translation, and (5) A thorough description of the methodologies and results related to machine translation. The paper analyzes several concerns and proposes efficient solutions to address these challenges.},
  archive      = {J_IJAIT},
  author       = {Sunil Kumar Sahoo and Bhramara Bar Biswal and Satya Ranjan Dash and Jyotiprakash Patra},
  doi          = {10.1142/S0218213025500058},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {1},
  pages        = {2550005},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Empirical analysis on machine translation possibilities for low-resource santali language},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An interactive real-time 3D representation of a heart using a 2D ultrasound vest: Proof of concept. <em>IJAIT</em>, <em>34</em>(1), 2550004. (<a href='https://doi.org/10.1142/S0218213025500046'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the population of older adults increases worldwide, the number of individuals afflicted with cardiovascular issues and diseases is also increasing. The rate at which individuals worldwide succumb to cardiovascular disease (CVD) is rising as well. That is, the World Health Organization (WHO) reports that the number one cause of death globally is from CVD either in the form of myocardial infarctions or strokes. The primary ways of assisting individuals with CVD are from either improved treatments, monitoring research, or primary and secondary prevention measures. In the form of cardiovascular structural monitoring, ultrasonography is very prevalent and allows for multiple configurations, is the least expensive, and has no detrimental side effects to the patient. This is the proof of concept study that investigates how we can combine a wearable ultrasound vest of multiple 2D transducers to create a 3D model of the heart for continuous monitoring. Furthermore, we create functional models to represent the states the heart can be in both respect to normal operations as well as Atrial Fibrillation. Using the wearable ultrasound vest created in our previous work, a 3D model is created via a structure from motion approach with synthetic data. Also, a denoising process is created to assist the modeling process. The 3D model is constructed with up to three views. That is, via the parasternal, frontal, and apical views where the frontal view is the halfway point between the apical and parasternal views. Furthermore, stochastic petri nets (SPN) are created to represent the cyclic states of the heart. The experimental results show a 3D model of the synthetic heart constructed from a point cloud created by the structure from the motion approach. Then, it is successfully denoised with our outlier detection and removal process. The resulting 3D model allows us to calculate surface areas and perform the continuous monitoring we initially set out to do. Finally, multiple SPN models are created for functional feature extraction as well as to assist medical professionals in continuous cardiovascular monitoring. In this paper, we demonstrated the structure from the motion approach to create a 3D model of the heart with our wearable ultrasound vest construction. Furthermore, we provided multiple SPN models for functional feature extraction and to monitor a normal heart and a heart affected by Atrial Fibrillation.},
  archive      = {J_IJAIT},
  author       = {G. Goodman and N. Bourbakis},
  doi          = {10.1142/S0218213025500046},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {1},
  pages        = {2550004},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {An interactive real-time 3D representation of a heart using a 2D ultrasound vest: Proof of concept},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijcia">IJCIA - 30</h2>
<ul>
<li><details>
<summary>
(2025). Calendar of events. <em>IJCIA</em>, <em>24</em>(3), 2583003. (<a href='https://doi.org/10.1142/S1469026825830032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIA},
  doi          = {10.1142/S1469026825830032},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2583003},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Calendar of events},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSR: A personalized movie recommendation model based on gate mechanism and attention network. <em>IJCIA</em>, <em>24</em>(3), 2442004. (<a href='https://doi.org/10.1142/S1469026824420045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized recommendation systems play a crucial role in alleviating information overload and satisfying users’ specific preferences. To address the challenges of inadequate user historical data extraction and the cold start problem inherent in traditional movie recommendation systems, we present a novel personalized movie recommendation model known as “movie recommendation with starring roles and ratings” (MSR). By incorporating a multi-head attention mechanism, the model captures intricate relationships among diverse data fields within users’ viewing records and facilitates the extraction of user features through the basic information-rating joint attention network (BRJA). The gate mechanism efficiently integrates fundamental movie information and average score into the movie representation vector, thereby generating candidate movie features. MSR can effectively provide recommendations even when confronted with limited user information, effectively mitigating the cold start problem. Comparative experiments on the movie lens dataset and ablation experiments focusing on key modules demonstrate the effectiveness of MSR in improving movie recommendations.},
  archive      = {J_IJCIA},
  author       = {Lei Liu and Jie Zhu and Jia Mi and Jing Li and Xinyu Cao and Haitao Wang},
  doi          = {10.1142/S1469026824420045},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2442004},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {MSR: A personalized movie recommendation model based on gate mechanism and attention network},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A real-time posture detection algorithm based on deep learning. <em>IJCIA</em>, <em>24</em>(3), 2442003. (<a href='https://doi.org/10.1142/S1469026824420033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of machine vision and multimedia technology, posture detection and related algorithms have become widely used in the field of human posture recognition. Traditional video surveillance methods have the disadvantages of slow detection speed, low accuracy, interference from occlusions, and poor real-time performance. This paper proposes a real-time pose detection algorithm based on deep learning, which can effectively perform real-time tracking and detection of single and multiple individuals in different indoor and outdoor environments and at different distances. First, a corresponding pose recognition dataset for complex scenes was created based on the YOLO network. Then, the OpenPose method was used to detect key points of the human body. Finally, the Kalman filter multi-object tracking method was used to predict the state of human targets within the occluded area. Real-time detection of human postures (sitting, stand up, standing, sit down, walking, fall down, and lying down) is achieved with corresponding alarms to ensure the timely detection and processing of emergencies.},
  archive      = {J_IJCIA},
  author       = {Yujie Jiang and Rongzhi Hang and Weipeng Huang and Yanhao Wu and Xiaoping Pan and Zhi Tao},
  doi          = {10.1142/S1469026824420033},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2442003},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {A real-time posture detection algorithm based on deep learning},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Informer-based method for stock intraday price prediction. <em>IJCIA</em>, <em>24</em>(3), 2442002. (<a href='https://doi.org/10.1142/S1469026824420021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a component of the capital market, the stock market plays a very important role in economic development. How to predict the stock price more accurately is the key concern of researchers and investors. To solve the above problems, this paper proposes an Informer based method for stock intraday price prediction. Informer based on attention mechanism can efficiently capture precise long-range dependencies between input and output to increase the prediction capacity. In this research, historical K-line data of traditional securities in China’s financial market are collected. Based on this data set, the intraday stock price prediction performance of Informer and Long Short-Term Memory neural network (LSTM) is compared. The experiment also uses the three-day K-line model to perform pattern recognition on the K-line data of candidate stocks. The results show that the prediction performance of Informer is significantly higher than that of LSTM, and the data information after three-day K-line pattern recognition can improve the prediction accuracy of Informer and reduce time and space overhead of Informer.},
  archive      = {J_IJCIA},
  author       = {Chen Zhang and Yu Sun and Ying Ding and Jiaxu Ning and Changsheng Zhang},
  doi          = {10.1142/S1469026824420021},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2442002},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Informer-based method for stock intraday price prediction},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Swin-caption: Swin transformer-based image captioning with feature enhancement and multi-stage fusion. <em>IJCIA</em>, <em>24</em>(3), 2442001. (<a href='https://doi.org/10.1142/S146902682442001X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of image captioning is to empower computers to generate human-like sentences autonomously, describing a provided image. To tackle the challenges of insufficient accuracy in image feature extraction and underutilization of visual information, we present a Swin Transformer-based model for image captioning with feature enhancement and multi-stage fusion (Swin-Caption). Initially, the Swin Transformer is employed in the capacity of an encoder for extracting images, while feature enhancement is adopted to gather additional image feature information. Subsequently, a multi-stage image and semantic fusion module is constructed to utilize the semantic information from past time steps. Lastly, a two-layer LSTM is utilized to decode semantic and image data, generating captions. The proposed model outperforms the baseline model in experimental tests and instance analysis on the public datasets Flickr8K, Flickr30K, and MS-COCO.},
  archive      = {J_IJCIA},
  author       = {Lei Liu and Yidi Jiao and Xiaoran Li and Jing Li and Haitao Wang and Xinyu Cao},
  doi          = {10.1142/S146902682442001X},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2442001},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Swin-caption: Swin transformer-based image captioning with feature enhancement and multi-stage fusion},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on fault detection for microservices based on log information and social network mechanism using BiLSTM-DCNN model. <em>IJCIA</em>, <em>24</em>(3), 2342002. (<a href='https://doi.org/10.1142/S1469026823420026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The microservice architecture breaks through the traditional cluster architecture mode based on virtual machines and uses containers as carriers to interact through lightweight communication mechanisms to reduce system coupling and provide more flexible system service support. With the expansion of the system scale, a large number of system logs with complex structures and chaotic relationships are generated. How to accurately analyze the system logs and make efficient fault prediction is particularly important for building a safe and reliable system. By studying neural network technology, this paper proposes an Attention-Based Bidirectional Long Short-Term Memory Network (Bi-LSTM). Combined with the dual channel convolutional neural network model (DCNN), it uses the attention mechanism to explore the differences between dimensional features, realizes multi-dimensional feature fusion, and establishes a BiLSTM-DCNN deep learning model that integrates the attention mechanism. From the perspective of social network analysis, a data preprocessing method is proposed to process fault redundant data and improve the accuracy of fault prediction under Microservices. Compare BiLSTM-DCNN with the mainstream system log analysis machine learning models SVM, CNN and Bi-LSTM, and explore the advantages of BiLSTM-DCNN in processing microservice system log text. The model is applied to simulation data and HDFS data set for experimental comparison, which proves the good generalization ability and universality of BiLSTM-DCNN.},
  archive      = {J_IJCIA},
  author       = {Shuai-Peng Guan and Zi-Hao Chen and Pei-Xuan Wu and Man-Yuan Guo},
  doi          = {10.1142/S1469026823420026},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2342002},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Research on fault detection for microservices based on log information and social network mechanism using BiLSTM-DCNN model},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on the investment strategy of private equity investment fund targeted increase in NEEQ — An empirical analysis based on BP and hopfield neural network model. <em>IJCIA</em>, <em>24</em>(3), 2342001. (<a href='https://doi.org/10.1142/S1469026823420014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Private equity investment funds targeted increase in NEEQ has become a new strategy for PE investment. However, the currently adopted Logit regression and one-factor ANOVA models are not suitable for analyzing nonlinear investment activities, and the investment appraisal does not work well. In this paper, all NEEQ companies that implemented private placement in 2017 are used as the study sample. This paper also empirically analyzes the current situation of domestic private equity investment funds based on BP and Hopfield neural network models, then the results of the two models are compared. It is concluded that the accuracy of the BP neural network model can be more than 90%. So, the BP neural network can be used as the optimal model of private equity investment funds investment strategy in NEEQ.},
  archive      = {J_IJCIA},
  author       = {Yajuan Liu and Wenbin Xu},
  doi          = {10.1142/S1469026823420014},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {3},
  pages        = {2342001},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Research on the investment strategy of private equity investment fund targeted increase in NEEQ — An empirical analysis based on BP and hopfield neural network model},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Calendar of events. <em>IJCIA</em>, <em>24</em>(2), 2583002. (<a href='https://doi.org/10.1142/S1469026825830020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIA},
  doi          = {10.1142/S1469026825830020},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2583002},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Calendar of events},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network model for early detection of currency crisis in singapore: Optimization comparison. <em>IJCIA</em>, <em>24</em>(2), 2550004. (<a href='https://doi.org/10.1142/S146902682550004X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to develop an early detection model for the currency crisis in Singapore using a neural network (NN) algorithm based on macroeconomic indicators. By utilizing the exchange market pressure (EMP) threshold approach, this study identifies currency crisis signals that can function as early warnings. In this study, a comparison of four NN optimization methods was conducted, namely stochastic gradient descent (SGD), Adam, Nadam, and AdaBound. The data used include 11 macroeconomic indicators from January 1990 to June 2021. The study results show that the NN model with Nadam optimization provides the best performance, with higher accuracy, sensitivity, and specificity compared to other optimization methods. This model successfully predicted crisis signals with an accuracy of 95.89%, a sensitivity of 98.36%, and a specificity of 83.33%. These findings can be used as a basis for decision-making in anticipating the currency crisis in Singapore.},
  archive      = {J_IJCIA},
  author       = {Sugiyanto and Etik Zukhronah and Fadia Mulyarti and Ihsan Fathoni Amri},
  doi          = {10.1142/S146902682550004X},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2550004},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Neural network model for early detection of currency crisis in singapore: Optimization comparison},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Centralized infrastructure-aware reliable data transaction model in IoT-enabled MANET and cloud using LDMOA and ELRNN. <em>IJCIA</em>, <em>24</em>(2), 2550003. (<a href='https://doi.org/10.1142/S1469026825500038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile ad-hoc networks (MANETs) face significant challenges due to the lack of centralized infrastructure and efficient routing techniques, which hinder optimal data transfer. This paper addresses these challenges by proposing a Centralized Infrastructure-Aware, Reliable Data Transaction Model for IoT-enabled MANETs in a cloud environment. The model incorporates novel approaches to enhance network efficiency and security, including the Learning-based Multi-objective Optimization Algorithm (LDMOA) and Extended Long-Short Term Recurrent Neural Network (ELRNN). The proposed framework operates in several stages: node initialization, optimal cluster head selection using LDMOA, and clustering. Multipath generation and path detail extraction follow, after which a hash tree is constructed and stored on a fog server. The trustworthiness of each path is evaluated using the KT-Fuzzy decision-making algorithm. If the trust is high, LDMOA selects the optimal path for data transfer, which is then encrypted using the Extended Particle Collision Chaos (EPCC) algorithm. The path’s hash code is verified in the fog server, and the data undergoes intrusion detection. The data path is re-configured if an attack is detected; otherwise, secure data are forwarded to the cloud server. The intrusion detection process involves data collection, feature extraction, and classification, with ELRNN used to predict potential attacks. The proposed ELRNN model achieves an accuracy of 98.42%, significantly outperforming traditional methods such as RNN, RBM, DBN, and DNN, which have maximum accuracies of around 93.57%. This improvement highlights the effectiveness of the ELRNN in detecting intrusions in Blockchain-based IoT devices, showcasing enhanced performance in precision, recall, and overall reliability compared to existing techniques.},
  archive      = {J_IJCIA},
  author       = {Sreekar Peddi and Dharma Teja Valivarthi and Swapna Narla and Sai Sathish Kethu and Durai Rajesh Natarajan and Dede Kurniadi},
  doi          = {10.1142/S1469026825500038},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2550003},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Centralized infrastructure-aware reliable data transaction model in IoT-enabled MANET and cloud using LDMOA and ELRNN},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-strategy artificial electric field algorithm for numerical optimization. <em>IJCIA</em>, <em>24</em>(2), 2550002. (<a href='https://doi.org/10.1142/S1469026825500026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial electric field algorithm (AEFA) is a metaheuristic optimization algorithm proposed in recent years, which has been successfully applied to address various optimization problems. However, it is likely to converge prematurely or fall into local optima when solving complex problems. To overcome these disadvantages, a multi-strategy artificial electric field algorithm (MAEFA) is proposed in this paper. For the MAEFA algorithm, the global optimal solution information is utilized to improve the diversity of population and global search ability. Then, the adaptive Coulomb’s constant is configured to balance the global exploration and local search. Also, a restart strategy is designed to further alleviate the premature convergence. To validate the effectiveness of MAEFA, it is compared with three AEFA algorithms and several other evolutionary algorithms on 14 test problems presented in CEC 2005 and 13 basic benchmark functions. Furthermore, a wind power prediction model based on MAEFA algorithm and back-propagation (BP) neural network is established to investigate its application ability. Experiments show that MAEFA is significantly superior to other algorithms in tackling these benchmark functions with different dimensions. Furthermore, in terms of wind power prediction, the BP neural network model optimized by MAEFA algorithm also provides higher prediction accuracy.},
  archive      = {J_IJCIA},
  author       = {Zhichao Feng and Jiatang Cheng},
  doi          = {10.1142/S1469026825500026},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2550002},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {A multi-strategy artificial electric field algorithm for numerical optimization},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deepfake video detection: A novel approach via NLP-based classification. <em>IJCIA</em>, <em>24</em>(2), 2550001. (<a href='https://doi.org/10.1142/S1469026825500014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the Deepfake technology is mainly used to harm people’s reputations and can trick the face recognition system by swapping faces between people, raising significant security concerns. Thus, methods for detecting Deepfake are crucial. The recent methods for Deepfake detection have performed well in distinguishing real content from fake content. Some research employed the Transformer technique, commonly used in natural language processing (NLP), to enhance performance. Therefore, this paper proposes a novel deepfake detection method that transforms extracted features into words and utilizes NLP techniques for deepfake classification. We employed a fine-tuned pre-trained Convolutional Neural Network (CNN) model to extract features from the face images in the videos. These extracted features are labeled based on grouping methods, such as mean and standard deviation (SD). Tokenization and classification are then performed using Long Short-Term Memory (LSTM) and Recurrent Neural Network (RNN). Additionally, Bidirectional Encoder Representations from Transformers (BERT) is used as another tokenizer and classifier to compare the performance of deepfake detection between the traditional model and the NLP model. The result states that the method using BERT as a tokenizer and classifier with Mean and SD grouping method shows better efficiency, achieving 99.57% on the Roc Curve, 99.58% Accuracy, 99.18% Precision, 100.00% recall, and 99.59% F -measure.},
  archive      = {J_IJCIA},
  author       = {Patchraphon Bunluesakdikul and Waranya Mahanan and Prompong Sungunnasil and Sumalee Sangamuang},
  doi          = {10.1142/S1469026825500014},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2550001},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Deepfake video detection: A novel approach via NLP-based classification},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FlightKoopman: Deep koopman for multi-dimensional flight trajectory prediction. <em>IJCIA</em>, <em>24</em>(2), 2450038. (<a href='https://doi.org/10.1142/S146902682450038X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-dimensional Flight Trajectory Prediction (MFTP) in Flight Operations Quality Assessment (FOQA) refers to the estimation of flight status at the future time, accurate prediction future flight positions, flight attitude and aero-engine monitoring parameters are its goals. Due to differences between flight trajectories and other kinds trajectories and difficult access to data and complex domain knowledge, MFTP in FOQA is much more challenging than Flight Trajectory Prediction (FTP) in Air Traffic Control (ATC) and other trajectory prediction. In this work, a deep Koopman neural operator-based multi-dimensional flight trajectory prediction framework, called Deep Koopman Neural Operator-Based Multi-Dimensional Flight Trajectories Prediction (FlightKoopman), is first proposed to address this challenge. This framework is based on data-driven Koopman theory, enables to construct a prediction model using only data without any prior knowledge, and approximate operator pattern to capture flight maneuver for downstream tasks. The framework recovers the complete state space of the flight dynamics system with Hankle embedding and reconstructs its phase space, and combines a fully connected neural network to generate the observation function of the state space and the approximation matrix of the Koopman operator to obtain an overall model for predicting the evolution. The paper also reveals a virgin dataset Civil Aviation Flight University of China (CAFUC) that could be used for MFTP tasks or other flight trajectory tasks. CAFUC Datasets and code is available at this repository: https://github.com/CAFUC-JJJ/FlightKoopman . Experiments on the real-world dataset demonstrate that FlightKoopman outperforms other baselines.},
  archive      = {J_IJCIA},
  author       = {Jing Lu and Jingjun Jiang and Yidan Bai and Wenxiang Dai and Wei Zhang},
  doi          = {10.1142/S146902682450038X},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2450038},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {FlightKoopman: Deep koopman for multi-dimensional flight trajectory prediction},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual deep autoencoder split generative adversarial networks with gooseneck barnacle optimization-based prediction of autism spectrum disorder in facial images. <em>IJCIA</em>, <em>24</em>(2), 2450037. (<a href='https://doi.org/10.1142/S1469026824500378'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism spectrum disorder (ASD) is a developmental disability that poses significant challenges in social interaction, communication, and behavior. Individuals with ASD have unique ways of interacting and communicating, and early prediction is crucial for timely therapy. Researchers are focusing on predicting ASD using image-processing techniques due to its neurological nature. The proposed novel Hybrid Convolutional Bilateral filter-based Deep Dual Swin Axial Generator Attention with Gooseneck Barnacle Optimization (FCB-DDSATGA-GBO) accurately predicts ASD. The facial image dataset is the input data source. The Hybrid Fast Convolutional Bilateral Filter (HFCBF) is used to pre-process the data. Dual Deep Autoencoder and Split Generative Adversarial Network (DDASGAN) is used to extract static features. Additionally, Swin-Gated Axial Attention Transformer (SGAAT) is used to segment the image. To forecast ASD, DDASGAN is used and optimized with Gooseneck Barnacle Optimization (GBO). The performance of the suggested methodology can be assessed using measures such as accuracy, recall, precision, sensitivity, f-score, and error, and compared to existing methods. The suggested FCB-DDSATGA-GBO model outperforms the current techniques, offering an enhanced f1-score of 99.66%, recall of 99.66%, accuracy of 99.67%, specificity of 99.67%, and precision of 99.66% when utilizing facial images.},
  archive      = {J_IJCIA},
  author       = {Jyothi Goddu and S. Anuradha and Yarramalle Srinivas},
  doi          = {10.1142/S1469026824500378},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2450037},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Dual deep autoencoder split generative adversarial networks with gooseneck barnacle optimization-based prediction of autism spectrum disorder in facial images},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integration of solar photovoltaic with modular multiport converter using a pi controller optimized through hybrid osprey optimization algorithm and relational bi-level aggregation graph network. <em>IJCIA</em>, <em>24</em>(2), 2450036. (<a href='https://doi.org/10.1142/S1469026824500366'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of solar photovoltaic (SPV) systems with modular multiport converters (MMPC) enables efficient energy conversion and distribution, enhancing the overall performance and reliability of renewable energy systems (RES). However, the complexity of the control algorithms and potential issues related to the dynamic response can pose challenges in achieving optimal performance and stability in varying operating conditions. This paper proposes a hybrid method for integrating SPV systems with MMPC to achieve efficient power management in modern renewable energy grids. The proposed hybrid method is the combined execution of the Osprey Optimization Algorithm (OOA) and Relational Bi-level Aggregation Graph Convolutional Network (RBAGCN). Hence it is named as OOA-RBAGCN technique. The aim is to ensure optimal power transfer, minimize total harmonic distortion (THD), maintain voltage stability under dynamic operating conditions, and ultimately improve the overall energy efficiency, reliability, and performance of SPV-based RES within smart grid applications. The OOA is used to optimize the control parameter of the proportional-integral (PI) controller. The RBAGCN is used to predict these optimized parameters. By then, the proposed approach is used on the MATLAB platform and compared with other approaches such as Starling Murmuration Optimization (SMO), Dung Beetle Optimizer (DBO), Improved Harris Hawks Optimization (IHHO), Grey Wolf Optimization (GWO), and Particle Swarm Optimization (PSO). The proposed method achieves a high efficiency of 98.1%, and a reduced THD of 2.9% significantly surpassing all existing methods.},
  archive      = {J_IJCIA},
  author       = {Srinivasa Rao Balasani and T. Santhana Krishnan and P. Venkata Prasad and Leeth Hassen Jaseem},
  doi          = {10.1142/S1469026824500366},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2450036},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Integration of solar photovoltaic with modular multiport converter using a pi controller optimized through hybrid osprey optimization algorithm and relational bi-level aggregation graph network},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IoT-cloud-centric smart healthcare monitoring system for heart disease prediction using a gated-controlled deep unfolding network with crayfish optimization. <em>IJCIA</em>, <em>24</em>(2), 2450035. (<a href='https://doi.org/10.1142/S1469026824500354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rising incidence of heart disease requires effective and robust prediction algorithms, especially in Internet of Things (IoT)-cloud-based smart healthcare frameworks. This study presents a novel method for forecasting cardiovascular disease using superior data preprocessing, feature selection, and deep learning techniques. First, preprocessing is done using the Z-score min–max normalization technique to ensure consistent data scaling and standardize the dataset. After preprocessing, an innovative hybrid feature selection technique that combines Black Widow Optimization (BWO) and Influencer Buddy Optimization (IBO) is utilized. By achieving equilibrium between invention and execution, the BWO-IBO technique enhances feature selection and extracts the most pertinent information for heart disease prediction. The Gates-Controlled Deep Unfolding Network (GCDUN), which is based on the Crayfish Optimization Algorithm (COA), is an innovative framework for prediction. Through the use of a gates-controlled mechanism and a COA component that speeds up network parameter tuning based on crayfish behavior, GCDUN-COA increases feature representation and enhances the decision plane. The fusion of the IoT and a cloud-based framework takes the present data collection, processing, and remote monitoring a notch higher, thus making the system highly scalable and efficient for clinical use. When predicting cardiac disease, the method recommended shows improved F1-score, specificity, accuracy, recall, and precision continuously achieving above 99% across all performance metrics. By providing prompt diagnosis and intervention via an intelligent, adaptive prediction system, an IoT-driven cloud-based medical technology has the potential to revolutionize cardiac care.},
  archive      = {J_IJCIA},
  author       = {Harish Kumar and Anuradha Taluja and R. Giri Prasad and Elangovan Muniyandy},
  doi          = {10.1142/S1469026824500354},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2450035},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {IoT-cloud-centric smart healthcare monitoring system for heart disease prediction using a gated-controlled deep unfolding network with crayfish optimization},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MKGFA: Multimodal knowledge graph construction and fact-assisted reasoning for VQA. <em>IJCIA</em>, <em>24</em>(2), 2450034. (<a href='https://doi.org/10.1142/S1469026824500342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge-based visual question answering relies on open-ended external knowledge and a fine-grained comprehension of both the visual content of images and semantic information. Existing methods for utilizing knowledge have the following limitations: (1) Language pre-training methods output answers in the form of plain text, which only understand shallow visual content; (2) The knowledge retrieved by image objects as labels is represented as first-order logic, making it difficult to infer complex questions. To address the above problems, this paper integrates visual-textual multimodal information, accumulates domain-specific and external multi-modal knowledge, introduces and supplements external objective facts, and proposes a multimodal knowledge graph construction and fact-assisted reasoning network (MKGFA). The network consists of three parts: the multimodal knowledge graph construction module (MKGC), the objective fact-assisted reasoning module (FAR), and the answer inference module. The MKGC engages in the coarse-to-fine-grained learning of triplet representations for multimodal knowledge units. The FAR establishes deep cross-modal relations between visual objects and factual words for correlating real answers. The answer inference module makes the final decision based on the results of both. Among them, the former two modules employ a pre-training and fine-tuning strategy, systematically accumulating foundational and domain-specific knowledge. Compared with the state-of-the-arts, MKGFA achieves 1.09% and 0.7% higher accuracy on the two challenging OKVQA and KRVQA datasets, respectively. The experimental results demonstrate the complementary advantages of the integration of the two modules.},
  archive      = {J_IJCIA},
  author       = {Longbao Wang and Jinhao Zhang and Libing Zhang and Shuai Zhang and Shufang Xu and Lin Yu and Hongmin Gao},
  doi          = {10.1142/S1469026824500342},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {2},
  pages        = {2450034},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {MKGFA: Multimodal knowledge graph construction and fact-assisted reasoning for VQA},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Calendar of events. <em>IJCIA</em>, <em>24</em>(1), 2583001. (<a href='https://doi.org/10.1142/S1469026825830019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIA},
  doi          = {10.1142/S1469026825830019},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2583001},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Calendar of events},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective deep learning-based intrusion detection system for the healthcare environment. <em>IJCIA</em>, <em>24</em>(1), 2450033. (<a href='https://doi.org/10.1142/S1469026824500330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the medical field, Internet of Things (IoT) applications allow for real-time diagnosis and remote patient monitoring, commonly called Internet of Health Things (IoHT). However, cybersecurity attacks may interrupt hospital operations and threaten patients’ health and well-being due to this integration. Hence, developing an Intrusion Detection System (IDS) suited explicitly for healthcare systems is essential to ensure efficiency and accuracy. Nevertheless, it is challenging to integrate anomaly-based IDS frameworks in healthcare systems as they necessitate additional processing time, temporal feature retention, and increased complexity. Therefore, a deep learning system based on SqueezeNet and NasNet is presented in this paper to detect intrusions in a healthcare setting. In this, SqueezeNet is employed to extract more significant features. On the other hand, network breaches while data transmission across distinct locations are detected by the NasNet-based classifier. In addition, the Rider Optimization Algorithm (ROA) is applied to adjust the classifier’s hyperparameters, guaranteeing that it would accurately detect attacks. Moreover, the Auxiliary Classifier Generative Adversarial Network (ACGAN) approach is integrated into the proposed framework to avoid data imbalance. Applying different performance constraints, the proposed approach is thoroughly assessed on three publicly available datasets (TON-IoT, ECU-IoHT, and WUSTL-EHMS). The results show that the proposed deep learning-based cybersecurity model outperforms traditional methods and produces better outcomes.},
  archive      = {J_IJCIA},
  author       = {K. Balaji and S. Satheesh Kumar and D. Vivek and S. Prem Kumar Deepak and K. V. Daya Sagar and S. Thabassum Khan},
  doi          = {10.1142/S1469026824500330},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450033},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {An effective deep learning-based intrusion detection system for the healthcare environment},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RN-STLSTM-GAN: Spatiotemporal-guided generative adversarial network for time-evolving precipitation downscaling. <em>IJCIA</em>, <em>24</em>(1), 2450032. (<a href='https://doi.org/10.1142/S1469026824500329'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial networks (GANs) have been widely applied in the field of meteorological research, particularly in the downscaling of images due to their ability to generate super-resolution images. In recent years, numerous researchers have combined GANs with recurrent neural networks (RNNs) to address the issue of meteorological super-resolution. However, these models do not take into account the spatial variations of meteorological sequences. In this paper, we propose a super-resolution method named RN-STLSTM-GAN, which combines GANs with RN-STLSTM and ESA networks to learn the spatiotemporal features of meteorological sequences. Specifically, we first apply the RN-STLSTM at the initialization of the generator and discriminator to learn the spatiotemporal relationships between sequential images. Second, an ESA network is combined with the RN-STLSTM structure to enhance the learning of spatial features. Thirdly, LeakyReLU is used as the activation function for both the generator and discriminator to minimize the loss of image data during model training. Experiments conducted on the NJU-CPOL datasets demonstrate that our proposed method outperforms other existing methods and can generate realistic and temporally consistent super-resolution sequences for datasets at different heights.},
  archive      = {J_IJCIA},
  author       = {Meng Li and Ziting Xu and Zhengjie Li and Yajie Qi},
  doi          = {10.1142/S1469026824500329},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450032},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {RN-STLSTM-GAN: Spatiotemporal-guided generative adversarial network for time-evolving precipitation downscaling},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing the hybrid feature selection in the DNA microarray for cancer diagnosis using fuzzy entropy and the giza pyramid construction algorithm. <em>IJCIA</em>, <em>24</em>(1), 2450031. (<a href='https://doi.org/10.1142/S1469026824500317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biotechnological analysis of DNA microarray genes provides valuable insights into the discovery and treatment of diseases such as cancer. It may also be crucial for the prevention and treatment of other genetic diseases. However, due to the large number of features and dimensions in a DNA microarray, the “curse of dimensions” problem is very common. Many machine learning methods require an effective subset of input genes to achieve high accuracy. Unfortunately, extracting features (genes) is an inherently NP-hard problem. Recently, the use of metaheuristics to overcome the NP-hardness of the feature extraction problem has attracted the attention of many researchers. In this paper, we use the combination of fuzzy entropy and Giza Pyramid Construction (GPC) for feature selection. First, redundant features in the microarray dataset are removed using the fuzzy entropy approach. GPC is then used to reduce the execution time. This results in the selection of a near-optimal subset of genes for cancer detection. Dimensionality reduction with GPC followed by classification with Convolutional Neural Network (CNN) creates a synergy to increase efficiency. The proposed method is tested on five well-known cancer patient datasets: leukemia, lymphoma, MLL, ovarian, and SRBCT. The performance of CNN was also measured with four well-known classifiers, including K-nearest neighbor, naïve Bayesian, decision tree, and logistic regression. Our results show that, on average, CNN has the highest accuracy, recall, precision, and F-measure in all datasets.},
  archive      = {J_IJCIA},
  author       = {Masoumeh Motevalli and Madjid Khalilian and Azam Bastanfard},
  doi          = {10.1142/S1469026824500317},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450031},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Optimizing the hybrid feature selection in the DNA microarray for cancer diagnosis using fuzzy entropy and the giza pyramid construction algorithm},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adadelta-CSA: Adadelta-chameleon swarm algorithm for EEG-based epileptic seizure detection. <em>IJCIA</em>, <em>24</em>(1), 2450030. (<a href='https://doi.org/10.1142/S1469026824500305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is referred to as a neurological disorder, which is detected via examination and manual comprehension of Electroencephalogram (EEG) signals. In deep learning schemes, various enhancements have emerged to efficiently address complex issues by end-to-end learning. The major objective of this research is to propose a new seizure detection approach from EEG signals using a deep learning-based classification technique. The pre-processing is the initial stage, where denoising is performed using a Short-Time Fourier Transform (STFT). Subsequently, the statistical features, time-domain features and spectral features are extracted from the pre-processed signal. Finally, an efficient optimization approach, named Adadelta-Chameleon Swarm Algorithm (Adadelta-CSA), is proposed and employed to train Deep Neural Network (DNN) to carry out the precise seizure prediction. Here, the integration of the Adadelta concept in the Chameleon Swarm Algorithm (CSA) has resulted in Adadelta-CSA. At last, the performance of the Adadelta-CSA scheme-based DNN is compared with the existing techniques by considering accuracy, sensitivity and specificity, and it is found to produce better values of 0.951, 0.966, and 0.935, respectively.},
  archive      = {J_IJCIA},
  author       = {G. Indu Salini and I. Sowmy},
  doi          = {10.1142/S1469026824500305},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450030},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Adadelta-CSA: Adadelta-chameleon swarm algorithm for EEG-based epileptic seizure detection},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised image aesthetic assessment based on transformer. <em>IJCIA</em>, <em>24</em>(1), 2450029. (<a href='https://doi.org/10.1142/S1469026824500299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual aesthetics has always been an important area of computational vision, and researchers have continued exploring it. To further improve the performance of the image aesthetic evaluation task, we introduce a Transformer into the image aesthetic evaluation task. This paper pioneers a novel self-supervised image aesthetic evaluation model founded upon Transformers. Meanwhile, we expand the pretext task to capture rich visual representations, adding a branch for inpainting the masked images in parallel with the tasks related to aesthetic quality degradation operations. Our model’s refinement employs the innovative uncertainty weighting method, seamlessly amalgamating three distinct losses into a unified objective. On the AVA dataset, our approach surpasses the efficacy of prevailing self-supervised image aesthetic assessment methods. Remarkably, we attain results approaching those of supervised methods, even while operating with a limited dataset. On the AADB dataset, our approach improves the aesthetic binary classification accuracy by roughly 16% compared to other self-supervised image aesthetic assessment methods and improves the prediction of aesthetic attributes.},
  archive      = {J_IJCIA},
  author       = {Minrui Jia and Guangao Wang and Zibei Wang and Shuai Yang and Yongzhen Ke and Kai Wang},
  doi          = {10.1142/S1469026824500299},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450029},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Self-supervised image aesthetic assessment based on transformer},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-stream fusion network for human energy expenditure estimation with wearable sensor. <em>IJCIA</em>, <em>24</em>(1), 2450028. (<a href='https://doi.org/10.1142/S1469026824500287'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing awareness of health, using wearable sensors to monitor individual activities and accurately estimate energy expenditure has become a current research focus. However, existing research encounters challenges including low estimation accuracy, a deficiency of frequency domain features, and difficulty in integrating time domain and frequency domain features. To address these issues, we propose an innovative framework called the Dual-Stream Fusion Network (DSFN). This framework combines the Time Domain Encoding (TDE) module, the Frequency Domain Hierarchical-Split Encoding (FDHSE) module, and a Two-Stage Feature Fusion (TSF) module. Specifically, the temporal stream of the framework employs the TDE module to capture deep temporal features that reflect the complex dynamic variations in time-series data. The frequency domain stream introduces the FDHSE module, which extracts frequency domain features using a multi-level, multi-scale approach, ensuring a comprehensive and diverse representation of frequency information. Through this dual-stream architecture, our model effectively learns both time and frequency domain features, addressing the limitations of frequency domain features observed in prior studies. Additionally, we propose the TSF module to fully integrate time and frequency domain features, effectively overcoming the challenge of fusing these two types of features. We conducted experiments on two public datasets, namely the GOTOV dataset (elderly people) and the JSI dataset (young people). Experimental results demonstrate that our method achieves excellent performance across different age groups. Compared to the baseline models, the proposed DSFN significantly improves the accuracy of human energy expenditure estimation.},
  archive      = {J_IJCIA},
  author       = {Shuo Xiao and Zhiyu Wang and Chaogang Tang and Zhenzhen Huang},
  doi          = {10.1142/S1469026824500287},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450028},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {A dual-stream fusion network for human energy expenditure estimation with wearable sensor},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rural tourist attractions recommendation model based on multi-feature fusion graph neural networks. <em>IJCIA</em>, <em>24</em>(1), 2450027. (<a href='https://doi.org/10.1142/S1469026824500275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of the rural tourism industry, traditional tourism recommendation technologies can no longer meet the necessary requirements. To address the issue of rural tourist attraction recommendations, a rural tourist attraction recommendation model is constructed based on a multi-feature fusion graph neural network. First, construct a feature map based on the relationship between tourists’ preferences and tourist attractions, and incorporate the attention mechanism to enhance the model’s learning capabilities. Second, utilize a two-part graph model to extract positive and negative preference features of tourists, and a conversation graph model to extract tourists’ transfer preference features. Finally, various features are utilized to generate suggested content by computing scores for tourists’ travel preferences. To address the problem of recommending tourist groups, suitable features for random group matching are collected and the cosine function is employed to identify users with similar random group features. Finally, the multi-features are merged, and the tourists’ interest preferences are scored to arrive at content recommendations. In the experiment on individualized attraction recommendations, data from the Chengdu area were used to test the proposed model. The accuracy of the model’s recommendations was 0.822 for five recommendations which outperformed the other models. In the experiment for group-based attraction recommendations, this experiment tested the Chengdu dataset. The proposed model achieved the highest accuracy of 0.972 when the group size was 70, outperforming the other two models. Additionally, with regards to different numbers of recommendations, the proposed model’s accuracy was 0.5241, which was the best performance among the three models when the number of recommendations was set to five. The proposed recommendation model performs optimally in suggesting tourist attractions and meets the needs of rural tourism. The research content provides crucial technical references for tourist traveling and rural tourism development.},
  archive      = {J_IJCIA},
  author       = {Xiangrong Zhang and Xueying Wang},
  doi          = {10.1142/S1469026824500275},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450027},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Rural tourist attractions recommendation model based on multi-feature fusion graph neural networks},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Music generation using dual interactive wasserstein fourier acquisitive generative adversarial network. <em>IJCIA</em>, <em>24</em>(1), 2450026. (<a href='https://doi.org/10.1142/S1469026824500263'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Music composition, an intricate blend of human creativity and emotion, presents substantial challenges when generating melodies from lyrics which hinders effective learning in neural networks and the inadequate depiction of harmonic structure that fails to encapsulate the complex relationships between lyrics and melodies. The existing methods often struggle to balance emotional depth and structural coherence, leading to compositions that lack both the intended emotional resonance and musical consistency. To overcome these issues, this research introduces a novel approach named Dual Interactive Wasserstein Fourier Acquisitive Generative Adversarial Network (DIWFA-GAN), which integrates innovative techniques like swish activation functions and the Giant Trevally Optimizer (GTO) for parameter optimization. Meanwhile, the GTO, inspired by the movement patterns of the Giant Trevally fish, provides efficient and effective parameter optimization, improving the model’s convergence speed and accuracy. Comparative analysis against recent existing models reveals superior performance for both the LMD-full MIDI and Reddit MIDI datasets, with impressive metrics including inception scores of 9.36 and 2.98, Fréchet inception distances of 35.29 and 135.54 and accuracies of 99.98% and 99.95%, respectively. The DIWFA-GAN significantly outperforms existing models in generating high-fidelity melodies, as evidenced by superior inception scores, Fréchet inception distances, and accuracies on both datasets.},
  archive      = {J_IJCIA},
  author       = {Tarannum Shaikh and Ashish Jadhav},
  doi          = {10.1142/S1469026824500263},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450026},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Music generation using dual interactive wasserstein fourier acquisitive generative adversarial network},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bi-population competition adaptive interior search algorithm based on reinforcement learning for flexible job shop scheduling problem. <em>IJCIA</em>, <em>24</em>(1), 2450025. (<a href='https://doi.org/10.1142/S1469026824500251'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a bi-population competition adaptive interior search algorithm (BCAISA) based on a reinforcement learning strategy is proposed for the classical flexible job shop scheduling problem (FJSP) to optimize the makespan. First, the scheduling solution is represented using a machine-job-based two-segment integer encoding method, and various heuristic rules are then applied to generate the initial population. Secondly, a bi-population mechanism is introduced to partition the population into two distinct sub-populations. These sub-populations are specifically tailored for machine assignment and operation permutation, employing different search strategies respectively, aiming to facilitate an efficient implementation of parallel search. A competition mechanism is introduced to facilitate the information exchange between the two sub-populations. Thirdly, the ISA is adapted for the discrete scheduling problem by discretizing a series of search operators, which include composition optimization, mirror search, and random walk. A Q-learning-based approach is proposed to dynamically adjust a key parameter, aiming to strike a balance between the capacity for global exploration and local exploitation. Finally, extensive experiments are conducted based on 10 well-known benchmark instances of the FJSP. The design of the experiment (DOE) method is employed to determine the algorithm’s parameters. Based on the computational results, the effectiveness of four improvement strategies is first validated. The BCAISA is then compared with fifteen published algorithms. The comparative data demonstrate that our algorithm outperforms other algorithms in 50% of benchmark instances. Additionally, according to the relative percentage deviation (RPD) from the state-of-the-art results, the BCAISA also exhibits superior performance. This highlights the effectiveness of our algorithm for solving the classical FJSP. To enhance the practical application, the scope of the ISA will be broadened in future work to more complex problems in real-world scenarios.},
  archive      = {J_IJCIA},
  author       = {Tianhua Jiang and Lu Liu},
  doi          = {10.1142/S1469026824500251},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450025},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {A bi-population competition adaptive interior search algorithm based on reinforcement learning for flexible job shop scheduling problem},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modified genetic algorithm for efficient high-utility itemset mining. <em>IJCIA</em>, <em>24</em>(1), 2450024. (<a href='https://doi.org/10.1142/S146902682450024X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In pattern mining, high-utility itemset mining (HUIM) is useful for discovering high-utility patterns. The study of HUIM using heuristic techniques reflects issues in producing better offspring. It is ineffective in terms of search space organization, population diversity, and utility calculation, which impact runtime and accuracy. It is observed that very few researchers have experimented with genetic algorithm (GA) and are still facing the same issues as mentioned before. To overcome these problems, a novel approach is proposed for HUIM using modified GA and optimized local search (HUIM-MGALS) with six potential contributions. First is linking the utility with the Bitmap dataset to reduce utility access time, leading to effective search space organization. Second, HUIM-MGALS employs a fitness scaling strategy to avoid redundancy. Third, a high-utility itemset (HUI) revision strategy is employed to explore significant HUIs. Modified population diversity maintenance strategy and iterative crossover help to preserve significant HUIs and improve search capability as fourth and fifth contributions. Sixth, the use of multiple mutations refines the wasted individuals to boost accuracy. Extensive experimentation showed that HUIM-MGALS significantly outperforms the presented algorithms, up to 8.6 times faster. It also demonstrates superior HUI discovery capabilities for both sparse and dense datasets. This is supported by the modified population diversity maintenance strategy, which is proved to be the most impactful modification for HUI discovery in HUIM-MGALS.},
  archive      = {J_IJCIA},
  author       = {Eduardus Hardika Sandy Atmaja and Kavita Sonawane},
  doi          = {10.1142/S146902682450024X},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450024},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Modified genetic algorithm for efficient high-utility itemset mining},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Student apartment access control system based on MTCNN-FaceNet algorithm. <em>IJCIA</em>, <em>24</em>(1), 2450022. (<a href='https://doi.org/10.1142/S1469026824500226'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the security management issues of student apartments, a study is conducted on a student apartment access control system based on multitasking cascaded convolutional networks and FaceNet. Firstly, a face detection model is built based on an improved multi-task cascaded convolutional network, and then a face recognition model is built using FaceNet. The results showed that the detection accuracy of the multi-task cascaded convolutional network using the improved non-maximum suppression algorithm was 98.7%, which was higher than the traditional multi-task cascaded convolutional network and effectively improved the detection performance of the multi-task cascaded convolutional network. The face detection model based on the improved multi-task cascaded convolutional network had the shortest average detection time of 361 s, the highest average detection accuracy of 90.3%, an accuracy of 99%, a recall rate of 98.5%, and an F 1 value of 99%. While maintaining high detection efficiency, it also ensured the accuracy of detection. The average accuracy of the mask detection method based on the MobileNet V2 network was relatively high, at 98.96%. The facial recognition model based on FaceNet achieved a recognition accuracy of 99.15% for faces without masks and 92.04% for faces with masks, with the highest accuracy and recall rates of 99.3% and 99.6%. The model constructed in the study has good application effects in face detection, which helps to improve the security of the student apartment access control system.},
  archive      = {J_IJCIA},
  author       = {Jing Zhang},
  doi          = {10.1142/S1469026824500226},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450022},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Student apartment access control system based on MTCNN-FaceNet algorithm},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative adversarial network optimization algorithm based on adaptive data augmentation. <em>IJCIA</em>, <em>24</em>(1), 2450021. (<a href='https://doi.org/10.1142/S1469026824500214'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the research of deep learning, an Unsupervised deep convolution-generated Generated Adversarial Network (UGAN) usually needs a large number of data samples to train. However, when faced with some small samples, the performance of the algorithm is often degraded due to over-fitting. Combined with specially designed data enhancement methods, a generated adversarial network optimization algorithm based on adaptive data augmentation (AdauGAN) is proposed. The adaptive data augmentation module is added before the discriminant network, and a spatial transformation is carried out simultaneously at the probability distribution level of generated data and real data. To alleviate the over-fitting phenomenon in the training process, the current enhancement intensity is adjusted adaptively after the over-fitting occurs. The proposed algorithm is verified on SVHN, CelebA and CIFAR-10 data sets. The Frechet Inception Distance (FID) values of AdauGAN achieve 22.10, 23.94, 34.87, respectively, which is close to or even higher than the training results of Deep Convolution Generated Adversarial Network (DCGAN) under all data. Extensive experiment results show that the proposed Adaugan has an excellent performance in small samples. Besides, in some cases, it can catch up with the large sample results of existing algorithms.},
  archive      = {J_IJCIA},
  author       = {Yanan Yu and Dunhuang Shi and Qi Pan},
  doi          = {10.1142/S1469026824500214},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450021},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Generative adversarial network optimization algorithm based on adaptive data augmentation},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijdsms">IJDSMS - 2</h2>
<ul>
<li><details>
<summary>
(2025). A modified halpern-type S-iteration process for a finite family of variational inequality problems in real hilbert space. <em>IJDSMS</em>, <em>3</em>(1), 11-37. (<a href='https://doi.org/10.1142/S2810939225500029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a finite family of variational inequality problems and fixed point problems in real Hilbert space. With the help of averaged mappings, we propose a new iterative process to solve the above-mentioned problem. Our proposed algorithm is the combination of Halpern iterative process, subgradient extragradient process and S-iteration process for variational inequalities. Under reasonable restrictions on control sequences, a strong convergence theorem has been proved. Further, some numerical experiments indicate that the suggested approach is practical.},
  archive      = {J_IJDSMS},
  author       = {Shamshad Husain and Mohd Asad},
  doi          = {10.1142/S2810939225500029},
  journal      = {International Journal of Data Science in the Mathematical Sciences},
  number       = {1},
  pages        = {11-37},
  shortjournal = {Int. J. Data Sci. Math. Sci.},
  title        = {A modified halpern-type S-iteration process for a finite family of variational inequality problems in real hilbert space},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-fermi liquids, strange metals and quasi-metaparticles. <em>IJDSMS</em>, <em>3</em>(1), 1-10. (<a href='https://doi.org/10.1142/S2810939225500017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce the concept of quasi-metaparticles based on the theory of metaparticles, the zero modes of the metastring. We apply the concept of quasi-metaparticles to the problem of non-Fermi liquids and the properties of strange metals. In particular, we point out that the quasi-metaparticle Green’s function interpolates between the canonical quasi-particle Green’s function and the result found in the context of the SYK model, which presents an exactly solvable model without quasiparticles. The linear dependence of resistivity with temperature is reproduced in the SYK limit. Also, the Cooper mechanism is possible in the quasi-metaparticle case. Finally, the new parameter that characterizes quasi-metaparticles can be extracted from ARPES data. Thus, the quasi-metaparticle could be a useful new concept in the study of strange metals and high-temperature superconductivity.},
  archive      = {J_IJDSMS},
  author       = {Edwin Barnes and J. J. Heremans and Djordje Minic},
  doi          = {10.1142/S2810939225500017},
  journal      = {International Journal of Data Science in the Mathematical Sciences},
  number       = {1},
  pages        = {1-10},
  shortjournal = {Int. J. Data Sci. Math. Sci.},
  title        = {Non-fermi liquids, strange metals and quasi-metaparticles},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijfcs">IJFCS - 52</h2>
<ul>
<li><details>
<summary>
(2025). The strong diagnosability of multiprocessor systems under the PMC model. <em>IJFCS</em>, <em>36</em>(6), 955-972. (<a href='https://doi.org/10.1142/S0129054125500030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The diagnosability is a prominent parameter to estimate the fault diagnosis capability of multiprocessor systems, which is the maximum number of faulty processors that can be identified by the system. Compared to traditional diagnosability, strong diagnosability proposed by Lai et al. [ 16 ] is a more pinpoint term for gauging multiprocessor systems’ reliability. A system is strongly t -diagnosable if it is t -diagnosable and can attain ( t + 1 ) -diagnosability, excepting certain circumstance in which all neighbors of some processor are faulty. In this paper, we obtain the strong diagnosability of regular networks as well as connected networks subject to certain circumstances under the PMC model, respectively. The previous result in Hsieh et al. [ 7 ] is extended.},
  archive      = {J_IJFCS},
  author       = {Xuemin Wu and Liqiong Xu and Chuanye Zheng},
  doi          = {10.1142/S0129054125500030},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {6},
  pages        = {955-972},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {The strong diagnosability of multiprocessor systems under the PMC model},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Almost perfect c-nonlinear permutations with trace functions over 𝔽2n. <em>IJFCS</em>, <em>36</em>(6), 939-953. (<a href='https://doi.org/10.1142/S0129054125500029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, by using the Weil sums, we derive that the c -differential uniformity of permutation polynomial of the form F ( x ) = x + Tr ( H ( x ) + H ( x + 1 ) ) ∈ 𝔽 2 n [ x ] is equal to 2 for H ( x ) = x 2 i + 2 j + 1 with 1 ≤ i ≠ j ≤ n − 1 and gcd ( n , i ) = gcd ( n , j ) = gcd ( n , i − j ) = 1 , or H ( x ) = ∑ i , j = 1 n − 1 x 2 i + 2 j + 1 with 1 ≤ i < j ≤ n − 1 , where n = 2 k + 1 . In particular, several explicit classes of APcN permutations over 𝔽 2 n are presented using different choices of the pair ( i , j ) for the monomial H ( x ) = x 2 i + 2 j + 1 .},
  archive      = {J_IJFCS},
  author       = {Yan-Ping Wang and Yiwen Chen and Qiang Wang},
  doi          = {10.1142/S0129054125500029},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {6},
  pages        = {939-953},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Almost perfect c-nonlinear permutations with trace functions over 𝔽2n},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New families of frequency-hopping sequence sets with optimal hamming correlation. <em>IJFCS</em>, <em>36</em>(6), 921-937. (<a href='https://doi.org/10.1142/S0129054125500017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advantage of transmitting messages efficiently along with switching frequencies at set intervals by each user, frequency-hopping sequence (FHS) has been widely applied in the frequency-hopping multiple access spread spectrum systems. In such systems, the Hamming correlation property of FHS is an important standard to measure the system performance. In this paper, a combinatorial description of difference-balanced function from 𝔽 q n ∗ onto 𝔽 q m is given, and the sizes of its preimage sets are determined without resorting to d -homogeneous property, where m and n are two positive integers with m | n . Afterwards, we construct new near-optimal FHSs and optimal FHS sets by virtue of the Chinese Remainder Theorem and d -homogeneous functions with difference-balanced property, which generalize some earlier constructions of optimal FHS sets and produce optimal FHS sets which are not covered in the foregoing literature.},
  archive      = {J_IJFCS},
  author       = {Shanding Xu},
  doi          = {10.1142/S0129054125500017},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {6},
  pages        = {921-937},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {New families of frequency-hopping sequence sets with optimal hamming correlation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The local metric dimension and distance-edge-monitoring number of graph. <em>IJFCS</em>, <em>36</em>(6), 901-920. (<a href='https://doi.org/10.1142/S0129054124500230'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let G be a graph and u , v , w ∈ V ( G ) . The vertex w is said to resolve a pair u and v if and only if d G ( w , u ) ≠ d G ( w , v ) . A set W ⊆ V ( G ) is defined as a resolving set of G if for all u , v ∈ V ( G ) , the pair ( u , v ) is resolved by some w ∈ W . The minimum cardinality of a resolve set of G is defined as dim ( G ) . A set R ⊆ V ( G ) is a local resolve set of G if for all u , v ∈ V ( G ) such that u v ∈ E ( G ) , the pair ( u , v ) is resolved by some r ∈ R . The minimum cardinality of a local resolve set of G is defined as dim ℓ ( G ) . An edge u v ∈ E ( G ) is said to be monitored by x ∈ V ( G ) if d G ( x , u ) ≠ d G − u v ( x , u ) or d G ( x , v ) ≠ d G − u v ( x , v ) . A set M ⊆ V ( G ) is a distance-edge-monitoring (DEM) set if for all e ∈ E ( G ) , e is monitored by some v ∈ M . The minimum cardinality of a D E M set of G is defined as dem ( G ) . In this paper, we obtained that 1 ≤ dim ℓ ( G ) ≤ dem ( G ) ≤ n − 1 for all non trivial graphs with order n , and the exact value of dim ℓ ( G ) and dem ( G ) for G ∈ { T n , K n , B n , N E n , Koch ( n ) } . Also, we obtained that if dim ℓ ( G ) = 1 then dem ( G ) ≤ ⌊ n 2 ⌋ . With respect to the relation between the defined graph invariants, it was proved a bound for ( dem − dim ) ( n ) for G ∈ 𝔊 n = { G | | V ( G ) | = n } and the exact values of ( dim − dim ℓ ) ( n ) for G ∈ 𝔊 n , where ( dem − dim ) ( n ) (resp, ( dim − dim ℓ ) ( n ) )is the maximum value of dem ( G ) − dim ( G ) (resp, dem ( G ) − dim ℓ ( G ) ) over all graphs G with order n . Finally, we proved that for 2 ≤ s ≤ t ≤ s + ⌊ n − 2 s 3 ⌋ , there exists a graph with order n such that dim ℓ ( G ) = s and dem ( G ) = t .},
  archive      = {J_IJFCS},
  author       = {Chenxu Yang and Zhen Ji and Wen Li and Yan Liang},
  doi          = {10.1142/S0129054124500230},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {6},
  pages        = {901-920},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {The local metric dimension and distance-edge-monitoring number of graph},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integer codes correcting single errors and detecting double adjacent errors. <em>IJFCS</em>, <em>36</em>(6), 885-899. (<a href='https://doi.org/10.1142/S0129054124500229'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents two classes of integer codes called integer SEC-(DAED) b codes and integer SEC-DAED codes. The first class of codes can correct all single errors and detect all double adjacent (DA) errors within a b -bit byte, while the second class of codes has the ability to correct all single errors and detect all DA errors. Both classes of codes are defined over integer rings and are generated by computer search. To evaluate the performance of the proposed codes, we analyze the probability of incorrect decoding for different error rates. In addition, the paper shows that the proposed codes have a slightly higher redundancy than linear SEC-DAED codes, but also a much simpler decoding algorithm.},
  archive      = {J_IJFCS},
  author       = {Aleksandar Radonjic and Igor Ristic and Ivan Scepanovic},
  doi          = {10.1142/S0129054124500229},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {6},
  pages        = {885-899},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Integer codes correcting single errors and detecting double adjacent errors},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conditionally accepted sampling: AB15 IO scheme with smaller deviation ratio. <em>IJFCS</em>, <em>36</em>(6), 867-883. (<a href='https://doi.org/10.1142/S0129054124500217'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indistinguishable Obfuscation (IO) is a very critical cryptography primitive. It can be used to construct almost any other cryptography schemes. AB15 indistinguishability obfuscation scheme is the first practical scheme. In order to avoid the ideal generator can be searched, authors of AB15 IO scheme set it to a relatively large size (In fact, such ideal generator should be a “small prime”). It causes the ratio of the standard deviation of Gaussian sampling and the size of ideal generator smaller. We call the ratio as “deviation ratio”. In this paper, we point that direct sampling and smaller deviation ratio makes the scheme insecure. A searching attack can reveal hidden coefficients of original boolean circuit from its obfuscator. Firstly, the attacker searches those level-0 encodings of 0, hoping that the code value is 0. Such event happens with probability 1 2 π σ ∗ or 1 4 π σ ∗ , where σ ∗ as the deviation ratio. By a series of searching, a weak obfuscator with prime module can be obtained. Then, the attacker can obtain all hidden coefficients of original boolean circuit. Take n as the dimension of independent variable, m as the dimension of coefficient of original boolean circuit. For Simple Obfuscator, searching time is 2 n + 2 m , and the probability that one successfully reveals hidden coefficients of original boolean circuit is about n + m 2 4 π σ ∗ ( 1 + 2 ) . For Robust Obfuscator, searching time and success probability are respectively n + m + C n + m 2 and n + m 2 2 π σ ∗ + C n + m 2 2 ( 4 π σ ∗ ) 2 . At last, we present a revised scheme with “conditionally accepted sampling” and smaller deviation ratio. The new scheme avoids above mentioned attack and greatly reduce the size complexity.},
  archive      = {J_IJFCS},
  author       = {Jiangshan Chen and Yupu Hu and Siyue Dong},
  doi          = {10.1142/S0129054124500217},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {6},
  pages        = {867-883},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Conditionally accepted sampling: AB15 IO scheme with smaller deviation ratio},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The degree and codegree threshold for generalized triangle and some trees covering. <em>IJFCS</em>, <em>36</em>(5), 841-865. (<a href='https://doi.org/10.1142/S0129054125460037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given two k -uniform hypergraphs F and G , we say that G has an F -covering if for every vertex in G there is a copy of F cover it. For 1 ≤ i ≤ k − 1 , the minimum i -degree δ i ( G ) of G is the minimum integer such that every i vertices are contained in at least δ i ( G ) edges. Let c i ( n , F ) be the largest minimum i -degree among all n -vertex k -uniform hypergraphs that have no F -covering. In this paper, we mainly consider the F -covering problem in 3 -uniform hypergraphs. When F is a generalized triangle T , we give the exact value of c 2 ( n , T ) and asymptotically determine c 1 ( n , T ) . Moreover, when F is a linear k -path P k or a star S k , we provide bounds of c i ( n , P k ) and c i ( n , S k ) for k ≥ 3 , where i = 1 , 2 .},
  archive      = {J_IJFCS},
  author       = {Ran Gu and Shuaichao Wang},
  doi          = {10.1142/S0129054125460037},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {5},
  pages        = {841-865},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {The degree and codegree threshold for generalized triangle and some trees covering},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-resumable scheduling on a single bounded parallel-batch machine with flexible maintenance. <em>IJFCS</em>, <em>36</em>(5), 827-840. (<a href='https://doi.org/10.1142/S0129054125460025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the scheduling problem on a single bounded parallel-batch machine with flexible maintenance, in which the time gap between any two consecutive maintenance is limited by a given constant and the last maintenance is required after all jobs are completed. A batch of jobs can be processed simultaneously in some available processing time interval as long as the total size of these jobs doesn’t exceed the machine capacity. The processing time of a job batch is the largest processing time of the jobs contained in this batch and the production progress is non-resumable. Our objective is to minimize the last maintenance completion time. For the case where jobs have unit processing times, we show the problem is strongly NP-hard and present a 2 -approximation algorithm. For the case where jobs have unit sizes, we show the problem is also strongly NP-hard and provide a 3 2 -approximation algorithm. Finally, we study the general case where jobs have non-identical processing times and sizes and propose a 3 -approximation algorithm.},
  archive      = {J_IJFCS},
  author       = {Jing Fan},
  doi          = {10.1142/S0129054125460025},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {5},
  pages        = {827-840},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Non-resumable scheduling on a single bounded parallel-batch machine with flexible maintenance},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The coordination mechanism for scheduling game with deterioration jobs and uniform-batch machines. <em>IJFCS</em>, <em>36</em>(5), 815-826. (<a href='https://doi.org/10.1142/S0129054125460013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider a scheduling game problem with uniform-batch machines and deterioration jobs. Each job J j ( j = 1 , 2 , … , n ) is owned by an agent and has a deterioration rate a j > 0 ( j = 1 , 2 , … , n ) . Each machine M i ( i = 1 , 2 , … , m ) has a speed s i > 0 . Each batch can process up to B jobs, and each job has a load l j > 0 . The start time of the jobs in the same batch is the same, and the completion time of the jobs in the same batch is the same. If the start time of job J j is t , then its actual load is l j = a j t . The load of a batch is the load of the longest job in the batch, i.e., the load of a batch is the load of the job with the largest deterioration rate in the batch. The processing time of a batch on machine M i is the ratio between the load of a batch and the speed s i . The completion time of a batch is the completion time of the longest job in the batch, i.e., the completion time of a batch is the completion time of the job with the largest deterioration rate in the batch. For the scheduling game problem, we use the Logarithm Price of Anarchy ( L P o A ) to measure the inefficiency of Nash Equilibrium. We present a coordination mechanism with L P o A not greater than 1 + 1 B ln ( 1 + a min s min ) ln ( 1 + a min s max ) + δ + ( 1 − 1 B ) ln ( 1 + a max s min ) ln ( 1 + a min s max ) + δ − 1 m Δ , where a min = min { a 1 , a 2 , … , a n } , a max = max { a 1 , a 2 , … , a n } , s min = min { s 1 , s 2 , … , s m } , s max = max { s 1 , s 2 , … , s m } , δ = ln ( 1 + ( i − 1 ) σ ) , σ is a small positive number, Δ = ln ( 1 + a min s max ) ln C max ∗ and C max ∗ is the optimal makespan.},
  archive      = {J_IJFCS},
  author       = {Ganhua Yu and Yuzhong Zhang},
  doi          = {10.1142/S0129054125460013},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {5},
  pages        = {815-826},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {The coordination mechanism for scheduling game with deterioration jobs and uniform-batch machines},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inverse spectral problems for a special acyclic matrix. <em>IJFCS</em>, <em>36</em>(5), 801-814. (<a href='https://doi.org/10.1142/S0129054123460048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the reconstruction of matrices whose graph is a star with root at the central vertex from given partial eigen data. Three inverse spectral problems are discussed. The necessary and sufficient conditions for the solvability of the problems are studied. Furthermore, the corresponding numerical algorithms are presented. Some numerical examples are also provided to demonstrate the applicability of the results obtained here.},
  archive      = {J_IJFCS},
  author       = {Qifang Su},
  doi          = {10.1142/S0129054123460048},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {5},
  pages        = {801-814},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Inverse spectral problems for a special acyclic matrix},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Algorithms for the truss maintenance problem on edge-weighted graphs. <em>IJFCS</em>, <em>36</em>(5), 781-800. (<a href='https://doi.org/10.1142/S0129054123460036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k -truss was proposed by Jonathan Cohen in 2008, and it is a widely used as index in graph analysis for cohesive subgraph mining. There are two basic problems in this area. One is the truss decomposition problem, which is to compute the truss number of every edge; the other is the truss maintenance problem, which is to update the truss numbers of the affected edges in a dynamic graph while avoiding the truss number recomputation of all edges. However, few results are known on edge-weighted graphs. In this paper, we focus on the truss maintenance problem on edge-weighted graphs. Firstly, we propose a basic algorithm for the truss decomposition problem on edge-weighted graphs. Then we propose two indices, weighted growth potential support (WGPS) and weighted remaining potential support (WRPS), to help find the edges with potential changes on their truss numbers. Finally, we propose algorithms for the truss maintenance problem on edge-weighted graphs.},
  archive      = {J_IJFCS},
  author       = {Bin Liu and Zhenming Liu and Feiteng Zhang},
  doi          = {10.1142/S0129054123460036},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {5},
  pages        = {781-800},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Algorithms for the truss maintenance problem on edge-weighted graphs},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The B-prize-collecting multicut problem in paths, spider graphs and rings. <em>IJFCS</em>, <em>36</em>(5), 767-780. (<a href='https://doi.org/10.1142/S0129054123460012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a graph G = ( V , E ) , a set of m source-sink pairs 𝒫 = { ( s 1 , t 1 ) , ( s 2 , t 2 ) , … , ( s m , t m ) } and a profit bound B , every edge e ∈ E has a cost c e , and every source-sink pair ( s j , t j ) ∈ 𝒫 has a profit p j and a penalty π j . The B -prize-collecting multicut problem ( B -PCMP) is to find a multicut M ⊆ E such that the objective cost, which consists of the total cost of the edges in M and the total penalty of the pairs still connected after removing M , is minimized and the total profit of the disconnected pairs by removing M is at least B . In this paper, we firstly consider the B -PCMP in paths, and prove that it is N P -hard even when π j = 0 for any ( s j , t j ) ∈ 𝒫 . Then, we present a fully polynomial time approximation scheme (FPTAS) whose running time is O ( n 3 ⋅ m 𝜖 ) for the B -PCMP in paths. Based on this algorithm, we present an FPTAS whose running time is O ( n k + 1 ⋅ m 𝜖 ) for the B -PCMP in spider graphs, and an FPTAS whose running time is O ( n 4 ⋅ m 𝜖 ) for the B -PCMP in rings, respectively, where k is the number of leaves of spider graph.},
  archive      = {J_IJFCS},
  author       = {Xiaofei Liu and Weidong Li},
  doi          = {10.1142/S0129054123460012},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {5},
  pages        = {767-780},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {The B-prize-collecting multicut problem in paths, spider graphs and rings},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hamiltonian-based efficient algorithms for legalization with neighbor diffusion effect. <em>IJFCS</em>, <em>36</em>(5), 745-765. (<a href='https://doi.org/10.1142/S0129054122460108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighbor diffusion effect (NDE) is a crucial aspect in advanced technology node that is well-known for its infamous consequence of significant performance decrement of the circuit. In this paper, we observe that NDE is caused by different diffusion heights (the number of fins) between two adjacent cells, and consider reducing the number of height differences in single row to reduce NDE violations. Ignoring the movement of the cells, we first propose a Hamiltonian-completion-based algorithm that reorders the cells in the row such that the number of NDE violations is reduced to a near-optimal value. Then, for a given fixed integer η > 0 , we devise an algorithm to compute the new positions of cells, such that the number of NDE violations is bounded by η + 1 and the maximum displacement is minimized. Moreover, we extend our algorithm for legalization in multiple rows against mixed-height cells. Experimental results show that our algorithm reduces the NDE violations to a near-optimal minimum without any area overheads while achieving a better practical running time compared to baselines conforming with the theoretical analysis.},
  archive      = {J_IJFCS},
  author       = {Hao Sun and Longkun Guo and Xiaoyan Zhang},
  doi          = {10.1142/S0129054122460108},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {5},
  pages        = {745-765},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Hamiltonian-based efficient algorithms for legalization with neighbor diffusion effect},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Properties and algorithm of lattice pseudo-submodular functions. <em>IJFCS</em>, <em>36</em>(5), 731-743. (<a href='https://doi.org/10.1142/S0129054122460091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a concept of a lattice pseudo-submodular (LPS) function and consider maximizing a monotone continuous real LPS function ϕ ( x ) under a convex polytope constraint. The concept of LPS function was proposed to describe the properties of some discrete functions or nonconvex continuous functions. It is a generalization of the lattice submodular function. For the real LPS maximization problem, we design the monotone Pseudo Frank-Wolfe (PFW) algorithm by taking advantage of the second derivative bound. The PFW algorithm iterates by constantly optimize linear gradient function v T ∇ ϕ ( x ) , and finally outputs the solution. We theoretically prove that PFK algorithm has an approximation ratio of ( 1 − e − ( β β + 1 ) 2 ) (where β ∈ ( 0 , 1 ] ), and it needs at least O ( n ζ ) rounds (where ζ is a parameter given in advance). The PFW algorithm is also useful for multilinear extension of discrete lattice pseudo-submodular maximization problems.},
  archive      = {J_IJFCS},
  author       = {Hongxiang Zhang and Chunlin Hao and Yu Cao and Gaidi Li},
  doi          = {10.1142/S0129054122460091},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {5},
  pages        = {731-743},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Properties and algorithm of lattice pseudo-submodular functions},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved approximation algorithms for matroid and knapsack means problems. <em>IJFCS</em>, <em>36</em>(5), 709-729. (<a href='https://doi.org/10.1142/S012905412246008X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Both matroid means and knapsack means are variations of the classic k -means problem in which we replace the cardinality constraint by matroid constraint or knapsack constraint respectively. In this paper, we give a 64-approximation algorithm for the matroid means problem and a ( 1 1 2 8 + 𝜖 ) -approximation algorithm for the knapsack means problem by using a simpler and more efficient rounding method. We improve previous 304 approximate ratio for the former and 20016 approximate ratio for the latter. In the rounding process, the application of integrality of the intersection of submodular (or matroid) polyhedra provides strong theoretical support. Moreover, we extend this method to matroid means problem with penalties, and give 64 and 880-approximate algorithms for uniform penalties and nonuniform penalties problem.},
  archive      = {J_IJFCS},
  author       = {Ao Zhao and Yang Zhou and Qian Liu},
  doi          = {10.1142/S012905412246008X},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {5},
  pages        = {709-729},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Improved approximation algorithms for matroid and knapsack means problems},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximate nash equilibria for scheduling game on serial-batching-machines with activation cost. <em>IJFCS</em>, <em>36</em>(5), 697-708. (<a href='https://doi.org/10.1142/S0129054122460078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the scheduling game with activation cost, where jobs as selfish agents compete for processing on serial-batching identical machines. Each job selects a machine (more precisely, a batch on a machine) for processing to minimize his disutility composed of the load of his machine and the fraction of activation cost. We claim that such a game may not admit any Nash equilibrium under the uniform sharing rule. We present an algorithm and prove that the schedule produced by the algorithm is a tight approximate Nash equilibria.},
  archive      = {J_IJFCS},
  author       = {Long Zhang and Jiguo Yu and Yuzhong Zhang and Donglei Du},
  doi          = {10.1142/S0129054122460078},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {5},
  pages        = {697-708},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Approximate nash equilibria for scheduling game on serial-batching-machines with activation cost},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Restricted existence and approximation algorithms for PMMS. <em>IJFCS</em>, <em>36</em>(5), 683-695. (<a href='https://doi.org/10.1142/S0129054122460066'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of dividing m indivisible items among n agents fairly and efficiently. Specifically, this research concentrates on pairwise maximin share (PMMS), which is defined to be the maximum value that an agent can guarantee for herself if she were to repartition the items with another agent and receive the bundle with the minimum value. PMMS is an important concept in the fair division. However, whether PMMS for indivisible items exists is still open. This work concentrates on PMMS by proving the existence of PMMS on linear graphs with binary valuation functions. Besides, this paper designs an algorithm to approximate PMMS in the case where different agents have identical valuations among the same items, achieving a ratio strictly greater than 0.8, which outperforms the state-of-the-art ratio of 0.781 from Kurokawa [22]. The time complexity of our FFD-based algorithm is O ( m n + m log m ) .},
  archive      = {J_IJFCS},
  author       = {Xinru Guo and Sijia Dai and Guichen Gao and Ruikang Ma and Yicheng Xu and Li Ning and Jianping Fan},
  doi          = {10.1142/S0129054122460066},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {5},
  pages        = {683-695},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Restricted existence and approximation algorithms for PMMS},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved approximation algorithms for bin packing with conflicts. <em>IJFCS</em>, <em>36</em>(5), 667-682. (<a href='https://doi.org/10.1142/S0129054122460054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a set of items, and a conflict graph defined on the item set, the problem of bin packing with conflicts asks for a partition of items into a minimum number of independent sets so that the total size of items in each independent set does not exceed the bin capacity. As a generalization of both classic bin packing and classic vertex coloring, it is hard to approximate the problem on general graphs. We present new approximation algorithms for bipartite graphs and split graphs. The absolute approximation ratios are shown to be 5 3 and 2 respectively, both improving the existing results.},
  archive      = {J_IJFCS},
  author       = {Zhihua Huang and An Zhang and György Dósa and Yong Chen and Chenling Xiong},
  doi          = {10.1142/S0129054122460054},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {5},
  pages        = {667-682},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Improved approximation algorithms for bin packing with conflicts},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A differentially private approximation algorithm for submodular maximization under a polymatroid constraint over the integer lattice. <em>IJFCS</em>, <em>36</em>(5), 649-666. (<a href='https://doi.org/10.1142/S0129054122460042'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of local privacy where actions are subsets of a ground multiset and expectation rewards are modeled by a 1 − decomposable monotone submodular function. For the DR-submodular maximization problem under a polymatroid constraint, Soma and Yoshida [26] provide a continuous greedy algorithm for no-privacy setting. In this paper, we obtain the first differentially private algorithm for DR-submodular maximization subject to a polymatroid constraint. Our algorithm achieves a ( 1 − 1 / e − O ( ρ ) ) − approximation with a little loss and runs in O ( n 2 r 3 / ρ 6 ⋅ log 3 ( n / ρ ) ⋅ log 3 r + n 8 ) times where r is the rank of the base polymatroid and n is the size of ground set. Along the way, we analyze the utility and privacy of our algorithm. A concrete experiment to simulate the privacy Uber pickups location problem is provided, and our algorithm performs well within the agreed range.},
  archive      = {J_IJFCS},
  author       = {Jiaming Hu and Chunlin Hao and Cuixia Miao and Bo Zhao},
  doi          = {10.1142/S0129054122460042},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {5},
  pages        = {649-666},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {A differentially private approximation algorithm for submodular maximization under a polymatroid constraint over the integer lattice},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-machine scheduling with a deteriorating maintenance activity and DeJong’s learning effect. <em>IJFCS</em>, <em>36</em>(5), 635-648. (<a href='https://doi.org/10.1142/S0129054122460030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the single-machine scheduling problems with DeJong’s learning effect and deteriorating maintenance activity, where DeJong’s learning effect is a special position-based learning effect and the duration of the deteriorating maintenance activity is a linear increasing function of its starting time. Our goal is to determine the job sequence of all jobs and the position of the maintenance activity to minimize some performance measures. When the performance measures are the makespan and the total completion time, we show that both of them can be solved in polynomial time. When the performance measure is the total weighted completion time, we develop a pseudo-polynomial time dynamic programming algorithm under a special case. When the performance measure is the maximum lateness, we show that the earliest due date first (EDD) order is a bad algorithm for the general case, and develop a polynomial time algorithm under a special case.},
  archive      = {J_IJFCS},
  author       = {Jie Gao and Juan Zou and Yuzhong Zhang},
  doi          = {10.1142/S0129054122460030},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {5},
  pages        = {635-648},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Single-machine scheduling with a deteriorating maintenance activity and DeJong’s learning effect},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph algorithm based submodular function for sparsest cut problem. <em>IJFCS</em>, <em>36</em>(5), 619-633. (<a href='https://doi.org/10.1142/S0129054122460029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparsest cut problems are very important graph partitions, which have been widely applied in expander graphs, Markov chains, and image segmentation. In this paper, we study the edge-weighted version of the Sparse Cut Problem, which minimizes the ratio of the total weight of edges between blocks and the total weight of edges incident to vertices in one block. We first prove that the problem is even NP-hard for an edge-weighted graph with bridges. Then, we combine and generalize submodular functions and principal partition to design a graph algorithm to improve the initial bipartition, which runs in polynomial time by using network flow as its subroutines.},
  archive      = {J_IJFCS},
  author       = {Xiaoyan Zhang and Hong Chang and Longkun Guo and Donglei Du and Gaokai Zou and Yuanyuan Xiong},
  doi          = {10.1142/S0129054122460029},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {5},
  pages        = {619-633},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Graph algorithm based submodular function for sparsest cut problem},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel image clustering algorithm based on supported nearest neighbors. <em>IJFCS</em>, <em>36</em>(5), 599-618. (<a href='https://doi.org/10.1142/S0129054122460017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised image clustering is a challenging task in computer vision. Recently, various deep clustering algorithms based on contrastive learning have achieved promising performance and some distinguishable features representation were obtained only by taking different augmented views of same image as positive pairs and maximizing their similarities, whereas taking other images’ augmentations in the same batch as negative pairs and minimizing their similarities. However, due to the fact that there is more than one image in a batch belong to the same class, simply pushing the negative instances apart will result in inter-class conflictions and lead to the clustering performance degradation. In order to solve this problem, we propose a deep clustering algorithm based on supported nearest neighbors (SNDC), which constructs positive pairs of current images by maintaining a support set and find its k nearest neighbors from the support set. By going beyond single instance positive, SNDC can learn more generalized features representation with inherent semantic meaning and therefore alleviating inter-class conflictions. Experimental results on multiple benchmark datasets show that the performance of SNDC is superior to the state-of-the-art clustering models, with accuracy improvement of 6.2% and 20.5% on CIFAR-10 and ImageNet-Dogs respectively.},
  archive      = {J_IJFCS},
  author       = {Lin Li and Feng Zhang and Jiashuai Zhang and Qiang Hua and Chun-Ru Dong and Chee-Peng Lim},
  doi          = {10.1142/S0129054122460017},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {5},
  pages        = {599-618},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {A novel image clustering algorithm based on supported nearest neighbors},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing reliability of folded petersen networks based on edge partition. <em>IJFCS</em>, <em>36</em>(4), 583-598. (<a href='https://doi.org/10.1142/S0129054124500205'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid expansion of infrastructure topology, especially noticeable in high-performance computing systems and data center networks, significantly increases the likelihood of failures in network components. While traditional (edge) connectivity has long been the standard for measuring the reliability of interconnection networks, this approach becomes less effective as networks grow more complex. To address this, two innovative metrics, named matroidal connectivity and conditional matroidal connectivity, have emerged. These metrics provide the flexibility to impose constraints on faulty edges across different dimensions and have shown promise in enhancing the edge fault tolerance of interconnection networks. In this paper, we explore (conditional) matroidal connectivity of the k k k -dimensional folded Petersen network F P k F P k FPk , which is constructed by iteratively applying the Cartesian product operation on the well-known Petersen graph and possesses a regular, vertex- and edge-symmetric architecture with optimal connectivity and logarithmic diameter. Specifically, the faulty edge set F F F is partitioned into k k k subsets according to the dimensions of F P k F P k FPk . We then arrange these subsets by their cardinality, imposing the restriction whereby the cardinality of the i i i th largest subset dose not exceed 3 ⋅ 1 0 i − 1 3 ⋅ 1 0 i − 1 3⋅10i−1 for 1 ≤ i ≤ k 1 ≤ i ≤ k 1≤i≤k . Subsequently, we show that F P k − F F P k − F FPk−F is connected with ∣ ∣ F ∣ ∣ ≤ ∑ k i = 1 ( 3 ⋅ 1 0 i − 1 ) | F | ≤ ∑ i = 1 k ( 3 ⋅ 1 0 i − 1 ) |F|≤∑i=1k(3⋅10i−1) and determine the exact value of matroidal connectivity and conditional matroidal connectivity.},
  archive      = {J_IJFCS},
  author       = {Wanling Lin and Zhaoding Lin and Hongbin Zhuang and Xiao-Yan Li},
  doi          = {10.1142/S0129054124500205},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {4},
  pages        = {583-598},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Enhancing reliability of folded petersen networks based on edge partition},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The generalized 3-connectivity of a family of regular networks. <em>IJFCS</em>, <em>36</em>(4), 569-582. (<a href='https://doi.org/10.1142/S0129054124500199'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generalized k -connectivity of a graph G , denoted by κ k ( G ) , is the minimum number of internally edge disjoint S -trees for any S ⊆ V ( G ) with | S | = k . The generalized k -connectivity of a graph is a natural extension of the classical connectivity and can be served as an essential parameter for measuring reliability and fault tolerance of the network. Hierarchical interconnection networks (HIN’s) are very important in applications related to the modern interconnection networks since they posses many desirable properties. In this paper, we firstly introduce a family of regular networks H G n that can be obtained from G n 1 ∪ G n 2 ∪ ⋯ ∪ G n t by adding a matching, where G n i and G n j are vertex-disjoint subgraphs and each G n i is isomorphic to a given graph G n ( 1 ≤ i < j ≤ t ). Then we determine the generalized 3-connectivity of H G n . As applications of the main result, the generalized 3-connectivity of some HIN’s, such as the hierarchical star network H S n , the hierarchical cubic network H C N n and the hierarchical folded hypercube H F Q n , can be determined immediately.},
  archive      = {J_IJFCS},
  author       = {Jing Wang and Xidao Luan and Yuanqiu Huang},
  doi          = {10.1142/S0129054124500199},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {4},
  pages        = {569-582},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {The generalized 3-connectivity of a family of regular networks},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Some constructions of perfect c-nonlinear and pseudo-perfect c-nonlinear functions. <em>IJFCS</em>, <em>36</em>(4), 553-568. (<a href='https://doi.org/10.1142/S0129054124500187'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The perfect nonlinear functions play an important role in block ciphers and have been widely investigated in the literature. Subsequently, the perfect c -nonlinear functions were generalized by Ellingsen et al. in 2020. In this paper, we study the c -differential uniformity of some functions. We first construct some perfect c -nonlinear functions from known ones. Additionally, pseudo-perfect c -nonlinear functions are also investigated and a necessary and sufficient condition for a function to be pseudo-perfect c -nonlinear is presented. Meanwhile, some pseudo-perfect c -nonlinear functions are constructed. Remarkably, we completely give the difference distribution table of a function with respect to the pseudo c -derivative.},
  archive      = {J_IJFCS},
  author       = {Xiangdong Cheng},
  doi          = {10.1142/S0129054124500187},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {4},
  pages        = {553-568},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Some constructions of perfect c-nonlinear and pseudo-perfect c-nonlinear functions},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parametric algorithm to find the largest empty rectangle from a set of line segments. <em>IJFCS</em>, <em>36</em>(4), 537-551. (<a href='https://doi.org/10.1142/S0129054124500175'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A combinatorial algorithm to locate the Maximum Empty Rectangle ( M E R ) inside a given set L of non-intersecting horizontal and vertical line segments is presented in this paper. The M E R is the maximum area rectangle such that no line segment lies in part or in full within the rectangle. The proposed algorithm uses the projection lists and line sweep technique 𝒪 ( k n log n ) , where n is the cardinality of the set L , and k is the maximum number of candidate rectangles for a line segment. Projection list is the projection of the line segments on X and Y axes.},
  archive      = {J_IJFCS},
  author       = {Raina Paul and Apurba Sarkar and Arindam Biswas},
  doi          = {10.1142/S0129054124500175},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {4},
  pages        = {537-551},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Parametric algorithm to find the largest empty rectangle from a set of line segments},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The 4-set tree connectivity of folded hypercube. <em>IJFCS</em>, <em>36</em>(4), 517-535. (<a href='https://doi.org/10.1142/S0129054124500163'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k -set tree connectivity, as a natural extension of classical connectivity, is a very important index to evaluate the fault-tolerance of interconnection networks. Let G = ( V , E ) be a connected graph and a subset S ⊆ V , an S -tree of graph G is a tree T = ( V ′ , E ′ ) that contains all the vertices of S and E ( T ) ⊆ E ( G ) . Two S -trees T and T ′ are internally disjoint if and only if E ( T ) ∩ E ( T ′ ) = Ø and V ( T ) ∩ V ( T ′ ) = S . The cardinality of maximum internally disjoint S -trees is defined as κ G ( S ) , and the k -set tree connectivity is defined by κ k ( G ) = min { κ G ( S ) | S ⊆ V ( G ) and | S | = k } . In this paper, we show that the k -set tree connectivity of folded hypercube when k = 4 , that is, κ 4 ( F Q n ) = n , where F Q n is folded hypercube for n ≥ 2 .},
  archive      = {J_IJFCS},
  author       = {Junzhen Wang and Shumin Zhang and Bo Zhu},
  doi          = {10.1142/S0129054124500163},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {4},
  pages        = {517-535},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {The 4-set tree connectivity of folded hypercube},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient algorithm to compute dot product dimension of some outerplanar graphs. <em>IJFCS</em>, <em>36</em>(4), 501-516. (<a href='https://doi.org/10.1142/S0129054124500151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A graph G = ( V ( G ) , E ( G ) ) is called a k -dot product graph if there is a function f : V ( G ) → ℝ k such that for any two distinct vertices u and v , f ( u ) . f ( v ) ≥ 1 if and only if u v ∈ E ( G ) . The minimum value k such that G is a k -dot product graph, is called the dot product dimension ρ ( G ) of G . In this paper, we give an efficient algorithm for computing the dot product dimension of outerplanar graphs of at most two edge-disjoint cycles. If the graph has two cycles, we only consider those outerplanar graphs if both cycles have exactly one vertex in common and the length of one of the cycles is greater than or equal to six.},
  archive      = {J_IJFCS},
  author       = {Mahin Bahrami and Dariush Kiani and Zahed Rahmati},
  doi          = {10.1142/S0129054124500151},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {4},
  pages        = {501-516},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {An efficient algorithm to compute dot product dimension of some outerplanar graphs},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Repetition factorization of automatic sequences. <em>IJFCS</em>, <em>36</em>(3), 479-499. (<a href='https://doi.org/10.1142/S0129054124430019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Following Inoue et al. , we define a word to be a repetition if it is a (fractional) power of exponent at least 2 . A word has a repetition factorization if it is the product of repetitions. We study repetition factorizations in several (generalized) automatic sequences, including the infinite Fibonacci word, the Thue-Morse word, paperfolding words, and the Rudin-Shapiro sequence.},
  archive      = {J_IJFCS},
  author       = {Narad Rampersad and Jeffrey Shallit and Xinhao Xu},
  doi          = {10.1142/S0129054124430019},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {3},
  pages        = {479-499},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Repetition factorization of automatic sequences},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-dimensional context-free grid grammars. <em>IJFCS</em>, <em>36</em>(3), 457-477. (<a href='https://doi.org/10.1142/S012905412543004X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We expand upon the concept of context-free grammars into two dimensions with the introduction of the two-dimensional context-free grid grammar. In this model, production right-hand sides consist of general matrices containing both terminals and nonterminals. This proposal extends the Kolam array matrix grammar originally proposed by Siromoney et al. in 1973. By doing so, we provide a theoretical foundation for grammars frequently utilized in document analysis, highlighting both their capabilities and limitations. Our research reveals that the resulting family of picture languages possesses some properties not found in traditional one-dimensional context-free languages, a phenomenon commonly observed in the domain of picture languages.},
  archive      = {J_IJFCS},
  author       = {Daniel Průša},
  doi          = {10.1142/S012905412543004X},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {3},
  pages        = {457-477},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Two-dimensional context-free grid grammars},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latvian quantum finite state automata for unary languages. <em>IJFCS</em>, <em>36</em>(3), 419-455. (<a href='https://doi.org/10.1142/S0129054124430032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We design Latvian quantum finite state automata ( lqfa s) recognizing unary regular languages with isolated cut point 1 2 . From an architectural viewpoint, we suitably combine two lqfa s recognizing with isolated cut point, respectively, the finite part and the ultimately periodic part any given unary regular language L consists of. In particular, both these lqfa s incorporate a sub-module discriminating strings on the basis of their length. Both the number of basis states and the isolation around the cut point of the resulting lqfa for L exponentially depend on the size of the minimal deterministic finite state automaton for L . Moreover, the recognition of L tends to becoming deterministic as the number of the basis states employed in the length-discriminating sub-module grows.},
  archive      = {J_IJFCS},
  author       = {Carlo Mereghetti and Beatrice Palano and Priscilla Raucci},
  doi          = {10.1142/S0129054124430032},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {3},
  pages        = {419-455},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Latvian quantum finite state automata for unary languages},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Kernels of context-free languages. <em>IJFCS</em>, <em>36</em>(3), 393-417. (<a href='https://doi.org/10.1142/S0129054124430056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the closure of a language family ℒ under certain language operations is the least family of languages which contains all members of ℒ and is closed under all of the operations, a kernel of ℒ is a maximal family of languages which is a sub-family of ℒ and is closed under all of the operations. Here we investigate properties of kernels of general language families and operations defined thereon as well as kernels of (deterministic) (linear) context-free languages with a focus on Boolean operations. While the closures of language families are unique, this uniqueness is not obvious for kernels. We consider properties of language families and of operations that yield unique and non-unique, i.e. a set, of kernels. For the latter case, the question whether the union of all kernels coincides with the language family, or whether there are languages that do not belong to any kernel is addressed. Additionally, languages that are mandatory for each (Boolean) kernel and languages that are optional for (Boolean) kernels are studied. That is, we consider the intersection of all Boolean kernels as well as their union. The expressive capacities of these families are addressed leading to a hierarchical structure. Further closure properties are considered. Furthermore, we study descriptional complexity aspects of these families, where languages are represented by context-free grammars with proofs attached. It turns out that the size trade-offs between all families in question and deterministic context-free languages are non-recursive. That is, one can choose an arbitrarily large recursive function f , but the gain in economy of description eventually exceeds f when changing from the latter system to the former.},
  archive      = {J_IJFCS},
  author       = {Martin Kutrib and Luca Prigioniero},
  doi          = {10.1142/S0129054124430056},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {3},
  pages        = {393-417},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Kernels of context-free languages},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Language quotients revisited. <em>IJFCS</em>, <em>36</em>(3), 371-391. (<a href='https://doi.org/10.1142/S0129054125430026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit the basic concept of quotient of a regular language R by a language L that is not necessarily regular. We revise the deterministic complexity upper bounds of the quotient operation, and we also address the nondeterministic case. Specifically, the revised deterministic upper bound is shown to be more accurate for all hard streams of regular languages. When both languages R and L are regular, we give algorithms to construct their quotient in four ways. If the two languages are given via NFAs, the first algorithm produces an NFA for the desired quotient. If the two languages are given via regular expressions, we present an algorithm that produces a regular expression for the quotient both using ordinary derivatives and using partial derivatives. Finally, we consider regular expressions with a quotient operator and define the set of partial derivatives for regular expressions with this operator. Thus, using the partial derivative automaton, one can directly produce an NFA for the quotient. We have implemented all algorithms and present here experimental results.},
  archive      = {J_IJFCS},
  author       = {Stavros Konstantinidis and Nelma Moreira and Rogério Reis},
  doi          = {10.1142/S0129054125430026},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {3},
  pages        = {371-391},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Language quotients revisited},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Language acceptors with a pushdown: Characterizations and complexity. <em>IJFCS</em>, <em>36</em>(3), 345-370. (<a href='https://doi.org/10.1142/S0129054124430044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study one-way nondeterministic pushdown automata ( N P D A ), optionally with reversal-bounded counters. Finite-turn pushdown automata are pushdown automata with a bound on the number of switches between pushing and popping. We give new characterizations for finite-turn pushdown automata, and for finite-turn pushdown automata augmented with reversal-bounded counters. The first is in terms of multi-tape nondeterministic finite automata ( N F A ), and the second is in terms of multi-tape N F A with reversal-bounded counters. We then use the characterizations to determine the complexity of the languages defined by these automata. In particular, we show that languages accepted by finite-turn N P D A augmented with reversal-bounded counters are in N L O G . For the non-finite-turn case, the languages are in D S P A C E ( log 2 n ) and in P . We also look at the space complexity of languages accepted by two-way machines. In particular, we show that every language accepted by a two-way N P D A with reversal-bounded counters that makes a polynomial (resp., exponential) number of input head reversals is in D S P A C E ( log 2 n ) (resp., D S P A C E ( n 2 ) ). This remains true if the pushdown can flip its contents a bounded number of times.},
  archive      = {J_IJFCS},
  author       = {Oscar H. Ibarra and Ian McQuillan},
  doi          = {10.1142/S0129054124430044},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {3},
  pages        = {345-370},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Language acceptors with a pushdown: Characterizations and complexity},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conversions between six models of finite automata. <em>IJFCS</em>, <em>36</em>(3), 321-344. (<a href='https://doi.org/10.1142/S0129054124430020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine the costs of the conversions between six automata models: deterministic finite automata, partial deterministic finite automata, nondeterministic finite automata with a unique final state and multiple final states, respectively, alternating finite automata, and Boolean finite automata. We present a tight upper bound for each conversion. All witnesses are described over a unary or binary alphabet, and we show that whenever a binary alphabet is used, it is always optimal.},
  archive      = {J_IJFCS},
  author       = {Michal Hospodár and Galina Jirásková},
  doi          = {10.1142/S0129054124430020},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {3},
  pages        = {321-344},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Conversions between six models of finite automata},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Binary coded unary regular languages. <em>IJFCS</em>, <em>36</em>(3), 285-319. (<a href='https://doi.org/10.1142/S0129054124430068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ℒ ⊆ { 0 , 1 } ∗ is a binary coded unary regular language, if there exists a unary regular language ℒ ′ ⊆ { a } ∗ such that a x is in ℒ ′ if and only if the binary representation of x is in ℒ . If a unary language ℒ ′ is accepted by a minimal deterministic finite automaton (DFA) 𝒜 ′ with n states, then its binary coded version ℒ is regular and can be accepted by a DFA 𝒜 using at most n states, but at least 1 + ⌈ log n ⌉ states. There are witness languages matching these upper and lower bounds exactly, for each n . More precisely, if 𝒜 ′ uses σ ≥ 0 states in the initial segment and μ ⋅ 2 ℓ states in the loop, where μ is odd and ℓ ≥ 0 , then the minimal 𝒜 for ℒ consists of a preamble with at most σ but at least max { 1 , 1 + ⌈ log σ ⌉ − ℓ } states, except for σ = 0 with no preamble, and a kernel with at most μ ⋅ 2 ℓ but at least μ + ℓ states. Also these lower bounds are matched exactly by witness languages, for each σ , μ , ℓ . If the length of the loop is fixed, the size of the preamble is bounded by O ( σ / log σ ) . The conversion in the opposite way is not always granted: there are binary regular languages the unary versions of which are not even context free. The conversion of a unary nondeterministic finite automaton (NFA) to a binary NFA uses O ( n 2 ) states and introduces a binary version of Chrobak normal form.},
  archive      = {J_IJFCS},
  author       = {Viliam Geffert and Dominika Pališínová and Juraj Šebej},
  doi          = {10.1142/S0129054124430068},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {3},
  pages        = {285-319},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Binary coded unary regular languages},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Giovanni in paris. <em>IJFCS</em>, <em>36</em>(3), 269-283. (<a href='https://doi.org/10.1142/S0129054125430014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiautomata are collections of independent finite two-way deterministic automata that read synchronously the same input and are occasionally capable of broadcasting their current states. The reception of such a message affects the run of the automata by resetting them to some deterministically predetermined new state. An input is accepted if a specific automaton, say the first one of the collection, enters an accepting state. We consider the case where the input is on a unary alphabet which can be viewed as an integer. We show that if the number of messages broadcast during the computation is finite, then the set of inputs recognised is a regular language.},
  archive      = {J_IJFCS},
  author       = {Christian Choffrut},
  doi          = {10.1142/S0129054125430014},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {3},
  pages        = {269-283},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Giovanni in paris},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leftmost derivations in CD grammar systems. <em>IJFCS</em>, <em>36</em>(3), 247-267. (<a href='https://doi.org/10.1142/S0129054125430038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the power of CD grammar systems using different types of leftmost derivations for all standard cooperation strategies including the so-called full-competence mode of derivation. It is proved that, for some types of leftmost restrictions and cooperation strategies, CD grammar systems generate the same language classes as in the unrestricted, “non-leftmost” case, but the generative power is also increased or decreased in several cases. Thereby, some new relations to well-known Chomsky and Lindenmayer classes are presented.},
  archive      = {J_IJFCS},
  author       = {Henning Bordihn and György Vaszil},
  doi          = {10.1142/S0129054125430038},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {3},
  pages        = {247-267},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Leftmost derivations in CD grammar systems},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterization of isometric words based on swap and mismatch distance. <em>IJFCS</em>, <em>36</em>(3), 221-245. (<a href='https://doi.org/10.1142/S0129054125430051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider an edit distance with swap and mismatch operations, called tilde-distance, and introduce the corresponding definition of tilde-isometric word. Isometric words are classically defined with respect to Hamming distance and combine the notion of edit distance with the property that a word does not appear as factor in other words. A word f is said tilde-isometric if, for any pair of f -free words u and v , there exists a minimal transformation from u to v via the related edit operations such that all the intermediate words are also f -free. This new setting is here studied giving a full characterization of the tilde-isometric words in terms of overlaps with errors.},
  archive      = {J_IJFCS},
  author       = {Marcella Anselmo and Giuseppa Castiglione and Manuela Flores and Dora Giammarresi and Maria Madonia and Sabrina Mantaci},
  doi          = {10.1142/S0129054125430051},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {3},
  pages        = {221-245},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Characterization of isometric words based on swap and mismatch distance},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preface. <em>IJFCS</em>, <em>36</em>(3), 219-220. (<a href='https://doi.org/10.1142/S0129054125020010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJFCS},
  author       = {Martin Kutrib and Andreas Malcher and Branislav Rovan},
  doi          = {10.1142/S0129054125020010},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {3},
  pages        = {219-220},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Preface},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The longest wave subsequence problem: Generalizations of the longest increasing subsequence problem. <em>IJFCS</em>, <em>36</em>(2), 203-218. (<a href='https://doi.org/10.1142/S012905412450014X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The longest increasing subsequence (LIS) problem aims to find the subsequence exhibiting an increasing trend in a numeric sequence with the maximum length. In this paper, we generalize the LIS problem to the longest wave subsequence (LWS) problem, which encompasses two versions: LWSt and LWSr. Given a numeric sequence A of distinct values and a target trend sequence T , the LWSt problem aims to identify the longest subsequence of A that preserves the trend of the prefix of T . And, the LWSr problem aims to find the longest subsequence of A within r segments, alternating increasing and decreasing subsequences. We propose two efficient algorithms for solving the two versions of the LWS problem. For the LWSt problem, the time complexity of our algorithm is O ( n log n ) , where n represents the length of the given numeric sequence A . Additionally, we propose an O ( r n log n ) -time algorithm for solving the LWSr problem. In both algorithms, we utilize the priority queues for the insertion, deletion, and successor operations.},
  archive      = {J_IJFCS},
  author       = {Guan-Zhi Chen and Chang-Biau Yang and Yu-Cheng Chang},
  doi          = {10.1142/S012905412450014X},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {2},
  pages        = {203-218},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {The longest wave subsequence problem: Generalizations of the longest increasing subsequence problem},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Eulerian and hamiltonian soft semigraphs. <em>IJFCS</em>, <em>36</em>(2), 183-202. (<a href='https://doi.org/10.1142/S0129054124500138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft set theory is a mathematical approach to address the challenges of handling vague or uncertain information. It is a more advanced version of classical set theory that deals with imprecise elements and enables the flexible representation of uncertain data. It involves categorizing the elements of the universe based on specific parameters. Semigraph is a generalization of a graph which is different from a hypergraph. A hypergraph extends the concept of a graph by allowing any subset of vertices to form an edge. Semigraphs, on the other hand, distinguish themselves from hypergraphs by imposing a specific order on the vertices within each edge. Soft semigraphs were developed using the principles of soft set theory applied to semigraphs. This study introduces Eulerian and Hamiltonian soft semigraphs. We establish a necessary and sufficient condition for a soft semigraph to be Eulerian, relying on parameters such as p -part consecutive adjacent degree, p -part end degree, and the p -part consecutive adjacency graph. Additionally, we provide the conditions for a soft semigraph to be Hamiltonian. We introduce the concept of maximal non-Hamiltonian p -part. Finally, we define the closure of a soft semigraph and demonstrate the relationship between a Hamiltonian soft semigraph and its closure.},
  archive      = {J_IJFCS},
  author       = {Bobin George and Jinta Jose and Rajesh K. Thumbakara},
  doi          = {10.1142/S0129054124500138},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {2},
  pages        = {183-202},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Eulerian and hamiltonian soft semigraphs},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Paired domination integrity of graphs. <em>IJFCS</em>, <em>36</em>(2), 161-181. (<a href='https://doi.org/10.1142/S0129054124500126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of vulnerability in a communication network plays an important role when there is a disruption in the network. There exist several graph parameters that measure the vulnerability of a communication network. Domination integrity is one of the vulnerability parameters that measure the performance of a communication network. In this paper, we introduce the concept of paired domination integrity of a graph as a new measure of graph vulnerability. Let G = ( V , E ) be a simple, connected graph. A set of vertices in a graph G , say S , is a paired dominating set if the following two conditions are satisfied: (i) every vertex of G has a neighbor in S and (ii) the subgraph induced by S contains a perfect matching. The paired domination integrity of G , denoted by P D I ( G ) , is defined as P D I ( G ) = m i n { | S | + m ( G − S ) : S is a paired dominating set of G } , where m ( G − S ) is the order of the largest component in the induced subgraph of G − S . In this paper, we determine few bounds relating paired domination integrity with other graph parameters and the paired domination integrity of some classes of graphs.},
  archive      = {J_IJFCS},
  author       = {Annie Clare Antony and V. Sangeetha},
  doi          = {10.1142/S0129054124500126},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {2},
  pages        = {161-181},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Paired domination integrity of graphs},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conditional fractional matching preclusion number of graphs. <em>IJFCS</em>, <em>36</em>(2), 143-159. (<a href='https://doi.org/10.1142/S0129054124500114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conditional fractional matching preclusion number (CFMP number for short) f m p 1 ( G ) of a graph G is the minimum number of edges whose deletion results in a graph without isolated vertices and without fractional perfect matchings. In this paper, we study the CFMP number of complete graphs, complete bipartite graphs and twisted cubes. Also, we give Nordhaus–Gaddum-type results for the CFMP numbers of general graphs.},
  archive      = {J_IJFCS},
  author       = {Wen Li and Yuhu Liu and Yinkui Li and Eddie Cheng and Yaping Mao},
  doi          = {10.1142/S0129054124500114},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {2},
  pages        = {143-159},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Conditional fractional matching preclusion number of graphs},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improvement for error-correcting pairs of some special MDS codes. <em>IJFCS</em>, <em>36</em>(2), 127-141. (<a href='https://doi.org/10.1142/S0129054124500102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The error-correcting pair is a general algebraic decoding method for linear codes. Since every linear code is contained in an MDS linear code with the same minimum distance over some finite field extensions, we focus on MDS linear codes. Recently, He and Liao showed that for an MDS linear code 𝒞 with minimum distance 2 ℓ + 2 , if it has an ℓ -error-correcting pair, then the parameters of the pair have three possibilities. Moreover, for the first case, they gave a necessary condition for an MDS linear code 𝒞 with minimum distance 2 ℓ + 2 to have an ℓ -error-correcting pair, and for the other two cases, they only gave some counterexamples. For the second case, in this paper, we give a necessary condition for an MDS linear code 𝒞 with minimum distance 2 ℓ + 2 to have an ℓ -error-correcting pair, and then basing on the Product Singleton Bound, we prove that there are two cases for such pairs, and then give some counterexamples basing on twisted generalized Reed–Solomon codes for these cases.},
  archive      = {J_IJFCS},
  author       = {Rui Xiao and Qunying Liao},
  doi          = {10.1142/S0129054124500102},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {2},
  pages        = {127-141},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {An improvement for error-correcting pairs of some special MDS codes},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The h-component diagnosability of alternating group graphs. <em>IJFCS</em>, <em>36</em>(2), 111-125. (<a href='https://doi.org/10.1142/S0129054124300018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid expansion of multiprocessor systems, the fault diagnosis is becoming more and more important. The h -component diagnosability of a multiprocessor system, is proposed to extend the traditional diagnosability and has been investigated widely. In this paper, we prove that under both the PMC model and MM* model the 2 -component and 3 -component diagnosability of an n -dimensional alternating group graph are 2 n − 5 and 3 n − 7 respectively.},
  archive      = {J_IJFCS},
  author       = {Nengjin Zhuo and Shumin Zhang and Yalan Li and Chengfu Ye},
  doi          = {10.1142/S0129054124300018},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {2},
  pages        = {111-125},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {The h-component diagnosability of alternating group graphs},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Some special perfect c-nonlinear functions on ℤn. <em>IJFCS</em>, <em>36</em>(1), 97-110. (<a href='https://doi.org/10.1142/S0129054124500096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The notion of c -differential uniformity was proposed by Ellingsen et al. , which generalizes the classical differential uniformity measuring the resistance against differential cryptanalysis. Since then, the research of functions with low c -differential uniformity over finite fields attracted many researchers’ attention. However, it seems that there is no study of function with low c -differential uniformity over integer rings modulo n . In this paper, we give an extension of the c -differential uniformity concept to rings of integers module some n > 0 , and we present several perfect c -nonlinear polynomial functions on the integer ring ℤ n for the different integer n .},
  archive      = {J_IJFCS},
  author       = {Yan-Ping Wang and Wei-Guo Zhang},
  doi          = {10.1142/S0129054124500096},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {1},
  pages        = {97-110},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Some special perfect c-nonlinear functions on ℤn},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed independent sets in interval and segment intersection graphs. <em>IJFCS</em>, <em>36</em>(1), 67-95. (<a href='https://doi.org/10.1142/S0129054124500084'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Maximum Independent Set problem is well-studied in graph theory and related areas. An independent set of a graph is a subset of non-adjacent vertices of the graph. A maximum independent set is an independent set of maximum size. This paper studies the Maximum Independent Set problem in some classes of geometric intersection graphs in a distributed setting. More precisely, we study the Maximum Independent Set problem on two geometric intersection graphs, interval and axis-parallel segment intersection graphs, and present deterministic distributed algorithms in a model that is similar but a little weaker than the local communication model. We compute the maximum independent set on interval graphs in O ( k ) rounds and O ( n ) messages, where k is the size of the maximum independent set and n is the number of nodes in the graph. We provide a matching lower bound of Ω ( k ) on the number of rounds, whereas Ω ( n ) is a trivial lower bound on message complexity. Thus, our algorithm is both time and message-optimal. We also study the Maximum Independent Set problem in interval count l graphs, a special case of the interval graphs where the intervals have exactly l different lengths. We propose an 1 2 -approximation algorithm that runs in O ( l ) round. For axis-parallel segment intersection graphs, we design an 1 2 -approximation algorithm that obtains a solution in O ( D ) rounds. The results in this paper extend the results of Molla et al. [J. Parallel Distrib. Comput. 2019].},
  archive      = {J_IJFCS},
  author       = {Nirmala Bhatt and Barun Gorain and Kaushik Mondal and Supantha Pandit},
  doi          = {10.1142/S0129054124500084},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {1},
  pages        = {67-95},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Distributed independent sets in interval and segment intersection graphs},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linear complexity of r-ary sequences derived from euler quotient modulo pq. <em>IJFCS</em>, <em>36</em>(1), 49-66. (<a href='https://doi.org/10.1142/S0129054124500072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a generic construction of r -ary sequences with period p q 2 based on the Euler quotient modulo p q , where p and q are odd primes satisfying that p divides q − 1 and r is any prime less than q . The minimal polynomial and the linear complexity of the proposed sequences are determined in most cases under the assumption that r q − 1 ≢ 1 ( mod q 2 ) . The result shows that each of the sequences has large linear complexity.},
  archive      = {J_IJFCS},
  author       = {Zibi Xiao and Zepeng Li and Bo Yang and Jinmei Fan},
  doi          = {10.1142/S0129054124500072},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {1},
  pages        = {49-66},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Linear complexity of r-ary sequences derived from euler quotient modulo pq},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Limit law for zagreb and wiener indices of random exponential recursive trees. <em>IJFCS</em>, <em>36</em>(1), 35-48. (<a href='https://doi.org/10.1142/S0129054124500060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Wiener index is the sum of distances of all pairs of nodes in a graph; and the Zagreb index is defined as the sum of squares of the degrees of nodes in a rooted tree. In this note, we calculate the first two moments of the Wiener and Zagreb indices of random exponential recursive trees (random ERTs) from two systems of recurrence relations. Then, by an application of the contraction method, we characterize the limit law for a scaled Zagreb index of ERTs. Via the martingale convergence theorem, we also show the almost sure convergence and quadratic mean convergence of an appropriately scaled Wiener index that is indicative of the distance of two randomly chosen nodes.},
  archive      = {J_IJFCS},
  author       = {Ali Q. M. Al-Saedi and Ramin Imany Nabiyyi and Mehri Javanian},
  doi          = {10.1142/S0129054124500060},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {1},
  pages        = {35-48},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Limit law for zagreb and wiener indices of random exponential recursive trees},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Algorithmic aspects of outer-independent double roman domination in graphs. <em>IJFCS</em>, <em>36</em>(1), 25-34. (<a href='https://doi.org/10.1142/S0129054124500059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let G = ( V , E ) be graph. For any function h : V → { 0 , 1 , 2 , 3 } , let V i = { v ∈ V : h ( v ) = i } , 0 ≤ i ≤ 3 . The function h is called an outer-independent double Roman dominating function (OIDRDF) if the following conditions are satisfied. The outer-independent double Roman domination number of G is defined by γ o i d R ( G ) = min ∑ v ∈ V h ( v ) : h is an OIDRDF OF G . We prove that the decision problem MOIDRDP, corresponding to γ o i d R ( G ) is NP-complete for split graphs. We also show that it is linear time solvable for connected threshold graphs and bounded treewidth graphs. Finally, we show that the MOIDRDP and domination are not equivalent in computational complexity aspects.},
  archive      = {J_IJFCS},
  author       = {Amit Sharma and P. Venkata Subba Reddy and S. Arumugam and Jakkepalli Pavan Kumar},
  doi          = {10.1142/S0129054124500059},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {1},
  pages        = {25-34},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Algorithmic aspects of outer-independent double roman domination in graphs},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Edge-disjoint hamiltonian cycles in balanced hypercubes with applications to fault-tolerant data broadcasting. <em>IJFCS</em>, <em>36</em>(1), 1-24. (<a href='https://doi.org/10.1142/S0129054124500047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existence of multiple edge-disjoint Hamiltonian cycles (EDHCs for short) is a desirable property of interconnection networks. These parallel cycles can provide an advantage for algorithms that require a ring structure. Additionally, EDHCs can enhance all-to-all data broadcasting and edge fault tolerance in network communications. In this paper, we investigate the construction of EDHCs in the balanced hypercube, which is a variant of the hypercube with many attractive properties, such as strong connectivity, regularity, and symmetry. In particular, each processor in the balanced hypercube has a backup processor that shares the common neighbors, enabling fault tolerance and efficient system reconfiguration. In 2019, Lü et al. provided an algorithm to construct two EDHCs in an n -dimensional balanced hypercube B H n for n ≥ 2 . We further study this topic and give some construction schemes to construct 2 ⌊ log 2 n ⌋ EDHCs in B H n for n ≥ 2 . Since B H n is 2 n -regular, our result is optimal for n = 2 r ( r ≥ 1 ). In addition, we simulate the fault-tolerant data broadcasting through these parallel cycles as transmission channels.},
  archive      = {J_IJFCS},
  author       = {Shuai Liu and Yan Wang and Jianxi Fan and Baolei Cheng},
  doi          = {10.1142/S0129054124500047},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Edge-disjoint hamiltonian cycles in balanced hypercubes with applications to fault-tolerant data broadcasting},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijitdm">IJITDM - 76</h2>
<ul>
<li><details>
<summary>
(2025). A comparison between fuzzy TOPSIS and VIKOR to the selection of aircraft for airspace defense. <em>IJITDM</em>, <em>24</em>(7), 2189-2224. (<a href='https://doi.org/10.1142/S0219622025500348'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since 2013, the Spanish fleet of EF-18 fighters has not received major updates nor any other jet has been proposed for their replacement. Thereby, a decision problem of interest to the Spanish Air Force is addressed in this study. In this regard, a collection of six potential alternatives (Eurofighter Typhoon, F-35 Lightning II, F/A-18 Super Hornet, Dassault Rafale, F-15 EX, and Saab 39 Gripen) and 14 criteria (3 of which being qualitative) are evaluated based on expert consensus by a combination of fuzzy logic and multi-criteria decision making (MCDM) approaches (AHP-VIKOR/AHP-TOPSIS). The weights of the criteria and the valuation of the qualitative ones (via questionnaires) were made possible by the participation of two independent groups of experts, all of them fighter pilots. Once the extraction of knowledge was carried out via a fuzzy version of a modified AHP, it was found that the two most important criteria (“air superiority over neighbor countries” and “tactical capability”) were qualitative. A comparison between the rankings of the alternatives provided by fuzzy VIKOR and fuzzy TOPSIS approaches highlights that the fuzzy VIKOR ranking appears highly influenced by the most important criteria. On the contrary, fuzzy TOPSIS presents a more compensatory behavior than fuzzy VIKOR. Given the differences observed when comparing such rankings of alternatives, a triple sensitivity analysis was conducted to ensure robustness. Our results highlight the Dassault Rafale as the most promising option for replacement. This finding suggests its potential as a benchmark for future fighter selection and next-generation fighter planning.},
  archive      = {J_IJITDM},
  author       = {Juan Miguel Sánchez–Lozano and M. Fernández–Martínez and Mariano Alonso Larraz},
  doi          = {10.1142/S0219622025500348},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {7},
  pages        = {2189-2224},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A comparison between fuzzy TOPSIS and VIKOR to the selection of aircraft for airspace defense},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predictive modeling for identifying undervalued stocks using machine learning. <em>IJITDM</em>, <em>24</em>(7), 2163-2188. (<a href='https://doi.org/10.1142/S0219622025500336'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the application of Machine Learning (ML) techniques to identify undervalued stocks, addressing the limitations of traditional investment strategies that rely heavily on fundamental analysis. As financial markets become more complex, characterized by volatility and information asymmetry, conventional valuation methods often struggle to capture these dynamics. In contrast, ML offers the ability to analyze large datasets and uncover intricate patterns, presenting a data-driven alternative for stock selection and portfolio optimization. A comprehensive predictive framework was developed, integrating traditional financial ratios with novel features derived from value investing principles and technical analysis. Several ML models — Random Forest, Long Short-Term Memory (LSTM), and Support Vector Machines — were assessed for their ability to predict high-return stocks. Performance metrics, including accuracy, precision, and recall, were used to evaluate model effectiveness. Among the models tested, the LSTM demonstrated the highest accuracy at 0.81, proving its robustness in identifying undervalued stocks. This research contributes to the growing body of literature on ML in finance by offering a practical framework that bridges theoretical concepts with real-world applications. The study also emphasizes the importance of refining ML algorithms to improve model interpretability and transparency, crucial for fostering trust in these systems. Future research should explore the use of ensemble methods and alternative data sources to further enhance prediction accuracy, while addressing challenges related to accountability in ML-driven investment strategies. This work advances the conversation around algorithmic trading and the future of data-driven finance.},
  archive      = {J_IJITDM},
  author       = {Narongsak Sukma and Chakkrit Snae Namahoot},
  doi          = {10.1142/S0219622025500336},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {7},
  pages        = {2163-2188},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Predictive modeling for identifying undervalued stocks using machine learning},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing interestingness evaluation in ontology-based association rules: A case study on US birth data. <em>IJITDM</em>, <em>24</em>(7), 2139-2162. (<a href='https://doi.org/10.1142/S0219622025500324'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of association rule mining, evaluating the interestingness of discovered rules plays a crucial role in extracting meaningful patterns. However, the context of interestingness poses challenges that call for improvements in rule evaluation. This study focuses on addressing this problem by enhancing the evaluation of interestingness in ontology-based association rules. In this study, we present the effective rule evaluation using the ontology (EREO) model, which aims to evaluate the interestingness of ontology-based association rules in the context of US birth data. The EREO model incorporates three levels of rule evaluation: the utilization of proposed effective measures, consultation with domain experts, and the utilization of AI-based methods. To indirectly evaluate the interestingness of ontology-based rules, we propose two effective measures: Ontology-based rule specificity (ORS) and ontology-based rule complexity (ORC). Rule evaluation is further facilitated by domain experts and AI-based methods, employing an interestingness measurement scale (IMS). Furthermore, we compare the average interestingness scores obtained from ORS, ORC, and the EREO model with those derived from traditional interestingness measures. Our findings demonstrate that the proposed interestingness measures consistently outperform the traditional ones, as indicated by higher average scores. Additionally, we observe a positive relationship between the interestingness scores obtained using the three levels of the EREO model. Overall, this study effectively showcases the efficacy of ontology-based association rule evaluation in improving the quality of discovered rules and supporting informed decision-making processes.},
  archive      = {J_IJITDM},
  author       = {C B Abhilash and Kavi Mahesh},
  doi          = {10.1142/S0219622025500324},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {7},
  pages        = {2139-2162},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Enhancing interestingness evaluation in ontology-based association rules: A case study on US birth data},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A MADRL-based credit allocation approach for interactive multi-agents. <em>IJITDM</em>, <em>24</em>(7), 2117-2137. (<a href='https://doi.org/10.1142/S0219622025500312'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-agent systems (MAS), the interactions and credit allocation among agents are essential for achieving efficient cooperation. To enhance the interactivity and efficiency of credit allocation in multi-agent reinforcement learning, we introduce a credit allocation for interactive multi-agents method (CAIM). CAIM not only considers the effects of various actions on other agents but also leverages attention mechanisms to handle the mismatch between observations and actions. With a unique credit allocation strategy, agents can more precisely assess their contributions during collaboration. Experiments in various adversarial scenarios within the SMAC benchmark environment indicate that CAIM markedly outperforms existing multi-agent reinforcement learning approaches. Further ablation studies confirm the effectiveness of each CAIM component. This research presents a new paradigm for enhancing collaboration efficiency and overall performance in MAS.},
  archive      = {J_IJITDM},
  author       = {Ershen Wang and Xiaotong Wu and Chen Hong and Xinna Shang and Peifeng Wu and Chenglong He and Pingping Qu},
  doi          = {10.1142/S0219622025500312},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {7},
  pages        = {2117-2137},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A MADRL-based credit allocation approach for interactive multi-agents},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of companies in applied education: Determining the criteria and a case study at an industrial university. <em>IJITDM</em>, <em>24</em>(7), 2079-2115. (<a href='https://doi.org/10.1142/S0219622025500300'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Universities are transitioning to applied education models within the framework of university–industry cooperation. In this case, both students and universities face the problem of choosing suitable companies. There is no study in the literature that deals with the solution of this problem. Thus, this study discusses companies’ evaluation and selection for the applied education model. A new hybrid methodology is proposed. The methodology consists of the following activities: determining the evaluation criteria with expert opinions, weighting the criteria with AHP, and ranking the companies with TOPSIS and PROMETHEE. The methodology has been tested in a case study with real data from an industrial university. While TOPSIS is effective for certain criteria, the findings suggest that PROMETHEE may provide more effective results specifically for company evaluations within the applied education model, aligning better with the study’s objectives. The applied education model is expected to yield several key outcomes: For company managers, it will lead to increased efficiency by hiring graduates who already have practical experience. From the educators’ perspective, it will result in the training of graduates who are both experienced and highly employable. For students, the model will enhance their employability aligning their skills with their career aspirations and increasing their chances of employment in companies, that match their competencies and preferences after graduation.},
  archive      = {J_IJITDM},
  author       = {Sema Çiftçi and Mehmet Pınarbaşı and HacıMehmet Alakaş},
  doi          = {10.1142/S0219622025500300},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {7},
  pages        = {2079-2115},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Evaluation of companies in applied education: Determining the criteria and a case study at an industrial university},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mining nonderivable association rules using a genetic algorithm and a tree-based pruning technique. <em>IJITDM</em>, <em>24</em>(7), 2043-2078. (<a href='https://doi.org/10.1142/S0219622025500294'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Association rule mining is a method for searching databases for patterns or co-occurrences in data. The fundamental step in extracting association rules is mining frequent item sets. However, the itemsets extracted were found to have redundancy in them. This study aims to tackle the redundancy present in the generated association rules and itemsets. One commonly used technique to address redundancy is extracting nonderivable itemsets. The traditional approach in mining such itemsets involved checking for upper and lower bound inequalities by making a breadth-wise search of the dataset. However, this generated many candidate itemsets, increasing the algorithm’s run time and memory consumption. Therefore, it became imperative to develop a technique that addressed these shortcomings. A new approach utilizing a genetic algorithm has been proposed to extract the necessary nonderivable itemsets. To our knowledge, such an approach has not been incorporated so far in extracting nonderivable itemsets. Here operations such as crossover and mutation are applied to generate the required itemsets and this was found to be faster and more efficient in memory in comparison to existing approaches based on distribution and discretization of data. Another problem of pressing concern is the redundancy that prevailed in the association rules that were extracted from the mined itemsets. Traditional approaches involved making repeated scans of the mined collection of association rules to prune out redundant rules. Due to this, the algorithm’s runtime increased. To handle this drawback our work proposes a novel approach based on tree-based pruning to remove redundant association rules. The left and right expansion principles provide the foundation of the tree’s construction. The Minimal Antecedent and Maximal Consequent concepts are used to eliminate redundant rules and produce the necessary set of nonderivable association rules. Based on the findings of this study, it is evident that the suggested method improves run time overall by 48.77% and memory by 35.65%. Concerning metrics such as Precision, Recall, and Accuracy an aggregate improvement of 94.92%, 90.8%, and 91.21% was observed in comparison to existing approaches.},
  archive      = {J_IJITDM},
  author       = {P. P. Jashma Suresh and U. Dinesh Acharya and N. V. Subba Reddy},
  doi          = {10.1142/S0219622025500294},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {7},
  pages        = {2043-2078},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Mining nonderivable association rules using a genetic algorithm and a tree-based pruning technique},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation and benchmarking trauma patients in intensive care units using a novel decision-making framework. <em>IJITDM</em>, <em>24</em>(7), 2005-2041. (<a href='https://doi.org/10.1142/S0219622025500282'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trauma patients often face complex health consequences and are at a risk of rapid deterioration. Prioritizing trauma patients in intensive care units (ICUs) is essential for timely intervention. Current prioritization approaches are challenging tasks that involve considering multiple evaluation criteria, trade-offs and criteria importance, thus requiring a robust multicriteria decision-making (MCDM) approach. In this study, we propose a novel MCDM framework for the evaluation and benchmarking of trauma patients on the basis of health control (HC) criteria derived from real trauma data. The framework consists of two main phases. In the first phase, a dataset of adult trauma patients referred to a trauma network in the West Midlands region of the United Kingdom is identified and preprocessed. This dataset covers the period from 15 May 2014 to 16 December 2016, providing continuous monitoring of the patients. In the second phase, MCDM methods are employed to develop a dynamic decision matrix (DM) that assesses 35 trauma patients on the basis of 16 HC trauma criteria. Using 2-tuple spherical fuzzy linguistic numbers with fuzzy-weighted zero-inconsistency (2TSFLNs-FWZIC), the framework ensures accurate weighting of the criteria, with C1=PS14 and C5=NISS receiving the highest weight values (0.062606) and C2=CD3+8+(106/L) receiving the lowest weight value (0.062353). This weighting process is guided by the input and expertise of a panel of five emergency medicine specialists who have experience in trauma patient management. The results indicate that CoCoSo effectively ranks patients from the least critical ( k = 1 . 3 4 8 7 2 5 ) to the most critical cases ( k = 1 . 6 2 2 0 5 3 ) for ICU admission. The proposed framework is evaluated via systematic ranking and sensitivity analysis, providing validation measures for its performance, robustness and reliability.},
  archive      = {J_IJITDM},
  author       = {A. S. Albahri and Mohammed S. Al-Samarraay and O. S. Albahri and A. H. Alamoodi and Rula A. Hamid and Raad Z. Homod and Saleh Mahdi Mohammed and Iman Mohamad Sharaf},
  doi          = {10.1142/S0219622025500282},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {7},
  pages        = {2005-2041},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Evaluation and benchmarking trauma patients in intensive care units using a novel decision-making framework},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault detection and predictive maintenance of photovoltaic facilities. <em>IJITDM</em>, <em>24</em>(7), 1971-2003. (<a href='https://doi.org/10.1142/S0219622025500531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces an automatic decision support system for photovoltaic fault detection and predictive maintenance without the use of meteorological variables, which is a remarkable feature due to the lack of weather forecasts and wide variety of cases. This system improves another previous methodology to fault detection and introduces for the first time a module to predictive maintenance with good results. This module is based on fuzzy sets and the modeling of the behavior of the facilities through the computation and selection of a set of decision rules. The new decision support system has been validated and tested in the facilities of the company Grupo Energético de Puerto Real S.A.},
  archive      = {J_IJITDM},
  author       = {Roberto G. Aragón and Fernando Chacón-Gómez and M. Eugenia Cornejo and Jesús Medina and Eloísa Ramírez-Poussa},
  doi          = {10.1142/S0219622025500531},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {7},
  pages        = {1971-2003},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Fault detection and predictive maintenance of photovoltaic facilities},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On COVID-19 epidemic prevention policy based on matrix game and sentiment analysis. <em>IJITDM</em>, <em>24</em>(7), 1941-1969. (<a href='https://doi.org/10.1142/S0219622025500270'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effectively combating the 2019 coronavirus disease (COVID-19), pandemic relies not only on robust governmental policies but also on the active cooperation of the populace. In order to formulate rational and effective preventive policies, this study proposes an interval 2-tuple linguistic matrix game method and defines an interval 2-tuple linguistic scoring function. Building upon this framework, the study employs sentiment analysis based on the BosonNLP sentiment dictionary to extract and calculate textual scores from user comments on COVID-19 pandemic-related topics in Weibo. These two approaches are then integrated and applied to policy decision-making for the COVID-19 situation in the Shanghai region. Finally, the matrix game method is used to find the optimal prevention and control strategy in Shanghai during the epidemic period. The first is “Implement citywide preventive measures”, the second is “Implement traffic control combined with regional control policy”, and the last is “Implement the home quarantine policy”.},
  archive      = {J_IJITDM},
  author       = {Huanyu Wan and Dong Qiu},
  doi          = {10.1142/S0219622025500270},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {7},
  pages        = {1941-1969},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {On COVID-19 epidemic prevention policy based on matrix game and sentiment analysis},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrated energy system evaluation based on singular value decomposition and group decision making with incomplete information. <em>IJITDM</em>, <em>24</em>(7), 1911-1939. (<a href='https://doi.org/10.1142/S0219622025500269'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transformation of energy development is the inevitable choice to achieve the target of carbon neutrality, and the integrated energy system (IES) is conducive to improving the energy efficiency of users and optimizing energy structure, which is an important direction of energy system transformation in the future. Evaluation of IESs is a major part of the implementation of IES projects, while the current evaluations are based on complete information and single decision making. Given this background, this paper studies the IES evaluation with incomplete information and focuses on the group decision. First, the singular value decomposition algorithm is adopted to predict the missing data. Then, when calculating the index weights, a new method based on standard deviation modified unique reference comparison judgment method is proposed, which not only integrates subjective and objective decision information, but also avoids the problem that the combination coefficients of subjective and objective weights cannot be reasonably allocated. Next, on the basis of the comprehensive weights of indexes and normalized evaluation matrix, the weighted evaluation matrix for each expert is constructed, and the expert weights are calculated by genetic algorithm. Finally, the ranking of IES schemes can be realized by integrating expert weights and expert scoring values. Based on the data of IES at a hospital in Henan, the performance of the proposed method is verified experimentally. Experiments results show that the proposed method is reasonable and effective.},
  archive      = {J_IJITDM},
  author       = {Huan Zhang and Ya-Jun Leng and Libo Zhang and Zong-Yu Wu},
  doi          = {10.1142/S0219622025500269},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {7},
  pages        = {1911-1939},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Integrated energy system evaluation based on singular value decomposition and group decision making with incomplete information},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editor’s introduction. <em>IJITDM</em>, <em>24</em>(7), 1905-1910. (<a href='https://doi.org/10.1142/S0219622025030075'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJITDM},
  author       = {Yong Shi},
  doi          = {10.1142/S0219622025030075},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {7},
  pages        = {1905-1910},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Editor’s introduction},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design of exogenous neuro-structure for dynamical analysis of nonlinear fractional financial crime systems. <em>IJITDM</em>, <em>24</em>(6), 1849-1903. (<a href='https://doi.org/10.1142/S0219622025500257'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The contributions of AI-based applications in monitoring real-time financial transactions, and detecting fraudulent activity by scrutinizing consumer behavior, transaction patterns, and other relevant measures are worth mentioning for potential threats identification in the fractional financial crime population dynamics. Leveraging these financial crime systems in terms of population dynamics with the exploitation of supervised Nonlinear Autoregressive Exogenous Networks Optimized with the Bayesian Regularization (NARX-BR) procedures for attaining sufficient accuracy and flexibility for the approximate solutions of a fractional variant of stiff Nonlinear Financial Crime Population Dynamics (NFCPDs) differential system. The population dynamics for the financial crime model are classified mainly into susceptible persons, financial criminals, individuals being prosecuted individuals under prosecution, imprisoned persons, and honest individuals by law. The acquisition of synthetic data generated with Grünwald–Letnikov (GL) fractional operator for the multi-layer structure execution of NARX-BR procedure for solving NFCPDs for varying financial crime parameters, such as influence rate, recruitment rate, conversion rate to honest people, freedom rate, financial criminal prosecution rate per capita, percentage of discharge rate from prosecution, transition rate to prison, discharge and acquittal rate from prosecutions. The estimated outcomes of NARX-BR and the calculated numerical solutions of NFCPDs consistently overlap implying that the error between the results is approximately equal to zero. The effectiveness of model performance is assessed through a variety of evaluation metrics, that include minimization of mean square error-based objective function, adaptive regulating parameters of the optimization algorithm, error distribution plots, regression studies, error endogeneity, and cross-correlation analyses. This study contributes to integrating fractional calculus with the knacks of innovative AI and open paths to provide data-driven efficient solution-based policy recommendations in the field of financial crime population dynamics.},
  archive      = {J_IJITDM},
  author       = {Farwah Ali Syed and Kwo-Ting Fang and Adiqa Kausar Kiani and Muhammad Shoaib and Muhammad Asif Zahoor Raja},
  doi          = {10.1142/S0219622025500257},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {6},
  pages        = {1849-1903},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Design of exogenous neuro-structure for dynamical analysis of nonlinear fractional financial crime systems},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consumer decision recognition based on EEG signals for neuromarketing applications. <em>IJITDM</em>, <em>24</em>(6), 1825-1847. (<a href='https://doi.org/10.1142/S0219622025500245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuromarketing is a blooming interdisciplinary field that tries to understand the biology of consumer behavior by combining neuroscience with marketing. This technique can be used to grasp consumers’ hidden choices, intentions and decisions by analyzing their physiological and brain signals. Electroencephalography (EEG) is one of the popular neuroimaging techniques to capture and record the neural activity of the brain. Numerous research projections have been made in this field to achieve better results. Earlier approaches did not prioritize effective EEG signal preprocessing and classification methods. This paper presents a model to recognize consumer preferences by analyzing and classifying EEG signals. In this model, EEG signals are decomposed into many subbands using wavelet transform. An enhanced wavelet thresholding method is proposed to eliminate noise from subbands. Several wavelet features are computed from each subband and then fed as input to classifiers. Finally, three different machine learning classifiers are used to classify the signal between like and dislike. The classifiers are K-Nearest Neighbor (KNN), Multilayer Perceptron (MLP) and Support Vector Machine (SVM). EEG signals from 25 people are collected to verify the developed system’s performance. The effectiveness of the developed method with different classifiers is validated by varying brain lobe features and band features. In comparison to other classifiers like KNN and MLP, the designed system with the SVM classifier performs better and achieves an accuracy of 98.21%. The experimental findings for the developed system suggest that research in this area has the potential to alter and enhance marketing tactics for the benefit of both manufacturers and consumers, ultimately leading to a mutually beneficial outcome.},
  archive      = {J_IJITDM},
  author       = {S. Kumar Chandar and J. Vijayadurai and M. Palanivel Rajan},
  doi          = {10.1142/S0219622025500245},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {6},
  pages        = {1825-1847},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Consumer decision recognition based on EEG signals for neuromarketing applications},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing the security of E-commerce systems against various types of attacks using deep learning model. <em>IJITDM</em>, <em>24</em>(6), 1801-1824. (<a href='https://doi.org/10.1142/S0219622025500233'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, hackers can exploit unprotected e-commerce networks to attack an e-commerce network. As Malware becomes increasingly prevalent, diverse and sophisticated, recent studies highlight the effectiveness of deep Convolutional Neural Networks (CNNs) in detecting malware through attack classification. The background of this is complicated by factors such as data immutability, buyer, fraud and social network attacks. To overcome these issues, our proposed Convolution-based Buffalo Optimization (CbBO) is developed. To increase the performance, traditional buffalo optimization can be combined in a hybrid way with neural networks. The process of buffalo optimization entails identifying the best options depending on herd behavior. It may be necessary to alter how the optimization procedure searches the hyperparameter space to adapt this method to CNNs. Create a fitness feature that assesses CNN’s performance, especially regarding malware detection. Moreover, this research acts as the security classifier for e-commerce systems to identify attack variants and enhance security attack detection. Additionally, a technical model is developed to depict the dynamism of the model’s constituent parts. In the context of e-commerce security, our study will present simulation results to assess the effectiveness of the proposed paradigm. The CbBO model has been implemented using the Python platform and experimental validation demonstrates its capability to achieve 96% accuracy in effectively identifying DDoS attacks.},
  archive      = {J_IJITDM},
  author       = {Pooja Yadav and Ajit Kumar Keshri},
  doi          = {10.1142/S0219622025500233},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {6},
  pages        = {1801-1824},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Enhancing the security of E-commerce systems against various types of attacks using deep learning model},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PRASIAS: A new preference ranking model for comparing organizational performance under disruption. <em>IJITDM</em>, <em>24</em>(6), 1771-1800. (<a href='https://doi.org/10.1142/S0219622025500208'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to investigate the impact of COVID-19 on the organizational performance of automotive, fast-moving consumer goods, consumer durables, and healthcare during both pre-and post-pandemic periods, forming a dual objective. To achieve this, the paper uses a set of market price-based ratios including Price-to-Earnings (P/E), Price-to-Book value (P/B), Price-to-Sales (P/S), and Price-to-Cash Flow (P/CF), along with market risk, as indicators for performance comparison. The scope of the assessment is limited to the financial performance analysis. The paper also attempts to relate performance to long-term growth prospects measured by Tobin’s Q model. Second, the paper proposes a Multi-criteria Decision-Making (MCDM) model called Preference Ranking based on Similarity to Ideal Average Solutions (PRASIAS) to compare the organizations. PRASIAS is a novel extension of the recently introduced Preference Ranking on the Basis of Ideal-Average Distance (PROBID) method. PRASIAS uses similarity measures in terms of inclination angle and considers positive and negative ideal solutions, as well as the average solution, to provide a comprehensive decision-making framework. To determine criteria weights, the paper applies a recently developed model called Logarithmic Percentage Change-driven Objective Weighting (LOPCOW). The paper validates the results by comparing them with the outcomes of other MCDM methods, and it also performs sensitivity analysis to examine the stability of the ranking. From the results, it is evident that there are some variations in the comparative positions over the years. Cipla Ltd., Dr. Reddy’s Laboratories Ltd., Bajaj Auto Ltd., and Britannia Industries Ltd. secured the top positions. P/E ratio remains a dominant influencing factor, as indicated by the calculated weights. A positive association is observed between financial stability and the comparative ranking of the organizations, while Tobin’s Q has not proven to be a significant influencer. It is also noteworthy that COVID-19 has impacted the performance of these entities.},
  archive      = {J_IJITDM},
  author       = {Sanjib Biswas and Prasenjit Chatterjee and Edmundas Kazimieras Zavadskas},
  doi          = {10.1142/S0219622025500208},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {6},
  pages        = {1771-1800},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {PRASIAS: A new preference ranking model for comparing organizational performance under disruption},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Honey badger optimized meta-material-based 4-port MIMO antenna with WiMAX, WLAN and X-bands for UWB application. <em>IJITDM</em>, <em>24</em>(6), 1741-1769. (<a href='https://doi.org/10.1142/S0219622025500178'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multiple input–multiple output (MIMO) antenna is a necessary part of the field of wireless communication systems. Further, the meta-material plays a major part in reducing coupling between antennas. Hence, in this work, a meta-material-based 4-port MIMO antenna is designed for the UWB application using three band operations such as WiMAX (3.2–3.7 GHz), WLAN (4.1–6 GHz) and X-bands (8–12.1 GHz). In this research, the MIMO antenna is designed with complementary-split ring resonators (C-SRR) to improve the bandwidth of antenna elements with defected ground structure (DGS). Further, the metaheuristic algorithm honey badger optimization (HBO) is used for optimizing the antenna dimensions. The proposed design is simulated in the HFSS simulation platform on an FR-4 substrate with dimensions of 3 8 × 3 8 × 1 . 6 mm 3 . The gap between the elements of an antenna is 0 . 1 λ 0 . The radiation efficiency attained by the proposed structure is 93.7% for the overall operating range. Further, the MIMO system is a compact size and achieved a better envelope correlation coefficient ( ECC < 0 . 0 1 ) , total active reflection coefficient ( TARC < − 1 0 dB ) , diversity gain ( DG < 9 . 9 dB ) , channel capacity loss ( CCL < 0 . 4 ) and mean effective gain ( MEG < 3 dB ) at 3.7 GHz. Finally, it is concluded that the proposed meta-material-based MIMO antenna is the appropriate selection for the UWB applications.},
  archive      = {J_IJITDM},
  author       = {Prabhakar S Manage and Udaykumar Naik and Vijay Rayar},
  doi          = {10.1142/S0219622025500178},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {6},
  pages        = {1741-1769},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Honey badger optimized meta-material-based 4-port MIMO antenna with WiMAX, WLAN and X-bands for UWB application},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-attribute decision-making: Scaling issues in pairwise comparison approaches based on the analytic hierarchy process. <em>IJITDM</em>, <em>24</em>(6), 1717-1740. (<a href='https://doi.org/10.1142/S021962202550018X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analytic hierarchy process (AHP) has been the subject of intensive discussions over the past decades. The multiplicative AHP (MAHP) was developed to deal with issues regarding the scale and aggregation procedure but has never achieved the same popularity. Both methods represent pairwise comparison processes (PCPs) based on a numerical scale with associated verbal definitions. However, they process the comparisons differently, leading to different results. This paper uses an empirical study to examine whether the original AHP’s results are generally more acceptable than MAHP’s. This leads to a review of principles relating to different scales based on comparative judgments, and finally, a revised scale parameter for MAHP is proposed. The participants in the empirical study are presented with the results of this alternative MAHP (A-MAHP). The results reveal that the A-MAHP — overcoming some theoretical issues discussed in this paper — should be considered for practical use. Thus, an innovative finding is that A-MAHP may serve as a proxy for AHP and accommodate users accustomed to this well-known method. Finally, perspectives are set out for future work.},
  archive      = {J_IJITDM},
  author       = {Steen Leleur and Michael Bruhn Barfod and George Panagakos},
  doi          = {10.1142/S021962202550018X},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {6},
  pages        = {1717-1740},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Multi-attribute decision-making: Scaling issues in pairwise comparison approaches based on the analytic hierarchy process},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predictive analytics on time series data to generate a deterministic decision model: A case study on school reopening safely during the pandemic. <em>IJITDM</em>, <em>24</em>(6), 1685-1715. (<a href='https://doi.org/10.1142/S0219622025500191'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research focuses on developing a new decision-making model to evaluate school reopening strategies during the COVID-19 pandemic. The model integrates deep learning and factor analysis to address the urgent need to restart educational services without worsening the health crisis. It starts by gathering time series data from various districts to apply deep learning for predicting virus dynamics, emphasizing feature extraction and hyperparameter optimization. The subsequent phase involves factor analysis to discover key factors influencing virus spread, using outputs from the deep learning step. Based on these factors, clustering methods then sort districts into controllable or vulnerable groups. The final stage combines these analyzes into a deterministic decision model aiding policymakers in crafting school reopening guidelines. The model identifies three primary controllable factors: infection growth rate, reduction in active cases, and lowered mortality rates. Clustering then reveals that three groups are controllable, enabling specific interventions. This model is noteworthy for considering causal links between pandemic metrics and its adaptability to diverse datasets across districts/subdistricts, offering a scalable solution for decision-makers. The results highlight the importance of local infection trends and tailored data in shaping policies, showing that strong predictive analytics and insight into significant factors are crucial for developing effective, safe school reopening plans.},
  archive      = {J_IJITDM},
  author       = {Feby Artwodini Muqtadiroh and Diana Purwitasari and Muhammad Reza Pahlawan and Riris Diana Rachmayanti and Tsuyoshi Usagawa and Eko Mulyanto Yuniarno and Supeno M. S. Nugroho and Mauridhi Hery Purnomo},
  doi          = {10.1142/S0219622025500191},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {6},
  pages        = {1685-1715},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Predictive analytics on time series data to generate a deterministic decision model: A case study on school reopening safely during the pandemic},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel parallel mechanism-based dynamic wearable assistive device for neck rehabilitation. <em>IJITDM</em>, <em>24</em>(6), 1653-1684. (<a href='https://doi.org/10.1142/S0219622025500166'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper details a dynamic Wearable Assistive Device (WAD) for individuals suffering from chronic neck pain. Individuals should wear conventional cervical collars, which limit head mobility to a single configuration. A dynamic WAD is designed based on the human anatomical head/neck data and a dimensional synthesis study has been conducted using a loop-closure approach, based on the input parameters like dimensions of the top and base platforms and neck height have been taken into consideration for synthesis. Based on the dimensional synthesis, for the given geometrical parameters the proposed device achieved a maximum angular tilt of 1 9 ∘ for flexion, extension of 1 9 ∘ and lateral bending (right and left) of 3 8 ∘ . However, a major concern in WADs is related to evaluating the performance of the device by assessing the strain on the surface muscles. To address this problem, strain gauges are considered for strain measurement on the surface muscles because they are simple, readily available and low cost when compared to electromyography. Nevertheless, based on the existing survey surface neck muscle strain measurement using a strain gauge has yet to be studied for the controlled head/neck motions. Hence, a NI-9236 C Series Strain Quarter Bridge Input Module DAQ (Data Acquisition system) is used to examine the strain generated on neck surface muscles. Experimental studies were conducted for the test subjects with and without WAD. The various neck surface muscle strain values for head/neck motions were plotted using NI DAQ Express and the results are discussed in detail and simulation studies conducted for various human head/neck dimensions using MATLAB. The obtained strain results for the test subjects were found to be satisfactory as the strain produced on the neck surface muscles using WAD was reduced by approximately 25% than the strain generated without WAD. The findings suggest that by using the proposed WAD, controlled head/neck motions can be achieved and might be used for neck rehabilitation purposes.},
  archive      = {J_IJITDM},
  author       = {B. Jaishankar and Brajesh Kumar Singh and P. Ravi Kumar and Arockya Selvakumar Arockya Doss},
  doi          = {10.1142/S0219622025500166},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {6},
  pages        = {1653-1684},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A novel parallel mechanism-based dynamic wearable assistive device for neck rehabilitation},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the effects of setting performance and learning goals in a transparent simulation of a dynamically complex task. <em>IJITDM</em>, <em>24</em>(6), 1631-1652. (<a href='https://doi.org/10.1142/S021962202550021X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulation-based learning environments are increasingly viewed as promising tools to foster learning in complex domains. However, research has indicated that subjects may nevertheless have persistent cognitive difficulties in comprehending and managing dynamic systems. Previous studies have revealed positive learning effects of using transparent simulations (that is, revealing to users the structure and behavior of the simulator model). This study explores the effects of combining exploratory guidance, learning goals, and performance goals in a transparent simulation of a dynamically complex system. In a simulation experiment, participants interacted with a system dynamics model representing the growth of a business venture. Participants who had previously worked higher learning goals under exploratory guidance and were then given higher performance goals achieved higher performance and demonstrated better comprehension of the model dynamics. However, participants who were only subjected to more specific, high performance goals did not improve their outcomes and revealed larger differences within the treatment group.},
  archive      = {J_IJITDM},
  author       = {Carlos Capelo and Renato Pereira},
  doi          = {10.1142/S021962202550021X},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {6},
  pages        = {1631-1652},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Exploring the effects of setting performance and learning goals in a transparent simulation of a dynamically complex task},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Smart tournament scheduling using a POX-heuristic genetic algorithm. <em>IJITDM</em>, <em>24</em>(6), 1613-1629. (<a href='https://doi.org/10.1142/S0219622025500221'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces an optimization algorithm that utilizes the precedence preserving order-based crossover (POX), heuristic techniques, and genetic algorithms (GAs) to address the task of arranging tournament scheduling for events of varying sizes. The study begins by conducting an extensive literature review on the subject of solving tournament scheduling problems. The GA approach is enhanced through the incorporation of POX for crossover operations and the inclusion of a heuristic algorithm for mutation. Subsequently, the POX-heuristic GA is developed and its performance is evaluated using data from 10 distinct tournaments. A comparison between the outcomes obtained from the proposed method and the results generated by the LeagueLobster software demonstrates that the proposed approach achieves a higher level of efficiency, with improvements ranging from 10.87% to 335.03% over the original actual schedule. The contributions stem from the successful integration of POX, heuristic techniques, and GAs to address the issue of poorly performing genes within chromosomes, ultimately leading to more effective optimization of the chromosomes.},
  archive      = {J_IJITDM},
  author       = {Mu-Chun Su and Jieh-Haur Chen and Achmad Muhyidin Arifai and Che-Hsuan Chang and Hsi-Hsien Wei},
  doi          = {10.1142/S0219622025500221},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {6},
  pages        = {1613-1629},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Smart tournament scheduling using a POX-heuristic genetic algorithm},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editor’s introduction. <em>IJITDM</em>, <em>24</em>(6), 1607-1612. (<a href='https://doi.org/10.1142/S0219622025030063'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJITDM},
  author       = {Yong Shi},
  doi          = {10.1142/S0219622025030063},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {6},
  pages        = {1607-1612},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Editor’s introduction},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel approach to scenario assessment and selection. <em>IJITDM</em>, <em>24</em>(5), 1567-1605. (<a href='https://doi.org/10.1142/S0219622025500154'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scenario planning is an effective and common tool that provides organizations with future insights and supports their strategic planning process by identifying alternative scenarios. Developing scenarios involves combining various future events, which require assessing and selecting a manageable number of distinct scenarios based on different criteria. Studies in the literature typically carry out this process relying on only a few criteria. Moreover, none of them considers multiple criteria simultaneously and they completely disregard the interaction among criteria. To address these issues, a novel approach that assesses scenarios through the simultaneous consideration of multiple criteria and their interactions is proposed. For the aggregation of the assessments, Choquet integral is used. Also, a new binary integer programming model that simultaneously accounts for multiple constraints is developed to select a manageable number of scenarios covering a wide range of distinct futures. The model allows complete flexibility in choosing the weights in the objective function. The approach is demonstrated for a manufacturing company to support its strategies for warehouse operations. A comparative analysis and the findings of the application indicate that the proposed approach effectively reduces possible loss of information and improves the comprehensiveness and accuracy of the scenario assessment and selection process.},
  archive      = {J_IJITDM},
  author       = {Ozgur Yanmaz and Umut Asan},
  doi          = {10.1142/S0219622025500154},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {5},
  pages        = {1567-1605},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A novel approach to scenario assessment and selection},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Manipulation of individual judgments in the quantitative pairwise comparisons method. <em>IJITDM</em>, <em>24</em>(5), 1539-1566. (<a href='https://doi.org/10.1142/S0219622025500142'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-making methods very often use the technique of comparing alternatives in pairs. In this approach, experts are asked to compare different options, and then a quantitative ranking is created from the results obtained. It is commonly believed that experts (decision-makers) are honest in their judgments. In our work, we consider a scenario in which experts are vulnerable to bribery. For this purpose, we define a framework that allows us to determine the intended manipulation and present three algorithms for achieving the intended goal. Analyzing these algorithms may provide clues to help defend against such attacks.},
  archive      = {J_IJITDM},
  author       = {Michał Strada and Konrad Kułakowski},
  doi          = {10.1142/S0219622025500142},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {5},
  pages        = {1539-1566},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Manipulation of individual judgments in the quantitative pairwise comparisons method},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The automated arbitrage strategy of cross-cryptocurrency exchanges. <em>IJITDM</em>, <em>24</em>(5), 1521-1537. (<a href='https://doi.org/10.1142/S0219622025500130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of decentralized finance (DeFi) allows arbitrageurs to obtain risk-free income from price gaps of cryptocurrency tokens in many global markets. Several automated arbitrage techniques have been invented to profit from single or multiple platforms, including Centralized and Decentralized Exchange (CEX and DEX), triangular, and DEX-Fait. This paper proposes the arbitrage strategy of cross-cryptocurrency exchanges (ASCEX), a novel automated arbitrage strategy for CEX-DEX platforms, to maximize profit and loss (PNL) using a token route searching algorithm. Based on feature comparison, ASCEX outperforms the existing trading strategies available. Our actual trade experiment shows that ASCEX can generate up to 0.95% monthly risk-free profit compared to 0.34% trading on DEX alone.},
  archive      = {J_IJITDM},
  author       = {Warodom Werapun and Naratorn Boonpeam and Esther Sangiamkul and Jakapan Suaboot},
  doi          = {10.1142/S0219622025500130},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {5},
  pages        = {1521-1537},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {The automated arbitrage strategy of cross-cryptocurrency exchanges},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Abstractive text summarization for legal documents using optimization-based bi-LSTM with Encoder–Decoder model. <em>IJITDM</em>, <em>24</em>(5), 1493-1519. (<a href='https://doi.org/10.1142/S0219622025500129'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the amount of textual data has grown quickly, creating a useful resource for information extraction and analysis. Due to the high complexity and unstructured nature of legal documents, automated text summarizing (ATS) is a necessary but difficult process. ATS is a technique that uses computer power to summarize lengthy paragraphs quickly. Summarizing the extensive materials manually is a highly difficult and time-consuming operation for people. As a result, an optimization-based deep learning (DL) model for abstract summarization is presented in the paper (AS). The proposed working procedure is broken down into three stages. They are text pre-processing, feature extraction, and abstractive summary categorization. The dataset is first placed through a pre-processing process, including stop word removal, tokenization, lemmatization, and stemming. The words and phrases are then represented in vector format throughout the feature extraction phase, which is handled by the NumberBatch (a combination of Enhanced GloVe Model (EGM), Enhanced FastText (EFT), and word2vector). To produce the abstractive text summary, the features obtained from the Numberbatch are fed into the DL model Bi-LSTM-based encoder–decoder with attention model. The metaheuristic optimization Honey Badger algorithm (HBA) is employed to optimize the network weights. This would increase the effectiveness of creating summaries based on ROUGE scores, and the proposed Bi-LSTM-HBA model performs better than currently used methods.},
  archive      = {J_IJITDM},
  author       = {Deepti Aggarwal and Arun Sharma},
  doi          = {10.1142/S0219622025500129},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {5},
  pages        = {1493-1519},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Abstractive text summarization for legal documents using optimization-based bi-LSTM with Encoder–Decoder model},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boundary and target value-based normalization procedures for MCDM methods: An application on workers’ physical workload evaluation by using CRITIC-PSI-CoCoSo. <em>IJITDM</em>, <em>24</em>(5), 1459-1491. (<a href='https://doi.org/10.1142/S0219622025500117'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is important to perform to find the most appropriate normalization procedure in MCDM methods. Normalization procedures proposed in the literature have tended to focus on cost and benefit type criteria. Some of the criteria discussed in MCDM problems may be required not to exceed a certain lower bound or upper bound, while others may be required to meet a certain target value. However, some criteria require target and boundary values-based normalizations, and these types of procedures receive much less attention despite their importance in many decision-making problems such as workers’ physical workload evaluation. Criteria affecting physical workload require target and boundary values-based normalizations because these normalization procedures best match the properties of human physiological capacities. In this context, this study proposes new normalization procedures based on target and boundary values. These new normalizations are applied in Criteria Importance through Inter-criteria Correlation (CRITIC), Preference Selection Index (PSI) to obtain criteria weights and Combined Compromise Solution (CoCoSo) method to prioritize workers for their physical workload levels. Additionally, a sensitivity analysis was performed to interpret the ranking differences for CRITIC-CoCoSo and PSI-CoCoSo integrations based on proposed normalization procedures.},
  archive      = {J_IJITDM},
  author       = {Pelin Toktaş and Gülin Feryal Can and Elif Kılıç Delice},
  doi          = {10.1142/S0219622025500117},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {5},
  pages        = {1459-1491},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Boundary and target value-based normalization procedures for MCDM methods: An application on workers’ physical workload evaluation by using CRITIC-PSI-CoCoSo},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Developing a grey wolf optimization-based gray box model for cash flow forecasting: A study on tehran stock exchange companies. <em>IJITDM</em>, <em>24</em>(5), 1435-1458. (<a href='https://doi.org/10.1142/S0219622025500087'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cash flow forecasting is a critical aspect of financial planning and has long been of interest to investors and creditors. The Gray Box (GB) method is a widely used tool for forecasting, but a significant challenge in developing a grey box model is parameter estimation. In this study, we introduce a novel approach to cash flow forecasting called the Grey Wolf Optimization-based Grey Box model (GWOGB). The GWOGB employs a GWO algorithm as a global search method to determine the parameters of the GB model. To enhance the accuracy of future cash flow forecasting, we incorporate firm-level control variables as well as market and financial control variables into the classical model. To evaluate the performance of the proposed model, we use a sample of 250 firms listed on the Tehran Stock Exchange. Our empirical findings indicate that the GWOGB outperforms the generalized method of moments (GMM). Additionally, we employ sensitivity analysis to discern the source of forecast error and find that the inclusion of the nonlinear effect of sales growth rate on working capital accruals and future cash flow significantly reduces forecast error. The results show that using a nonlinear form of the GWOGB model is a promising approach for modeling the complex relationships between cash flow and working capital accruals.},
  archive      = {J_IJITDM},
  author       = {Ahmad Ahmadi and Farzaneh Nassirzadeh and Esmaeil Hadavandi and Mohammad Chavosh Nejad and Arash Ghorbani},
  doi          = {10.1142/S0219622025500087},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {5},
  pages        = {1435-1458},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Developing a grey wolf optimization-based gray box model for cash flow forecasting: A study on tehran stock exchange companies},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent fusion of heuristically optimized 1DCNN with weighted optimized DNN for thyroid disorder prediction framework. <em>IJITDM</em>, <em>24</em>(5), 1397-1433. (<a href='https://doi.org/10.1142/S0219622025500105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The early stage of thyroid disease prediction is useful to decrease the mortality and morbidity rate and also to increase the diagnosis efficiency of the patient-specific treatments. Existing thyroid prediction approaches suffer from several limitations because of unreliable human false-positive predictive outcomes. The deep learning-based diagnosis methodology provides higher prediction accuracy and earlier detection of thyroid disorders from the collected data set. However, the researchers face several challenges in the prediction of thyroid nodules from large dimensional datasets with higher prediction accuracy. Hence, this research aims to implement an efficient and Hybrid Deep Learning (HDL) for thyroid prediction to provide better treatment for thyroid disorder. Initially, the experimental data are obtained from standard datasets. The collected data are normalized using the data normalization technique. The normalized data are further utilized in the optimal feature selection, which is carried out using the Hybrid Artificial Gorilla Troops Sandpiper Optimization (HAGTSO) to get the optimally required features for thyroid prediction. The thyroid disorder can be identified using the HDL with One-Dimensional Convolutional Neural Network Model (1DCNN) and Deep Neural Network (DNN), where parameters in 1DCNN and weight in DNN get optimized using the developed HAGTSO. The experimental results demonstrate that higher performance is provided by the newly developed thyroid predictive model when compared to other comparative algorithms while considering the negative and positive metrics. The numerical analysis of the offered model shows 97% and 96% in terms of accuracy and specificity measures. Here, the designed model proved that it shows better performance than the existing methods.},
  archive      = {J_IJITDM},
  author       = {K. Hema Priya and K. Valarmathi},
  doi          = {10.1142/S0219622025500105},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {5},
  pages        = {1397-1433},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Intelligent fusion of heuristically optimized 1DCNN with weighted optimized DNN for thyroid disorder prediction framework},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discriminant decision making of cardiovascular diseases based on cloud-based convolutional attention network. <em>IJITDM</em>, <em>24</em>(5), 1361-1396. (<a href='https://doi.org/10.1142/S0219622024500032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular diseases (CVDs) have become the number one killer affecting human health. In order to reduce the burden of medical workers, facilitate government screening of the population and enable patients to conduct their own health status checks, there is an urgent need for a complementary diagnostic system to predict the occurrence of CVD. In this study, a new cloud-based convolutional attention network (C-CAN) model is proposed for the discriminant decision making of CVD. In this model, the indicator data for discriminant decision making of CVD are trained using an improved one-dimensional convolutional neural network (1D CNN) model structure based on the correlation of factors influencing CVD given by decision-making trial and evaluation laboratory (DEMATEL) and cloud models. This 1D CNN model consists of a convolutional pooling module, an attention module and a fully connected module. The cloud model is used to process the original data based on the discriminating opinion of experts, so as to select the important factors that affect CVD. The attention mechanism is effective in augmenting attention to the essential elements of the data and reducing attention to the less important features. Both have similarities in that they are effective in augmenting the important features in the data and combine with each other to achieve better results. Moreover, the C-CAN is compared with decision tree (DT), K -nearest neighbors (KNN), random forests (RF) and normal CNN according to the CVD dataset from the Kaggle platform. The results show that the classification accuracy, precision, recall and F1 value of C-CAN are all higher than that of all compared models. Further, the proposed model is further externally validated using other imbalanced datasets, and the results indicate that C-CAN has good resilience for imbalanced data. Our findings suggest that C-CAN represents a promising new approach that may somehow address the challenges associated with deep learning (DL) in the medical field.},
  archive      = {J_IJITDM},
  author       = {Wei Liu and Congjun Rao},
  doi          = {10.1142/S0219622024500032},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {5},
  pages        = {1361-1396},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Discriminant decision making of cardiovascular diseases based on cloud-based convolutional attention network},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reliability evaluation of binary group decision-making mechanism. <em>IJITDM</em>, <em>24</em>(5), 1329-1360. (<a href='https://doi.org/10.1142/S021962202450007X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-making is an important management activity. This study evaluates the reliability of group decision-making (GDM) and multi-attribute GDM (MAGDM) mechanisms for a class of 0–1 binary decision-making problem. We define the reliability of GDM and MAGDM, use the weighted voting system to model the GDM and MAGDM mechanisms, and propose two algorithms to evaluate the reliability of GDM and MAGDM considering the participation of general or professional decision makers. Additionally, the influence of some system parameters, such as the number of decision makers or attributes, cognitive accuracy of decision makers, and threshold of weighted majority voting rule, on the reliability of GDM and MAGDM was analyzed using random simulation experiments. The results of the random experiment show that: increasing the number of decision makers or attributes could improve the decision accuracy; the reduction in the individual subjective accuracy reduces the overall decision accuracy, which was difficult to compensate for by increasing the number of DMs; guiding DMs to reach consensus through group discussion decreased the decision accuracy of GDM and MAGDM.},
  archive      = {J_IJITDM},
  author       = {Qiang Liu and Xinyu Peng and Qingmiao Liu and Qiao Li},
  doi          = {10.1142/S021962202450007X},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {5},
  pages        = {1329-1360},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Reliability evaluation of binary group decision-making mechanism},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating the critical success factors of marketing automation through cross-case analysis and DEMATEL. <em>IJITDM</em>, <em>24</em>(5), 1283-1327. (<a href='https://doi.org/10.1142/S0219622024500081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the critical success factors (CSFs) of marketing automation (MA) for business-to-business (B2B) IT companies. The research employs a distinctive approach combining qualitative and quantitative methods to study the cause–effect phenomena and ascertain the rank of the CSFs to address the lack of comprehensive research in the existing literature. Utilizing the technology acceptance model (TAM) and DeLone & McLean’s information system success model (D&M ISSM) as a theoretical framework, the study underscores the underexplored domain of MA in the B2B IT sector. Expert interviews and the decision-making trial and evaluation laboratory method (DEMATEL) are employed to understand and rank CSFs comprehensively. Methodological triangulation is applied to the findings of expert interviews and DEMATEL analysis to confirm the CSFs of MA. The study finds that “system integration,” “flexibility and adaptation,” “personalized information,” and “general satisfaction” are the highest-ranked CSFs for adopting MA among B2B IT firms. This study provides valuable insights for managers in B2B IT companies on the CSFs driving MA adoption and effectiveness, enabling them to make informed decisions and optimize their MA strategies.},
  archive      = {J_IJITDM},
  author       = {Akshay Mathur and Saumya Singh},
  doi          = {10.1142/S0219622024500081},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {5},
  pages        = {1283-1327},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Evaluating the critical success factors of marketing automation through cross-case analysis and DEMATEL},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editor’s introduction. <em>IJITDM</em>, <em>24</em>(5), 1277-1281. (<a href='https://doi.org/10.1142/S0219622025030051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJITDM},
  author       = {Yong Shi},
  doi          = {10.1142/S0219622025030051},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {5},
  pages        = {1277-1281},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Editor’s introduction},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-criteria strategic evaluation model to determine the suitability of newly rising engineering departments in turkish universities based on the data from the year 2009 to 2020 using the econophysics perspective. <em>IJITDM</em>, <em>24</em>(4), 1247-1276. (<a href='https://doi.org/10.1142/S0219622024500044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent decade, engineering and technology have been developed rapidly, and new requirements are rising for engineering education. So, new and more focused departments are rising in the engineering faculty. The Turkish economy has been developed, and it is necessary to develop new technologies in industry based on the new investments. The scientific models are required to decide which engineering departments are necessary based on the socio-economic development of the economy. For this aim, we present a strategic analysis of which department can be established to meet the requirements in Turkey in light of the latest developments in the world. In the analysis stage, we listed engineering departments in the world universities and compared them with Turkish universities. We determined the selection criteria for the alternative departments, following these analyses and their related data collected from the Turkish Statistical Institute’s website. We used the new impulse and momentum principle-based weight assignment procedure integrated Technique for Order Preferences by Similarity to the Ideal Solution (IMP-TOPSIS) method to rank alternative departments using different scenarios. We concluded that Artificial Intelligence Engineering is the most suitable alternative. In addition, Aerospace Engineering has the second importance, and Materials Science and Nanotechnology Engineering have the third importance, according to the obtained results.},
  archive      = {J_IJITDM},
  author       = {Yusuf Tansel İç},
  doi          = {10.1142/S0219622024500044},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {4},
  pages        = {1247-1276},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A multi-criteria strategic evaluation model to determine the suitability of newly rising engineering departments in turkish universities based on the data from the year 2009 to 2020 using the econophysics perspective},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hedging salmon price risk based on fuzzy copula-GMM model. <em>IJITDM</em>, <em>24</em>(4), 1221-1246. (<a href='https://doi.org/10.1142/S0219622023500682'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Copula method can explain the dependent function or connection function which connects the joint distribution and the univariate marginal distribution. Therefore, copula has recently become a most significant important tool in the financial field of risk management, portfolio allocation, and derivative asset pricing. However, it leads to a possibilistic uncertainty in estimating the parameters of copulas because of insufficient historical data, imprecise parameter estimation, and uncertain knowledge of future prices. This paper proposes a fuzzy copula model via Kullback–Leibler (KL) divergence to model the fuzzy relations, and further to investigate the hedging issues of salmon futures. We use a new framework of hedging under fuzzy circumstances, consisting of innovative marginal distributions and fuzzy intervals. By synergizing fuzzy copula and simulations, we use the fuzzy copula-GMM to obtain the hedge ratios of salmon futures. The empirical results show that, compared with traditional probabilistic methods, the fuzzy copula-GMM hedges the salmon spot risk measured by variance more successfully.},
  archive      = {J_IJITDM},
  author       = {Xing Yu and Chenya Liu and Weiguo Zhang},
  doi          = {10.1142/S0219622023500682},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {4},
  pages        = {1221-1246},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Hedging salmon price risk based on fuzzy copula-GMM model},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling photovoltaic facilities via fuzzy sets and linguistic petri nets. <em>IJITDM</em>, <em>24</em>(4), 1191-1219. (<a href='https://doi.org/10.1142/S0219622024500068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a formal procedure based on linguistic Petri nets and fuzzy sets in order to model photovoltaic facilities and provide different alerts with respect to a correct performance. Furthermore, this procedure has been illustrated in a real case. Specifically, it is tested on six solar photovoltaic facilities (stations) owned by the company Grupo Energético de Puerto Real (GEN). The energy generated by each station has been compared through Dynamic Time Warping (DTW) and analyzed by a designed Petri net, which considers fuzzy sets and Natural Language for a better interpretation and understanding for the (nonexpert) user. The results show that the proposed procedure offers excellent results, bigger profits for the company and that it can be scalable and exportable to other facilities.},
  archive      = {J_IJITDM},
  author       = {Jesús Medina and Juan Moreno-García},
  doi          = {10.1142/S0219622024500068},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {4},
  pages        = {1191-1219},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Modeling photovoltaic facilities via fuzzy sets and linguistic petri nets},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A personalized individual semantic extraction model based on criterion for adaptive consensus reaching process under improved basic uncertain linguistic environment. <em>IJITDM</em>, <em>24</em>(4), 1155-1190. (<a href='https://doi.org/10.1142/S0219622023500591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized individual semantics (PIS) is an important factor reflecting the personal habits of decision makers (DMs) and has been widely studied by scholars. Using criteria as a non-negligible information source in multi-criteria group decision making (MCGDM), how to extract PIS from it is a research gap to be solved. In addition, existing measurements of consensus are insufficiently sensitive to differences between individuals, while the current direction rules use a matrix as the unit of measurement, which is not detailed and precise enough. Therefore, this paper first constructs a PIS extraction model according to the principle that similar criteria have similar descriptions and mutually exclusive criteria have dissimilar descriptions. Secondly, the preference information of PIS is mingled with uncertainty and reliability of improved basic uncertain linguistic information (IBULI) as the data of the consensus reaching algorithm. The proposed consensus algorithm not only fully considers the dispersion of DMs in the consensus measurement stage, but also improves the objectivity of the consensus process through an adaptive feedback stage. Finally, the validity of the proposed model is verified by an example and comparative analysis of the selection of sustainable building materials.},
  archive      = {J_IJITDM},
  author       = {Mengmeng Zhu and Junjun Mao and Wei Xu},
  doi          = {10.1142/S0219622023500591},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {4},
  pages        = {1155-1190},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A personalized individual semantic extraction model based on criterion for adaptive consensus reaching process under improved basic uncertain linguistic environment},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance assessment of business process optimization algorithms using a prototype dataset generator. <em>IJITDM</em>, <em>24</em>(4), 1125-1154. (<a href='https://doi.org/10.1142/S0219622024500056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern approaches of business administration consider processes as the fundamental element for the structure of a company that pursues high competitiveness and profitability. Hence, the implementation of effective processes has become a major concern, in an attempt to develop methodologies for their continuous improvement with respect to predefined evaluation criteria. Considering that an optimization method needs to be evaluated systematically in terms of performance and accuracy, the aim of this paper is the development of a generator that can construct synthetic test problems of diverse size and difficulty, employing well-defined complexity parameters derived from the Graph Theory and where a business process design is represented as a two-terminal-directed acyclic graph. However, a plethora of different formulations regarding the process optimization problem that have been presented in the relevant literature motivated our research to consider the target model of the generator as an ideal case, which can be derived by the aforementioned formulations after reducing some of their constraints. The experimental evaluation demonstrates how different value settings of the complexity parameters affect the difficulty of the generated instances, proving the capability of the proposed generator to create test sets of varying complexity.},
  archive      = {J_IJITDM},
  author       = {Athanasios Dragoslis and Ilias Sakellariou and Kostas Vergidis},
  doi          = {10.1142/S0219622024500056},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {4},
  pages        = {1125-1154},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Performance assessment of business process optimization algorithms using a prototype dataset generator},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Basic statistical methods in determining criteria weights. <em>IJITDM</em>, <em>24</em>(4), 1103-1124. (<a href='https://doi.org/10.1142/S0219622024500093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of technology has facilitated data accessibility, leading to an expansion in the range of criteria employed in decision problem design. This situation offers an advantage for making precise and rational decisions, but when it comes to managing spending, it becomes a disadvantage. Specifically, the expense of acquiring expert views utilized in the computation of criteria weights by subjective approaches experiences a substantial rise. Hence, decision-makers may employ objective methodologies to determine criterion weights. Nevertheless, objective methods provide a more limited range of choices compared to subjective methods. The study aims to utilize two widely recognized fundamental statistical approaches in order to enhance the capabilities of objective methods. One of the suggested approaches is the dissimilarity-based weighting method, which calculates the differentiation of values within the criteria. Another approach is the weighting method, which relies on the interquartile range. The methods were adapted as means of weighting criteria. Explanatory examples were provided, simulation-based comparisons were conducted, and ultimately applied to an actual data set. The data from each scenario were compared using the factorial analysis of variance method. The findings produced demonstrate that the proposed methods align with other objective methodologies. Furthermore, the proposed approaches were observed to take more time to finish the procedure compared to the Entropy and Standard Deviation methods, but less time compared to the Critic and Merec methods. Consequently, the suggested techniques are introduced as alternative approaches derived from established fundamental statistical procedures, which are straightforward to comprehend and valuable for professionals.},
  archive      = {J_IJITDM},
  author       = {Üzeyir Fidan},
  doi          = {10.1142/S0219622024500093},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {4},
  pages        = {1103-1124},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Basic statistical methods in determining criteria weights},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mean-CVaR portfolio optimization models based on chance theory. <em>IJITDM</em>, <em>24</em>(4), 1067-1101. (<a href='https://doi.org/10.1142/S021962202350058X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The indeterminacy of financial markets leads investors to face different types of security returns. Usually, security returns are assumed to be random variables when sufficient transaction data are available. If data are missing, they can be regarded as uncertain variables. However, uncertainty and randomness coexist. In this situation, chance theory is the main tool to deal with this complex phenomenon. This paper investigates the conditional value at risk (CVaR) of uncertain random variables and its application to portfolio selection. First, we define the CVaR of uncertain random variables and discuss some of its mathematical properties. Then, we propose an uncertain random simulation to approximate the CVaR. Next, we define the inverse function of the CVaR of uncertain random variables, as well as a computational procedure. As an application in finance, we establish uncertain random mean-CVaR portfolio selection models. We also perform a numerical example to illustrate the applicability of the proposed models. Finally, we numerically compare the mean-CVaR models with the mean-variance models with respect to the optimal investment strategy.},
  archive      = {J_IJITDM},
  author       = {Souad Chennaf and Jaleleddine Ben Amor},
  doi          = {10.1142/S021962202350058X},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {4},
  pages        = {1067-1101},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Mean-CVaR portfolio optimization models based on chance theory},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An integrated interval type-2 fuzzy PROMETHEE-II decision model for the selection of medical waste treatment techniques. <em>IJITDM</em>, <em>24</em>(4), 1035-1065. (<a href='https://doi.org/10.1142/S0219622023500554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The selection of medical waste treatment techniques has become a serious health and safety issue since the amount and variety of medical waste are rapidly increasing during the Corona Virus Disease 2019 (COVID-19) pandemic in the whole world. This paper aims to propose an integrated interval type-2 fuzzy Preference Ranking Organization Method for Enrichment Evaluations-II (PROMETHEE-II) decision model for medical waste treatment techniques selection problem considering interactive relationships among criteria under a high uncertain environment. First, interval type-2 fuzzy sets (IT2FSs) are introduced to express imprecision information within the context of high uncertainty. Second, a type-2 Prioritized Aggregation (PA) operator is constructed to aggregate the evaluation information considering the priority of experts. Third, the Decision Making Trial and Evaluation Laboratory (DEMATEL) method is combined with the IT2FS to calculate the weights of criteria considering the interaction relationships among them. Then, an extended interval type-2 fuzzy PROMETHEE-II method is proposed to rank each alternative, in which a distance measure-based preference function is adopted. After that, a case study of medical waste treatment selection in Jiangsu province is used to illustrate the effectiveness of the proposed approach. The results demonstrate that incineration is the most appropriate approach in handling medical waste. Finally, sensitivity analysis and comparative analysis are implemented to further test the advantages of the proposed approach.},
  archive      = {J_IJITDM},
  author       = {Jing Tang and Xinwang Liu and Weizhong Wang},
  doi          = {10.1142/S0219622023500554},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {4},
  pages        = {1035-1065},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {An integrated interval type-2 fuzzy PROMETHEE-II decision model for the selection of medical waste treatment techniques},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Factors affecting the adoption of cloud for software development: A case from turkey. <em>IJITDM</em>, <em>24</em>(4), 997-1033. (<a href='https://doi.org/10.1142/S0219622023500517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud-based solutions for software development activities have been emerging in the last decade. This study aims to develop a hybrid technology adoption model for cloud use in software development activities. It is based on Technology Acceptance Model (TAM), Technology–Organization–Environment (TOE) framework, and the proposed extension Personal–Organization–Project (POP) structure. The methodology selected is a questionnaire-based survey and data are collected through personally administered questionnaire sessions with developers and managers, resulting in 268 responses regarding 84 software development projects from 30 organizations in Turkey, selected by considering company and project sizes and geographical proximity to allow face-to-face response collection. Structural Equation Modeling (SEM) is used for statistical evaluation and hypothesis testing. The final model was reached upon modifications and it was found to explain the intention to adopt and use the cloud for software development meaningfully. To the best of our knowledge, this is the first study to identify and understand factors that affect the intention of developing software on the cloud. The developed hybrid model was validated to be used in further technology adoption studies. Upon modifying the conceptual model and discovering new relations, a novel model is proposed to draw the relationships between the identified factors and the actual use, intention to use and perceived suitability. Practical and social implications are drawn from the results to help organizations and individuals make decisions on cloud adoption for software development.},
  archive      = {J_IJITDM},
  author       = {Erhan Pisirir and Oumout Chouseinoglou and Cüneyt Sevgi and Erkan Uçar},
  doi          = {10.1142/S0219622023500517},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {4},
  pages        = {997-1033},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Factors affecting the adoption of cloud for software development: A case from turkey},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An OWA analysis of the VSTOXX volatility index. <em>IJITDM</em>, <em>24</em>(4), 963-995. (<a href='https://doi.org/10.1142/S0219622025500099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we analyze the information value of the VSTOXX (volatility) index as a measure of risk for the European stock market. Based upon daily data from 2007 to 2023, the properties of the VSTOXX index are inspected and contrasted under various market conditions and in high- and low-volatility periods. Moreover, to evaluate the contribution of each country-specific index to the VSTOXX index, we employ the Ordered Weighted Averaging (OWA) operator as an analysis tool. We obtain a number of useful insights. Only for France and Germany the correlation between the country-specific volatility index and the VSTOXX index is high during the entire period. In addition, the VSTOXX index acts more like a maximum than as a minimum of volatility for the European stock markets and acts as an average only during periods of extreme volatility. Our findings offer important implications for both investors and policymakers.},
  archive      = {J_IJITDM},
  author       = {Luca Gambarelli and Silvia Muzzioli and Bernard De Baets},
  doi          = {10.1142/S0219622025500099},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {4},
  pages        = {963-995},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {An OWA analysis of the VSTOXX volatility index},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editor’s introduction. <em>IJITDM</em>, <em>24</em>(4), 957-961. (<a href='https://doi.org/10.1142/S021962202503004X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJITDM},
  author       = {Yong Shi},
  doi          = {10.1142/S021962202503004X},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {4},
  pages        = {957-961},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Editor’s introduction},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A PAE model based on synthetic control method and policy instruments for the carbon emission reduction effect of green finance pilot zones. <em>IJITDM</em>, <em>24</em>(3), 929-956. (<a href='https://doi.org/10.1142/S0219622025410056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Green finance directs social capital to support projects that benefit the environment and sustainable development. This paper constructs a policy analysis and evaluation (PAE) model based on a synthetic control method and policy instrument. Through the quantitative analysis of the actual effect of policy impacts and the analysis of policy instruments, the PAE model jointly analyses and evaluates the policy effects from both causes and consequences. This paper takes the first batch of green finance pilot zones in China as an example. The model results show that Guizhou has the best emission constraint effect. The carbon reduction effect in Jiangxi and Zhejiang is not significant. The growth of carbon emissions in Guangdong and Xinjiang accelerated. Furthermore, the PAE model analyses the mechanism of policy impacts. The difference in policy focus is the cause of the difference in carbon emission control effects. This result strengthens the reliability of the evaluation conclusions from the perspective of policy supply and provides valuable policy experience.},
  archive      = {J_IJITDM},
  author       = {Che Han and Aihua Li and Yuxue Chi and Bing Ma},
  doi          = {10.1142/S0219622025410056},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {3},
  pages        = {929-956},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A PAE model based on synthetic control method and policy instruments for the carbon emission reduction effect of green finance pilot zones},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving the opportunities to implement industry 4.0 through absorptive capacity: A multi mediator model evaluation in the manufacturing industry of mexico. <em>IJITDM</em>, <em>24</em>(3), 891-928. (<a href='https://doi.org/10.1142/S0219622025410044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge absorptive capacity (ACAP) has been recognized as a driving force for ICT-driven digital transformation; however, questions remain about how to maximize opportunities for implementing Industry 4.0 (I4.0) while considering the role of ACAP. Our primary objectives are to analyze how ACAP influences I4.0 opportunities (strategic, operational, and environmental/social) and to examine the mediating role of these opportunities in the connection between ACAP and I4.0 implementation. This empirical study, employing a predictive type, analyzed data from 200 manufacturing SMEs in Guanajuato, Mexico, using Partial Least Squares Structural Equation Modeling (PLS-SEM) via SmartPLS4, with a hierarchical component model Type I. The findings underscore that ACAP significantly enhances the potential for successful I4.0 implementation. Furthermore, the study highlights the critical importance of a strategic approach to leveraging I4.0 opportunities. Interestingly, the environmental and social opportunities showed limited influence on I4.0 adoption, with no evidence of their mediating role. This research contributes to illuminating the complex interplay between ACAP, I4.0 opportunities, and their collective contribution to the successful implementation of Industry 4.0 in Mexican SMEs. Finally, the study offers actionable insights for industrial practitioners and contributes to methodological advancements in PLS-SEM analysis.},
  archive      = {J_IJITDM},
  author       = {Héctor Cuevas-Vargas and Rudy Fernández-Escobedo},
  doi          = {10.1142/S0219622025410044},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {3},
  pages        = {891-928},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Improving the opportunities to implement industry 4.0 through absorptive capacity: A multi mediator model evaluation in the manufacturing industry of mexico},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective route optimization for long-distance cold chain transportation considering time window. <em>IJITDM</em>, <em>24</em>(3), 865-889. (<a href='https://doi.org/10.1142/S0219622025410032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the long-distance cold chain transportation from production to distribution, besides the high transportation cost, the product spoilage and carbon emission from refrigerant and fuel usage during transportation also merit attention. At the same time, the time window for transportation indirectly affects customer satisfaction, so this paper shows how to develop a suitable transportation route with multiple optimization objectives mentioned above. First, the optimization objectives of long-distance cold chain transport are specified as transport cost, product spoilage and carbon emission, and the time window of delivery is taken into account to establish a multi-objective optimization model. Second, an improved ant colony algorithm is employed to resolve the Pareto optimal solution of the model. Finally, the effectiveness of the model is confirmed by a calculation example and compared with other methods.},
  archive      = {J_IJITDM},
  author       = {Congmiao Fang and Xiaoyan Gu and Shuangshuang Cheng and Dengsheng Wu},
  doi          = {10.1142/S0219622025410032},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {3},
  pages        = {865-889},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Multi-objective route optimization for long-distance cold chain transportation considering time window},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting crude oil prices using a convolutional neural network with time-delay embedding. <em>IJITDM</em>, <em>24</em>(3), 843-863. (<a href='https://doi.org/10.1142/S0219622025410020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel hybrid forecasting model, TDE-CNN, to model the complex dynamics of crude oil price movements. The model integrates Time-Delay Embedding (TDE) Method with a Convolutional Neural Network (CNN) to leverage both spatial and temporal information. The TDE-CNN model uses the TDE method to transform raw crude oil data into higher-dimensional space to reveal underlying spatio-temporal patterns, while the CNN effectively models these patterns for improved predictive accuracy. The TDE-CNN model is applied to forecast major crude oil spot price movements, and its forecasting performance has been comprehensively and rigorously evaluated. Empirical results demonstrate that the TDE-CNN model achieves lower forecasting errors compared to benchmark models, as measured by Mean Squared Error (MSE). Additionally, the Diebold-Mariano test confirms that the improvement in forecasting accuracy is statistically significant.},
  archive      = {J_IJITDM},
  author       = {Kaijian He and Lean Yu and Jia Liu and Yingchao Zou},
  doi          = {10.1142/S0219622025410020},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {3},
  pages        = {843-863},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Forecasting crude oil prices using a convolutional neural network with time-delay embedding},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantile-based spillover network analysis of financial institutions in chinese mainland and hong kong. <em>IJITDM</em>, <em>24</em>(3), 817-842. (<a href='https://doi.org/10.1142/S0219622025410019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strong connection among financial institutions provides more possible channels for information spillovers under different market conditions. Therefore, this paper attempts to comprehensively capture the spillover effects among financial institutions in Chinese mainland and Hong Kong by constructing the spillover networks based on the Quantile Vector AutoRegression (QVAR) model. By taking the stock prices as the representatives of financial institutions, we find that the spillover effects under extremely positive and negative conditions are larger than those under normal conditions. The magnitudes of spillovers are dynamic and show a dramatically upward trend when the market encounters extreme shocks, such as the Sino-US trade friction and the COVID-19 pandemic. The directional spillovers of the financial sector and its subsectors from Chinese mainland to Hong Kong are greater than those from Hong Kong to Chinese mainland, and banking contributes more to the spillovers. In addition, most institutions in Chinese mainland are spillover transmitters, and whether the institutions are net receivers or not varies over shock sizes. These results are essential for risk management in financial institutions in the opening financial markets.},
  archive      = {J_IJITDM},
  author       = {Yinhong Yao and Zhensong Chen and Wei Chen and Xueyong Liu},
  doi          = {10.1142/S0219622025410019},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {3},
  pages        = {817-842},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Quantile-based spillover network analysis of financial institutions in chinese mainland and hong kong},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grain temperature prediction based on GRU deep fusion model. <em>IJITDM</em>, <em>24</em>(3), 797-815. (<a href='https://doi.org/10.1142/S0219622023410031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temperature is an essential quality index in storage. Prediction of temperature can help the grain storage industry to apply the appropriate operations such as ventilation or drying to improve the quality of grain and extend the suitable storage time. Traditional machine learning methods usually cannot accurately predict the temperature data of the grain considering the complexity of environmental factors and grain warehouse conditions. To make better use of the temporal data such as temperature/humidity information of grain itself and its environment, this paper proposes a gated recurrent unit (GRU)-based algorithm to predict the change of the data. The grain warehouse environmental data are collected by multi-functional sensors inside a grain depot, including temperature, humidity, wind speed, air pressure, etc. Some of these data features such as rain or snow days are sparse data features. Excessive sparse features can affect the training accuracy of the model. At the same time, due to sensor aging or extreme weather conditions, the data collected may not be accurate, and the data contain noise, which also has a significant impact on the training of the model. To improve the performance of the proposed GRU framework, multivariate linear regression is used for feature generation to optimize the volatility of weather data, strengthen and construct the characteristics of datasets, and wavelet filtering is used to denoise the corresponding features. This paper focuses on the data sparse and noise problem and applies the MLR and wavelet filtering to improve the GRU prediction framework for grain warehouse temporal data. According to our experiment, the temperature prediction results based on the GRU deep fusion model have better improvement in prediction accuracy and time than the existing neural network algorithms such as long–short-term memory (LSTM), GRU, and transformer.},
  archive      = {J_IJITDM},
  author       = {Bo Mao and Shancheng Tao and Bingchan Li},
  doi          = {10.1142/S0219622023410031},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {3},
  pages        = {797-815},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Grain temperature prediction based on GRU deep fusion model},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ecological, social and governance impact on the company’s performance: Information technology sector insight. <em>IJITDM</em>, <em>24</em>(3), 765-795. (<a href='https://doi.org/10.1142/S0219622023410043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sustainable topics have become increasingly important in recent years, as the world faces growing environmental and social challenges. Environmental, social, and governance (ESG) ratings are tools used to assess the sustainability practices of companies. This study focuses on the impact of environmental, social and governance components on the financial performance of IT companies. The panel data were collected for 43 IT companies operating in the time period from 2004 to 2020. Data include ESG ratings, their components and financial performance indicators of IT companies. The method of OLS regression, a model with fixed individual effects or a model with random individual effects, was used. It was found that the increase in the environmental and social scores has a significant impact on the financial performance of IT companies. This paper is an extended version of our work published in the ITQM 2022.},
  archive      = {J_IJITDM},
  author       = {Alexander M. Karminsky and Alexandra A. Egorova and Daria A. Chigireva},
  doi          = {10.1142/S0219622023410043},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {3},
  pages        = {765-795},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Ecological, social and governance impact on the company’s performance: Information technology sector insight},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discovering high-risk bank risk factors based on risk matrix. <em>IJITDM</em>, <em>24</em>(3), 743-764. (<a href='https://doi.org/10.1142/S021962202341002X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bank risk management is a crucial issue in the stability of the financial system. How to select high-risk factors that make banks in trouble and how these factors affect bank risks have always been a core problem. Previous studies comprehensively identified bank risk factors from textual risk disclosures and used the disclosure frequency of risk factors to determine important factors to which banks should pay more attention. This paper creatively constructs the textual risk matrix with frequency and sentiment of risk factors to divide bank risk factors into the high-risk category, mid-risk category, and low-risk category. Then we explore the impact of different categories of risk factors on bank risk and the risk perception of investors. Based on 457,383 sentences of 2,735 Form 10-K reports of 240 American commercial banks from 2006 to 2020, 33 bank risk factors were identified. Three risk factors belong to in high-risk category, including loan loss risk, regulation risk, and interest rate risk. Three factors are classified in the mid-risk category and 27 risk factors are low-risk factors. The regression results show that compared with individual bankruptcy risk, risk factors have better prediction and interpretive ability on the systemic risk. The disclosure of bank risk factors will affect the investors’ risk perception, especially the worse risk situation of the high-risk factors will increase the risk perceived by investors.},
  archive      = {J_IJITDM},
  author       = {Lu Wei and Xiyuan Miao and Haozhe Jing and Guowen Li},
  doi          = {10.1142/S021962202341002X},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {3},
  pages        = {743-764},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Discovering high-risk bank risk factors based on risk matrix},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Operational risk measurement: An optimal timescale selection method based on information entropy. <em>IJITDM</em>, <em>24</em>(3), 713-741. (<a href='https://doi.org/10.1142/S0219622023410055'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operational risk capital is typically allocated on an annual timescale in extant research, while ignoring that the dependence between operational risk events may differ on different timescales, such as semi-annual and quarterly. This study examines whether operational risk dependence structures differ on multiple timescales and proposes an optimal timescale selection method based on information entropy theory to obtain more reasonable operational risk measurement results. Different dependence modeling methods, including linear correlation and copula functions, are employed to analyze the dependence structures on multiple timescales. The information changes between different timescales are calculated to select the optimal timescale. The empirical analysis is based on 2,024 operational risk events from 1994 to 2017 in the Chinese Operational Loss Database (COLD), which is one of the largest external operational risk datasets for the Chinese banking industry. The results reveal significant differences in operational risk dependence at different timescales which affect the operational risk measurement results. Crucially, the quarterly timescale should be considered for more reasonable measurements. The findings provide important insights for considering a more reasonable allocation of operational risk capital under multiple timescale dependence.},
  archive      = {J_IJITDM},
  author       = {Yanpeng Chang and Yinghui Wang and Jianping Li and Xiaoqian Zhu},
  doi          = {10.1142/S0219622023410055},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {3},
  pages        = {713-741},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Operational risk measurement: An optimal timescale selection method based on information entropy},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editor’s introduction. <em>IJITDM</em>, <em>24</em>(3), 707-711. (<a href='https://doi.org/10.1142/S0219622025030038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJITDM},
  author       = {Yong Shi},
  doi          = {10.1142/S0219622025030038},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {3},
  pages        = {707-711},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Editor’s introduction},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A health evaluation method of complex systems based on evidential reasoning rule considering perturbations. <em>IJITDM</em>, <em>24</em>(2), 679-706. (<a href='https://doi.org/10.1142/S0219622022500419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex system has been widely applied in aerospace, chemical industry, manufacturing, military equipment and other fields. To ensure its safe and reliable operation, it is necessary for technicians to grasp the health state of the system effectively. However, if there are perturbations in the observation data, the evaluation result may be inaccurate. Besides, the effectiveness of evaluation result can be affected by perturbation, which means that the threshold of perturbation intensity should be determined. To solve these problems, in this paper, a new health evaluation method of complex systems is proposed based on the evidential reasoning (ER) rule by considering perturbations. First, the structure of the evaluation model is constructed. Second, an ER rule-based health evaluation model is proposed, and the idea of perturbation analysis is introduced for the robustness analysis of the model. Third, a parameter optimization model is established, and the upper bound of perturbation intensity is estimated accurately. The threshold can measure the effectiveness of the evaluation result and the anti-perturbation ability of the system in engineering practice. Finally, a case study of the WD615 model diesel engine is conducted to validate the effectiveness of the proposed method.},
  archive      = {J_IJITDM},
  author       = {Shuaiwen Tang and Zhijie Zhou and You Cao and Pengyun Ning and Peng Zhang and Dao Zhao and Leiyu Chen},
  doi          = {10.1142/S0219622022500419},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {2},
  pages        = {679-706},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A health evaluation method of complex systems based on evidential reasoning rule considering perturbations},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessment of financial systemic crisis on a causal and reliable perspective. <em>IJITDM</em>, <em>24</em>(2), 651-677. (<a href='https://doi.org/10.1142/S0219622023500475'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In financial network models, to assess systemic risk, a general understanding and prediction of precisely how a single financial institution is associated with systemic risk from the network perspective remains lacking. This paper proposes a framework for predicting and assessing system crises through inferring the cause–effect relationships between financial institutions and system state, which is structured in three steps: the assessment stage for system state based on the mean-variance framework, the prediction stage based on a Bayesian network and the reliability stage based on the Markov process. By applying them to monthly returns of financial institutions, it implies the need to pay attention to insurance and Broker sectors while regulating the banking system on the Bayesian network theory. Moreover, we find that the measure contains predictive power both during tranquil periods and during financial crisis periods. The results can be applied to derive interventions in financial crisis management with regard to systemic risk prediction and system state reliability.},
  archive      = {J_IJITDM},
  author       = {Yafei Wang and Zhengming Zhou and Xiao Cao},
  doi          = {10.1142/S0219622023500475},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {2},
  pages        = {651-677},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Assessment of financial systemic crisis on a causal and reliable perspective},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAMOM: Multicriteria attribution model for online marketing. <em>IJITDM</em>, <em>24</em>(2), 627-649. (<a href='https://doi.org/10.1142/S021962202250081X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the problems facing online marketing in omni-channel environments is efficient budget allocation to each channel. The complexity of this problem is greater in omni-channel environments due to the greater number of channels and the need to analyze data sources containing user interaction information. To solve this problem, different attribution models have been proposed to assign the weight that each channel has in the acquisition of a product, also known as conversion. Each of these attribution models adopts a strategy to define the weighting of channels. The decision-making strategy is established using the company’s expert knowledge, which can contain different criteria depending on the department to which the expert belongs. The aim of this research is to present a new multicriteria attribution model for online marketing (MAMOM) based on Analytical Hierarchical Process, that resolves this type of problem. MAMOM is a meta-model that takes as input information related to channel features, user interactions and even decisions from other strategies. This information is integrated to enable the integration of interdepartmental strategies as well as to obtain a dynamic attribution model based on expert interviews. The expert assessment procedure is carried out subjectively and simply with a pairwise assessment of the criteria, finally MAMOM obtains a final formulation to calculate the investment to be made in each channel if the experts’ opinions are considered. Results show that first five channels selected by the MAMOM are nearly identical to those that would be obtained with the traditional models but with a different sequence caused by experts’ knowledge. This result shows the capacity of MAMOM to factor in expert opinion and experience for making the investment outcome more aligned with the tactical and strategic objectives of a given online marketing campaign.},
  archive      = {J_IJITDM},
  author       = {Miguel A. Patricio and Antonio Berlanga and David Palomero and José M. Molina},
  doi          = {10.1142/S021962202250081X},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {2},
  pages        = {627-649},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {MAMOM: Multicriteria attribution model for online marketing},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SPEEDSER: A possibilistic system for query disambiguation, expansion and translation. <em>IJITDM</em>, <em>24</em>(2), 583-625. (<a href='https://doi.org/10.1142/S0219622023500499'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We design, implement and assess in this paper a new architecture of a possibilistic mono- and cross-language information retrieval (IR/CLIR) system. The latter is useful to experiment query disambiguation, expansion and translation processes in both IR and CLIR frameworks. We take advantage of possibility theory to overcome the problems of query disambiguation and expansion in an uncertain and imprecise IR/CLIR context. We investigate the impact of combining possibilistic query disambiguation with expansion on IR/CLIR efficiency. A co-occurrence graph representation is exploited to quantify the similarity between query terms and their semantically close words (expansion task) or between query terms and their possible meanings (disambiguation task). We extend the possibilistic mono-language query disambiguation approach to a cross-language framework. We conduct a set of experiments using ROMANSEVAL data collection, the French–English parallel text corpus Europarl and the CLEF-2003 French–English IR/CLIR test collection. Results highlight some statistically significant improvements of our possibilistic approaches when compared to some state-of-the-art IR/CLIR works.},
  archive      = {J_IJITDM},
  author       = {Bilel Elayeb and Oussama Ben Khiroun},
  doi          = {10.1142/S0219622023500499},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {2},
  pages        = {583-625},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {SPEEDSER: A possibilistic system for query disambiguation, expansion and translation},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sustainable supplier evaluation in an automotive company using fuzzy multi-criteria decision-making methods. <em>IJITDM</em>, <em>24</em>(2), 535-581. (<a href='https://doi.org/10.1142/S0219622022500833'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sustainable supplier management literature is mainly on sustainable supplier selection but sustainable supplier performance monitoring & evaluation studies are scarce. Furthermore, the studies do not differentiate the sustainability evaluation criteria between the supplier selection and monitoring & evaluation stages. To bridge this gap, this study aimed to monitor & evaluate sustainability performance of the suppliers of a focal manufacturing company in automotive sector with the TBL approach. Toward that end, we questioned and tried to identify first the sustainable supplier selection and monitoring & evaluation differentiating criteria, and then, how we can rank and rate the sustainable suppliers for developmental purposes in the monitoring & evaluation phase. 21 criteria were determined for sustainable supplier performance in monitoring & evaluation by a detailed literature review and taking the opinions of the focal company. Then, decision makers assessed sustainability dimensions and determined criteria related to these dimensions. The weights of dimensions and criteria were calculated by Interval-Valued Intuitionistic Fuzzy AHP method. Then, sustainability performances of selected suppliers from the focal company’s portfolio were ranked by using Fuzzy EDAS, Fuzzy CODAS and Fuzzy MOORA methods. The results show that sustainable supplier monitoring & evaluation criteria involve a mix of external criteria (rules and regulations) and internal criteria (suppliers’ values). This finding helps us understand how we can have a more relaxed criteria set involving basic external criteria while selecting suppliers to have access to a more innovative and diverse supplier space and then have more challenging internal and external criteria to monitor & evaluate those suppliers toward true sustainability.},
  archive      = {J_IJITDM},
  author       = {Tuğçe Şişman and Sinem Büyüksaatçi Kiriş and Dilek Yilmaz},
  doi          = {10.1142/S0219622022500833},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {2},
  pages        = {535-581},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Sustainable supplier evaluation in an automotive company using fuzzy multi-criteria decision-making methods},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complex pythagorean fuzzy decision-based approach for developing english translation of the scripture-based multiclustering algorithms. <em>IJITDM</em>, <em>24</em>(2), 473-533. (<a href='https://doi.org/10.1142/S0219622025500075'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The English Translation of the Quran Tafsir (ETQT) is essential to understanding and interpreting Allah’s words. Clustering is a common text mining technique for eliciting meaningful knowledge from a text collection. It is commonly used when the selected datasets lack typical ground truths. To the best of our knowledge, no study has evaluated and benchmarked ETQTs to select the most comprehensive and appropriate one. The process of evaluating and benchmarking ETQTs falls under the multicriteria decision-making (MCDM) problem because of different issues, namely, multiple internal clustering validation criteria, data variation, and trade-offs between different criteria. The fuzzy decision by opinion score method (FDOSM) is one of the most recommended MCDM ranking methods in the literature to address the said issues. FDOSM has been extended under different fuzzy set (FS) environments to address issues of uncertainty and vagueness caused by expert feedback subjectivity. Although prior versions of FDOSM improved the uncertainty and vagueness issues, they remain open issues. Therefore, this paper extended FDOSM into the complex Pythagorean fuzzy decision by opinion score method (CPFDOSM) to evaluate and benchmark ETQTs. The proposed method consists of two main phases. The first phase formulates decision-matrix-based cluster algorithms and internal cluster validation criteria. The second phase (CPFDOSM development) prioritizes ETQTs and selects the optimum one. Data generation is performed on five different cluster algorithms and six internal cluster validation criteria using 16 ETQTs based on three decision-makers (DMs). Results show the following: (1) 6.25% of the individual decision-making results are identical among the three DMs, whereas 93.75% ( n = 1 5 / 1 6 ) are different when δ = 0 . 5 and δ = 2 . When δ = 0 . 5 . In addition, T7 has consistent ranks (Rank = 16) across all DMs, whereas T14 has consistent ranks (Rank = 1) across all DMs when δ = 1 . (2) The results of the group decision-making reveal T14 is the most comprehensive and appropriate ETQT across all δ values. Objective validation and comparison analysis show the proposed method is ranked systematically.},
  archive      = {J_IJITDM},
  author       = {Mohammed A. Ahmed and A. A. Zaidan and Sarah Qahtan and Hassan A. Alsattar and B. B. Zaidan and Nahia Mourad and Hanif Baharin and Gang Kou and Khaironi Yatim},
  doi          = {10.1142/S0219622025500075},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {2},
  pages        = {473-533},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Complex pythagorean fuzzy decision-based approach for developing english translation of the scripture-based multiclustering algorithms},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance dependence multi-criteria decision-making: A preference model based on an improved choquet integral. <em>IJITDM</em>, <em>24</em>(2), 443-472. (<a href='https://doi.org/10.1142/S021962202550004X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-criteria decision-making, the Choquet integral can handle the interaction between criteria; however, the interaction between criteria is not only related to the criteria themselves but may also depend on the performance values of criteria. We present a further extension of the Choquet integral considering this fact. A classic example is used to illustrate the limitations of the Choquet integral, and a performance-dependent assumption is proposed that describes the interactions influenced by the performance of alternatives on criteria. Based on this assumption, we propose an alternative capacity and construct an improved Choquet integral to obtain alternative’s global utility. A preference model based on the improved Choquet integral with a wider range of applicability and more realistic decision results is proposed. Finally, a numerical example is provided to illustrate the feasibility and validity of our reference model.},
  archive      = {J_IJITDM},
  author       = {Yu Gao and Mei Cai and Jingmei Xiao and Guang Yang},
  doi          = {10.1142/S021962202550004X},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {2},
  pages        = {443-472},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Performance dependence multi-criteria decision-making: A preference model based on an improved choquet integral},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring corporate reputation factors through cluster and sentiment analysis of CEO letters. <em>IJITDM</em>, <em>24</em>(2), 419-442. (<a href='https://doi.org/10.1142/S0219622025500051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Corporate reputation is one of the most valuable assets a company must maintain to remain in business, and it becomes even more critical during crises such as COVID-19, which pose a severe threat not only to employees, customers, and the general public but also to the company’s fundamental survival. The purpose of this study is to identify themes affecting corporate reputation and assess how leading companies responded to the COVID-19 crisis. This study targeted the top 100 (RQ score higher than 50) companies according to the 23rd Annual Reputation Quotient from Axios-Harries Poll 100 RQ report. Employing cluster and sentiment analysis, the study explores CEO letters to understand how they emphasize reputation factors and employ impression management tactics. Findings of our study illustrate nuanced reactions and attitudes of CEOs toward issues presented by COVID-19, shed light on the intricacies of reputation management during times of crisis.},
  archive      = {J_IJITDM},
  author       = {Jue Wang and Hak-Seon Kim},
  doi          = {10.1142/S0219622025500051},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {2},
  pages        = {419-442},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Exploring corporate reputation factors through cluster and sentiment analysis of CEO letters},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An ontology-aware model-driven approach for service-oriented application development: A stepwise refinement manner. <em>IJITDM</em>, <em>24</em>(2), 395-418. (<a href='https://doi.org/10.1142/S0219622024500123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ontologies are attracting increasing attention in software engineering research due to their ability to precisely model the semantic aspects of systems. Enriching software system models using ontology principles, especially in the process of developing interactive systems like Service-Oriented Architecture (SOA), can lead to the automated production of high-quality codes. Additionally, ontology-aware specification of the service from the abstract to the concrete level leads to early precise extraction of the service required by the users. This paper introduces a model-driven ontology-aware service development process to reduce the burden of code generation. This integrated approach utilizes a stepwise refinement methodology facilitated by a novel refinement algorithm to automate SOA development. The effectiveness of the approach is evaluated using three proposed parameters which examine the characteristics of the refined model in each refining step through some practical SOA case studies. Finally, we calculate the recall, precision, F-measure, accuracy, and also time analysis of discovered querying services for various scenarios in AWS and Netflix before and after applying ontology. The results show an average of 17% improvement in these metrics after applying ontology.},
  archive      = {J_IJITDM},
  author       = {Abdolghader Pourali and Maryam Nooraei Abadeh},
  doi          = {10.1142/S0219622024500123},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {2},
  pages        = {395-418},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {An ontology-aware model-driven approach for service-oriented application development: A stepwise refinement manner},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How to select algorithms for predictive maintenance: An economic decision model and real-world instantiation. <em>IJITDM</em>, <em>24</em>(2), 361-394. (<a href='https://doi.org/10.1142/S0219622024500147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive maintenance represents a promising application of Artificial Intelligence in the industrial context. The evaluation and selection of predictive maintenance algorithms primarily rely on statistical measures such as absolute and relative prediction errors. However, a purely statistical approach to algorithm selection may not necessarily lead to the optimal economic outcome, as the two types of prediction errors are negatively correlated, thus, cannot be jointly optimized, and are associated with different costs. As the current literature lacks corresponding guidance, we developed a decision model for industrial full-service providers, applying an economic perspective to selecting predictive maintenance algorithms. The decision model was instantiated and evaluated in a real-world setting with a European machinery company providing full-service solutions in the field of car wash systems. Building on sensor data from 4.9 million car wash cycles, the instantiation demonstrates the applicability and effectiveness of the decision model with fidelity to a real-world phenomenon. In sum, the decision model provides economic insights into the trade-off between the algorithms’ error types and enables users to focus on economic concerns in algorithm selection. Our work contributes to the prescriptive knowledge of algorithm selection and predictive maintenance in line with the consideration of different types of cost.},
  archive      = {J_IJITDM},
  author       = {Lukas Fabri and Björn Häckel and Robert Keller and Anna Maria Oberländer},
  doi          = {10.1142/S0219622024500147},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {2},
  pages        = {361-394},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {How to select algorithms for predictive maintenance: An economic decision model and real-world instantiation},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editor’s introduction. <em>IJITDM</em>, <em>24</em>(2), 355-360. (<a href='https://doi.org/10.1142/S0219622025030026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJITDM},
  author       = {Yong Shi},
  doi          = {10.1142/S0219622025030026},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {2},
  pages        = {355-360},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Editor’s introduction},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reject inference using discriminative dual stack sparse auto-encoders for consumer credit risk evaluation. <em>IJITDM</em>, <em>24</em>(1), 327-353. (<a href='https://doi.org/10.1142/S0219622025500038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit risk evaluation has gained substantial attention within financial institutions, serving as a pivotal tool to predict borrower repayment behavior and provide precise credit risk estimations. Traditional credit risk approaches discarded rejected applicants and were built only on accepted applicants, which posed sample selection bias issue. Previous reject inference methods solved the bias issue by incorporating information of rejected applicants. However, these methods assumed that the accepted and rejected samples had identical dimensions. In practical financial scenarios, financial institutions often encounter situations where the dimensions of accepted samples were larger than those of the rejected samples. Therefore, the additional features in accepted samples might not be fully utilized in the previous reject inference. In this study, we proposed a discriminative dual stack sparse auto-encoder (DD-SSAE) reject inference method that was suitable for the real scenarios. The proposed DD-SSAE has the following characteristics: (1) rejected samples were filtered based on our selection mechanism; (2) a stack sparse auto-encoder (SSAE), within a self-taught learning framework, was carried out to incorporate information of the selected rejected samples into the common features of accepted samples; and (3) a data fusion module, consisting of another SSAE network and a data fusion layer, was introduced to combine extra features with common features for accepted samples. The proposed method was verified on a Chinese consumer dataset and the findings illustrated its superiority over four conventional credit scoring models and five previous reject inference models.},
  archive      = {J_IJITDM},
  author       = {Gang Kou and Siqi Weng and Feng Shen and Fahd Saleh S. Alotaibi},
  doi          = {10.1142/S0219622025500038},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {1},
  pages        = {327-353},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Reject inference using discriminative dual stack sparse auto-encoders for consumer credit risk evaluation},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple risks and uncertain portfolio management. <em>IJITDM</em>, <em>24</em>(1), 297-325. (<a href='https://doi.org/10.1142/S0219622023500190'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies comparative static effects under uncertainty when investors face a portfolio decision problem with both an endogenous risk and a background risk. Since the security market is complex, there exists situation where security return and background asset return are given by experts’ estimates when they cannot be reflected by historical data. Focusing on such a situation, an uncertain mean-chance model with background risk for optimal portfolio selection is developed, in which the use of chance of portfolio return failing to reach the threshold can help investors easily determine their tolerance toward risk and thus facilitate a decision making. Then we analyze the solution of the programming problem under different threshold return level, i.e., how different degrees of threshold return will affect allocation between risky asset and risk-free asset. Furthermore, we discuss the effects of changes in mean and standard deviation of risky asset and background asset on investment decisions when security return and background asset return follow normal uncertainty distributions. Finally, a real portfolio selection example is given as illustration.},
  archive      = {J_IJITDM},
  author       = {Guowei Jiang and Xiaoxia Huang and Tingting Yang},
  doi          = {10.1142/S0219622023500190},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {1},
  pages        = {297-325},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Multiple risks and uncertain portfolio management},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Megale: A metadata-driven graph-based system for data lake exploration. <em>IJITDM</em>, <em>24</em>(1), 259-295. (<a href='https://doi.org/10.1142/S0219622024500135'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data lakes are storage repositories that contain large amounts of data (big data) in its native format; encompassing structured, semi-structured or unstructured. Data lakes are open to a wide range of use cases, such as carrying out advanced analytics and extracting knowledge patterns. However, the sheer dumping of data into a data lake would only lead to a data swamp. To prevent such a situation, enterprises can adopt best practices, among which to manage data lake metadata. A growing body of research has focused on proposing metadata systems and models for data lakes with a special interest on model genericness. However, existing models fail to cover all aspects of a data lake, due to their static modeling approach. Besides, they do not fully cover essential features for an effective metadata management, namely governance, visibility and uniform treatment of data lake concepts. In this paper, we propose a dynamic modeling approach to meet these features, based on two main constructs: data lake concept and data lake relationship . We showcase our approach by Megale, a graph-based metadata system for NoSQL data lake exploration. We present a proof-of-concept implementation of Megale and we show its effectiveness and efficiency in exploring the data lake.},
  archive      = {J_IJITDM},
  author       = {Doulkifli Boukraa and Meriem Bouraoui and Chaima Grine and Racha Ouahab},
  doi          = {10.1142/S0219622024500135},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {1},
  pages        = {259-295},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Megale: A metadata-driven graph-based system for data lake exploration},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The impact of trade credit on financing strategy in a dual capital-constrained supply chain. <em>IJITDM</em>, <em>24</em>(1), 223-257. (<a href='https://doi.org/10.1142/S0219622022500687'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study analyzes the financing strategy of a two-echelon supply chain, consisting of a manufacturer and a retailer, both subject to capital constraints. Specifically, the bank provides loans to the manufacturer, who then grants trade credit to the retailer. Based on the three-party game analysis framework of the bank, manufacturer, and retailer, this paper constructs a supply chain financing model under the information symmetry and information asymmetry structures, respectively; measures the maximum financing ability of the manufacturer; and discusses the influence of trade credit, moral hazard, and information structure on the manufacturer’s and bank’s strategies. The results show that under the trade credit situation, it is critical for the bank to provide loan to manufacturer who does not have moral hazard. The maximum financing capacity of the manufacturer is affected by the rate of return on moral hazard and the intensity of trade credit default. The increase of trade credit default intensity and risk exposure will lead to the increase of the interest rate of bank loan, and in the case of information asymmetry, the bank will often ask for a higher interest rate to deal with the information disadvantage. The strategy for the bank to make the credit line is more complex, and the degree of information asymmetry plays a positive moderating effect on the influence of trade credit on the credit line. Our findings provide implications for participants who implement financing actions to improve their financial performance and control the moral hazard and default risk along a supply chain.},
  archive      = {J_IJITDM},
  author       = {Xiaofeng Xie and Yang Yang and Xingyang Lyu and Fengying Zhang and Xiuying Hu and Zongfang Zhou},
  doi          = {10.1142/S0219622022500687},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {1},
  pages        = {223-257},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {The impact of trade credit on financing strategy in a dual capital-constrained supply chain},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dwarf mongoose chimp optimization enabled RMDL for sentiment categorization using cell phone data. <em>IJITDM</em>, <em>24</em>(1), 197-222. (<a href='https://doi.org/10.1142/S0219622025500026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is the process of looking through digital text to determine if the emotional tone of a text is positive, negative, or neutral. It helps companies improve their product, but a serious problem arises in classifying the polarity of certain texts with information, sentences or features to forecast their opinion. Therefore, sentiment classification should be done using new technology that classifies reviews as positive or negative so that users can make effective decisions. This research paper develops an effective model to classify sentiment using cell phone data. Initially, the Amazon phone document is passed to the BERT tokenization stage to split the acquired reviews. Then, the Aspect Term Extraction (ATE) is applied and the Term Frequency-Inverse Document Frequency (TF-IDF) is extracted as the first output. Afterward, Wordnet ontology features are extricated as the second output. Moreover, features like statistical, sarcasm linguistic, and N -gram features are extracted from BERT tokenization and considered as the third output. Finally, the sentiment is classified by subjecting the obtained three outputs to Random Multimodal Deep Learning (RMDL), which is tuned by Dwarf Mongoose Chimp Optimization (DMCO). DMCO is created by the combination of the Dwarf Mongoose Optimization (DMO) and the Chimp Optimization Algorithm (ChOA). The developed DMCO-RMDL approach attained high accuracy, True Positive Rate (TPR), True Negative Rate (TNR), precision, recall, and F 1-score values of 93%, 92.8%, 92.2%, 91.5%, 94.1%, and 94.8%, respectively.},
  archive      = {J_IJITDM},
  author       = {Minu P. Abraham and K. R. Udaya Kumar Reddy},
  doi          = {10.1142/S0219622025500026},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {1},
  pages        = {197-222},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Dwarf mongoose chimp optimization enabled RMDL for sentiment categorization using cell phone data},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The best evaluation sequence method and application based on quantum cognitive theory. <em>IJITDM</em>, <em>24</em>(1), 169-196. (<a href='https://doi.org/10.1142/S0219622025500014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the credit risk evaluation process, considering that the decision maker’s irrational behavior may cause the interference effect between evaluation information, and further decrease the reliability of evaluation results. To solve this problem, the best evaluation sequence method and its application in credit risk evaluation based on quantum cognitive theory is proposed in this paper. First, the quantum cognition theory and the evaluation information given by the decision maker are used to get the interference degree between evaluation information. Second, the interference degree between evaluation information is aggregated to obtain the comprehensive interference degree of each alternative. Third, according to the idea that the greater the comprehensive interference degree of the alternative, the more backward the evaluation sequence of the alternative is, we determine the best evaluation sequence of alternatives. Finally, our proposed method is applied to obtain the best evaluation sequence of commercial bank credit risk.},
  archive      = {J_IJITDM},
  author       = {Wangwang Yu and Xinwang Liu and Yingping Zi},
  doi          = {10.1142/S0219622025500014},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {1},
  pages        = {169-196},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {The best evaluation sequence method and application based on quantum cognitive theory},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decision modeling approach for data acquisition systems of the vehicle industry based on interval-valued linear diophantine fuzzy set. <em>IJITDM</em>, <em>24</em>(1), 89-168. (<a href='https://doi.org/10.1142/S0219622023500487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling data acquisition systems (DASs) can support the vehicle industry in the development and design of sophisticated driver assistance systems. Modeling DASs on the basis of multiple criteria is considered as a multicriteria decision-making (MCDM) problem. Although literature reviews have provided models for DASs, the issue of imprecise, unclear, and ambiguous information remains unresolved. Compared with existing MCDM methods, the robustness of the fuzzy decision by opinion score method II (FDOSM II) and fuzzy weighted with zero inconsistency II (FWZIC II) is demonstrated for modeling the DASs. However, these methods are implemented in an intuitionistic fuzzy set environment that restricts the ability of experts to provide membership and nonmembership degrees freely, simulate real-world ambiguity efficiently, utilize a narrow fuzzy number space, and deal with interval data. Thus, this study used a more efficient fuzzy environment interval-valued linear Diophantine fuzzy set (IVLDF) with FWZIC II for criterion weighting and IVLDF with FDOSM for DAS modeling to address the issues and support industrial community characteristics in the design and implementation of advanced driver assistance systems in vehicles. The proposed methodology comprises two consecutive phases. The first phase involves adapting a decision matrix that intersects DAS alternatives and criteria. The second phase (development phase) proposes a decision modeling approach based on formulation of IVLD-FWZIC II and IVLD-FDOSM II to model DASs. A total of 14 DASs were modeled on the basis of 15 DAS criteria, including seven subcriteria for “comprehensive complexity assessment” and eight subcriteria for “design and implementation,” which had a remarkable effect on the DAS design when implemented by industrial communities. Systematic ranking, sensitivity analysis, and modeling checklists were conducted to demonstrate that the modeling results were subject to systematic ranking, as indicated by the high correlations across all described scenarios of changing criterion weight values, supporting the most important research points, and proposing a value-adding process in modeling the most desirable DAS.},
  archive      = {J_IJITDM},
  author       = {M. J. Baqer and H. A. AlSattar and Sarah Qahtan and A. A. Zaidan and Mohd Azri Mohd Izhar and Iraq T. Abbas},
  doi          = {10.1142/S0219622023500487},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {1},
  pages        = {89-168},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A decision modeling approach for data acquisition systems of the vehicle industry based on interval-valued linear diophantine fuzzy set},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multidimensional analysis of investment priorities for circular economy with quantum spherical fuzzy hybrid modeling. <em>IJITDM</em>, <em>24</em>(1), 61-87. (<a href='https://doi.org/10.1142/S021962202350075X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Circular economy aims recycling in the production process instead of destroying the products. With the help of this situation, waste can be considered in the remanufacturing process so that the rate of consumption of natural resources can be decreased. It is necessary to focus on certain investment issues to achieve a circular economy, but all investments have some risks. Hence, the economies should make priority analysis to take efficient actions. Investment priorities are identified to have circular economy. A novel fuzzy decision-making model has been created for this purpose. In the first stage, balanced scorecard criteria are evaluated with the help of multi stepwise weight assessment ratio analysis (M-SWARA). Later, the multidimensional investment priorities of circular economy are ranked. In this context, elimination and choice translating reality (ELECTRE) approach is taken into consideration. The main contribution of the paper is that a new methodology is created by the name of M-SWARA. Owing to these new improvements, cause and effect relationship among the items can be analyzed. It is identified that financial issues play the most crucial role for investments to improve circular economy. On the other side, it is also concluded that remanufacturing is the most significant investment alternative to develop circular economy. For the sustainability of the investment to improve circular economy, necessary financial analysis should be performed. With the help of this situation, these substances can be reintroduced into the production process in the form of raw materials. With the increase of remanufacturing, it will be possible to reduce waste and save scarce material resources.},
  archive      = {J_IJITDM},
  author       = {Hasan Dinçer and Serhat Yüksel and Umit Hacıoglu and Babek Erdebilli},
  doi          = {10.1142/S021962202350075X},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {1},
  pages        = {61-87},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Multidimensional analysis of investment priorities for circular economy with quantum spherical fuzzy hybrid modeling},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stage integrated dynamic assessment method for urban resilience based on multisource data. <em>IJITDM</em>, <em>24</em>(1), 29-59. (<a href='https://doi.org/10.1142/S0219622024410013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban resilience assessment (URA) is challenging because of urban system complexity and dynamic resilience variability. This paper develops a URA method with comprehensive feature consideration and integrated data use and then constructs a hierarchical URA criteria system. Subsequently, a two-stage integrated dynamic assessment method based on multisource data is presented, wherein the subjective–objective combination weights are determined, and the dimensional and overall urban resilience (UR) indexes are constructed. The applicability and superiority of the proposed method to existing methods are verified using a case study in Beijing. The results showed that UR in Beijing has improved substantially in 2016–2020; social and ecological dimensions are important for UR improvement; and synergies exist between different UR dimensions, which are crucial for resilient urban development. This study provides a systematic solution for URA that features a dynamic perspective, multisource data utilization, and subjective–objective combination weights, enhancing URA comprehensiveness and accuracy.},
  archive      = {J_IJITDM},
  author       = {Lulu Shen and Jianping Li and Xiaolei Sun and Weilan Suo},
  doi          = {10.1142/S0219622024410013},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {1},
  pages        = {29-59},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Two-stage integrated dynamic assessment method for urban resilience based on multisource data},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linear step-adjusting programming in factor space. <em>IJITDM</em>, <em>24</em>(1), 7-28. (<a href='https://doi.org/10.1142/S0219622023410018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent behavior that appears in a decision process can be treated as a point y , the dynamic state observed and controlled by the agent, moving in a factor space impelled by the goal factor and blocked by the constraint factors. Suppose that the feasible region is cut by a group of hyperplanes, when point y reaches the region’s wall, a hyperplane will block the moving, and the agent needs to adjust the moving direction such that the target is pursued as faithfully as possible. Since the wall is not able to be represented by a differentiable function, the gradient method cannot be applied to describe the adjusting process. We, therefore, suggest a new model, named linear step-adjusting programming (LSP) in this paper. LSP is similar to a kind of relaxed linear programming (LP). The difference between LP and LSP is that the former aims to find the ultimate optimal point, while the latter just does a direct action in a short period. Where will a blocker encounter? How do you adjust the moving direction? Where further blockers may be encountered next, and how should the direction be adjusted again? … If the ultimate best is found, that’s a blessing; if not, that’s fine. We request at least an adjustment should be got at the first time. However, the former is idealism, and the latter is realism. In place of a gradient vector, the projection of goal direction g in a subspace plays a core role in LSP. If a hyperplane block y goes ahead along with the direction d , then we must adjust the new direction d ′ as the projection of g in the blocking plane. Suppose there is only one blocker at a time. In that case, it is straightforward to calculate the projection, but how to calculate the projection when more than one blocker is encountered simultaneously? It is still an open problem for LP researchers. We suggest a projection calculation using the Hat matrix in the paper. LSP will attract interest in economic restructuring, financial prediction, and reinforcement learning.},
  archive      = {J_IJITDM},
  author       = {Jing He and Hui Zheng and Rozbeh Zarei and Ho-Chung Lui and Qi-Wei Kong and Yi-Mu Ji and Xingsen Li and Hailong Yang and Baorui Du and Yong Shi and Pingjiang Wang and Andre van Zundert},
  doi          = {10.1142/S0219622023410018},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {1},
  pages        = {7-28},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Linear step-adjusting programming in factor space},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editor’s introduction. <em>IJITDM</em>, <em>24</em>(1), 1-5. (<a href='https://doi.org/10.1142/S0219622025030014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJITDM},
  author       = {Yong Shi},
  doi          = {10.1142/S0219622025030014},
  journal      = {International Journal of Information Technology & Decision Making},
  number       = {1},
  pages        = {1-5},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Editor’s introduction},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijns">IJNS - 62</h2>
<ul>
<li><details>
<summary>
(2025). Multi-layer feature cascade fusion spiking neural network for object detection. <em>IJNS</em>, <em>35</em>(11), 2550063. (<a href='https://doi.org/10.1142/S0129065725500637'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs), as a biologically inspired computational model, have garnered significant attention in object detection and image classification due to their event-driven mechanism and low-power characteristics. However, in object detection tasks, the residual structures in conventional networks introduce nonspiking operations, posing a critical challenge for SNNs. To address this issue, we propose a multi-layer feature cascade fusion SNN (MFCF-SNN) for object detection. During feature extraction, our novel multi-level cascaded feature extraction module replaces residual connections with cascade operations, eliminating nonspiking computations while enhancing gradient propagation to deeper layers. For downsampling, we introduce a pooling-convolution module that combines max-pooling and spiking convolution, effectively preserving feature information and improving gradient flow. These two modules collectively ensure pure spike-based computation while facilitating deep network training, thereby enhancing detection accuracy. Experimental results on the PASCAL VOC 2012 and SSDD datasets demonstrate state-of-the-art performance, validating the effectiveness of our approach in advancing SNN-based object detection.},
  archive      = {J_IJNS},
  author       = {Yongqiang Ma and Bailin Guo and Xuetao Zhang},
  doi          = {10.1142/S0129065725500637},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2550063},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Multi-layer feature cascade fusion spiking neural network for object detection},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Matrix representation of virus machines and an application to the discrete logarithm problem. <em>IJNS</em>, <em>35</em>(11), 2550049. (<a href='https://doi.org/10.1142/S0129065725500492'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virus machines, which develop models of computation inspired by biological processes and the spread of viruses among hosts, deviate from the traditional methods. These virus machines are recognized for their computational power (functioning as algorithms) and their ability to tackle computationally difficult problems. In this paper, we introduce a new extension of the matrix-based representation of virus machines. In this way, hosts, the number of viruses and the instructions to control virus transmission are represented as vectors and matrices, describing the computations of virus machines by linear algebra operations. We also use our matrix representation to show invariants, useful in the proofs, of such machines. In addition, an explicit example is shown to clarify the computation and invariants using the representation. That is, a virus machine that computes the discrete logarithm, which relies on the presumed intractability of cryptosystems such the digital signature algorithm.},
  archive      = {J_IJNS},
  author       = {Antonio Ramírez-de-Arellano and David Orellana-Martín and Mario J. Pérez-Jiménez and Francis George C. Cabarle and Henry N. Adorna},
  doi          = {10.1142/S0129065725500492},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2550049},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Matrix representation of virus machines and an application to the discrete logarithm problem},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A salient object detection network enhanced by nonlinear spiking neural systems and transformer. <em>IJNS</em>, <em>35</em>(11), 2550045. (<a href='https://doi.org/10.1142/S0129065725500455'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although a variety of deep learning-based methods have been introduced for Salient Object Detection (SOD) to RGB and Depth (RGB-D) images, existing approaches still encounter challenges, including inadequate cross-modal feature fusion, significant errors in saliency estimation due to noise in depth information, and limited model generalization capabilities. To tackle these challenges, this paper introduces an innovative method for RGB-D SOD, TranSNP-Net, which integrates Nonlinear Spiking Neural P (NSNP) systems with Transformer networks. TranSNP-Net effectively fuses RGB and depth features by introducing an enhanced feature fusion module (SNPFusion) and an attention mechanism. Unlike traditional methods, TranSNP-Net leverages fine-tuned Swin (shifted window transformer) as its backbone network, significantly improving the model’s generalization performance. Furthermore, the proposed hierarchical feature decoder (SNP-D) notably enhances accuracy in complex scenes where depth noise is prevalent. According to the experimental findings, the mean scores for the four metrics S-measure, F-measure, E-measure and MEA on the six RGB-D benchmark datasets are 0.9328, 0.9356, 0.9558 and 0.0288. TranSNP-Net achieves superior performance compared to 14 leading methods in six RGB-D benchmark datasets.},
  archive      = {J_IJNS},
  author       = {Wang Li and Meichen Xia and Hong Peng and Zhicai Liu and Jun Guo},
  doi          = {10.1142/S0129065725500455},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2550045},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A salient object detection network enhanced by nonlinear spiking neural systems and transformer},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear spiking neural systems for thermal image semantic segmentation networks. <em>IJNS</em>, <em>35</em>(11), 2550038. (<a href='https://doi.org/10.1142/S0129065725500388'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thermal and RGB images exhibit significant differences in information representation, especially in low-light or nighttime environments. Thermal images provide temperature information, complementing the RGB images by restoring details and contextual information. However, the spatial discrepancy between different modalities in RGB-Thermal (RGB-T) semantic segmentation tasks complicates the process of multimodal feature fusion, leading to a loss of spatial contextual information and limited model performance. This paper proposes a channel-space fusion nonlinear spiking neural P system model network (CSPM-SNPNet) to address these challenges. This paper designs a novel color-thermal image fusion module to effectively integrate features from both modalities. During decoding, a nonlinear spiking neural P system is introduced to enhance multi-channel information extraction through the convolution of spiking neural P systems (ConvSNP) operations, fully restoring features learned in the encoder. Experimental results on public datasets MFNet and PST900 demonstrate that CSPM-SNPNet significantly improves segmentation performance. Compared with the existing methods, CSPM-SNPNet achieves a 0.5% improvement in mIOU on MFNet and 1.8% on PST900, showcasing its effectiveness in complex scenes.},
  archive      = {J_IJNS},
  author       = {Peng Wang and Minglong He and Hong Peng and Zhicai Liu},
  doi          = {10.1142/S0129065725500388},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2550038},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Nonlinear spiking neural systems for thermal image semantic segmentation networks},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the computational complexity of spiking neural membrane systems with colored spikes. <em>IJNS</em>, <em>35</em>(11), 2550035. (<a href='https://doi.org/10.1142/S0129065725500352'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural P Systems are parallel and distributed computational models inspired by biological neurons, emerging from membrane computing and applied to solving computationally difficult problems. This paper focuses on the computational complexity of such systems using neuron division rules and colored spikes for the SAT problem. We prove a conjecture stated in a recent paper, showing that enhancing the model with an input module reduces computing time. Additionally, we prove that the inclusion of budding rules extends the model’s capability to solve all problems in the complexity class PSPACE . These findings advance research on Spiking Neural P Systems and their application to complex problems; however, whether both budding rules and division rules are required to extend these methods to problem domains beyond the NP class remains an open question.},
  archive      = {J_IJNS},
  author       = {Antonio Grillo and Claudio Zandron},
  doi          = {10.1142/S0129065725500352},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2550035},
  shortjournal = {Int. J. Neural Syst.},
  title        = {On the computational complexity of spiking neural membrane systems with colored spikes},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward a biologically plausible SNN-based associative memory with context-dependent hebbian connectivity. <em>IJNS</em>, <em>35</em>(11), 2550027. (<a href='https://doi.org/10.1142/S0129065725500273'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a spiking neural network model with Hebbian connectivity for implementing energy-efficient associative memory, whose activity is determined by input stimuli. The model consists of three interacting layers of Hodgkin–Huxley–Mainen spiking neurons with excitatory and inhibitory synaptic connections. Information patterns are stored in memory using a symmetric Hebbian matrix and can be retrieved in response to a specific stimulus pattern. Binary images are encoded using in-phase and anti-phase oscillations relative to a global clock signal. Utilizing the phase-locking effect allows for cluster synchronization of neurons (both on the input and output layers). Interneurons in the intermediate layer filter signal propagation pathways depending on the context of the input layer, effectively engaging only a portion of the synaptic connections within the Hebbian matrix for recognition. The stability of the oscillation phase is investigated for both in-phase and anti-phase synchronization modes when recognizing direct and inverse images. This context-dependent effect opens promising avenues for the development of analog hardware circuits for energy-efficient neurocomputing applications, potentially leading to breakthroughs in artificial intelligence and cognitive computing.},
  archive      = {J_IJNS},
  author       = {S. Yu. Makovkin and S. Yu. Gordleeva and I. A. Kastalskiy},
  doi          = {10.1142/S0129065725500273},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2550027},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Toward a biologically plausible SNN-based associative memory with context-dependent hebbian connectivity},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Introduction. <em>IJNS</em>, <em>35</em>(11), 2502003. (<a href='https://doi.org/10.1142/S0129065725020034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJNS},
  author       = {Marian Gheorghe and Alberto Leporati and Ferrante Neri and David Orellana Martín and Mario J. Pérez-Jiménez},
  doi          = {10.1142/S0129065725020034},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2502003},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Introduction},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stability-aware dual-head network with prototype-based consistency for semi-supervised medical image segmentation. <em>IJNS</em>, <em>35</em>(10), 2550054. (<a href='https://doi.org/10.1142/S0129065725500546'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised semantic segmentation for medical images has evolved through time. While it can leverage the unlabeled data to significantly improve the segmentation performance, it still suffers the problems of intra-class variance and the consequent class-domain distribution misalignment along with costly training. In this paper, a stability-aware dual-head architecture is proposed to synergize prototype-based and Fully Convolutional Network (FCN) methodologies. By integrating prototype-based method for feature consistency and FCN method for spatial detail preservation, our method enforces consistency between different feature representations. It combines the semantic consistency of prototype learning with the precision of dense prediction. A sample-level stability-aware adaptive augmentation strategy is introduced to further mitigate intra-class variance and distribution shifts. The following certainty guided fusion process dynamically refines the pseudo-labels, better utilizing the advantages in different methods. Experiments on BraTS2019 and LA Heart demonstrate State-Of-The-Art (SOTA) performance, achieving significant improvements over the previous SOTA methods on multiple metrics. The framework effectively bridges domain gaps and enhances pseudo-label reliability for medical image analysis. (Code is available at https://github.com/Alfredzly/SDNP ).},
  archive      = {J_IJNS},
  author       = {Leyi Zhang and Jiayi Li and Yu Yan and Xiaolong Xu and Lei Zhang},
  doi          = {10.1142/S0129065725500546},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2550054},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A stability-aware dual-head network with prototype-based consistency for semi-supervised medical image segmentation},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Expanding domain-specific datasets with stable diffusion generative models for simulating myocardial infarction. <em>IJNS</em>, <em>35</em>(10), 2550052. (<a href='https://doi.org/10.1142/S0129065725500522'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Areas, such as the identification of human activity, have accelerated thanks to the immense development of artificial intelligence (AI). However, the lack of data is a major obstacle to even faster progress. This is particularly true in computer vision, where training a model typically requires at least tens of thousands of images. Moreover, when the activity a researcher is interested in is far from the usual, such as falls, it is difficult to have a sufficiently large dataset. An example of this could be the identification of people suffering from a heart attack. In this sense, this work proposes a novel approach that relies on generative models to extend image datasets, adapting them to generate more domain-relevant images. To this end, a refinement to stable diffusion models was performed using low-rank adaptation. A dataset of 100 images of individuals simulating infarct situations and neutral poses was created, annotated, and used. The images generated with the adapted models were evaluated using learned perceptual image patch similarity to test their closeness to the target scenario. The results obtained demonstrate the potential of synthetic datasets, and in particular the strategy proposed here, to overcome data sparsity in AI-based applications. This approach can not only be more cost-effective than building a dataset in the traditional way, but also reduces the ethical concerns of its applicability in smart environments, health monitoring, and anomaly detection. In fact, all data are owned by the researcher and can be added and modified at any time without requiring additional permissions, streamlining their research.},
  archive      = {J_IJNS},
  author       = {Gabriel Rojas-Albarracín and António Pereira and Antonio Fernández-Caballero and María T. López},
  doi          = {10.1142/S0129065725500522},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2550052},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Expanding domain-specific datasets with stable diffusion generative models for simulating myocardial infarction},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dominant classifier-assisted hybrid evolutionary multi-objective neural architecture search. <em>IJNS</em>, <em>35</em>(10), 2550051. (<a href='https://doi.org/10.1142/S0129065725500510'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Architecture Search (NAS) automates the design of deep neural networks but remains computationally expensive, particularly in multi-objective settings. Existing predictor-assisted evolutionary NAS methods suffer from slow convergence and rank disorder, which undermines prediction accuracy. To overcome these limitations, we propose CHENAS: a Classifier-assisted multi-objective Hybrid Evolutionary NAS framework. CHENAS combines the global exploration of evolutionary algorithms with the local refinement of gradient-based optimization to accelerate convergence and enhance solution quality. A novel dominance classifier predicts Pareto dominance relationships among candidate architectures, reframing multi-objective optimization as a classification task and mitigating rank disorder. To further improve efficiency, we employ a contrastive learning-based autoencoder that maps architectures into a continuous, structured latent space tailored for dominance prediction. Experiments on several benchmark datasets demonstrate that CHENAS outperforms state-of-the-art NAS approaches in identifying high-performing architectures across multiple objectives. Future work will focus on improving the computational efficiency of the framework and extending it to other application domains.},
  archive      = {J_IJNS},
  author       = {Yu Xue and Keyu Liu and Ferrante Neri},
  doi          = {10.1142/S0129065725500510},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2550051},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Dominant classifier-assisted hybrid evolutionary multi-objective neural architecture search},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A contrastive learning-enhanced residual network for predicting epileptic seizures using EEG signals. <em>IJNS</em>, <em>35</em>(10), 2550050. (<a href='https://doi.org/10.1142/S0129065725500509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The models used to predict epileptic seizures based on electroencephalogram (EEG) signals often encounter substantial challenges due to the requirement for large, labeled datasets and the inherent complexity of EEG data, which hinders their robustness and generalization capability. This study proposes CLResNet, a framework for predicting epileptic seizures, which combines contrastive self-supervised learning with a modified deep residual neural network to address the above challenges. In contrast to traditional models, CLResNet uses unlabeled EEG data for pre-training to extract robust feature representations. It is then fine-tuned on a smaller labeled dataset to significantly reduce its reliance on labeled data while improving its efficiency and predictive accuracy. The contrastive learning (CL) framework enhances the ability of the model to distinguish between preictal and interictal states, thus improving its robustness and generalizability. The architecture of CLResNet contains residual connections that enable it to learn deep features of the data and ensure an efficient gradient flow. The results of the evaluation of the model on the CHB-MIT dataset showed that it outperformed prevalent methods in the field, with an accuracy of 92.97%, sensitivity of 94.18%, and false-positive rate of 0.043/h. On the Siena dataset, the model also achieved competitive performance, with an accuracy of 92.79%, a sensitivity of 91.47%, and a false-positive rate of 0.041/h. These results confirm the effectiveness of CLResNet in addressing variations in EEG data, and show that contrastive self-supervised learning is a robust and accurate approach for predicting seizures.},
  archive      = {J_IJNS},
  author       = {Longfei Qi and Shasha Yuan and Feng Li and Junliang Shang and Juan Wang and Shihan Wang},
  doi          = {10.1142/S0129065725500509},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2550050},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A contrastive learning-enhanced residual network for predicting epileptic seizures using EEG signals},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised brain MRI anomaly detection via inter-realization channels. <em>IJNS</em>, <em>35</em>(10), 2550047. (<a href='https://doi.org/10.1142/S0129065725500479'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate anomaly detection in brain Magnetic Resonance Imaging (MRI) is crucial for early diagnosis of neurological disorders, yet remains a significant challenge due to the high heterogeneity of brain abnormalities and the scarcity of annotated data. Traditional one-class classification models require extensive training on normal samples, limiting their adaptability to diverse clinical cases. In this work, we introduce MadIRC, an unsupervised anomaly detection framework that leverages Inter-Realization Channels (IRC) to construct a robust nominal model without any reliance on labeled data. We extensively evaluate MadIRC on brain MRI as the primary application domain, achieving a localization AUROC of 0.96 outperforming state-of-the-art supervised anomaly detection methods. Additionally, we further validate our approach on liver CT and retinal images to assess its generalizability across medical imaging modalities. Our results demonstrate that MadIRC provides a scalable, label-free solution for brain MRI anomaly detection, offering a promising avenue for integration into real-world clinical workflows.},
  archive      = {J_IJNS},
  author       = {Hussain Ahmad Madni and Hafsa Shujat and Axel De Nardin and Silvia Zottin and Gian Luca Foresti},
  doi          = {10.1142/S0129065725500479},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2550047},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Unsupervised brain MRI anomaly detection via inter-realization channels},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A performance benchmarking review of transformers for speaker-independent speech emotion recognition. <em>IJNS</em>, <em>35</em>(10), 2530001. (<a href='https://doi.org/10.1142/S0129065725300013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech Emotion Recognition (SER) is becoming a key element of speech-based human–computer interfaces, endowing them with some form of empathy towards the emotional status of the human. Transformers have become a central Deep Learning (DL) architecture in natural language processing and signal processing, recently including audio signals for Automatic Speech Recognition (ASR) and SER. A central question addressed in this paper is the achievement of speaker-independent SER systems, i.e. systems that perform independently of a specific training set, enabling their deployment in real-world situations by overcoming the typical limitations of laboratory environments. This paper presents a comprehensive performance evaluation review of transformer architectures that have been proposed to deal with the SER task, carrying out an independent validation at different levels over the most relevant publicly available datasets for validation of SER models. The comprehensive experimental design implemented in this paper provides an accurate picture of the performance achieved by current state-of-the-art transformer models in speaker-independent SER. We have found that most experimental instances reach accuracies below 40% when a model is trained on a dataset and tested on a different one. A speaker-independent evaluation combining up to five datasets and testing on a different one achieves up to 58.85% accuracy. In conclusion, the SER results improved with the aggregation of datasets, indicating that model generalization can be enhanced by extracting data from diverse datasets.},
  archive      = {J_IJNS},
  author       = {Francisco Portal and Javier De Lope and Manuel Graña},
  doi          = {10.1142/S0129065725300013},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2530001},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A performance benchmarking review of transformers for speaker-independent speech emotion recognition},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph spectral analysis using electroencephalography in alzheimer disease and frontotemporal dementia patients. <em>IJNS</em>, <em>35</em>(9), 2550048. (<a href='https://doi.org/10.1142/S0129065725500480'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph theory has proven to be useful in studying brain dysfunction in Alzheimer’s disease using MagnetoEncephaloGraphy (MEG) and fMRI signals. However, it has not yet been tested enough with reduced sets of electrodes, as in the 10–20 EEG. In this paper, we applied techniques from the Graph Spectral Analysis (GSA) derived from EEG signals of patients with Alzheimer, Frontotemporal Dementia and control subjects. A collection of global GSA metrics were computed, accounting for general properties of the adjacency or Laplacian matrices. Also, regional GSA metrics were calculated, disentangling centrality measures in five cortical regions (frontal, central, parietal, temporal and occipital). These two sort of measures were then utilized in a binary AD/controls classification problem to test their utility in AD diagnosis and identify most valuable parameters. The Theta band appeared as the most connected and synchronizable rhythm for all three groups. Also, it was the rhythm with most preserved connections among temporal electrodes, exhibiting the shortest average distances among T 3 , T 4 , T 5 and T 6 . In addition, Theta emerged as the rhythm with the highest classification performances based on regional parameters according to a k = 5 cross-validation scheme (mean accuracy = 0 . 7 4 ± 0 . 0 3 , mean recall = 0 . 7 2 ± 0 . 0 5 and mean F 1- score = 0 . 7 2 ± 0 . 0 3 ). In general, regional parameters produced better classification performances for most of the rhythms, encouraging further investigation into GSA parameters with refined spatial and functional specificity.},
  archive      = {J_IJNS},
  author       = {María Paula Bonomini and Eduardo Ghiglioni and Noelia Belén Ríos},
  doi          = {10.1142/S0129065725500480},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2550048},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Graph spectral analysis using electroencephalography in alzheimer disease and frontotemporal dementia patients},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding of task-specific and subject-specific components in surface EMG. <em>IJNS</em>, <em>35</em>(9), 2550046. (<a href='https://doi.org/10.1142/S0129065725500467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface electromyogram (sEMG) signals are widely used in human–machine interfaces for gesture recognition and user identification, but existing models often struggle with generalization across different individuals due to subject-specific neuromuscular characteristics. This study introduced a disentanglement model to separate task-specific and subject-specific components from sEMG signals, thus improving the generalization and interpretability of gesture recognition and user identification systems. Experimental results demonstrate that disentangled task-specific components significantly improve the accuracy of both gesture classification and user identification across different subjects and days, outperforming conventional methods in the same scenario. Further analysis of the extracted components reveals that task-specific components capture consistent activation patterns for the same gestures across individuals. In contrast, subject-specific components reflect unique neuromuscular characteristics that can be used for user identification. Notably, subject-specific components show reduced similarity compared to task-specific components in inter-day scenarios, contributing to more accuracy decrease in user identification than in gesture recognition. These findings suggest that the disentanglement approach not only boosts classification performance but also provides deeper insights into the physiological mechanisms underlying sEMG signals. The model’s ability to isolate and interpret different neuromuscular components holds promise for enhancing the robustness of sEMG-based applications in real-world settings, such as rehabilitation and user authentication.},
  archive      = {J_IJNS},
  author       = {Yangyang Yuan and Jionghui Liu and Xinyu Jiang and Jiahao Fan and Chih-Hong Chou and Chenyun Dai},
  doi          = {10.1142/S0129065725500467},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2550046},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Understanding of task-specific and subject-specific components in surface EMG},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Post-movement beta rebound for longitudinal monitoring of motor rehabilitation in stroke patients using an exoskeleton-assisted paradigm. <em>IJNS</em>, <em>35</em>(9), 2550044. (<a href='https://doi.org/10.1142/S0129065725500443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task-oriented rehabilitation is essential for hand function recovery in stroke patients, and recent advancements in BCI-controlled exoskeletons and neural biomarkers — such as post-movement beta rebound (PMBR) — offer new pathways to optimize these therapies. Movement-related EEG signals from the sensorimotor cortex, particularly PMBR (post-movement) and event-related desynchronization (ERD, during movement), exhibit high task specificity and correlate with stroke severity. This study evaluated PMBR in 34 chronic stroke patients across two cohorts, along with a control group of 16 healthy participants, during voluntary and exoskeleton-assisted movement tasks. Longitudinal tracking in the second cohort enabled the analysis of PMBR changes, with EEG recordings acquired at three timepoints over a 30-session rehabilitation program. Findings revealed significant PMBR alterations in both passive and active movement tasks: patients with severe impairment lacked a PMBR dipole in the ipsilesional hemisphere, while moderately impaired patients showed a diminished response. The marked differences in PMBR patterns between stroke patients and controls highlight the extent of sensorimotor cortex disruption due to stroke. ERD showed minimal task-specific variation, underscoring PMBR as a more reliable biomarker of motor function impairment. These findings support the use of PMBR, particularly the PMBR/ERD ratio, as a biomarker for EEG-guided monitoring of motor recovery over time during exoskeleton-assisted rehabilitation.},
  archive      = {J_IJNS},
  author       = {Juan A. Barios and Yolanda Vales and Jose M. Catalán and Andrea Blanco-Ivorra and David Martínez-Pascual and Nicolás García-Aracil},
  doi          = {10.1142/S0129065725500443},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2550044},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Post-movement beta rebound for longitudinal monitoring of motor rehabilitation in stroke patients using an exoskeleton-assisted paradigm},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing dementia diagnosis through distance-correlation feature space and dimensionality reduction. <em>IJNS</em>, <em>35</em>(9), 2550042. (<a href='https://doi.org/10.1142/S012906572550042X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reduction of dimensionality in machine learning and artificial intelligence problems constitutes a pivotal element in the simplification of models, significantly enhancing both their performance and execution time. This process enables the generation of results more rapidly while also facilitating the scalability and optimization of systems that rely on such models. Two primary approaches are commonly employed to achieve dimensionality reduction: feature selection-based methods and those grounded in feature extraction. In this paper, we propose a distance-correlation feature space, upon which we define a dimensionality reduction algorithm based on space transformations and graph embeddings. This methodology is applied in the context of dementia diagnosis through learning models, with the overarching objective of optimizing the diagnostic process.},
  archive      = {J_IJNS},
  author       = {Pablo Zubasti and Miguel A. Patricio and Antonio Berlanga and Jose M. Molina},
  doi          = {10.1142/S012906572550042X},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2550042},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Optimizing dementia diagnosis through distance-correlation feature space and dimensionality reduction},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interactive EEG emotion recognition with incremental gaussian processes. <em>IJNS</em>, <em>35</em>(9), 2550041. (<a href='https://doi.org/10.1142/S0129065725500418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactivity is crucial for enabling models to adjust and optimize based on user feedback, thereby enhancing overall performance. However, existing electroencephalogram (EEG)-based emotion recognition models rely on static training paradigms, lack interactivity, and struggle to effectively handle uncertainty in predictions. To address this issue, we propose a novel paradigm for interactive emotion recognition based on incremental Gaussian processes (GP). Unlike existing methods, our approach introduces an expert interaction mechanism to correct samples with high predictive uncertainty and incrementally update the model accordingly, thereby optimizing its performance. First, we model the emotion recognition task as a GP-based framework, utilizing the variance of the GP to quantify the model’s uncertainty, thereby guiding experts in targeted interactions. Second, within the GP framework, we propose a novel incremental update strategy that allows the GP to incrementally update prediction results and uncertainties based only on new data obtained through expert interactions, without reprocessing all existing data. This effectively overcomes the shortcomings of traditional GP in updating efficiency. Third, to address the high computational complexity of GP, we use a sparse approximation strategy, selecting inducing points and performing variational inference to efficiently approximate the GP posterior, thereby reducing computational complexity. Subject-dependent and subject-independent experiments conducted on the DEAP and DREAMER datasets demonstrate that the proposed method exhibits significant advantages over state-of-the-art (SOTA) methods. In subject-dependent experiments, our method achieved the highest improvement (1.73%) in the Dominance dimension on the DREAMER dataset. In subject-independent experiments, it attained the largest performance improvement (2.96%) in the Arousal dimension on the DEAP dataset. These results further validate the proposed method’s effectiveness.},
  archive      = {J_IJNS},
  author       = {Xiangle Ping and Wenhui Huang},
  doi          = {10.1142/S0129065725500418},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2550041},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Interactive EEG emotion recognition with incremental gaussian processes},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An explainable connectome convolutional transformer for multimodal autism spectrum disorder classification. <em>IJNS</em>, <em>35</em>(8), 2550043. (<a href='https://doi.org/10.1142/S0129065725500431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The diagnosis of autism spectrum disorder (ASD) is often hampered by its heterogeneity and reliance on time-consuming behavioral assessments. Automated neuroimaging-based diagnostic tools offer a promising alternative, but multi-site data integration often introduces variability, hindering the achievement of accurate and interpretable results. This study presents the Connectome Convolutional Transformer (CCTF), a multimodal deep learning framework that integrates functional and structural brain connectivity information from fMRI and sMRI modalities. The CCTF enriches feature representation by incorporating diverse functional connectivity metrics and structural covariance networks based on multiple morphological properties. It employs a connectome convolutional embedding module and transformer encoder to capture and refine brain connectivity patterns. In addition, a node-to-graph pooling layer facilitates the identification of potential ASD biomarkers. Evaluation on the multi-site ABIDE dataset demonstrated that CCTF outperformed state-of-the-art methods, achieving accuracies of 8 4 . 3 % for fMRI, 7 4 . 3 % for sMRI, and 8 8 . 2 % for the ensemble fMRI+sMRI model in intra-site cross-validation. In the inter-site leave-one-site-out cross-validation, the CCTF maintained its superiority, with the ensemble model reaching 8 9 . 2 % accuracy, underscoring its robustness and generalizability across different sites. The identified brain regions are consistent with established ASD neurobiology, underscoring CCTF’s potential to advance the understanding of the neural mechanisms underlying this complex disorder.},
  archive      = {J_IJNS},
  author       = {Reza Nazari and Mostafa Salehi and Afshin Shoeibi},
  doi          = {10.1142/S0129065725500431},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2550043},
  shortjournal = {Int. J. Neural Syst.},
  title        = {An explainable connectome convolutional transformer for multimodal autism spectrum disorder classification},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic regulation of the Serotonin–Dopamine interaction within a meta-reinforcement learning framework encompassing the prefrontal cortex and basal ganglia. <em>IJNS</em>, <em>35</em>(8), 2550040. (<a href='https://doi.org/10.1142/S0129065725500406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action inhibition is essential for cognitive control, enabling individuals to prioritize relevant information over internal urges in response to changing demands. While current artificial agents excel in repetitive tasks, real-world scenarios often require the handling of unexpected constraints, such as the suppression of unwanted actions. Meta-learning, acting as an outer loop that regulates the reinforcement learning scheme in the inner loop of learning, facilitates adaptation in dynamic environments. Building upon our previous work, 1 where we implemented a brain-inspired meta-reinforcement learning framework for conflictual inhibition decision-making encompassing brain regions of the prefrontal cortex and the basal ganglia circuit and tested it within the NoGo and Stop-Signal Paradigms, this study introduces the following novelties. We explored the effects of changes in concentration and efficacy of the D 1 -mesocorticolimbic and D 2 -nigrostriatal pathways externally modulated by serotonin release on meta-reinforcement learning rules, thus the extent to which they affect behavioral performance during action cancellation within the Stop-Signal Paradigm. Our findings suggest that external serotoninergic modulation on these pathways asymmetrically affects behavioral performance, revealing that inhibitory behavior is primarily mediated by serotonin acting on D 1 dopamine receptors and is therefore asymmetrically influenced by changes in D 1 and D 2 efficacy. These pathways exhibit synergistic effects in response inhibition, with a predominant role for reductions in D 1 efficacy. Furthermore, we extended the meta-reinforcement learning framework by designing brain-inspired meta-learning rules that replicate the serotonin–dopamine dynamic interactions during action inhibition in a closed-loop fashion by using the Wilson–Cowan formalism 2 enabling a dynamic regulation of the exploration/exploitation rate β meta-parameter. Our framework generates new predictive hypotheses and provides insights about the dynamic interaction between serotonin and dopamine D 1 and D 2 , understanding their impact in response inhibition and, consequently, how they might be involved in impulsive behaviors. This knowledge suggests potential neural mechanisms underlying cognitive control in the brain and, at the same time, could contribute to the development of more flexible and robust artificial systems capable of adapting in real-world applications.},
  archive      = {J_IJNS},
  author       = {Federica Robertazzi and Matteo Vissani and Egidio Falotico},
  doi          = {10.1142/S0129065725500406},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2550040},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Dynamic regulation of the Serotonin–Dopamine interaction within a meta-reinforcement learning framework encompassing the prefrontal cortex and basal ganglia},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-order extension codes for palmprint recognition. <em>IJNS</em>, <em>35</em>(8), 2550039. (<a href='https://doi.org/10.1142/S012906572550039X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Palmprint recognition is a pivotal biometric modality, renowned for its numerous advantages and applications in the field of biometrics. The Gabor filter is a classic and efficient texture feature extractor abstracted from the nervous system. The existing palmprint texture coding methods only focus on first-order texture features (1TFs), while neglecting discriminative second-order texture features (2TFs). Therefore, this paper proposes multi-order extensions for state-of-the-art (SOTA) palmprint texture coding methods, which makes full usage of 1TFs and 2TFs. A filter is used to extract 1TFs from the palmprint image, and the same filter is applied to extract 2TFs from 1TFs. Here, different methods employ various filters to extract diverse textures. Due to the simultaneous participations of 1TFs and 2TFs in multi-order extension codes, more discriminative features are extracted and fused. The experimental results on three public databases, including contact, noncontact and multispectral acquisition types, show that the accuracies of all the palmprint texture coding methods are remarkably improved by multi-order extension, establishing it as a general framework extendable to other texture-based recognition tasks.},
  archive      = {J_IJNS},
  author       = {Fengxiang Liao and Lu Leng and Ziyuan Yang and Bob Zhang},
  doi          = {10.1142/S012906572550039X},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2550039},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Multi-order extension codes for palmprint recognition},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced graph attention network by integrating transformer for epileptic EEG identification. <em>IJNS</em>, <em>35</em>(8), 2550037. (<a href='https://doi.org/10.1142/S0129065725500376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography signal classification is essential for the diagnosis and monitoring of neurological disorders, with significant implications for patient treatment. Despite the progress made, existing methods face challenges such as capturing the complex dynamics of Electroencephalogram (EEG) signals and generalizing across diverse patient populations. In this study, the graph attention network and the transformer model are integrated for EEG signal classification, leveraging the enhanced capability to dynamically compute attention weights and adapt to the variable relevance of brain regions. The proposed approach is capable of modeling the intricate relationships within EEG activities by learning context-dependent attention scores. We conducted a comprehensive evaluation of the proposed approach comparing with the state-of-the-art algorithms. Experimental outcomes show that it surpasses the competing models. The superior performance is attributed to the proposed approach’s dynamic attention mechanism, which better captures the nuanced patterns in EEG signals across different subjects and seizure types. In the experiments, the CHB-MIT dataset was exploited, which served as a benchmark for evaluating the performance of the proposed framework in distinguishing interictal, ictal, and normal EEG patterns. The results prove the usefulness of our work in advancing EEG signal classification. The findings suggest that the combination of graph attention and self-attention mechanisms is a promising approach for improving the accuracy and reliability of EEG-based diagnostics, potentially improving the management of neurological disorders.},
  archive      = {J_IJNS},
  author       = {Zhenhua Xie and Jian Lian and Dong Wang},
  doi          = {10.1142/S0129065725500376},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2550037},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Enhanced graph attention network by integrating transformer for epileptic EEG identification},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global–Local feature fusion network based on nonlinear spiking neural convolutional model for MRI brain tumor segmentation. <em>IJNS</em>, <em>35</em>(8), 2550036. (<a href='https://doi.org/10.1142/S0129065725500364'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the differences in size, shape, and location of brain tumors, brain tumor segmentation differs greatly from that of other organs. The purpose of brain tumor segmentation is to accurately locate and segment tumors from MRI images to assist doctors in diagnosis, treatment planning and surgical navigation. NSNP-like convolutional model is a new neural-like convolutional model inspired by nonlinear spiking mechanism of nonlinear spiking neural P (NSNP) systems. Therefore, this paper proposes a global–local feature fusion network based on NSNP-like convolutional model for MRI brain tumor segmentation. To this end, we have designed three characteristic modules that take full advantage of the NSNP-like convolution model: dilated SNP module (DSNP), multi-path dilated SNP pooling module (MDSP) and Poolformer module. The DSNP and MDSP modules are employed to construct the encoders. These modules help address the issue of feature loss and enable the fusion of more high-level features. On the other hand, the Poolformer module is used in the decoder. It processes features that contain global context information and facilitates the interaction between local and global features. In addition, channel spatial attention (CSA) module is designed at the skip connection between encoder and decoder to establish the long-range dependence between the same layers, thereby enhancing the relationship between channels and making the model have global modeling capabilities. In the experiments, our model achieves Dice coefficients of 85.71 % , 92.32 % , 87.75 % for ET, WT, and TC, respectively, on the N-BraTS2021 dataset. Moreover, our model achieves Dice coefficients of 83.91 % , 91.96 % , 90.14 % and 85.05 % , 92.30 % , 90.31 % on the BraTS2018 and BraTS2019 datasets respectively. Experimental results also indicate that our model not only achieves good brain tumor segmentation performance, but also has good generalization ability. The code is already available on GitHub: https://github.com/Li-JJ-1/NSNP-brain-tumor-segmentation .},
  archive      = {J_IJNS},
  author       = {Junjie Li and Hong Peng and Bing Li and Zhicai Liu and Rikong Lugu and Bingyan He},
  doi          = {10.1142/S0129065725500364},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2550036},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Global–Local feature fusion network based on nonlinear spiking neural convolutional model for MRI brain tumor segmentation},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tiny convolutional neural network with supervised contrastive learning for epileptic seizure prediction. <em>IJNS</em>, <em>35</em>(7), 2550034. (<a href='https://doi.org/10.1142/S0129065725500340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic seizure prediction based on ElectroEncephaloGraphy (EEG) ensures the safety of patients with epilepsy and mitigates anxiety. In recent years, significant progress has been made in this field. However, the predictive performance of existing methods encounters a bottleneck that is difficult to overcome. Moreover, there are certain limitations such as significant differences in prediction efficacy among patients or intricate model structures. Given these considerations, Siamese Network (SiaNet) and Triplet Network (TriNet) are proposed based on tiny convolutional neural network and supervised contrastive learning. Short-Time Fourier Transform (STFT) is first applied to the pre-processed data. Then data tuples are constructed and fed into the networks for training. Both networks try to minimize the interval between samples of the same class while maximize the interval between samples of different classes. The two networks consist of multiple branches with shared weights, which can learn from each other via contrastive learning. Promising results are obtained on the CHB-MIT and Siena datasets, with a total of 35 patients. Meanwhile, both models have only 19.351K parameters.},
  archive      = {J_IJNS},
  author       = {Yongfeng Zhang and Hailing Feng and Shuai Wang and Hongbin Lv and Tiantian Xiao and Ziwei Wang and Yanna Zhao},
  doi          = {10.1142/S0129065725500340},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2550034},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Tiny convolutional neural network with supervised contrastive learning for epileptic seizure prediction},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolution of the motor symptoms in parkinson disease under auditory stimulation. <em>IJNS</em>, <em>35</em>(7), 2550030. (<a href='https://doi.org/10.1142/S0129065725500303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes a study that analyzes the effect of periodic binaural auditory stimulation in the beta band on two of the major motor symptoms of patients with Parkinson’s disease (PD), resting tremor and bradykinesia. Participants included two groups of PD patients ( n = 2 1 n = 2 1 n=21 , age 6 3 . 6 9 ± 7 . 4 3 6 3 . 6 9 ± 7 . 4 3 63.69±7.43 , stage 1 . 5 5 ± 0 . 5 5 1 . 5 5 ± 0 . 5 5 1.55±0.55 Hoehn & Yahr scale) that were exposed to an experimental (group A) or placebo (group B) auditory stimulation once a day, and a group of healthy controls ( n = 7 n = 7 n=7 , age 6 4 . 0 0 ± 5 . 4 5 6 4 . 0 0 ± 5 . 4 5 64.00±5.45 ) that was not exposed to any stimulation. The experimental stimulation consisted of 10 min of binaural beats at 14 Hz presented rhythmically and masked with pink noise, while the placebo stimulation consisted of pink noise only. All participants were monitored using wearable devices and mobile phones to assess the evolution of resting tremors and bradykinesia. Both indicators were obtained from accelerometer signals during the execution of specific motor tasks extracted from the MDS-UPDRS scale Part III once a week. The results show a significant difference between the group of healthy controls and PD patients for the resting tremor and bradykinesia indicators, suggesting the predictive validity of the monitoring system and the consistency of the indicators. Regarding the effect of auditory stimulation, a reduction in the level of resting tremor was observed in patients who received the experimental stimulation compared to those who received the placebo stimulation ( p = 0 . 0 0 4 ) ( p = 0 . 0 0 4 ) (p=0.004) over the course of the 8 weeks of monitoring. However, no improvement in bradykinesia was observed. The generalization of results is compromised due to a set of limitations that have been identified, so guidance is provided that might contribute to improving future experimental designs in similar studies.},
  archive      = {J_IJNS},
  author       = {David González and Luis Sigcha and Juan Manuel López and César Asensio and Ignacio Pavón and Nelson Costa and Susana Costa and Miguel Gago and Juan Carlos Martínez-Castrillo and Guillermo de Arcas},
  doi          = {10.1142/S0129065725500303},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2550030},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Evolution of the motor symptoms in parkinson disease under auditory stimulation},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding robot gesture perception in children with autism spectrum disorder during Human–Robot interaction. <em>IJNS</em>, <em>35</em>(7), 2550026. (<a href='https://doi.org/10.1142/S0129065725500261'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social robots are increasingly being used in therapeutic contexts, especially as a complement in the therapy of children with Autism Spectrum Disorder (ASD). Because of this, the aim of this study is to understand how children with ASD perceive and interpret the gestures made by the robot Pepper versus human instructor, which can also be influenced by verbal communication. This study analyzes the impact of both conditions (verbal and nonverbal communication) and types of gestures (conversational and emotional) on gesture recognition through the study of the accuracy rate and examines the physiological responses of children with the Empatica E4 device. The results reveal that verbal communication is more accessible to children with ASD and neurotypicals (NT), with emotional gestures being more interpretable than conversational gestures. The Pepper robot was found to generate lower responses of emotional arousal compared to the human instructor in both ASD and neurotypical children. This study highlights the potential of robots like Pepper to support the communication skills of children with ASD, especially in structured and predictable nonverbal gestures. However, the findings also point to challenges, such as the need for more reliable robotic communication methods, and highlight the importance of changing interventions tailored to individual needs.},
  archive      = {J_IJNS},
  author       = {Gema Benedicto-Rodríguez and Facundo Bosch and Carlos G. Juan and Maria Paula Bonomini and Antonio Fernández-Caballero and Eduardo Fernandez-Jover and Jose Manuel Ferrández-Vicente},
  doi          = {10.1142/S0129065725500261},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2550026},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Understanding robot gesture perception in children with autism spectrum disorder during Human–Robot interaction},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Electroencephalography decoding with conditional identification generator. <em>IJNS</em>, <em>35</em>(7), 2550024. (<a href='https://doi.org/10.1142/S0129065725500248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decoding Electroencephalography (EEG) signals are extremely useful for advancing and understanding human–artificial intelligence (AI) interaction systems. Recent advancements in deep neural networks (DNNs) have demonstrated significant promise in this respect due to their ability to model complex nonlinear relationships. However, DNNs face persistent challenges in addressing the inter-person variability inherent in EEG signals, which limits their generalizability. To tackle this limitation, we propose a novel framework that integrates conditional identification information, leveraging the interaction between EEG signals and individual traits to enhance the model’s internal representation and improve decoding accuracy. Building on this foundation, we further introduce a privacy-preserving conditional information generator — a generative model that derives embedding knowledge directly from raw EEG signals. This approach eliminates the need for personal identification via individual tests, ensuring both efficiency and privacy. Experimental evaluations conducted on WithMe dataset confirm that this framework outperforms baseline network architectures. Notably, our approach achieves substantial improvements in decoding accuracy for both familiar and unseen subjects, paving the way for efficient, robust, and privacy-conscious human–computer interface systems.},
  archive      = {J_IJNS},
  author       = {Pengfei Sun and Jorg De Winne and Malu Zhang and Paul Devos and Dick Botteldooren},
  doi          = {10.1142/S0129065725500248},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2550024},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Electroencephalography decoding with conditional identification generator},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient seizure detection by complementary integration of convolutional neural network and vision transformer. <em>IJNS</em>, <em>35</em>(7), 2550023. (<a href='https://doi.org/10.1142/S0129065725500236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy, as a prevalent neurological disorder, is characterized by its high incidence, sudden onset, and recurrent nature. The development of an accurate and real-time automatic seizure detection system is crucial for assisting clinicians in making precise diagnoses and providing timely treatment for epilepsy. However, conventional automatic seizure detection methods often face limitations in simultaneously capturing both local features and long-range correlations inherent in EEG signals, which constrains the accuracy of these existing detection systems. To address this challenge, we propose a novel end-to-end seizure detection framework, named CNN-ViT, which complementarily integrates a Convolutional Neural Network (CNN) for capturing local inductive bias of EEG and Vision Transformer (ViT) for further mining their long-range dependency. Initially, raw electroencephalogram (EEG) signals are filtered and segmented and then sent into the CNN-ViT model to learn their local and global feature representations and identify the seizure patterns. Meanwhile, we adopt a global max-pooling strategy to reduce the scale of the CNN-ViT model and make it focus on the most discriminative features. Given the occurrence of diverse artifacts in long-term EEG recordings, we further employ post-processing techniques to improve the seizure detection performance. The proposed CNN-ViT model, when evaluated using the publicly accessible CHB-MIT EEG dataset, reveals its outstanding performance with a sensitivity of 99.34% at a segment-based level and 99.70% at an event-based level. On the SH-SDU dataset we collected, our method yielded a segment-based sensitivity of 99.86%, specificity of 94.33%, and accuracy of 94.40%, along with an event-based sensitivity of 100%. The total processing time for 1 h EEG data was only 3.07 s. These exceptional results demonstrate the potential of our method as a reference for clinical real-time seizure detection applications.},
  archive      = {J_IJNS},
  author       = {Jiaqi Wang and Haotian Li and Chuanyu Li and Weisen Lu and Haozhou Cui and Xiangwen Zhong and Shuhao Ren and Zhida Shang and Weidong Zhou},
  doi          = {10.1142/S0129065725500236},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2550023},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Efficient seizure detection by complementary integration of convolutional neural network and vision transformer},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting intraoperative burst suppression using preoperative EEG and patient characteristics. <em>IJNS</em>, <em>35</em>(6), 2550033. (<a href='https://doi.org/10.1142/S0129065725500339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Burst suppression (BS) is an electroencephalogram (EEG) pattern observed in patients undergoing general anesthesia. The occurrence of BS is associated with adverse outcomes such as postoperative delirium, extended recovery time, and increased postoperative mortality. The detection and prediction of BS can help expedite the evaluation of patient conditions, optimize anesthesia administration, and improve patient safety. This study explores the potential for automatic BS detection using intraoperative EEG and BS prediction using preoperative EEG signals and patient characteristics. A dataset comprising 287 patients who underwent carotid endarterectomy procedures at Maastricht University Medical Center+ was analyzed. An EEG toolbox developed by T. Zhan at the Massachusetts Institute of Technology was utilized for the automatic detection/annotation of BS, while five machine learning classifiers were employed to predict BS occurrence using preoperative data. Based on the 160 patients manually annotated by EEG experts (regarding the presence or absence of BS), the automatic detection tool demonstrated an accuracy of 0.75. For the BS prediction task, an initial subset of 120 patients was evaluated, showing modest performance, with the K -nearest neighbors ( K = 7 ) classifier achieving the best results, with an accuracy of 0.72. Subsequent experiments indicated that increasing the number of patients (by using Zhan’s Toolbox to annotate the unlabeled instances), applying SMOTE to balance the training set, and enriching the feature set was beneficial. The final experiment demonstrated a significant improvement, with Random Forest and Gradient Boosting outperforming other classifiers, achieving an accuracy of 0.86 and ROC–AUC of 0.94. Patient characteristics, including type of anesthetic agents, symptoms, age, mean absolute delta power, mean absolute theta power, and cognitive impairment, were identified by an xAI method as important features potentially indicating the predisposition to experience BS.},
  archive      = {J_IJNS},
  author       = {Jingyi He and Joël M. H. Karel and Marcus L. F. Janssen and Erik D. Gommer and Catherine J. Vossen and Enrique Hortal},
  doi          = {10.1142/S0129065725500339},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2550033},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Predicting intraoperative burst suppression using preoperative EEG and patient characteristics},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Directed weighted EEG connectogram insights of one-to-one causality for identifying developmental dyslexia. <em>IJNS</em>, <em>35</em>(6), 2550032. (<a href='https://doi.org/10.1142/S0129065725500327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developmental dyslexia (DD) affects approximately 5–12% of learners, posing persistent challenges in reading and writing. This study presents a novel electroencephalography (EEG)-based methodology for identifying DD using two auditory stimuli modulated at 4.8 Hz (prosodic) and 40 Hz (phonemic). EEG signals were processed to estimate one-to-one Granger causality, yielding directed and weighted connectivity matrices. A novel Mutually Informed Correlation Coefficient (MICC) feature selection method was employed to identify the most relevant causal links, which were visualized using connectograms. Under the 4.8 Hz stimulus, altered theta-band connectivity between frontal and occipital regions indicated compensatory frontal activation for prosodic processing and visual–auditory integration difficulties, while gamma-band anomalies between occipital and temporal regions suggested impaired visual–prosodic integration. Classification analysis under the 4.8 Hz stimulus yielded area under the ROC curve (AUC) values of 0.92 (theta) and 0.91 (gamma band). Under the 40 Hz stimulus, theta abnormalities reflected dysfunctions in integrating auditory phoneme signals with executive and motor regions, and gamma alterations indicated difficulties coordinating visual and auditory inputs for phonological decoding, with AUC values of 0.84 (theta) and 0.89 (gamma). These results support both the Temporal Sampling Framework and the Phonological Core Deficit Hypothesis. Future research should extend the range of stimuli frequencies and include more diverse cohorts to further validate these potential biomarkers.},
  archive      = {J_IJNS},
  author       = {Ignacio Rodríguez-Rodríguez and José Ignacio Mateo-Trujillo and Andrés Ortiz and Nicolás J. Gallego-Molina and Diego Castillo-Barnes and Juan L. Luque},
  doi          = {10.1142/S0129065725500327},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2550032},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Directed weighted EEG connectogram insights of one-to-one causality for identifying developmental dyslexia},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neuronal waveform classification in multielectrode recordings using machine learning techniques and multidimensional analysis. <em>IJNS</em>, <em>35</em>(6), 2550031. (<a href='https://doi.org/10.1142/S0129065725500315'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracellular recordings of neuronal spikes are crucial for studying brain activity. These signals are typically classified based on firing patterns and waveform shape, particularly trough-to-peak duration. While useful, this method oversimplifies the diversity of cortical neurons and discharge patterns. Recent advances in recording and analysis techniques allow for more precise waveform classification, though the main criteria remain waveform features. We aim to develop an automatic spike waveform classifier using advanced machine learning techniques selected from a range of candidate methods based on their optimized performance, such as Uniform Manifold Approximation and Projection (UMAP), Gaussian Mixture Model (GMM), and Random Forest (RF). The classifier is part of the working progress of a preprocessing pipeline previously developed. For the classifying step, we use all voltage samples that define each waveform, enabling a multi-dimensional analysis. To evaluate our approach, RF model was trained and tested on a subset of electrophysiological recordings from the human visual cortex achieving high F 1 -scores. The comparison of the classified neurons was carried out between our method and a waveform analysis toolbox described in the literature. Our method improves the characterization of the clusters of waveforms based on statistical measurements that found a third group while the accepted method categorizes just broad and narrow waveforms, labeling some as unclassifiable.},
  archive      = {J_IJNS},
  author       = {Rocío López-Peco and Mikel Val-Calvo and Cristina Soto-Sánchez and Adrián Villamarin-Ortiz and Gloria Ruiz-Boix and José Manuel Ferrández-Vicente and Eduardo Fernández},
  doi          = {10.1142/S0129065725500315},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2550031},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Neuronal waveform classification in multielectrode recordings using machine learning techniques and multidimensional analysis},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing laryngeal neuromotor activity from phonation. <em>IJNS</em>, <em>35</em>(6), 2550029. (<a href='https://doi.org/10.1142/S0129065725500297'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurodegenerative motor disorders affect the neuromuscular system challenging daily life and normal activity. Parkinson’s Disease (PD) is among the most prevalent ones, with a large impact and rising prevalence rates. Speech is most affected by PD as far as phonatory and articulatory performance is concerned. Neuromotor activity (NMA) alterations have an impact on larynx muscles responsible for vocal fold adduction and abduction, hampering phonation stability and regularity. The main muscular articulators involved in phonation control are the cricothyroid (tensor) and thyroarytenoid (relaxer) systems, regulated by two distinct direct neuromotor pathways, activated by the precentral gyrus laryngeal control areas. These articulations control the musculus vocalis , directly responsible for regular vocal fold vibration. An indirect estimation of the muscular tension produced by inverse filtering may split into two independent channels, assumed to be the tensor and relaxer neuromotor pathways such as the differential neuromotor activity (DNMA). The amplitude distributions of both DNMA channels allow comparing phonations from PD-affected persons (PDPs) and age-matched healthy control participants (HCPs) with respect to a set of reference mid-age normative participants (RSPs). The comparisons are carried out by Jensen–Shannon distributions of PDP and HCP phonations with respect to those of RSPs. A dataset of 96 phonation samples from participants balanced by gender is used to train a set of decision tree classifiers (DTCs) to distinguish PDP from HCP phonation. The best results from 10-fold cross-validation offered accumulated mismatches of 0.09 and 0.1292 for male and female subsets. The sensitivity, specificity, and accuracy of the classification results when separating PDP from HCP phonatios were 93.33%, 88.23%, and 90.63% (male PDP versus HCP) and 92.86%, 83.33%, and 87.50% (female PDP versus HCP), providing a stratification of PDPs and HCPs by objective disease grading from explainable AI (XAI) methods.},
  archive      = {J_IJNS},
  author       = {Pedro Gómez-Vilda and Andrés Gómez-Rodellar and Jiři Mekyska and Agustín Álvarez-Marquina and Daniel Palacios-Alonso and Irena Rektorová},
  doi          = {10.1142/S0129065725500297},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2550029},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Assessing laryngeal neuromotor activity from phonation},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal integration of EEG and near-infrared spectroscopy for robust cross-frequency coupling estimation. <em>IJNS</em>, <em>35</em>(6), 2550028. (<a href='https://doi.org/10.1142/S0129065725500285'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuroimaging techniques have had a major impact on medical science, allowing advances in the research of many neurological diseases and improving their diagnosis. In this context, multimodal neuroimaging approaches, based on the neurovascular coupling phenomenon, exploit their individual strengths to provide complementary information on the neural activity of the brain cortex. This work proposes a novel method for combining electroencephalography (EEG) and functional near–infrared spectroscopy (fNIRS) to explore the functional activity of the brain processes related to low-level language processing of skilled and dyslexic seven-year-old readers. We have transformed EEG signals into image sequences considering the interaction between different frequency bands by means of cross-frequency coupling (CFC), and applied an activation mask sequence obtained from the local functional brain activity inferred from simultaneously recorded fNIRS signals. Thus, the resulting image sequences preserve spatial and temporal information of the communication and interaction between different neural processes and provide discriminative information that allows differentiation between controls and dyslexic subjects with an AUC of 77.1%. Finally, explainability is improved by introducing an easily comprehensible representation of the SHAP values obtained for the classification method in the brainSHAP maps.},
  archive      = {J_IJNS},
  author       = {Nicolás J. Gallego-Molina and Andrés Ortiz and Francisco J. Martínez-Murcia and Wai Lok Woo},
  doi          = {10.1142/S0129065725500285},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2550028},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Multimodal integration of EEG and near-infrared spectroscopy for robust cross-frequency coupling estimation},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continual learning by contrastive learning of regularized classes in multivariate gaussian distributions. <em>IJNS</em>, <em>35</em>(6), 2550025. (<a href='https://doi.org/10.1142/S012906572550025X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks struggle with incremental updates due to catastrophic forgetting, where newly acquired knowledge interferes with the learned previously. Continual learning (CL) methods aim to overcome this limitation by effectively updating the model without losing previous knowledge, but they find it difficult to continuously maintain knowledge about previous tasks, resulting from overlapping stored information. In this paper, we propose a CL method that preserves previous knowledge as multivariate Gaussian distributions by independently storing the model’s outputs per class and continually reproducing them for future tasks. We enhance the discriminability between classes and ensure the plasticity for future tasks by exploiting contrastive learning and representation regularization. The class-wise spatial means and covariances, distinguished in the latent space, are stored in memory, where the previous knowledge is effectively preserved and reproduced for incremental tasks. Extensive experiments on benchmark datasets such as CIFAR-10, CIFAR-100, and ImageNet-100 demonstrate that the proposed method achieves accuracies of 93.21%, 77.57%, and 78.15%, respectively, outperforming state-of-the-art CL methods by 2.34 %p, 2.1 %p, and 1.91 %p. Additionally, it achieves the lowest mean forgetting rates across all datasets.},
  archive      = {J_IJNS},
  author       = {Hyung-Jun Moon and Sung-Bae Cho},
  doi          = {10.1142/S012906572550025X},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2550025},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Continual learning by contrastive learning of regularized classes in multivariate gaussian distributions},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Introduction. <em>IJNS</em>, <em>35</em>(6), 2502002. (<a href='https://doi.org/10.1142/S0129065725020022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJNS},
  author       = {José Manuel Ferrández},
  doi          = {10.1142/S0129065725020022},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2502002},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Introduction},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive dynamic surface control of epileptor model based on nonlinear luenberger state observer. <em>IJNS</em>, <em>35</em>(5), 2550022. (<a href='https://doi.org/10.1142/S0129065725500224'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is a prevalent neurological disorder characterized by recurrent seizures, which are sudden bursts of electrical activity in the brain. The Epileptor model is a computational model specifically created to replicate the complex dynamics of epileptic seizures. The parameters of the Epileptor model can be adjusted to simulate activities associated with some seizure classes seen in patients. Due to the closeness of this model to nonlinear systems with nonstrict feedback form and the existence of uncertainties in the model, an adaptive dynamic surface controller is chosen for control of the system. Considering that the states in the Epileptor model are not measurable and the only measurable output is the Local Field Potentials signal, a nonlinear Luenberger state observer is developed to estimate the system states. It is the first time that the Luenberger state observer is used for the Epileptor model. In this approach, Radial Basis Neural Networks are utilized to estimate the system’s nonlinear dynamics. The stability of our proposed controller along with the observer is proved, and the performance is shown using simulation. Simulation results show that by using the suggested method, the output and states of the, system track their reference, value with an acceptable error.},
  archive      = {J_IJNS},
  author       = {Mahdi Kamali Dolatabadi and Marzieh Kamali and Farzaneh Shayegh},
  doi          = {10.1142/S0129065725500224},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2550022},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Adaptive dynamic surface control of epileptor model based on nonlinear luenberger state observer},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coherence-based graph convolution network to assess brain reorganization in spinal cord injury patients. <em>IJNS</em>, <em>35</em>(5), 2550021. (<a href='https://doi.org/10.1142/S0129065725500212'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motor imagery (MI) engages a broad network of brain regions to imagine a specific action. Investigating the mechanism of brain network reorganization during MI after spinal cord injury (SCI) is crucial because it reflects overall brain activity. Using electroencephalogram (EEG) data from SCI patients, we conducted EEG-based coherence analysis to examine different brain network reorganizations across different frequency bands, from resting to MI. Furthermore, we introduced a consistency calculation-based residual graph convolution (C-ResGCN) classification algorithm. The results show that the α - and β -band connectivity weakens, and brain activity decreases during the MI task compared to the resting state. In contrast, the γ -band connectivity increases in motor regions while the default mode network activity declines during MI. Our C-ResGCN algorithm showed excellent performance, achieving a maximum classification accuracy of 96.25%, highlighting its reliability and stability. These findings suggest that brain reorganization in SCI patients reallocates relevant brain resources from the resting state to MI, and effective network reorganization correlates with improved MI performance. This study offers new insights into the mechanisms of MI and potential biomarkers for evaluating rehabilitation outcomes in patients with SCI.},
  archive      = {J_IJNS},
  author       = {Jiancai Leng and Jiaqi Zhao and Yongjian Wu and Chengyan Lv and Zhixiao Lun and Yanzi Li and Chao Zhang and Bin Zhang and Yang Zhang and Fangzhou Xu and Changsong Yi and Tzyy-Ping Jung},
  doi          = {10.1142/S0129065725500212},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2550021},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Coherence-based graph convolution network to assess brain reorganization in spinal cord injury patients},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scene text detection based on text stroke components. <em>IJNS</em>, <em>35</em>(5), 2550020. (<a href='https://doi.org/10.1142/S0129065725500200'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of scene text holds significant importance across a variety of application scenarios. However, previous methods were insufficient for detecting and recognizing text instances, such as variations in text size, chaotic background and diverse text orientations. To address these challenges, this paper proposes a novel methodology based on Text Stroke Components (TSC). The method leverages Harris corner detection to identify critical points of text strokes, such as endpoints, turning points, and curvatures. By analyzing the clustered regions of these points, the approach effectively localizes text characters. To enhance the detection process, a transparency parameter α is introduced to control the fusion between original images and corner-detection images. This improves the localization of key stroke points, and reduces background noise interference. The proposed method is evaluated through extensive experiments, demonstrating superior performance compared to existing scene text detectors. Furthermore, the method is jointly trained with the ABINet recognition model across all stages. Comprehensive experiments conducted on 13 datasets reveal that this approach significantly outperforms SOTA methods. These results underscore the advantages of using text stroke components for key-point localization through the corner detection algorithm in scene text detection.},
  archive      = {J_IJNS},
  author       = {Xinyue Hou and Pengsen Cheng and Hongyu Gao and Xin Li and Jiayong Liu},
  doi          = {10.1142/S0129065725500200},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2550020},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Scene text detection based on text stroke components},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A heterogeneous attractor model for neural dynamical mechanism of movement preparation. <em>IJNS</em>, <em>35</em>(5), 2550019. (<a href='https://doi.org/10.1142/S0129065725500194'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preparatory activity is crucial for voluntary motor control, reducing reaction time and enhancing precision. To understand the neurodynamic mechanisms behind this, we construct a dynamical model within the motor cortex, which comprises coupled heterogeneous attractors to simulate delayed reaching tasks. This model replicates the neural activity patterns observed in the macaque motor cortex, within distinct attractor spaces for preparatory and executive activities. It can capture the transition from preparation to execution through shifts in an orthogonal subspace combined with a thresholding mechanism. Results show that the preparation duration modulates behavioral accuracy, with optimal preparation intervals enhancing performance. External inputs primarily shape the preparatory activity, while synaptic connections dominate execution. Our analysis of the network’s multi-stable dynamics reveals that external inputs reshape the stable points of the heterogeneous attractor modules both before and after preparation, while synaptic strength affects dynamical stability and input sensitivity, allowing rapid and precise actions. Additionally, sensitivity to external perturbations decreases as preparatory time increases, emphasizing the importance of external inputs during preparation. Overall, this study provides insights into the neurodynamic mechanisms underlying the transition from motor preparation to execution and underscores the significance of preparatory activity for accurate motor control.},
  archive      = {J_IJNS},
  author       = {Lining Yin and Lanyun Cui and Ying Yu and Qingyun Wang},
  doi          = {10.1142/S0129065725500194},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2550019},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A heterogeneous attractor model for neural dynamical mechanism of movement preparation},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding the spatio-temporal coupling of spikes and spindles in focal epilepsy through a network-level computational model. <em>IJNS</em>, <em>35</em>(5), 2550018. (<a href='https://doi.org/10.1142/S0129065725500182'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The electrophysiological findings have shown that epileptiform spikes triggering sleep spindles within 1 s across multiple channels are commonly observed during sleep in focal epilepsy (FE). Such spatio-temporal couplings of spikes and spindles (STCSSs) are defined as a kind of pathological waves, and frequent emergence of them may cause the degradation of cognitive function for FE patients. However, the neural mechanisms underlying STCSSs are not well understood. To this end, this work first develops a neural mass network model for focal epilepsy (FE-NMNM) with multiple thalamocortical columns being its nodes and the long-range synaptic interactions of thalamocortical columns being its edges, where each thalamocortical column is extended on the basis of Costa model and then they are connected through excitatory synapses between pyramidal cells. Then, how the cortico-cortical connectivity affects the evolution of STCSSs across the network is especially discussed by simulations in two cases, where the inter-ictal state and the ictal state are considered separately. Simulation results demonstrate that: (1) the more STCSSs occur in a more extensive area when the cortico-cortical connectivity becomes stronger, and the significant increase of coupling discharges is attributed to the presence of abundant spikes; (2) when the connectivity is excessively strong, the cortical hyperexcitability will happen, thereby inducing massive spike discharges which may further inhibit the occurrence of spindles, and hence, resulting in the disappearance of STCSSs. The obtained results provide a mechanistic insight into STCSSs, and suggest that such coupling patterns could reflect widespread network dysfunction in FE, thereby potentially advancing therapeutic strategies for FE.},
  archive      = {J_IJNS},
  author       = {Min Pan and Qiang Li and Jiangling Song and Bo Wang and Wenhua Wang and Rui Zhang},
  doi          = {10.1142/S0129065725500182},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2550018},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Understanding the spatio-temporal coupling of spikes and spindles in focal epilepsy through a network-level computational model},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised image segmentation using meta-learning and multi-backbone feature fusion. <em>IJNS</em>, <em>35</em>(5), 2550012. (<a href='https://doi.org/10.1142/S0129065725500121'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot segmentation (FSS) aims to reduce the need for manual annotation, which is both expensive and time-consuming. While FSS enhances model generalization to new concepts with only limited test samples, it still relies on a substantial amount of labeled training data for base classes. To address these issues, we propose a multi-backbone few shot segmentation (MBFSS) method. This self-supervised FSS technique utilizes unsupervised saliency for pseudo-labeling, allowing the model to be trained on unlabeled data. In addition, it integrates features from multiple backbones (ResNet, ResNeXt, and PVT v2) to generate a richer feature representation than a single backbone. Through extensive experimentation on PASCAL-5i and COCO-20i, our method achieves 54.3% and 25.1% on one-shot segmentation, exceeding the baseline methods by 13.5% and 4%, respectively. These improvements significantly enhance the model’s performance in real-world applications with negligible labeling effort.},
  archive      = {J_IJNS},
  author       = {Muhammad Shahroz Ajmal and Guohua Geng and Xiaofeng Wang and Mohsin Ashraf},
  doi          = {10.1142/S0129065725500121},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2550012},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Self-supervised image segmentation using meta-learning and multi-backbone feature fusion},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-user confidence in artificial intelligence-based predictions applied to biomedical data. <em>IJNS</em>, <em>35</em>(4), 2550017. (<a href='https://doi.org/10.1142/S0129065725500170'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applications of Artificial Intelligence (AI) are revolutionizing biomedical research and healthcare by offering data-driven predictions that assist in diagnoses. Supervised learning systems are trained on large datasets to predict outcomes for new test cases. However, they typically do not provide an indication of the reliability of these predictions, even though error estimates are integral to model development. Here, we introduce a novel method to identify regions in the feature space that diverge from training data, where an AI model may perform poorly. We utilize a compact precompiled structure that allows for fast and direct access to confidence scores in real time at the point of use without requiring access to the training data or model algorithms. As a result, users can determine when to trust the AI model’s outputs, while developers can identify where the model’s applicability is limited. We validate our approach using simulated data and several biomedical case studies, demonstrating that our approach provides fast confidence estimates ( < 0 . 2 milliseconds per case), with high concordance to previously developed methods ( f - score > 0 . 9 6 5 ). These estimates can be easily added to real-world AI applications. We argue that providing confidence estimates should be a standard practice for all AI applications in public use.},
  archive      = {J_IJNS},
  author       = {Zvi Kam and Lorenzo Peracchio and Giovanna Nicora},
  doi          = {10.1142/S0129065725500170},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550017},
  shortjournal = {Int. J. Neural Syst.},
  title        = {End-user confidence in artificial intelligence-based predictions applied to biomedical data},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Minimal neural network conditions for encoding future interactions. <em>IJNS</em>, <em>35</em>(4), 2550016. (<a href='https://doi.org/10.1142/S0129065725500169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Space and time are fundamental attributes of the external world. Deciphering the brain mechanisms involved in processing the surrounding environment is one of the main challenges in neuroscience. This is particularly defiant when situations change rapidly over time because of the intertwining of spatial and temporal information. However, understanding the cognitive processes that allow coping with dynamic environments is critical, as the nervous system evolved in them due to the pressure for survival. Recent experiments have revealed a new cognitive mechanism called time compaction. According to it, a dynamic situation is represented internally by a static map of the future interactions between the perceived elements (including the subject itself). The salience of predicted interactions (e.g. collisions) over other spatiotemporal and dynamic attributes during the processing of time-changing situations has been shown in humans, rats, and bats. Motivated by this ubiquity, we study an artificial neural network to explore its minimal conditions necessary to represent a dynamic stimulus through the future interactions present in it. We show that, under general and simple conditions, the neural activity linked to the predicted interactions emerges to encode the perceived dynamic stimulus. Our results show that this encoding improves learning, memorization and decision making when dealing with stimuli with impending interactions compared to no-interaction stimuli. These findings are in agreement with theoretical and experimental results that have supported time compaction as a novel and ubiquitous cognitive process.},
  archive      = {J_IJNS},
  author       = {Sergio Diez-Hermano and Gonzalo Aparicio-Rodriguez and Paloma Manubens and Abel Sanchez-Jimenez and Carlos Calvo-Tapia and David Levcik and José Antonio Villacorta-Atienza},
  doi          = {10.1142/S0129065725500169},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550016},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Minimal neural network conditions for encoding future interactions},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-assisted local attention in lower layers of visual transformers. <em>IJNS</em>, <em>35</em>(4), 2550015. (<a href='https://doi.org/10.1142/S0129065725500157'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since vision transformers excel at establishing global relationships between features, they play an important role in current vision tasks. However, the global attention mechanism restricts the capture of local features, making convolutional assistance necessary. This paper indicates that transformer-based models can attend to local information without using convolutional blocks, similar to convolutional kernels, by employing a special initialization method. Therefore, this paper proposes a novel hybrid multi-scale model called Frequency-Assisted Local Attention Transformer (FALAT). FALAT introduces a Frequency-Assisted Window-based Positional Self-Attention (FWPSA) module that limits the attention distance of query tokens, enabling the capture of local contents in the early stage. The information from value tokens in the frequency domain enhances information diversity during self-attention computation. Additionally, the traditional convolutional method is replaced with a depth-wise separable convolution to downsample in the spatial reduction attention module for long-distance contents in the later stages. Experimental results demonstrate that FALAT-S achieves 83.0% accuracy on IN-1k with an input size of 2 2 4 × 2 2 4 using 29.9 M parameters and 5.6 G FLOPs. This model outperforms the Next-ViT-S by 0.9 AP b /0.8 AP m with Mask-R-CNN 1 × on COCO and surpasses the recent FastViT-SA36 by 3.1% mIoU with FPN on ADE20k.},
  archive      = {J_IJNS},
  author       = {Xin Zhou and Zeyu Jiang and Shihua Zhou and Zhaohui Ren and Yongchao Zhang and Tianzhuang Yu and Yulin Liu},
  doi          = {10.1142/S0129065725500157},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550015},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Frequency-assisted local attention in lower layers of visual transformers},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online and cross-user finger movement pattern recognition by decoding neural drive information from surface electromyogram. <em>IJNS</em>, <em>35</em>(4), 2550014. (<a href='https://doi.org/10.1142/S0129065725500145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-user variability is a well-known challenge that leads to severe performance degradation and impacts the robustness of practical myoelectric control systems. To address this issue, a novel method for myoelectric recognition of finger movement patterns is proposed by incorporating a neural decoding approach with unsupervised domain adaption (UDA) learning. In our method, the neural decoding approach is implemented by extracting microscopic features characterizing individual motor unit (MU) activities obtained from a two-stage online surface electromyogram (SEMG) decomposition. A specific deep learning model is designed and initially trained using labeled data from a set of existing users. The model can update adaptively when recognizing the movement patterns of a new user. The final movement pattern was determined by a fuzzy weighted decision strategy. SEMG signals were collected from the finger extensor muscles of 15 subjects to detect seven dexterous finger-movement patterns. The proposed method achieved a movement pattern recognition accuracy of ( 9 3 . 9 4 ± 1 . 5 4 )% over seven movements under cross-user testing scenarios, much higher than that of the conventional methods using global SEMG features. Our study presents a novel robust myoelectric pattern recognition approach at a fine-grained MU level, with wide applications in neural interface and prosthesis control.},
  archive      = {J_IJNS},
  author       = {Haowen Zhao and Yunfei Liu and Xinhui Li and Xiang Chen and Xu Zhang},
  doi          = {10.1142/S0129065725500145},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550014},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Online and cross-user finger movement pattern recognition by decoding neural drive information from surface electromyogram},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Architecture knowledge distillation for evolutionary generative adversarial network. <em>IJNS</em>, <em>35</em>(4), 2550013. (<a href='https://doi.org/10.1142/S0129065725500133'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) are effective for image generation, but their unstable training limits broader applications. Additionally, neural architecture search (NAS) for GANs with one-shot models often leads to insufficient subnet training, where subnets inherit weights from a supernet without proper optimization, further degrading performance. To address both issues, we propose Architecture Knowledge Distillation for Evolutionary GAN (AKD-EGAN). AKD-EGAN operates in two stages. First, architecture knowledge distillation (AKD) is used during supernet training to efficiently optimize subnetworks and accelerate learning. Second, a multi-objective evolutionary algorithm (MOEA) searches for optimal subnet architectures, ensuring efficiency by considering multiple performance metrics. This approach, combined with a strategy for architecture inheritance, enhances GAN stability and image quality. Experiments show that AKD-EGAN surpasses state-of-the-art methods, achieving a Fréchet Inception Distance (FID) of 7.91 and an Inception Score (IS) of 8.97 on CIFAR-10, along with competitive results on STL-10 (FID: 20.32, IS: 10.06). Code and models will be available at https://github.com/njit-ly/AKD-EGAN .},
  archive      = {J_IJNS},
  author       = {Yu Xue and Yan Lin and Ferrante Neri},
  doi          = {10.1142/S0129065725500133},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550013},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Architecture knowledge distillation for evolutionary generative adversarial network},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autism spectrum disorder detection using prominent connectivity features from electroencephalography. <em>IJNS</em>, <em>35</em>(3), 2550011. (<a href='https://doi.org/10.1142/S012906572550011X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism Spectrum Disorder (ASD) is a disorder of brain growth with great variability whose clinical presentation initially shows up during early stages or youth, and ASD follows a repetitive pattern of behavior in most cases. Accurate diagnosis of ASD has been difficult in clinical practice as there is currently no valid indicator of ASD. Since ASD is regarded as a neurodevelopmental disorder, brain signals specially electroencephalography (EEG) are an effective method for detecting ASD. Therefore, this research aims at developing a method of extracting features from EEG signal for discriminating between ASD and control subjects. This study applies six prominent connectivity features, namely Cross Correlation (XCOR), Phase Locking Value (PLV), Pearson’s Correlation Coefficient (PCC), Mutual Information (MI), Normalized Mutual Information (NMI) and Transfer Entropy (TE), for feature extraction. The Connectivity Feature Maps (CFMs) are constructed and used for classification through Convolutional Neural Network (CNN). As CFMs contain spatial information, they are able to distinguish ASD and control subjects better than other features. Rigorous experimentation has been performed on the EEG datasets collected from Italy and Saudi Arabia according to different criteria. MI feature shows the best result for categorizing ASD and control participants with increased sample size and segmentation.},
  archive      = {J_IJNS},
  author       = {Zahrul Jannat Peya and Mahfuza Akter Maria and Sk Imran Hossain and M. A. H. Akhand and Nazmul Siddique},
  doi          = {10.1142/S012906572550011X},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550011},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Autism spectrum disorder detection using prominent connectivity features from electroencephalography},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label zero-shot learning via contrastive label-based attention. <em>IJNS</em>, <em>35</em>(3), 2550010. (<a href='https://doi.org/10.1142/S0129065725500108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label zero-shot learning (ML-ZSL) strives to recognize all objects in an image, regardless of whether they are present in the training data. Recent methods incorporate an attention mechanism to locate labels in the image and generate class-specific semantic information. However, the attention mechanism built on visual features treats label embeddings equally in the prediction score, leading to severe semantic ambiguity. This study focuses on efficiently utilizing semantic information in the attention mechanism. We propose a contrastive label-based attention method (CLA) to associate each label with the most relevant image regions. Specifically, our label-based attention, guided by the latent label embedding, captures discriminative image details. To distinguish region-wise correlations, we implement a region-level contrastive loss. In addition, we utilize a global feature alignment module to identify labels with general information. Extensive experiments on two benchmarks, NUS-WIDE and Open Images, demonstrate that our CLA outperforms the state-of-the-art methods. Especially under the ZSL setting, our method achieves 2.0% improvements in mean Average Precision (mAP) for NUS-WIDE and 4.0% for Open Images compared with recent methods.},
  archive      = {J_IJNS},
  author       = {Shixuan Meng and Rongxin Jiang and Xiang Tian and Fan Zhou and Yaowu Chen and Junjie Liu and Chen Shen},
  doi          = {10.1142/S0129065725500108},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550010},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Multi-label zero-shot learning via contrastive label-based attention},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unraveling the differential efficiency of dorsal and ventral pathways in visual semantic decoding. <em>IJNS</em>, <em>35</em>(3), 2550009. (<a href='https://doi.org/10.1142/S0129065725500091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual semantic decoding aims to extract perceived semantic information from the visual responses of the human brain and convert it into interpretable semantic labels. Although significant progress has been made in semantic decoding across individual visual cortices, studies on the semantic decoding of the ventral and dorsal cortical visual pathways remain limited. This study proposed a graph neural network (GNN)-based semantic decoding model on a natural scene dataset (NSD) to investigate the decoding differences between the dorsal and ventral pathways in process various parts of speech, including verbs, nouns, and adjectives. Our results indicate that the decoding accuracies for verbs and nouns with motion attributes were significantly higher for the dorsal pathway as compared to those for the ventral pathway. Comparative analyses reveal that the dorsal pathway significantly outperformed the ventral pathway in terms of decoding performance for verbs and nouns with motion attributes, with evidence showing that this superiority largely stemmed from higher-level visual cortices rather than lower-level ones. Furthermore, these two pathways appear to converge in their heightened sensitivity toward semantic content related to actions. These findings reveal unique visual neural mechanisms through which the dorsal and ventral cortical pathways segregate and converge when processing stimuli with different semantic categories.},
  archive      = {J_IJNS},
  author       = {Wei Huang and Ying Tang and Sizhuo Wang and Jingpeng Li and Kaiwen Cheng and Hongmei Yan},
  doi          = {10.1142/S0129065725500091},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550009},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Unraveling the differential efficiency of dorsal and ventral pathways in visual semantic decoding},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel state space model with dynamic graphic neural network for EEG event detection. <em>IJNS</em>, <em>35</em>(3), 2550008. (<a href='https://doi.org/10.1142/S012906572550008X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) is a widely used physiological signal to obtain information of brain activity, and its automatic detection holds significant research importance, which saves doctors’ time, improves detection efficiency and accuracy. However, current automatic detection studies face several challenges: large EEG data volumes require substantial time and space for data reading and model training; EEG’s long-term dependencies test the temporal feature extraction capabilities of models; and the dynamic changes in brain activity and the non-Euclidean spatial structure between electrodes complicate the acquisition of spatial information. The proposed method uses range-EEG (rEEG) to extract time-frequency features from EEG to reduce data volume and resource consumption. Additionally, the next-generation state-space model Mamba is utilized as a temporal feature extractor to effectively capture the temporal information in EEG data. To address the limitations of state space models (SSMs) in spatial feature extraction, Mamba is combined with Dynamic Graph Neural Networks, creating an efficient model called DG-Mamba for EEG event detection. Testing on seizure detection and sleep stage classification tasks showed that the proposed method improved training speed by 10 times and reduced memory usage to less than one-seventh of the original data while maintaining superior performance. On the TUSZ dataset, DG-Mamba achieved an AUROC of 0.931 for seizure detection and in the sleep stage classification task, the proposed model surpassed all baselines.},
  archive      = {J_IJNS},
  author       = {Xinying Li and Shengjie Yan and Yonglin Wu and Chenyun Dai and Yao Guo},
  doi          = {10.1142/S012906572550008X},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550008},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A novel state space model with dynamic graphic neural network for EEG event detection},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the versatility of spiking neural networks: Applications across diverse scenarios. <em>IJNS</em>, <em>35</em>(3), 2550007. (<a href='https://doi.org/10.1142/S0129065725500078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last few decades, Artificial Neural Networks have become more and more important, evolving into a powerful tool to implement learning algorithms. Spiking neural networks represent the third generation of Artificial Neural Networks; they have earned growing significance due to their remarkable achievements in pattern recognition, finding extensive utility across diverse domains such as e.g. diagnostic medicine. Usually, Spiking Neural Networks are slightly less accurate than other Artificial Neural Networks, but they require a reduced amount of energy to perform calculations; this amount of energy further reduces in a very significant manner if they are implemented on hardware specifically designed for them, like neuromorphic hardware. In this work, we focus on exploring the versatility of Spiking Neural Networks and their potential applications across a range of scenarios by exploiting their adaptability and dynamic processing capabilities, which make them suitable for various tasks. A first rough network is designed based on the dataset’s general attributes; the network is then refined through an extensive grid search algorithm to identify the optimal values for hyperparameters. This dual-step process ensures that the Spiking Neural Network can be tailored to diverse and potentially very different situations in a direct and intuitive manner. We test this by considering three different scenarios: epileptic seizure detection, both considering binary and multi-classification tasks, as well as wine classification. The proposed methodology turned out to be highly effective in binary class scenarios: the Spiking Neural Networks models achieved significantly lower energy consumption compared to Artificial Neural Networks while approaching nearly 100% accuracy. In the case of multi-class classification, the model achieved an accuracy of approximately 90%, thus indicating that it can still be further improved.},
  archive      = {J_IJNS},
  author       = {Matteo Cavaleri and Claudio Zandron},
  doi          = {10.1142/S0129065725500078},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550007},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Exploring the versatility of spiking neural networks: Applications across diverse scenarios},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A context-dependent CNN-based framework for multiple sclerosis segmentation in MRI. <em>IJNS</em>, <em>35</em>(3), 2550006. (<a href='https://doi.org/10.1142/S0129065725500066'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite several automated strategies for identification/segmentation of Multiple Sclerosis (MS) lesions in Magnetic Resonance Imaging (MRI) being developed, they consistently fall short when compared to the performance of human experts. This emphasizes the unique skills and expertise of human professionals in dealing with the uncertainty resulting from the vagueness and variability of MS, the lack of specificity of MRI concerning MS, and the inherent instabilities of MRI. Physicians manage this uncertainty in part by relying on their radiological, clinical, and anatomical experience. We have developed an automated framework for identifying and segmenting MS lesions in MRI scans by introducing a novel approach to replicating human diagnosis, a significant advancement in the field. This framework has the potential to revolutionize the way MS lesions are identified and segmented, being based on three main concepts: (1) Modeling the uncertainty; (2) Use of separately trained Convolutional Neural Networks (CNNs) optimized for detecting lesions, also considering their context in the brain, and to ensure spatial continuity; (3) Implementing an ensemble classifier to combine information from these CNNs. The proposed framework has been trained, validated, and tested on a single MRI modality, the FLuid-Attenuated Inversion Recovery (FLAIR) of the MSSEG benchmark public data set containing annotated data from seven expert radiologists and one ground truth. The comparison with the ground truth and each of the seven human raters demonstrates that it operates similarly to human raters. At the same time, the proposed model demonstrates more stability, effectiveness and robustness to biases than any other state-of-the-art model though using just the FLAIR modality.},
  archive      = {J_IJNS},
  author       = {Giuseppe Placidi and Luigi Cinque and Gian Luca Foresti and Francesca Galassi and Filippo Mignosi and Michele Nappi and Matteo Polsinelli},
  doi          = {10.1142/S0129065725500066},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550006},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A context-dependent CNN-based framework for multiple sclerosis segmentation in MRI},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cloud detection network based on adaptive laplacian coordination enhanced cross-feature U-net. <em>IJNS</em>, <em>35</em>(2), 2550005. (<a href='https://doi.org/10.1142/S0129065725500054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud cover experiences rapid fluctuations, significantly impacting the irradiance reaching the ground and causing frequent variations in photovoltaic power output. Accurate detection of thin and fragmented clouds is crucial for reliable photovoltaic power generation forecasting. In this paper, we introduce a novel cloud detection method, termed Adaptive Laplacian Coordination Enhanced Cross-Feature U-Net (ALCU-Net). This method augments the traditional U-Net architecture with three innovative components: an Adaptive Feature Coordination (AFC) module, an Adaptive Laplacian Cross-Feature U-Net with a Multi-Grained Laplacian-Enhanced (MLE) feature module, and a Criss-Cross Feature Fused Detection (CCFE) module. The AFC module enhances spatial coherence and bridges semantic gaps across multi-channel images. The Adaptive Laplacian Cross-Feature U-Net integrates features from adjacent hierarchical levels, using the MLE module to refine cloud characteristics and edge details over time. The CCFE module, embedded in the U-Net decoder, leverages criss-cross features to improve detection accuracy. Experimental evaluations show that ALCU-Net consistently outperforms existing cloud detection methods, demonstrating superior accuracy in identifying both thick and thin clouds and in mapping fragmented cloud patches across various environments, including oceans, polar regions, and complex ocean-land mixtures.},
  archive      = {J_IJNS},
  author       = {Kaizheng Wang and Ruohan Zhou and Jian Wang and Ferrante Neri and Yitong Fu and Shunzhen Zhou},
  doi          = {10.1142/S0129065725500054},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2550005},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A cloud detection network based on adaptive laplacian coordination enhanced cross-feature U-net},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anomaly detection using complete cycle consistent generative adversarial network. <em>IJNS</em>, <em>35</em>(2), 2550004. (<a href='https://doi.org/10.1142/S0129065725500042'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research presents a robust adversarial method for anomaly detection in real-world scenarios, leveraging the power of generative adversarial neural networks (GANs) through cycle consistency in reconstruction error. Traditional approaches often falter due to high variance in class-wise accuracy, rendering them ineffective across different anomaly types. Our proposed model addresses these challenges by introducing an innovative flow of information in the training procedure and integrating it as a new discriminator into the framework, thereby optimizing the training dynamics. Furthermore, it employs a supplementary distribution in the input space to steer reconstructions toward the normal data distribution. This adjustment distinctly isolates anomalous instances and enhances detection precision. Also, two unique anomaly scoring mechanisms were developed to augment detection capabilities. Comprehensive evaluations on six varied datasets have confirmed that our model outperforms one-class anomaly detection benchmarks. The implementation is openly accessible to the academic community, available on Github. a},
  archive      = {J_IJNS},
  author       = {Zahra Dehghanian and Saeed Saravani and Maryam Amirmazlaghani and Mohamad Rahmati},
  doi          = {10.1142/S0129065725500042},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2550004},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Anomaly detection using complete cycle consistent generative adversarial network},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A modified transformer network for seizure detection using EEG signals. <em>IJNS</em>, <em>35</em>(2), 2550003. (<a href='https://doi.org/10.1142/S0129065725500030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seizures have a serious impact on the physical function and daily life of epileptic patients. The automated detection of seizures can assist clinicians in taking preventive measures for patients during the diagnosis process. The combination of deep learning (DL) model with convolutional neural network (CNN) and transformer network can effectively extract both local and global features, resulting in improved seizure detection performance. In this study, an enhanced transformer network named Inresformer is proposed for seizure detection, which is combined with Inception and Residual network extracting different scale features of electroencephalography (EEG) signals to enrich the feature representation. In addition, the improved transformer network replaces the existing Feedforward layers with two half-step Feedforward layers to enhance the nonlinear representation of the model. The proposed architecture utilizes discrete wavelet transform (DWT) to decompose the original EEG signals, and the three sub-bands are selected for signal reconstruction. Then, the Co-MixUp method is adopted to solve the problem of data imbalance, and the processed signals are sent to the Inresformer network for seizure information capture and recognition. Finally, discriminant fusion is performed on the results of three-scale EEG sub-signals to achieve final seizure recognition. The proposed network achieves the best accuracy of 100% on Bonn dataset and the average accuracy of 98.03%, sensitivity of 95.65%, and specificity of 98.57% on the long-term CHB-MIT dataset. Compared to the existing DL networks, the proposed method holds significant potential for clinical research and diagnosis applications with competitive performance.},
  archive      = {J_IJNS},
  author       = {Wenrong Hu and Juan Wang and Feng Li and Daohui Ge and Yuxia Wang and Qingwei Jia and Shasha Yuan},
  doi          = {10.1142/S0129065725500030},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2550003},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A modified transformer network for seizure detection using EEG signals},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SATEER: Subject-aware transformer for EEG-based emotion recognition. <em>IJNS</em>, <em>35</em>(2), 2550002. (<a href='https://doi.org/10.1142/S0129065725500029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a Subject-Aware Transformer-based neural network designed for the Electroencephalogram (EEG) Emotion Recognition task (SATEER), which entails the analysis of EEG signals to classify and interpret human emotional states. SATEER processes the EEG waveforms by transforming them into Mel spectrograms, which can be seen as particular cases of images with the number of channels equal to the number of electrodes used during the recording process; this type of data can thus be processed using a Computer Vision pipeline. Distinct from preceding approaches, this model addresses the variability in individual responses to identical stimuli by incorporating a User Embedder module. This module enables the association of individual profiles with their EEGs, thereby enhancing classification accuracy. The efficacy of the model was rigorously evaluated using four publicly available datasets, demonstrating superior performance over existing methods in all conducted benchmarks. For instance, on the AMIGOS dataset (A dataset for Multimodal research of affect, personality traits, and mood on Individuals and GrOupS), SATEER’s accuracy exceeds 99.8% accuracy across all labels and showcases an improvement of 0.47% over the state of the art. Furthermore, an exhaustive ablation study underscores the pivotal role of the User Embedder module and each other component of the presented model in achieving these advancements.},
  archive      = {J_IJNS},
  author       = {Romeo Lanzino and Danilo Avola and Federico Fontana and Luigi Cinque and Francesco Scarcello and Gian Luca Foresti},
  doi          = {10.1142/S0129065725500029},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2550002},
  shortjournal = {Int. J. Neural Syst.},
  title        = {SATEER: Subject-aware transformer for EEG-based emotion recognition},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse spike feature learning to recognize traceable interictal epileptiform spikes. <em>IJNS</em>, <em>35</em>(2), 2450071. (<a href='https://doi.org/10.1142/S0129065724500710'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interictal epileptiform spikes (spikes) and epileptogenic focus are strongly correlated. However, partial spikes are insensitive to epileptogenic focus, which restricts epilepsy neurosurgery. Therefore, identifying spike subtypes that are strongly associated with epileptogenic focus (traceable spikes) could facilitate their use as reliable signal sources for accurately tracing epileptogenic focus. However, the sparse firing phenomenon in the transmission of intracranial neuronal discharges leads to differences within spikes that cannot be observed visually. Therefore, neuro-electro-physiologists are unable to identify traceable spikes that could accurately locate epileptogenic focus. Herein, we propose a novel sparse spike feature learning method to recognize traceable spikes and extract discrimination information related to epileptogenic focus. First, a multilevel eigensystem feature representation was determined based on a multilevel feature representation module to express the intrinsic properties of a spike. Second, the sparse feature learning module expressed the sparse spike multi-domain context feature representation to extract sparse spike feature representations. Among them, a sparse spike encoding strategy was implemented to effectively simulate the sparse firing phenomenon for the accurate encoding of the activity of intracranial neurosources. The sensitivity of the proposed method was 97.1%, demonstrating its effectiveness and significant efficiency relative to other state-of-the-art methods.},
  archive      = {J_IJNS},
  author       = {Chenchen Cheng and Yunbo Shi and Yan Liu and Bo You and Yuanfeng Zhou and Ardalan Aarabi and Yakang Dai},
  doi          = {10.1142/S0129065724500710},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2450071},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Sparse spike feature learning to recognize traceable interictal epileptiform spikes},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning recognition of paroxysmal kinesigenic dyskinesia based on EEG functional connectivity. <em>IJNS</em>, <em>35</em>(1), 2550001. (<a href='https://doi.org/10.1142/S0129065725500017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Paroxysmal kinesigenic dyskinesia (PKD) is a rare neurological disorder marked by transient involuntary movements triggered by sudden actions. Current diagnostic approaches, including genetic screening, face challenges in identifying secondary cases due to symptom overlap with other disorders. This study introduces a novel PKD recognition method utilizing a resting-state electroencephalogram (EEG) functional connectivity matrix and a deep learning architecture (AT-1CBL). Resting-state EEG data from 44 PKD patients and 44 healthy controls (HCs) were collected using a 128-channel EEG system. Functional connectivity matrices were computed and transformed into graph data to examine brain network property differences between PKD patients and controls through graph theory. Source localization was conducted to explore neural circuit differences in patients. The AT-1CBL model, integrating 1D-CNN and Bi-LSTM with attentional mechanisms, achieved a classification accuracy of 93.77% on phase lag index (PLI) features in the Theta band. Graph theoretic analysis revealed significant phase synchronization impairments in the Theta band of the functional brain network in PKD patients, particularly in the distribution of weak connections compared to HCs. Source localization analyses indicated greater differences in functional connectivity in sensorimotor regions and the frontal-limbic system in PKD patients, suggesting abnormalities in motor integration related to clinical symptoms. This study highlights the potential of deep learning models based on EEG functional connectivity for accurate and cost-effective PKD diagnosis, supporting the development of portable EEG devices for clinical monitoring and diagnosis. However, the limited dataset size may affect generalizability, and further exploration of multimodal data integration and advanced deep learning architectures is necessary to enhance the robustness of PKD diagnostic models.},
  archive      = {J_IJNS},
  author       = {Liang Zhao and Renling Zou and Linpeng Jin},
  doi          = {10.1142/S0129065725500017},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2550001},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Deep learning recognition of paroxysmal kinesigenic dyskinesia based on EEG functional connectivity},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoding continuous tracking eye movements from cortical spiking activity. <em>IJNS</em>, <em>35</em>(1), 2450070. (<a href='https://doi.org/10.1142/S0129065724500709'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eye movements are the primary way primates interact with the world. Understanding how the brain controls the eyes is therefore crucial for improving human health and designing visual rehabilitation devices. However, brain activity is challenging to decipher. Here, we leveraged machine learning algorithms to reconstruct tracking eye movements from high-resolution neuronal recordings. We found that continuous eye position could be decoded with high accuracy using spiking data from only a few dozen cortical neurons. We tested eight decoders and found that neural network models yielded the highest decoding accuracy. Simpler models performed well above chance with a substantial reduction in training time. We measured the impact of data quantity (e.g. number of neurons) and data format (e.g. bin width) on training time, inference time, and generalizability. Training models with more input data improved performance, as expected, but the format of the behavioral output was critical for emphasizing or omitting specific oculomotor events. Our results provide the first demonstration, to our knowledge, of continuously decoded eye movements across a large field of view. Our comprehensive investigation of predictive power and computational efficiency for common decoder architectures provides a much-needed foundation for future work on real-time gaze-tracking devices.},
  archive      = {J_IJNS},
  author       = {Kendra K. Noneman and J. Patrick Mayo},
  doi          = {10.1142/S0129065724500709},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2450070},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Decoding continuous tracking eye movements from cortical spiking activity},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing motor imagery classification with residual graph convolutional networks and multi-feature fusion. <em>IJNS</em>, <em>35</em>(1), 2450069. (<a href='https://doi.org/10.1142/S0129065724500692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stroke, an abrupt cerebrovascular ailment resulting in brain tissue damage, has prompted the adoption of motor imagery (MI)-based brain–computer interface (BCI) systems in stroke rehabilitation. However, analyzing electroencephalogram (EEG) signals from stroke patients poses challenges. To address the issues of low accuracy and efficiency in EEG classification, particularly involving MI, the study proposes a residual graph convolutional network (M-ResGCN) framework based on the modified S -transform (MST), and introduces the self-attention mechanism into residual graph convolutional network (ResGCN). This study uses MST to extract EEG time-frequency domain features, derives spatial EEG features by calculating the absolute Pearson correlation coefficient (aPcc) between channels, and devises a method to construct the adjacency matrix of the brain network using aPcc to measure the strength of the connection between channels. Experimental results involving 16 stroke patients and 16 healthy subjects demonstrate significant improvements in classification quality and robustness across tests and subjects. The highest classification accuracy reached 94.91% and a Kappa coefficient of 0.8918. The average accuracy and F 1 scores from 10 times 10-fold cross-validation are 94.38% and 94.36%, respectively. By validating the feasibility and applicability of brain networks constructed using the aPcc in EEG signal analysis and feature encoding, it was established that the aPcc effectively reflects overall brain activity. The proposed method presents a novel approach to exploring channel relationships in MI-EEG and improving classification performance. It holds promise for real-time applications in MI-based BCI systems.},
  archive      = {J_IJNS},
  author       = {Fangzhou Xu and Weiyou Shi and Chengyan Lv and Yuan Sun and Shuai Guo and Chao Feng and Yang Zhang and Tzyy-Ping Jung and Jiancai Leng},
  doi          = {10.1142/S0129065724500692},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2450069},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Enhancing motor imagery classification with residual graph convolutional networks and multi-feature fusion},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural memory state space models for medical image segmentation. <em>IJNS</em>, <em>35</em>(1), 2450068. (<a href='https://doi.org/10.1142/S0129065724500680'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of deep learning, computer-aided diagnosis and treatment have become crucial in medicine. UNet is a widely used architecture for medical image segmentation, and various methods for improving UNet have been extensively explored. One popular approach is incorporating transformers, though their quadratic computational complexity poses challenges. Recently, State-Space Models (SSMs), exemplified by Mamba, have gained significant attention as a promising alternative due to their linear computational complexity. Another approach, neural memory Ordinary Differential Equations (nmODEs), exhibits similar principles and achieves good results. In this paper, we explore the respective strengths and weaknesses of nmODEs and SSMs and propose a novel architecture, the nmSSM decoder, which combines the advantages of both approaches. This architecture possesses powerful nonlinear representation capabilities while retaining the ability to preserve input and process global information. We construct nmSSM-UNet using the nmSSM decoder and conduct comprehensive experiments on the PH2, ISIC2018, and BU-COCO datasets to validate its effectiveness in medical image segmentation. The results demonstrate the promising application value of nmSSM-UNet. Additionally, we conducted ablation experiments to verify the effectiveness of our proposed improvements on SSMs and nmODEs.},
  archive      = {J_IJNS},
  author       = {Zhihua Wang and Jingjun Gu and Wang Zhou and Quansong He and Tianli Zhao and Jialong Guo and Li Lu and Tao He and Jiajun Bu},
  doi          = {10.1142/S0129065724500680},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2450068},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Neural memory state space models for medical image segmentation},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatially selective retinal ganglion cell activation using low invasive extraocular temporal interference stimulation. <em>IJNS</em>, <em>35</em>(1), 2450066. (<a href='https://doi.org/10.1142/S0129065724500667'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional retinal implants involve complex surgical procedures and require invasive implantation. Temporal Interference Stimulation (TIS) has achieved noninvasive and focused stimulation of deep brain regions by delivering high-frequency currents with small frequency differences on multiple electrodes. In this study, we conducted in silico investigations to evaluate extraocular TIS’s potential as a novel visual restoration approach. Different from the previously published retinal TIS model, the new model of extraocular TIS incorporated a biophysically detailed retinal ganglion cell (RGC) population, enabling a more accurate simulation of retinal outputs under electrical stimulation. Using this improved model, we made the following major discoveries: (1) the maximum value of TIS envelope electric potential ( EP max ) showed a strong correlation with TIS-induced RGC activation; (2) the preferred stimulating/return electrode (SE/RE) locations to achieve focalized TIS were predicted; (3) the performance of extraocular TIS was better than same-frequency sinusoidal stimulation (SSS) in terms of lower RGC threshold and more focused RGC activation; (4) the optimal stimulation parameters to achieve lower threshold and focused activation were identified; and (5) spatial selectivity of TIS could be improved by integrating current steering strategy and reducing electrode size. This study provides insights into the feasibility and effectiveness of a low-invasive stimulation approach in enhancing vision restoration.},
  archive      = {J_IJNS},
  author       = {Xiaoyu Song and Tianruo Guo and Saidong Ma and Feng Zhou and Jiaxin Tian and Zhengyang Liu and Jiao Liu and Heng Li and Yao Chen and Xinyu Chai and Liming Li},
  doi          = {10.1142/S0129065724500667},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2450066},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Spatially selective retinal ganglion cell activation using low invasive extraocular temporal interference stimulation},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijprai">IJPRAI - 149</h2>
<ul>
<li><details>
<summary>
(2025). Explainable modeling of quality anomaly traceability in industrial processes. <em>IJPRAI</em>, <em>39</em>(13), 2559018. (<a href='https://doi.org/10.1142/S0218001425590189'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the defect traceability challenges caused by the complexity of modern industrial process operation mechanisms and high-dimensional parameter coupling, a quality anomaly diagnosis framework integrating interpretable machine learning and knowledge graph is proposed. The quantitative contributions of process parameters to quality indicators are assessed by constructing an architecture combining XGBoost prediction model and SHAP (SHapley Additive exPlanation) interpretable analysis. Structured storage of variable association patterns of historical data based on a knowledge graph. The K Nearest Neighbors (KNN) algorithm is further introduced to construct a data matching mechanism to achieve causal traceability of real-time anomalies through similarity-driven historical defect retrieval. The experimental results show that the method has a good ability to identify the root cause parameters of defects under multiple working condition scenarios, and provides a solution with both data-driven characteristics and knowledge interpretability for the quality control of complex industrial processes.},
  archive      = {J_IJPRAI},
  author       = {Biqing Wang},
  doi          = {10.1142/S0218001425590189},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2559018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Explainable modeling of quality anomaly traceability in industrial processes},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization method of intelligent cleaning control strategy for cleaning of Rice–Wheat combine harvester. <em>IJPRAI</em>, <em>39</em>(13), 2559012. (<a href='https://doi.org/10.1142/S0218001425590128'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key stage of the intelligent cleaning control strategy for rice–wheat combine harvesters is the initial setting of cleaning operation parameters. There is a lack of research on intelligent control methods that reveal the correlation between rice and wheat attributes such as variety, moisture content, and grass to grain ratio, and the initial values of cleaning device operating parameters, as well as the correlation between cleaning loss rate and cleaning impurity rate. This paper constructs an optimization model for the initial operation parameters of the cleaning, and based on the dynamic monitoring and control system of the cleaning’s operation quality and parameters, intelligently regulates the cleaning of the rice–wheat combine harvester. Field experiments and analysis demonstrated that the intelligent control system, guided by the initial parameter setting model, successfully stabilized the cleaning quality metrics (e.g. impurity rate and loss rate) of the rice–wheat combine harvester, thereby validating the effectiveness of the optimized cleaning control strategy based on the perceptual neural vision algorithm.},
  archive      = {J_IJPRAI},
  author       = {Zusheng Li and Yang Liu and Qing Jiang and Jing Zhang and YuQing Zhang and JiaHan Yu and ChangMin Zhan},
  doi          = {10.1142/S0218001425590128},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2559012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Optimization method of intelligent cleaning control strategy for cleaning of Rice–Wheat combine harvester},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BC-MBINet: A novel architecture for accurate classification of breast cancer with microscopic biopsy images using deep convolutional neural networks. <em>IJPRAI</em>, <em>39</em>(13), 2557015. (<a href='https://doi.org/10.1142/S0218001425570150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer (BC) is the second most frequent malignancy, accounting for roughly 25% of all cases of cancer. BC is caused by genetic, epigenetic, and environmental factors, and their interaction too. The diagnosis of a BC is a critical step in the treatment process, and histopathological imaging is required to determine the type of illness. Identifying a disease is an important stage in the treatment process. However, this time-consuming task is exhausting, and people are prone to making mistakes that go unnoticed, making it difficult to determine the severity of the condition and this diagnosing step also relies on a pathologist’s expertise. In this paper, we have developed a novel BC with microscopic biopsy images network (BC-MBINet) model using deep convolutional neural networks. Feature extraction is handled by a sequence of convolutional layers, nonlinearity is handled using LeakyReLU activations, and learning is stabilized by batch normalization. A last Softmax layer is employed for binary classification into benign and malignant tumors, and dropout layers are included to decrease overfitting. The model achieves state-of-the-art accuracy and resilience in discriminating BC types by being trained on a publically available dataset of microscopic biopsy images. The proposed model is capable of classifying between the benign and malignant BC tumors with 99.04% accuracy. The model gives state-of-the-art results in its accuracy in classifying BC tumors into Benign or Malignant.},
  archive      = {J_IJPRAI},
  author       = {Kuljeet Singh and Amrit Sudershan and Sachin Kumar and Sourabh Shastri and Vibhakar Mansotra},
  doi          = {10.1142/S0218001425570150},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2557015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {BC-MBINet: A novel architecture for accurate classification of breast cancer with microscopic biopsy images using deep convolutional neural networks},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CVD-M3NET: Cardiovascular disease stage classification via mamdani fuzzy-based modified mobile network. <em>IJPRAI</em>, <em>39</em>(13), 2557014. (<a href='https://doi.org/10.1142/S0218001425570149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Globally, cardiovascular diseases (CVDs) remain an important cause of mortality, for early and precise diagnosis. Traditional machine learning (ML) models struggle with feature redundancy, data imbalance, and suboptimal performance due to inefficient feature selection and lack of robust deep learning (DL) architectures. To overcome these challenges, we propose a novel Cardiovascular Disease Stage Classification via the Mamdani Fuzzy-based Modified Mobile Network (CVD-M 3 Net) by integrating hybrid feature selection, DL network and Fuzzy logic for improved CVD stage classification. The proposed CVD-M 3 Net utilizes data from multiple sources including Cleveland, MIMIC-IV, UK Biobank, Statlog, Switzerland, Hungary, and VA Long Beach datasets. The Boruta-LASSO and Fast ICA techniques are used for feature selection by ensuring the retention of critical diagnostic attributes while eliminating irrelevant ones. The selected features undergo Z -score normalization for improved data consistency between the 15 features. The Modified MobileNet (MOMO-Net) is introduced with the integration of 1D convolutional and transformer layers in the MobileNet structure to categorize the tabular data for real-time CVD stage detection. The proposed CVD-M 3 Net utilizes the Mamdani fuzzy inference system (FIS) with a trapezoidal membership function to predict the CVD Stage Score (CSS). The efficiency of the proposed CVD-M 3 Net was estimated with the Accuracy, Sensitivity, Precision, Recall, and F1-score. From the experimental analysis, the proposed CVD-M 3 Net achieves an overall accuracy of 98.61% for efficient classification of CVD stages. The proposed CVD-M 3 Net increases the accuracy by 0.11%, 0.62%, 3.25%, and 0.38% better than ML algorithms, O-SBGC-LSTM, MaLCaDD, and DL-based CNN, respectively.},
  archive      = {J_IJPRAI},
  author       = {Lijetha Christopher Jaffrin and Visumathi James},
  doi          = {10.1142/S0218001425570149},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2557014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {CVD-M3NET: Cardiovascular disease stage classification via mamdani fuzzy-based modified mobile network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving brain tumor stage diagnosis with multi-stage hybrid classifier models. <em>IJPRAI</em>, <em>39</em>(13), 2557013. (<a href='https://doi.org/10.1142/S0218001425570137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To make informed clinical decisions and plan successful treatments, it is essential that magnetic resonance imaging (MRI) identify and diagnose brain tumors accurately. This research introduces a new method for multi-stage tumor detection and classification that uses a hybrid classifier (HC) to improve the accuracy of diagnoses. The first step of the suggested method is to identify possible tumor areas by obtaining features from grey-scale intensity analysis of successive pixels, which captures important differences. A systematic categorization technique relates these traits to distinct tumor stages. The HC uses rectilinear classifiers to analyze linear pixel changes and expanded classifiers to find bounded edges within regional pixel distributions. With this two-pronged strategy, tumors of any shape or size may be detected. Training classifiers on datasets with restricted edge characteristics and linear variation patterns allows for exact stage distinction, which is essential for learning. Compared to traditional classification approaches, the multi-stage framework greatly improves the capacity to detect complicated and nuanced tumor traits. Our powerful diagnostic approach permits precise and effective tumor identification and stage categorization to facilitate prompt treatments. The hybrid technique highlights its promise as a dependable, scalable solution to improve patient outcomes in medical imaging applications and advance brain tumor diagnosis.},
  archive      = {J_IJPRAI},
  author       = {S. R. Sowmiya and N. Sabiyath Fatima},
  doi          = {10.1142/S0218001425570137},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2557013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Improving brain tumor stage diagnosis with multi-stage hybrid classifier models},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SRGAN-based input enhancement and attention-guided YOLOv5s for real-time excavator pose estimation. <em>IJPRAI</em>, <em>39</em>(13), 2554014. (<a href='https://doi.org/10.1142/S021800142554014X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The measurement of excavator pose information is crucial for advancing intelligent excavator control systems. To address challenges in excavator pose detection — such as small pose measurement targets and blurred images — a high-speed, high-accuracy visual technology-based pose recognition algorithm, super-resolution input-YOLOv5s, was developed. This algorithm includes an image target designed specifically to facilitate the detection of the excavator arm’s pose angles. Excavator pose information is derived through the analysis of the target image data. The SRGAN model is used to enhance the quality of input data for YOLOv5, while attention mechanisms are introduced at the terminal stage of the backbone network. Focal loss is employed as the loss function to improve the detection accuracy and stability for small targets in complex construction environments, while also mitigating class imbalance. Experimental results demonstrate that the improved algorithm, SRI-YOLOv5s, achieved a detection speed of 59.20 FPS, with a mean average precision (mAP) of 89.46%, precision of 91.7%, and recall of 92.1%, outperforming the original model. The model’s real-time performance and robustness meet the requirements for excavator pose detection in practical environments.},
  archive      = {J_IJPRAI},
  author       = {Wangting Zeng and Qixiang Huang and Ke Wu and Xuedong Zhang and Bo Cui},
  doi          = {10.1142/S021800142554014X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2554014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {SRGAN-based input enhancement and attention-guided YOLOv5s for real-time excavator pose estimation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploration of simulation environments for visual question answering: 3D dense captioning for outdoor scenes. <em>IJPRAI</em>, <em>39</em>(13), 2552020. (<a href='https://doi.org/10.1142/S0218001425520202'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel simulation framework tailored for Visual Question Answering (VQA) in complex outdoor environments, where existing datasets and systems fall short in semantic density and spatial reasoning. The proposed pipeline integrates procedural 3D scene generation, region-level dense captioning augmented with geometric priors, and structured scene graph construction to bridge vision and language understanding. A transformer-based reasoning module processes joint embeddings of questions and scene graphs to produce interpretable answers grounded in 3D semantics. The system supports diverse spatial and contextual queries and enables large-scale dataset synthesis with region-aligned captions and question–answer pairs. Extensive experiments across four datasets — Outdoor-Sim, SYNTHIA, StreetLearn, and ScanNet-VQA — demonstrate the framework’s superior performance over three strong baselines in accuracy, MRR, and convergence stability. Visualizations show robust alignment between captions, object layout, and semantic graphs. This study advances outdoor VQA by introducing a scalable, interpretable, and semantically grounded solution suitable for downstream robotics and scene understanding applications.},
  archive      = {J_IJPRAI},
  author       = {Renyue Wu and Kalama Bitur},
  doi          = {10.1142/S0218001425520202},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2552020},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Exploration of simulation environments for visual question answering: 3D dense captioning for outdoor scenes},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-assisted localized content-based image retrieval framework with multiple-instance learning algorithm. <em>IJPRAI</em>, <em>39</em>(13), 2552019. (<a href='https://doi.org/10.1142/S0218001425520196'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional content-based image retrieval (CBIR) searches a database for pictures that match a single, unannotated query image. A comprehensive (or worldwide) perspective of the picture is essential for this kind of search. However, the intended picture content is frequently not global rather regional. Computer vision, pattern recognition, and CBIR are just a few of the applications that have long faced the “semantic gap” issue: how to bridge the gap between human perception of low-level semantic concepts and machine collection of high-level image pixels. In light of the recent achievements in deep learning research, there is hope for bridging the semantic gap. Therefore, the deep learning-assisted localized content-based image retrieval framework (DL-LCBIRF) was suggested in this study to rank photos in the database according to a similarity metric dependent upon specific areas inside the image. The first layer consists of “generic” descriptors that stand in for groups of feature vectors that are comparable and rotationally invariant. The combined probability of the frequencies of the “generic” descriptions over neighborhoods makes up the second layer. The proposed DL-LCBIR uses labelled images combined with a multiple-instance learning algorithm (MILA) to locate the target item and adjust the feature weights. This multi-modal probability is shown as a collection of “spatial frequency” clusters. It augments rotationally invariant statistical spatial constraints. In addition to enhancing the model’s performance, choosing a unique structure determines the model’s distinguishing features, which are common in good cases and seldom in negative ones.},
  archive      = {J_IJPRAI},
  author       = {P. Arulmozhi and R. Gopi},
  doi          = {10.1142/S0218001425520196},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2552019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Deep learning-assisted localized content-based image retrieval framework with multiple-instance learning algorithm},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Action space pruning for deep reinforcement learning in dou di zhu. <em>IJPRAI</em>, <em>39</em>(13), 2552014. (<a href='https://doi.org/10.1142/S0218001425520147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The card game Dou Di Zhu (competitive two-against-one game) presents a challenging multiplayer imperfect-information game problem due to its large action space. We developed a deep Monte Carlo (DMC) reinforcement learning (RL) framework called ASP-DouZero, which employs dynamic programming (DP) to prune the action space effectively, using statistical analysis results. The pruned action space was then applied to self-play data generation and neural network decision processes. We evaluated ASP-DouZero against the state-of-the-art DouZero framework under identical training conditions. Results showed the proposed approach achieved a 5% higher win rate in standardized matches after convergence while requiring 50% less training time on equivalent hardware. These findings demonstrate that action space pruning significantly improves decision-making performance and training efficiency in DMC-based approaches for Dou Di Zhu.},
  archive      = {J_IJPRAI},
  author       = {Shanglin Li and Jiabao Du and Yu Zhao and Tianle Xiang and Yulin Lan},
  doi          = {10.1142/S0218001425520147},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2552014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Action space pruning for deep reinforcement learning in dou di zhu},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight object detection for real-time aerial video analysis on edge-deployed UAVs. <em>IJPRAI</em>, <em>39</em>(13), 2550025. (<a href='https://doi.org/10.1142/S0218001425500259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time object detection in aerial videos captured by Unmanned Aerial Vehicles (UAVs) plays a vital role in applications such as traffic surveillance, disaster response, and intelligent aerial operations. However, deploying deep learning models directly on UAV platforms faces significant challenges due to limited onboard computing capabilities and strict power constraints imposed by the aircraft’s propulsion system. The efficiency of the detection algorithm directly impacts not only processing latency but also the energy consumption and endurance of the UAVs flight dynamics. To address these challenges, this paper presents UAVDet, a lightweight object detection framework optimized for edge-deployed UAVs operating under propulsion-aware constraints. UAVDet comprises three modules: a Multi-Scale Lightweight Backbone (MSLB) for efficient multi-resolution feature extraction, a Temporal-Consistent Feature Alignment (TCFA) module that enhances inter-frame stability under aerial motion, and an Adaptive Context Enhancement Head (ACEH) for spatially and semantically precise detection. Extensive experiments on a custom UAV dataset demonstrate that UAVDet achieves a superior balance between detection accuracy and runtime efficiency. Moreover, its low computational overhead supports deployment on energy-constrained UAV platforms, reducing the burden on the propulsion system and enabling longer, smarter missions.},
  archive      = {J_IJPRAI},
  author       = {Hong Zhu and He Qin},
  doi          = {10.1142/S0218001425500259},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2550025},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Lightweight object detection for real-time aerial video analysis on edge-deployed UAVs},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic detection of obstacles in underground railway tracks for collision prevention. <em>IJPRAI</em>, <em>39</em>(13), 2550024. (<a href='https://doi.org/10.1142/S0218001425500247'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned underground vehicles (UUVs) offer significant advantages for coal mine transportation. However, the subterranean environment is often complex and prone to unexpected obstacles, particularly pedestrians, which pose substantial safety risks. To mitigate these risks, we developed an automated collision avoidance system. Additionally, we established an information network enabling real-time map tracking of UUVs to facilitate efficient dispatch and operation. Advanced deep learning algorithms detect tracks, obstacles, and pedestrians. Within the track detection zone, the system employs the Hough transform to identify line segments. These segments are then assigned weighting factors based on clarity, clustering, and fitting techniques, enabling accurate reconstruction of the track’s left and right boundaries. Furthermore, a defined safety zone effectively assesses the distance between pedestrians and vehicles. In practical operation, UUVs autonomously trigger audible alarms or initiate braking when pedestrians enter a critical proximity, when other UUVs obstruct the roadway, or when vehicles approach from the opposite direction. This integrated system significantly enhances safety for underground coal mine transportation.},
  archive      = {J_IJPRAI},
  author       = {Kai Zhao and Xuenan Zhang and Liwei Chen},
  doi          = {10.1142/S0218001425500247},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2550024},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Automatic detection of obstacles in underground railway tracks for collision prevention},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human–Machine coupling study for fast visual target capture. <em>IJPRAI</em>, <em>39</em>(13), 2550023. (<a href='https://doi.org/10.1142/S0218001425500235'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous advancement of computer vision, human–computer interaction, and intelligent sensing technologies, accurate line-of-sight (LOS) tracking has become a critical research topic. However, traditional gaze tracking systems face significant limitations under conditions of natural head movement. The direction of human vision is determined jointly by head posture and eye movement, and precise acquisition of head pose remains a key challenge in gaze tracking technology. To address the limitations imposed by head movement, this study aims to improve the robustness of gaze tracking in natural interaction scenarios. This paper proposes a novel head pose estimation method based on the 3D spatial information of facial feature points. The method utilizes stereo vision to reconstruct 3D feature points and employs a geometric model to calculate head pose, effectively decoupling head movement from eye movement in gaze tracking. In the experimental setup, two interaction modalities were tested: head pointing combined with key pressing, and gaze estimation combined with head pointing. Experimental results demonstrate that the proposed method achieves interaction latency between 100 ms and 200 ms, with a fast capture success rate of up to 85%, slightly outperforming traditional visual target acquisition algorithms. These results indicate the method’s superior responsiveness and stability under natural head movement conditions. The research provides an important technical foundation for achieving natural, efficient human–computer interaction in complex environments.},
  archive      = {J_IJPRAI},
  author       = {Wenbo Huang and Mingwei Zhao and Heng Zhang and Xiaoqiao Wang},
  doi          = {10.1142/S0218001425500235},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2550023},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Human–Machine coupling study for fast visual target capture},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AN advanced AI approach-based skin disease prediction system utilizing EN-QNN and grad-CAM in IoMT environment. <em>IJPRAI</em>, <em>39</em>(13), 2550013. (<a href='https://doi.org/10.1142/S0218001425500132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin acts as a natural shield, protecting the body from ultraviolet rays, extreme weather, and harmful chemicals. However, it can be affected by pollution, weakened immunity, and unhealthy lifestyles, leading to various skin diseases. Early detection of these conditions is crucial for timely treatment and better outcomes. Existing research has often overlooked skin diseases with similar visual characteristics, making it challenging to distinguish between different conditions using visual inspection alone. To address this, the paper proposes an AI-enabled prediction framework for skin disease prediction using EN-QNN and Grad-CAM. Initially, the images are collected using IoMT devices of skin diseases and undergo preprocessing, which includes resizing, noise removal and contrast enhancement using AK-CLAHE, followed by color analysis and segmentation using YCbCr and DF-U-Net. Morphological operations are then applied during post-processing. The shape and structure of lesions are analyzed using CMED. Meanwhile, using Grad-CAM, Contextual Information Analysis (CIA) is performed on preprocessed data. Concurrently, disease symptom prediction data (i.e. clinical data) are collected, and features are extracted from this data, including boundary localization and CIA. Finally, skin diseases are classified using EN-QNN. The proposed model achieved a high accuracy of 98.68051%, surpassing current techniques.},
  archive      = {J_IJPRAI},
  author       = {Bhavya Kadiyala and Sunil Kumar Alavilli and Rajani Priya Nippatla and Subramanyam Boyapati and Chaitanya Vasamsetty and Harleen Kaur},
  doi          = {10.1142/S0218001425500132},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2550013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {AN advanced AI approach-based skin disease prediction system utilizing EN-QNN and grad-CAM in IoMT environment},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SUMMR: A unified multimodal representation framework for songs. <em>IJPRAI</em>, <em>39</em>(12), 2558001. (<a href='https://doi.org/10.1142/S0218001425580017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The understanding and representation of songs is a crucial issue in music platforms, as it can facilitate numerous applications in the music field. Songs are a common multimodal art form within the music domain, achieving rich musical connotations and strong expressiveness. However, the data of songs exhibit obvious multimodal and heterogeneous characteristics, presenting significant challenges to the understanding and representation of songs. Regrettably, the current methods do not respond to these challenges effectively. To this end, in this study, a unified multimodal representation framework for songs, namely SUMMR, is proposed. Specifically, first, a two-layer framework is put forward. In embedding layer, the features of different modalities data are embedded into a unified space. In content layer, a novel cross-modal attention mechanism is designed, which effectively capture the cross-modal semantic associations and deep music features, thereby obtaining a unified representation of songs. Then, a two-level hierarchical pre-training algorithm is proposed, which can effectively lower the training cost. Finally, experiments are conducted on two typical music tasks with public datasets of songs, where the experimental results demonstrate the effectiveness of SUMMR for understanding and representation of songs, and also show that SUMMR has good capability of being fine-tuned in many song-based tasks.},
  archive      = {J_IJPRAI},
  author       = {Lei Ye and Bing Shen and Yu Su and Xiao Chen and Yi Gong and Yifei Zhou and JunYu Lu},
  doi          = {10.1142/S0218001425580017},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2558001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {SUMMR: A unified multimodal representation framework for songs},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal medical image fusion based on total variation decomposition and spectral residual saliency. <em>IJPRAI</em>, <em>39</em>(12), 2557016. (<a href='https://doi.org/10.1142/S0218001425570162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image fusion is an image processing method that uses computer technology to integrate medical images of different modalities to achieve synchronous visualization of multiple types of information; in this way, multiple medical images complement each other, increasing the accuracy and completeness of clinical diagnosis and treatment. Multiple medical image fusion algorithms have been developed, but they all have drawbacks. One of these is that they are not always reusable or portable due to issues such as faulty fusion rule design. Image reconstruction leads to a decrease in image quality, as the reconstruction process may lose some original information, and the complexity of transformation algorithms and medical images can easily affect performance and robustness. By merging spectral residual (SR) saliency with total variation decomposition, this paper presents a medical image fusion method that addresses current issues. Using total variation, we first dissect the source images to identify their structural and textural elements. Additionally, SRs are utilized for the extraction of saliency images. Moreover, separate procedures are used to merge the structural, textural, and saliency pictures. Finally, the three fused images are added together to form the final product. In terms of both clarity of detail and information retention, our experimental results show that this approach is superior to competing methods. In addition, our Q SD increased by 31.76%, and our Q RMSE increased by 48.19% compared with the average value of the reference algorithms.},
  archive      = {J_IJPRAI},
  author       = {Xiaolong Gu and Ying Xia and Ying Wei},
  doi          = {10.1142/S0218001425570162},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2557016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multimodal medical image fusion based on total variation decomposition and spectral residual saliency},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient prediction and analysis of diabetics based on hybrid convolutional pyramid squeeze attention network with explainable AI. <em>IJPRAI</em>, <em>39</em>(12), 2557012. (<a href='https://doi.org/10.1142/S0218001425570125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes is a chronic metabolic condition that manifests early as high blood sugar levels brought on by the body’s incapacity to properly metabolize or use insulin. The increasing incidence of diabetes worldwide highlights the urgent need for early detection and prediction methods to enable timely management and intervention. This study proposes a four-phase optimized lightweight convolutional pyramid squeeze attention (LwCPSA) model for diabetes prediction. The log-sinh with adaptive Box-Cox transformation is used to handle outliers, normalize data, and improve model robustness, ensuring accurate diabetes prediction. The LwCPSA model enhances multi-scale feature extraction, and the improved gold rush optimization (GRO) fine-tunes model parameters to improve accuracy while reducing computational complexity. The improved GRO is used to further tune the LwCPSA parameters, which lowers computing complexity. SHAP-based explainability is utilized to identify the most influential features contributing to diabetes prediction, providing transparent insights into how the model weighs different risk factors, such as glucose levels, BMI, and HbA1c, to make accurate predictions. The proposed method is implemented using Python. The proposed approach achieves remarkable results, with an F1-score of 99.47%, an accuracy of 99.65%, a precision of 99.45%, a recall of 99.23%, a specificity of 99.56%, and so on. These findings improve prediction accuracy and provide a flexible, scalable approach for diabetes prediction, which greatly increases the effectiveness of medical applications. Furthermore, the proposed approach has the potential to improve diabetes diagnosis and treatment outcomes by enabling early and accurate prediction, ultimately reducing the risk of complications and improving patient quality of life.},
  archive      = {J_IJPRAI},
  author       = {S. Sai Prakash and A. C. Subhajini},
  doi          = {10.1142/S0218001425570125},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2557012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An efficient prediction and analysis of diabetics based on hybrid convolutional pyramid squeeze attention network with explainable AI},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight low-light image enhancement network via channel prior and gamma correction. <em>IJPRAI</em>, <em>39</em>(12), 2554013. (<a href='https://doi.org/10.1142/S0218001425540138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human vision relies heavily on available ambient light to perceive objects. Low-light scenes pose two distinct challenges: information loss due to insufficient illumination and undesirable brightness shifts. Low-light image enhancement (LLIE) refers to image enhancement technology tailored to handle this scenario. We introduce CPGA-Net, an innovative LLIE network that combines dark/bright channel priors and gamma correction via deep learning and integrates features inspired by the atmospheric scattering model and the Retinex theory. This approach combines the use of traditional and deep learning methodologies, designed within a simple yet efficient architectural framework that focuses on essential feature extraction. The resulting CPGA-Net is a lightweight network with only 0.025 million parameters and 0.030 s for inference time, yet it achieves superior performance over existing LLIE methods on both objective and subjective evaluation criteria. Furthermore, we utilized knowledge distillation with explainable factors and proposed an efficient version that achieves 0.018 million parameters and 0.006 s for inference time. The proposed approaches inject new solution ideas into LLIE, providing practical applications in challenging low-light scenarios.},
  archive      = {J_IJPRAI},
  author       = {Shyang-En Weng and Shaou-Gang Miaou and Ricky Christanto},
  doi          = {10.1142/S0218001425540138},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2554013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A lightweight low-light image enhancement network via channel prior and gamma correction},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A GPU-based framework for adaptive kernel size selection in visual pattern recognition. <em>IJPRAI</em>, <em>39</em>(12), 2552017. (<a href='https://doi.org/10.1142/S0218001425520172'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual pattern recognition systems relying on fixed-kernel Convolutional Neural Networks (CNNs) often struggle with heterogeneous image regions, leading to suboptimal feature extraction. This paper introduces a GPU-based framework that addresses the challenges of adaptive kernel size selection, including parallelism disruption, resource contention, and real-time constraints. The framework comprises three key innovations: (1) an online feature analysis module with lightweight reinforcement learning (RL) for dynamic kernel selection, leveraging multi-scale feature pyramids and a Q-learning model optimized for GPU parallel execution; (2) a dynamic resource allocation strategy that partitions GPU resources by kernel size, predicts register/shared memory requirements, and optimizes memory access patterns; and (3) a pipeline folding and cache-aware scheduling framework that integrates feature analysis, decision-making, and convolution into a single kernel while enabling priority-driven preemption for real-time performance. Extensive experiments on datasets like CIFAR-100, ImageNet-1K, and VOC2012 demonstrate that the framework achieves up to 39% higher inference throughput, 2.2% improved recognition accuracy, and 16% better GPU utilization compared to state-of-the-art methods, all while maintaining sub-30 ms end-to-end latency. The proposed approach bridges the gap between adaptive kernel intelligence and GPU efficiency, offering a robust solution for real-time visual pattern recognition tasks.},
  archive      = {J_IJPRAI},
  author       = {Jiahong Wang and Zixuan Wang},
  doi          = {10.1142/S0218001425520172},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2552017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A GPU-based framework for adaptive kernel size selection in visual pattern recognition},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Jaya-waterwheel plant algorithm with hybrid deep learning and probabilistic fusion for image inpainting. <em>IJPRAI</em>, <em>39</em>(12), 2552015. (<a href='https://doi.org/10.1142/S0218001425520159'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a memory-efficient and high-resolution image inpainting framework called Jaya Waterwheel Plant Algorithm-Hybrid Context Deep Learning (JWWPA-Hybrid DL). Designed to address the limitations of conventional Deep Learning (DL) models that handle only low-resolution images due to memory constraints, the proposed method integrates optimization and DL for more accurate and realistic image restoration. The workflow involves: (1) acquiring a damaged input image from the Figshare database, (2) applying inpainting via a Context-Conditional Generative Adversarial Networks (CC-GAN) and a context encoder, both optimized using the JWWPA — a hybrid of the Jaya algorithm and the Waterwheel Plant Algorithm (WWPA), and (3) combining the outputs through probabilistic function-based image fusion. The proposed JWWPA-Hybrid DL achieves a PSNR of 38.555 dB, SDME of 58.472 dB, SSIM of 0.817, and UQI of 0.827, demonstrating superior performance compared to existing approaches.},
  archive      = {J_IJPRAI},
  author       = {T. M. Sivanesan and N. Vijayaraj},
  doi          = {10.1142/S0218001425520159},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2552015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Jaya-waterwheel plant algorithm with hybrid deep learning and probabilistic fusion for image inpainting},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A transformer-based method for few-shot image recognition in federated learning environments. <em>IJPRAI</em>, <em>39</em>(12), 2551015. (<a href='https://doi.org/10.1142/S0218001425510152'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot image recognition in federated learning (FL) environments presents unique challenges due to data heterogeneity, limited local samples, and strict privacy constraints. To address these issues, we propose a novel Transformer-based approach that enables effective visual recognition with minimal labeled data on distributed clients. The proposed model introduces an adaptive multi-scale window attention mechanism to enhance feature extraction under sparse data conditions. Furthermore, a collaborative attention strategy is developed to enable privacy-preserving semantic knowledge exchange across clients. To alleviate the class imbalance and overfitting problems common in few-shot settings, we design an improved Focal Loss function guided by class-wise entropy. Additionally, a progressive knowledge distillation framework is incorporated to maintain model consistency across training rounds. Extensive experiments conducted on multiple few-shot image benchmarks under federated settings demonstrate that our method significantly outperforms existing baselines in terms of accuracy, communication efficiency, and generalization.},
  archive      = {J_IJPRAI},
  author       = {Guodong Wang and Qianqian Li and Xinyi Lin and Zixuan Wang and Fengjun Zhou and Qun Wang and Weiguo Lai and Xueqiang Gao},
  doi          = {10.1142/S0218001425510152},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2551015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A transformer-based method for few-shot image recognition in federated learning environments},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A framework for damage detection of building facades using three-dimensional laser scanning and the revit model. <em>IJPRAI</em>, <em>39</em>(12), 2550022. (<a href='https://doi.org/10.1142/S0218001425500223'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid urbanization and proliferation of high-rise buildings in China, facade damage such as cracking, peeling, and tile detachment has become increasingly prevalent, posing severe safety risks to the public. Traditional visual inspection methods are labor-intensive, subjective, and lack quantitative standards, often resulting in missed or inaccurate damage detection. This study proposes a systematic framework that leverages high-precision three-dimensional (3D) laser scanning and Revit model to detect facade anomalies efficiently and quantitatively. Using a dormitory building in Yibin City, Sichuan Province as a case study, we employed the Z + F IMAGER 5010C laser scanner to capture dense point cloud data of the building facade. This model was then quantitatively compared with the Revit solid model to establish a spatial information database for facade damage. This database was further calibrated with actual site conditions. The case study demonstrated that using a deviation threshold of ± 6 mm as the demarcation point effectively identified hollowing and peeling damage, and other issues on a building facade. A total of 18 bulges on the example building facade were identified via the proposed framework; the detection results allowed for quantification and visualization of the facade issues. The results were integrated into a digital building management platform that supports damage classification, spatial mapping, task scheduling, and closed-loop maintenance tracking. This integrated approach enhances facade safety monitoring by providing a quantifiable, repeatable, and automated detection workflow, providing a scalable solution for digitalized facade condition monitoring in urban environments.},
  archive      = {J_IJPRAI},
  author       = {Yi Wu and Zhewei Wang and Hong Wen and Xuebin Tang and Dan Yuan and Zhihao Chen and Liang Zeng},
  doi          = {10.1142/S0218001425500223},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2550022},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A framework for damage detection of building facades using three-dimensional laser scanning and the revit model},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UNet and swin transformer fusion network for lesion segmentation in biological kidney imaging. <em>IJPRAI</em>, <em>39</em>(12), 2550021. (<a href='https://doi.org/10.1142/S0218001425500211'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We research the segmentation of lesions in medical images using the PST-UNet model, verifying the preservation of spatial features of medical lesions, and improving the accuracy of medical lesion segmentation. The PST-UNet (positive distribution data Swin transformer) model combines transformer and U-shaped structures. It uses cascaded convolution fusion modules to integrate the encoder’s multi-scale features. The encoder includes the Swin transformer block and the entire Gaussian Error Linear Unit (GELU) activation function. The decoder uses the Swin transformer block, upsampling, and skip connections from the cascaded convolution fusion modules. This approach effectively preserves more spatial features of medical lesions and improves the accuracy of kidney lesion segmentation, achieving a 0.02289 improvement in accuracy. The PST-UNet model can improve the segmentation accuracy of normally distributed medical lesion data, which has a positive effect on the treatment of kidney disease.},
  archive      = {J_IJPRAI},
  author       = {Xuemei Shi and Xiedong Song and Ming Deng and Dalei Zhang and Xiaoyan Li and Baoguo Chen},
  doi          = {10.1142/S0218001425500211},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2550021},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {UNet and swin transformer fusion network for lesion segmentation in biological kidney imaging},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAR-FPN: Scale adaptive and reverse fusion object detection. <em>IJPRAI</em>, <em>39</em>(12), 2550020. (<a href='https://doi.org/10.1142/S021800142550020X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is widely used in many fields, and multi-scale feature extraction is crucial for accurate detection. The Feature Pyramid Network (FPN) is a commonly adopted feature extraction approach in object detection. Nevertheless, direct fusion between top-down feature layers in FPN leads to misalignment and loss of feature information. To address these limitations, this paper proposes a novel feature pyramid network based on FPN, termed SAR-FPN, which consists of two components: the Scale Adaptive Triple-Branch Module (SATM) and the Reverse Feature Fusion Module (RFFM). Specifically, SATM enhances the performance for large objects through its triple-branch design. It selects the appropriate branch based on object scale, assigns suitable receptive fields for objects of different sizes, and performs feature alignment. The RFFM addresses the issue of poor performance in small object detection by implementing a bottom-up feature fusion pathway. Extensive experiments on the PASCAL VOC 2012 and MS COCO 2017 datasets validated the effectiveness of SAR-FPN.},
  archive      = {J_IJPRAI},
  author       = {Nuo Cheng and TaiPing Xiong and Gengshen Cui and Minghua Pan and Xiangjie Wu},
  doi          = {10.1142/S021800142550020X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2550020},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {SAR-FPN: Scale adaptive and reverse fusion object detection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLM-based sensitive data recognition with stepwise chain-of-thought reasoning. <em>IJPRAI</em>, <em>39</em>(12), 2550019. (<a href='https://doi.org/10.1142/S0218001425500193'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying sensitive text data remains a critical challenge for industrial data protection, as conventional methods lack flexibility and demand extensive manual labeling. While Large Language Models (LLMs) offer a promising avenue for automated sensitive data recognition (SDR), their susceptibility to “hallucination” often leads to misclassification. To overcome this, we introduce an LLM-based SDR framework powered by stepwise Chain-of-Thought (CoT) reasoning. Our approach employs a rigorously designed prompt template to enable LLMs to iteratively reassess and refine their output, leading to precise identification of sensitive text positions and highly fine-grained recognition results. Experiments on a real-world dataset from the electric sector demonstrate the superior performance of our method in domain-specific SDR tasks, highlighting its strong potential for robust and scalable application in complex industrial environments.},
  archive      = {J_IJPRAI},
  author       = {Honggang Wang and Shenglong Liu and Yiwen Jiang and Zhenqi Guo and Jiehao Tang},
  doi          = {10.1142/S0218001425500193},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2550019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {LLM-based sensitive data recognition with stepwise chain-of-thought reasoning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application exploration of multi-scale edge detection and SIFT feature fusion in digital twin pattern recognition for power grids. <em>IJPRAI</em>, <em>39</em>(12), 2550016. (<a href='https://doi.org/10.1142/S0218001425500168'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital twin technology is transforming the way power grid infrastructure is monitored and managed, yet accurate pattern recognition under complex visual conditions remains a significant challenge. Traditional edge- or feature-based methods struggle to maintain robustness in environments affected by fog, shadow, or occlusion. This paper proposes a fusion framework that combines multi-scale edge detection and SIFT-based local descriptors, integrated through a learnable attention mechanism that adaptively weights features at each pixel location. The method is evaluated on a custom UAV-acquired dataset containing high-resolution power grid imagery under diverse environmental scenarios. Experimental results demonstrate that the proposed approach significantly outperforms edge-only, SIFT-only, and U-Net models across SSIM, F 1-score, and IoU metrics, while maintaining practical inference speed. The model also achieves the lowest 3D registration error in point cloud alignment. These results confirm the effectiveness of our method and highlight its potential for accurate, robust digital twin construction in real-world grid inspection systems.},
  archive      = {J_IJPRAI},
  author       = {Chunmei Zhang and Xingque Xu and Yongjian Li and Silin Liu and Jianyi Li},
  doi          = {10.1142/S0218001425500168},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2550016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Application exploration of multi-scale edge detection and SIFT feature fusion in digital twin pattern recognition for power grids},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inverse gaussian harmonic filter (IGHF): Spatial filter with contrast stretching priority. <em>IJPRAI</em>, <em>39</em>(12), 2534001. (<a href='https://doi.org/10.1142/S0218001425340018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images are corrupted by the Additive White Gaussian Noise (AWGN) from imaging devices. Existing spatial-domain filters often introduce edge distortion at high noise levels. We propose the Inverse Gaussian Harmonic Filter (IGHF), a novel training-free denoising framework that inverts the Gaussian kernel and employs harmonic weighting on standard deviation terms. The first closed-form mathematical model provides superior edge preservation while effectively suppressing noise. We evaluate hybrid approaches combining IGHF with BM3D [K. Dabov, A. Foi, V. Katkovnik and K. Egiazarian, Image denoising by sparse 3-D transform-domain collaborative filtering, IEEE Trans. Image Process . 8 (2007) 2080–2095.] and DnCNN [K. Zhang K, W. Zuo W, Y. Chen, D. Meng and L. Zhang, Beyond a Gaussian denoiser: Residual learning of deep CNN for image denoising, IEEE Trans. Image Process . 7 (2017) 3142–3155.], achieving up to 1.50 dB PSNR gain over the state-of-the-art spatial methods. Quantitative evaluation on eight benchmark images demonstrates effectiveness across noise levels ( σ 2 = 0 . 0 1 –0.05). Triple-Hybrid fusion achieves 31.96 dB PSNR with superior SSIM (0.912) and edge-preservation FOM (0.850), outperforming BM3D by 0.35 dB through systematic grid-search optimization. Runtime analysis confirms real-time capability: Enhanced IGHF processes HD frames in < 2 0 0 ms with minimal memory footprint ( < 8 MB), enabling consumer-grade deployment. The deterministic approach provides a novel mathematical foundation for spatial-domain denoising with applications in deep-learning architectures.},
  archive      = {J_IJPRAI},
  author       = {Fatih Marasli and Serkan Ozturk},
  doi          = {10.1142/S0218001425340018},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2534001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Inverse gaussian harmonic filter (IGHF): Spatial filter with contrast stretching priority},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personality traits prediction methods: A survey. <em>IJPRAI</em>, <em>39</em>(12), 2530002. (<a href='https://doi.org/10.1142/S0218001425300024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personality traits prediction plays a significant role in several real-world applications, such as improving the education system, improving production in manufacturing, monitoring social media content, sentiment analysis of crowds for opinion mining, judging abnormalities in personal behavior, etc. The demand for personality traits prediction has increased drastically after COVID-19. Therefore, numerous methods have emerged to predict personality traits from a variety of sources, including handwriting, interviews, social media, text, images, and audio. This review focuses on methods developed between the years 2020 and 2024, categorizing them into Handwriting (Graphology), Vision (images and videos), Audio (speech and acoustic signals), Textual (status updates, descriptions), and Multimodal (combinations of the aforementioned) approaches. We critically analyze the methods proposed, the datasets, the scope of the work, the results obtained, and noteworthy remarks. Based on our critical analysis, we notice that increasingly methods tend to use deep learning over handcrafted features. Additionally, personality traits prediction methods are trending more toward multimodal methods because they consistently achieve the highest accuracy among the input modalities. Detailed discussions, tabular presentations, and figures facilitate easy comprehension and future reference. Then, we shed light on the challenges in this field. Many key applications are detailed. Additionally, we highlight significant limitations and offer insights into potential future directions.},
  archive      = {J_IJPRAI},
  author       = {Kunal Biswas and Shivakumara Palaiahnakote and Umapada Pal and Ram Sarkar},
  doi          = {10.1142/S0218001425300024},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2530002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Personality traits prediction methods: A survey},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The time and frequency distribution characteristics of interference signals based on artificial intelligence technology. <em>IJPRAI</em>, <em>39</em>(11), 2559014. (<a href='https://doi.org/10.1142/S0218001425590141'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a method with artificial intelligence to optimize manual astronomical observation works. For the large amount of data generated by radio astronomy monitoring, we compile 4 algorithms including VTD, WSV, MAD, and MAS in the procedure of data analysis. Then the platform can recognize the radio interference signals from radio astronomy monitoring data and analyze the spatiotemporal distribution characteristics, and generate reports automatically. Through this method, the amount of work would greatly improve work efficiency and accuracy. The distribution patterns and changes of radio frequency interference signals in the area can be grasped and analyzed efficiently and quickly by astronomy researchers.},
  archive      = {J_IJPRAI},
  author       = {Shengyang Li and Zhixiang Zhao and Bin Tian and Junwen Tang and Ning Fu and Liang Dong},
  doi          = {10.1142/S0218001425590141},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2559014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {The time and frequency distribution characteristics of interference signals based on artificial intelligence technology},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bipartite coordination control for multi-robot systems with coopetition-interaction. <em>IJPRAI</em>, <em>39</em>(11), 2559013. (<a href='https://doi.org/10.1142/S021800142559013X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distributed bipartite coordination control problem of multi-robot systems (MRSs) with coopetition-interaction is investigated in this paper. First, a novel symmetric positive definite matrix is constructed based on bipartite consensus protocol without taking into account mutual velocity information, where the control gain constant is determined by the properties of the Laplacian matrix corresponding to the directed graph. Second, leveraging matrix decomposition properties, our schemes ensure the symmetric evolution of the convergence state and the explicit expression of the bipartite containment solution for all followers. Finally, two numerical simulations are presented to demonstrate the feasibility and effectiveness of the proposed algorithms.},
  archive      = {J_IJPRAI},
  author       = {Jingyi Liu and Hengyu Li and Hongkun Zhou},
  doi          = {10.1142/S021800142559013X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2559013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Bipartite coordination control for multi-robot systems with coopetition-interaction},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local attention mechanism and temporal prediction-based multi-person pose estimation. <em>IJPRAI</em>, <em>39</em>(11), 2557018. (<a href='https://doi.org/10.1142/S0218001425570186'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, attention mechanisms have been widely used in many fields due to their excellent image focusing ability to produce more discriminative feature representations. However, in human pose estimation, methods based on attention mechanisms tend to have high computational overhead and are difficult to process video data in real time. In addition, existing algorithms do not make good use of the similarity between consecutive frames, and often repeat the computation many times on the same image. Therefore, this paper proposes a method based on a local attention mechanism and temporal prediction. The method first passes the input image through a body detector and then focuses attention on the head of the person, generating a large module of head information perception. This helps to find all the people in the image, avoiding missed detections, and this approach, which uses a local attention mechanism, has a small computational overhead. Then, to make the network layers closer to each other while keeping the parameters sparse, the features generated by the deep network will be reconstructed and compared with the input image. Finally, in order to reduce repetitive computation, the method determines the similarity between the preceding and following frames by means of multiple sampling points, which is used to determine whether the information from the previous frame is used to guide the localization of the nodes in the following frame. This allows the algorithm to remain real time when processing video. Experiments on the COCO and PoseData I datasets show that the algorithm outperforms all 10 comparison algorithms in terms of both accuracy and image continuity.},
  archive      = {J_IJPRAI},
  author       = {Jianghai He and Ting Wu and Ronghua Shang and Weitong Zhang and Yangyang Li},
  doi          = {10.1142/S0218001425570186},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2557018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Local attention mechanism and temporal prediction-based multi-person pose estimation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MFAF-net: Lung lobe segmentation in CT images based on multiscale feature and attention fusion network. <em>IJPRAI</em>, <em>39</em>(11), 2557017. (<a href='https://doi.org/10.1142/S0218001425570174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computed tomography (CT) images are widely used as clinical aids. Accurate lung lobe segmentation in CT images provides a strong basis for the diagnosis and treatment of lung diseases, but challenges arise from incomplete fissures, unpredictable pathological deformations, indistinguishable pulmonary arteries and veins, and severe injuries to the lung airways. To tackle these issues, we propose a multiscale feature and attention fusion network (MFAF-Net), which emphasizes lung fissure representations and suppresses the influence of other structures in lung lobe segmentation. First, the network follows the traditional encoder–decoder structure, incorporating FastKANConv-based residual modules to prevent gradient vanishing and further improve the spatial feature information extraction capability. Second, the adaptive spatial feature fusion module (ASFF), the atrous spatial pyramid pooling module (ASPP), and the feature fusion strategy are fused to address the target feature information loss issue effectively. Third, a stronger spatial and channel squeezing and excitation module (scSE) is improved to extract semantic information in both the spatial and channel domains in the skip connection part. The efficacy of the presented model is validated through experiments conducted on an existing dataset, which demonstrate superior intersection over union (IoU) values and lower Hausdorff distances (HD) than other efficient segmentation networks. The experimental results substantiate that the designed framework can effectively segment lung lobes in CT images.},
  archive      = {J_IJPRAI},
  author       = {Yuanyuan Peng and Jiawei Liao},
  doi          = {10.1142/S0218001425570174},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2557017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {MFAF-net: Lung lobe segmentation in CT images based on multiscale feature and attention fusion network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visual rhythms-based video face spoofing detection using deformable self-attention ResNet model. <em>IJPRAI</em>, <em>39</em>(11), 2557010. (<a href='https://doi.org/10.1142/S0218001425570101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are primarily three types of techniques that may compromise face authentication: print, replay, as well as 3D mask. It seems that video replay assaults are the most difficult to detect out of all of them. Even if there are a lot of ways to prevent spoofing assaults, especially with high-quality videos, a sophisticated detector is still required. This study describes video-based spoofing techniques by analyzing the frequency-domain noise residual and extracting discriminative features with a dynamic texture descriptor. We present a potential detector that outperforms the state-of-the-art on the most difficult video spoofing dataset. On the other side, inexperienced camera operators often introduce undesired camera shake or motion into their recordings. The goal of video face spoofing methods is to improve the quality of the captured image by identifying and fixing any imperfections that may have occurred during capture. To assess video face spoofing techniques qualitatively, we offer and examine a new representation using Visual Rhythms (VR). The efficiency of the visual representation as a qualitative metric for analyzing spoofing attacks is shown via experiments done on various video sequences. Using ResNet-18, our database achieved a spoofing detection accuracy of 99.75%. Spoof detection abilities were better for photographs with a pinch angle, close distance images, with replay assaults compared to front images, far distance visuals, with print attacks, respectively, according to the trial findings for different circumstances. Compared to testing with6 other databases (DBs) before training with our DB, the results of the cross-database verification showed an improvement in performance. Since there was little variation in the findings of the cross-device verification based on camera type, we can say that the detection accuracy is unaffected by the kind of image sensor. We also provide a method to objectively determine a measure derived from VR. The experiment found that the Total Error Rate (HTER) for the four independent data sets was 3.5%, whereas the synthesized data set had an HTER of 1%.},
  archive      = {J_IJPRAI},
  author       = {Devi Palanisamy and S. Anila},
  doi          = {10.1142/S0218001425570101},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2557010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Visual rhythms-based video face spoofing detection using deformable self-attention ResNet model},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A real-time application-based bidirectional long short-term memory-based adam optimizer for leaf disease classification in sugarcane leaves. <em>IJPRAI</em>, <em>39</em>(11), 2557009. (<a href='https://doi.org/10.1142/S0218001425570095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sugarcane is considered to be a vital crop across worldwide, but the production of it is impacted by the effect of different diseases. Early diagnosis and detection are mandatory for the timely intervention and yield preservation. This will ensure the optimal yield of the crop and its quality. Hence in this approach a real-time hybrid approach BADAM is proposed for the detection and classification of the sugarcane leaf diseases. The hybrid approach BADAM consists of Bidirectional Long Short-Term Memory (BiLSTM) network combined with the Adam optimizer. For training the model both disease-affected leaves and the nonaffected leaves are considered and initially subjected to preprocessing model for enhancing the feature extraction process. The BiLSTM model is designed to capture both temporal and spatial dependencies within the image sequences, effectively addressing the challenges posed by varying leaf conditions and environmental factors. The Adam optimizer is employed to improve convergence rates and enhance model performance through adaptive learning rates. The model’s performance is evaluated using the metrics like accuracy, recall, F 1 -score and precision by demonstrating significant improvements over traditional classification methods. The experimentation results indicate that the proposed approach provides better accuracy by facilitating the real-time disease detection by making it comfortable by providing a valuable tool for farmers and agricultural practitioners. The implications of this work extend to the development of smart agricultural systems that leverage deep learning technologies for sustainable farming practices. This approach not only provides an effective tool for leaf disease classification but also establishes a foundation for future research in precision agriculture and plant health monitoring, promoting sustainable farming practices through early disease detection and intervention.},
  archive      = {J_IJPRAI},
  author       = {J. Chandraleka and P. Selvaraj},
  doi          = {10.1142/S0218001425570095},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2557009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A real-time application-based bidirectional long short-term memory-based adam optimizer for leaf disease classification in sugarcane leaves},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective image denoising model using improved deep learning techniques with optimization algorithm. <em>IJPRAI</em>, <em>39</em>(11), 2552018. (<a href='https://doi.org/10.1142/S0218001425520184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physicians and radiologists utilize medical image processing to diagnose diseases. However, medical images can be compromised by noise introduced through various imaging processes, leading to diminished image quality. This degradation manifests as blurred boundaries, suppressed edges, and loss of structural details. Preserving edges and details is crucial for accurate disease diagnosis. Therefore, medical image denoising is essential in aiding physicians with diagnosis. MRI, CT, X-ray, and ultrasound images are examples of common medical image types. To overcome the above problems, this work implemented an Improved Convolutional Neural Network (ICNN) with the Self-Improved Orca Predation Algorithm (SI-OPA) for image denoising for medical image denoising. ICNN has been used to treat noise-distorted medical images. The CNN’s weights are modified by SI-OPA, increasing the precision of denoising. Comprehensive evaluations concern cutting-edge denoising approaches, encompassing conventional, and deep learning-based methods, emphasizing denoising efficacy, computing efficiency, and picture detail retention. Compared to traditional image denoising algorithms, the proposed method offers superior noise suppression, as evidenced by improved accuracy, Structural Similarity (SSIM), Peak Signal-to-Noise Ratio (PSNR), and Standard Deviation (STD) metrics. Additionally, experimental findings support the suggested denoising algorithm’s viability and efficiency. Finally, the findings show that whereas the current approaches only reach 86%, 82%, 78%, and 65% of the study results, the suggested model achieves a high 94%. Accuracy is 91%, SSIM is 0.91, PSNR is 45.75%, and STD metrics is 43.89%.},
  archive      = {J_IJPRAI},
  author       = {S. Mythili and S. S. Sivaraju and T. Anuradha and S. Sivarajan},
  doi          = {10.1142/S0218001425520184},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2552018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An effective image denoising model using improved deep learning techniques with optimization algorithm},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic compiler tuning for inlining with machine learning. <em>IJPRAI</em>, <em>39</em>(11), 2552016. (<a href='https://doi.org/10.1142/S0218001425520160'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic compiler tuning has become one of the hot research areas attracting extensive attention in recent years. By using machine learning models to learn from large-scale experimental samples, it can efficiently search through the massive combinations of compiler optimization parameters within limited time, identifying parameter sets that better suit the current microprocessor architecture and application programs, thereby achieving higher execution efficiency of target programs than default compilation options. This paper designs and implements an automatic compiler tuning mechanism, employing an XGBoost performance model built through a “learn-while-searching” approach to guide the search process of simulated annealing algorithm (SA). The XGBoost model can predict the performance deltas of different GCC optimization parameters, and these deltas are used to bias the annealing acceptance probability. This mechanism combines the global modeling capability of machine learning with the local search advantages of the SA, enhancing both search efficiency and effectiveness. Based on this tuning mechanism, the paper conducts in-depth research on the inlining optimization process inside the GCC compiler, proposing and implementing two automatic tuning schemes: (1) automatic tuning of inlining compilation options, which influences the number of inlined functions through different values of these options, thereby affecting program performance; (2) automatic tuning of function inlining at call sites, which uses GCC plugins technology to replace the ipa-inline pass in GCC optimization, enabling control over whether to inline functions at each call site and thus impacting program performance. Extensive experiments are conducted on benchmark suites such as SPEC CPU2006, cBench, and WRF. The results show that compared with the Critical Flag Selection-based Compiler Auto-tuning (CFSCA) method published in ASE2023, the Bayesian Optimization-based Compiler Auto-tuning (BOCA) method published in ICSE2021, and other traditional search algorithms, the proposed tuning mechanism achieves better optimization effects on most benchmarks.},
  archive      = {J_IJPRAI},
  author       = {Da Huang and Xiaohua Shi and Yuchen Feng and Changhai Zhao and Jiamin Wen and Minqiang Shang},
  doi          = {10.1142/S0218001425520160},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2552016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Automatic compiler tuning for inlining with machine learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedIoT: Optimizing the communication-efficient federated learning aggregation algorithm under heterogeneous data for large-scale IoT. <em>IJPRAI</em>, <em>39</em>(11), 2552013. (<a href='https://doi.org/10.1142/S0218001425520135'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training machine learning models effectively under severe communication, computation, and privacy restrictions has become more challenging due to the fast proliferation of Internet of Things (IoT) networks. With federated learning, dispersed IoT devices may train together without exposing any sensitive data. Unfortunately, privacy concerns, device heterogeneity, and communication constraints are common issues with large-scale installations. Through the utilization of adaptive asynchronous training, dynamic communication optimization, hierarchical aggregation, and differential privacy enhancement, we present a new federated learning communication framework that can withstand device delays, minimize bandwidth usage, improve scalability through edge-cloud coordination, and guarantee the protection of user data. Extensive testing on both real-world and synthetic datasets shows that the suggested architecture drastically cuts down on communication cost and training delay in heterogeneous IoT environments, all while keeping model accuracy high and privacy resilient.},
  archive      = {J_IJPRAI},
  author       = {Qing Yan and Guoshi Wang and Dazhi Zhu and Jinxun Li},
  doi          = {10.1142/S0218001425520135},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2552013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {FedIoT: Optimizing the communication-efficient federated learning aggregation algorithm under heterogeneous data for large-scale IoT},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ResCap-MobileNet: Integrating multi-modal feature extraction and ensemble learning for osteoporotic fracture detection. <em>IJPRAI</em>, <em>39</em>(11), 2551013. (<a href='https://doi.org/10.1142/S0218001425510139'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Osteoporotic fracture risk prediction algorithms using clinical risk factors, with or without bone mineral density measurements, have improved the accuracy of treatment targeting, yet current methods often suffer from limitations in image quality, computational cost, and diagnostic precision. To address these challenges, this methodology proposes a novel ensemble learning framework that introduces a novel ensemble learning framework called ResCap-MobileNet, to improve osteoporosis diagnosis using multi-modal medical imaging data taken from X-ray images. The approach begins with preprocessing, where contrast-limited adaptive histogram equalization (CLAHE) enhances image quality, followed by guided filtering for denoising and augmentation techniques like shearing and flipping. Segmentation is performed using a dual-scale residual U-Net (DSR_U-Net) for accurate identification of osteoporotic regions. For feature extraction, graph convolution networks (GCNs) preserve node connectivity in irregular data, while spherical harmonic transforms (SHTs) and topological data analysis (TDA) capture spatial and topological patterns. Feature selection is optimized through the self-adaptive hippopotamus optimization (SAHO) algorithm, which enhances global exploration with predator defense and exploration strategies. The classification stage utilizes ResCap-MobileNet, which integrates ResNeXt-101, MobileNetV3, and a capsule network (CapsNet) to ensure precise identification of osteoporotic fractures.},
  archive      = {J_IJPRAI},
  author       = {Srilatha Yelamati and Srikanth Thota},
  doi          = {10.1142/S0218001425510139},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2551013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {ResCap-MobileNet: Integrating multi-modal feature extraction and ensemble learning for osteoporotic fracture detection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metric-based shape segmentation and retrieval. <em>IJPRAI</em>, <em>39</em>(11), 2550018. (<a href='https://doi.org/10.1142/S0218001425500181'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skeleton cut space has been used in shape segmentation and shape retrieval, and gives comparable good results in these two fields. However, only the cut length of the skeleton cut model has been used for these two research topics. So, we propose other three metrics extracted from the skeleton cut model for shape segmentation and retrieval. These metrics are max distance metric, average distance metric, and max–min distance metric. Finally, we show shape segmentation and retrieval experimental results by using our metrics. Our proposed metrics have added value to part-based segmentation and shape retrieval.},
  archive      = {J_IJPRAI},
  author       = {Cong Feng and Fangfang Peng and Ning Wang},
  doi          = {10.1142/S0218001425500181},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2550018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Metric-based shape segmentation and retrieval},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint waveform design of cognitive MIMO radar for multi-target detection. <em>IJPRAI</em>, <em>39</em>(11), 2550015. (<a href='https://doi.org/10.1142/S0218001425500156'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The waveform design for cognitive multiple input multiple output (MIMO) radar systems remains an active area of research in modern radar signal processing. This study tackles the critical challenge of multi-target detection in cognitive MIMO radar by maximizing the minimum output signal-to-interference-plus-noise ratio (SINR) across all the detected targets. To resolve the nonconvex optimization problem arising from multi-target scenarios, we implement a semi-definite programming (SDP) algorithm incorporating approximate output SINR. Joint waveforms, including intra-pulse and inter-pulse, are applied to improve the freedom of the radar. The proposed work specifically integrates practical peak-to-average ratio (PAR) limitations, ensuring waveform feasibility for implementation in physical radar systems. Simulation results show that the proposed joint waveform can achieve more robust simultaneous multi-target detection performance in coherent clutter, while suppressing coherent interferences from other targets when detecting a certain target. Besides, our optimization algorithm has better real-time performance than existing algorithms.},
  archive      = {J_IJPRAI},
  author       = {Yunlei Zhang and Ke Li and Tingli Shen and Pei Peng},
  doi          = {10.1142/S0218001425500156},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2550015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Joint waveform design of cognitive MIMO radar for multi-target detection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pedestrian detection using event cameras and YOLOv8: An optimized event stream to event frame conversion algorithm. <em>IJPRAI</em>, <em>39</em>(11), 2532002. (<a href='https://doi.org/10.1142/S0218001425320027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian detection is a crucial aspect of intelligent transportation systems and autonomous driving technologies, ensuring the safety and reliability of these systems. This paper presents a novel approach to pedestrian detection utilizing event cameras and the YOLOv8 model. The core of our methodology lies in a newly optimized algorithm for converting event streams to event frames, specifically tailored for pedestrian recognition. By addressing the unique challenges posed by high-speed and dynamic environments, our approach enhances the accuracy and efficiency of pedestrian detection systems. The proposed algorithm leverages the temporal and spatial resolution advantages of event cameras, effectively reducing noise and improving the clarity of the event frames through advanced denoising techniques such as temporal filtering, spatial filtering, and polarity consistency checks. These techniques ensure precise feature extraction and robust pedestrian identification. We conducted extensive road tests using the EVK4 event camera, capturing dynamic scenes involving pedestrian movement in various real-world conditions. Our experimental results demonstrate significant improvements in detection performance, achieving an Average Precision (AP) of 88.6%, a detection speed of 114 FPS, and high robustness under low light and high contrast conditions.},
  archive      = {J_IJPRAI},
  author       = {Qiufeng Wang and Qianying Guo and Kui Zhang and Lin Liu},
  doi          = {10.1142/S0218001425320027},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2532002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Pedestrian detection using event cameras and YOLOv8: An optimized event stream to event frame conversion algorithm},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent predictive battery management system with optimized bayesian LSTM network for lithium-ion batteries. <em>IJPRAI</em>, <em>39</em>(10), 2559011. (<a href='https://doi.org/10.1142/S0218001425590116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an Intelligent Predictive Battery Management System (IPBMS) designed to enhance the longevity, safety, and performance of lithium-ion batteries in e-bikes. Conventional battery management systems often estimate State of Charge (SoC), State of Health (SoH), or Remaining Useful Life (RUL) independently, limiting their effectiveness in predictive maintenance. To bridge this gap, the proposed IPBMS provides a comprehensive framework that simultaneously estimates SoC, SoH, and RUL, enabling a holistic battery health assessment. Hot Deck Imputation addresses missing and inconsistent data to ensure data reliability, while an Unscented Kalman Filter models battery nonlinearities, enhancing SoC estimation accuracy. Additionally, an Optimized Bayesian LSTM, refined with Mountain Gazelle Optimization, captures temporal dependencies to improve SoH and RUL predictions, further refined using a dense regression layer that minimizes errors. The model achieves Mean Absolute Error (MAE), Mean Squared Error (MSE), and Root Mean Squared Error (RMSE) of 0.59, 1.28, and 1.13 for SoC; 0.87, 1.50, and 1.22 for SoH; and 1.60, 1.28, and 2.69 for RUL, outperforming conventional models. Beyond prediction, the IPBMS offers actionable insights for charging optimization, early fault detection, energy-saving strategies, and adaptive riding modes, ensuring safer and more efficient battery utilization. This framework extends battery lifespan, minimizes unnecessary replacements, and enhances sustainability by optimizing energy management and reducing environmental impact, providing a novel, practical solution to improve battery reliability and efficiency in modern electric transportation.},
  archive      = {J_IJPRAI},
  author       = {P. Suresh Kumar and Niresh Jayarajan},
  doi          = {10.1142/S0218001425590116},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2559011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Intelligent predictive battery management system with optimized bayesian LSTM network for lithium-ion batteries},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heart disease detection using green anaconda optimization selection and MLGConv-based LWTNet classification with enhanced PeaFowl-based artificial intelligence algorithm. <em>IJPRAI</em>, <em>39</em>(10), 2557011. (<a href='https://doi.org/10.1142/S0218001425570113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The leading cause of death worldwide is heart disease. To counter this, a Deep Learning (DL) system, a subset of Artificial Intelligence (AI), has been developed to lower mortality rates by utilizing clinical insights for early detection. This study presents a novel method for diagnosing heart disease in patients and improving their prognosis. The extensive analysis is supported by multiple datasets sourced from repositories like UCI and Kaggle and locations like Long Beach, Cleveland, Switzerland, and Hungary. Gaussian Noise Removal, Motion Noise Reduction, and Contact Loss Handling (CLH) are used with a Fuzzy Inference System (KL-based FIS) integrated with Kalman filtering during the data preprocessing stage. The state-of-the-art Green Anaconda Optimization (GAO) is used for feature selection, simulating the stages of exploration and exploitation seen in wild green anacondas (GAs). The Multi-Level Group Convolution Light Weight Transformer Network, or LWTNet, which is based on MLGConv, is the foundation of the heart disease classification model. MLGConv is a module that effectively maintains lower computational costs while simultaneously representing multi-level and multi-group features, thereby improving local feature diversity. The Light Former transformer block comes from MLGConv and uses the least processing power to capture global dependencies, resulting in the final LWTNet. The Enhanced PeaFowl Optimization Algorithm (EPFOA) is utilized in the hyperparameter tuning of the classifier model. Interestingly, the suggested model outperforms earlier versions, with a remarkable accuracy rate of 99.87% in a comparative study.},
  archive      = {J_IJPRAI},
  author       = {Priyan Malarvizhi Kumar and C. Gokulnath and Jeeva Selvaraj and Balasubramanian Prabhu Kavin},
  doi          = {10.1142/S0218001425570113},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2557011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Heart disease detection using green anaconda optimization selection and MLGConv-based LWTNet classification with enhanced PeaFowl-based artificial intelligence algorithm},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DeepSkinGuard: A robust skin cancer detection framework integrating modified U-net segmentation and QuadraBlendNet fusion. <em>IJPRAI</em>, <em>39</em>(10), 2557007. (<a href='https://doi.org/10.1142/S0218001425570071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Global concern over skin cancer prompts the need for early detection to improve patient outcomes. This research addresses the critical issue of skin cancer detection, emphasizing the significance of early diagnosis for improved patient outcomes. The study identifies existing challenges in accuracy and robustness within current detection systems. To overcome these limitations, an advanced methodology is proposed, integrating cutting-edge techniques at every stage of the process. Methods: The research outlines key objectives, including the development of a comprehensive image augmentation strategy, the implementation of sophisticated preprocessing techniques, and the design of a modified U-Net architecture for accurate Region of Interest (ROI) identification. The hybrid optimization model, Bridging Optimization: Eagles’ Cruise Attack Fusion (BOECAF) Algorithm, merges the strengths of the Bald Eagle Search Optimization (BES) and Golden Eagle Optimizer (GEO) to effectively optimize the batch size of the U-Net. Deep learning-based feature extraction is employed using a pre-trained Inception V3, complemented by the extraction of color-based and texture-based features. A weighted feature fusion approach is introduced to effectively combine these diverse features. The integration of the QuadraBlendNet model, incorporating SqueezeNet, Xception, ResNet50, and DenseNet201, culminates in a comprehensive and diverse representation for skin cancer detection. Results: Utilizing Python, the model is implemented and yielded an accuracy of 98%, showcasing its high performance in classification tasks, and the ISIC dataset is used for evaluation. Conclusion: Anticipated outcomes include enhanced accuracy, improved generalization capabilities, and a significant advancement in early skin cancer diagnosis. This research contributes to the field by offering a more reliable and effective approach to address current limitations in skin cancer detection methodologies.},
  archive      = {J_IJPRAI},
  author       = {Joseph George and A. Parivazhagan},
  doi          = {10.1142/S0218001425570071},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2557007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {DeepSkinGuard: A robust skin cancer detection framework integrating modified U-net segmentation and QuadraBlendNet fusion},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic attention-augmented neural network for accurate and efficient brain tumor classification and segmentation using MRI. <em>IJPRAI</em>, <em>39</em>(10), 2557005. (<a href='https://doi.org/10.1142/S0218001425570058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic Resonance Imaging (MRI) classification and segmentation of brain tumors are still an important problem in medical imaging because tumors are typically heterogeneous and multicellular. Old-fashioned diagnostics do not scale, generalize or compute efficiently, and hence do not apply clinically. In order to overcome these problems, the research introduces a new Dynamic Attention-Augmented Neural Network (DAANN) that will improve the classification accuracy, robustness and computational efficiency of brain tumors. The proposed DAANN features a dynamic attention system that enables it to choose the diagnostically relevant areas from MRI images automatically, enabling it to perform even in noisy or sparse data. Combined with feature extraction over time, the model captures morphological and sequential dependencies to render full tumor analysis. When trained on benchmark MRI images, the DAANN had a classification precision of 94.8% and topped models like CNN and BiLSTM. The model was also robust to noise — with 89.0% accuracy under moderate noise levels — and operated efficiently using very little training data, with 78.0% accuracy on 10% of the training set. These findings point to the DAANN’s real-time clinical availability in resource-constrained settings. As it takes up the challenge of what is possible, this work adds value to medical imaging as it provides a scalable and reproducible way to diagnose brain tumors. The work in the future will be to extend the model to multi-organ classification and to make it more easily read by clinical decision makers.},
  archive      = {J_IJPRAI},
  author       = {Manjunathan Alagarsamy and Jeevitha Sakkarai and E. Mariappan and K. Malathi and G. K. Kamalam and Arun Anthonisamy and Faisal Alshanketi and A. Rajaram},
  doi          = {10.1142/S0218001425570058},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2557005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Dynamic attention-augmented neural network for accurate and efficient brain tumor classification and segmentation using MRI},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Some efficient stock price trend prediction based on multi-category textual information and support vector machines. <em>IJPRAI</em>, <em>39</em>(10), 2555014. (<a href='https://doi.org/10.1142/S0218001425550146'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a selected portfolio of large-cap blue-chip stocks in China A-share market, this study selects and quantifies three categories of textual information with comparatively notably low average daily volume: responses from Secretaries of the Boards of Listed Companies (RSB), Comments by Internet Influencers on Listed Companies (CII), and Official Press Releases of High-level Meetings of the Communist Party of China and Central Government (R-M-P&G). Then, for every category of textual information, the predictive role of a Gaussian Kernel Learning-Support Vector Machine(GKL-SVM) model, employing the information independently, is explored and assessed on stock (price) trends. Based on a comparative analysis of A-share market transaction data for this investment portfolio over the past three years, the GKL-SVM model, individually utilizing any type of textual information, demonstrates some enhancement in predicting short-term trends of Daily Closing (DC) stock prices compared to the coin-toss benchmark. These improvements further enable the corresponding Intraday Decision-making Short-term (IDS) trading strategy to achieve positive average daily returns in a simulated trading environment. Furthermore, by innovatively adapting the Multi-Kernel Learning (MKL) applied in Support Vector Machine (SVM) models into a Multi-Gauss-Kernel Learning (MGKL) framework consisting of the three GKs employed, respectively, for the above three different categories of textual information, i.e. RSB, CII, and R-M-P&G, the corresponding MGKL-SVM model is constructed for DC stock (price) trend prediction. This novel modeling approach integrating multiple categories of textual information not only significantly reduces the volume of textual data required and the computational complexity for intelligent analysis but also achieves a 10 + percentage point improvement in prediction accuracy compared to the three single-category (text-processing) GKL-SVM models (termed RSB, CII, and R-M-P&G (category) GKL-SVM models). The simulated trading results further demonstrate that the IDS trading strategy generates superior average daily returns relative to its single-category GKL-SVM counterparts. Finally, applying the MGKL-SVM model to Weekly Closing (WC) stock (price) trend prediction achieves significantly higher accuracy than daily prediction, indicating its potential practical value for medium-to-long-term value investing.},
  archive      = {J_IJPRAI},
  author       = {Yangsong He and Yao Ge and Gengyu Zhan and Yanhong Gu},
  doi          = {10.1142/S0218001425550146},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2555014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Some efficient stock price trend prediction based on multi-category textual information and support vector machines},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TNet: Power pole classification with deep learning for automated inspection in smart grids. <em>IJPRAI</em>, <em>39</em>(10), 2555013. (<a href='https://doi.org/10.1142/S0218001425550134'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With advancements in artificial intelligence, the field of power inspection faces challenges in utilizing upgraded AI technologies to improve operational efficiency. As part of the smart grid initiative, each power pole must be accurately modeled. However, manual classification of strain poles and tangent poles remains hindered by three primary limitations: low accuracy, high costs, and poor timeliness. To address these issues, this paper introduces the following contributions: (1) A computer vision model, TNet, is proposed to distinguish strain poles from tangent poles, leveraging a stable T module and ResNet to extract fine-grained features from images. This approach utilizes high-speed computing to enhance timeliness and mitigates high costs by reducing manual labor, with electricity being the only primary operational cost. (2) We introduce a newly collected power pole classification dataset, featuring images of pole heads from 6 and 10 kV power lines in a specific city. This dataset includes 695 images of tangent poles and 329 images of strain poles, with a total size of 3.52 GB. Finally, the model can achieve an accuracy of 93.76% and an F 1-score of 0.91 on the MyGT2.0 dataset. Our work has been practically applied to the circuit maintenance work of a certain power supply company in 2024.},
  archive      = {J_IJPRAI},
  author       = {Zishuo Gao and Ge Gao and Chen Liu and Yiteng Xu and Chaopeng Liu and Zhuang Luo and Yi Hu},
  doi          = {10.1142/S0218001425550134},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2555013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {TNet: Power pole classification with deep learning for automated inspection in smart grids},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing video captioning via visual-linguistic feature fusion. <em>IJPRAI</em>, <em>39</em>(10), 2555012. (<a href='https://doi.org/10.1142/S0218001425550122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video captioning is a challenging multimodal task that combines computer vision and natural language processing. Previous methods primarily extract useful information from visual features by designing sophisticated encoders. Natural language descriptions generated solely from visual features often fall short of expected performance due to the semantic gap between the visual modality and the textual modality. In this paper, we propose a novel encoder–decoder-based approach for video captioning, which enhances video feature representations by incorporating object and action-centric linguistic features from upstream encoders. Specially, we leverage a cross-attention mechanism to incorporate textual information into visual features, thereby enhancing their expressive capability. Additionally, we introduce a fusion layer to facilitate the interaction between heterogeneous representations and mitigating irrelevant noise. Extensive experiments on the MSVD, MSR-VTT and VATEX datasets demonstrate the superiority of our method and achieve significantly superior performance across standard evaluation metrics.},
  archive      = {J_IJPRAI},
  author       = {Guanghua Chen and Bin Fang},
  doi          = {10.1142/S0218001425550122},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2555012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Advancing video captioning via visual-linguistic feature fusion},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image super-resolution with dense-parallel swin transformer. <em>IJPRAI</em>, <em>39</em>(10), 2554012. (<a href='https://doi.org/10.1142/S0218001425540126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in Swin Transformer-based image super-resolution (SR) methods have demonstrated remarkable progress through efficient modeling capabilities and feature extraction. However, existing approaches still have limitations: in hierarchical feature representation architectures, inter-layer feature propagation efficiency progressively degrades with increasing network depth. For this, the paper proposes an SR model, namely, SwinDPSR, composed of Dense-Parallel Swin Transformer (DPST) blocks. The proposed method innovatively constructs a densely connected parallel Swin Transformer architecture that enhances information flow through multi-level feature reuse mechanisms. Simultaneously, we introduce the Spatial Frequency Block (SFB) that establishes global contextual correlations in the frequency domain branch to precisely compensate for local detail loss. Experiments demonstrate significant improvements over the SwinIR across five benchmarks (Set5, Set14, BSD100, Urban100, and Manga109), achieving an average PSNR gain of 0.28 dB in 4 × SR tasks. Theoretical analysis and experimental validation confirm the effectiveness of the parallel architecture, which improves FPS by 6.8% through enhanced computational parallelism. Ablation studies verify the synergistic optimization effect of dense connections and SFB.},
  archive      = {J_IJPRAI},
  author       = {Guojin Pei and Zekun Wang and Xinxing Yang and Genke Yang and Jian Chu},
  doi          = {10.1142/S0218001425540126},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2554012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Image super-resolution with dense-parallel swin transformer},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rearranging multidimensional graphic elements for graphic design applications of image enhancement. <em>IJPRAI</em>, <em>39</em>(10), 2554011. (<a href='https://doi.org/10.1142/S0218001425540114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study looks into rearranging multidimensional visual elements in graphic design for picture enhancement. It also suggests a multidimensional method for enhancing histograms and combining graphic elements that are based on the framework of a visual communication system. The three primary components of the system are an output and visual graphic display module, a data processing module, and an image collector. First, the Scale-Invariant Feature Transform (SIFT) feature description method is used to extract the multidimensional features from the graphical elements, and the feature transformation matrix calculation is used to achieve feature alignment. Subsequently, employing the window-based graphic element fusion technique, the “energy” metric determines the ideal pixel value to guarantee the correctness and smoothness of the fusion outcome. The graphic design image’s histogram is then created, denoised, and enhanced utilizing a combination of standard variance and entropy as the local complexity measurement factor. In the end, MATLAB 2020a simulation tests are conducted, and peak signal-to-noise ratio and structure similarity index are used to confirm the effectiveness of this paper’s approach. The experimental findings demonstrate that the suggested method effectively denoises and enhances photos and can greatly increase images’ visual impact and detail richness. This work offers theoretical justification and a novel, efficient technique for optimizing graphic design pictures.},
  archive      = {J_IJPRAI},
  author       = {Zhongda Cao},
  doi          = {10.1142/S0218001425540114},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2554011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Rearranging multidimensional graphic elements for graphic design applications of image enhancement},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Breakpoint resumption migration method of two-level sharding for single table with billion data. <em>IJPRAI</em>, <em>39</em>(10), 2554010. (<a href='https://doi.org/10.1142/S0218001425540102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the arrival of the big data era, tens of billions of single-table big data generation, the increasing data scale shows how to efficiently and quickly big data migration has become a key challenge. Current traditional big data migration methods have the problem of slow migration speed, and the risk of abnormal interruptions. This paper proposes a method for breakpoint resumption migration of secondary sharding for single-table data at the billion-scale level. Dividing primary shards into secondary shards, and employing a dynamic load balancing strategy to migrate to multiple databases enhance the independence and controllability of data migration, consequently reducing overall migration time. Additionally, in case of any anomalies during the migration process, simply rolling back and re-migrating the affected data shards ensure minimal impact on other shards or the overall migration process. To evaluate the efficacy of this method, our study conducted experiments on migrating Oracle database to other databases. The findings confirmed that the proposed approach supports migration to diverse databases, and as the number of nodes increases, migration efficiency grows exponentially. Additionally, comparative experiments were conducted between the data migration tool developed by this method and both DataX and the DaMeng Transfer Service (DTS), with equivalent data volumes. The experimental results indicate that this method performs comparably well to the leading DTS in terms of migration efficiency. However, this method’s advantage lies in its support for distributed deployment, resulting in the highest overall migration efficiency. Furthermore, unlike other migration tools, it also supports migration to multiple database platforms.},
  archive      = {J_IJPRAI},
  author       = {Wensheng Tang and Zesan Liu and Tian Tian and Yanjie Wang},
  doi          = {10.1142/S0218001425540102},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2554010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Breakpoint resumption migration method of two-level sharding for single table with billion data},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design of ultra-wideband millimeter-wave circularly polarized 3D-printed lens antenna using optimized convolutional spiking network for biomedical application. <em>IJPRAI</em>, <em>39</em>(10), 2553003. (<a href='https://doi.org/10.1142/S0218001425530039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel approach to wireless communication is presented by the Circularly Polarized (CP) 3D-printed metalens lens antenna, an ultra-wideband millimeter-wave (mm-wave) antenna. Combining 3D printing technology with advanced metalens construction, it offers wide bandwidth, circular polarization, and a compact form factor, promising enhanced performance for future millimeter-wave communication systems. In this research work, an optimized Convolutional Spiking Neural Network (CSNN)-based Ultra-wideband mm-wave CP 3D-printed metalens lens antenna is proposed for kidney tumor detection. The proposed method combines phase compensation, UC design, and EM response prediction of CP 3D-printed metalens in a single framework using CSNN with Improved Poplar Optimization Algorithm (IPOA). The proposed CSNN consists of two input modules with two attention layers. The initial module smartly furnishes the necessary constraints of the Unit Cells (UC) and forecasts the transmission magnitudes. The next module predicts the geometric parameters for a CP 3D-printed metalens lens antenna. At last, the attention layer combines the geometric parameters and optimizes the design process. The error rate of CSNN is optimized by IPOA. A compact CP metalens antenna was created via 3D printing in order to evaluate the concept. The measured results indicate an 8.2% gain and a 3-dB gain bandwidth achieved by this antenna. Furthermore, the 3-dB Axial Ratio (AR) covers the whole 80–120 GHz W-band. Subsequently, the developed antenna is utilized for kidney cancer detection. The reflection coefficient was simulated using the CST microwave studio for both renal cancer and non-cancerous situations.},
  archive      = {J_IJPRAI},
  author       = {M. Ramkumar and P. Karthigaikumar and M. S. Gowtham and Sathish Kumar Nagarajan},
  doi          = {10.1142/S0218001425530039},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2553003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Design of ultra-wideband millimeter-wave circularly polarized 3D-printed lens antenna using optimized convolutional spiking network for biomedical application},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information-enhanced image denoising method based on deep learning. <em>IJPRAI</em>, <em>39</em>(10), 2552012. (<a href='https://doi.org/10.1142/S0218001425520123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image denoising is a fundamental task in computer vision, essential for enhancing visual quality and facilitating downstream applications. Traditional denoising methods often rely on handcrafted priors or statistical assumptions, which limit their effectiveness in real-world scenarios with complex noise patterns. Recent advances in deep learning have led to significant improvements by leveraging data-driven approaches. In this paper, we propose an information-enhanced image denoising framework based on deep convolutional neural networks (CNNs), which incorporates both spatial and frequency-domain features to improve denoising performance. Our method integrates a dual-branch architecture: one branch extracts spatial features using a residual CNN, while the other encodes frequency components through discrete wavelet transform (DWT) and learns texture-aware representations. A feature fusion module adaptively combines multi-scale information, enabling robust noise suppression while preserving fine structural details. Extensive experiments on standard benchmarks such as BSD68, Set12, and Urban100 demonstrate that our approach outperforms state-of-the-art denoising methods in terms of PSNR and SSIM, particularly under challenging noise levels and non-Gaussian conditions. The results confirm the effectiveness of information enhancement in deep learning-based image denoising.},
  archive      = {J_IJPRAI},
  author       = {Haocheng Luo},
  doi          = {10.1142/S0218001425520123},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2552012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Information-enhanced image denoising method based on deep learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel adaptive data transformation for contrastive learning. <em>IJPRAI</em>, <em>39</em>(10), 2551012. (<a href='https://doi.org/10.1142/S0218001425510127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although contrastive learning has been playing a critical role in pattern recognition, how to optimize positive pairs through data transformation is still not well developed up to now. In this paper, we propose a novel Adaptive Data Transformation , named ADTrans , to identify an optimal sequence of data transformations, which enables generating high-quality positive pairs adaptively during contrastive training. Extensive experiments on benchmark datasets have shown that ADTrans can improve the performance of representation learning on downstream tasks significantly, including image classification, instance segmentation, and object detection. It can achieve a classification accuracy of 12% and 9% higher than the existing MOCO v2, SimSiam, and BYOL on the STL 10 and TinyImageNet datasets, respectively, with the ResNet-18 backbone. Moreover, it outperforms MOCO v2 on COCO instance segmentation, object detection, and Pascal VOC instance segmentation.},
  archive      = {J_IJPRAI},
  author       = {Yucong Shen and Hai Phan and Frank Y. Shih},
  doi          = {10.1142/S0218001425510127},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2551012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A novel adaptive data transformation for contrastive learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced segmentation techniques for early detection of uterine fibroids using multi-scale feature extraction and hybrid ensemble classification. <em>IJPRAI</em>, <em>39</em>(10), 2551011. (<a href='https://doi.org/10.1142/S0218001425510115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early uterine fibroids detection must be essential because it will avoid complications and improve patient outcomes. Segmentation techniques in medical imaging, such as MRI and ultrasound, have been used to identify and delineate fibroids for diagnosis. Traditional approaches with Thresholding, region growth, and edge detection approaches showed various degrees of success. Still, they always encountered problems such as poor boundary delineation, sensitivity to noise, and inability to distinguish fibroids from surrounding tissues. All these issues reflect the shortcomings of current technology approaches toward dealing with complexity and variability in shapes and sizes of fibroids, calling for more advanced techniques for segmenting these structures to enhance detection accuracy and minimize false negatives. The proposed work introduces two novel segmentation and classification frameworks that could improve the accuracy of uterine fibroid detection by removing the limitations that have been mentioned. First, this work presents in the first phase an adaptive multi-scale feature segmentation model for fibroid features across multiple scales with improved boundary detection using an Adaptive Multi-Scale Feature Segmentation Network (AMFS-Net). It applies edge-water segmentation (EWS), one of the developed hybrid techniques combining the well-known ‘Edge Detection Algorithm’ with the very popular ‘Watershed Algorithm’. The EWS method aims to combine the advantages of both algorithms to offer better segmentation accuracy and reliability in areas where traditional methods cannot be used due to high levels of noise or complexities within the images. The second phase of the proposed work realizes the hybrid multi-layer ensemble classification model (HME-CM), which combines the strengths of multiple classifiers for boosting segmentation performances. This is superior in performance, with detection accuracy being 98.4%. Thus, the resultant work is improved and not limited by the state-of-the-art methods, providing a more reliable early detection system of uterine fibroids.},
  archive      = {J_IJPRAI},
  author       = {Minu Inba Shanthini Watson Benjamin and J. Visumathi},
  doi          = {10.1142/S0218001425510115},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2551011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Enhanced segmentation techniques for early detection of uterine fibroids using multi-scale feature extraction and hybrid ensemble classification},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improvement of the control and surveillance process for automotive diagnostic centers through the development of a computer vision and deep learning-based software. <em>IJPRAI</em>, <em>39</em>(9), 2557008. (<a href='https://doi.org/10.1142/S0218001425570083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the development and implementation of the “Manhattan” system, a proprietary software solution designed to enhance control and surveillance processes in Automotive Diagnostic Centers (CDAs) in Colombia carried out by Compaa Internacional de Integracin S.A. (CI2). The primary objective of this project was to address critical inefficiencies and fraud risks in vehicle inspections by leveraging Industry 4.0 technologies, including Computer Vision, Deep Learning, and Artificial Intelligence. The system integrates modular applications such as Oslo (for real-time license plate recognition using YOLO-Darknet with 98.8% accuracy), Platino (for video consolidation), and Gambito (for secure data transmission), ensuring seamless coordination with regulatory entities like the Superintendence of Ports and Transport. Validated across 2 CDAs that involbe 2.094 characters, and later deployed in 419 centers (covering 60% of the national market), the system demonstrated a 70% reduction in operational costs, a 40% improvement in video processing speed, and a 45% increase in data transmission capacity. These results highlight its scalability and effectiveness in automating inspections, reducing fraud, and optimizing resource utilization. The project underscores the transformative potential of AI-driven solutions in regulatory compliance and industrial automation.},
  archive      = {J_IJPRAI},
  author       = {Leonel Alberto Forero Forero and Giovanny Andres Diaz Vargas and Sergio Guarin Valencia and Jhon Jairo Ayala and Jhonathan Mauricio Vargas Barbosa},
  doi          = {10.1142/S0218001425570083},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2557008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Improvement of the control and surveillance process for automotive diagnostic centers through the development of a computer vision and deep learning-based software},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). One-step multi-frame inpainting framework for real-time lip-sync digital human generation. <em>IJPRAI</em>, <em>39</em>(9), 2557006. (<a href='https://doi.org/10.1142/S021800142557006X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, audio-driven lip-synching generation for digital humans has attracted considerable attention. However, the prevailing methodologies frequently encounter challenges pertaining to elevated computational complexity and deficient real-time performance. Although the MuseTalk framework has achieved notable progress in inference efficiency through its end-to-end, latent-space-based single-step generation algorithm, it still suffers from noticeable lip jitter and insufficient synchronization between audio and lip movements. To address these limitations, we propose an enhanced multi-frame inpainting framework that integrates Variational Autoencoders (VAE) and a multi-scale U-Net architecture. Specifically, our approach directly synthesizes the occluded lip region by leveraging multi-frame visual references combined with corresponding audio embeddings, thereby effectively improving lip synchronization and maintaining identity consistency. Furthermore, we introduce a landmark-guided multi-frame sampling strategy designed to enhance model attention towards lip dynamics. To facilitate deeper feature extraction and fusion, we propose a hierarchical latent-space feature fusion network (FusionNet), incorporating global and local residual connections and an enhanced Convolutional Block Attention Module. Additionally, a frame interpolation technique is employed during inference to further smooth lip movements and significantly mitigate lip jitter. The model has been trained on a large-scale Chinese dataset and comprehensively evaluated using both Chinese and English datasets. The experimental results demonstrate that the proposed framework achieves high visual accuracy, consistent lip synchronization, and efficient real-time inference, highlighting its strong cross-lingual generalization capability.},
  archive      = {J_IJPRAI},
  author       = {Yijun Bei and Yunze Qi and Hengrui Lou and Erteng Liu and Ke Wang and Hongchang Zhang},
  doi          = {10.1142/S021800142557006X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2557006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {One-step multi-frame inpainting framework for real-time lip-sync digital human generation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Video compression optimization and rate control for cyberspace application. <em>IJPRAI</em>, <em>39</em>(9), 2556002. (<a href='https://doi.org/10.1142/S0218001425560026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video traffic has become the principal part of data resources in the current cyberspace which brings many challenges such as security, stability and scalability of streaming transmission. Moreover, how to ensure high visual quality while obtaining a significant bit-rate reduction has always been the focus of the industry. By constructing a source distortion temporal propagation (SDTP) model, this paper proposes a temporal dependent RDO (TDRDO) algorithm to resolve the global RDO problem in the temporal domain. Besides, a fuzzy logic based rate control (FLRC) algorithm is proposed to robustly regulate encoding bit-rates. The two algorithms have previously been adopted by Audio Video Coding Standard Workgroup of China and integrated into the second generation (AVS2). Experimental results prove the excellence of the proposed algorithms, for significantly improving the AVS2 video coding performance and providing AVS2 with superb efficiency to compete with HEVC/H.265 in modern video compression.},
  archive      = {J_IJPRAI},
  author       = {Yimin Zhou and Chengzong Peng and Jie Luo and Juelin Liu and Siqi Yang and Juan Wang and Yang Bai},
  doi          = {10.1142/S0218001425560026},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2556002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Video compression optimization and rate control for cyberspace application},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting object in remote sensing image based on improved RT-DETR. <em>IJPRAI</em>, <em>39</em>(9), 2555011. (<a href='https://doi.org/10.1142/S0218001425550110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to tackle the challenges associated with low detection performance and high computational resource consumption, which result from diverse scenes, complex backgrounds, small and dense targets, and large data volumes in remote sensing images, we propose an improvement on real-time detection transformer (RT-DETR) for detecting objects in remote sensing images. By introducing the Mosaic9 data augmentation technique, we enhance the model’s adaptability to multi-scene targets, as well as its target recognition performance in different backgrounds. Furthermore, to decrease resource usage without compromising detection precision, we replace the Basic Block structure in the backbone of RT-DETR with the more lightweight FasterNet Block. Finally, we enhance the adaptive intra-scale feature interaction (AIFI) by replacing multi-head self-attention (MHSA) with deformable attention, enabling the model to dynamically adjust its attention range and better capture distinctive target features in complex scenarios. Experimental validation conducted on the DSTD dataset reveals that the modified RT-DETR model achieves a detection accuracy of 94.9%, representing an improvement of 1% compared to the baseline RT-DETR. Simultaneously, the improvements reduce GFLOPs, total parameters, and overall model size by approximately 12.4%, 15.5%, and 15.2%, respectively, thus realizing a balance between performance and lightweight architecture. Moreover, generalization experiments on the NWPU VHR-10 dataset further substantiate the enhanced model’s robustness and adaptability across diverse remote sensing scenes, confirming the efficacy and practical value of the proposed enhancements.},
  archive      = {J_IJPRAI},
  author       = {Jinyan Bai and Tao Jiang and Zhengbin Zou and Yizheng Wang and Tiancheng Xue},
  doi          = {10.1142/S0218001425550110},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2555011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Detecting object in remote sensing image based on improved RT-DETR},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Underwater image enhancement based on U-net architecture and channel attention mechanism fusion generative adversarial network. <em>IJPRAI</em>, <em>39</em>(9), 2555008. (<a href='https://doi.org/10.1142/S0218001425550080'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the challenges of blur distortion, low contrast and color fading in underwater images, caused by complex environmental factors and light attenuation, this study presents a novel underwater image enhancement method that leverages the U-Net architecture and channel attention mechanism fusion generative adversarial network (GAN), named UAEGAN. UAEGAN is built on the framework of GAN, combining the U-Net structure with a channel attention mechanism to construct a generator network, reducing the loss of low-level information during feature extraction and enhancing image details. Additionally, the algorithm employs a PatchGAN discriminator, which improves image resolution and detail representation by performing fine-grained true/false judgments on local image patches. Finally, the visual quality of the enhanced image is further optimized through the weighted fusion of multiple loss functions. Experimental results on the UIEB dataset indicate that UAEGAN outperforms the latest methods in terms of both visual quality and numerical metrics. The algorithm effectively enhances the clarity and visual quality of underwater images, providing strong support for subsequent underwater image processing tasks and applications.},
  archive      = {J_IJPRAI},
  author       = {Gang Li and Jiaqing Fan and Chenyu Cheng},
  doi          = {10.1142/S0218001425550080},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2555008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Underwater image enhancement based on U-net architecture and channel attention mechanism fusion generative adversarial network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A joint entity and relation extraction model driven by fine-grained feature extraction. <em>IJPRAI</em>, <em>39</em>(9), 2554009. (<a href='https://doi.org/10.1142/S0218001425540096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint entity and relation extraction plays a crucial role in various fields, including natural language processing, knowledge graph construction, and question answering systems. Among these methods, the joint extraction approach based on table filling has become a focal point for researchers due to its excellent performance and ability to accurately extract entities and relations from intricate sentences. Despite this, there is still potential to be further explored in such methods. Currently, most methods focus on learning relational features between words but neglect the relational features between labels and between labels and words. These relations are also important because a relation triplet can only be correctly identified when all labels are predicted correctly. This some what increases the risk of missing key information and inefficient decoding in the entity and relation extraction process. To overcome this limitation, we design a fine-grained relation feature extraction module that aims to encourage the model to fully consider the associations between words and labels, as well as between labels, while focusing on the relationships between words. Specifically, we create label representations and embed them into fine-grained relation extraction, enabling it to treat labels and word representations as queries, keys, and values, and then utilize the self-attention mechanism to model the associations between them. Additionally, the table labeling strategy has a significant impact on model performance, especially in terms of decoding efficiency. We propose a vertex labeling method to label the table, enhancing the model’s accuracy in entity recognition and overall decoding efficiency. We evaluate our proposed model on three benchmark datasets. The experimental results demonstrate that our model is effective and achieves state-of-the-art performance on all these datasets.},
  archive      = {J_IJPRAI},
  author       = {Hongli Yu and Han Cao and Chenxi Dong and Haihang Wang and Hanwen Liang and Yachao Cui},
  doi          = {10.1142/S0218001425540096},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2554009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A joint entity and relation extraction model driven by fine-grained feature extraction},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long short-term multivariate time series anomaly detection via double-branch attention and dynamic graph attention network. <em>IJPRAI</em>, <em>39</em>(9), 2554008. (<a href='https://doi.org/10.1142/S0218001425540084'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the industrial Internet, intelligent operation and maintenance can ensure the secure and stable operation of industrial software. To achieve effective intelligent operation and maintenance, it’s essential to conduct time series anomaly detection within software systems and other devices. To enhance the detection effectiveness, extensive research has been conducted. However, multivariate time series are composed of high-dimensional, high-noise, and random data. These anomalies are both subtle and dense. It is difficult to detect anomalies accurately. The increased complexity of existing methods results in lower operational efficiency. To address these issues, this paper proposes the time series anomaly detection method DG-LSFNet. DG-LSFNet adeptly captures feature correlations across various temporal states to extract additional valuable insights. Next, DG-LSFNet establishes long-term and short-term temporal correlations. It can capture normal information within short intervals between anomalies, thereby reducing false alarm in anomaly detection. Then, DG-LSFNet approximate and unearth the original data information to improve anomaly detection performance. In addition, DG-LSFNet reduces time complexity by simplifying the model structure and effectively improves the efficiency of anomaly detection. This paper conducts experiments to compare DG-LSFNet with state-of-the-art methods on four benchmark datasets. The experimental results indicate that DG-LSFNet outperforms state-of-the-art methods in terms of anomaly detection performance, enhancing the interpretability of anomaly detection.},
  archive      = {J_IJPRAI},
  author       = {Xiangheng Huang and Fei Zhou and Tao Deng and Fanglin Chen and Jining Chen and Ningjiang Chen},
  doi          = {10.1142/S0218001425540084},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2554008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Long short-term multivariate time series anomaly detection via double-branch attention and dynamic graph attention network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of well-logging curves based on MPSO/D-optimized deep neural networks. <em>IJPRAI</em>, <em>39</em>(9), 2553001. (<a href='https://doi.org/10.1142/S0218001425530015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the limitations of traditional logging curve prediction methods in complex reservoirs, particularly their inadequate generalization ability and the challenges associated with high-dimensional nonlinear modeling. We propose a deep neural network (DNN) logging curve prediction method, which is based on a multi-objective particle swarm optimization algorithm with target space decomposition (MPSO/D). This method effectively balances prediction accuracy and model complexity through target space decomposition, dynamic neighborhood search, and a constraint adaptive adjustment mechanism. This approach surmounts the issue of traditional parameter tuning, which often falls into local optima. The global search capability of MPSO/D is well-suited to the high-dimensional noise environment of logging data, thereby significantly enhancing the robustness of DNN in heterogeneous reservoirs. We applied this method to predict the resistivity curves in the logging data of wells B1, B2, and B3 in the A block of the Songliao Basin in the Daqing Oilfield. We compared our prediction results with those obtained from four other improved algorithms. The experimental findings indicate that the mean squared error values derived from MPSO/D-DNN are markedly lower than those produced by other models. Furthermore, the prediction curve exhibits the highest degree of congruence with actual values, thereby substantiating the efficacy and practicality of this method.},
  archive      = {J_IJPRAI},
  author       = {Yanan Hu and Jian-Gang Dong and Xiao-Qing Zhao and Dan Wang and Xing-Wang Li},
  doi          = {10.1142/S0218001425530015},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2553001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Prediction of well-logging curves based on MPSO/D-optimized deep neural networks},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DLA-FCIL: Federated class-incremental learning for dynamic data with forgetting compensation and auxiliary generators. <em>IJPRAI</em>, <em>39</em>(9), 2552010. (<a href='https://doi.org/10.1142/S021800142552010X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Class-Incremental Learning (FCIL) enables dynamic model updates, but suffers from local and global catastrophic forgetting due to limited client storage and cross-client class non-i.i.d. issues. To address catastrophic forgetting, we propose a multi-scale FCIL scheme, DLA-FCIL, which incorporates a Double-Loss-assisted forgetting compensation mechanism and the Auxiliary generators based on data characteristics. Specifically, to mitigate local catastrophic forgetting, we incorporate an auxiliary generator on local clients for knowledge replay, augmenting the training datasets with generated samples to form hybrid datasets. Then, to fully leverage the hybrid datasets, we design a double-loss forgetting compensation mechanism. This mechanism includes a gradient-weighted compensation loss that normalizes forgetting rates across old class knowledge, and a semantic-transition compensation loss that extracts the semantic relationships between old and new classes, preventing abrupt shifts in semantic consistency during the class transitions. Besides, to effectively alleviate the catastrophic forgetting problem caused by global class imbalance, the trained auxiliary generator is sent to a proxy server with minimal communication cost to build an i.i.d. dataset, enabling the development of an optimal global model. Finally, comparison experiments on CIFAR100, ImageNet-Subset, and Tiny-ImageNet datasets demonstrate that DLA-FCIL consistently outperforms other FCIL baselines by approximately 3–15% in test accuracy.},
  archive      = {J_IJPRAI},
  author       = {Bowen Xing and Junqing Le and Di Zhang and Xiaofeng Liao},
  doi          = {10.1142/S021800142552010X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2552010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {DLA-FCIL: Federated class-incremental learning for dynamic data with forgetting compensation and auxiliary generators},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed intelligence in IoHT using federated learning and edge AI for chronic kidney disease prediction using ReLU and bi-directional GRU with feature-wise dropout and fuzzy neural network. <em>IJPRAI</em>, <em>39</em>(9), 2552009. (<a href='https://doi.org/10.1142/S0218001425520093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research aims to enhance the forecasting of Chronic Kidney Disease (CKD) by discovering the importance of collective intelligence within the Internet of Healthcare Things (IoHT), by focusing on combining Edge Artificial Intelligence (AI) and Federated Learning. This method safeguards the patients’ information to stay localized, capturing the circulated flora of Federated Learning to uphold confidentiality and fulfill serious data security parameters that are challenging in Medicare backgrounds. The presence of Bi-directional Gated Recurrent Unit (Bi-GRU) with a Rectified Linear Unit (ReLU) improves the algorithm’s forecasting competencies by efficiently obtaining both the past and future needs in consecutive medical information. Moreover, the algorithm’s flexibility has been enhanced via feature-wise regressive dropout that decreases overfitting and guarantees its aptness to various datasets of patients. Thus, this agenda surpasses convolutional DL models like ALO-CNN-GRU, CNN, and LSTM exhibiting supremacy in handling complicated medical datasets with an excellent accuracy of about 99.98%. When compared to the existing algorithms, the adoption of Fuzzy Neural Network (FNN) for the forecasting of CKD efficiently reduces the computational times by allowing the algorithm to analyze irregular and confusing data. Thus, the advanced method not just allows real-time and précised findings of CKD but also proves the real-world application of Federated Learning and Edge AI for maintaining the medical data securely. The results demonstrate how this approach has the possibility to change healthcare, cheer initial detection and improve the overall results of the health by contributing extensible, efficient and patient-focused treatments inside the IoHT environment.},
  archive      = {J_IJPRAI},
  author       = {Vijaykumar Mamidala and Rama Krishna Mani Kanta Yalla and Thirusubramanian Ganesan and Akhil Raj Gaius Yallamelli and Mohanarangan Veerapperumal Devarajan and Aceng Sambas},
  doi          = {10.1142/S0218001425520093},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2552009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Distributed intelligence in IoHT using federated learning and edge AI for chronic kidney disease prediction using ReLU and bi-directional GRU with feature-wise dropout and fuzzy neural network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized parameter prediction for aluminum alloy 7075 machining using a hybrid experimental design strategy. <em>IJPRAI</em>, <em>39</em>(9), 2552006. (<a href='https://doi.org/10.1142/S0218001425520068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a high-performance machining accuracy and parameter prediction algorithm was proposed that better meets specific surface roughness requirements of the boring machining of aluminum alloy 7075. First, a hybrid experiment design strategy that incorporates factor range segmentation and exchange methods was used to improve data collection and ensure that the model accurately reflects the processing characteristics of the machine used. Then, a 1D CNN deep learning algorithm was used to model the relationship between boring parameters and the machining results, integrated with a particle swarm optimization algorithm to solve the parameter optimization problem for different processing objectives. The results proved that the proposed method was useful for the solution of the parameter prediction problem in specific machining objectives.},
  archive      = {J_IJPRAI},
  author       = {Yu-Chi Liu and Tzu-Wei Hsu},
  doi          = {10.1142/S0218001425520068},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2552006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Optimized parameter prediction for aluminum alloy 7075 machining using a hybrid experimental design strategy},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YOLOv7-DBV: A lightweight object detection algorithm based on cross-stage local network. <em>IJPRAI</em>, <em>39</em>(9), 2550014. (<a href='https://doi.org/10.1142/S0218001425500144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection algorithms that achieve high accuracy in complex application scenarios often result in complex network structures and exhibit poor detection performance for deformed objects and densely distributed small objects. These complex networks have high hardware requirements for mobile terminals or devices that are resource-constrained, significantly limiting their practical applications. To balance detection accuracy and network complexity, we propose a lightweight object detection algorithm based on a cross-stage local network, termed YOLOv7-DBV. First, a lightweight VoV-GSDSBCSP structure is designed to optimize the Head network structure of YOLOv7. Next, DCNv3 is introduced to enhance the YOLOv7 backbone network, improving the extraction of feature information for deformed objects. Finally, a Bi-level Routing Attention (BRA) mechanism is incorporated to further optimize the backbone network of YOLOv7, emphasizing the feature information of small objects. Experiments on a public underwater object detection dataset demonstrate that the YOLOv7-DBV model increases mAP0.5 by 1.05% and reduces the number of parameters by 15.31% compared to the original YOLOv7 model. The proposed algorithm achieves a better balance between detection accuracy and network complexity, outperforming YOLOv7, YOLOv6l, YOLOv5l, and other algorithms.},
  archive      = {J_IJPRAI},
  author       = {Danyang Cao and Yongfu Wong and Fangfang Liu},
  doi          = {10.1142/S0218001425500144},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2550014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {YOLOv7-DBV: A lightweight object detection algorithm based on cross-stage local network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient bearing fault diagnosis using depthwise separable convolution and transformer with SSA multi-objective optimization. <em>IJPRAI</em>, <em>39</em>(9), 2550012. (<a href='https://doi.org/10.1142/S0218001425500120'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To tackle the challenges of computational overhead and reliance on manual hyperparameter tuning in bearing fault diagnosis models, this study presents an optimized DSCNN-Transformer framework enhanced by the Sparrow Search Algorithm (SSA). The proposed framework employs Depthwise Separable Convolution (DSCNN) significantly mitigating computational costs in resource-limited setups. The Transformer module captures intricate global dependencies in time-series data to boost feature representation and diagnostic accuracy. A novel multi-objective optimization strategy utilizing SSA balances classification precision and parameter efficiency through dynamic weight adjustments. Experimental validation on the Case Western Reserve University (CWRU) bearing dataset highlights the model’s outstanding performance, achieving a 99.55% accuracy in a 10-class classification task, coupled with excellent real-time efficiency and adaptability. Future efforts will optimize the model’s lightweight design further, especially targeting edge computing applications.},
  archive      = {J_IJPRAI},
  author       = {Fang Han and Yuqin Zhu and Wenyan Nie},
  doi          = {10.1142/S0218001425500120},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2550012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Efficient bearing fault diagnosis using depthwise separable convolution and transformer with SSA multi-objective optimization},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PFE-KD: A defense method against membership inference attack without loss of accuracy. <em>IJPRAI</em>, <em>39</em>(9), 2450020. (<a href='https://doi.org/10.1142/S0218001424500204'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the usage of deep learning applications continues to proliferate, concerns surrounding the privacy and security of deep learning models have intensified. Recent research has pointed out that deep learning models are vulnerable to various privacy attacks, with Membership Inference Attacks (MIAs) being particularly prevalent. MIA can compromise privacy by revealing the presence of unknown data points in a model’s training set, posing a significant threat especially when the training data contains sensitive information. To this end, scholars have proposed many defense strategies, but striking a balance between protecting model privacy and maintaining utility remains a difficult challenge. In this paper, we propose a defense method against membership inference attacks, called RFE-KD, which integrates feature extraction technology and knowledge distillation technology. Extensive experiments show that our approach significantly reduces the accuracy of membership inference attacks without sacrificing model accuracy, consistently outperforming the most existing defense methods.},
  archive      = {J_IJPRAI},
  author       = {Hao Liu and Shuyao He and Ting Xu},
  doi          = {10.1142/S0218001424500204},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2450020},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {PFE-KD: A defense method against membership inference attack without loss of accuracy},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing stability of multi-underwater robot swarms based on the fusion of social force and vicsek models. <em>IJPRAI</em>, <em>39</em>(8), 2559010. (<a href='https://doi.org/10.1142/S0218001425590104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the demand for marine environmental monitoring and deep-sea operations continues to grow, AUV swarm systems have become a research hotspot due to their high flexibility. This paper proposes a navigation control method for multi-AUV swarms that integrates the Social Force Model (SFM) with the Vicsek model to improve collaboration efficiency and motion stability in dynamic underwater environments. The proposed control strategy incorporates both physical forces and alignment mechanisms to achieve dynamic behavioral coordination among the robots in the swarm. The SFM is used to characterize interactions between individuals, ensuring collision avoidance, while the Vicsek model provides a neighborhood-based velocity alignment mechanism to enhance swarm coherence. Additionally, the control framework introduces a leader-follower structure, effectively integrating local perception with global navigation information. Simulation results indicate that the robot swarm can maintain effective obstacle avoidance and structural stability even in complex environments with obstacles. In the absence of the Vicsek model, navigation tasks may fail or significantly increase navigation time. Even with low alignment strength and higher speeds, navigation time can be reduced by 35%, while higher alignment strength combined with lower speeds can shorten navigation time by up to 50%. Tests with large-scale swarms demonstrate that the proposed method exhibits good scalability and effectively prevents excessive aggregation within the group. Future research will focus on integrating intelligent optimization methods, such as deep reinforcement learning, to enhance the generalization ability of the control strategy in unstructured and dynamic environments.},
  archive      = {J_IJPRAI},
  author       = {Qiang Zhao and Bing Li and Gang Wang},
  doi          = {10.1142/S0218001425590104},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2559010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Enhancing stability of multi-underwater robot swarms based on the fusion of social force and vicsek models},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network-aided multiple-symbol noncoherent detection scheme of LDPC coded MPSK receiver for unmanned aerial vehicle communications. <em>IJPRAI</em>, <em>39</em>(8), 2558003. (<a href='https://doi.org/10.1142/S0218001425580030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple-symbol noncoherent detection (MSND) with the aid of Neural Networks (NNs) for low-density parity-check (LDPC) coded multiple phase shift keying (MPSK) signals is studied for Unmanned aerial vehicle (UAV) communications. In the traditional MSND scheme, the number of the candidate sequences grows exponentially with respect to the length of the symbol observation period. Implementing the optimal bit log-likelihood ratio (LLR) for decoding is challenging, even when the observed symbol period is two. In this paper, we first proposed an improved scheme to reduce the number of the candidate sequences by phase combination, the phase is uniformly quantized into L discrete values. We find that the performance requirements can be well met when the phase quantization order is only 4. Then we utilize Back Propagation neural networks (BPN) to compute the bit LLR. To enhance the training efficiency of our NNs and achieve better performance, we also uniformly quantize the carrier phase offset (CPO) into discrete states. The decoding convergence is accelerated significantly compared to the improved traditional scheme. The complexity is reduced to a certain extent within the acceptable range of performance loss.},
  archive      = {J_IJPRAI},
  author       = {Di Wu and Gege Wei and Gaolei Song and Yongen Li and Gaoyuan Zhang},
  doi          = {10.1142/S0218001425580030},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2558003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Neural network-aided multiple-symbol noncoherent detection scheme of LDPC coded MPSK receiver for unmanned aerial vehicle communications},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot counting with multi-scale vision transformers and attention mechanisms. <em>IJPRAI</em>, <em>39</em>(8), 2556001. (<a href='https://doi.org/10.1142/S0218001425560014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object counting is a fundamental task in computer vision, with critical applications in areas such as crowd monitoring and ecological conservation. Traditional methods typically rely on large-scale annotated datasets, which are costly and time-consuming to obtain. Few-shot object counting has emerged as a promising solution, enabling accurate counting with minimal annotated samples. However, in real-world scenarios, objects often exhibit significant scale variations due to factors such as view distortion, varying shooting distances, and inherent size differences. Existing few-shot methods usually struggle to address this challenge effectively. To address these issues, we propose a Scale-Aware Vision Transformer (SAViT) framework. Specifically, we design a multi-scale dilated convolution module in SAViT, which can adaptively adjust convolution kernel sampling rates to handle objects of varying sizes. Additionally, we incorporate a global channel attention mechanism to strengthen the model’s ability to capture robust feature representations, thereby improving detection accuracy. For practical usability, we integrate the Segment Anything Model (SAM) to create an exemplar box selection module, simplifying the process by allowing users to generate precise exemplar boxes with a single line drawn on the target object. Extensive experiments on the FSC-147 dataset demonstrate the effectiveness of our approach, achieving a Mean Absolute Error (MAE) of 8.92 and a Root Mean Squared Error (RMSE) of 31.26. Compared to the state-of-the-art method, CACViT, our model reduces MAE by 0.21 (2.30% improvement) and RMSE by 17.7 (36.15% improvement). Our approach not only provides an effective solution for few-shot object counting but also provides a new practical paradigm for extending few-shot learning to complex vision tasks requiring multi-scale reasoning. The code of our paper is available at https://github.com/BlouseDong/SAViT .},
  archive      = {J_IJPRAI},
  author       = {Xiaopan Chen and Zhiwei Dong and Xiaoke Zhu and Fan Zhang and Caihong Yuan},
  doi          = {10.1142/S0218001425560014},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2556001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Few-shot counting with multi-scale vision transformers and attention mechanisms},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal pre-trained framework for aligning Image–Text relation semantics. <em>IJPRAI</em>, <em>39</em>(8), 2555010. (<a href='https://doi.org/10.1142/S0218001425550109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image–text relation (ITR) in social media plays a crucial role in mining the semantics of the posts. Vision and language pre-trained models (PTMs) or multimodal PTMs have been used to create multimodal embeddings. The conventional practice of fine-tuning pre-trained models with labeled data for specific image–text relation tasks often falls short due to misalignment between general pre-training objectives and task-specific requirements. In this research, we introduce a cutting-edge pre-trained framework tailored for aligning image–text relation semantics. Our novel framework leverages unlabeled data to enhance learning of image–text relation representations through deep multimodal clustering and multimodal contrastive learning tasks. Our method significantly narrows the disparity between generic Vision-Language Pre-trained Models (VL-PTMs) and image–text relation tasks, showcasing an impressive performance boost of up to 10.4 points in linear probe tests. By achieving state-of-the-art results on image–text relation datasets, our pre-training framework stands out for its effectiveness in capturing and aligning image–text semantics. The visualizations generated by class activation map (CAM) also demonstrate that our models provide more accurate image–text semantic correspondence. The code is available on the website: https://github.com/qingyuannk/ITR .},
  archive      = {J_IJPRAI},
  author       = {Lin Sun and Yindu Su and Zhewei Zhou and Qingyuan Li and Ruichen Xia},
  doi          = {10.1142/S0218001425550109},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2555010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multimodal pre-trained framework for aligning Image–Text relation semantics},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BFC-cap: Background and frequency-guided contextual image captioning. <em>IJPRAI</em>, <em>39</em>(8), 2555009. (<a href='https://doi.org/10.1142/S0218001425550092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective image captioning relies on both visual understanding and contextual relevance. In this paper, we present two approaches, BFC-Cap b –a novel background-based image captioning and its extension BFC-Cap f –frequency-guided, to achieve the above goals. First, we develop an Object-Background Attention (OBA) module to capture the interaction and relationship between objects and background features. Then, we incorporate feature fusion with spatial shift operation, enabling alignment with neighbors and avoiding potential redundancy. This framework is extended to transform grid features into frequency domain and filter out low-frequency components to enhance fine details. Our approaches are evaluated using traditional and recent metrics on MS COCO image captioning benchmark. Experimental results show the effectiveness of our proposed approaches, achieving better quantitative scores as compared to the relevant existing methods. Furthermore, our methods show improved qualitative captions with more background and concise contextual information, including more accurate information regarding the objects and their attributes.},
  archive      = {J_IJPRAI},
  author       = {Al Shahriar Rubel and Frank Y. Shih and Fadi P. Deek},
  doi          = {10.1142/S0218001425550092},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2555009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {BFC-cap: Background and frequency-guided contextual image captioning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive SURELET-based image denoising in wavelet domain with spatially varying noise. <em>IJPRAI</em>, <em>39</em>(8), 2554007. (<a href='https://doi.org/10.1142/S0218001425540072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image denoising is a critical task in numerous real-world applications. This paper presents an innovative method for image denoising in the wavelet domain, extending the SURELET approach to handle spatially varying noise levels. Traditional methods often assume a constant noise level across the entire image, which is unrealistic in practical scenarios. Our proposed method estimates the noise level locally within small neighborhoods in the wavelet domain, adapting well to images with spatially varying noise. This approach effectively reduces both uniform and spatially varying noise, as demonstrated through extensive experiments on six test images with five distinct noise patterns. The results, evaluated using peak signal-to-noise ratio (PSNR), show that our method outperforms existing denoising techniques, particularly in scenarios with spatially varying noise. This study not only advances the state-of-the-art in image denoising but also highlights the importance of adaptive noise estimation in real-world applications.},
  archive      = {J_IJPRAI},
  author       = {Guang Yi Chen and Yaser Esmaeili Salehani and Sepehr Ghamari},
  doi          = {10.1142/S0218001425540072},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2554007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Adaptive SURELET-based image denoising in wavelet domain with spatially varying noise},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EAUR-net: Enhancing MRI reconstruction with edge-aware undersampling and deep learning. <em>IJPRAI</em>, <em>39</em>(8), 2552011. (<a href='https://doi.org/10.1142/S0218001425520111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonance imaging (MRI) is an essential imaging technique used for detailed anatomical assessment and clinical decision-making. Conventional MRI acquisition methods, however, are often time-consuming and resource-demanding. To overcome these limitations, compressed sensing (CS) approaches have been developed to accelerate MRI data acquisition by exploiting image sparsity. In this work, we present the Edge-Aware Undersampling and Reconstruction Network (EAUR-Net), an innovative deep learning architecture designed to enhance MRI reconstruction by incorporating dynamic edge-based sampling strategies. EAUR-Net focuses on intelligently sampling data points based on edge information, which is critical for preserving key structural details and improving reconstruction quality while reducing the amount of acquired data. This paper provides a thorough evaluation of EAUR-Net, detailing its architectural components, training procedures, experimental outcomes, and potential future improvements.},
  archive      = {J_IJPRAI},
  author       = {Libya Thomas and Joseph Zacharias},
  doi          = {10.1142/S0218001425520111},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2552011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {EAUR-net: Enhancing MRI reconstruction with edge-aware undersampling and deep learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight and effective YOLO model for infrared small object detection. <em>IJPRAI</em>, <em>39</em>(8), 2551009. (<a href='https://doi.org/10.1142/S0218001425510097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting small targets in infrared images presents significant challenges due to low resolution, lack of texture information, and high noise interference. To address these issues, this paper proposes an improved YOLO model aimed at enhancing the accuracy and efficiency of small target detection in infrared images. First, we integrate the Coordinate Attention (CA) mechanism into the backbone network to improve the model’s feature extraction capability in complex scenes. Second, we introduce the Contextual Feature Aggregation (CFA) module into the neck network, effectively merging multi-level contextual information and enhancing the detection capability for small targets. To further optimize the model, we simplify the detection layers for large targets in YOLO, reducing the number of parameters while maintaining high detection accuracy. Finally, we incorporate the Normalized Wasserstein Distance (NWD) loss function, which is insensitive to target size and can accelerate model convergence while improving small target detection performance. We evaluated the model on public datasets such as VisDrone2019 and FLIR, using metrics like mean Average Precision (mAP) to assess performance. Experimental results indicate that the proposed method achieves higher detection accuracy and efficiency while maintaining a low parameter count compared to baseline models.},
  archive      = {J_IJPRAI},
  author       = {Shiyi Wen and Liangfu Li and Wenchao Ren},
  doi          = {10.1142/S0218001425510097},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2551009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A lightweight and effective YOLO model for infrared small object detection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RFA: Regularized feature alignment method for cross-subject human activity recognition. <em>IJPRAI</em>, <em>39</em>(8), 2551008. (<a href='https://doi.org/10.1142/S0218001425510085'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-subject activity recognition is challenging in the human activity recognition field. Previous studies have often assumed that training and test data follow the same distribution, which is impractical in real-world applications. Thus, models’ performance will significantly decline when applied to data collected from new unseen subjects because of the different physical conditions and human habits. To solve the above challenges, we proposed the regularized feature alignment (RFA) network. The RFA introduces a source domain selection mechanism (SDSM) based on calculating the Wasserstein distance between different subjects. Through SDSM, subjects with high similarity in the source domain can be retained, which implicitly compacts the feature subspace distribution. We implemented linear data augmentation on the retained subjects to mitigate the effects of the decline in the training set. In addition, the regularized dropout method was adopted to explicitly compact the feature subspace distributions. Finally, multi-level feature alignment is performed via maximum mean discrepancy regularization to precisely match the source and target domain. To demonstrate the effectiveness of RFA, comprehensive experiments were conducted on four public datasets under the iterative left-one-subject-out setting. The experimental results demonstrate that RFA outperformed the state-of-the-art methods in datasets with a large divergence between subjects and achieved performance comparable to the state-of-the-art methods in a subject-balanced dataset.},
  archive      = {J_IJPRAI},
  author       = {Zhe Yang and Hao Fu and Ruohong Huan and Mengjie Qu and Yun Pan},
  doi          = {10.1142/S0218001425510085},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2551008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {RFA: Regularized feature alignment method for cross-subject human activity recognition},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DRF-YOLO: A transformer-enhanced framework for underwater image enhancement and object detection. <em>IJPRAI</em>, <em>39</em>(8), 2550011. (<a href='https://doi.org/10.1142/S0218001425500119'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater aquatic systems play a crucial role in maintaining ecological balance and supporting marine biodiversity. However, due to low visibility, color distortion, and scattering effects caused by light absorption, efficient monitoring and detecting objects in such environments remain challenging. Deep learning-based image processing techniques have revolutionized underwater exploration by providing robust solutions for enhancing image quality, extracting meaningful features, and enabling precise classification. Integrating advanced image enhancement methods with deep learning architectures facilitates accurate detection and monitoring of aquatic species, objects, and anomalies. This study introduces a novel approach that synergistically combines the Multiscale Retinex (MSR) and Dark Channel Prior (DCP) approaches for underwater image enhancement in the form of the Dark Retinex Fusion (DRF) model. The DRF model is further integrated with a YOLO-based Transformer framework, leveraging attention mechanisms to enhance feature extraction and classification. The proposed DRF-YOLO-based Transformer framework effectively reduces haze, enhances contrast, and balances colors for an underwater environment. It incorporates advanced spatial precision features in the YOLO backbone and applies the attention module from the Transformer model that captures the long-range dependencies for better contextual understanding. The model was tested on underwater object datasets, achieving an accuracy of 98% and a loss of 0.2, outperforming traditional methods. Additionally, the framework demonstrated resilience to overfitting and local minima, maintaining consistent performance under varying conditions.},
  archive      = {J_IJPRAI},
  author       = {Manikandan Sundaram and S. Vinoth Kumar and R. Lakshmana Kumar and P. Punitha},
  doi          = {10.1142/S0218001425500119},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2550011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {DRF-YOLO: A transformer-enhanced framework for underwater image enhancement and object detection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization calculating of artificial intelligence IPGA algorithm. <em>IJPRAI</em>, <em>39</em>(7), 2559009. (<a href='https://doi.org/10.1142/S0218001425590098'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional genetic algorithm (GA) known as the island model parallel genetic algorithm (IPGA) has limitations regarding speed and accuracy, especially when applied to large-scale datasets in parallel computing environments. This study addresses the optimization challenges associated with IPGA in the context of big data. Initially, an enhanced adaptive covariance matrix evolution strategy (CMA-ES) is implemented to replace the conventional Gaussian evolution strategy used in traditional IPGA. Additionally, a normalization function is integrated into the CMA-ES framework to constrain the range of random values during the iterative optimization process, thereby improving both the speed and accuracy of IPGA in managing big data computations. Furthermore, the MapReduce paradigm is utilized within a Hadoop cluster to optimize the computational process of IPGA, making it more suitable for distributed parallel operations on extensive datasets. Experimental findings indicate that the proposed methodologies significantly enhance the speed and accuracy of IPGA optimization, particularly in the context of large-scale and ultra-large-scale datasets, with a marked improvement in computational speed.},
  archive      = {J_IJPRAI},
  author       = {Zhenliu Zhou and Yan Xia and Shun Yu and Junyu Hu and Liming Wang and Rongxu Hou},
  doi          = {10.1142/S0218001425590098},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2559009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Optimization calculating of artificial intelligence IPGA algorithm},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive AI-enhanced signal processing framework for optimized communication in the internet of underwater things (IOUT). <em>IJPRAI</em>, <em>39</em>(7), 2558002. (<a href='https://doi.org/10.1142/S0218001425580029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Underwater Things (IoUT) is an emerging revolution in underwater monitoring and communication, offering real-time detection of objects and data collection in harsh aquatic conditions. Severe communication problems, including signal attenuation, high latency, limited bandwidth, and noise/interference vulnerability, reduce underwater network performance and impede IoUT deployment. The proposed work introduces three new techniques to tackle these problems. The first work introduces the Sequential Memory Fusion Network (SMFN) for predicting environmental changes using historical and real-time data and predicting factors such as signal degradation and noise levels. In the second work, the Adaptive Condition-Based Binary Phase-Shift Keying system (ACB-BPSK) dynamically switches between modulation schemes of high-noise and low-noise modes with the help of real-time feedback to achieve signal robustness and optimized data rates. ACB-EBPSK handles adaptation in modulation techniques according to environmental conditions for enhancing wireless communication’s reliability and efficiency. The third contribution is an Energy-Efficient Reinforcement Learning (EERL) framework for routing decisions, which learns from network feedback, packet loss, and congestion-allows inserting energy into the routing policy and prolonging the lifetime of battery-operated devices considering the dynamic natures of network conditions. The developed techniques’ advantages include increased communication reliability, higher data transmission rates, and prolonged network lifetime.},
  archive      = {J_IJPRAI},
  author       = {V. Padmavathi and C. Suresh and R. Lakshmana Kumar and P. Punitha},
  doi          = {10.1142/S0218001425580029},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2558002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Adaptive AI-enhanced signal processing framework for optimized communication in the internet of underwater things (IOUT)},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anomaly detection and control in supply chains based on image feature modeling. <em>IJPRAI</em>, <em>39</em>(7), 2554006. (<a href='https://doi.org/10.1142/S0218001425540060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring process quality in supply chains is a critical challenge due to the complexity and variability of production processes. Conventional methods often struggle to accurately detect and address quality issues in such dynamic environments. This paper proposes a novel anomaly detection and control method based on image feature modeling to enhance process monitoring and decision-making in supply chain operations. By leveraging advanced image processing techniques, key features of production processes are extracted and modeled, enabling accurate identification of deviations and anomalies. Experimental results demonstrate that the proposed method significantly improves detection accuracy and response time compared to traditional approaches. This study contributes to the development of intelligent quality control solutions, offering scalability and robustness for real-world supply chain applications.},
  archive      = {J_IJPRAI},
  author       = {Yue Pan},
  doi          = {10.1142/S0218001425540060},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2554006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Anomaly detection and control in supply chains based on image feature modeling},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid deep learning-based automatic diagnosis of breast cancer from mammograms using segmentation and feature selection. <em>IJPRAI</em>, <em>39</em>(7), 2554004. (<a href='https://doi.org/10.1142/S0218001425540047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image processing plays a crucial role in the early detection and classification of diseases, particularly breast cancer, which is a leading cause of death among women. Mammography is widely used for breast cancer diagnosis, but accurately interpreting mammograms remains challenging even for expert radiologists. To address this, we propose a novel framework for automatic breast cancer diagnosis that integrates mass segmentation, feature selection, and a hybrid deep learning-based classifier. Our approach introduces the enhanced black widow optimization (EBWO) algorithm for mass segmentation, effectively identifying the region of interest (ROI) in mammograms. The Improved UNet model is used for deep feature extraction, enhancing feature representations from the segmented masses. To tackle the issue of high-dimensional data, we employ the modified snow ablation optimization (MSAO) algorithm for optimal feature selection, ensuring the best features are chosen for classification. The optimal threshold graph neural network (OT-GNN) is then utilized for classifying breast cancer into three categories: normal, benign, and malignant. In comparison with existing methods, our framework demonstrates superior performance. We validate the proposed UNet+MSAO+OT-GNN method using augmented datasets such as DDSM and INbreast, achieving IOU scores of 99.912% and 99.909%, respectively. Our method outperforms existing classifiers, achieving accuracy scores of 99.523% and 99.859% on DDSM and INbreast datasets, respectively, showcasing significant improvements in both segmentation and classification accuracy. This highlights the effectiveness and novelty of our approach in comparison to traditional methods.},
  archive      = {J_IJPRAI},
  author       = {N. Rajesh Pandian and N. Selvaganesh and D. Shanthi},
  doi          = {10.1142/S0218001425540047},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2554004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Hybrid deep learning-based automatic diagnosis of breast cancer from mammograms using segmentation and feature selection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning research on quantitative evaluation model of tea taste based on NAR neural network. <em>IJPRAI</em>, <em>39</em>(7), 2552008. (<a href='https://doi.org/10.1142/S0218001425520081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demand for tea from consumers exhibits a diversified and personalized trend. Initiating from the scientific analysis of tea taste, this paper addresses issues such as the incomplete cognition standard of tea market taste, varying evaluation criteria for tea, and the development of a young tea consumption group, utilizing the Nonlinear Auto-Regressive (NAR) model, a quantitative evaluation of tea taste is conducted. In this study, raw and ripe tea samples from Pu-erh tea were used as training data, and the NAR was employed for deep learning, error analysis, and comparison. The aim was to predict the taste resulting from different content ratios of chemical components in tea, further verifying the feasibility and scientific accuracy of the quantitative evaluation of tea taste based on the NAR. This study not only broadens the research field of NAR neural network, but also further enables tea enterprises to better provide consumers with diversified tea taste, and provides an important reference for tea taste evaluation.},
  archive      = {J_IJPRAI},
  author       = {Mingxin Ji and Xingrui Wang and Di Wu and Siyi Wu and Meng Yang and Yue Li},
  doi          = {10.1142/S0218001425520081},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2552008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Deep learning research on quantitative evaluation model of tea taste based on NAR neural network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Source-free domain adaptation via enhanced self-supervised learning. <em>IJPRAI</em>, <em>39</em>(7), 2552007. (<a href='https://doi.org/10.1142/S021800142552007X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the challenge of Source-free Domain Adaptation (SFDA), where knowledge is transferred from a labeled source domain to an unlabeled target domain without requiring access to the source data during adaptation. Traditional Unsupervised Domain Adaptation (UDA) methods typically depend on source data availability during training, which raises concerns related to privacy, security, and scalability. Our proposed approach eliminates this dependency by leveraging only a pre-trained source model for adaptation to the target domain. We introduce a comprehensive framework that incorporates iterative centroid refinement for pseudo-labeling, enhanced self-supervised learning strategies, advanced regularization techniques, and dynamic loss weighting mechanisms. These innovations improve feature alignment and classification performance in the target domain. Extensive experiments conducted on diverse datasets, including digital and object benchmarks, demonstrate that our method consistently outperforms state-of-the-art techniques in both accuracy and robustness. Additionally, this study delves into the theoretical foundations of SFDA, providing insights into its efficacy and exploring its practical applications across various domains.},
  archive      = {J_IJPRAI},
  author       = {Jih Pin Yeh and Yihjia Tsai and Hsiau-Wen Lin and Hwei Jen Lin and Yoshimasa Tokuyama},
  doi          = {10.1142/S021800142552007X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2552007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Source-free domain adaptation via enhanced self-supervised learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). JFD-GNN: A joint graph neural network approach for detecting fake news. <em>IJPRAI</em>, <em>39</em>(7), 2552005. (<a href='https://doi.org/10.1142/S0218001425520056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake news is often designed to closely mimic legitimate news, making its detection based on content analysis alone unreliable. Hence, we propose a deeper exploration of the correlation between fake news and user profiles to understand its widespread. For this purpose, we propose a Joint Fake News Detection framework, called JFD-GNN, which consists of two distinct models designed to integrate user profiles, internal preferences, and external context. The first model, based on Graph Neural Networks (GNN), incorporates user preferences and leverages the tweet history of the post’s publisher as endogenous features. Additionally, it utilizes propagation graphs as exogenous features to derive a joint representation of user engagement. The second model focuses on user profile details and textual embeddings of comments as user features, constructing a GNN-based model for user profile analysis. We use BERT and Word2Vec as data encoders. To enhance the performance of the joint model, the fused output is passed through a fully connected layer to compute the final output and then compare it with the target. We conducted several experiments on two publicly available fake news datasets, Politifact and Gossipcop, where our approach achieved 97.99% accuracy on Gossipcop dataset and 95.16% accuracy on Politifact dataset. This illustrates the effectiveness of JFD-GNN for identifying fake news, and the proposed method reaches a comparatively high level by combining various information levels from different modalities.},
  archive      = {J_IJPRAI},
  author       = {Soufiane Khedairia and Hafed Zarzour and Djalel Chefrour},
  doi          = {10.1142/S0218001425520056},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2552005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {JFD-GNN: A joint graph neural network approach for detecting fake news},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable multiple kernel K-means clustering with entropy regularization. <em>IJPRAI</em>, <em>39</em>(7), 2551010. (<a href='https://doi.org/10.1142/S0218001425510103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-kernel k-means clustering (MKC) aims to learn a composite kernel from multiple precomputed basic kernels to better reflect the data distribution. In the existing MKC models, the optimal composite kernel is linearly combined by basic kernels with varying weights, subject to different constraints. While some state-of-the-art models have achieved satisfactory clustering performance, they often do so at the expense of model interpretability. To address this issue, this paper proposes a new M ulti- K ernel K -means C lustering model with maximized E ntropy regularization (MKKC-E). In the new model, convex combination of basic kernels is used to learn the optimal composite kernel to enhance interpretability. Meanwhile, an entropy regularization term is introduced to prevent the kernel weights from becoming overly sparse, thereby improving the model’s robustness. Experimental results demonstrate that the proposed model’s interpretability and robustness are validated on synthetic datasets, while its superior clustering performance is confirmed on benchmark datasets. In conclusion, the MKKC-E model not only achieves excellent clustering performance but also offers significant interpretability.},
  archive      = {J_IJPRAI},
  author       = {Fengjiao Peng and Shuisheng Zhou},
  doi          = {10.1142/S0218001425510103},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2551010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Interpretable multiple kernel K-means clustering with entropy regularization},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-granularity semantic convolutional model for pig face recognition. <em>IJPRAI</em>, <em>39</em>(7), 2550009. (<a href='https://doi.org/10.1142/S0218001425500090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intensification and automation of the pig farming industry have created an urgent need for cost-effective and efficient identification of individual pigs. Pig identification is crucial for disease prevention and control, pork quality traceability, genetic breeding, and insurance services. To address the challenges faced by existing noncontact pig face recognition models in overcoming strong environmental interference in pigsties and the minimal differences among pig faces, this paper proposes a convolutional neural network based on multi-granularity semantic analysis (MGSNet). By integrating pixel-level, component-level, and object-level semantic features, the model significantly improves recognition performance in complex scenarios. Specifically, the model addresses challenges such as environmental interference and high similarity among individual pigs. Experimental results show that the algorithm achieves a high test accuracy of 92.50% on a dataset of 10 pigs collected from actual pig farms, with lightweight network parameters. Through deconvolution and gradient-weighted class activation mapping techniques, the feature extraction process of the model is visually interpretable, providing reliable technical support for farmers. The research findings can be directly applied to precision feeding, disease monitoring, breeding optimization, and other scenarios, promoting the comprehensive adoption of smart agriculture.},
  archive      = {J_IJPRAI},
  author       = {Yadong Yang and Yourui Huang and Deyong She and Jing Zhang and Mingjing Pei and Xiancun Zhou},
  doi          = {10.1142/S0218001425500090},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2550009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-granularity semantic convolutional model for pig face recognition},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A small target recognition method based on an improved YOLOv8. <em>IJPRAI</em>, <em>39</em>(7), 2550008. (<a href='https://doi.org/10.1142/S0218001425500089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recognition of small-size targets presents a significant challenge in computer vision, as their reduced dimensions often lead to diminished detection accuracy. To address this issue, this paper proposes an enhanced small-size target recognition method based on an improved version of You Only Look Once Version 8 (YOLOv8). The proposed improvements include integrating the dynamic attention mechanism of BiFormer (Vision Transformer with Bi-level Routing Attention), which leverages the sparsity of dynamic and query perception to enable more flexible and adaptive content perception. Additionally, the Weighted Intersection over Union (WIOU) loss function is introduced to address the imbalance in Bounding Box Regression (BBR) between samples, enhancing the overall accuracy of the model. Furthermore, a specialized detection head for small targets and a confidence-adaptive module are added at the detection head’s end, improving feature extraction and continuous tracking capabilities for small targets, especially under conditions of low visibility and target occlusion. Experimental results demonstrate that the improved model significantly enhances the detection of incomplete and small-sized targets, providing robust performance in scenarios with occlusion and reduced visibility. This study emphasizes the potential of the enhanced YOLOv8 model in real-world applications, providing new improvement ideas for the development of occluded and small target recognition.},
  archive      = {J_IJPRAI},
  author       = {Saibiao Jiang and Jianan Fan and Zhijin Sun and Kaitao Deng and Yanbing Huang},
  doi          = {10.1142/S0218001425500089},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2550008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A small target recognition method based on an improved YOLOv8},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing visual transformer and faster R-CNN integration for efficient object detection. <em>IJPRAI</em>, <em>39</em>(6), 2559008. (<a href='https://doi.org/10.1142/S0218001425590086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of Visual Transformers (ViTs) with Faster R-CNN has shown significant promise in computer vision tasks requiring both high accuracy and efficient object detection. However, the computational cost and resource requirements of these models often limit their application in real time, resource-constrained environments. This paper proposes a novel optimization strategy for integrating ViT with Faster R-CNN to enhance both performance and efficiency. We introduce an improved ViT-Tiny backbone with a hybrid attention mechanism, CS-attention, that combines high- and low-frequency attention to better capture local and global features while minimizing computational overhead. Additionally, a pyramid feature network (FPN) is incorporated to enhance multi-scale feature extraction, allowing the model to accurately detect objects at varying scales. Experimental results demonstrate that the optimized model achieves high accuracy and real-time processing capabilities, making it suitable for deployment in industrial and edge computing applications. The proposed approach is validated through extensive experiments, providing a general solution for efficient object detection across various domains.},
  archive      = {J_IJPRAI},
  author       = {Lin Lei and Yun Huang},
  doi          = {10.1142/S0218001425590086},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2559008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Optimizing visual transformer and faster R-CNN integration for efficient object detection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Patch feature transformation: An anomaly detection method with succinct feature filtering. <em>IJPRAI</em>, <em>39</em>(6), 2559006. (<a href='https://doi.org/10.1142/S0218001425590062'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is often approached as an out-of-distribution (OOD) detection task, where a feature distribution from normal samples is constructed, and deviations are flagged as anomalies. This approach is dependent on manual labeling, as subtle visual anomalies can be easily overlooked, resulting in the potential for bias in labeling and subsequent unsatisfactory detection results. Based on the issue, we propose Anomaly Detection with Succinct Feature Filtering (ADSFF) for unlabeled samples. Our method avoids sample labeling bias and provides a solution to the coexistence of anomalous and normal features in the feature space of unlabeled samples. ADSFF includes a data preprocessing module and a feature filtering module, where the data preprocessing module improves the visibility of subtle anomalies, while the feature filtering module screens the local features of the samples. In feature filtering, we found that feedforward neural networks do not lose feature information during the feature transformation process. Consequently, we utilized feedforward neural networks for feature filtering and achieved expected results. Furthermore, we investigate the impact of sample imbalance on the task of anomaly detection using unlabeled samples. This paper assesses the performance of ADSFF using the MVTec AD and BeanTech Anomaly Detection (BTAD) datasets. The results demonstrate that ADSFF achieves an average area under the curve (AUC) of 0.978 on the MVTec AD and an average AUC of 0.942 on the BTAD. ADSFF outperformed other methods on seven test datasets in MVTec AD, achieving the highest average accuracy on MVTec AD.},
  archive      = {J_IJPRAI},
  author       = {Yaohua Guo and Guoai Xu and Jianping Yin and Siqi Wang},
  doi          = {10.1142/S0218001425590062},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2559006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Patch feature transformation: An anomaly detection method with succinct feature filtering},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced website fingerprinting attacks based on attention mechanism and spatial-temporal features. <em>IJPRAI</em>, <em>39</em>(6), 2559005. (<a href='https://doi.org/10.1142/S0218001425590050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Website fingerprinting (WF) attacks leverage deep learning to analyze encrypted traffic and identify the websites accessed by Tor users, posing a critical threat to online anonymity. However, existing detection models often suffer from low accuracy and weak robustness in open-world scenarios. To address these issues, we propose a novel spatiotemporal WF framework integrating a lightweight attention mechanism and parallel multi-size feature extraction with dilated convolution. This design significantly enhances detection performance while maintaining high efficiency. Experimental results show that our approach outperforms CNN and LSTM models by 3–5% in accuracy and surpasses the DF model by about 1%, while achieving a 50% increase in efficiency. Furthermore, it demonstrates robust performance as the number of website categories grows and remains effective against defenses such as WTF-PAD and Walkie-Talkie. Notably, our framework also mitigates the impact of concept drift, exhibiting minimal performance degradation when traffic distributions evolve over time. These findings not only underscore the unique potential of our model to advance WF attacks, but also highlight the urgent need for stronger privacy-preserving measures to protect Tor users in real-world environments.},
  archive      = {J_IJPRAI},
  author       = {Chunqian Guo and Gang Chen and Deliang Jin and Zhihan Lin},
  doi          = {10.1142/S0218001425590050},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2559005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An enhanced website fingerprinting attacks based on attention mechanism and spatial-temporal features},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A PMSM speed control strategy of LADRC based on neural network load torque estimation. <em>IJPRAI</em>, <em>39</em>(6), 2559003. (<a href='https://doi.org/10.1142/S0218001425590037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel speed control method for Permanent Magnet Synchronous Motors (PMSM) utilizing Linear Active Disturbance Rejection Control (LADRC). The initial step involves collecting data on the motor’s d -axis and q -axis currents, speed, and load torque during stable operation. A small-scale neural network, characterized by low computational demands, is then trained to provide a non-exact load torque estimation. Subsequently, this estimated value of the load torque is incorporated into the LADRC, resulting in a reduction of the pressure calculated by the Extended State Observer (ESO). The discrepancy between the actual and estimated load torque can be viewed as the total disturbance experienced by the system. Finally, a LADRC speed controller that utilizes an imprecise load torque estimation is constructed. To enhance the flexibility and adaptability of the method, a weight coefficient is added to the estimated load torque. The efficacy of this speed control strategy is confirmed through Matlab/Simulink simulation, demonstrating superior control performance when faced with sudden changes in load torque.},
  archive      = {J_IJPRAI},
  author       = {Lijie Yin and Chen Tang and Lijun Wei},
  doi          = {10.1142/S0218001425590037},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2559003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A PMSM speed control strategy of LADRC based on neural network load torque estimation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward generalized 3D lane representation with lane geometry supervision for autonomous driving. <em>IJPRAI</em>, <em>39</em>(6), 2555007. (<a href='https://doi.org/10.1142/S0218001425550079'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lane detection is crucial for autonomous driving. Recent advancements have expanded traditional two-dimensional (2D) lane detection to three-dimensional (3D) by predicting lane positions in 3D space. These methods rely on fully supervised learning, requiring high-quality 3D labels, which are difficult to obtain. This challenge motivates a weakly supervised approach leveraging abundant and easily scalable 2D lane annotations. Specifically, we systematically analyze lane geometric structure priors and introduce Lane Geometry Supervision (LGS), which relies solely on 2D lane labels. Extensive experiments on both synthetic and real-world datasets demonstrate that our method achieves performance comparable to fully supervised approaches using direct 3D labels. Moreover, incorporating LGS as a regularization term further enhances the performance of existing fully supervised methods. Finally, we show that LGS enables a label-efficient training methodology for 3D monocular lane detection, effectively utilizing both scarce yet complete 3D lane labels and abundant but incomplete 2D lane labels.},
  archive      = {J_IJPRAI},
  author       = {Wenbo Ding and Wenlian Lu},
  doi          = {10.1142/S0218001425550079},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2555007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Toward generalized 3D lane representation with lane geometry supervision for autonomous driving},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quadrotor attitude control via three-loop ADRC and backstepping integral method: Dynamic modeling and validation. <em>IJPRAI</em>, <em>39</em>(6), 2555006. (<a href='https://doi.org/10.1142/S0218001425550067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the dynamic characteristics of four-rotor attitude control, including nonlinearity, internal underactuation and strong coupling, this study proposes a control strategy that integrates adaptive Active Disturbance Rejection Control (ADRC) with the inverse step integration method. This approach aims to enhance adaptability to uncertain parameters and external disturbances. First, a mathematical model for the flight attitude angle of the quadrotor is formulated. The dynamics of the quadrotor is partitioned into three subsystems corresponding to the pitch, roll and yaw axes, with ADRC parameters being individually calibrated for each. Subsequently, the Extended State Observer (ESO) component of ADRC is integrated into the design of each virtual control layer, enabling real-time estimation and compensation for dynamic disturbances within the subsystems. An adaptive parameter adjustment mechanism is incorporated during the backstepping process to enhance the precision and response speed of attitude angle control. Finally, the anti-interference performance and robustness of the tri-loop cascaded ADRC controller are validated using the fusion inverse integration method on the MATLAB simulation platform. Experimental results show that, compared to the single-loop attitude control ADRC, the three-loop cascaded ADRC integrated with the backstepping integral method significantly improves the response times for the pitch, roll and yaw axes by approximately 67.7%, 69.8% and 58.4%, respectively, under the same strong interference conditions. Additionally, the average fluctuation amplitude of the angles decreases to 0 . 2 3 8 ∘ , 0 . 1 1 5 ∘ and 0 . 2 1 2 ∘ for the pitch, roll and yaw axes, respectively. Therefore, the backstepping integral method integrated with the three-loop cascaded ADRC not only ensures a higher response speed across all three axes but also strengthens the robustness of the quadrotor, improving angle stability by nearly a factor of 10. It offers innovative theoretical insights and technical solutions for addressing the dynamic stability control challenges in strongly nonlinear and multi-source uncertain systems.},
  archive      = {J_IJPRAI},
  author       = {Guiyu Zhou and Zhengcong Du and Hong Wen and Lianghua Wen and Haibo Zhang},
  doi          = {10.1142/S0218001425550067},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2555006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Quadrotor attitude control via three-loop ADRC and backstepping integral method: Dynamic modeling and validation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STSODNet: Scale transformer small object detection network. <em>IJPRAI</em>, <em>39</em>(6), 2555004. (<a href='https://doi.org/10.1142/S0218001425550043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense small object detection in complex scenes is a valuable and challenging research field. While deep learning has driven significant advancements in computer vision, traditional object detection models still struggle to achieve high accuracy in detecting small objects, particularly in large-scale aerial images. Challenges such as scale variations, occlusions, and complex backgrounds continue to hinder the effective detection of dense small objects. In this paper, we present the Scale Transformer Small Object Detection Network (STSODNet), a novel architecture designed to address these challenges. First, we conceptualize the pronounced scale variation in drone images as an anomalous disturbance and propose a multiscale feature enhancement module (MSFEM), built upon the Spatial Transformer Network, to mitigate this effect. The multiscale feature enhancement module performs learnable, multi-point magnification on regions surrounding objects based on spatial saliency, enhancing the model’s scale invariance. Second, to generate a more accurate global saliency map and heighten the model’s focus on small target regions, we introduce a refined spatial attention mechanism, termed Spatial Region Attention. This mechanism combines coarse region attention with fine spatial attention to produce a more detailed saliency map and improve long-range dependency capture. Third, to achieve more accurate spatial regression of small objects, the traditional three-layer detection head is improved by expanding its output layer, resulting in a finer and larger output while maintaining the same number of parameters. Extensive experiments on the VisDrone and SeaPerson benchmark datasets validate that STSODNet achieves superior precision and robustness, outperforming current state-of-the-art object detection methods for small object detection.},
  archive      = {J_IJPRAI},
  author       = {Jincheng Li and Lina Yang and Patrick Shen-Pei Wang},
  doi          = {10.1142/S0218001425550043},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2555004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {STSODNet: Scale transformer small object detection network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-clues adaptive learning for cloth-changing person re-identification. <em>IJPRAI</em>, <em>39</em>(6), 2555001. (<a href='https://doi.org/10.1142/S0218001425550018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving long-term Cloth-Changing Person Re-identification (CC-ReID) requires extracting features insensitive to clothing such as face, silhouette, gait and pose estimation. Most current work focuses on modeling from a single feature, but we observe that CC-ReID problems in open environments are often difficult to solve solely based on a single feature, for instance, sometimes, contour features may be advantageous for recognition, while at other times gait features may be more valuable. In our paper, we suggest a novel multi-clues guided Adaptive Learning Transformer (ALT) which can adaptively select the most readily identifiable features based on different scenarios. The method comprises two parts: a Multi-clues Guiding Module (MGM) and a Feature Selection Module (FSM). We utilize clothes-irrelevant features from multi-modality information as clues, integrating multiple features to extract robust representations invariant to clothing changes for CC-ReID through cross-attention and Mixture of Experts (MoEs). We utilized contour sketch and gait as clues, conducting experiments on the CC-ReID dataset. The experimental results show that our recommended approach prevails over all other SOTA methods, particularly showing significant improvement compared to using contour sketch and gait alone.},
  archive      = {J_IJPRAI},
  author       = {Xiang Zhou and Junzhu Liu and Xinyang Jiang and Pengyu Li and Cairong Zhao},
  doi          = {10.1142/S0218001425550018},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2555001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-clues adaptive learning for cloth-changing person re-identification},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian uncertainty weighted optimization for offline reinforcement learning. <em>IJPRAI</em>, <em>39</em>(6), 2551001. (<a href='https://doi.org/10.1142/S0218001425510012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline reinforcement learning (offline RL) endeavors to learn effective policies from a large batch of pre-collected datasets without any costly or dangerous online exploration. Nevertheless, offline RL always suffers from substantial algorithmic extrapolation errors and may fail when bootstrapping from out-of-distribution (OOD) actions or states. In this work, we introduce a practical and effective Bayesian uncertainty weighted optimization (BUWO) to leverage the Bayesian uncertainty to account for the epistemic uncertainty associated with each training sample and penalize the state-action pairs with high uncertainty. We compare BUWO with other prevailing offline RL algorithms on D4RL benchmarks. The experimental results demonstrate that the algorithm can enhance the average reward score by almost 15% without additional computational costs compared to the current state-of-the-art algorithm.},
  archive      = {J_IJPRAI},
  author       = {Tianyi Li and Genke Yang and Jian Chu},
  doi          = {10.1142/S0218001425510012},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2551001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Bayesian uncertainty weighted optimization for offline reinforcement learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale adaptive diffusion feature fusion with causal invariance learning for hyperspectral image classification. <em>IJPRAI</em>, <em>39</em>(6), 2550010. (<a href='https://doi.org/10.1142/S0218001425500107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image (HSI) classification is a significant research area in remote sensing with a wide range of application scenarios. Recently, numerous HSI classification methods based on convolutional neural networks (CNNs) and Transformers have demonstrated promising classification performance. However, these methods demonstrate insufficient capability in mining spectral–spatial relationships from limited HSI samples and fail to extract features pertinent to the target category. To address these challenges, we propose a multi-scale adaptive diffusion feature fusion and causal invariance learning (MSDF-CIL) framework based on diffusion models. Specifically, the framework establishes spectral–spatial distribution relationships through forward and backward diffusion processes. The forward process gradually introduces noise to the HSI input. In the backward diffusion process, our pre-trained hyperspectral denoising network extracts semantically rich multi-scale diffusion features from complex spectral–spatial relationships. A multi-scale adaptive diffusion feature fusion (MSADFF) module is designed to learn key information about each scale and fuse it to enhance the representation. In addition, a causal invariance learning (CIL) module is designed to focus on features causally related to the target class, enabling the model to eliminate spurious correlations among diffusion features. Experimental results on three public HSI datasets show that the proposed MSDF-CIL outperforms other state-of-the-art HSI classification methods, even with minimal samples. When the number of training samples in each class reaches 30, the MSDF-CIL achieves overall accuracy improvements of 4.0% on the Pavia University dataset, 2.3% on the Indian Pines dataset, and 2.3% on the Houston13 dataset, respectively.},
  archive      = {J_IJPRAI},
  author       = {Wanxing Zha and Lina Yang and Huafu Xu and Bingzhen Wang and Danyang Chen and Yuwen Lin and Yiqun Wang and Patrick Shen-Pei Wang},
  doi          = {10.1142/S0218001425500107},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2550010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-scale adaptive diffusion feature fusion with causal invariance learning for hyperspectral image classification},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence on power flow stability control of high-penetration Wind–Solar-ES (Energy storage) distribution grid network. <em>IJPRAI</em>, <em>39</em>(5), 2559004. (<a href='https://doi.org/10.1142/S0218001425590049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of new energy systems, the stability of the power system is challenged. By adding energy storage links access to the power system, the original source–grid–load structure has been transformed into source–grid–load-ES (energy storage) structure. In order to monitor the stability of the high-penetration wind–solar-ES distribution network, this paper starts from the flow stability of the renewable power system, establishes a stability monitoring matrix as artificial intelligence, and uses the fluctuation of current and power flow as the measurement index to establish reasonable monitoring points for each parameter to encounter the demand of the point with the highest fluctuation. By monitoring and comparing various fluctuation indicators of the power flow in the high-penetration wind–solar-ES distribution grid with wind–solar power access ratio of 10–50%, the stability data of the power flow in the high-penetration wind–solar-ES distribution grid is determined, providing reference for the stable operation of the rapidly developing new power system.},
  archive      = {J_IJPRAI},
  author       = {Zhilin Ding and Wenping Bu and Yao Xu and Hui Li},
  doi          = {10.1142/S0218001425590049},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2559004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Artificial intelligence on power flow stability control of high-penetration Wind–Solar-ES (Energy storage) distribution grid network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An end-to-end classification network model based on hybrid supervision for industrial surface defect detection. <em>IJPRAI</em>, <em>39</em>(5), 2555005. (<a href='https://doi.org/10.1142/S0218001425550055'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial part surface defect detection aims to precisely locate defects in images, which is crucial for quality control in manufacturing. The traditional method needs to be designed in advance, but it has shortcomings in terms of generalization ability. Deep neural network-based defect detection faces issues such as low resolution, data scarcity, labeling costs, and high computation. Therefore, an improved solution is necessary to enhance industrial product quality control efficiency and accuracy. A new method is proposed that utilizes end-to-end training of a two-stage neural network based on segmentation with an extended training process. The gradient flow from the classification to the segmentation network is adjusted to prevent unstable features from interfering with learning. To address the problem of image oversampling and undersampling during training, a frequency sampling scheme for negative samples is introduced. Additionally, positive pixels in the region-based segmentation mask are weighted using the distance transform algorithm so that regions with a high probability of defects can be detected without detailed annotation. Experiments are conducted across three distinct defect datasets by applying hybrid supervision encompassing diverse conditions. In the optimal case, the AP rate of the proposed model on the DAGM and KolektorSDD datasets reaches 100%, and the AP rate on the Severstal Steel dataset reaches 98.99%. The experiments’ results show that the detection accuracy has improved greatly, showing how well the proposed method works in the industry.},
  archive      = {J_IJPRAI},
  author       = {Runbing Qin and Ningjiang Chen and Shukun Gan},
  doi          = {10.1142/S0218001425550055},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2555005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An end-to-end classification network model based on hybrid supervision for industrial surface defect detection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optic nerve segmentation model based on fully-convolutional-based masked autoencoders and direction field. <em>IJPRAI</em>, <em>39</em>(5), 2554005. (<a href='https://doi.org/10.1142/S0218001425540059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasound measurement of optic nerve sheath diameter (ONSD) is considered a noninvasive method for estimating elevated intracranial pressure (ICP) in patients. Clinical trials have demonstrated a strong correlation between changes in ONSD and changes in ICP. Therefore, accurate segmentation of the ONSD is crucial for noninvasive ICP assessment. In this paper, we propose a two-stage self-supervised semantic segmentation method to enhance optic nerve segmentation. In the pre-training phase, we use a fully convolutional-based masked autoencoder (FCMAE) to reconstruct full images from partially masked inputs. The encoder of FCMAE aggregates contextual information to infer the masked image regions, and this pretrained encoder is then migrated to the segmentation task for parameter initialization. In the fine-tuning phase, we perform the optic nerve segmentation task. After obtaining the initial segmentation results through the UPerNet network, we use a direction field (DF) module to compute a vector of DFs pointing to the nearest edge of the optic nerve for each pixel. This DF information is then used to refine the initial segmentation results via the feature correction module. The model was trained on a dataset of optic nerve sheath images collected from hospital patients and achieved a Dice score of 98.03%. Our proposed method exhibits superior performance across all metrics compared to other segmentation models.},
  archive      = {J_IJPRAI},
  author       = {M. Jiang and Q. Huang and X. Huang and J. Zhang and C. Wu and T. Huang and L. Xia and T. Tan and Z. Wang and Y. Chu},
  doi          = {10.1142/S0218001425540059},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2554005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An optic nerve segmentation model based on fully-convolutional-based masked autoencoders and direction field},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hummingbird optimization with deep learning enabled feature reduction and classification approach for high dimensional data. <em>IJPRAI</em>, <em>39</em>(5), 2552004. (<a href='https://doi.org/10.1142/S0218001425520044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel technique for image classification tasks that handles high-dimensional data: Hummingbird Optimization Deep Learning-based Feature Reduction and Classification (HBODL-FRC). The proposed method incorporates several cutting-edge methodologies to improve the precision and effectiveness of the categorization process. To ensure the quality of the input data, bilateral filtering is first used to successfully remove noise. After that, key features are extracted by combining texture features and histograms, which form the basis of the feature reduction procedure that follows. One of the main innovations in this work is the deployment of the Hummingbird Optimization (HBO) algorithm, which is used to intentionally minimize the feature sets’ complexity. The final classification of the images is accomplished by feeding the optimized feature set into a “multi-head attention-based bidirectional long short-term memory” (MABi-LSTM) model. To further improve classification accuracy, the MABi-LSTM model makes use of the attention mechanism to concentrate on the most pertinent portions of the data. Using benchmark datasets, the HBODL-FRC model’s performance was thoroughly assessed and compared to the existing techniques. The HBODL-FRC model performs better than previous methods in terms of robustness and classification accuracy, according to extensive experimental results.},
  archive      = {J_IJPRAI},
  author       = {D. Mahalakshmi and S. Appavu Alias Balamurugan and M. Chinnadurai},
  doi          = {10.1142/S0218001425520044},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2552004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Hummingbird optimization with deep learning enabled feature reduction and classification approach for high dimensional data},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The utilization of machine learning approaches in predicting the prominent physicochemical properties of polychlorinated biphenyl. <em>IJPRAI</em>, <em>39</em>(5), 2551007. (<a href='https://doi.org/10.1142/S0218001425510073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the difficulties in experimental measurement, machine learning offers a viable alternative method to reduce and minimize costs and time. Machine learning enhances the effectiveness and efficiency of environmental pollutant monitoring, supporting better management and protection of ecosystems and public health. Random forest is indeed a significant machine learning method, widely used for various applications due to its robustness and versatility. Polychlorinated biphenyls (PCBs), a vital class of persistent organic pollutants, have garnered significant attention from the scientific community due to their detrimental impacts. In this study, a computational prediction model for octanol–water partition coefficient (log P ) and bioconcentration factor (logBCF) of PCBs was developed by using random forest (RF), sparrow search algorithm random forest (SSA-RF), particle swarm optimization random forest (PSO-RF), and gray wolf optimization random forest (GWO-RF) methods. We performed a comprehensive validation, evaluation, and mechanistic explanation of the model for ensuring its reliability and applicability. Overall, the internal and external validation statistical parameters of the eight models have good robustness and predictive power. The Williams plots further show that all models are built in a wide range of application domains, and therefore they can be applied to unrecognized PCBs already in the environment to fill in the gaps in relevant experimental data. SSA-RF was superior to other methods, suggesting that it is more appropriate for computational studies of PCBs.},
  archive      = {J_IJPRAI},
  author       = {Hongqin Zhang and Ying Zhang and Lei Xu},
  doi          = {10.1142/S0218001425510073},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2551007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {The utilization of machine learning approaches in predicting the prominent physicochemical properties of polychlorinated biphenyl},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of job offers to measure gender barriers through natural language processing and soft computing techniques. <em>IJPRAI</em>, <em>39</em>(5), 2551005. (<a href='https://doi.org/10.1142/S021800142551005X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gender-biased language is still traced in job advertisements. Legal requirements to avoid direct gender-biased adjectives, and the usage of special software to detect and substitute gender-based words, scale up the issue more than solve it. The veil of discrimination on gender in job advertisements becomes more sophisticated with each succeeding level of its official and technical (including AI) prevention. This paper is mainly focused on the application of natural language processing (NLP) to detect gender-biased and discrimination of candidates by analyzing job offers posted online. NLP is an Artificial Intelligence tool that was applied in combination with Term Frequency-Inverse Document Frequency (TF-IDF) and Latent Dirichlet Allocation (LDA) to analyze the type of language used in job advertisements, detect the most relevant words used in the ads, and ultimately detect gender-bias. The main objective of this work is to provide equal access to employment opportunities from the very initial stage of the recruitment process. In addition, clustering techniques were applied to create groups based on the target public and the type of language used, providing evidence of gender-biased practices. The system was tested using a database of 2000 job ads in four different sectors: nursery, secretarial, managerial, and engineering.},
  archive      = {J_IJPRAI},
  author       = {Cristina Puente and Ivan Sanchez-Perez and Evhenia Kolomiyets-Ludwig and Clara Palacios-Castrillo and Patrick S. P. Wang and Rafael Palacios},
  doi          = {10.1142/S021800142551005X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2551005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Analysis of job offers to measure gender barriers through natural language processing and soft computing techniques},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). State recognition method of power equipment in smart grid based on machine learning. <em>IJPRAI</em>, <em>39</em>(5), 2551004. (<a href='https://doi.org/10.1142/S0218001425510048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, machine learning is used to solve the problem of power equipment state recognition, aiming to improve the accuracy of equipment operation state recognition. With the ever-expanding size of the power system, an increasing number of devices are becoming more intricate, posing significant challenges to the security of the electricity network. Consequently, enhancing equipment operational reliability is imperative to ensure the reliability of power system operations. This study focuses on the identification of the operating status of power equipment, which integrates intelligent optimization algorithms and machine learning techniques, utilizing an ameliorative FOA to solve the parameter setting problem of support vector machine (SVM). Subsequently, the new diagnosis model is utilized to distinguish the fault types of the equipment. Through simulation and measured data verification, it shows that the new power equipment state recognition model by using machine learning has high diagnostic accuracy. The method effectively enhances equipment status identification capabilities and equipment fault diagnosis proficiency.},
  archive      = {J_IJPRAI},
  author       = {Zhihui Kang and Yunlong Li and Yang Chai and Min Zhao},
  doi          = {10.1142/S0218001425510048},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2551004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {State recognition method of power equipment in smart grid based on machine learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimating the number of communities based on maximum a posteriori. <em>IJPRAI</em>, <em>39</em>(5), 2550007. (<a href='https://doi.org/10.1142/S0218001425500077'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community structure is one of the important characteristics of complex networks. Community discovery or detection has important theoretical significance and practical value. At present, estimation of the number of communities (or clusters) is still an open question. By Bayesian inference, this research deduces the relationship between maximum possible partition and mutual information and information entropy, and proposes a framework algorithm Clustering Number Estimation (CNE) and a concrete implementation to estimate the number of clusters ( K ). Several typical algorithms for community number estimation are compared on several typical data sets, and primary experiments validate the effectiveness of this method.},
  archive      = {J_IJPRAI},
  author       = {Ningsi Li and Chuanpeng Wang and Dong Li},
  doi          = {10.1142/S0218001425500077},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2550007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Estimating the number of communities based on maximum a posteriori},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gait recognition by combining recurrent neural network and fully convolutional network. <em>IJPRAI</em>, <em>39</em>(5), 2550006. (<a href='https://doi.org/10.1142/S0218001425500065'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait recognition is one of the key technologies for exoskeleton robot control. The existing gait recognition methods cannot meet the needs of real-time control well in terms of recognition accuracy and robustness. In this paper, a gait recognition method based on the recurrent neural network and fully convolutional network (RNN-FCN) algorithm is proposed. In this paper, a human lower limb gait information acquisition device is developed, ten types of human lower limb gait data are collected, and a human gait recognition model is constructed using the RNN-FCN algorithm. The experimental results demonstrate that the RNN-FCN algorithm achieves an average recognition classification accuracy of 94.43% in the experiments, outperforming the other four algorithms.},
  archive      = {J_IJPRAI},
  author       = {Xinbin Zhang and Weixiang Xiong and Zhihao Yang and Qinghong Zhang and Jianjun Yan},
  doi          = {10.1142/S0218001425500065},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2550006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Gait recognition by combining recurrent neural network and fully convolutional network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-layer gated recurrent unit-based recurrent neural network for image captioning. <em>IJPRAI</em>, <em>39</em>(5), 2454018. (<a href='https://doi.org/10.1142/S0218001424540181'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating natural language descriptions of an image, namely image captioning, has received much attention in computer vision and natural language processing. Recent image captioning models are mainly based on the encoder-decoder framework in which visual information is extracted by an encoder, e.g. using convolutional neural network (CNN), and captions are generated by a decoder, e.g. using recurrent neural network (RNN). Although this framework is promising for image captioning, there are still issues in the RNN decoder for exploiting the visual information to generate grammatically and semantically correct captions. More specifically, the RNN decoder has limited ability in dealing with long-term complex dependencies, leading to ineffective use of contextual information from the encoded data. To address this issue, in this paper, we introduce a multi-layer gated recurrent unit (ML-GRU) within the conventional RNN decoder, which enables the modulation of the relevant information flow inside the unit, and thus leads to the generation of semantically coherent captions. The proposed ML-GRU-based RNN decoder has been extensively evaluated on the MSCOCO dataset, and experimental results demonstrate the advantage of our proposed approach over the state-of-the-art approaches across multiple performance metrics.},
  archive      = {J_IJPRAI},
  author       = {Özkan Çaylı and Volkan Kılıç and Aytuğ Onan and Wenwu Wang},
  doi          = {10.1142/S0218001424540181},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2454018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-layer gated recurrent unit-based recurrent neural network for image captioning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting the fatigue crack life of train axles using a collaborative network of yolov5 and LSTM for acoustic emission signals. <em>IJPRAI</em>, <em>39</em>(03n04), 2559002. (<a href='https://doi.org/10.1142/S0218001425590025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of axles, life forecasting can be used to predict the lifespan of the axle and to determine more effective maintenance schedules. The life forecasting can have a significant positive impact on the safe operation of train axles, which can be used to predict the lifespan of the axle and to determine more effective maintenance schedules. Traditional methods for predicting the life of the shaft are based on experimental and statistical analysis, but these methods can be expensive and time-consuming. The LSTM-based Lifetime Forecasting method uses machine learning technology and historical data on the axles to more accurately predict remaining lifespan, thereby reducing costs and improving efficiency. This invention is innovative in that it introduces a semi-monitoring technique for estimating an axle RUL’s full life based on YOLOv5 and LSTM training. A large number of unmarked data are trained along with YOLOv5 and LSTM to determine interrupted data to RUL predictions. The use of a laboratory-collected sound crack on the 5 million, 7 million and 10 million signal data collection and RMSE MAE values, for verifying the performance of the model, respectively, for the full cycle of life of 5, 7 million, 10 million vehicles, is predicted with a strong difference between the predictable life of 5M and the remaining value of the forecast model.},
  archive      = {J_IJPRAI},
  author       = {Li Lin and Chunpeng Zhang and Liwen Ding and Lin Sun},
  doi          = {10.1142/S0218001425590025},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2559002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Predicting the fatigue crack life of train axles using a collaborative network of yolov5 and LSTM for acoustic emission signals},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Manifold matrices-based attention mechanisms on 3D skeletons for human action recognition. <em>IJPRAI</em>, <em>39</em>(03n04), 2557001. (<a href='https://doi.org/10.1142/S0218001425570010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, one of the most well-liked study fields in computer-vision is skeleton-based human action recognition. As the Lie group in Riemannian manifolds is able to precisely describe 3D geometric relationships among rigid bodies, it is widely used in skeleton-based action recognition approaches to construct action feature descriptors. Regrettably, the majority of these approaches overlook crucial body parts and skeletons in favor of focusing solely on spatio-temporal descriptors of an action as a whole. A manifold-based rigid body motion attention mechanism is proposed to assign varying degrees of importance to the relative geometries of different limb motions, and then a skeleton-based spatial attention module is constructed on the basis of limb motions for the more efficient extraction of spatial features from skeletons. Furthermore, a Lie group-based temporal attention mechanism is proposed on the basis of the first two phases to choose significant skeleton frames in an effort to raise the level of action recognition accuracy even higher. Results from experiments on four of the most influential action datasets demonstrate that the proposed approach performs better in terms of action recognition accuracy than many cutting-edge approaches based on skeletons.},
  archive      = {J_IJPRAI},
  author       = {Guang Li and Chongyang Ding and Jianjun Li},
  doi          = {10.1142/S0218001425570010},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2557001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Manifold matrices-based attention mechanisms on 3D skeletons for human action recognition},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DGNet: A double-graph framework combined with occluded person re-identification for the prediction of pedestrian flow in scenic spots. <em>IJPRAI</em>, <em>39</em>(03n04), 2555003. (<a href='https://doi.org/10.1142/S0218001425550031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting pedestrian flow in scenic spots is a critical challenge for managing tourist areas. To address this, we propose the double-graph network (DGNet) framework, which combines occluded person re-identification and pedestrian flow prediction. Scenic spots are represented as nodes in a graph, with their pedestrian flow as node attributes, naturally forming a graph structure. DGNet consists of two key graphs: CNN-transformer graph (CTG) for occluded person re-identification and spatial-temporal graph (STG) for pedestrian flow prediction. CTG integrates global and local features using CNN, Transformer, and graph convolutional network (GCN) to handle occlusions effectively. STG employs spatial-temporal attention mechanisms to extract correlations across time and space for accurate pedestrian flow prediction. Based on comprehensive experiments, the proposed CTG obtains a comparable performance to the current mainstream occluded person re-identification algorithms. Comparative experiments with other models show that the STG achieves the best results on MAE, RMSE and MAPE metrics, outperforming other models by at least 0.29%, 0.51%, and 0.52%. These results highlight the framework’s robustness and accuracy. Moreover, the novelty of DGNet lies in its ability to bridge occluded person re-identification with flow prediction tasks, offering a scalable solution applicable to diverse scenic spots. This work provides practical insights into leveraging video surveillance for effective crowd management in tourist areas.},
  archive      = {J_IJPRAI},
  author       = {Jianrong Wang and Zhikang Meng and Fengping An},
  doi          = {10.1142/S0218001425550031},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2555003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {DGNet: A double-graph framework combined with occluded person re-identification for the prediction of pedestrian flow in scenic spots},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel topic modeling framework for automated surveying of computer vision research in prostate cancer detection. <em>IJPRAI</em>, <em>39</em>(03n04), 2555002. (<a href='https://doi.org/10.1142/S021800142555002X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retrieving the relevant information or material makes a big difference in the medical field because it is necessary to acquire updates on recent findings and inferences so that the practitioners can understand the state-of-the-art topics. Thus, extracting relevant material automatically from the pool of large databases like Web of Science and IEE Explore on particular issues is important. This work focuses on extracting articles on different topics for prostate cancer detection. Due to a huge number of articles in large databases with many variations in the format, keywords, text in various forms, etc., extracting relevant articles is an open challenge. This observation motivated us to propose new Agnostic-topic modeling for retrieving articles across different categories, namely, Tasks (Image Classification, Image Segmentation, Gleason Grading, Object Detection, Image Enhancement, Motion Tracking, Image Registration, Image Synthesis, and Image Reconstruction), Models (CNN, UNet, GAN, Convolutional ML models, and Uncategorized) and Image Data Type (MRI, CT, Histological Images, Ultrasound Images, Nuclear Imaging, and Others). To address the above open challenge, the proposed work adapted ChatGPT and compared it with well-known models like LDA and BERT to show the robustness of ChatGPT. Furthermore, the extracted information is used to derive new inferences and findings. For example, the trend analysis according to the abovementioned tasks, models, and image types. To the best of our knowledge, this is the first work on retrieving articles automatically for prostate cancer detection.},
  archive      = {J_IJPRAI},
  author       = {Razieh Fadaeidehcheshmeh and Kaveh Kiani and Shivakumara Palaiahnakote and Taha Mansouri},
  doi          = {10.1142/S021800142555002X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2555002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A novel topic modeling framework for automated surveying of computer vision research in prostate cancer detection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid-domain attention dense network for efficient image super-resolution. <em>IJPRAI</em>, <em>39</em>(03n04), 2554003. (<a href='https://doi.org/10.1142/S0218001425540035'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient Image Super Resolution (EISR) techniques are critical to meeting the real-time demands of resource-constrained devices. Current approaches focus too much on parameter reduction, thus slightly sacrificing image quality. To alleviate this issue, we propose a novel Hybrid Attention Dense Network (HADN) in this paper. HADN fully explores how to balance model performance and image recovery quality better. It incorporates two key designs: (1) We apply Hybrid-domain Attention Dense Blocks (HADB) with different feature layers cumulatively connected to enhance the representation of shallow features. (2) We designed a novel Hybrid-domain Attention Block (HAB) to reinforce the correlation between image edges and receptive fields for effective information fusion to improve the perception of detailed image features. Extensive experimental analyses affirm the competitiveness of the proposed method, showcasing its ability to balance performance and recovery effectively, even with smaller training datasets. The code is available at https://github.com/Yuii666/HADN .},
  archive      = {J_IJPRAI},
  author       = {Yanyi He and Jinhong He and Minglong Xue and Senming Zhong and Mingliang Zhou},
  doi          = {10.1142/S0218001425540035},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2554003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Hybrid-domain attention dense network for efficient image super-resolution},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stock market analysis and social media index based on deep learning. <em>IJPRAI</em>, <em>39</em>(03n04), 2552003. (<a href='https://doi.org/10.1142/S0218001425520032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a hybrid sentiment analysis model, FinBERT-BiLSTM-TextCNN, which integrates deep learning and machine learning techniques to accurately analyze the sentiment strength of comments in financial forums. We conduct a regression analysis of stock prices and apply economic analysis methods to evaluate the impact of social media sentiment on market dynamics. By processing user comments, we construct a comprehensive investor sentiment measurement indicator known as the Social Media Sentiment Index (SMI). This index innovatively combines two key metrics: sentiment strength and user engagement, offering a novel analytical tool for quantifying and characterizing investor sentiment. Our experimental results indicate two main findings: (1) Compared to current sentiment classification approaches, the hybrid FinBERT-BiLSTM-TextCNN sentiment analysis model achieves over a 3% improvement in sentiment classification accuracy on stock market forum datasets; (2) Based on real trading data from the Chinese stock market over two years and an analysis of 20 million comments from the East Money Forum, the proposed Social Media Sentiment Index more accurately reflects changes in individual stock characteristics and tracks market sentiment fluctuations more efficiently, with a correlation to stock price movements improving by more than 4% compared to traditional methods. This study demonstrates the significant role of integrating economic analysis with sentiment analysis in predicting stock market trends, highlighting the value of the Social Media Sentiment Index as a robust indicator of investor behavior and market sentiment.},
  archive      = {J_IJPRAI},
  author       = {Xiyao Xu},
  doi          = {10.1142/S0218001425520032},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2552003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Stock market analysis and social media index based on deep learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CAT-UNet: Integrating CNN attention mechanism and TransUNet for lung mass segmentation. <em>IJPRAI</em>, <em>39</em>(03n04), 2552002. (<a href='https://doi.org/10.1142/S0218001425520020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chest X-ray is one of the most common tests in radiology and plays a vital role in helping physicians spot different chest conditions. This paper proposes a new model called CAT-UNet to segment lung masses in chest X-ray images. The CAT-UNet uses TransUNet as the leading architecture and mixes CNN and transformer as an encoder. The CNN uses ResNet50 as the backbone, embedding the coordinate attention (CA) block and four skip connections of different scales to improve the accuracy of finding shallow features. Vision Transformer (ViT), which applied the transformer structure, was used in our method to enhance the feature representation ability of images, and Atrous Spatial Pyramid Pooling (ASPP) was used to adjust the filter’s field-of-view and control the resolution of features. In the decoder, the Convolutional Block Attention Modules (CBAM) are embedded for upsampling so that the segmentation details can be better optimized. To evaluate the performance and generalizability of the proposed method, we conducted a 3-fold cross-validation experiment using 1914 chest X-ray images labeled by radiologists collected from the Department of Radiology at Dalin Tzu Chi Hospital, Taiwan. Experimental results show that the proposed CAT-UNet achieves 89.06% on Dice, 91.62% on sensitivity, 98.64% on specificity, and 95.15% on accuracy, outperforming U-Net, TransUNet, and Swin-UNet encoders.},
  archive      = {J_IJPRAI},
  author       = {Ade Irma Suryani and Chuan-Wang Chang and Hsin-Tien Cheng and Tin-Kwang Lin and Chin-Wen Lin and Chuan-Yu Chang},
  doi          = {10.1142/S0218001425520020},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2552002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {CAT-UNet: Integrating CNN attention mechanism and TransUNet for lung mass segmentation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-driven multi-modal interactive learning environment using deep learning and chain-of-thought reasoning. <em>IJPRAI</em>, <em>39</em>(03n04), 2552001. (<a href='https://doi.org/10.1142/S0218001425520019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of rapid advancements in educational technology, Active Interactive Learning Environments (ILEs) have emerged as key tools for enhancing instructional outcomes and student engagement. This paper presents an innovative active interactive learning system based on multi-modal chain-of-thought (CoT) reasoning, aiming to optimize personalized support in the learning process by integrating multi-modal data (including text, images, and videos) with CoT techniques. The system utilizes advanced deep learning technologies such as Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Retrieval-Augmented Generation (RAG) to achieve dynamic, real-time personalized content generation and feedback mechanisms. Experimental results indicate that this system significantly improves student performance and engagement in the “Computer Networks” course, demonstrating its effectiveness in practical teaching settings. This study provides a solid theoretical foundation and practical guidance for further research and application of intelligent educational systems, highlighting the potential for driving future educational innovation.},
  archive      = {J_IJPRAI},
  author       = {Tong Li},
  doi          = {10.1142/S0218001425520019},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2552001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {AI-driven multi-modal interactive learning environment using deep learning and chain-of-thought reasoning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing AutoTVM by parallel genetic algorithms. <em>IJPRAI</em>, <em>39</em>(03n04), 2551006. (<a href='https://doi.org/10.1142/S0218001425510061'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To make deep neural networks automatically achieve the same or better performance compared with those in hand-optimized libraries, Tensor Virtual Machine (TVM) has combined a genetic algorithm (GA) with its AutoTVM auto-tuning process. The genetic algorithm of TVM has a primary and classic design, with restrictions in terms of searching scope, ability, and efficiency. Meanwhile, the current AutoTVM process is time-consuming. The whole process may last hours on GPUs. As such, we propose a new auto-tuning method that is based on a parallel GA and takes advantage of the strengths of the Roofline model-based cost models and machine learning classification models to widen the search scope and improve search efficiency. The new auto-tuning method achieves double optimization on both tuning results and tuning time. A series of experiments show that the new way improves the inference time of typical deep networks by about 8–14% and speeds up the time consumption of the auto-tuning process up to 1.2– 1 . 5 2 × on GPUs compared with the original GA process of AutoTVM.},
  archive      = {J_IJPRAI},
  author       = {Changhai Zhao and Jiamin Wen and Minqiang Shang and Yuchen Feng and Xiaohua Shi},
  doi          = {10.1142/S0218001425510061},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2551006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Optimizing AutoTVM by parallel genetic algorithms},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proton exchange membrane fuel cells lifetime estimation using GCN-GRU: Simulation and prospective tramway applications. <em>IJPRAI</em>, <em>39</em>(03n04), 2551003. (<a href='https://doi.org/10.1142/S0218001425510036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proton Exchange Membrane Fuel Cells (PEMFC) are a high-efficiency, clean energy source with significant potential for intelligent transportation systems, such as tramways. However, accurately predicting the lifespan of these fuel cells remains a significant challenge, critical for ensuring reliable and continuous tramway operation. This paper proposes an innovative hybrid neural network model combining Graph Convolutional Networks (GCN) and Gated Recurrent Units (GRU) for precise Remaining Useful Life (RUL) prediction of PEMFC. The model employs a graph learning layer to capture inter-node relationships from PEMFC data, constructing an asymmetric adjacency matrix that reflects the system’s internal directional dependencies. It then utilizes a mix-hop propagation layer to integrate time-series data, effectively capturing the dynamic behaviors and performance variations of PEMFC. Experimental results show that this model outperforms traditional GRU and CNN-GRU models in both short-term and long-term predictions, providing more accurate RUL estimations. The model utilizes high-fidelity test data from a France laboratory to improve the accuracy of fuel cell lifetime predictions, and the potential applications and experimental validation of the model in future intelligent transportation systems such as trams are discussed. This innovative approach provides a robust framework for predictive maintenance, and provides reliable data support and optimization schemes for practical applications in tramways, enhancing the reliability and efficiency of intelligent transportation systems.},
  archive      = {J_IJPRAI},
  author       = {Jinling Ma and Jiye Zhang and Jibin Yang},
  doi          = {10.1142/S0218001425510036},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2551003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Proton exchange membrane fuel cells lifetime estimation using GCN-GRU: Simulation and prospective tramway applications},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-validation-based multi-fault detection of gas turbine. <em>IJPRAI</em>, <em>39</em>(03n04), 2551002. (<a href='https://doi.org/10.1142/S0218001425510024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operating in harsh environments, gas turbines may encounter a variety of faults. Failure to promptly detect these faults can severely impact their safe and stable operation. During actual operations, accurately detecting the specific location of faults in gas turbines, such as sensors, actuators, or gas paths, to ensure prompt maintenance and safe, stable operation, is a crucial aspect of gas turbine maintenance. To address this issue, this study proposes a multi-fault detection method based on cross-validation. In situations with limited data, we have designed a classification method grounded in logical reasoning and constructed a cross-validation system. This system will be applied to layered analysis and discrimination of multiple faults, aiming to achieve effective detection of faults in gas turbine sensors, actuators, and air paths. Finally, simulation experiments have verified the effectiveness and feasibility of this method.},
  archive      = {J_IJPRAI},
  author       = {Ying Wang and Yunpeng Cao and Shuying Li and Linhai Zhu and Ke Han},
  doi          = {10.1142/S0218001425510024},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2551002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Cross-validation-based multi-fault detection of gas turbine},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mining emerging patterns of data stream for improving classification performance. <em>IJPRAI</em>, <em>39</em>(03n04), 2550005. (<a href='https://doi.org/10.1142/S0218001425500053'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emerging patterns consider the support of patterns in the target class and opposite class datasets, which has a significant impact on improving the performance of data stream classification. The emerging pattern must first be a frequent pattern, and IncMine is a well-known data stream algorithm with frequent closed pattern mining. However, existing frequent pattern mining algorithms are oriented toward transactional data streams, and the itemset does not have class constraints, making it impossible to further mine emerging patterns for data stream classification. This paper proposes an emerging patterns based on IncMine (EPBIM) mining method, which improves the IncMine algorithm and uses Charm_Cla to mine frequent closed itemsets with class value constraints and obtain emerging patterns for Bayesian classification of data streams. The Charm_Cla runs on the WEKA platform, mining the emerging patterns of a batch and updating the semi-emerging patterns (semi-EPs) in the sliding window of data stream through the IncMine algorithm. Multiple real and simulated data streams were run on the data stream analysis platform massive online analysis (MOA), and the experimental results verified the effectiveness of the method.},
  archive      = {J_IJPRAI},
  author       = {Zhijie Li and Xuhong Liao and Sha Liao and Yuanxiang Li},
  doi          = {10.1142/S0218001425500053},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2550005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Mining emerging patterns of data stream for improving classification performance},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An invisible backdoor attack based on semantic feature. <em>IJPRAI</em>, <em>39</em>(03n04), 2550004. (<a href='https://doi.org/10.1142/S0218001425500041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backdoor attacks have severely threatened deep neural network (DNN) models in the past several years. Compared to adversarial attacks, backdoor attacks are always carried out during the training phase. The attacked model behaves normally on benign samples, it makes wrong predictions for samples containing triggers. This paper proposes a novel backdoor attack that makes imperceptible changes. Concretely, the attack first utilizes the pre-trained victim model to extract low-level and high-level semantic features from clean images and generates trigger patterns associated with high-level features based on channel attention. Then, the encoder model generates poisoned images based on the trigger and extracted low-level semantic features without causing noticeable feature loss. The attack is evaluated on two prominent image classification DNNs across three standard datasets. The results demonstrate that our attack achieves high attack success rates while maintaining robustness against backdoor defenses. Furthermore, extensive image similarity experiments emphasize the stealthiness of this attack strategy.},
  archive      = {J_IJPRAI},
  author       = {Yangming Chen and Xiaowei Xu and Xiaodong Wang and Zewen Li and Wenmin Chen},
  doi          = {10.1142/S0218001425500041},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2550004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An invisible backdoor attack based on semantic feature},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-based texture feature extraction technique for face annotation. <em>IJPRAI</em>, <em>39</em>(03n04), 2532001. (<a href='https://doi.org/10.1142/S0218001425320015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face annotation plays a crucial role in the field of computer vision. Its purpose is to accurately label the faces that appear in an image. The effectiveness of face annotation relies heavily on the representation of facial features, such as color, texture, and shape. Deep texture features, in particular, play a significant role in face annotation systems. It is worth noting that different individuals can possess similar texture features, which can impact the performance of annotation. Therefore, this study addresses the enduring complexity of face similarity by introducing an innovative approach called the Deep Learning-based Texture Feature (DLTF) through the utilization of the efficient deep learning model known as the Residual Network (ResNet). Despite the variations in poses, lighting, expressions, and occlusions that can greatly alter faces, ResNet’s deep architecture and feature retention capabilities make it resilient to these changes, ensuring consistent and accurate annotations under diverse conditions. Experimental results obtained from the IMFDB, LFW, and Yahoo datasets demonstrate that the proposed DLTF is the most effective description of deep texture features, leading to improved face naming performance. Furthermore, the proposed DLTF enhances the efficiency of the face-naming task by effectively addressing real-life challenges.},
  archive      = {J_IJPRAI},
  author       = {A. Kasthuri and A. Suruliandi and E. Poongothai and S. P. Raja},
  doi          = {10.1142/S0218001425320015},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2532001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Deep learning-based texture feature extraction technique for face annotation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale GAN with NSCT prediction for seismic data denoising. <em>IJPRAI</em>, <em>39</em>(03n04), 2458006. (<a href='https://doi.org/10.1142/S0218001424580060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on denoising seismic signals effectively to obtain high-quality data, which is crucially important for oil-gas reservoir prediction and seismic interpretation tasks. The rapid progress of deep learning has brought new development opportunities to seismic oil and gas exploration technologies. However, current deep learning-based seismic denoising models have limited learning ability due to insufficient extraction features in strong noise backgrounds. For this reason, we develop a new multi-scale generative adversarial networks (GAN) with transform prediction for seismic signal denoising. First, we develop a deep multi-scale diversion fusion (MSDF) network in a GAN generator considering the advantages of combining GAN and convolutional neural networks. MSDF network primarily contains several MSDF blocks that mine abundant long-short path features in multiple receptive fields to restore seismic signals in a rough to detailed manner. Additionally, current deep learning-based seismic denoising models only exploit features in the spatial domain, not considering high-frequency characteristics, which results in insufficient high-frequency details when reconstructing seismic data. So, we propose to predict high-frequency components during learning by employing the superior non-subsampled contourlet transform (NSCT), which further preserves the better global topological structure and local texture characteristics of MSDF in GAN generator than the spatial domain, promoting the discrimination ability in GAN discriminator. The qualitative and quantitative results on our constructed synthetic dataset and actual seismic data demonstrate that the proposed method surpasses other deep learning-based approaches in realizing higher signal-to-noise ratio, as well as mining more effective high-frequency signals.},
  archive      = {J_IJPRAI},
  author       = {Cong Tang and Kang Chen and Bing Luo and Qi Ran and Majia Zheng and Han Xiao},
  doi          = {10.1142/S0218001424580060},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2458006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-scale GAN with NSCT prediction for seismic data denoising},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative artificial intelligence model for multi-granularity power data simulation. <em>IJPRAI</em>, <em>39</em>(2), 2559001. (<a href='https://doi.org/10.1142/S0218001425590013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric power resources are essential for the efficient and orderly development of society. Accurate power load forecasting is a key driver for the low-carbon upgrade of power systems. Traditional forecasting methods often struggle to capture long-term dependencies. Additionally, extracting complex nonlinear features from data remains a significant challenge, making it challenging to meet the accuracy demands of modern power systems. Besides, current deep learning-based forecasting methods cannot simulate multi-granularity power load data. To address these challenges, this paper presents a Generative Pre-trained Transformer model, GPT4PLTS, designed for power data simulation and fine-grained power load forecasting. The model leverages the Transformer architecture, incorporating the first six layers of the GPT decoder structure. It utilizes a multi-head attention mechanism to extract temporal features and includes a time alignment layer to maintain the sequence of time-series data, addressing both short-term and long-term dependencies. Extensive experiments are conducted on load observations from 2000 enterprises. The results demonstrate that GPT4PLTS achieves high accuracy in data simulation and forecasts across different time granularities, particularly excelling in short and medium-term predictions. Future research could focus on optimizing the model structure to enhance the model’s generalization ability.},
  archive      = {J_IJPRAI},
  author       = {Yiwen Jiang and Sheng Xiang and Yihan Dai and Dawei Cheng},
  doi          = {10.1142/S0218001425590013},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2559001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Generative artificial intelligence model for multi-granularity power data simulation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AMP: Multi-task transfer learning via leveraging attention mechanism on task embeddings. <em>IJPRAI</em>, <em>39</em>(2), 2557004. (<a href='https://doi.org/10.1142/S0218001425570046'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The attention mechanism has been successfully used in a sequence consisted of a series of word embeddings to improve the representation of the sequence. Inspired by this, we leverage the attention mechanism on a set of tasks to implement a multi-task transfer learning method called AMP (Attentions between Multiple Prompts). First, we encode a task into a prompt as task representation called task embedding. Second, we learn an attention component on all task embeddings to generate a combined prompt for each task, which is an attention-weighted sum of task embeddings. Each combined prompt incorporates the knowledge of all tasks. The word embedding is a vector, but the task embedding is a 2D matrix. The attention mechanism can be exploited on a set of vectors rather than on a set of matrices. The prior methods employ pooling or flattened method to transform the matrix to the vector for computing the attentions between matrices. We propose a method called DAM (Direct Attention Mechanism) which can compute attentions between matrices directly without transforming. DAM method can more exactly compute the attentions between matrices. Wide experiments demonstrate that AMP outperforms prompt-tuning method and prior prompt transfer methods.},
  archive      = {J_IJPRAI},
  author       = {Yangyang Yu and Keru Wang},
  doi          = {10.1142/S0218001425570046},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2557004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {AMP: Multi-task transfer learning via leveraging attention mechanism on task embeddings},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lift-type power catwalk system based on dual closed-loop error-driven active disturbance rejection control. <em>IJPRAI</em>, <em>39</em>(2), 2557003. (<a href='https://doi.org/10.1142/S0218001425570034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To mitigate the flutter instability observed during lift-type power catwalk operations, a Dual-Loop Error-Driven Adaptive Disturbance Rejection Control (EDDL-ADRC) strategy is proposed. This approach enhances the tracking accuracy and robustness of the electro-hydraulic servo system under variable load and large inertia conditions, effectively alleviating flutter induced by fluctuations in driving speed. Under low-frequency small load conditions, the EDDL-ADRC overcomes the limitations of traditional Active Disturbance Rejection Control (ADRC), particularly those related to system order, and demonstrates superior control performance compared to conventional ADRC. The dual-loop error-driven controller consists of two identical second-order ADRC modules. The primary controller operates in a conventional driving mode, while the error-driven controller utilizes both the system’s output error and control input as driving signals. This error-driven controller effectively compensates for phase lag in the main controller and the limited observation accuracy of the Extended State Observer (ESO), thereby improving overall system performance. The proposed control strategy’s effectiveness is validated via a joint simulation platform that integrates both the electro-hydraulic and mechanical systems of the catwalk mechanism.},
  archive      = {J_IJPRAI},
  author       = {Jia Chen and Li Xiong and Simin Kang and Yi Yang and Zhongfeng Li},
  doi          = {10.1142/S0218001425570034},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2557003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Lift-type power catwalk system based on dual closed-loop error-driven active disturbance rejection control},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An indoor WiFi fingerprint positioning based on RSS and CSI. <em>IJPRAI</em>, <em>39</em>(2), 2557002. (<a href='https://doi.org/10.1142/S0218001425570022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous people to determine the location by wireless fingerprint technology indoors at present. The premise of fingerprint positioning is to assume that the received signal strength distance is consistent with the positioning distance. However, due to the interference of obstacles such as walls, desks, chairs, pedestrians, the closest distance selected using the received signal strength distance may not be the closest to the target at its corresponding position, which may lead to large positioning errors. To improve accuracy, this paper analyzes the advantages of the respective features of RSS and CSI, use algorithms to extract them, and proposes a novel WiFi fingerprint positioning algorithm for fusion to estimate the target location. The experimental data show that this method has certain advantages in improving positioning accuracy.},
  archive      = {J_IJPRAI},
  author       = {Kun Zhang and Feixue Cheng and Haifeng Wang and Yu Zhou and Qiang Geng and Jinyang Zhou and Yukang Fan and Wenting Pan},
  doi          = {10.1142/S0218001425570022},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2557002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An indoor WiFi fingerprint positioning based on RSS and CSI},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rough intuitionistic fuzzy set based on inclusion degree. <em>IJPRAI</em>, <em>39</em>(2), 2554002. (<a href='https://doi.org/10.1142/S0218001425540023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper first proposes the notion of the intuitionistic fuzzy sets on inclusion degree, furthermore, a couple of dual operators’ lower approximations, and upper approximations of fuzzy inclusion approximate space are provided, thus, a probabilistic intuitionistic fuzzy set model that stemmed from inclusion degree was obtained. A rough intuitionistic fuzzy set and histogram equalization-based image enhancement algorithm is proposed to address the shortcomings of excessive enhancement and loss of image detail information in fuzzy enhancement that cannot improve image contrast and histogram equalization enhancement. The fusion of rough intuitionistic blur enhancement and histogram equalization focuses on rough intuitionistic blur enhancement while suppressing the shortcomings of histogram equalization, which not only enhances the detailed information of the image but also improves its contrast. Finally, its effectiveness is verified through typical image enhancement examples.},
  archive      = {J_IJPRAI},
  author       = {Qiuna Zhang and Chunhai Hu and Ling Zhang},
  doi          = {10.1142/S0218001425540023},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2554002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Rough intuitionistic fuzzy set based on inclusion degree},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image deblurring algorithm incorporating self-attention mechanism. <em>IJPRAI</em>, <em>39</em>(2), 2554001. (<a href='https://doi.org/10.1142/S0218001425540011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The acquisition of clear images is a critical aspect in various fields including computer vision, aerial detection, and medical imaging. The issue of image blur caused by object motion poses a challenge in obtaining clear images. To address this, an improved AT-DGAN network model is proposed in this paper. This model integrates the pyramid generator module of the DeblurGAN-v2 network with a self-attention mechanism. The feature pyramid is employed for image feature extraction and representation, while the self-attention mechanism dynamically adjusts the weight of important features in each pyramid layer and performs weighted fusion, thereby compensating for the information loss during feature extraction in the feature pyramid network. Additionally, a hinge loss function is designed for the proposed model to balance the discriminator and the generator, enhancing the stability and training efficiency of the generative adversarial network. The experimental results show that compared to other algorithms of the same type, this improved algorithm has increased the Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) of restored images by 0.58 dB and 1.5%, respectively.},
  archive      = {J_IJPRAI},
  author       = {Tingting Yu and Qiang Lv and Zhen Huang and Zhang Su and XiangLi Wang},
  doi          = {10.1142/S0218001425540011},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2554001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Image deblurring algorithm incorporating self-attention mechanism},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A modified model with multi-scale feature fusion and multi-decoupled-head for detecting traffic object. <em>IJPRAI</em>, <em>39</em>(2), 2550003. (<a href='https://doi.org/10.1142/S021800142550003X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately and rapidly detecting traffic object has been attracted intensive attention due to its potential applications in the fields of autonomous driving, traffic flow monitoring, augmented reality (AR) and so on. However, there are many difficulties in the process of traffic object detection indeed, such as occlusion and aggregation between objects, insufficient feature extraction of objects, in particular the presence of a large number of small objects, which bring great challenges to these traffic objects detection. In this paper, an improved traffic object detection model based on You-Only-Look-Once version 5 small (YOLOv5s) is proposed to address the issues. By utilizing spatial pyramids to extract multi-scale spatial features and applying Squeeze-and-Excitation (SE) channel attention to capture more global and local semantic features, especially by designing a sub-network in the neck to fuse high-resolution information in shallow layers with more accurately semantic information in deep layers, the detection sensitivity of object features is enhanced. More importantly, by explanting decoupled-head into the network, outstanding performance of the model with high detection accuracy and rapid detection speed is realized. The experimental results on the Karlsruhe Institute of Technology and Toyota Technological Institute (KITTI) and Laboratory for Intelligent and Safe Automobiles (LISA) traffic signs datasets both show that the modified model significantly improves the detection accuracy. Meanwhile, the high real-time performance is still maintained. Undoubtedly, the modified model proposed in this paper can effectively address many difficulties in traffic object detection under various complex scenes, which would be greatly helpful for its potential applications in the future.},
  archive      = {J_IJPRAI},
  author       = {Yongfan Duan and Hongtao Gong and Haoyang Yu and Kuijie Shi and Bingbing Wang and Daoxun Jin and Wenqian Wan and Zihua Wang and Shuqin Liu and Gang Liu},
  doi          = {10.1142/S021800142550003X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2550003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A modified model with multi-scale feature fusion and multi-decoupled-head for detecting traffic object},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using hybrid transformer and convolutional neural network for malware detection in internet of things. <em>IJPRAI</em>, <em>39</em>(2), 2550002. (<a href='https://doi.org/10.1142/S0218001425500028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malicious firmware upgrading represents a critical security vulnerability in Internet of Things (IoT) devices. This study introduces HyCNNAt, a novel hybrid deep learning network for IoT malware detection that synergistically combines Convolutional Neural Networks (CNNs) with transformer attention mechanisms. HyCNNAt’s architecture vertically and horizontally stacks convolution and attention layers, enhancing the network’s generalization capabilities, capacity, and overall effectiveness. We evaluated HyCNNAt using a publicly available IoT firmware dataset, where it demonstrated superior performance with the highest accuracy ( 9 7 . 1 1 % ± 1 . 0 2 % ), F1-score ( 9 9 . 9 9 2 % ± 0 . 0 0 4 % ), and recall ( 9 7 . 4 8 % ± 2 . 6 5 5 6 % ), highlighting its robust classification capabilities, although its precision ( 9 1 . 2 7 % ± 4 5 . 0 8 % ) exhibited variability compared to state-of-the-art models such as CoAtNet, MobileViT, MobileNet, and MobileNet variants using transfer learning. These results underscore HyCNNAt’s potential as a robust solution for addressing the pressing challenge of IoT malware detection.},
  archive      = {J_IJPRAI},
  author       = {Yanhui Guo and Chunlai Du and Zelal Mustafaoglu and Abdulkadir Sengur and Harish Garg and Kemal Polat and Deepika Koundal},
  doi          = {10.1142/S0218001425500028},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2550002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Using hybrid transformer and convolutional neural network for malware detection in internet of things},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Biased block term tensor decomposition for temporal pattern-aware QoS prediction. <em>IJPRAI</em>, <em>39</em>(2), 2550001. (<a href='https://doi.org/10.1142/S0218001425500016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread application of cloud services make users pay more attention to Quality of Service (QoS). Generally, the user cannot call all services simultaneously to obtain corresponding QoS data and can only choose a service from a few known data, thus it’s critical to predict unknown QoS values. A third-order tensor can model temporal patterns of QoS data, and studies indicate that the tensor latent factor analysis models based on Canonical Polyadic (CP) decomposition can effectively capture temporal patterns to predict unknown data in QoS. However, the existing CP decomposition-based models limit their learning ability since rank-one tensors contain less structure information, which results in low prediction accuracy. Therefore, this paper proposes a Biased Block Term Tensor Decomposition (BBTTD) model to achieve high accuracy for temporal pattern-aware QoS prediction. It mainly adopts the following three-fold ideas: (a) implementing a tensor learning model by adopting the block term decomposition in rank-( L r , L r , 1) terms; (b) proposing the bias block term tensors to enhance the model’s prediction accuracy; (c) designing a nonnegative multiplication update algorithm to learning model parameters. Extensive experiments on two public dynamic QoS datasets demonstrate that BBTTD has higher prediction accuracy compared with several QoS prediction models.},
  archive      = {J_IJPRAI},
  author       = {Qu Wang and Xin Liao and Hao Wu},
  doi          = {10.1142/S0218001425500016},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2550001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Biased block term tensor decomposition for temporal pattern-aware QoS prediction},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bayesian network-based scenario-response model for situation deduction in emergency management of rainstorm scenarios. <em>IJPRAI</em>, <em>39</em>(2), 2530001. (<a href='https://doi.org/10.1142/S0218001425300012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevalence of safety hazards has intensified, underscoring the pressing need for effective responses to sudden disasters and enhanced emergency management. The traditional forecast-response paradigm is no longer adequately addressing the management and decision-making needs for contemporary emergency incidents. Existing emergency management frameworks often struggle with the systemic characteristics of unexpected events. This study proposes a Bayesian network-based scenario-response framework for situation deduction in Emergency Management, taking the torrential rain disaster in Henan Province as a point of reference. In this context, the fundamental units of disaster-forming environment (E), emergency measures (M), and scenario state (S) are employed to construct a coherent and dynamic scenario evolution chain, which effectively depicts the progression of the scenario linkage process. This approach facilitates a deeper understanding of the evolution of emergencies and enhances predictive capacity.},
  archive      = {J_IJPRAI},
  author       = {Liming Zhang and Jiangqinzhe Liu and Ruijie Zhao and Fenghua Zhang and Huiyou Chang},
  doi          = {10.1142/S0218001425300012},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2530001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A bayesian network-based scenario-response model for situation deduction in emergency management of rainstorm scenarios},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated human action recognition with improved graph convolutional network-based pose estimation. <em>IJPRAI</em>, <em>39</em>(2), 2457016. (<a href='https://doi.org/10.1142/S0218001424570167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process of utilizing Artificial Intelligence (AI) to identify and label human behaviors from unprocessed activity data gathered from various sources is known as Human Activity Recognition (HAR). Because of its potential applications across multiple areas, computer vision faces a significant challenge in recognizing human actions and the accompanying interactions with objects and the environment. Investigating the temporal and geographical characteristics of the skeleton sequence is essential for this endeavor, according to recent studies. However, efficiently extracting discriminative temporal and spatial information remains a difficult task. This work proposes a novel Human Action Recognition Model exploiting improved Graph Convolutional Network (GCN)-based pose estimation with a Hybrid Classifier (IGCN-HC). The phases carried out in this model are pre-processing, pose estimation, feature extraction, and activity recognition. Initially, the input video will be pre-processed and a frame from the input video stream will be generated. Subsequently, human pose estimation exploiting improved GCN will be accomplished. Further, human skeletal joints’ coordinates in two- or three-dimensional spaces are determined via human pose estimation. Then, Shape Local Binary Texture (SLBT) and an improved hierarchy of skeleton features have been used to detect the variance in different activities. In the last phase, a hybrid classification model with the combination of Deep Maxout and customized CNN has been proposed for the recognition phase. The model utilizes two inputs pose estimation results (skeleton) and the extracted features for training purposes. Finally, the proposed trained model is evaluated for recognition on different test inputs and contrasted with the existing techniques.},
  archive      = {J_IJPRAI},
  author       = {Amit Baghel and Alok Kumar Singh Kushwaha and Roshan Singh},
  doi          = {10.1142/S0218001424570167},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2457016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Automated human action recognition with improved graph convolutional network-based pose estimation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PDC bit design based on deep learning for gravel layer. <em>IJPRAI</em>, <em>39</em>(2), 2452023. (<a href='https://doi.org/10.1142/S0218001424520232'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are lots of gravel layers gradually increasing from east to west of Kuqa Piedstone in Tarim Basin, especially the thickest gravel layer, high gravel content, large particle size, high compressive strength and poor drillability in Bozi block, which are the key factors that result in low drilling efficiency and complex drilling accidents. Therefore, this paper presents a design scheme based on lithology characteristics deep learning and artificial intelligence analysis of bit failure mode and characteristics of large section gravel layer in fore-salt. The design scheme of a PDC special-shaped tooth bit with strong impact resistance has been formed through the structural design of anti-impact aggressive PDC teeth, rock breaking efficiency study, combined with the optimization design of bit layout. The design scheme not only improves the anti-impact but also improves the anti-eddy performance of the PDC special-shaped tooth bit. It effectively expands both the application range of PDC special tooth bit in the gravel layer and prolongs the bit life. The artificial intelligence optimized PDC special-shaped tooth bit has obtained a great effect in deep gravel stratum, in the meantime, it successfully solved the problems of slow drilling rate and short footage of single bit in Kuqa formation and other formations.},
  archive      = {J_IJPRAI},
  author       = {Yongxing Sun},
  doi          = {10.1142/S0218001424520232},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2452023},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {PDC bit design based on deep learning for gravel layer},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class incremental learning based on playback images generated by classification network. <em>IJPRAI</em>, <em>39</em>(2), 2451021. (<a href='https://doi.org/10.1142/S0218001424510212'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image classification has surpassed human performance in numerous domains. However, in real-world scenarios, challenges such as storage constraints, privacy concerns, and commercial data protection necessitate the enhancement of existing models to accommodate new class classifications — a critical area of research known as class incremental learning. Data replay stands out as a pivotal technique within this domain. The DeepInversion algorithm ingeniously employs classification networks to generate training set images of notable quality. In this study, we improve the DeepInversion algorithm, leveraging a pre-trained model to yield superior quality playback images for class incremental learning. Within the context of class incremental learning, we introduce a cosine orthogonal classification loss function, formulated on the basis of linear layer analysis, to guide image generation and augment class incremental learning. This loss function is designed to ensure the mutual orthogonality of all class centers while minimizing intra-class distances. In the realm of knowledge distillation, we harness a combination of limited real images, a profusion of synthesized images, and Mix virtual images to facilitate feature cosine distance distillation. Sufficient comparative experiments and analyses with similar latest methods underscore the efficacy of our proposed approach, and obtain the SOTA results. The code for the paper can be found at http://github.com/YunXiaooooo/Class-incremental-learning-based-on-playback-images-generated-by-classification-network},
  archive      = {J_IJPRAI},
  author       = {Qiuyu Zhu and Yunxiao Zhang and Yunhang Zhuo and Junli Chen},
  doi          = {10.1142/S0218001424510212},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2451021},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Class incremental learning based on playback images generated by classification network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diagnostic method for demagnetization fault of elevator synchronous traction machine based on informer. <em>IJPRAI</em>, <em>39</em>(2), 2451007. (<a href='https://doi.org/10.1142/S0218001424510078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a fault diagnosis method for synchronous traction machine demagnetization based on the Informer model. The method utilizes the Informer model to analyze and model the sensor data of the synchronous traction machine, adaptively learn the feature representation of time series data, and predict the future states in order to accurately identify and predict demagnetization faults. The specific steps include: (1) collecting sensor data of the synchronous traction machine, including parameters such as current, voltage, and rotational speed; (2) preprocessing the data, including denoising, normalization, and feature extraction; (3) constructing the Informer model and training and optimizing it using the preprocessed sensor data; and (4) using the trained model to predict and determine new sensor data, thereby achieving an accurate diagnosis of demagnetization faults. The advantages of this method are as follows: (1) automatic learning and extraction of important features of time series data without the need for manual feature design, improving diagnostic accuracy; (2) ability to handle long sequence data and strong modeling capability for time dependencies, better predicting future states and fault occurrences; and (3) adaptability to the characteristics and data features of different elevator systems and strong generalization capability.},
  archive      = {J_IJPRAI},
  author       = {Peng Shao and Bo Zheng and Xiaozhou Tang and Chao Chen and Xuefeng Hou},
  doi          = {10.1142/S0218001424510078},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2451007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Diagnostic method for demagnetization fault of elevator synchronous traction machine based on informer},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OTOT: An online training and offline testing system for 6D object pose estimation. <em>IJPRAI</em>, <em>39</em>(2), 2351015. (<a href='https://doi.org/10.1142/S0218001423510151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a novel system to assist 6D object pose estimation network training, which is only deployed in the training progress to optimize the network parameters, and does not work in the testing stage, called Online training and offline testing system (OTOT). OTOT consists of two modules: a feature fusion module and a supervision module. The feature fusion module fuses several feature maps from the pose estimation network in a specified order to obtain a fused feature. Then, the supervision module uses the encoder–decoder structure network to implicitly extract useful features from the fused feature and optimizes the pose estimation network online through the back-propagation mechanism. OTOT can be migrated to any network with encoder–decoder structure. The network trained with OTOT achieves 56.11% accuracy in terms of the VSD metric on the TLESS dataset using RGB inputs, compared to the 46.70% accuracy of the original network trained without OTOT. Experiments show that OTOT greatly improves the accuracy of the pose estimation network, and since OTOT is not deployed in the testing stage, it does not increase any parameters during testing and affect the original speed of the network.},
  archive      = {J_IJPRAI},
  author       = {Yilin Yuan and Qian Jiang and Quan Mu and Wenchao Jia and Boya Fu and Renzhi He and Jian Wen and Fei Liu and Qin Mao and Mingliang Zhou},
  doi          = {10.1142/S0218001423510151},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2351015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {OTOT: An online training and offline testing system for 6D object pose estimation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-target detection method of intelligent driving traffic scene based on faster R-CNN++. <em>IJPRAI</em>, <em>39</em>(1), 2459019. (<a href='https://doi.org/10.1142/S0218001424590195'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current multi-objective detection methods are plagued by several issues, including insufficient detection efficiency, slow speeds, and difficulties in deciphering driving rules. To address these challenges, we introduce a traffic scene classification method that utilizes Improved Faster Regions with Convolutional Neural Network features (Faster R-CNN++). Initially, the shared convolutional layer and the Recurrent Criss-Cross Attention (RCCA) layer are employed to extract features from the input image. Subsequently, the derived feature map is fed into the Region Proposal Network (RPN) to generate detection boxes, and the Region of Interest Align (RoI Align) layer selects features corresponding to each Region of Interest (RoI) on the feature map, guided by the RPN’s output. Ultimately, we adopt an alternating training approach. Simulation experiments confirm the effectiveness of our method in multi-scene object detection. Our method has demonstrated significant improvements over existing algorithms and has delivered outstanding performance on the BDD-100 K, ApolloScape, and NuScenes datasets. The results indicate that our deep learning-based traffic scene classification method can accurately discern the behavioral characteristics of various traffic participants.},
  archive      = {J_IJPRAI},
  author       = {Qiangqiang Xu and Junhua Guo},
  doi          = {10.1142/S0218001424590195},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2459019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-target detection method of intelligent driving traffic scene based on faster R-CNN++},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance improvement in MIMO-OFDM VLC systems through combined adaptive modulation and coding with symbol decomposition. <em>IJPRAI</em>, <em>39</em>(1), 2458007. (<a href='https://doi.org/10.1142/S0218001424580072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the visible light communication (VLC) system, adaptive symbol decomposition technology is one of the methods to reduce peak-to-average power ratio (PAPR) and suppress LED nonlinear distortion. However, at high symbol variances, there still exists a high PAPR, leading to a higher number of decomposed symbols, which in turn reduces the information rate and increases the bit error rate (BER) performance. Therefore, a combined approach of adaptive modulation, adaptive symbol decomposition serial transmission (ASDST), and space–time block code and orthogonal cyclic matrix transform (STBC-OCT) coding is proposed. The characteristics of PAPR, symbol decomposition and BER under different approaches through Monte Carlo simulation were analyzed. The simulation results show that when using 4-Quadrate Amplitude Modulation (4QAM) modulation and CCDF= 2 × 1 0 − 4 , the STBC-OCT-ASDST scheme gains a 5 dB improvement compared to ASDST alone. At a BER of 3 × 1 0 − 2 , STBC-OCT-ASDST achieves a 10 dBm gain in symbol variance compared to ASDST. Moreover, when the symbol variance of STBC-OCT-ASDST is less than 34 dBm, the BER remains below the 7% threshold of forward error correction (FEC) error rate.},
  archive      = {J_IJPRAI},
  author       = {Na Zhang and JianQiang He and Jiao Liu and YuanYuan Wang},
  doi          = {10.1142/S0218001424580072},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2458007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Performance improvement in MIMO-OFDM VLC systems through combined adaptive modulation and coding with symbol decomposition},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revolutionizing brain tumor diagnosis: A comprehensive model integrating VGG19 and LSTM for accurate MRI classification. <em>IJPRAI</em>, <em>39</em>(1), 2457015. (<a href='https://doi.org/10.1142/S0218001424570155'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diagnosing brain tumors is particularly difficult because they can grow in unpredictable ways and look very different on MRI scans. The current methods used to automatically identify these tumors often struggle because of the wide variety of tumor types and the complex structure of the brain. As a result, these methods don’t always classify tumors accurately, which can affect patient treatment and outcomes. The main problems with these methods are that they find it hard to distinguish between different types of tumors accurately and to deal with the various ways tumors can appear on MRI scans. To improve this situation, our study integrates the robust image classification capabilities of VGG19 with the sequential data processing strengths of LSTM. This synergistic approach enhances our model’s ability to accurately classify various types of brain tumors from MRI scans, addressing the inherent challenges associated with tumor heterogeneity in medical imaging. VGG19, a deep convolutional neural network, is employed to extract detailed features from MRI scans, facilitating precise tumor characterization based on visual patterns and LSTM complements VGG19 by capturing temporal dependencies in the sequential data of MRI scans, enabling the model to discern subtle variations in tumor appearances over time. By leveraging the combined power of VGG19 and LSTM architectures, our study achieves significant advancements in the accurate classification of brain tumors from MRI images. This approach not only enhances diagnostic precision but also lays the groundwork for future improvements in neuro-oncological imaging diagnostics. Our study includes 1000 patients evaluated with MRI for brain tumors. We achieved an overall accuracy of 98.32% demonstrating the efficacy of our VGG19-LSTM model in accurate tumor classification. By using both, our model aims to get better at understanding MRI scans and, as a result, be more accurate at identifying brain tumors. This combination is a new step forward in making brain tumor diagnosis more precise through a detailed and cooperative approach using neural networks.},
  archive      = {J_IJPRAI},
  author       = {Chandrasekar Venkatachalam and M. Umamaheswari and Priyanka Shah and Arastu Thakur},
  doi          = {10.1142/S0218001424570155},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2457015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Revolutionizing brain tumor diagnosis: A comprehensive model integrating VGG19 and LSTM for accurate MRI classification},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-frequency based EEG features for classification of human emotions. <em>IJPRAI</em>, <em>39</em>(1), 2457014. (<a href='https://doi.org/10.1142/S0218001424570143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human emotion classification without bias and unfairness is challenging because most existing image-based methods are directly or indirectly affected by subjectivity. Therefore, we propose an EEG (Electroencephalogram) based model for an accurate emotion classification without the effect of subjectivity. The captured EEG signals are converted into Delta, Theta, Alpha, Beta, and Gama frequency bands. As emotions change, the frequency bands change and provide unique patterns for each emotion irrespective of different persons. With this observation, the statical features, namely, mean, standard deviation, variance, and kurtosis, and frequency-based features, namely, Power Spectral Density (PSD) and Petrosian Fractal Dimension (PFD) are extracted. To integrate the strength of spatial and frequency-based features, the features are supplied to quadratic discriminative analysis for the final classification. The experiments on the benchmark datasets, DEAP and SEED-IV, achieve 99.40% and 91.97% accuracy, respectively. A comparison with state-of-the-art methods shows that the method performs very well on some datasets.},
  archive      = {J_IJPRAI},
  author       = {Shivanand S. Gornale and Shivakumara Palaiahnakote and Amruta Unki and Sunil Vadera},
  doi          = {10.1142/S0218001424570143},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2457014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Spatial-frequency based EEG features for classification of human emotions},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization-enabled shepard convolutional quantum neural network for brain tumor detection using MRI image. <em>IJPRAI</em>, <em>39</em>(1), 2457013. (<a href='https://doi.org/10.1142/S0218001424570131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumors develop when abnormal cells grow within or near the brain. Determining the extent of the tumor is crucial for effective treatment. Magnetic Resonance Imaging (MRI) has emerged as a non-ionizing radiation tool for diagnosing brain tumors. Segmenting brain tumors manually is a tedious process so the performance depends on the experience of the operator. To overcome the above-mentioned problem, in this research project, brain tumor detection is classified by the proposed Shepard Convolutional Quantum Neural Network (ShCQNN) using MRI images. Initially, pre-processing of the input image is carried out with a Mean filter and the process of segmentation is executed by LinkNet. Here, the proposed Chicken Swarm Stock Exchange Trading Optimization (CSSETO) is used to train LinkNet. This CSSETO is formed from Stock Exchange Trading Optimization (SETO) and Chicken Swarm Optimization (CSO). Further, image augmentation includes rotation, random erasing, brightness or contrast adjustment, and shearing. Moreover, the extraction of features is done next to image augmentation, where some important features such as Local Ternary Pattern (LTP), Convolutional Neural Network (CNN), and Local Optimal Oriented Pattern (LOOP) are obtained. In the last stage, a brain tumor is detected using ShCQNN which is the amalgamation of Shepard Convolutional Neural Network (ShCNN) along with Quantum Neural Network (QNN). The two benchmark datasets, namely Multimodal Brain Tumor Segmentation Challenge 2018 (BraTS2018) database and the Figshare dataset are used to assess the performance of the proposed model using performance measures, such as specificity, accuracy, and sensitivity. Also, the performance of the proposed method has been compared with existing models, such as VGG Stacked Classifier Network (VGG-SCNet), Whale Harris Hawks Optimization (WHHO), CNN model, and EfficientNet-B0 and the results revealed that the proposed method provided superior performance than other existing methods. The proposed method obtains the accuracy of 0.925, sensitivity of 0.915, and specificity of 0.915. Regarding the accuracy, the performance improvement of the devised ShCQNN technique is 19.14%, 18.60%, 10.81%, and 2.70% higher than the existing methods VGG-SCNet, WHHO, CNN model, and EfficientNet-B0.},
  archive      = {J_IJPRAI},
  author       = {Swaminathan Balasubramanian and Veerraju Gampala and Alok Misra and Telu Venkata Madhusudhana Rao},
  doi          = {10.1142/S0218001424570131},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2457013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Optimization-enabled shepard convolutional quantum neural network for brain tumor detection using MRI image},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight and efficient wheat spike detection for small targets. <em>IJPRAI</em>, <em>39</em>(1), 2455014. (<a href='https://doi.org/10.1142/S0218001424550140'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wheat spike detection is a crucial component of wheat yield prediction. In this study, n lightweight and efficient wheat spike detection model is proposed. The model employs a novel Wheat Spike Net Block (WSNB) within a lightweight network architecture, integrating Depth-Wise Convolution (DW-Conv) and Efficient Window Multi-Head Self-Attention (EW-MHSA) to rapidly process images and accurately identify wheat spikes, even under compact small target conditions. The model is equipped with four detection heads to effectively handle targets of varying scales and incorporates the innovative EMF-IOU loss function for refined bounding box estimation. Tested on a self-constructed Shangluo winter wheat dataset, the model achieves a detection speed of 96.1 FPS on NVIDIA Tesla V100 and mAP@0.5 of 95.3%, surpassing YOLOv5, EfficientV2, YOlOX,transformer, and MobileVIt3 in terms of accuracy and efficiency. The model’s performance across diverse hardware platforms highlights its potential for practical implementation in real-time wheat yield estimation and precision agriculture.},
  archive      = {J_IJPRAI},
  author       = {Bo Wang and Yawen Li and Jun Zhang and Liqiong Huang},
  doi          = {10.1142/S0218001424550140},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2455014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Lightweight and efficient wheat spike detection for small targets},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel infogain and multi-axial wavelet-based transformer for personality trait question answering. <em>IJPRAI</em>, <em>39</em>(1), 2451023. (<a href='https://doi.org/10.1142/S0218001424510236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Question Answering (VQA) is one of the attractive topics in the field of multimedia, affective, and empathic computing to garner user interest. Unlike existing models which aim at addressing challenges of VQA for the scene images, this work aims at developing a new model for Personality Trait Question Answering (PQA). It uses Twitter account information, which includes shared images, profile pictures, banners, text in the images, and descriptions of the images. Motivated by the accomplishments of the transformer, for encoding visual features of the images, a new InfoGain Multi-Axial Wavelet Vision Transformer (IgMaWaViT) is explored here. For encoding textual features in the images and descriptions, a new Information Gain BERT (InfoBert) method is introduced, which can handle the variable length encoding of text by choosing the optimal discriminator. Furthermore, the model fuses encodings of images and text according to the questions on different personality traits for question answering. The model is called InfoGain Multi-Axial Wavelet Vision Transformer for Personality Traits Question Answering (IgMaWaViT-PQA). To validate the efficacy of the proposed model, a dataset has been constructed, and it is used along with standard datasets for experimentation. Comprehensive experiments show that the proposed model is better than the state-of-the-art models. The code is available at the link: https://github.com/biswaskunal29/InfoGain_MultiAxial_PQA .},
  archive      = {J_IJPRAI},
  author       = {Kunal Biswas and Shivakumara Palaiahnakote and Saumik Bhattacharya and Umapada Pal and Ram Sarkar},
  doi          = {10.1142/S0218001424510236},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2451023},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A novel infogain and multi-axial wavelet-based transformer for personality trait question answering},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of specialized deep-learning models for crop freshness assessment to mitigate post-harvest loss. <em>IJPRAI</em>, <em>39</em>(1), 2451022. (<a href='https://doi.org/10.1142/S0218001424510224'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional methods for evaluating crop ripeness are critiqued for their inefficiency and potential harm to produce. The use of image-processing and deep-learning techniques can solve these issues as a trend in non-destructive methods. However, an overfitting problem arises when optimization and generalization are used to estimate the parameters of the next epoch. In this paper, we develop specialized models with a high volume of training images for a single type of crop to achieve the goal of 100% accuracy for both test and validation datasets. This development contributes insights into leveraging deep learning for crop assessment, emphasizing its potential application in diverse agricultural scenarios. Experimental results show that the proposed models are superior to several existing available methods.},
  archive      = {J_IJPRAI},
  author       = {Wellington Cunha and Arashdeep Kaur and Frank Y. Shih},
  doi          = {10.1142/S0218001424510224},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2451022},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Development of specialized deep-learning models for crop freshness assessment to mitigate post-harvest loss},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). XAttentionHAR ensemble: Leveraging cross-modal attention for enhanced activity recognition. <em>IJPRAI</em>, <em>39</em>(1), 2450026. (<a href='https://doi.org/10.1142/S0218001424500265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Activity Recognition (HAR) is pivotal in ubiquitous computing, offering benefits to human-centric services such as health monitoring, smart homes, and eldercare systems. HAR leverages smartphones, smartwatches, and other wearable devices to collect sensory data annotated with activity labels, which are then used to train machine learning or deep learning models for automatic activity recognition. Effective HAR systems must integrate information from multiple modalities to accurately assist users. This paper introduces the XAttentionHAR model, an innovative cross-modality attention-based ensemble model for HAR. Our approach utilizes a self-attention module to extract features within each modality and an inter-domain cross-attention module to capture and integrate long-term dependencies across domains. The cross-modality attention mechanism enhances the fusion of diverse modalities, enriching the semantic information. We conducted extensive experiments on the WISDM public dataset, which includes accelerometer and gyroscope data from smartwatches and smartphones. Our results demonstrate that XAttentionHAR outperforms other state-of-the-art methods in activity recognition, achieving 98.48% accuracy for smartphone-based HAR and 98.73% accuracy for smartwatch-based HAR, paving the way for improved human-centric services.},
  archive      = {J_IJPRAI},
  author       = {Sarita Sahni and Sweta Jain and Sri Khetwat Saritha},
  doi          = {10.1142/S0218001424500265},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2450026},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {XAttentionHAR ensemble: Leveraging cross-modal attention for enhanced activity recognition},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A newly adopted YOLOv9 model for detecting mould regions inside of buildings. <em>IJPRAI</em>, <em>39</em>(1), 2450025. (<a href='https://doi.org/10.1142/S0218001424500253'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Molds on wall and ceiling surfaces in damp indoor environments especially in houses with poor insulation and ventilation are common in the UK. Since it releases toxic chemicals as it grows, it is a serious health hazard for occupants who live in such houses. For example, eye irritation, sneezing, nose bleeds, respiratory infections, and skin irritations. Furthermore, there are chances of developing serious medical conditions like lung infections and respiratory diseases which may even lead to death. The main challenge here is that due to their irregular patterns, camouflaged with the background, it is not so easy to detect with our naked eyes in the early stage and often confused as stains. Therefore, inspired by the accomplishments of the Yolo architecture for object detection, the Yolov9 model is explored for mold detection by considering mold region as an object in this work. The overall result shows a promising 76% average classification rate. Since the mold does not have a shape, specific pattern, or color, adapting the Yolov9 for accurate mold detection is challenging. To the best of our knowledge, this is the first of its kind compared to existing methods. Since it is the first work, we constructed a dataset to perform experiments and evaluate the proposed method. To demonstrate the proposed method’s effectiveness, the results were also compared with the results of the Yolov8 and Yolov10 models.},
  archive      = {J_IJPRAI},
  author       = {Taha Mansouri and Md. Shadab Mashuk and Shivakumara Palaiahnakote and Aaron Chacko and Lawrence Sykes and Ali Alameer},
  doi          = {10.1142/S0218001424500253},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2450025},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A newly adopted YOLOv9 model for detecting mould regions inside of buildings},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight safety activity recognition algorithm for railway field personnel based on portable cards. <em>IJPRAI</em>, <em>39</em>(1), 2450024. (<a href='https://doi.org/10.1142/S0218001424500241'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, railway construction has been plagued by frequent safety accidents, with workers’ safety during the construction process remaining a major concern. To mitigate this issue, intelligent monitoring of railway workers’ activity has been proposed as a means of improving the safety coefficient of construction. Human activity recognition (HAR) based on wearable devices holds significant application value in areas such as health monitoring, motion analysis, and intelligent assistance. Recently, convolutional neural networks (CNNs) have gained extensive adoption and demonstrated outstanding performance in HAR. However, current HAR research still faces some challenges, including problems with establishing spatial–temporal dependencies and addressing the demand for lightweight models. To address the above issues, we propose a lightweight dual-stream convolution model (LDSC) based on deformable convolution and hierarchical segmentation. The model adaptively captures significant variations in sensor readings over time from portable cards of railway personnel through a temporal stream and learns the interactive information among sensor channels over a spatial stream. LDSC consists of three lightweight convolutional modules that combine deep convolution and point convolution to reduce model parameters, thus meeting the demand for a lightweight model. Experiments and ablation studies are conducted on three available datasets (UCI-HAR, UniMiB-SHAR, and WISDM) to evaluate the proposed model. The experimental results indicate that our model outperforms existing state-of-the-art methods in terms of recognition accuracy, validating the effectiveness and feasibility of LDSC. In addition, theoretical analysis and ablation experiments demonstrate that the proposed LDSC embodies lightweight characteristics.},
  archive      = {J_IJPRAI},
  author       = {Hailu Zuo and Jiukai Deng and Zihan Liu and Guangjun Tian and Shuo Xiao},
  doi          = {10.1142/S0218001424500241},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2450024},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Lightweight safety activity recognition algorithm for railway field personnel based on portable cards},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijseke">IJSEKE - 54</h2>
<ul>
<li><details>
<summary>
(2025). APT: A simple adapter for reusing RGB video transformers in compressed video action recognition. <em>IJSEKE</em>, <em>35</em>(9), 1369-1382. (<a href='https://doi.org/10.1142/S021819402550041X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing adoption of compressed video across diverse applications underscores the demand for efficient action recognition methods. Traditional RGB-based methods face limitations, especially because they depend heavily on computationally intensive optical flow for temporal analysis. We propose a novel method for compressed video action recognition that aims to effectively bridge the gap between compressed-domain and RGB-domain. Specifically, we design a plug-and-play multi-modal feature adapter that enables pretrained RGB-based Transformer models to be directly applied to compressed videos. Our method offers a low-cost cross-domain transfer solution by efficiently fusing I-frame and P-frame within compressed videos, facilitating deep feature alignment and modeling in the compressed domain. Extensive experiments on the UCF101 (93.8%) and HMDB51 (70.7%) datasets demonstrate that the proposed method significantly outperforms state-of-the-art approaches for compressed video action recognition.},
  archive      = {J_IJSEKE},
  author       = {Jiyuan Wang and Huilan Luo},
  doi          = {10.1142/S021819402550041X},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {9},
  pages        = {1369-1382},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {APT: A simple adapter for reusing RGB video transformers in compressed video action recognition},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VulEPEDE: A function-level vulnerability detection method via enhanced positional encoding and dependency embedding. <em>IJSEKE</em>, <em>35</em>(9), 1341-1368. (<a href='https://doi.org/10.1142/S0218194025500408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As software complexity increases, integrating vulnerability detection becomes essential to ensure the security and integrity of modern systems. Traditional static and dynamic analysis methods face limitations in efficiency and accuracy, particularly for large-scale vulnerability detection, while existing deep learning methods struggle to fully capture structural information and dependencies in code, leading to incomplete identification of vulnerabilities. In this paper, we propose VulEPEDE, an innovative function-level vulnerability detection method. VulEPEDE leverages Program Dependency Graphs (PDG) to represent function code and constructs a Vulnerability Semantic Dependency Graph (VSDG) using slicing techniques, introducing function parameter nodes as slicing candidates to capture more comprehensive vulnerability trigger chains. It integrates two core modules: the Enhanced Positional Encoding (EPE) module and the Dependency Embedding (DE) module. The EPE module combines node attribute encoding with positional encoding using a Transformer and multi-head attention mechanism to capture complex features and contextual semantics of code, while the DE module learns dependency embeddings between code nodes through convolutional neural networks. We evaluate VulEPEDE on three widely used datasets, comparing its performance against state-of-the-art deep learning-based methods. Experimental results demonstrate that VulEPEDE outperforms the best baseline methods by 1.66%, 17.54%, and 28.96% in F1-score across the three datasets, with considerable computational efficiency.},
  archive      = {J_IJSEKE},
  author       = {Shuailin Yang and Jiadong Ren and Jiazheng Li and Bing Zhang and Ke Xu},
  doi          = {10.1142/S0218194025500408},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {9},
  pages        = {1341-1368},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {VulEPEDE: A function-level vulnerability detection method via enhanced positional encoding and dependency embedding},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DB-DSCN: Image tampering detection using dual branch deep stacked convolutional network. <em>IJSEKE</em>, <em>35</em>(9), 1323-1340. (<a href='https://doi.org/10.1142/S0218194025500366'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the new era of technology with unusual image forging equipment and procedures, digital imaging has become basic. Digital images cannot even be used as evidence anywhere, since it is widely recognized that they may be faked. In order to assist in relieving such derelictions, the problem is examined in an incomprehensible manner. In the digital era, copy-move and splicing of images to produce a fabricated one are commonplace. While the latter entails combining two images to drastically alter the original and produce a new, forged image, copy-move entails copying a portion of the image and pasting it onto another portion of the image. Therefore, to address the limitation of the existing model, a novel hybrid Deep Learning (DL) model is developed. To enhance image details before detecting a tampered image, high pass filtering is employed. The high pass filter might reveal information that has emerged due to the tampered image. To extract the visual semantic features and statistical features, Attention-based Residual Network (AttResNet) and Grey Level Co-occurrence Matrix (GLCM) are utilized. An Attention-based Feature Fusion (AttFF) module is used to fuse the extracted features. A Dual Branch Deep Stacked Convolutional Network (DB-DSCN) is employed to classify the tampered image. The experimental results of the proposed model achieved an accuracy of 98.26%, a precision of 96.28%, a recall of 95.98% and an F 1-score of 96%. The proposed model seems to be a superior model for detecting tampered images compared to existing models. It acquired higher accuracy than other existing models. The performance of the proposed model is evaluated in terms of accuracy, precision, recall and F 1-score, respectively.},
  archive      = {J_IJSEKE},
  author       = {V. M. Ponney and B. L. Velammal and K. Kulothungan},
  doi          = {10.1142/S0218194025500366},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {9},
  pages        = {1323-1340},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {DB-DSCN: Image tampering detection using dual branch deep stacked convolutional network},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-level formal specifications for deep neural networks. <em>IJSEKE</em>, <em>35</em>(9), 1289-1321. (<a href='https://doi.org/10.1142/S0218194025500342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obtaining sufficient high-quality labeled data remains a critical challenge for training deep neural networks (DNNs). Recently, a specification-based method has been proposed to systematically define object characteristics for automated data generation. However, this approach typically relies on abstract descriptions, resulting in a gap between specifications and executable data generation. To address this issue, this paper proposes a two-level formal specification approach. Specifically, we apply the first-level specification to describe object characteristics and the second-level specification to define parameters and values suitable for data generation. This paper focuses on discussing both levels of specifications to facilitate human comprehension and machine handling to reduce the gap mentioned above. The performance of this approach is demonstrated through a case study on traffic sign recognition.},
  archive      = {J_IJSEKE},
  author       = {Yanzhao Xia and Shaoying Liu},
  doi          = {10.1142/S0218194025500342},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {9},
  pages        = {1289-1321},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Two-level formal specifications for deep neural networks},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the combination of classical knowledge engineering tools and LLMs to build automated planning models. <em>IJSEKE</em>, <em>35</em>(9), 1267-1287. (<a href='https://doi.org/10.1142/S0218194025430028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated Planning (AP) is a problem-solving technique applicable to a wide range of scenarios and goals. It typically requires a complete and accurate description of the planning task expressed in a formal language to generate a solution plan that achieves the goals. However, creating these descriptions can be time-consuming and error-prone, often resulting in unsolvable planning tasks. Planning systems often lack the ability to explain why a task is deemed unsolvable. In this work, we present an integrated knowledge engineering system that allows users to graphically depict AP use cases using transition diagrams, which are automatically converted into a formal language. To facilitate the debugging process, we propose connecting the system with large language models (LLMs) to explore their capabilities in assisting with flawed planning tasks, fixing the model and making the tasks solvable.},
  archive      = {J_IJSEKE},
  author       = {Alba Gragera and Ángel García-Olaya and Fernando Fernández},
  doi          = {10.1142/S0218194025430028},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {9},
  pages        = {1267-1287},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {On the combination of classical knowledge engineering tools and LLMs to build automated planning models},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Applying scrum to knowledge transfer among software developers. <em>IJSEKE</em>, <em>35</em>(9), 1239-1265. (<a href='https://doi.org/10.1142/S0218194023430015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the teaching-learning processes, research and continuous innovation are encouraged. Now, when talking about innovation, the concept of adapting methodologies that have been successfully applied to speed up and increase the quality of software projects begins to emerge, is the case of agile software development methodologies. Scrum is one of the most widely used methodologies in the software development process, it increases productivity and deliverable quality of software development teams, but there is not much evidence of how to use it to structure learning content and its use to transfer new knowledge in training or software development contexts. To fill this gap, this research analyzes the applicability of Scrum for transferring new knowledge among software developers is developed. In this paper, we describe the details of how to start transferring knowledge using Scrum, guiding the reader through its standards, processes, phases, and objectives. We also report an experiment for improving students’ performance to support the approach’s benefits in the academy context and a case study performed inside the company context.},
  archive      = {J_IJSEKE},
  author       = {Fernando Ibarra-Torres and Matias Urbieta and Nuria Medina-Medina},
  doi          = {10.1142/S0218194023430015},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {9},
  pages        = {1239-1265},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Applying scrum to knowledge transfer among software developers},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Secure and efficient authentication for smart grid communication using ECC and PUF. <em>IJSEKE</em>, <em>35</em>(8), 1219-1238. (<a href='https://doi.org/10.1142/S0218194025500391'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advanced metering infrastructure AMI is an essential component of the smart grid (SG), providing essential support for two-way communication and real-time data exchange between users and utility providers. However, due to the potential untrustworthiness of the open channel, protecting the confidentiality and integrity of communication data is challenging. Previously, a number of privacy-preserving authentication and key agreement (AKA) schemes have been proposed for securing SGs. However, these solutions either have some security and privacy vulnerabilities or require expensive computational and communication costs that cannot be applied to resource-constrained smart meters. In this work, we propose a novel, lightweight and privacy-preserving AKA scheme for SGs based on the elliptic curve cryptography and physically uncloneable function. The security analysis shows that our construction is secure against several security attacks. In addition, performance comparison with several related works shows the practicality of our design.},
  archive      = {J_IJSEKE},
  author       = {Rixuan Qiu and Zhiyuan Luo and Qun He and Yu Zhou and Shuiping Kang and Chaoping Wei},
  doi          = {10.1142/S0218194025500391},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {8},
  pages        = {1219-1238},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Secure and efficient authentication for smart grid communication using ECC and PUF},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-energy complementary scheduling based on interval many-objective optimization of power grid for sustainable cloud computing center. <em>IJSEKE</em>, <em>35</em>(8), 1201-1217. (<a href='https://doi.org/10.1142/S021819402550038X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of renewable energy sources (RES) into new power system (NPS) represents a crucial approach for reducing carbon emissions (CEs) and mitigating resource consumption in cloud computing centers. However, the inherent uncertainties of RES generation, such as randomness, volatility, and intermittency, pose significant challenges to the scheduling of NPS. A data-driven multi-energy complementary uncertainty scheduling method is proposed to address these issues and ensure a stable power supply from NPS to cloud computing centers. First, we constructed a stochastic differential equation (SDE) to represent the uncertainty characteristics of renewable energy generation, and proposed a SDE deep network based on LSTM (LSTM-SDE Net) to capture and learn the aleatoric uncertainty and epistemic uncertainty of units; subsequently, we established the multi-energy complementary uncertain many-objective scheduling model (MuC-UMaOSM) by utilizing the interval parametric estimation, which aims to optimize grid total cost (TC), RES consumption rate (CR), CEs, grid economic benefits (EB) and load balancing (LB); finally, in order to obtain trade-off solutions with improved convergence, diversity, and uncertainty, we designed a two-population cooperative interval many-objective evolutionary algorithm (T-PIMaOEA) to solve the proposed model. Experimental results demonstrate the excellent performance of our method in the multi-energy complementary scheduling (MECS).},
  archive      = {J_IJSEKE},
  author       = {Jingbo Zhang and Jie Wen and Xingjuan Cai and Wuzhao Li},
  doi          = {10.1142/S021819402550038X},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {8},
  pages        = {1201-1217},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Multi-energy complementary scheduling based on interval many-objective optimization of power grid for sustainable cloud computing center},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Credit card fraud detection algorithm based on a stacked ensemble model. <em>IJSEKE</em>, <em>35</em>(8), 1177-1200. (<a href='https://doi.org/10.1142/S0218194025500378'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread global adoption of credit card payments has significantly increased convenience for consumers. However, this shift has also heightened the demand for robust fraud detection systems across various financial institutions. While numerous fraud detection algorithms have been proposed in both academia and industry, significant challenges remain in the accurate identification of minority class samples and the effective capture of time series information during feature extraction. To address these challenges, this paper proposes a long short-term memory-logistic regression stacked ensemble model (LLSE) that integrates long short-term memory (LSTM) and logistic regression (LR). The first layer of the model extracts time series features by combining three independently trained LSTM base learners whose outputs are concatenated and passed to the second layer, an LR meta-learner, to generate the final predictions. This dual-layer decision-making mechanism effectively captures spatiotemporal correlation features in fraudulent transactions, thereby enhancing the overall performance of the model. The model’s performance is evaluated via two publicly available credit card datasets. This study innovatively combines the TS-N2VA feature extraction model with the LLSE classifier to comprehensively enhance credit card fraud detection performance through both hidden feature extraction and classifier improvement. Experiments on two public credit card datasets demonstrate that the LLSE classifier achieves significantly better performance in identifying minority class samples while maintaining overall recognition accuracy, outperforming other fraud detection models in the experiments.},
  archive      = {J_IJSEKE},
  author       = {Tinggui Chen and Xiaqin Yang and Limin Ni},
  doi          = {10.1142/S0218194025500378},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {8},
  pages        = {1177-1200},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Credit card fraud detection algorithm based on a stacked ensemble model},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robot control knowledge recommendation model PKGAT based on multimodal knowledge graph. <em>IJSEKE</em>, <em>35</em>(8), 1149-1175. (<a href='https://doi.org/10.1142/S0218194025500354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of robotic control, the interdisciplinary and complex nature of knowledge leads to issues such as knowledge fragmentation and a steep learning curve, posing significant challenges to mastering domain expertise. Recommendation systems, as typical information-filtering tools, are often employed to facilitate knowledge retrieval. Nevertheless, they inherently suffer from cold-start and data sparsity problems, which compromise recommendation accuracy. To overcome these limitations, this study first combines the recommendation system with the knowledge graph and improves upon the traditional BERT-BiLSTM-CRF entity recognition model by incorporating an attention mechanism to enhance entity extraction performance. Verified on the public dataset, the accuracy rate, recall rate and F1 value of the improved model were 91.6%, 94.5% and 93.1%, respectively, which increased by 1.4%, 2.9% and 2.3%, respectively, compared with the BERT-BiLSTM-CRF model. Subsequently, by using the YOLOv5 object detection network to extract image features from the self-built robot image dataset, a multimodal robot control knowledge graph was constructed. Finally, to address the limitations of conventional KGAT, a Personalized Knowledge Graph Attention Network (PKGAT) model is proposed by integrating the recommendation system with the constructed knowledge graph and incorporating a cold-start mitigation module. This results in a knowledge graph-based recommendation system tailored for robotic control domain knowledge. The results from the experiments show that the AUC value and F1 value of the PKGAT model in the MovieLens dataset are 94.56% and 94.20% respectively, which have increased by 2.35% and 2.07%, respectively, compared with the KGAT model. The AUC value and F1 value in the Book-Crossing dataset were 75.30% and 73.60%, respectively, which increased by 2.02% and 1.48%, respectively, compared with the KGAT model.},
  archive      = {J_IJSEKE},
  author       = {Xingda Hu and Zhongchen Yuan and Zongmin Ma},
  doi          = {10.1142/S0218194025500354},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {8},
  pages        = {1149-1175},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {A robot control knowledge recommendation model PKGAT based on multimodal knowledge graph},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RAPRSUM: Retrieval-augmented code summarization with advanced prototype refinement. <em>IJSEKE</em>, <em>35</em>(8), 1121-1147. (<a href='https://doi.org/10.1142/S0218194025500317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code summarization aims to automatically generate natural language descriptions for code snippets, thereby enhancing programmers’ comprehension of the code and significantly improving code maintainability and development efficiency. Code reuse is a prevalent practice in software development, and information retrieval approaches, which leverage similar summaries from a corpus, have shown promising results. However, these approaches often heavily rely on the quality of the corpus, and discrepancies between retrieved and target summaries may result in inaccuracies or incomplete descriptions. In this paper, we propose RAPRSUM, a retrieval-augmented code summarization framework that integrates information retrieval and deep learning techniques. Specifically, RAPRSUM refines retrieved summary prototypes using a deep learning model to preserve essential information while eliminating redundancy. A pretrained large language model is then employed to generate the final summary by jointly considering the input code and the refined prototype. We evaluated RAPRSUM on three public datasets, demonstrating its significant improvement over existing baseline methods. Additional ablation studies confirm the effectiveness of the proposed modules. Finally, through case analysis and robustness verification, we highlight RAPRSUM’s superior performance in generating high-quality code summaries.},
  archive      = {J_IJSEKE},
  author       = {Yangbo Lin and Xingqi Wang and Shanggui Zhan and Dan Wei and Bin Chen},
  doi          = {10.1142/S0218194025500317},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {8},
  pages        = {1121-1147},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {RAPRSUM: Retrieval-augmented code summarization with advanced prototype refinement},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modernizing 90s era software to a new language and environment using LLMs — An empirical investigation. <em>IJSEKE</em>, <em>35</em>(8), 1099-1119. (<a href='https://doi.org/10.1142/S021819402550024X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Legacy software, particularly from the 1990s, often becomes obsolete due to aging hardware and outdated software environments. Traditionally, software modernization required extensive manual effort, involving reverse engineering, code rewriting, and re-architecting. However, advancements in large language models (LLMs) have introduced new possibilities for automating software translation and modernization. This paper explores the feasibility of using LLMs for modernizing 90s-era Windows applications, specifically migrating legacy C and C + + code to Python. Our methodology includes decompilation, source code analysis, automated translation using ChatGPT, and user interface reconstruction. We empirically evaluate three software projects by analyzing LLM-based translation accuracy across different code structures, including algorithmic logic, file handling, and graphical interfaces. Results indicate that while LLMs achieve high translation accuracy ( − 8 8 % ) for structured code, challenges persist in handling decompiled code and user interface generation. The study provides insights into the effectiveness and limitations of LLMs in real-world software renovation, offering guidelines for leveraging machine learning in legacy system modernization. These findings contribute to both academic research and practical applications, suggesting a pathway for cost-effective and scalable legacy software migration.},
  archive      = {J_IJSEKE},
  author       = {Dragan Bojić and Dražen Drašković},
  doi          = {10.1142/S021819402550024X},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {8},
  pages        = {1099-1119},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Modernizing 90s era software to a new language and environment using LLMs — An empirical investigation},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generation of tutorial systems on PCs for smartphone apps. <em>IJSEKE</em>, <em>35</em>(7), 1071-1098. (<a href='https://doi.org/10.1142/S0218194025500330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The total number and diversity of smartphone users are increasing. Additionally, their usage varies such as communication, document processing and online shopping. Applications realize different usages to meet users’ requirements. However, some users are unfamiliar with smartphones. They have difficulty learning the operations and need support. A tutorial system, which provides operations along with users’ status, is effective to resolve these issues. However, showing both the target application’s screen and the tutorial on a smartphone display is challenging. Herein we propose a method to generate a system that shows tutorials on a Personal Computer (PC). The target application on a smartphone and the tutorial system on a PC are connected. The user’s status is sent to the tutorial system to realize a customized tutorial. To generate the tutorial system, a log obtaining function is added to the target application without modifying the source program. The log data of user’s operations are recorded. Operation flows in the target application are constructed and frequent operations are weighted. Then tutorials are generated and shown based on the weighting. Our method allows a user to view appropriate tutorials for the current status of the operation on a large display of a PC.},
  archive      = {J_IJSEKE},
  author       = {Sixin Hua and Junko Shirogane and Yoshiaki Fukazawa},
  doi          = {10.1142/S0218194025500330},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {7},
  pages        = {1071-1098},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Generation of tutorial systems on PCs for smartphone apps},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An empirical study of MBFL on novice programs across different programming languages. <em>IJSEKE</em>, <em>35</em>(7), 1037-1070. (<a href='https://doi.org/10.1142/S0218194025500329'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Programming education in computer science is growing rapidly, and debugging is a key challenge for novice programmers due to their limited experience. Mutation-Based Fault Localization (MBFL) is widely used in industry, but its effectiveness and challenges in novice programs need further study. While Python is a popular language in machine learning and data science, there is little research comparing fault localization in Python and Java for novice programmers. To bridge this gap, we conduct an empirical study to evaluate MBFL’s accuracy and execution overhead in common novice programming errors across different languages. We analyze how program features like code coverage and mutation score affect MBFL’s performance and whether these effects differ between languages. We also examine how MBFL’s effectiveness changes when suspiciousness scores are the same and how mutant noise and coincidental correct test cases vary across languages. Additionally, we propose a mutation confidence formula based on repair potential and behavioral difference to assess the usefulness of mutants in MBFL. Our study demonstrates that MBFL works well for novice fault localization in both Java and Python, with Python performing better. MBFL correctly identifies 45, 70, and 92 faults within the TOP-N (N = 1, 3, 5), proving its strong performance. However, tie problems, mutant noise, and coincidental correct test cases weaken MBFL, especially in Java. Results in both languages show a strong positive correlation between mutant confidence and fault localization accuracy, confirming the formula’s effectiveness across languages.},
  archive      = {J_IJSEKE},
  author       = {Yating Yang and Ao Mei and Chao Yang},
  doi          = {10.1142/S0218194025500329},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {7},
  pages        = {1037-1070},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {An empirical study of MBFL on novice programs across different programming languages},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MalRGBDet: Windows malware detection method based on RGB image representation and heterogeneous neural network. <em>IJSEKE</em>, <em>35</em>(7), 1009-1036. (<a href='https://doi.org/10.1142/S0218194025500305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the world’s most widely used operating system, Windows has long been a primary target for malware attacks, causing severe economic losses and threats to data security for users and enterprises. Existing detection methods often struggle with low accuracy when dealing with complex malware, suffering from high false-negative and false-positive rates. Additionally, malware detection in Windows faces challenges such as limited datasets, a lack of benign sample contrast and insufficient original feature information. To address these issues, we propose a malware detection method based on RGB image representation and heterogeneous neural network (MalRGBDet). First, we collected malware samples from the GitHub and VirusShare platforms, along with benign software from Windows systems, to build a dataset named MalDet. This data set contains unprocessed malicious and benign samples, providing original feature information and addressing the lack of benign samples in existing data sets. Next, we extracted three key features from the malware samples: code sections, data sections and API call sequences. These features closely relate to the behavior of malware and accurately describe its operations. We then transformed these features into uniformly sized RGB images, which helped reveal hidden patterns. Finally, we employ a heterogeneous neural network that integrates ResNet and AlexNet for classification. ResNet, with its deep architecture and residual learning mechanism, significantly enhances the model’s representation capability and classification performance, thereby improving detection accuracy. Meanwhile, AlexNet’s Dropout regularization strategy effectively boosts the model’s generalization ability. In our data set of 1952 Windows software samples, MalRGBDet achieved more than 95% in accuracy, precision, recall and F1-score, improving these metrics by up to 4% compared to the latest methods. Furthermore, false-negative and false-positive rates were kept below 5%.},
  archive      = {J_IJSEKE},
  author       = {Rong Ren and Hongchang Zhang and Bing Zhang and Haitao He and Guoyan Huang and Qian Wang},
  doi          = {10.1142/S0218194025500305},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {7},
  pages        = {1009-1036},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {MalRGBDet: Windows malware detection method based on RGB image representation and heterogeneous neural network},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced fault detection using coupling and cohesion metrics with deep CNN modeling. <em>IJSEKE</em>, <em>35</em>(7), 987-1007. (<a href='https://doi.org/10.1142/S0218194025500299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting faults in software modules is important for reducing system failures and improving software quality. Traditional fault prediction methods often rely on failure history or statistical models, which may not work well when structural complexities exist within the code. This work introduces a new model called Enhanced Coupling and Cohesion Metrics-based Fault Detection (ECCMFD). It uses deep structural properties of code, such as Conceptual Lack of Cohesion in Methods (C-LCOM) and Conceptual Coupling Between Object Classes (CCBO), to capture how components interact and how focused each class remains on its purpose. These metrics are passed into a Deep Convolutional Neural Network (Deep CNN) that learns patterns in software design and predicts fault-prone modules. The model is evaluated on standard NASA MDP datasets including KC1, CM1 and PC3. It outperforms widely used models like Baseline CNN, Random Forest (RF) and XGBoost in all key evaluation metrics. ECCMFD achieved a 5% improvement in precision, a reduction in Root Mean Square Error (RMSE) by 0.3, and better performance in F1 score and accuracy. This improvement is due to the combination of well-defined structural metrics and the deeper feature learning capability of the deep CNN architecture.},
  archive      = {J_IJSEKE},
  author       = {Ravi Kumar Tirandasu and Prasanth Yalla and Sridevi Tumula and Premkumar Chithaluru and Manoj Kumar and Anuradha Dhull},
  doi          = {10.1142/S0218194025500299},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {7},
  pages        = {987-1007},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Enhanced fault detection using coupling and cohesion metrics with deep CNN modeling},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing python code smell detection with heterogeneous ensembles. <em>IJSEKE</em>, <em>35</em>(7), 963-986. (<a href='https://doi.org/10.1142/S0218194025500287'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code smells indicate potential issues in Software design that can impact maintainability, testing and overall quality. Detecting them early is crucial for improving system reliability. While machine learning has been used for code smell detection, most studies focused on Java, with limited research on other languages. In this study, we empirically investigated the effectiveness of both deep learning and heterogeneous ensemble models in detecting multiple Python code smells, including Large Class, Long Method, Long Scope Chaining, Long Parameter List and Long Base Class List. We evaluated three heterogeneous ensemble models: Stacking, Hard Voting and Soft Voting ensembles, alongside three deep learning models: Convolutional Neural Networks, Long Short-Term Memory and Gated Recurrent Units. Each ensemble was built using eight base models, and the Wilcoxon test was used to assess performance differences. Results indicated that Stacking consistently outperformed other models with superior stability and detection performance. Convolutional Neural Networks performed well in some smells but struggled with complex nested structures, where ensemble models offered more stability. Hard and Soft Voting ensembles were competitive but less stable than Stacking. These findings highlight the potential of ensemble and deep learning models in enhancing Python code smell detection.},
  archive      = {J_IJSEKE},
  author       = {Rana Sandouka and Hamoud Aljamaan},
  doi          = {10.1142/S0218194025500287},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {7},
  pages        = {963-986},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Enhancing python code smell detection with heterogeneous ensembles},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advances and challenges in multimodal entity linking: A comprehensive survey. <em>IJSEKE</em>, <em>35</em>(7), 943-961. (<a href='https://doi.org/10.1142/S0218194025300039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study offers a comprehensive examination of the recent advances and challenges in multimodal entity linking (MEL). The paper begins by outlining the background of the growth of multimodal data and the significance of knowledge bases. It provides a detailed description of the definition and architecture of the MEL task. Through an extensive analysis of existing methods, datasets, and evaluation metrics, this paper highlights the potential of MEL to enhance information retrieval accuracy and facilitate knowledge graph construction. The study indicates that, despite significant progress in the MEL field, challenges remain, including issues related to data quality, model generalization, model interpretability and multimodal fusion technologies. Finally, the paper proposes future research directions, such as the application of large language model and the development of scientific theories related to multimodal information fusion and disambiguation, thereby offering clear guidance for subsequent research.},
  archive      = {J_IJSEKE},
  author       = {Huayu Li and Xiaotong He and Yang Yue and Cuicui Wang},
  doi          = {10.1142/S0218194025300039},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {7},
  pages        = {943-961},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Advances and challenges in multimodal entity linking: A comprehensive survey},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative API recommendation based on global semantics and local context. <em>IJSEKE</em>, <em>35</em>(6), 917-941. (<a href='https://doi.org/10.1142/S0218194025500275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During software development, developers often need appropriate but unfamiliar APIs to implement a specific functionality. Under such circumstances, developers tend to leverage search tools to seek for the relevant APIs. However, there are always semantic gaps between query words and APIs, which negatively affects the performance of these tools. In this study, we introduce Glo-APIRec, a method that combines global semantics with local context to estimate the semantic relevance between query words and APIs to recommend APIs. In this method, the Transformer model is employed to obtain global semantics, while the Word2Vec model is utilized to capture local context using a fixed-size window. First, Glo-APIRec collects millions of Java projects from GitHub to construct the corpus. Afterward, a set of tuples consisting of words and APIs is built by extracting comments and API sequences from the source code files. Finally, Transformer is employed to capture long distance semantics about API sequences and code comments. Meanwhile, Word2Vec is used to generate word vectors to capture the local context by introducing the random shuffling strategy to break the positions of words and APIs in the tuples. We evaluate the performance of Glo-APIRec with 30 sentence-level queries. Experimental results show that Glo-APIRec can achieve 0.600 in terms of SuccessRate for top-1 recommendation and 0.900 for top-10 recommendation. When recommending 10 APIs, Glo-APIRec can achieve 0.480, 0.703 and 0.717 in terms of precision, Mean Reciprocal Rank ( M R R M R R MRR ) and Normalized Discounted Cumulative Gain ( N D C G N D C G NDCG ), and outperforms the state-of-the-art method by 26.2%, 31.7% and 27.9%, respectively.},
  archive      = {J_IJSEKE},
  author       = {Shuoming Li and Dongjin Yu and Xin Chen and Xulin Fan and Dengfa Luo and Tong Wu and Wangliang Yan},
  doi          = {10.1142/S0218194025500275},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {6},
  pages        = {917-941},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Generative API recommendation based on global semantics and local context},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SCATCom: Code comment generation by fusing multi-information. <em>IJSEKE</em>, <em>35</em>(6), 887-916. (<a href='https://doi.org/10.1142/S0218194025500263'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several code comment generation approaches based on sequence-to-sequence (Seq2Seq) models have been proposed. Such approaches often extract structure information from abstract syntax trees (ASTs) using a certain serialization method. However, some structural information is inevitably lost while serializing ASTs. Furthermore, existing serialization methods only consider the “type” attribute of the nodes, neglecting the “value” attribute of the nodes. To further improve the performance of code comment generation, we propose a code comment generation approach, called SCATCom, which integrates a more comprehensive set of information from source code and ASTs, encompassing semantic, sequential, syntactic, and hierarchical structure information for code comment generation. Meanwhile, an AST traversal method, called V-POT, is presented, which considers both the “type” and the “value” attributes of the nodes. Experiments were designed and conducted on two commonly used datasets to validate the performance of our approach and the impact of five different serialization ways of ASTs on two code comment generation methods. The BLEU, METEOR, and ROUGE scores for our approach reach 52.6, 34.16, and 63.26 with an improvement of 4 . 1 7 ∼ 1 7 . 3 9 , 5 . 1 ∼ 2 1 . 5 5 , and 6 . 3 6 ∼ 2 2 . 1 6 compared to the baselines. It is evident that V-POT, which retains both the “type” and the “value” attributes, is superior to other methods that use only the “type” attribute.},
  archive      = {J_IJSEKE},
  author       = {Rongcun Wang and Jie Zhou and Xiang Chen and Zhanqi Cui and Shujuan Jiang},
  doi          = {10.1142/S0218194025500263},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {6},
  pages        = {887-916},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {SCATCom: Code comment generation by fusing multi-information},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying android malware using fine-grained path information from HIN. <em>IJSEKE</em>, <em>35</em>(6), 861-886. (<a href='https://doi.org/10.1142/S0218194025500251'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the rapid advances of mobile internet and Internet of Things (IoT), Android has become one of the most widely used operating systems in mobile terminals and IoT devices. However, the massive growth of Android malware poses challenging security problems to these terminals and devices. In this paper, we propose a novel heterogeneous information network (HIN)-based method, called FDroid, for fast and accurate detection of Android malware. Specifically, we first design a fine-grained HIN to model the relationship between APKs and APIs and then extract finer-grained path information, including code blocks, packages and call patterns compared to traditional HIN-based methods, which can effectively improve the detection accuracy without increasing the number of paths. Second, we devise a TF-IWF-based contribution calculation algorithm to select a small number of sensitive APIs calls with high representativeness, which can effectively save the detection time and storage space. Third, we develop an expanded matrix-assisted support vector machine (SVM) classifier for Android malware detection. Experimental results show that the FDroid can achieve 97.43% detection accuracy. Meanwhile, compared with the other related HIN-based malware detection methods, the training time of FDroid is less than 0.1% of them, and the detection time is less than 10% of them.},
  archive      = {J_IJSEKE},
  author       = {Erfan Zhao and Weina Niu and Cheng Huang and Xixuan Ren and Jiacheng Gong and Anran Hou},
  doi          = {10.1142/S0218194025500251},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {6},
  pages        = {861-886},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Identifying android malware using fine-grained path information from HIN},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RESEARCH NOTES: Multiclass classification for self-admitted technical debt via large pre-trained language model. <em>IJSEKE</em>, <em>35</em>(6), 835-860. (<a href='https://doi.org/10.1142/S0218194025500238'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technical debt refers to suboptimal solutions adopted for short-term goals. Self-admitted technical debt (SATD) is the debt that is explicitly marked through comments or documentation, making it traceable. Multi-classification of SATD helps developers understand different debt types and improve efficiency. This paper proposes a SATD multi-classification method based on Fine-Tuning the GPT-3.5-turbo model for SATD prediction. This study uses a public dataset containing 10 projects with code comments. We classify design debt, requirement debt, and defect debt and evaluate our method’s performance. The experimental results show that compared to the best baseline model, our method achieves average improvements of 11.41%, 1.72% and 3.72% in MacroF, MacroP and MacroR metrics, respectively, in the MTO scenario. In the OTO scenario, improvements are 2.33%, 3.70% and 2.18%, respectively. These results indicate that our method has a strong generalization ability in SATD multi-classification and offers a new approach to managing technical debt.},
  archive      = {J_IJSEKE},
  author       = {Yiyang Du and Xingguang Yang and Zhenyu Shu and Zijie Huang and Gang Wang and Libo Xu},
  doi          = {10.1142/S0218194025500238},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {6},
  pages        = {835-860},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {RESEARCH NOTES: Multiclass classification for self-admitted technical debt via large pre-trained language model},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RR-GCN: Exploring untrained random embeddings for relational graphs. <em>IJSEKE</em>, <em>35</em>(6), 809-834. (<a href='https://doi.org/10.1142/S0218194025500184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inception of the Relational Graph Convolutional Network (R-GCN) marked a milestone in the Semantic Web domain as a widely cited method that generalizes end-to-end hierarchical representation learning to Knowledge Graphs (KGs). R-GCNs generate representations for nodes of interest by repeatedly aggregating parametrized, relation-specific transformations of their neighbors. However, in this work, it is posited that the R-GCN’s main contribution lies in this “message passing” paradigm , rather than the learned weights. To prove this, the “Random Relational Graph Convolutional Network” (RR-GCN) is introduced, which leaves all parameters untrained and thus constructs node embeddings by aggregating randomly transformed random representations from neighbors. Additionally, the advantage offered by learnable parameters for RR-GCN without completely losing the advantages of random transformations is explored. It is empirically shown that RR-GCNs can compete with fully trained R-GCNs in node classification.},
  archive      = {J_IJSEKE},
  author       = {Sandeep Ramachandra and Vic Degraeve and Gilles Vandewiele and Bram Steenwinckel and Sofie Van Hoecke and Femke Ongenae},
  doi          = {10.1142/S0218194025500184},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {6},
  pages        = {809-834},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {RR-GCN: Exploring untrained random embeddings for relational graphs},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancements in call graph methodologies for enhanced program comprehension. <em>IJSEKE</em>, <em>35</em>(6), 793-808. (<a href='https://doi.org/10.1142/S0218194025300015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the evolving landscape of software development, where maintaining and understanding complex systems is increasingly challenging, call graph techniques play a critical role in enhancing software comprehension by providing a visual and structural representation of function calls within a system. This paper explores the role of call graphs in simplifying software maintenance and debugging. It highlights how call graphs significantly improve developers’ understanding of system architectures and function interactions, reducing the time spent on manual code exploration. Furthermore, the paper explores recent advancements in call graph techniques, particularly the integration of machine learning and deep learning models with traditional call graph approaches. This hybrid methodology demonstrates enhanced accuracy and relevance in tasks such as program comprehension and code refactoring, making it a valuable tool for modern software engineering practices.},
  archive      = {J_IJSEKE},
  author       = {Rakan Alanazi},
  doi          = {10.1142/S0218194025300015},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {6},
  pages        = {793-808},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Advancements in call graph methodologies for enhanced program comprehension},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class imbalance-oriented online feature selection method for just-in-time software defect prediction. <em>IJSEKE</em>, <em>35</em>(5), 767-791. (<a href='https://doi.org/10.1142/S0218194025500226'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Just-in-time software defect prediction (JIT-SDP) is a defect prediction technique that targets changes in software code, offering significant advantages in quickly identifying potential defects and improving development efficiency. However, most existing methods assume that the importance of features remains stable over time, overlooking the dynamic changes in feature distributions and the evolution of class imbalance in real-world development environments. This limitation eventually degrades the predictive performance. To address this issue, this paper proposes an Imbalance-oriented Online Feature Selection (IOFS) method, which dynamically adjusts the feature importance and uncertainty parameters to adapt in real time to concept drift and class imbalance in data streams, thereby enhancing model performance and generalization. The experimental validation on 14 open-source project datasets demonstrates that IOFS significantly improves the values of G − G − G− Mean on 11 datasets and effectively reduces the average of the absolute differences between recalls for each time step, exhibiting robustness to dynamic feature changes and sensitivity to development-phase feature differences. This study provides an effective solution for online JIT-SDP.},
  archive      = {J_IJSEKE},
  author       = {Qiao Yu and Siyu Ren and Yi Zhu and Jiaxuan Jiang and Shutao Zhang},
  doi          = {10.1142/S0218194025500226},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {5},
  pages        = {767-791},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Class imbalance-oriented online feature selection method for just-in-time software defect prediction},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CodeQG: Automated multiple question generation for source code comprehension. <em>IJSEKE</em>, <em>35</em>(5), 737-765. (<a href='https://doi.org/10.1142/S0218194025500214'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During software maintenance and evolution, developers spend more than half of their time on code comprehension activities. In order to understand an unfamiliar code base, they would naturally ask different types of questions related to code snippets and try to find the answers. In this paper, we conduct an initial work to explore the possibility of automatic question generation for program comprehension. We construct a large-scale data set containing pairs of source code and questions that are automatically transformed from inline comments based on dependency analysis and semantic role labeling. We also build a comprehensive taxonomy of question types so as to generate questions concerning different aspects of code snippets, such as purpose, implementation details and so on. Then, we propose a deep learning-based prototype CodeQG to automatically generates multiple types of questions for code snippets. We evaluate CodeQG by using both typical performance metrics and manual evaluation. The results show that (1) we can achieve a value of 42.02 on BLEU4 and 60.81 on ROUGE-L for the generated questions; (2) overall, the questions are very correct in grammatical, semantic and format; (3) the questions are related to the corresponding code snippet and are helpful for developers in source code comprehension activities. Our work gives insights into automatically generating multiple types of questions for code comprehension. We expect this exploration will improve the applicability and generality of machine code comprehension.},
  archive      = {J_IJSEKE},
  author       = {Xiaowei Zhang and Lin Chen and Kaiyuan Qi and Weiqin Zou and Liye Pang and Lianfa Zhang and Peng Zhang and Guanqun Xu and Dong Zhang},
  doi          = {10.1142/S0218194025500214},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {5},
  pages        = {737-765},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {CodeQG: Automated multiple question generation for source code comprehension},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MTCEA: Guiding multi-modal entity alignment via entity-type information. <em>IJSEKE</em>, <em>35</em>(5), 707-735. (<a href='https://doi.org/10.1142/S0218194025500202'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal entity alignment aims to identify equivalent entities across diverse knowledge graphs by leveraging multiple modalities of entity information. This process is crucial for the fusion of multi-modal knowledge graphs. While current research primarily investigates how to utilize side information from entity visuals, relations, and attributes, it often overlooks the significant role of entity-type information. Furthermore, multi-modal data embedding encounters noise that negatively impacts the performance of the entity alignment task. To address these gaps, this paper introduces MTCEA, a multi-modal entity alignment method guided by entity-type information. The proposed method captures the constraints associated with entities based on the entity-type information obtained from knowledge graph ontology; then, it utilizes two embedding strategies for type constraints to enhance the model’s performance in knowledge representation. This allows effective modal fusion that integrates more fine-grained semantic constraints related to types, which improves the alignment accuracy across various cross-lingual knowledge graphs. MTCEA is validated on three subsets of DBP15K. Experimental results demonstrate that our model achieves good results overall on the Hits@1, Hits@10, and MRR metrics. In an experimental setting without using entity name, MTCEA outperforms state-of-the-art baselines.},
  archive      = {J_IJSEKE},
  author       = {Xiaoming Zhang and Ziyi Zheng and Huiyong Wang and Mehdi Naseriparsa},
  doi          = {10.1142/S0218194025500202},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {5},
  pages        = {707-735},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {MTCEA: Guiding multi-modal entity alignment via entity-type information},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VulnTrace: Tracking and detecting code vulnerabilities with historical commits and semantic embeddings. <em>IJSEKE</em>, <em>35</em>(5), 679-706. (<a href='https://doi.org/10.1142/S0218194025500196'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open source software has evolved into a fundamental element of the contemporary information sector; however, security threats within its supply chain are persistently rising. Within the collaborative development framework of open source, the introduction of malicious code can lead to significant security vulnerabilities. Conventional methods for detecting these vulnerabilities, which rely on machine learning, face challenges such as a lack of sufficient datasets, inadequate deep semantic understanding, and limitations to single-vulnerability detection. To address these challenges, we introduce a novel approach named VulnTrace, which analyzes historical records of submissions in open source projects to construct a high-quality dataset of vulnerabilities with accurate labels. VulnTrace employs Word2Vec alongside Abstract Syntax Tree (AST) technologies to capture both the semantic and structural details of code segments and utilizes a Transformer model for precise vulnerability identification, thereby enhancing accuracy and interpretability in detection. Experimental results indicate that VulnTrace achieves approximately 93% accuracy, 95% precision, 83% recall and an F1 score of 88% in vulnerability detection tasks, significantly reducing false positives and demonstrating remarkable robustness.},
  archive      = {J_IJSEKE},
  author       = {Qijie Song and Jiaobo Jin and Tiantian Zhu and Tieming Chen and Mingqi Lv and Licheng Pan and Jian-Ping Mei and Xiang Pan},
  doi          = {10.1142/S0218194025500196},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {5},
  pages        = {679-706},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {VulnTrace: Tracking and detecting code vulnerabilities with historical commits and semantic embeddings},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Augmenting the interpretability of GraphCodeBERT for code similarity tasks. <em>IJSEKE</em>, <em>35</em>(5), 657-678. (<a href='https://doi.org/10.1142/S0218194025500160'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing the degree of similarity of code fragments is crucial for ensuring software quality, but it remains challenging due to the need to capture the deeper semantic aspects of code. Traditional syntactic methods often fail to identify these connections. Recent advancements have addressed this challenge, though they frequently sacrifice interpretability. To improve this, we present an approach aiming to augment the transparency of the similarity assessment by using GraphCodeBERT, which enables the identification of semantic relationships between code fragments. This approach identifies similar code fragments and clarifies the reasons behind that identification, helping developers better understand and trust the results. The source code for our implementation is available at https://www.github.com/jorge-martinez-gil/graphcodebert-interpretability .},
  archive      = {J_IJSEKE},
  author       = {Jorge Martinez-Gil},
  doi          = {10.1142/S0218194025500160},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {5},
  pages        = {657-678},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Augmenting the interpretability of GraphCodeBERT for code similarity tasks},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic literature review of software vulnerability mining approaches based on symbolic execution. <em>IJSEKE</em>, <em>35</em>(5), 609-656. (<a href='https://doi.org/10.1142/S0218194025300027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of the software industry, the escalating issue of software vulnerabilities has posed significant risks to users. Symbolic execution as a vulnerability mining technology offers a high-test coverage. The existing reviews of symbolic execution methods focus on summarizing various techniques and tools. While some studies have analyzed the technical challenges, classification frameworks and development trends of these methods, they lack a comprehensive and systematic review. This study aims to address the gap in existing reviews by providing a comprehensive, systematic analysis of symbolic execution techniques for vulnerability mining. We conducted a detailed review of 60 peer-reviewed papers published between 2005 and 2024, focusing on symbolic execution techniques for vulnerability mining. First, we reviewed the main techniques used in the symbolic execution process, including program instrumentation, path selection strategy and constraint-solving techniques. Second, we extracted the main information from the selected papers, and the detailed information on the symbolic execution tools is in the form of a table. Compared and analyzed the research object, the execution process at the same time, the software architecture and the application on different system platforms. Finally, we present a comprehensive and systematic summary of current challenges and corresponding solutions in the field. This study provides an in-depth analysis of vulnerability detection technologies based on symbolic execution, serving as a valuable guide for researchers in this domain.},
  archive      = {J_IJSEKE},
  author       = {Lining Li and Rong Ren and Jun Dong and Bing Zhang and Xu Kang},
  doi          = {10.1142/S0218194025300027},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {5},
  pages        = {609-656},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {A systematic literature review of software vulnerability mining approaches based on symbolic execution},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PEAPOD: A heterogeneous defect prediction approach based on deep density sampling and deep domain adaptation. <em>IJSEKE</em>, <em>35</em>(4), 569-607. (<a href='https://doi.org/10.1142/S0218194025500172'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous Defect Prediction (HDP) refers to using labeled instance data from source projects to predict potential defect instances for the target project. This approach addresses the feature heterogeneity problem between different datasets, aiming to improve software quality actually. Notably, existing research on HDP addresses imbalance issues by focusing solely on minority classes and neglecting the influence of majority classes. Moreover, these studies fail to regard issues of feature consistency and differences in data distribution in depth while addressing heterogeneity in the feature space. Consequently, this paper proposes a 2-stage HDP approach, PEAPOD, based on dee P d E nsity s A mple and dee P d O main a D aptation. First, PEAPOD creates a balanced dataset by transforming data into a latent space, selecting high-quality samples by density and enhancing the defective class with synthetic samples through feature-level oversampling. Next, PEAPOD aligns matching features utilizing KS-test and the Hungarian algorithm and subsequently reduces data distribution differences via a Domain Adversarial Neural Network (DANN). Extensive and rigorous experimental results on 23 projects from 5 public datasets demonstrate PEAPOD outperforms HDP baseline methods.},
  archive      = {J_IJSEKE},
  author       = {Yifan Zou and Huiqiang Wang and Hongwu Lv and Shuai Zhao},
  doi          = {10.1142/S0218194025500172},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {4},
  pages        = {569-607},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {PEAPOD: A heterogeneous defect prediction approach based on deep density sampling and deep domain adaptation},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep neural networks for traffic flow estimation for Spatial–Temporal DOMAIN. <em>IJSEKE</em>, <em>35</em>(4), 547-567. (<a href='https://doi.org/10.1142/S0218194025500159'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow estimation is critical for road traffic management. However, the traditional systems measuring procedures demand a significant amount of time and money to continually collect the essential data and keep the associated hardware, like cameras and sensors. On the other hand, deep learning approaches give a scientifically solid framework for modeling the ambiguity and complicated relationships between multiple variables. Accordingly, this study utilized deep learning networks and built a model to estimate traffic flows using anticipated journey times. Stacked Autoencoders (SAEs), Gated Recurrent Units (GRUs) and Long Short-Time Memory units (LSTMs) techniques were specifically used to train the model. A number of experiments were carried out using various time sequence values and compared the estimated traffic flows produced by the suggested model and the actual ones collected from real sensors. The results demonstrate that the suggested model is capable of capturing the general trend of actual traffic flows. Our research proposes building a model to estimate traffic flows using anticipated journey times to capture the general trend of actual traffic loads using a deep learning model. Different experiments are completed using various time sequence values and comparing the estimated traffic flows produced by the suggested models and real data sensors. This work provides a solution using a deep learning model to estimate traffic flow that provides a consummate for e-businesses to use this approach to reduce their transportation cost and increase their customer satisfaction.},
  archive      = {J_IJSEKE},
  author       = {Ahmet E. Topcu and Yehia Ibrahim Alzoubi and Ersin Elbasi and Erdem Ozdemir},
  doi          = {10.1142/S0218194025500159},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {4},
  pages        = {547-567},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Deep neural networks for traffic flow estimation for Spatial–Temporal DOMAIN},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximate query for industrial fault knowledge graph based on vector index. <em>IJSEKE</em>, <em>35</em>(4), 525-545. (<a href='https://doi.org/10.1142/S0218194025500147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the industrial sector, index-based fault knowledge graph query techniques are essential for accelerating fault information retrieval and improving the accuracy and efficiency of diagnosing equipment issues. Using knowledge graph embedding, these systems transform entities and their relationships into dense vectors, making it easier for machine learning algorithms to process knowledge graph queries effectively. However, existing models often focus on boosting search accuracy at the cost of time efficiency, particularly when dealing with large fault knowledge graphs. To address this, we propose an optimized query method for fault knowledge graphs using vector indexing. The process starts by converting the entities and relationships in the knowledge graph into a vector space, generating a concise vector representation. Advanced vector database technology is then employed to build a specialized vector index library designed for fault knowledge graphs. This includes dividing the search space through clustering algorithms and employing approximate matching techniques to enhance query speed. By utilizing the indexed fault knowledge graph, we can conduct similarity searches to facilitate approximate querying. Evaluations show that our approach significantly reduces search times and outperforms traditional methods in terms of accuracy, demonstrating the value of vector index libraries in boosting the overall query efficiency of knowledge graphs, while keeping high accuracy levels.},
  archive      = {J_IJSEKE},
  author       = {Shichen Zhai and Hao Ji and Kun Zhang and Yongcheng Wu and Zongmin Ma},
  doi          = {10.1142/S0218194025500147},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {4},
  pages        = {525-545},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Approximate query for industrial fault knowledge graph based on vector index},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Experimental examination of the effect of programming languages and frameworks on mobile application development processes. <em>IJSEKE</em>, <em>35</em>(4), 503-523. (<a href='https://doi.org/10.1142/S0218194025500135'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile technologies have become an integral part of our daily lives, making it increasingly important for developers to create mobile applications quickly and efficiently. There are many programming languages and frameworks available for mobile application development. This study discusses frameworks like Flutter and React Native, as well as the languages Kotlin and Java used in native application development. It also investigates which application development technique provides better services for developers. As part of the research, similar applications were developed in each language and subjected to various performance tests. These tests measured parameters such as central processing unit (CPU) usage, Random Access Memory (RAM) consumption, code length, and application size. In the study, three applications with different levels of complexity were developed separately using Flutter, React Native, and Kotlin. The applications included a to-do list with 250, 500, and 1000 items, a simple calculator, and a tic-tac-toe game. Performance tests were then conducted. The results showed that Kotlin stands out as the most efficient platform, with low CPU and memory usage, small file size, and high performance. Flutter is notable for its balanced resource usage and cross-platform support. Although React Native offers a fast development process, it should be carefully considered for large projects where performance is crucial due to its high resource usage. The suitability of these three mobile application development techniques for a given project can be determined using the results obtained from this study.},
  archive      = {J_IJSEKE},
  author       = {Durmuş Özkan Şahin and Zeynep Altun and Öykü Kaya and Batuhan Semiz},
  doi          = {10.1142/S0218194025500135},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {4},
  pages        = {503-523},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Experimental examination of the effect of programming languages and frameworks on mobile application development processes},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A static analysis framework for investigating tainted data sources in software systems. <em>IJSEKE</em>, <em>35</em>(4), 469-501. (<a href='https://doi.org/10.1142/S0218194025500123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most effective methods for detecting software security vulnerabilities is taint analysis. Some software defects originate from certain external input data. Analyzing the taint sources and the data flow propagation from these sources to defect points through static analysis can help us understand the causes of software defects and reduce the difficulty of debugging them. This paper combines intraprocedural and interprocedural analysis methods to obtain global taint source information. A novel propagation path calculation algorithm is proposed, incorporating predecessor node computation and alias analysis, effectively reducing the negative impact of irrelevant code on the performance of taint analysis. This method not only helps detect errors that lead to vulnerabilities but also analyzes the impact of vulnerable input data on the system. Based on the global taint source analysis algorithm, we developed a static taint source analysis prototype tool for C programs, called AWsTS. Experiments conducted on five open-source projects show that AWsTS improves the accuracy of analysis results without increasing the required analysis time. The average precision for intra-procedural taint source analysis is 93.4%, and the average recall is 90.2%. Similarly, for interprocedural taint source analysis, the average precision is 87.6%, and the average recall is 84.9%. Additionally, AWsTS can output taint propagation paths, providing valuable support for further taint analysis.},
  archive      = {J_IJSEKE},
  author       = {Peng Dai and Xiaoqin Ma and Zebo Peng and Chen Zhao and Qianjin Zhang},
  doi          = {10.1142/S0218194025500123},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {4},
  pages        = {469-501},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {A static analysis framework for investigating tainted data sources in software systems},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Applying epistemic network analysis to open source software projects. <em>IJSEKE</em>, <em>35</em>(4), 441-467. (<a href='https://doi.org/10.1142/S0218194025500093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The massive emergence of Open Source Software (OSS) projects led to the rapid increment of data available to software engineers and those who would like to contribute to an OSS project. There is an arising need for a way to analyze and draw conclusions about the value of an OSS project, from an epistemic point of view. OSS projects have been used for a long time as vehicles for learning programming and software engineering. However, there is a need for more evidence about the scientific value conveyed by OSS projects. We posit that if we deeply study the dialogues of software engineers involved in the communities of the various projects and draw conclusions from them, this can be an additional way of assessing OSS projects. Learning analytics, data mining and data science provide diverse statistical and computational approaches to analyzing data. In this work, we describe Epistemic Network Analysis (ENA), a network analysis technique used by a growing community of researchers to support thick descriptions based on large volumes of data. ENA is based on the theory of epistemic frames. The theory of epistemic frames models the ways of being, thinking and acting inside some community of practice. In this research, we focus on the epistemic frame of software engineering and discuss the elements of this frame: the knowledge, the set of skills and values and the set of processes for making and justifying decisions. We coded the discourses of two well-known open source projects, LibreOffice and OpenOffice, and we used the online tool ENA WebKit to analyze the coded rows of the discourses, but also to visualize and compare the networks of different units of data. We conducted three types of experiments and comparisons on the mean networks of the two projects, on the networks of the different bugs, as well as on the networks of some software engineers who participated in the discussions, and we came to conclusions about how epistemic these dialogues were and therefore assessing their educational value. This is an introductory work utilizing the ENA method for OSS discourse analysis. We believe that the rational presented in this paper can lead to a set of processes on evaluating OSS projects based on their epistemology and at the same time, become an educational tool for software engineering courses and research groups.},
  archive      = {J_IJSEKE},
  author       = {Apostolos Kritikos and Konstantina Papadopoulou and Ioannis Stamelos},
  doi          = {10.1142/S0218194025500093},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {4},
  pages        = {441-467},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Applying epistemic network analysis to open source software projects},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable instance matching using lucene and mongodb. <em>IJSEKE</em>, <em>35</em>(3), 421-440. (<a href='https://doi.org/10.1142/S0218194025500111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of the semantic web and Linked Open Data (LOD) cloud has led to the creation and integration of various knowledge bases defined by ontologies. A significant challenge within the LOD paradigm is identifying resources that refer to the same real-world object to enable large-scale data integration and sharing. In this context, instance matching has emerged as a key solution, linking co-referent instances from heterogeneous data sources using owl:sameAs links. Traditional approaches focus on schema-level matching but often fail to address property-level heterogeneity. Moreover, given the large scale of instances, examining all possible instance pairs is impractical. This paper proposes a scalable and efficient instance-matching approach using MongoDb (Humongous database) and Lucene. MongoDb stores instances at any scale and Lucene uses inverted indexes to identify matching candidates. Experiments on the instance matching track from the Ontology Alignment Evaluation Initiative (OAEI’2022) show that our approach matches the F -measure score of RE-Miner, the top performer in OAEI’2020, while surpassing all other participants in OAEI’2020, 2021 and 2022. Additionally, it operates 17 times faster than RE-Miner, four times faster than Lily and 15 times faster than LogMap, the fastest in OAEI’2020, 2021 and 2022, respectively. Moreover, we evaluate our approach on other knowledge bases from OAEI’2010. Once again, our approach gets highly competitive resuts compared to state-of-the-art approaches.},
  archive      = {J_IJSEKE},
  author       = {Siham Amrouch and Ryma Guefrouchi and Nawel Zemmal and Sadok Ben Yahia},
  doi          = {10.1142/S0218194025500111},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {3},
  pages        = {421-440},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Scalable instance matching using lucene and mongodb},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OscSe: A practical security assessment model for general open source components. <em>IJSEKE</em>, <em>35</em>(3), 397-419. (<a href='https://doi.org/10.1142/S021819402550010X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open source components (OSCs) have become a vital part for developing modern applications. The security of these components could affect the overall security of the software depends on them. Thus, the security of an OSC should be evaluated first before integrating to the software. However, the existing models lack generality, and cannot be easily automatic applied to OSCs developed in different programming language. To this end, we propose a security assessment model for OSCs, called the CRAM, which features generality and automation. The proposed model is constructed under the hypothesis that OSC with a larger and more active community is more likely to disclose more vulnerabilities. And it evaluates the security of OSC from its performance in size as well as activities of open source community and vulnerability disclosures. In the experiment section, we present validation and application experiments. In the validation experiment, we find that the basic hypothesis of the proposed model is valid, and there is a positive correlation between the community size as well as activities and vulnerability risk of OSCs. In the application experiment, we further evaluate our approach with large-scale open source components. Our hypothesis is further validated. The most of OSCs in the ecosystem are in line with the hypothesis. Finally, we successfully build the security baseline according to the hypothesis, and 5 vulnerable OSCs classified as vulnerable by our model are analyzed. The result proves the effectiveness of our model to identify a vulnerable open source ecosystem around the ecosystem.},
  archive      = {J_IJSEKE},
  author       = {Ziyan Wang and Cheng Huang and Yang You},
  doi          = {10.1142/S021819402550010X},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {3},
  pages        = {397-419},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {OscSe: A practical security assessment model for general open source components},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A change-level defect prediction approach based on Teacher–Student network. <em>IJSEKE</em>, <em>35</em>(3), 375-396. (<a href='https://doi.org/10.1142/S0218194025500081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Change-level defect prediction, also known as just-in-time (JIT) defect prediction, concentrates on predicting if a specific commit is likely to introduce defects. It effectively alleviates the limitations of traditional file-level defect prediction techniques, such as coarse-grained, hard to trace and poor timeliness. Currently, most change-level defect prediction techniques construct defect prediction models by using either expert features or semantic features. Recent studies have shown that the defect prediction performance can be enhanced by integrating these two types of features. However, obtaining expert features is not an easy task, due to missing historical data in real projects. To address the aforementioned problem, this paper proposes TS-SDP ( T eacher– S tudent based S oftware D efect P rediction) based on teacher–student network. First, the source code is analyzed to extract expert features and semantic features. Then, a teacher–student network framework is constructed. In this framework, both features are used as inputs to the teacher network and only semantic features are used as inputs to the student network. The student network is enabled to learn about the expert features from the teacher network through the loss function. Finally, the student network is used to differentiate commits that are defect-inducing and those that are not, in the presence of only semantic features. The results of the experiments carried out on a dataset containing 21 different projects show that, when only semantic features are available, the cross-network knowledge dissemination between the teacher and student network makes it possible to predict defects. When compared to the state-of-the-art change-level defect prediction method, JIT-Fine, TS-SDP is 0.130, 0.114, 0.123 and 0.016 greater in P r e c i s i o n , R e c a l l , F - measure and A c c u r a c y , respectively.},
  archive      = {J_IJSEKE},
  author       = {Xinhong Duan and Xiguo Gu and Jiale Zhang and Zhanqi Cui},
  doi          = {10.1142/S0218194025500081},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {3},
  pages        = {375-396},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {A change-level defect prediction approach based on Teacher–Student network},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting interaction related bugs in a multi-tenant setting using kubernetes. <em>IJSEKE</em>, <em>35</em>(3), 351-374. (<a href='https://doi.org/10.1142/S021819402550007X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-tenant architectures allow multiple users to run similar applications on shared infrastructure, reducing the cost of resources. Developers of such applications must ensure tenant isolation to prevent users from interfering with one another. Concurrency bugs may arise only when a specific set of users is logged in at the same time. This paper introduces a framework for testing user interactions with a server, aimed at detecting timing-related bugs. The framework uses a scheduler to control when users log in and out of the system. If a particular set of users is logged in simultaneously, the server will simulate a potential bug. Users also keep a copy of the server’s data, and if the server’s data differs from their copy, a bug has occurred, which the user will report. The framework is designed to be flexible, supporting the addition of custom schedulers that can use either static scheduling algorithms or advanced Artificial Intelligence techniques to speed up bug detection more efficiently than traditional fuzz testing methods.},
  archive      = {J_IJSEKE},
  author       = {Bogdan Ghimis},
  doi          = {10.1142/S021819402550007X},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {3},
  pages        = {351-374},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Detecting interaction related bugs in a multi-tenant setting using kubernetes},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RESEARCH NOTES — GMRepair: Graph mining template-based automated software repair. <em>IJSEKE</em>, <em>35</em>(3), 327-349. (<a href='https://doi.org/10.1142/S0218194025500068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing scale and complexity of software recently, automated software bug repair has grown in importance. However, the current automated software bug repair process suffers from issues such as coarse-grained repair granularity and poor patch quality. To address these problems, we propose a graph mining template-based automatic software repair (GMRepair) to improve the performance of automated software bug repair. First, this approach adopts the Ochiai fault localization technique to locate and generate a list of suspicious defect statements. We utilize the GumTree tool to parse the bug and repair program files, generating edit scripts. These edit scripts are then transformed into a graphical representation. Second, we utilize a frequent graph miner to obtain graph mining templates by matching the context of the suspicious statements with the context of the graph mining templates, generating an initial population for them. The buggy program is evolved using genetic programming through mutation and crossover operations, generating new individuals. Finally, we sequentially pass the candidate patches (CPs) through corresponding test cases and prioritize the test cases using priority sorting techniques. Patches that fail to pass the test cases are filtered out, and the patches that pass the test cases are output. We conducted the experiments using two datasets, QuixBugs and Defects4J. In Defects4J, the GMRepair successfully repaired 41 defects, while in QuixBugs, it successfully repaired 15 defects. Compared to the existing methods, GMRepair offers a higher success rate and efficiency in defect repair.},
  archive      = {J_IJSEKE},
  author       = {Heling Cao and Yanlong Guo and Yun Wang and Fangchao Tian and Zhaolong Wang and Yonghe Chu and Miaolei Deng and Panpan Wang and Zhenghao He and Shuting Wei},
  doi          = {10.1142/S0218194025500068},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {3},
  pages        = {327-349},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {RESEARCH NOTES — GMRepair: Graph mining template-based automated software repair},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SPERT: Reinforcement learning-enhanced transformer model for agile story point estimation. <em>IJSEKE</em>, <em>35</em>(3), 293-325. (<a href='https://doi.org/10.1142/S0218194025500044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Story point estimation is a key practice in Agile project management that assigns effort values to user stories, helping teams manage workloads effectively. Inaccurate story point estimation can lead to project delays, resource misallocation and budget overruns. This study introduces Story Point Estimation using Reinforced Transformers (SPERT), a novel model that integrates transformer-based embeddings with reinforcement learning (RL) to improve the accuracy of story point estimation. SPERT utilizes Bidirectional Encoder Representations from Transformers (BERT) embeddings, which capture the deep semantic relationships within user stories, while the RL component refines predictions dynamically based on project feedback. We evaluate SPERT across multiple Agile projects and benchmark its performance against state-of-the-art models, including SBERT-XG, LHC-SE, Deep-SE and TF-IDF-SE. Results demonstrate that SPERT outperforms these models in terms of Mean Absolute Error (MAE), Median Absolute Error (MdAE) and Standardized Accuracy (SA). Statistical analysis using Wilcoxon tests and A12 effect size confirms the significance of SPERT’s performance, highlighting its ability to generalize across diverse projects and improve estimation accuracy in Agile environments.},
  archive      = {J_IJSEKE},
  author       = {Waleed Younas and Rui Chen and Jing Zhao and Tahreem Iqbal and Mohamed Sharaf and Azhar Imran},
  doi          = {10.1142/S0218194025500044},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {3},
  pages        = {293-325},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {SPERT: Reinforcement learning-enhanced transformer model for agile story point estimation},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HCIA: Hierarchical change impact analysis based on hierarchy program slices. <em>IJSEKE</em>, <em>35</em>(2), 263-292. (<a href='https://doi.org/10.1142/S0218194025500056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Change impact analysis (CIA) is an essential method in software maintenance and evolution. Its accuracy and usability play a crucial role in its application. However, most CIAs are coarse-grained and limited to class and method levels. Despite the fine-grained CIAs’ success in giving the statement-level impact set, they are still limited without the sub-statement level dependency analysis, leading to low precision. Additionally, their unstructured impact sets make it challenging for users to comprehend the impact content. This paper proposes Hierarchical Change Impact Analysis (HCIA), a Hierarchical CIA technique based on the sub-statement level dependence graph. HCIA can perform a forward hierarchy program slicing on the change set from five levels: sub-statement, statement, method, class, and package. Based on the program slices, HCIA calculates the impact factor of the impact sets at the five levels to generate the final impact set. In the experiment, we evaluate the relationship between the impact factor and the actual affected codes and assess the most appropriate size of HCIA impact sets. Furthermore, we evaluate HCIA on 10 open-source projects by comparing our approach with popular CIAs at the five levels. The experimental result shows that HCIA is more accurate than the popular CIAs.},
  archive      = {J_IJSEKE},
  author       = {Jianming Chang and Lulu Wang and Zaixing Zhang},
  doi          = {10.1142/S0218194025500056},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {2},
  pages        = {263-292},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {HCIA: Hierarchical change impact analysis based on hierarchy program slices},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A model-based evaluation metric for question answering systems. <em>IJSEKE</em>, <em>35</em>(2), 243-262. (<a href='https://doi.org/10.1142/S0218194025500032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper addresses the limitations of traditional evaluation metrics for Question Answering (QA) systems that primarily focus on syntax and n-gram similarity. We propose a novel model-based evaluation metric, MQA-metric, and create a human-judgment-based dataset, squad-qametric and marco-qametric, to validate our approach. The research aims to solve several key problems: the objectivity in dataset labeling, the effectiveness of metrics when there is no syntax similarity, the impact of answer length on metric performance, and the influence of real answer quality on metric results. To tackle these challenges, we designed an interface for dataset labeling and conducted extensive experiments with human reviewers. Our analysis shows that the MQA-metric outperforms traditional metrics like BLEU, ROUGE and METEOR. Unlike existing metrics, MQA-metric leverages semantic comprehension through large language models (LLMs), enabling it to capture contextual nuances and synonymous expressions more effectively. This approach sets a standard for evaluating QA systems by prioritizing semantic accuracy over surface-level similarities. The proposed metric correlates better with human judgment, making it a more reliable tool for evaluating QA systems. Our contributions include the development of a robust evaluation workflow, creation of high-quality datasets, and an extensive comparison with existing evaluation methods. The results indicate that our model-based approach provides a significant improvement in assessing the quality of QA systems, which is crucial for their practical application and trustworthiness.},
  archive      = {J_IJSEKE},
  author       = {Dilan Bakır and Mehmet S. Aktas and Beytullah Yıldız},
  doi          = {10.1142/S0218194025500032},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {2},
  pages        = {243-262},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {A model-based evaluation metric for question answering systems},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A method to evaluate the credibility of domain knowledge network using validated expert knowledge. <em>IJSEKE</em>, <em>35</em>(2), 217-241. (<a href='https://doi.org/10.1142/S0218194025500020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are living in an era of knowledge explosion, where all kinds of knowledge are emerging and becoming more and more complicated with the development of new techniques and new ideas. When we study knowledge and apply them to understand and solve problems, the credibility of knowledge is becoming our main concerns. Usually, high credible domain knowledge can guide us correctly understand all concepts and the relationships between them in this domain. Due to its good layer structure and scalability, domain knowledge network is widely used to represent knowledge in knowledge engineering, artificial intelligence and others in recent years. How to ensure the credibility of domain knowledge network? This is an important and interesting topic. In this paper, we propose a method to evaluate the knowledge credibility for domain knowledge network, which means that we can start from the layer structure of domain knowledge network, and evaluate the credibility of knowledge layer by layer using validated expert knowledge such as domain dictionary, domain ontology and domain expert experience. We conduct experiments with six domain knowledge network constructed based on network data and six domain knowledge network constructed manually based on published books or domain dictionaries, which describe the same domain knowledge in pairs. Experimental results show that the knowledge credibility of domain knowledge network constructed from validated expert knowledge is significantly higher than the knowledge credibility of domain knowledge network constructed directly from network data, which satisfy our expectation and also prove the effectiveness of our credibility evaluation method.},
  archive      = {J_IJSEKE},
  author       = {Yin Li and Ying Zhou and Li Liao and Bixin Li},
  doi          = {10.1142/S0218194025500020},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {2},
  pages        = {217-241},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {A method to evaluate the credibility of domain knowledge network using validated expert knowledge},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RESEARCH NOTES: Design of a distributed and highly scalable fog architecture for heterogeneous IoT infrastructures. <em>IJSEKE</em>, <em>35</em>(2), 195-215. (<a href='https://doi.org/10.1142/S0218194025430016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fog computing can provide an effective solution to the challenges presented by today’s ever-emerging Internet of Things (IoT) infrastructures. As the number of interconnected devices progressively increases, these infrastructures require better solutions to ensure high scalability and processing capacity, along with an efficient use of available resources. This is why this paper presents a distributed Fog architecture, specifically designed to address the challenges and difficulties presented by heterogeneous IoT environments. This Fog architecture is used as an intermediate layer between the IoT devices and the final layer, it has been designed after the previous analysis of the requirements to be met for the solution, then the modularization of the architecture has been carried out so that it can be easily distributed, and finally, an implementation has been generated on a real environment as a validation case of the proposal.},
  archive      = {J_IJSEKE},
  author       = {Lucía Arnau Muñoz and José Vicente Berná Martínez and Carlos Calatayud Asensi and David Saavedra Pastor},
  doi          = {10.1142/S0218194025430016},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {2},
  pages        = {195-215},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {RESEARCH NOTES: Design of a distributed and highly scalable fog architecture for heterogeneous IoT infrastructures},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward a pattern-based comprehensive framework using process mining for RBAC conformance checks. <em>IJSEKE</em>, <em>35</em>(2), 157-194. (<a href='https://doi.org/10.1142/S0218194025500019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event logs often record the execution of business process instances. Detecting traces in the event logs that do not comply with access control policies, such as role-based access control (RBAC) policies, is essential to ensuring system security. Moreover, process mining has been extensively utilized for security analysis in recent years. However, pattern-based approaches for designing and analyzing RBAC policies in the context of business processes through process mining are notably absent. In this paper, we present a systematic framework for checking the conformance of RBAC implemented in the event logs of business processes with the RBAC policies specified in domain knowledge. To facilitate the representation of the RBAC policies derived from the domain knowledge, we employ an RBAC domain-specific language (DSL) combined with our RBAC-driven object constraint language (OCL) invariant patterns built from the various types of RBAC constraints. The implemented RBAC in an event log is represented as snapshots within our framework. Then, we validate the snapshots with the RBAC policies to be able to detect RBAC conformance issues. The proposed framework is experimented with and evaluated on two business process logs, one simulated log and one real-world event log named “BPI Challenge 2017”.},
  archive      = {J_IJSEKE},
  author       = {Duc-Hieu Nguyen and Yuichi Sei and Yasuyuki Tahara and Akihiko Ohsuga},
  doi          = {10.1142/S0218194025500019},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {2},
  pages        = {157-194},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Toward a pattern-based comprehensive framework using process mining for RBAC conformance checks},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Software quality assessment model: A new approach for software testing tools. <em>IJSEKE</em>, <em>35</em>(2), 139-155. (<a href='https://doi.org/10.1142/S0218194024500517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process of software testing is a crucial phase in determining the quality of software, and this phase requires significant costs and a considerable amount of time for testers. This paper discusses the development of a framework for software quality assessment, involving flexible choices of software testing methods and variables in the form of an application. The method used is experimental, developing a new framework based on previous research, where previous research was limited to specific methods and testing variables. The result of this research is the creation of a new framework for software quality assessment. It is hoped that this framework can serve as a reference for software companies in evaluating software quality. In terms of complexity, this framework has the advantage of allowing a tester to choose methods with more flexible or unlimited testing variables. Regarding the estimated time and costs, with PF = 4 , 5 and 1 0 , the practical application complexity of the developed framework is estimated to have the best costs, time and human resources at IDR 254,240,000, with an estimated time of 3,178 work hours and 6,356 work hours with a team of 3 people.},
  archive      = {J_IJSEKE},
  author       = {Zulkifli Zulkifli and Mardiana Mardiana and Dikpride Despa},
  doi          = {10.1142/S0218194024500517},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {2},
  pages        = {139-155},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Software quality assessment model: A new approach for software testing tools},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mining fine-grained code change patterns using multiple feature analysis. <em>IJSEKE</em>, <em>35</em>(1), 111-138. (<a href='https://doi.org/10.1142/S0218194024500505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maintaining high code quality is a crucial concern in software development. Existing studies demonstrated that developers frequently face recurrent bugs and adopt similar fix measures, known as code change patterns. As an essential static analysis technique, code pattern mining supports various tasks, including code refactoring, automated program repair, and defect prediction, thus significantly improving software development processes. A prevalent approach to identifying code patterns involves translating code changes to edit actions into a Bag-of-Words (BoW) model. However, when applied to open-source projects, this method exhibits several limitations. For instance, it overlooks function call information and disregards feature word order. This study introduces MIFA, a novel technique for mining code change patterns using multiple feature analysis. MIFA extends existing BoW methods by incorporating analysis of function calls and overall changes in the Abstract Syntax Tree (AST) structure. We selected 20 popular Python projects and evaluated MIFA in both intra-project and cross-project scenarios. The experimental results indicate that: (1) MIFA achieved higher silhouette coefficients and F1 scores compared to other state-of-the-art methods, demonstrating a superior accuracy; (2) MIFA can assist developers in detecting unique change patterns more earlier, with an efficiency improvement of over 40% compared to random sampling. Additionally, we discussed critical parameters for measuring the similarity of code changes, guiding users to apply our method effectively.},
  archive      = {J_IJSEKE},
  author       = {Di Liu and Yang Feng},
  doi          = {10.1142/S0218194024500505},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {1},
  pages        = {111-138},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Mining fine-grained code change patterns using multiple feature analysis},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Code recommendation for schema evolution of mimic storage systems. <em>IJSEKE</em>, <em>35</em>(1), 89-110. (<a href='https://doi.org/10.1142/S0218194024500499'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Schema evolution of mimic storage systems is a time-consuming and error-prone task due to the redundant development of heterogeneous executors. The ORM-based proxy requires an entire class to represent the structure of a data table. There lacks domain-specific code recommendation techniques to boost storage development. To address this issue, we design a novel type of code context, i.e. schema context, that combines features of code text, syntax and structure. Regarding the requirements of class-level granularity, we focus on behavior and attribute in code syntax, and use element position and structural metrics to mine the hidden relationships. Based on schema context and an existing inference mode, we propose SchemaRec to recommend ORM-related class for the database executors once one of them has been changed. We conduct experiments with 110 open-source projects, and the results show that SchemaRec obtains more accurate results than Lucene, DeepCS, QobCS and SEA in terms of Top-1, Top-10 and MRR accuracy due to the better ability of context representation. We also find that code syntax is the most important information because it involves behavior and attribute information of ORM-related classes.},
  archive      = {J_IJSEKE},
  author       = {Xianglong Kong and Zhuo Lv and Cen Chen and Hao Chang and Nuannuan Li and Fan Zhang},
  doi          = {10.1142/S0218194024500499},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {1},
  pages        = {89-110},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Code recommendation for schema evolution of mimic storage systems},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The trustworthiness metric model of interface based on defects. <em>IJSEKE</em>, <em>35</em>(1), 59-88. (<a href='https://doi.org/10.1142/S0218194024500487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interface is a crucial element in component-based software, enabling the linkage of distinct components to facilitate interaction. Defects within the interface can significantly impact the overall trustworthiness of the system. Therefore, it is essential to assess the interface trustworthiness based on a defect-centric approach. This paper introduces a novel model for evaluating interface trustworthiness, anchored in defect analysis. First, the defect types are formalized based on interface specifications. Then, the comprehensive weight allocation method is established to characterize the importance degree of each interface defect type by combining the G1 and CRITIC methods. Subsequently, the attributes of the interface are evaluated by defect value analysis, and the trustworthiness measurement model of the interface is proposed based on these attributes. Furthermore, to evaluate the trustworthiness of the whole system, the trustworthiness measure models under different combination structure of components are established. Finally, the model’s’ applicability is demonstrated through an illustrative example. This trustworthiness evaluation from the interface view can guide interface designers to obtain high-quality interfaces and improve the trustworthiness of the entire software.},
  archive      = {J_IJSEKE},
  author       = {Yanfang Ma and Xiaotong Gao},
  doi          = {10.1142/S0218194024500487},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {1},
  pages        = {59-88},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {The trustworthiness metric model of interface based on defects},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing translation validation of compiler transformations with large language models. <em>IJSEKE</em>, <em>35</em>(1), 45-57. (<a href='https://doi.org/10.1142/S0218194024500475'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a framework that integrates Large Language Models (LLMs) into translation validation, targeting LLVM compiler transformations where formal verification tools fall short. Our framework utilizes the existing tools, like Alive2, to perform initial validation. For transformations deemed unsolvable by traditional methods, our approach leverages fine-tuned LLMs to predict soundness or unsoundness, with subsequent fuzzing applied to identify counterexamples for unsound transformations. Our approach has proven effective in complex scenarios, such as deep-learning accelerator designs, enhancing the reliability of compiler transformations.},
  archive      = {J_IJSEKE},
  author       = {Yanzhao Wang and Fei Xie},
  doi          = {10.1142/S0218194024500475},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {1},
  pages        = {45-57},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Enhancing translation validation of compiler transformations with large language models},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An empirical study of fault localization on novice programs and addressing the tie problem. <em>IJSEKE</em>, <em>35</em>(1), 19-44. (<a href='https://doi.org/10.1142/S0218194024500426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Programming education is becoming increasingly popular in universities. However, due to a lack of debugging experience, novices often encounter numerous difficulties in the programming process. Automatic fault localization techniques have emerged as a promising solution to address this issue. Among these techniques, Spectrum-Based Fault Localization (SBFL) and Mutation-Based Fault Localization (MBFL) have been widely used in industrial programs. However, there is a significant difference between industrial and novice programs and the performance of these methods on novice programs has not been extensively studied. To fill this gap, we conducted an empirical study to evaluate the fault localization performance and execution overhead of SBFL and MBFL in a typical novice programming environment. Our study specifically examined how different program characteristics, including code coverage and mutation score, affect the accuracy of these localization methods. Additionally, during the study, we identified the tie problem in both methods and further investigated its impact on fault localization techniques in novice programs. To remove the impact of the tie problem, we proposed using PageRank scores as weights for the suspiciousness, sorting, and locating faults based on the weighted suspiciousness. The PageRank algorithm is based on statement coverage information and constructs a directed graph. From the directed graph, a transition matrix generates the weight scores (PageRank scores) for each statement. Our research demonstrates that both SBFL and MBFL are effective for fault localization in novice programs, with MBFL showing significantly better performance in our tests. In TOP- N ( N = 1 , 3 , 5 ) , MBFL accurately locates 67, 96 and 114 faults, respectively, indicating superior performance. Additionally, calculating weighted suspiciousness significantly alleviates the tie problem.},
  archive      = {J_IJSEKE},
  author       = {Yuxing Liu and Jiaxin Zhong and Qihua Hei and Xuchuan Zhou and Jingzhong Xiao},
  doi          = {10.1142/S0218194024500426},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {1},
  pages        = {19-44},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {An empirical study of fault localization on novice programs and addressing the tie problem},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using peer assessment leveraging large language models in software engineering education. <em>IJSEKE</em>, <em>35</em>(1), 1-18. (<a href='https://doi.org/10.1142/S0218194024500359'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the integration of generative AI and large language models into the realm of software engineering education and training, with a specific focus on the transformation of traditional peer assessment methodologies. The motivation stems from the growing demand for innovative educational techniques that can effectively engage and empower learners in mastering Software Engineering principles. The proposed approach involves presenting students with modeling exercises solved by ChatGPT, prompting them to critically evaluate and provide constructive feedback on the generated solutions. By engaging students in a dialogue with the AI model, we aim to foster a dynamic learning environment where learners can articulate their considerations and insights, thereby enhancing their comprehension of software engineering principles, critical thinking and self evaluation skills. Preliminary results from pilot implementations indicate promising outcomes, suggesting that this approach not only enhances the quality of peer feedback but also contributes to a more interactive and engaging educational experience.},
  archive      = {J_IJSEKE},
  author       = {Marco Fiore and Marina Mongiello},
  doi          = {10.1142/S0218194024500359},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Using peer assessment leveraging large language models in software engineering education},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijufks">IJUFKS - 44</h2>
<ul>
<li><details>
<summary>
(2025). Interval methods in knowledge representation. <em>IJUFKS</em>, <em>33</em>(6), 825-826. (<a href='https://doi.org/10.1142/S0218488525970074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJUFKS},
  doi          = {10.1142/S0218488525970074},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {6},
  pages        = {825-826},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Interval methods in knowledge representation},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On robust and non-robust modified liu estimation in poisson regression model with multicollinearity and outliers. <em>IJUFKS</em>, <em>33</em>(6), 787-823. (<a href='https://doi.org/10.1142/S0218488525500266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Poisson regression model is widely used in statistical data modeling in diverse fields, such as epidemiology, economics, engineering, and sports. Its popularity stems from its ability to effectively describe the relationship between a statistical response variable and a set of explanatory variables. However, multicollinearity among predictors and outliers in the data can severely affect the reliability of parameter estimation, leading to inflated variances and biased results. Multicollinearity increases the sensitivity of estimators to small changes in the data, while outliers can disproportionately affect the model fit, especially in the maximum likelihood estimation framework. To address these issues, robust biased estimation techniques, such as the ridge estimator and modified ridge-type estimator, have been introduced to mitigate multicollinearity by introducing shrinkage parameters. However, the transformed M-estimator remains sensitive to outliers. In this study, we propose robust and non-robust modified Liu estimators for the Poisson regression model. The non-robust method reduces the effect of multicollinearity by developing a Liu estimator, while the proposed robust method combines transformed M-estimation with a modified form of the Liu estimator to simultaneously address multicollinearity and reduce the influence of outliers. We derive the theoretical properties of the estimators and investigate their performance through extended Monte Carlo simulations. The results indicate that the non-robust modified Liu estimator provides more stable and accurate estimates than maximum likelihood estimation, ridge estimator, and modified ridge-type estimators in the case of multicollinearity, but the robust version of the modified Liu estimator generally outperforms, especially in the presence of both multicollinearity and outliers. We also analyze a real-world dataset to demonstrate the practical value of the proposed methods.},
  archive      = {J_IJUFKS},
  author       = {Fatimah M. Alghamdi and Ali T. Hammad and B. M. Golam Kibria and Gamal A. Abd-Elmougod and Laxmi Prasad Sapkota and Ahmed M. Gemeay},
  doi          = {10.1142/S0218488525500266},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {6},
  pages        = {787-823},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {On robust and non-robust modified liu estimation in poisson regression model with multicollinearity and outliers},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamically stabilized recurrent neural network optimized with binary emperor penguin optimization algorithm fostered sentiment classification and information retrieval. <em>IJUFKS</em>, <em>33</em>(6), 761-786. (<a href='https://doi.org/10.1142/S0218488525500254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the widespread increase of online reviews, sentiment classification is now a fascinating study in both academic and industrial research. Annotated training data is difficult to obtain, so reviews help in many domains. Numerous methods have been created for sentiment classification, but the process of retrieving information is not exact, less effective, and has a slower rate of convergence. To overcome these problems, this research proposes and evaluates a novel technique for information retrieval and sentiment classification called Dynamically Stabilized Recurrent Neural Network Optimized with Binary Emperor Penguin Optimization Algorithm (SCIR-DSRNN-BEPOA). This approach seeks to enhance the accuracy and efficiency of sentiment analysis by integrating advanced optimization techniques and also to address the challenges such as slow convergence and inefficiency in sentiment analysis, ultimately achieving superior performance metrics. The input data is gathered through Amazon unlocked mobile reviews database and telecom tweets for sentiment categorization with information retrieval. Afterward, the data is fed to the preprocessing. By using the Unscented Trainable Kalman Filter, the preprocessing process removes noise from reviews by fixing typos and removing ellipsis. These pre-processed data is fed to Adaptive and Concise Empirical Wavelet Transform (ACEWT) to extract the features, such as elongated words, punctuation, hash tag, numerical values. The extracted features are given to the DSRNN which classifies the sentiment, like neutral, positive and negative. In general, DSRNN does not show any optimization adaption methods to determine the optimum parameter to offer accurate sentiment classification. Therefore, Binary Emperor Penguin Optimization Algorithm (BEPOA) is proposed to optimize the DSRNN classifier that categorizes the sentiment precisely. Attention Enhanced Temporal Graph Convolutional Network (AETGCN) method is used to extract the necessary review. The proposed SCIR-DSRNN-BEPOA is implemented in MATLAB. To classify the sentiment, the performance metrics, like Precision, Accuracy, F1-score, Recall (Sensitivity), Specificity, Error rate, Computation time, False Alarm Rate, RoC is considered. The performance of the SCIR-DSRNN-BEPOA approach attains 20.11%, 21.12%, 27.73% higher accuracy, 11.13%, 23.04%, 9.51% lesser computation time, 15.29%, 19.43%, 12.45% greater ROC, 28.65%, 23.98%, 27.03% lower false alarm rate when compared with existing methods: Deep Learning improved spider monkey crow optimization algorithm for sentiment analysis and information recovery (SCIR-DRNN), Deep Learning topical level sentiment analysis of social media data (SCIR-LSTM), and a machine learning-based term weighting and feature selection strategy for sentiment analysis of online product evaluations (SCIR-ENN).},
  archive      = {J_IJUFKS},
  author       = {R. Jothilakshmi and P. Chinniah and R. Rajesh Sharma and T. R. Vijaya Lakshmi},
  doi          = {10.1142/S0218488525500254},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {6},
  pages        = {761-786},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Dynamically stabilized recurrent neural network optimized with binary emperor penguin optimization algorithm fostered sentiment classification and information retrieval},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An image-based recommendation system using voting-assisted ensemble machine learning approach. <em>IJUFKS</em>, <em>33</em>(6), 733-759. (<a href='https://doi.org/10.1142/S0218488525500242'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent days, e-commerce platforms have grown at an unexpected level worldwide. These sites usually rely on recommendation algorithms, which employ user terms to identify related goods or products. Most e-commerce applications are based on customer reviews, which are knowledge-based recommendations. Moreover, customers wish for an interactive platform to buy their needs, where interactions increase interest. In general, recommendations based on images that solve the interaction problem are rarely studied in the literature. Hence, the proposed paper focuses on an Image-Based Recommendation System using Deep Feature Extraction and Ensemble Machine Learning Approach. In the technique, initially, the image is pre-processed by removing the background using Adaptive Otsu thresholding-based segmentation. Secondly, the Stacked ResNET pyramid dilated convolution (PDC-ResNET) model is employed to extract the high-level features from the images. The extracted features are then selected using Binary Hunger Games search optimization (BHGO). Lastly, the product’s class or kind is categorized using a voting-based Ensemble of AdaBoost XG-Gradient Boosting Decision Tree (AX-BDT). There are two main levels in the suggested recommendation system: Level 1 and Level 2. The suggested model determines the product’s class and category at Level 1. The suggested recommendation algorithm in Level 2 retrieves products that are closely matched and similar. Two datasets, the Fashion product dataset and the Amazon product dataset, are used to assess the suggested approach. In the fashion product dataset, the proposed model results in 96.99% accuracy. In the Amazon product dataset, the proposed model results in 97.94% accuracy.},
  archive      = {J_IJUFKS},
  author       = {Harsh Khatter and Raj Kumar and Amit Kumar Singh Sanger and Ajay Kumar Shrivastava and Anurag Mishra and Arun Prakash Agrawal},
  doi          = {10.1142/S0218488525500242},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {6},
  pages        = {733-759},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {An image-based recommendation system using voting-assisted ensemble machine learning approach},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertain free disposal hull model with application to chinese banks. <em>IJUFKS</em>, <em>33</em>(6), 717-732. (<a href='https://doi.org/10.1142/S0218488525500230'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an alternative model to the data envelopment analysis (DEA), the free disposal hull (FDH) model has excellent performance in measuring decision making unit (DMU) efficiency under the condition that the production possibilities do not satisfy the convexity assumption. However, in actual production and life, many data are difficult to collect and cannot obtain accurate values, such as carbon dioxide emissions. In the case of imprecise data, the FDH model cannot evaluate the efficiency of DMU. In this context, a new uncertain FDH model based on uncertainty theory is proposed. In this paper, the uncertain FDH model is solved precisely by means of the uncertain chance constraint method and the expected value method. Finally, an application example of measuring the efficiency of 30 banks in China in 2019 is given to documenting the feasibility of the proposed model.},
  archive      = {J_IJUFKS},
  author       = {Jiali Wu and Wenxuan Xie and Yuhong Sheng},
  doi          = {10.1142/S0218488525500230},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {6},
  pages        = {717-732},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Uncertain free disposal hull model with application to chinese banks},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel risk-based portfolio optimization with return prediction using enhanced heap optimizer aided serial cascaded deep residual networks. <em>IJUFKS</em>, <em>33</em>(6), 687-715. (<a href='https://doi.org/10.1142/S0218488525500229'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of the stock market is still a complicated task to pursue in the field of machine learning as it relies on previous and past data, which is generally unstable and noisy. Existing methods of predicting the stock market are usually supervised approaches in which the prior labeling of the data as negative as well as positive moments is necessary to provide accurate results. However, this method of training the machine learning algorithms is complicated as it is vulnerable to overfitting issues as the behavior of the market usually relies on certain constraints like political events, marketing trends, and so on. The functioning of the actual portfolio optimization framework can be enhanced by fusing the return prediction in the conventional time series systems in the process of generating portfolios. Thus, the implementation of a better portfolio optimization system, which has a return prediction system integrated along with making the investors obtain more stable profits, is the major goal of this work. The modeling of the return forecasting model initially begins with the gathering of past stock marketing data. Then, the returns are estimated with the development of the Serial Cascaded Deep Residual Networks (SCDRN), where the deep learning models are utilized for predicting the future return of each stock. The risk level of each stock is also determined during the return prediction process. Then, with the aid of the developed optimization strategy named Enhanced Heap-based optimizer (EHO), the optimal portfolio is formulated, where the up-to-date market conditions are captured to rebalance the portfolio. The optimal selection of asset trading systems functions on the basis of the Sharpe ratio, and it maximizes the profit relative to the risk taken. An extensive analysis is executed to test the efficacy of the proposed portfolio optimization model regarding several baseline works with heuristic strategies.},
  archive      = {J_IJUFKS},
  author       = {V. Mehala and D. Sundar},
  doi          = {10.1142/S0218488525500229},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {6},
  pages        = {687-715},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {A novel risk-based portfolio optimization with return prediction using enhanced heap optimizer aided serial cascaded deep residual networks},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interval methods in knowledge representation. <em>IJUFKS</em>, <em>33</em>(5), 685-686. (<a href='https://doi.org/10.1142/S0218488525970062'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJUFKS},
  doi          = {10.1142/S0218488525970062},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {5},
  pages        = {685-686},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Interval methods in knowledge representation},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing building damage classification accuracy through machine learning-based model design using high resolution remote sensing images. <em>IJUFKS</em>, <em>33</em>(5), 665-683. (<a href='https://doi.org/10.1142/S0218488525400100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to evaluate the damage to buildings both accurately and precisely is essential for disaster recovery, planning, and rescue services. This paper proposes a new approach based on integrating machine learning algorithms in building damage classification. To achieve higher precision in classifying the level of building damage, this research proposes a new technique that employs machine learning strategies. The researchers were able to train the model to be able to differentiate the different levels of building damage and the feature extraction was performed through machine learning. The model effectively extracts and learns multiple complex signals which represent different degrees of damage from a well picked database which include several degrees of damage. In a single pass, the Siamese U-Net can perform feature extraction and similarity measurement between two different images. The efficiency and effectiveness of the Siamese U-net model can be increased by reducing inference time, thus increasing its ability to deliver faster predictions while also improving its accuracy. The suggested Enhanced U-Net (EU-Net) could greatly increase the accuracy of building-level classification. As it turned out, the results are very promising and reach beyond traditional approaches with bringing more sample opportunities of machine learning integration in the building damage assessment context. Additionally, this study believes that the accuracy of building damage classification can be further enhanced demonstrating the usefulness of machine learning in disaster management.},
  archive      = {J_IJUFKS},
  author       = {I Sajitha and Rakoth Kandan Sambandam and Saju P John},
  doi          = {10.1142/S0218488525400100},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {5},
  pages        = {665-683},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Advancing building damage classification accuracy through machine learning-based model design using high resolution remote sensing images},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced panoptic tooth image segmentation using regional-edge network model. <em>IJUFKS</em>, <em>33</em>(5), 645-664. (<a href='https://doi.org/10.1142/S0218488525400094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid growth of new healthcare technologies has emerged due to artificial intelligence (AI). When planning panoptic segmentation, a patient’s CT or panoramic radiography pictures determine the ideal teeth location and reduce surgical risk. Using a cone beam computed tomography (CBCT) image dataset, this effort aims to develop a Regional Edge detection with a Fully Connected Network Model (RED-FCN) approach that uses deep learning to locate missing teeth. In this investigation, five hundred CBCT pictures were used. After pre-processing, the samples are randomly split into training, validation and testing data. In this study, RED-FCN models that have already been trained are used. Furthermore, tests were conducted on the suggested models, both with and without the segmentation technique. With precision scores greater than 0.90, the recommended pre-trained DL models fared well in the average teeth class. Average teeth class is a generalized category representing common tooth characteristics, such as shape, size, or structure, based on an averaged dataset. Additionally, the trial outcomes validated RED-FCN benefit with a precision of 0.98. In addition, the precision values were 95%. With 95% segmentation accuracy and 94% classification accuracy for missing tooth areas, the RED-FCN model demonstrated strong performance across the various detection stages. This model could provide dentists with a time-saving technique and significantly advance automated dental segmentation.},
  archive      = {J_IJUFKS},
  author       = {Pulipati Nagaraju},
  doi          = {10.1142/S0218488525400094},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {5},
  pages        = {645-664},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Enhanced panoptic tooth image segmentation using regional-edge network model},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Securing financial transactions through cutting-edge machine learning approaches to effectively combat credit card fraud. <em>IJUFKS</em>, <em>33</em>(5), 623-643. (<a href='https://doi.org/10.1142/S0218488525400082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise in credit card transactions has made fraud detection more important. While credit cards offer convenience, they also increase the risk of fraud, posing threats to financial security and consumer trust. To address this challenge, in this work, six machine learning (ML) algorithms were examined: Logistic Regression (LR), Random Forest (RF), K-Nearest Neighbours (KNN), Decision Tree (DT), Support Vector Machine (SVM), and Naive Bayes (NB). A dataset of 568,630 transactions from European cardholders in 2023 was utilized, featuring 30 attributes. Pre-processing techniques such as feature scaling and class balancing were applied to balance the data and improve accuracy. Detailed data analysis was performed to identify important patterns among the features. Each algorithm underwent training and optimization through hyperparameter tuning and cross-validation. Performance was evaluated using precision, accuracy, recall, F1 score, and Area under the ROC Curve (AUC). Results indicated that RF and LR performed best. High accuracy and AUC values were attained by RF, whereas LR successfully identified fraudulent and authentic transactions. These insights highlight the value of ML in enhancing fraud detection systems. As credit card use continues to grow, these tools will be essential for improving financial security.},
  archive      = {J_IJUFKS},
  author       = {Hye Jin Kim and Rhee Jung Soo},
  doi          = {10.1142/S0218488525400082},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {5},
  pages        = {623-643},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Securing financial transactions through cutting-edge machine learning approaches to effectively combat credit card fraud},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CNN-RBM integrated deep learning design for categorizing attack in an intrusion detection system. <em>IJUFKS</em>, <em>33</em>(5), 613-622. (<a href='https://doi.org/10.1142/S0218488525400070'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, network attacks and intrusions are increasing due to expansions in computer networks. The most critical issue these days in modern cyber networks are network attacks. Intrusion prevention systems are designed to enhance security along with the firewalls and other intrusion prevention systems. Each and every network regardless of its size is exposed to network attacks. An Intrusion Detection System (IDS) is an essential security tool for categorizing malicious attacks in networks. Presently, Machine Learning (ML) and Deep Learning (DL) models are applied for developing a competent IDS and in numerous domains. Automated detection of malicious attacks in a timely manner is the purpose of IDS. Advanced cyber security solutions are required for continuous detection of malicious threats. Hence, investigators are generating an effective IDS for this research problem due to complex malicious attacks. In this article, an integrated DL model comprising of Convolutional Neural Network (CNN) with Restricted Boltzmann Machine (RBM) are applied to generate a fusion IDS to predict and classify malicious attacks. In the proposed Integrated Convolutional Restricted Boltzmann Machine Intrusion Detection System (ICRBM_IDS), the CNN executes convolution to hold local features and RBM captures the temporal features to enhance the performance of Intrusion Detection and Prediction. The ability of the ICRBM_IDS model is assessed based on the ID data present widely. The experiments were conducted on CSE-CIC-DS2018 dataset which is the result of collaborative project between Communications security Establishment (CSE) and the Canadian Institute of Cybersecurity (CIC) that is currently used and realistic. The simulation results of the proposed ICRBM_IDS outperform the present ID methods by attaining a high accuracy rate by detecting malicious attacks.},
  archive      = {J_IJUFKS},
  author       = {A. Kalaivani and R. Pugazendi},
  doi          = {10.1142/S0218488525400070},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {5},
  pages        = {613-622},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {CNN-RBM integrated deep learning design for categorizing attack in an intrusion detection system},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analyzing human mental state and emotions using a novel emonet learning model with unconstraint videos. <em>IJUFKS</em>, <em>33</em>(5), 591-612. (<a href='https://doi.org/10.1142/S0218488525400069'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mental state of a human is determined by an essential indicator known as emotion. Factors like satisfaction, stress, and the detection of emotions from various situations are essential in analyzing the sequential evaluation for specific functions. The computer vision method of emotion detection is a prominent technique of recognizing emotions from visual media such as videos and images of a person’s activities. The present models used only a simple concatenation feature to analyze the emotion. Thus, they should have observed the essential complementary gains between the context data in the video files and face, which is highly required to address the issues of misunderstanding and confusion. The proposed technique concentrates on the inter-feature interaction data, which helps us completely exploit the complex data between the context features and the face. We addressed a novel Convolutional Emotion Network (CEmoNet) model to obtain exact detection using high-definition video files. It captures the complex context and facial expression features by operating a network method. An individual channel’s feature maps are customized by applying the ReLU and Max_pool block. The hierarchical encoding contains the Conv_1 to Conv_4 block to obtain the favourable weights of the feature fusion and acquire the features of adaptive emotions through the weighting operation of the hybrid feature. Finally, the deep fusion block cooperates with the available features of adaptive emotions to forecast an individual’s emotion recognition. Extensive evaluation outcomes of the dataset from CAER-S experiments the performance of our model, revealing its efficiency in analyzing tourist evaluation with video files, analysis of work stress intensity with emotional proof of video files, or assessment of psychological fitness.},
  archive      = {J_IJUFKS},
  author       = {P. Naga Bhushanam and S. Selva Kumar},
  doi          = {10.1142/S0218488525400069},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {5},
  pages        = {591-612},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Analyzing human mental state and emotions using a novel emonet learning model with unconstraint videos},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fraud detection in financial transactions using advanced neural network techniques. <em>IJUFKS</em>, <em>33</em>(5), 573-589. (<a href='https://doi.org/10.1142/S0218488525400057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines a binary classification issue in fraud detection using several neural network methodologies, including the Synthetic Minority Oversampling Technique (SMOTE) and SMOTE combined with Edited Nearest Neighbours (ENN). This work underscores the pressing need for improved detection approaches due to the rising incidence of fraud in financial institutions. Several configurations were tested on a Feedforward Neural Network (FNN) to tackle class imbalance with class weighting, undersampling, oversampling (SMOTE), and SMOTE + ENN SMOTE + ENN SMOTE+ENN . The results demonstrated that SMOTE + ENN SMOTE + ENN SMOTE+ENN successfully addressed the imbalance problem, leading to further investigation of models that integrate SMOTE + ENN SMOTE + ENN SMOTE+ENN with Long Short-Term Memory (LSTM) networks and Random Forest (RF). Finally, a hybrid model combining the balancing techniques of SMOTE + ENN SMOTE + ENN SMOTE+ENN with the neural network architectures of FNN + LSTM FNN + LSTM FNN+LSTM was developed to harness the strengths of both approaches. The FNN + SMOTE + ENN FNN + SMOTE + ENN FNN+SMOTE+ENN achieved an impressive accuracy of 99.99% with an ROC-AUC score of 0.9678, showcasing its strong performance in the classification task. In contrast, the LSTM model reached an accuracy of 99.91% and a ROC-AUC score of 0.9424. While LSTM performed well, it faced challenges in effectively distinguishing the minority class.},
  archive      = {J_IJUFKS},
  author       = {Hye Jin Kim and Rhee Jung Soo},
  doi          = {10.1142/S0218488525400057},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {5},
  pages        = {573-589},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Fraud detection in financial transactions using advanced neural network techniques},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Priority based group key management for secure data transmission in IoT health network with cryptography linked approach. <em>IJUFKS</em>, <em>33</em>(5), 559-572. (<a href='https://doi.org/10.1142/S0218488525400045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The research field in Internet of Things (IoT) is exponentially developing, however yet susceptible to privacy and security risks. Due to resource constraints and decentralized architecture, conventional privacy and security solutions are inoperable for IoT devices. Integrating cryptography and IoT can create a secure environment for data transmission. It is essential to understand the complexities faced in past research before building and executing a cryptography-based approach that can be integrated with IoT. The authentication of each IoT device is required before it can be added to the network. It also enables IoT devices to verify the identity of trustworthy services and smart e-health networks before entrusting them with session and group keys. With mutual authentication between all of the devices in the multicast group, group keys can be safely disseminated for encrypted group communication. There is a growing need for information interchange among patients, providers, and payers, as well as greater usage of digital patient information and stricter regulations, greater consolidation of health practitioners, and improved data security. In order to ensure that electronic health data can be accessed quickly, a multi-key server strategy is employed to distribute the workload among several servers. A new method for managing keys has been proposed to further improve the security of healthcare information. To provide an environment for secure data transmission, a Priority based Group Key Management with Cryptography Linked Approach (PbGKM-CLA) is proposed. The proposed model handles key generation and distribution generated by using the cryptography model. The proposed model is compared with the traditional models and the results exhibit that the proposed model performance is efficient.},
  archive      = {J_IJUFKS},
  author       = {Srilakshmi Puli and Nulaka Srinivasu},
  doi          = {10.1142/S0218488525400045},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {5},
  pages        = {559-572},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Priority based group key management for secure data transmission in IoT health network with cryptography linked approach},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid network with multicategory adversarial feature learning: McAFL fusion. <em>IJUFKS</em>, <em>33</em>(5), 549-558. (<a href='https://doi.org/10.1142/S0218488525400033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of Near-Infrared and visible images is critical in fields such as surveillance, medical imaging, and remote sensing, necessitating high-quality image fusion. The proposed hybrid image fusion network develops a Near-Infrared and visible image fusion system using a multicategory adversarial mechanism within the feature space. Compared to current methods, this approach’s fusion rules are more rational and perform better. An autoencoder network, trained with spatial and channel attention, extracts feature and reconstructs images. A Generative Adversarial Network then derives fusion rules from the trained encoder’s feature space. The hybrid network includes a feature fusion network (generator) that combines features from the source image and a multiclassifier (discriminator) ensuring the fused features match the probability distribution of both Near-Infrared and visible modes. The trained decoder reconstructs the fused image, preserving salient features. Experimental results show the proposed hybrid network surpasses contemporary techniques like GTF, MDLatLRR, DenseFuse, FusionGAN, and U2Fusion in subjective quality.},
  archive      = {J_IJUFKS},
  author       = {Lokesh Gopinath and A. Ruhan Bevi},
  doi          = {10.1142/S0218488525400033},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {5},
  pages        = {549-558},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {A hybrid network with multicategory adversarial feature learning: McAFL fusion},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quasi-chain routing for optimized network participation in wireless sensor networks within obstacle-free IoT ecosystems. <em>IJUFKS</em>, <em>33</em>(5), 537-548. (<a href='https://doi.org/10.1142/S0218488525400021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper delves into optimizing WSNs within the IoT paradigm, addressing the critical issue of coverage holes, which significantly impede network performance. In this work, sensor nodes are randomly placed in a predefined area and sink node is placed in a predefined position. The network is triangulated making use of the special properties of Delaunay Triangulation for the placement of mobile nodes and thus to have improved participation of sensor nodes in the network. Algorithms are introduced by placing the mobile nodes in specially identified positions will improve the participation of nodes in the network, thus making the network contribute with better results. To address the energy management, we introduce semi-chain protocols that significantly prolong network lifespan and reduce complexity. By integrating Delaunay Triangulation in chain construction, we simplify the process of nearest neighbor identification, minimizing the energy expenditure of individual nodes. The synergy of these techniques culminates in a WSN that is both resilient and energy-efficient, ideal for IoT applications where precise and reliable data collection is imperative.},
  archive      = {J_IJUFKS},
  author       = {Sreeram Sivadasan and Govindan Nagarajan},
  doi          = {10.1142/S0218488525400021},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {5},
  pages        = {537-548},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Quasi-chain routing for optimized network participation in wireless sensor networks within obstacle-free IoT ecosystems},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient medical image compression with 2D-DWT-EZW for resource optimization. <em>IJUFKS</em>, <em>33</em>(5), 527-535. (<a href='https://doi.org/10.1142/S021848852540001X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to compress medical images while maintaining their diagnostic quality. The 2D Discrete Wavelet Transform (2D-DWT) and the Embedded Zerotree Wavelet (EZW) algorithms are combined in the method. This paper addresses the EZW algorithm for further compression. Experimentation was performed to determine the optimal keep factor for the 2D-DWT algorithm, which preserves image quality. This paper further involves applying the EZW algorithm to compress the images further. The compression ratio and bits per pixel (BPP) were measured for the final compressed images. The results show that the combination of 2D-DWT and EZW algorithms effectively compresses medical images while preserving their diagnostic quality. The optimal keep factor for 2D-DWT was found to be 50%, resulting in a compression ratio of 1.632 and a BPP of 0.839.},
  archive      = {J_IJUFKS},
  author       = {S. Prayla Shyry and K. C. Prabu Shankar and M. Hema},
  doi          = {10.1142/S021848852540001X},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {5},
  pages        = {527-535},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Efficient medical image compression with 2D-DWT-EZW for resource optimization},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interval methods in knowledge representation. <em>IJUFKS</em>, <em>33</em>(4), 525-526. (<a href='https://doi.org/10.1142/S0218488525970050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJUFKS},
  doi          = {10.1142/S0218488525970050},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {4},
  pages        = {525-526},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Interval methods in knowledge representation},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hampel estimation for uncertain autoregressive model. <em>IJUFKS</em>, <em>33</em>(4), 507-524. (<a href='https://doi.org/10.1142/S0218488525500217'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameter estimation is widely used as an essential branch of uncertain time series, among which the least squares (LSE) estimation is the most representative. Since LSE estimation is ineffective in the presence of outliers, Hampel estimation that its stability solves this problem well. Therefore, in this paper, we use Hampel estimation to calculate the parameters of the uncertain autoregressive (UAR) model. The sum of sample errors (SSE) function is used to determine the parameters in Hampel estimation before fitting the UAR model. In addition, the residuals are analysed, and future trends in the data are predicted. Finally, numerical examples comparing the Hampel estimation with the LSE estimation, the least absolute deviation (LAD) estimation, and the Huber estimation illustrate the validity and stability of the Hampel estimation, as well as its applicability in predicting carbon dioxide emissions in China.},
  archive      = {J_IJUFKS},
  author       = {Xiang Xiao and Yuhong Sheng},
  doi          = {10.1142/S0218488525500217},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {4},
  pages        = {507-524},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Hampel estimation for uncertain autoregressive model},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved sparrow search algorithm with logistic chaotic sequence and crisscross strategy. <em>IJUFKS</em>, <em>33</em>(4), 483-506. (<a href='https://doi.org/10.1142/S0218488525500205'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents the SSALC (enhanced sparrow search algorithm), a novel approach for improving the efficiency of industrial robots. It incorporates logistic chaotic sequences and crisscross strategy optimization. The logistic chaotic sequence generates a more uniformly distributed population, while the nonlinear inertia weight controls the algorithm’s step size. The crisscross strategy enhances the position-updating mechanism, and the horizontal crossover operation improves global optimization capability. Furthermore, the vertical crossover operation allows for dimension mutation in some individuals, reducing susceptibility to local optima. Extensive testing against 11 CEC benchmark functions, complemented by the Wilcoxon rank sum test, confirms the effectiveness of the approach. Results demonstrate the SSALC’s fast convergence, high accuracy, and improved global search ability in addressing both unimodal and multimodal optimization challenges.},
  archive      = {J_IJUFKS},
  author       = {Zhang Lin-Bei-Zi and Chen Lei and Ran Qi-Yu and Liu Yu-Qiang and Nong Wei-Hang and Ding Jiang},
  doi          = {10.1142/S0218488525500205},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {4},
  pages        = {483-506},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {An improved sparrow search algorithm with logistic chaotic sequence and crisscross strategy},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized complex-valued spatio-temporal graph convolutional neural network for sentiment analysis on twitter data. <em>IJUFKS</em>, <em>33</em>(4), 459-482. (<a href='https://doi.org/10.1142/S0218488525500199'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Twitter is one of the popular social media websites. It is a great resource to gain knowledge about other feelings, sentiments, and opinions. Experts developed algorithms to assess the general vibe of tweets and identify positive or negative messages. In this research work, Optimized Complex-Valued Spatio-Temporal Graph Convolutional Neural Network for Sentiment Analysis on Twitter Data (CVSTGCN-SA-TD) is proposed. Here, the input data is gathered from the SST-2 dataset. The input data is fed to the pre-processing stage, where the Multi-Window Savitzky-Golay Filter (MWSGF) removes irrelevant items, such as retweets, punctuation, URLs, symbols, and numbers. Then the preprocessed data is given to Revised Tunable Q-Factor Wavelet Transform (RTQFWT) to extract the relevant features. Then the extracted features are fed into a neural network called CVSTGCN to classify the tweet as positive and negative. Generally, CVSTGCN does not adapt any optimization strategies to determine the optimal parameters to guarantee accurate efficiency of Twitter sentiment analysis. Therefore, High level Target Navigation Pigeon Inspired Optimization (HLTNPIO) is proposed to improve the weight parameter of CVSTGCN that classifies the tweet as positive and negative accurately. The efficiency of the proposed CVSTGCN-SA-TD approach is analyzed under some metrics, like Accuracy, Precision, Recall, Specificity, F1-score, ROC, Computational Time. The proposed CVSTGCN-SA-TD method attains 22.36%, 25.42% and 18.27% better accuracy, 21.36%, 26.42%, 18.27% better recall, 21.36%, 22.42%, 19.27% better precision compared with existing methods: Twitter sentiment analysis depending on elephant herd optimization along hybrid deep learning strategy on online food services (TSA-OFS-EHO), Sentiment analysis utilizing Twitter information: a comparative appliance of lexicon-also machine learning-dependent method (SATD-CAL-ML), Twitter sentiment analysis utilizing ensemble dependent deep learning towards COVID-19 in India and Europe countries (TSA-DL-IEC) respectively.},
  archive      = {J_IJUFKS},
  author       = {S. Jayanthi and S. S. Arumugam},
  doi          = {10.1142/S0218488525500199},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {4},
  pages        = {459-482},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Optimized complex-valued spatio-temporal graph convolutional neural network for sentiment analysis on twitter data},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An accurate stock price prediction using deep recurrent neural network with search and rescue approach. <em>IJUFKS</em>, <em>33</em>(4), 433-457. (<a href='https://doi.org/10.1142/S0218488525500187'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the stock market is crucial for estimating financial time series and organizations’ future values. In the stock market, the situation may change in an instant, and hence, an accurate stock prediction approach is needed. This paper presented an accurate stock price prediction using a deep learning framework with improved optimization approaches. Initially, the data is taken from the National Stock Exchange (NSE) stock dataset. Then, methodological pointers such as the Relative Strength Index (RSI), Exponential Moving Average (EMA), Moving Average Convergence Divergence (MACD), Stochastic Momentum Index (SMI), Commodity Channel Index (CCI), Rate of Change (RoC), Momentum, Williams Percent Range, Moving Average of n days, on balance volume and Stochastic Oscillator are calculated. Afterward, the best features are selected using an adaptive tree growth algorithm. Finally, a hybrid Recurrent Neural Network with Search and Rescue optimization (hybrid RNN-SRO) is proposed to make the closing price prediction. The effectiveness of the suggested method is evaluated in comparison to the various current methods. The proposed stock price prediction methodology provides improved performance in terms of different performance metrics such as accuracy (99.97%), F1-score (99.24%), precision (99.25%), Mean Squared Error (MSE) (0.0027), Mean Absolute Percentage Error (MAPE) (0.0219), Recall (99%), Area Under the receiver operating characteristics Curve (AUC) (99.25%), processing time (3.528 seconds) and Root Mean Squared Error (RMSE) (0.052).},
  archive      = {J_IJUFKS},
  author       = {Parag P. Kadu and G. R. Bamnote},
  doi          = {10.1142/S0218488525500187},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {4},
  pages        = {433-457},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {An accurate stock price prediction using deep recurrent neural network with search and rescue approach},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep neural networks and experience replay in Q-learning extensions: A review. <em>IJUFKS</em>, <em>33</em>(4), 401-432. (<a href='https://doi.org/10.1142/S0218488525500175'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement Learning (RL) is a type of machine learning where actions are learned and taken to solve sequential decision problems. There have been several extensions in the Q-learning algorithm, but more extensions have occurred since the breakthrough of the Deep Q-network algorithm. We study the two pivotal aspects of the DQN algorithm (deep neural network and experience replay) and other related extensions; we focus on experience replay. Our study identifies multiple extensions in network structure, experience sampling strategies, memory managing techniques, and memory structures. We further indicate the extended algorithms’ strengths and weaknesses and suggest future works.},
  archive      = {J_IJUFKS},
  author       = {Richard Sakyi Osei and Daphne Lopez},
  doi          = {10.1142/S0218488525500175},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {4},
  pages        = {401-432},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Deep neural networks and experience replay in Q-learning extensions: A review},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertain refutation information propagation model by considering multiple realistic constraints. <em>IJUFKS</em>, <em>33</em>(4), 381-400. (<a href='https://doi.org/10.1142/S0218488525500163'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The online rumor refutation platform is an important channel for clarifying rumors, and the public obtains relevant debunking information and knows the truth through online rumor refutation platforms. Therefore, it is particularly important to reasonably select and utilize relevant online rumor refutation platforms, which can help the public participate in rumor governance and deepen network ecological governance. However, there are many uncertain factors in the entire process of debunking rumors, such as the promotional debunking abilities of different levels of online rumor refutation platforms, while also considering various practical constraints. In order to consider the influence of uncertain factors during the refutation process to improve the effectiveness of refutation, and explore the applicability of uncertainty theory in practice, this paper studies a new mode of refutation information promotion led by social managers such as the government and collaborated by various online refutation platforms, and proposes an uncertain refutation information propagation (URIP) model by considering multiple realistic constraints. Specifically, we characterize the uncertain factors as uncertain variables in the refutation process, such as the debunking ability of online refutation platforms, and solve for the optimal solution by maximizing the expected value of refutation propagation effectiveness. Subsequently, based on the relevant knowledge of uncertainty theory, we derive an equivalent deterministic model for the URIP model. Finally, in order to enable decision-makers to better apply the URIP model in practice, a numerical example is applied to compare the URIP model proposed in this paper with the URIP model without realistic constraints, which proves the superiority of our model.},
  archive      = {J_IJUFKS},
  author       = {Chunhua Gao and Yang Liu and Yufu Ning and Fengming Liu},
  doi          = {10.1142/S0218488525500163},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {4},
  pages        = {381-400},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Uncertain refutation information propagation model by considering multiple realistic constraints},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Foreword. <em>IJUFKS</em>, <em>33</em>(3), v-vi. (<a href='https://doi.org/10.1142/S0218488525010019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJUFKS},
  author       = {Bernadette Bouchon-Meunier and Jesús Medina-Moreno and Manuel Ojeda-Aciego},
  doi          = {10.1142/S0218488525010019},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {3},
  pages        = {v-vi},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Foreword},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interval methods in knowledge representation. <em>IJUFKS</em>, <em>33</em>(3), 379-380. (<a href='https://doi.org/10.1142/S0218488525970049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJUFKS},
  doi          = {10.1142/S0218488525970049},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {3},
  pages        = {379-380},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Interval methods in knowledge representation},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing cybersecurity in the big data era: A GA-optimized fuzzy clustering approach. <em>IJUFKS</em>, <em>33</em>(3), 353-377. (<a href='https://doi.org/10.1142/S0218488525500151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research Highlights Cybersecurity includes protecting computer networks and systems from unauthorized access, harm, and fraud, employing various techniques and technologies such as barriers, antivirus software, and cryptography. Regular system updates, employee training, and adherence to best practices are crucial for maintaining confidentiality and ensuring reliable IT services in both corporate and public sectors. This paper introduces a GA-AFCM technique, which enhances intrusion detection and cybersecurity tasks by combining the strengths of Genetic Algorithms and Adaptive Fuzzy C-Means Clustering. The study began with data collection and preprocessing using Z-score normalization, followed by feature extraction through Linear Discrimination Analysis (LDA). The GA-AFCM approach was compared with traditional methods such as K-Means, Density Peaks, GMM, and MKKM-IC. The results demonstrate the TPR (91%), FPR (4%) precision (83.56%), accuracy (95.6%), and F1-score (87%) are used to examining and interpreting quickly and dynamically generated data streams efficiently solved by the proposed approach. The GA-AFCM method significantly enhances detection rates to over 95% while substantially reducing false positives, establishing it as a robust solution for cybersecurity in the big data era.},
  archive      = {J_IJUFKS},
  author       = {Tieguang Xu and Can Ma and Zhaozhao Su and Jingqiong Su and Zhiming Ma and Jianzhen Wang and Zhaolong Yang},
  doi          = {10.1142/S0218488525500151},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {3},
  pages        = {353-377},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Enhancing cybersecurity in the big data era: A GA-optimized fuzzy clustering approach},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep FC-IIWO fuzzy clustering: An optimized fuzzy clustering approach for big data clustering. <em>IJUFKS</em>, <em>33</em>(3), 329-352. (<a href='https://doi.org/10.1142/S021848852550014X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A significant role is played by clustering approaches in data mining processes, which becomes more challenging because of the rising dimension of the available databases. Clustering strategies are employed in various sectors like information retrieval, social network analytics, image processing, and so on. Clustering assists the user to understand dissimilarity and similarity among objects. The big data concept has collected incredible attention from various research areas, like government and industry within a short lifetime. In this paper, a Deep Fractional Calculus-Improved Invasive Weed Optimization fuzzy clustering (Deep FC-IIWO fuzzy clustering) based scheme is developed to cluster big data. The map-reduce architecture is employed to tackle the over-fitting obstacles occurring in the clustering of big data. The features are extracted using the mapping function which is followed by clustering in the reducer stage. Furthermore, the selection of features is essential for further clustering process. Here, the Minkowski distance measure is applied for selecting the most prominent features. The approach of clustering is executed with the help of the devised Deep FC-IIWO fuzzy clustering model. The implemented FC-IIWO framework is newly created by integrating Fractional Calculus (FC) and Improved Invasive Weed Optimizer (IIWO). The proposed Deep FC-IIWO fuzzy clustering scheme performed better than other prevailing models concerning the rand coefficient, Jaccard coefficient, and clustering accuracy of 0.9563, 0.9379, and 0.9522, correspondingly.},
  archive      = {J_IJUFKS},
  author       = {D. Sudha and S. Gowri},
  doi          = {10.1142/S021848852550014X},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {3},
  pages        = {329-352},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Deep FC-IIWO fuzzy clustering: An optimized fuzzy clustering approach for big data clustering},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The fuzzy ESL values for a class of cooperative games with fuzzy payoffs. <em>IJUFKS</em>, <em>33</em>(3), 299-327. (<a href='https://doi.org/10.1142/S0218488525500138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a cooperative game with fuzzy payoff value (i.e., fuzzy TU- game), the fuzzy Shapley value is the fuzzy expected value of player marginal contribution, which is also an extension of Shapley value. As the ESL value (satisfying efficiency, symmetry and linearity) is a generalized form of Shapley value for a cooperative game, the relative marginal contribution of player is taken into consideration. Following the ESL value, interaction between coalitions in a fuzzy TU-game is also need to consider. In this study, we extend the fuzzy Shapley value based on the fuzzy payoff value and propose the fuzzy ESL value (i.e., F-ESL value) for a class of fuzzy TU-games. As a generalized form of potential function, a weighted fuzzy potential function to introduced to characterize the F-ESL value. This F-ESL value has a certain degree of flexibility by considering the interaction between coalitions. The proposed fuzzy ESL value is generalized value for a class of fuzzy TU-games, including the Shapley value, the ESL value, and the fuzzy Shapley value, which has a wider range of applications.},
  archive      = {J_IJUFKS},
  author       = {Yu Xiaohui and Wu You and Wang Chenglin},
  doi          = {10.1142/S0218488525500138},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {3},
  pages        = {299-327},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {The fuzzy ESL values for a class of cooperative games with fuzzy payoffs},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy median graph and its application in the deployment of wireless sensor networks. <em>IJUFKS</em>, <em>33</em>(3), 279-298. (<a href='https://doi.org/10.1142/S0218488525500126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Median graphs represent a unique category of graphs with significant importance in distance-related concepts within graph theory. This paper aims to expand the concept of median graphs into fuzzy graph theory and investigate whether every fuzzy tree belongs to the classification of the fuzzy median graph. Furthermore, this study characterizes the strong edges in a fuzzy graph using median sets. Additionally, the work delves into the impact of removing bridges and cutvertices on a fuzzy median graph. Finally, the paper proposes a novel model rooted in the concept of the fuzzy median graph for deploying wireless sensors, which is meticulously compared with the widely used branch and bound algorithm. The proposed model demonstrates superior performance in significantly reducing the inter-sensor distances.},
  archive      = {J_IJUFKS},
  author       = {Anandhu Mohan and M.V. Dhanyamol},
  doi          = {10.1142/S0218488525500126},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {3},
  pages        = {279-298},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Fuzzy median graph and its application in the deployment of wireless sensor networks},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On strict convergence in measure theorems for seminormed and semiconormed fuzzy integrals. <em>IJUFKS</em>, <em>33</em>(3), 257-278. (<a href='https://doi.org/10.1142/S0218488525500114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide several strict convergence in measure theorems for the seminormed and semiconormed fuzzy integrals. These results are finer in comparison with the strict convergence in measure theorem which has been previously studied.},
  archive      = {J_IJUFKS},
  author       = {Do Huy Hoang and Truong Thi Nhan and Pham Thanh Son and Dao Van Duong and Tran Nhat Luan},
  doi          = {10.1142/S0218488525500114},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {3},
  pages        = {257-278},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {On strict convergence in measure theorems for seminormed and semiconormed fuzzy integrals},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interval methods in knowledge representation. <em>IJUFKS</em>, <em>33</em>(2), 255-256. (<a href='https://doi.org/10.1142/S0218488525970037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJUFKS},
  doi          = {10.1142/S0218488525970037},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {2},
  pages        = {255-256},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Interval methods in knowledge representation},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Acknowledgements to the referees. <em>IJUFKS</em>, <em>33</em>(2), 253-254. (<a href='https://doi.org/10.1142/S0218488525970025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJUFKS},
  doi          = {10.1142/S0218488525970025},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {2},
  pages        = {253-254},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Acknowledgements to the referees},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). V-SVR with imprecise observations. <em>IJUFKS</em>, <em>33</em>(2), 235-252. (<a href='https://doi.org/10.1142/S0218488525500102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector regression (SVR) has been widely used in academia and industry with excellent performance. Crisp data always be trained by classic SVR and its varieties. However, classic SVR is feeble if data are imprecise or low-quality. Hence, the uncertainty theory emerged as the times require, which can process the imprecise observations well. In this study, a novel SVR model be introduced into uncertainty theory, termed v -SVR with imprecise observations, designed to handle imprecise or low-quality data. Unlike the conventional ε -SVR with imprecise observations approach, v -SVR offers an automated computation of the accuracy parameter ε , thereby eliminating the need for manual selection. This results in improved performance with simplified parameter tuning. The effectiveness of the approach in this paper be demonstrated through a numerical example.},
  archive      = {J_IJUFKS},
  author       = {Hao Zhang and Yuhong Sheng},
  doi          = {10.1142/S0218488525500102},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {2},
  pages        = {235-252},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {V-SVR with imprecise observations},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Entropic semi-supervised dimensionality reduction for distance metric learning. <em>IJUFKS</em>, <em>33</em>(2), 219-234. (<a href='https://doi.org/10.1142/S0218488525500096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distance metric learning and nonlinear dimensionality reduction are intrinsically related, since they are both different perspectives of the same fundamental problem: to learn compact and meaningful data representations for classification and visualization. In this paper, we propose a graph-based generalization of Semi-Supervised Dimensionality Reduction (SSDR) algorithm that uses stochastic distances (Kullback-Leibler, Bhattacharyya and Cauchy-Schwarz divergences) to compute the similarity between local multivariate Gaussian distributions along the K Nearest Neighbors (KNN) graph build from the samples in the input high-dimensional space. In summary, there are two variants of the proposed method: one which uses only a fraction of the labeled samples (10%) and another that also uses a clustering method (Gaussian Mixture Models) to estimate the labels of the minimum spanning tree of the KNN graph, incorporating more information into the process. Experimental results with several real datasets show that the proposed method is able to improve the classification accuracy of several supervised classifiers and also the quality of the obtained clusters (Silhouette Coefficients) in comparison to the regular SSDR algorithm, making it a viable alternative for pattern classification problems.},
  archive      = {J_IJUFKS},
  author       = {Alexandre L. M. Levada},
  doi          = {10.1142/S0218488525500096},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {2},
  pages        = {219-234},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Entropic semi-supervised dimensionality reduction for distance metric learning},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bi-level alternating meta-learning for recurring concept on evolving data streams instructions for typing. <em>IJUFKS</em>, <em>33</em>(2), 193-217. (<a href='https://doi.org/10.1142/S0218488525500084'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans’ learning involves remembering patterns of the past to better understand recurring concepts as their knowledge grows. However, a key issue that arises from these cases is that previous knowledge in deep neural networks could be gradually forgotten when they are trained for a new concept. We address this problem by learning a general representation that can remember the previous information and promote future learning. In this pursuit, a new controller is introduced by the meta-learning strategy that guides the network to keep the balance between the previously learned concepts and the new concept, hence it avoids catastrophic forgetting. Compared to previous online incremental learning for evolving data streams, our approach is dedicated to handling recurring concepts. When encountering recurring concepts, the model can remember and recall the previous knowledge and can quickly adapt to this change. In this paper, we propose a Bi-level Alternating Meta-learning approach for recurring concepts (BLAML), which emphasizes the hidden representation learning of different concepts in model-level learning, and obtains a set of shared parameters through the global meta-learning strategy. Through extensive experiments, the effectiveness of the proposed method is proved.},
  archive      = {J_IJUFKS},
  author       = {Jian-Wei Liu and Si-Si Zhang and Zhong-Lin Bao},
  doi          = {10.1142/S0218488525500084},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {2},
  pages        = {193-217},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {A bi-level alternating meta-learning for recurring concept on evolving data streams instructions for typing},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An unconstrained primal based twin parametric insensitive support vector regression. <em>IJUFKS</em>, <em>33</em>(2), 173-192. (<a href='https://doi.org/10.1142/S0218488525500072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an efficient regression algorithm based on primal formulation of twin support vector machine. This is an efficient approach to solve the optimization problem leading to reduced computation time. The proposed method is termed as twin parametric insensitive support vector regression (UPTPISVR). The optimization problems of the proposed (UPTPISVR) are a pair of unconstrained convex minimization problems. Moreover, the objective functions of UPTPISVR are strongly convex, differentiable and piecewise quadratic. Therefore, an approximate solution is obtained in primal variables instead of solving the dual formulation. Further, an absolute value equation problem is solved by using a functional iterative algorithm for UPTPISVR, termed as FUPTPISVR. The objective function of the proposed formulation involves the plus function which is non-smooth and therefore, smooth approximation functions are used to replace the plus function, termed as SUPTPISVR. The Newton-Armijo algorithm is then used to iteratively obtain the solutions, thus eliminates the requirement of any optimization toolbox. Various numerical experiments on synthetic and benchmark real-world datasets are presented for justifying the applicability and effectiveness of the proposed UPTPISVR. The results clearly indicate that the proposed algorithms outperform the existing algorithms in terms of root mean square error (RMSE) on most datasets.},
  archive      = {J_IJUFKS},
  author       = {Deepak Gupta and Bharat Richhariya and Parashjyoti Borah},
  doi          = {10.1142/S0218488525500072},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {2},
  pages        = {173-192},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {An unconstrained primal based twin parametric insensitive support vector regression},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple item support constraints based frequent pattern mining using dynamic prefix tree. <em>IJUFKS</em>, <em>33</em>(2), 143-172. (<a href='https://doi.org/10.1142/S0218488525500060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The structural complexity of the pattern mining algorithm depends on the types of datasets. Even though they are highly connected, it can be intriguing to identify patterns in some application areas where they do not usually occur. FP tree construction practice with traversal of conditional pattern base with conditional FP Tree, with path traversing, to address the issue of massive memory and time usage. The creation of a non-recursive single-label dynamic prefix tree with a rule generation method utilizing multiple-item support restrictions is the paper’s significant contribution. The effectiveness of our proposed method is also compared to the FP tree and state-of-the-art TIS tree on various datasets in terms of time and memory complexity.},
  archive      = {J_IJUFKS},
  author       = {Sudarsan Biswas and Diganta Saha and Rajat Pandit},
  doi          = {10.1142/S0218488525500060},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {2},
  pages        = {143-172},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Multiple item support constraints based frequent pattern mining using dynamic prefix tree},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interval methods in knowledge representation. <em>IJUFKS</em>, <em>33</em>(1), 141-142. (<a href='https://doi.org/10.1142/S0218488525970013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJUFKS},
  author       = {Vladik Kreinovich},
  doi          = {10.1142/S0218488525970013},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {1},
  pages        = {141-142},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Interval methods in knowledge representation},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Risk index based uncertain portfolio selection with monotone increasing multiplicative background risk. <em>IJUFKS</em>, <em>33</em>(1), 119-140. (<a href='https://doi.org/10.1142/S0218488525500059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Investors usually invest not only in risky assets but also in risk-free assets and face not only portfolio risk but also background risk. This paper discusses an uncertain portfolio selection problem in risky assets and risk-free assets with monotone increasing multiplicative background risk (MBR), which is prevalent but less research has been done. To do so, we first propose an uncertain mean-risk index model based on uncertainty theory where the security return and MBR are regarded as uncertain variables and give the deterministic form of the model. Then for further analysis, we discuss the critical constraint and optimality condition of the model. Based on the discussion, we study the influence of uncertain MBR on the investors’ decisions. Finally, we provide the case analysis to illustrate the application of our method and the analysis results.},
  archive      = {J_IJUFKS},
  author       = {Di Ma and Xiaoxia Huang and Kwang-Il Choe},
  doi          = {10.1142/S0218488525500059},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {1},
  pages        = {119-140},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Risk index based uncertain portfolio selection with monotone increasing multiplicative background risk},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ICE: Incremental subspace clustering of high-dimensional categorical data. <em>IJUFKS</em>, <em>33</em>(1), 87-118. (<a href='https://doi.org/10.1142/S0218488525500047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subspace clustering is an effective way to analyze high-dimensional data. The main problems of the conventional subspace clustering techniques are as follows: first, conventional clustering methods can not describe categorical attribute space in more detail; second, most subspace-clustering techniques failure to process dynamic data effectively; finally, lack of effective noise recognition leads to the decline of the efficiency of incremental subspace-clustering analysis. We address the above problems by an incremental subspace-clustering algorithm — called ICE . With attribute subspace constructed by a rough set-based weight computing method, ICE obtains clustering results through initial and incremental clustering stage. Utilizing the original cluster results generated from initial clustering stage, we adopt merging and splitting operation to dynamic adjust cluster-structure in incremental clustering stage. Before achieving the final results, a polymerization-based noise recognition technique is employed to automatically identify noise from sparse clusters without human threshold intervention. We implement ICE on synthetic and real-world datasets. The experimental results reveal that incremental subspace-clustering method can achieves satisfactory performance on extensibility, accuracy and robustness.},
  archive      = {J_IJUFKS},
  author       = {Ning Pang and Chaowei Zhang and Jifu Zhang and Xiao Qin},
  doi          = {10.1142/S0218488525500047},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {1},
  pages        = {87-118},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {ICE: Incremental subspace clustering of high-dimensional categorical data},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized feature selection approach with elicit conditional generative adversarial network based class balancing approach for multimodal sentiment analysis in car reviews. <em>IJUFKS</em>, <em>33</em>(1), 55-86. (<a href='https://doi.org/10.1142/S0218488525500035'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Sentiment Analysis (MSA) is a growing area of emotional computing that involves analyzing data from three different modalities. Gathering data from Multimodal Sentiment analysis in Car Reviews (MuSe-CaR) is challenging due to data imbalance across modalities. To address this, an effective data augmentation approach is proposed by combining dynamic synthetic minority oversampling with a multimodal elicitation conditional generative adversarial network for emotion recognition using audio, text, and visual data. The balanced data is then fed into a granular elastic-net regression with a hybrid feature selection method based on dandelion fick’s law optimization to analyze sentiments. The selected features are input into a multilabel wavelet convolutional neural network to classify emotion states accurately. The proposed approach, implemented in python, outperforms existing methods in terms of trustworthiness (0.695), arousal (0.723), and valence (0.6245) on the car review dataset. Additionally, the feature selection method achieves high accuracy (99.65%), recall (99.45%), and precision (99.66%). This demonstrates the effectiveness of the proposed MSA approach, even with three modalities of data.},
  archive      = {J_IJUFKS},
  author       = {Sri Raman Kothuri and N. R. Rajalakshmi},
  doi          = {10.1142/S0218488525500035},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {1},
  pages        = {55-86},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Optimized feature selection approach with elicit conditional generative adversarial network based class balancing approach for multimodal sentiment analysis in car reviews},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An intelligent optimized compression framework for columnar database. <em>IJUFKS</em>, <em>33</em>(1), 29-53. (<a href='https://doi.org/10.1142/S0218488525500023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instead of storing data in rows, a columnar database is a type of Database Management System (DBMS). To speed up the processing and reply to a question, a columnar database’s job is to efficiently write and read data to and from hard disc storage. One of the most crucial methods in the creation of column-oriented database systems is compression. For columns with Zero-length string types, all heavier and light-in-weight compression techniques have limitations. Processing of transactions online, these databases are substantially more effective for online analytical processing than for online transactional processing. This indicates that although they are made to examine transactions, they are not very effective at updating them. To overcome these issues a Zero Length Recurrent based Fruit Fly Optimization (ZLRFF) model is used. Additionally, a reduction technique is known as ZLRFF was designed to achieve a high compression ratio and allow straight lookups on compressed material without decompression first. ZLRFF’s main goal is to divide a Zero-length string written column vertically into smaller columns that can each be compressed using a separate lightweight compression technique. To search directly on compressed data, we also provide a search technique we call FF-search. Extensive testing demonstrates that ZLRFF supports direct searching on compressed data in addition to achieving a decent compression ratio, which enhances query performance.},
  archive      = {J_IJUFKS},
  author       = {B. A. Jadhawar and Narendra Sharma},
  doi          = {10.1142/S0218488525500023},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {1},
  pages        = {29-53},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {An intelligent optimized compression framework for columnar database},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and development of schema for schemaless databases. <em>IJUFKS</em>, <em>33</em>(1), 1-28. (<a href='https://doi.org/10.1142/S0218488525500011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A schema database functions as a repository for interconnected data points, facilitating comprehension of data structures by organizing information into tables with rows and columns. These databases utilize established connections to arrange data, with attribute values linking related tuples. This integrated approach to data management and distributed processing enables schema databases to maintain models even when the working set size surpasses available RAM. However, challenges such as data quality, storage, scarcity of data science professionals, data validation, and sourcing from diverse origins persist. Notably, while schema databases excel at reviewing transactions, they often fall short in updating them effectively. To address these issues, a Chimp-based radial basis neural model (CbRBNM) is employed. Initially, the Schemaless database was considered and integrated into the Python system. Subsequently, compression functions were applied to both schema and schema-less databases to optimize relational data size by eliminating redundant files. Performance validation involved calculating compression parameters, with the proposed method achieving memory usage of 383.37 Mb, a computation time of 0.455 s, a training time of 167.5 ms, and a compression rate of 5.60%. Extensive testing demonstrates that CbRBNM yields a favorable compression ratio and enables direct searching on compressed data, thereby enhancing query performance.},
  archive      = {J_IJUFKS},
  author       = {Ashwini Mandale and Neeraj Sharma},
  doi          = {10.1142/S0218488525500011},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Design and development of schema for schemaless databases},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="wsarai">WSARAI - 2</h2>
<ul>
<li><details>
<summary>
(2025). An overview of trustworthy and sustainable AI development for catalyst screening: The role of explainable AI (XAI). <em>WSARAI</em>, <em>3</em>, 2540002. (<a href='https://doi.org/10.1142/S2811032325400028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significance of predicting the trustworthiness of Explainable Artificial Intelligence (XAI) in the context of sustainable AI-based catalyst screening lies in ensuring the reliability and interpretability of AI-driven decisions in catalysis research. Trustworthy XAI can enhance the transparency and accountability of AI models, crucial for gaining the confidence of scientists and stakeholders in the findings. By accurately predicting the performance and reliability of catalysts, XAI aids in identifying the most promising candidates efficiently, reducing the need for extensive experimental trials, thus saving time and resources. Moreover, trustworthy XAI facilitates better understanding of the underlying mechanisms driving catalyst performance, leading to more informed and targeted research directions. In sustainable AI-based catalyst screening, where environmental and economic considerations are paramount, the integration of XAI ensures that AI models are not only accurate but also aligned with sustainable development goals. This fosters the development of greener and more efficient catalytic processes, ultimately contributing to the advancement of sustainable technologies. The ability to predict and ensure the trustworthiness of XAI in catalyst screening thus represents a critical step towards leveraging AI for sustainable and impactful scientific advancements. This review discusses various techniques commonly used in sustainable AI for catalyst screening, highlighting different XAI methods with their benefits and drawbacks in the catalyst screening process. It suggests integrating multiple XAI tools to overcome individual limitations and presents significant findings in catalyst screening. The review also addresses challenges and explores future directions in this field.},
  archive      = {J_WSARAI},
  author       = {Nirmala Parisutham},
  doi          = {10.1142/S2811032325400028},
  journal      = {World Scientific Annual Review of Artificial Intelligence},
  pages        = {2540002},
  shortjournal = {World Sci. Ann. Rev. Artif. Intell.},
  title        = {An overview of trustworthy and sustainable AI development for catalyst screening: The role of explainable AI (XAI)},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient training of deep neural operator networks via randomized sampling. <em>WSARAI</em>, <em>3</em>, 2540001. (<a href='https://doi.org/10.1142/S2811032325400016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural operators (NOs) employ deep neural networks to learn the mappings between infinitedimensional function spaces. Deep operator network (DeepONet), a popular NO architecture, has demonstrated success in the real-time prediction of complex dynamics across various scientific and engineering applications. In this work, we introduce a random sampling technique to be adopted during the training of DeepONet, aimed at improving the generalization ability of the model, while significantly reducing the computational time. The proposed approach targets the trunk network of the DeepONet model that outputs the basis functions corresponding to the spatiotemporal locations of the bounded domain on which the physical system is defined. While constructing the loss function, DeepONet training traditionally considers a uniform grid of spatiotemporal points at which all the output functions are evaluated for each iteration. This approach leads to a larger batch size, resulting in poor generalization and increased memory demands, due to the limitations of the stochastic gradient descent (SGD) optimizer. The proposed random sampling over the inputs of the trunk net mitigates these challenges, improving generalization and reducing the memory requirements during training, resulting in significant computational gains. We validate our hypothesis through three benchmark examples, demonstrating substantial reductions in training time while achieving comparable or lower overall test errors relative to the traditional training approach. Our results indicate that incorporating randomization in the trunk network inputs during training enhances the efficiency and robustness of DeepONet, offering a promising avenue for improving the framework’s performance in modeling complex physical systems.},
  archive      = {J_WSARAI},
  author       = {Sharmila Karumuri and Lori Graham-Brady and Somdatta Goswami},
  doi          = {10.1142/S2811032325400016},
  journal      = {World Scientific Annual Review of Artificial Intelligence},
  pages        = {2540001},
  shortjournal = {World Sci. Ann. Rev. Artif. Intell.},
  title        = {Efficient training of deep neural operator networks via randomized sampling},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
