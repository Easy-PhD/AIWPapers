<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJNS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijns">IJNS - 62</h2>
<ul>
<li><details>
<summary>
(2025). Multi-layer feature cascade fusion spiking neural network for object detection. <em>IJNS</em>, <em>35</em>(11), 2550063. (<a href='https://doi.org/10.1142/S0129065725500637'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs), as a biologically inspired computational model, have garnered significant attention in object detection and image classification due to their event-driven mechanism and low-power characteristics. However, in object detection tasks, the residual structures in conventional networks introduce nonspiking operations, posing a critical challenge for SNNs. To address this issue, we propose a multi-layer feature cascade fusion SNN (MFCF-SNN) for object detection. During feature extraction, our novel multi-level cascaded feature extraction module replaces residual connections with cascade operations, eliminating nonspiking computations while enhancing gradient propagation to deeper layers. For downsampling, we introduce a pooling-convolution module that combines max-pooling and spiking convolution, effectively preserving feature information and improving gradient flow. These two modules collectively ensure pure spike-based computation while facilitating deep network training, thereby enhancing detection accuracy. Experimental results on the PASCAL VOC 2012 and SSDD datasets demonstrate state-of-the-art performance, validating the effectiveness of our approach in advancing SNN-based object detection.},
  archive      = {J_IJNS},
  author       = {Yongqiang Ma and Bailin Guo and Xuetao Zhang},
  doi          = {10.1142/S0129065725500637},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2550063},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Multi-layer feature cascade fusion spiking neural network for object detection},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Matrix representation of virus machines and an application to the discrete logarithm problem. <em>IJNS</em>, <em>35</em>(11), 2550049. (<a href='https://doi.org/10.1142/S0129065725500492'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virus machines, which develop models of computation inspired by biological processes and the spread of viruses among hosts, deviate from the traditional methods. These virus machines are recognized for their computational power (functioning as algorithms) and their ability to tackle computationally difficult problems. In this paper, we introduce a new extension of the matrix-based representation of virus machines. In this way, hosts, the number of viruses and the instructions to control virus transmission are represented as vectors and matrices, describing the computations of virus machines by linear algebra operations. We also use our matrix representation to show invariants, useful in the proofs, of such machines. In addition, an explicit example is shown to clarify the computation and invariants using the representation. That is, a virus machine that computes the discrete logarithm, which relies on the presumed intractability of cryptosystems such the digital signature algorithm.},
  archive      = {J_IJNS},
  author       = {Antonio Ramírez-de-Arellano and David Orellana-Martín and Mario J. Pérez-Jiménez and Francis George C. Cabarle and Henry N. Adorna},
  doi          = {10.1142/S0129065725500492},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2550049},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Matrix representation of virus machines and an application to the discrete logarithm problem},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A salient object detection network enhanced by nonlinear spiking neural systems and transformer. <em>IJNS</em>, <em>35</em>(11), 2550045. (<a href='https://doi.org/10.1142/S0129065725500455'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although a variety of deep learning-based methods have been introduced for Salient Object Detection (SOD) to RGB and Depth (RGB-D) images, existing approaches still encounter challenges, including inadequate cross-modal feature fusion, significant errors in saliency estimation due to noise in depth information, and limited model generalization capabilities. To tackle these challenges, this paper introduces an innovative method for RGB-D SOD, TranSNP-Net, which integrates Nonlinear Spiking Neural P (NSNP) systems with Transformer networks. TranSNP-Net effectively fuses RGB and depth features by introducing an enhanced feature fusion module (SNPFusion) and an attention mechanism. Unlike traditional methods, TranSNP-Net leverages fine-tuned Swin (shifted window transformer) as its backbone network, significantly improving the model’s generalization performance. Furthermore, the proposed hierarchical feature decoder (SNP-D) notably enhances accuracy in complex scenes where depth noise is prevalent. According to the experimental findings, the mean scores for the four metrics S-measure, F-measure, E-measure and MEA on the six RGB-D benchmark datasets are 0.9328, 0.9356, 0.9558 and 0.0288. TranSNP-Net achieves superior performance compared to 14 leading methods in six RGB-D benchmark datasets.},
  archive      = {J_IJNS},
  author       = {Wang Li and Meichen Xia and Hong Peng and Zhicai Liu and Jun Guo},
  doi          = {10.1142/S0129065725500455},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2550045},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A salient object detection network enhanced by nonlinear spiking neural systems and transformer},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear spiking neural systems for thermal image semantic segmentation networks. <em>IJNS</em>, <em>35</em>(11), 2550038. (<a href='https://doi.org/10.1142/S0129065725500388'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thermal and RGB images exhibit significant differences in information representation, especially in low-light or nighttime environments. Thermal images provide temperature information, complementing the RGB images by restoring details and contextual information. However, the spatial discrepancy between different modalities in RGB-Thermal (RGB-T) semantic segmentation tasks complicates the process of multimodal feature fusion, leading to a loss of spatial contextual information and limited model performance. This paper proposes a channel-space fusion nonlinear spiking neural P system model network (CSPM-SNPNet) to address these challenges. This paper designs a novel color-thermal image fusion module to effectively integrate features from both modalities. During decoding, a nonlinear spiking neural P system is introduced to enhance multi-channel information extraction through the convolution of spiking neural P systems (ConvSNP) operations, fully restoring features learned in the encoder. Experimental results on public datasets MFNet and PST900 demonstrate that CSPM-SNPNet significantly improves segmentation performance. Compared with the existing methods, CSPM-SNPNet achieves a 0.5% improvement in mIOU on MFNet and 1.8% on PST900, showcasing its effectiveness in complex scenes.},
  archive      = {J_IJNS},
  author       = {Peng Wang and Minglong He and Hong Peng and Zhicai Liu},
  doi          = {10.1142/S0129065725500388},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2550038},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Nonlinear spiking neural systems for thermal image semantic segmentation networks},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the computational complexity of spiking neural membrane systems with colored spikes. <em>IJNS</em>, <em>35</em>(11), 2550035. (<a href='https://doi.org/10.1142/S0129065725500352'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural P Systems are parallel and distributed computational models inspired by biological neurons, emerging from membrane computing and applied to solving computationally difficult problems. This paper focuses on the computational complexity of such systems using neuron division rules and colored spikes for the SAT problem. We prove a conjecture stated in a recent paper, showing that enhancing the model with an input module reduces computing time. Additionally, we prove that the inclusion of budding rules extends the model’s capability to solve all problems in the complexity class PSPACE . These findings advance research on Spiking Neural P Systems and their application to complex problems; however, whether both budding rules and division rules are required to extend these methods to problem domains beyond the NP class remains an open question.},
  archive      = {J_IJNS},
  author       = {Antonio Grillo and Claudio Zandron},
  doi          = {10.1142/S0129065725500352},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2550035},
  shortjournal = {Int. J. Neural Syst.},
  title        = {On the computational complexity of spiking neural membrane systems with colored spikes},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward a biologically plausible SNN-based associative memory with context-dependent hebbian connectivity. <em>IJNS</em>, <em>35</em>(11), 2550027. (<a href='https://doi.org/10.1142/S0129065725500273'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a spiking neural network model with Hebbian connectivity for implementing energy-efficient associative memory, whose activity is determined by input stimuli. The model consists of three interacting layers of Hodgkin–Huxley–Mainen spiking neurons with excitatory and inhibitory synaptic connections. Information patterns are stored in memory using a symmetric Hebbian matrix and can be retrieved in response to a specific stimulus pattern. Binary images are encoded using in-phase and anti-phase oscillations relative to a global clock signal. Utilizing the phase-locking effect allows for cluster synchronization of neurons (both on the input and output layers). Interneurons in the intermediate layer filter signal propagation pathways depending on the context of the input layer, effectively engaging only a portion of the synaptic connections within the Hebbian matrix for recognition. The stability of the oscillation phase is investigated for both in-phase and anti-phase synchronization modes when recognizing direct and inverse images. This context-dependent effect opens promising avenues for the development of analog hardware circuits for energy-efficient neurocomputing applications, potentially leading to breakthroughs in artificial intelligence and cognitive computing.},
  archive      = {J_IJNS},
  author       = {S. Yu. Makovkin and S. Yu. Gordleeva and I. A. Kastalskiy},
  doi          = {10.1142/S0129065725500273},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2550027},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Toward a biologically plausible SNN-based associative memory with context-dependent hebbian connectivity},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Introduction. <em>IJNS</em>, <em>35</em>(11), 2502003. (<a href='https://doi.org/10.1142/S0129065725020034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJNS},
  author       = {Marian Gheorghe and Alberto Leporati and Ferrante Neri and David Orellana Martín and Mario J. Pérez-Jiménez},
  doi          = {10.1142/S0129065725020034},
  journal      = {International Journal of Neural Systems},
  number       = {11},
  pages        = {2502003},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Introduction},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stability-aware dual-head network with prototype-based consistency for semi-supervised medical image segmentation. <em>IJNS</em>, <em>35</em>(10), 2550054. (<a href='https://doi.org/10.1142/S0129065725500546'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised semantic segmentation for medical images has evolved through time. While it can leverage the unlabeled data to significantly improve the segmentation performance, it still suffers the problems of intra-class variance and the consequent class-domain distribution misalignment along with costly training. In this paper, a stability-aware dual-head architecture is proposed to synergize prototype-based and Fully Convolutional Network (FCN) methodologies. By integrating prototype-based method for feature consistency and FCN method for spatial detail preservation, our method enforces consistency between different feature representations. It combines the semantic consistency of prototype learning with the precision of dense prediction. A sample-level stability-aware adaptive augmentation strategy is introduced to further mitigate intra-class variance and distribution shifts. The following certainty guided fusion process dynamically refines the pseudo-labels, better utilizing the advantages in different methods. Experiments on BraTS2019 and LA Heart demonstrate State-Of-The-Art (SOTA) performance, achieving significant improvements over the previous SOTA methods on multiple metrics. The framework effectively bridges domain gaps and enhances pseudo-label reliability for medical image analysis. (Code is available at https://github.com/Alfredzly/SDNP ).},
  archive      = {J_IJNS},
  author       = {Leyi Zhang and Jiayi Li and Yu Yan and Xiaolong Xu and Lei Zhang},
  doi          = {10.1142/S0129065725500546},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2550054},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A stability-aware dual-head network with prototype-based consistency for semi-supervised medical image segmentation},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Expanding domain-specific datasets with stable diffusion generative models for simulating myocardial infarction. <em>IJNS</em>, <em>35</em>(10), 2550052. (<a href='https://doi.org/10.1142/S0129065725500522'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Areas, such as the identification of human activity, have accelerated thanks to the immense development of artificial intelligence (AI). However, the lack of data is a major obstacle to even faster progress. This is particularly true in computer vision, where training a model typically requires at least tens of thousands of images. Moreover, when the activity a researcher is interested in is far from the usual, such as falls, it is difficult to have a sufficiently large dataset. An example of this could be the identification of people suffering from a heart attack. In this sense, this work proposes a novel approach that relies on generative models to extend image datasets, adapting them to generate more domain-relevant images. To this end, a refinement to stable diffusion models was performed using low-rank adaptation. A dataset of 100 images of individuals simulating infarct situations and neutral poses was created, annotated, and used. The images generated with the adapted models were evaluated using learned perceptual image patch similarity to test their closeness to the target scenario. The results obtained demonstrate the potential of synthetic datasets, and in particular the strategy proposed here, to overcome data sparsity in AI-based applications. This approach can not only be more cost-effective than building a dataset in the traditional way, but also reduces the ethical concerns of its applicability in smart environments, health monitoring, and anomaly detection. In fact, all data are owned by the researcher and can be added and modified at any time without requiring additional permissions, streamlining their research.},
  archive      = {J_IJNS},
  author       = {Gabriel Rojas-Albarracín and António Pereira and Antonio Fernández-Caballero and María T. López},
  doi          = {10.1142/S0129065725500522},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2550052},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Expanding domain-specific datasets with stable diffusion generative models for simulating myocardial infarction},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dominant classifier-assisted hybrid evolutionary multi-objective neural architecture search. <em>IJNS</em>, <em>35</em>(10), 2550051. (<a href='https://doi.org/10.1142/S0129065725500510'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Architecture Search (NAS) automates the design of deep neural networks but remains computationally expensive, particularly in multi-objective settings. Existing predictor-assisted evolutionary NAS methods suffer from slow convergence and rank disorder, which undermines prediction accuracy. To overcome these limitations, we propose CHENAS: a Classifier-assisted multi-objective Hybrid Evolutionary NAS framework. CHENAS combines the global exploration of evolutionary algorithms with the local refinement of gradient-based optimization to accelerate convergence and enhance solution quality. A novel dominance classifier predicts Pareto dominance relationships among candidate architectures, reframing multi-objective optimization as a classification task and mitigating rank disorder. To further improve efficiency, we employ a contrastive learning-based autoencoder that maps architectures into a continuous, structured latent space tailored for dominance prediction. Experiments on several benchmark datasets demonstrate that CHENAS outperforms state-of-the-art NAS approaches in identifying high-performing architectures across multiple objectives. Future work will focus on improving the computational efficiency of the framework and extending it to other application domains.},
  archive      = {J_IJNS},
  author       = {Yu Xue and Keyu Liu and Ferrante Neri},
  doi          = {10.1142/S0129065725500510},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2550051},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Dominant classifier-assisted hybrid evolutionary multi-objective neural architecture search},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A contrastive learning-enhanced residual network for predicting epileptic seizures using EEG signals. <em>IJNS</em>, <em>35</em>(10), 2550050. (<a href='https://doi.org/10.1142/S0129065725500509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The models used to predict epileptic seizures based on electroencephalogram (EEG) signals often encounter substantial challenges due to the requirement for large, labeled datasets and the inherent complexity of EEG data, which hinders their robustness and generalization capability. This study proposes CLResNet, a framework for predicting epileptic seizures, which combines contrastive self-supervised learning with a modified deep residual neural network to address the above challenges. In contrast to traditional models, CLResNet uses unlabeled EEG data for pre-training to extract robust feature representations. It is then fine-tuned on a smaller labeled dataset to significantly reduce its reliance on labeled data while improving its efficiency and predictive accuracy. The contrastive learning (CL) framework enhances the ability of the model to distinguish between preictal and interictal states, thus improving its robustness and generalizability. The architecture of CLResNet contains residual connections that enable it to learn deep features of the data and ensure an efficient gradient flow. The results of the evaluation of the model on the CHB-MIT dataset showed that it outperformed prevalent methods in the field, with an accuracy of 92.97%, sensitivity of 94.18%, and false-positive rate of 0.043/h. On the Siena dataset, the model also achieved competitive performance, with an accuracy of 92.79%, a sensitivity of 91.47%, and a false-positive rate of 0.041/h. These results confirm the effectiveness of CLResNet in addressing variations in EEG data, and show that contrastive self-supervised learning is a robust and accurate approach for predicting seizures.},
  archive      = {J_IJNS},
  author       = {Longfei Qi and Shasha Yuan and Feng Li and Junliang Shang and Juan Wang and Shihan Wang},
  doi          = {10.1142/S0129065725500509},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2550050},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A contrastive learning-enhanced residual network for predicting epileptic seizures using EEG signals},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised brain MRI anomaly detection via inter-realization channels. <em>IJNS</em>, <em>35</em>(10), 2550047. (<a href='https://doi.org/10.1142/S0129065725500479'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate anomaly detection in brain Magnetic Resonance Imaging (MRI) is crucial for early diagnosis of neurological disorders, yet remains a significant challenge due to the high heterogeneity of brain abnormalities and the scarcity of annotated data. Traditional one-class classification models require extensive training on normal samples, limiting their adaptability to diverse clinical cases. In this work, we introduce MadIRC, an unsupervised anomaly detection framework that leverages Inter-Realization Channels (IRC) to construct a robust nominal model without any reliance on labeled data. We extensively evaluate MadIRC on brain MRI as the primary application domain, achieving a localization AUROC of 0.96 outperforming state-of-the-art supervised anomaly detection methods. Additionally, we further validate our approach on liver CT and retinal images to assess its generalizability across medical imaging modalities. Our results demonstrate that MadIRC provides a scalable, label-free solution for brain MRI anomaly detection, offering a promising avenue for integration into real-world clinical workflows.},
  archive      = {J_IJNS},
  author       = {Hussain Ahmad Madni and Hafsa Shujat and Axel De Nardin and Silvia Zottin and Gian Luca Foresti},
  doi          = {10.1142/S0129065725500479},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2550047},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Unsupervised brain MRI anomaly detection via inter-realization channels},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A performance benchmarking review of transformers for speaker-independent speech emotion recognition. <em>IJNS</em>, <em>35</em>(10), 2530001. (<a href='https://doi.org/10.1142/S0129065725300013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech Emotion Recognition (SER) is becoming a key element of speech-based human–computer interfaces, endowing them with some form of empathy towards the emotional status of the human. Transformers have become a central Deep Learning (DL) architecture in natural language processing and signal processing, recently including audio signals for Automatic Speech Recognition (ASR) and SER. A central question addressed in this paper is the achievement of speaker-independent SER systems, i.e. systems that perform independently of a specific training set, enabling their deployment in real-world situations by overcoming the typical limitations of laboratory environments. This paper presents a comprehensive performance evaluation review of transformer architectures that have been proposed to deal with the SER task, carrying out an independent validation at different levels over the most relevant publicly available datasets for validation of SER models. The comprehensive experimental design implemented in this paper provides an accurate picture of the performance achieved by current state-of-the-art transformer models in speaker-independent SER. We have found that most experimental instances reach accuracies below 40% when a model is trained on a dataset and tested on a different one. A speaker-independent evaluation combining up to five datasets and testing on a different one achieves up to 58.85% accuracy. In conclusion, the SER results improved with the aggregation of datasets, indicating that model generalization can be enhanced by extracting data from diverse datasets.},
  archive      = {J_IJNS},
  author       = {Francisco Portal and Javier De Lope and Manuel Graña},
  doi          = {10.1142/S0129065725300013},
  journal      = {International Journal of Neural Systems},
  number       = {10},
  pages        = {2530001},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A performance benchmarking review of transformers for speaker-independent speech emotion recognition},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph spectral analysis using electroencephalography in alzheimer disease and frontotemporal dementia patients. <em>IJNS</em>, <em>35</em>(9), 2550048. (<a href='https://doi.org/10.1142/S0129065725500480'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph theory has proven to be useful in studying brain dysfunction in Alzheimer’s disease using MagnetoEncephaloGraphy (MEG) and fMRI signals. However, it has not yet been tested enough with reduced sets of electrodes, as in the 10–20 EEG. In this paper, we applied techniques from the Graph Spectral Analysis (GSA) derived from EEG signals of patients with Alzheimer, Frontotemporal Dementia and control subjects. A collection of global GSA metrics were computed, accounting for general properties of the adjacency or Laplacian matrices. Also, regional GSA metrics were calculated, disentangling centrality measures in five cortical regions (frontal, central, parietal, temporal and occipital). These two sort of measures were then utilized in a binary AD/controls classification problem to test their utility in AD diagnosis and identify most valuable parameters. The Theta band appeared as the most connected and synchronizable rhythm for all three groups. Also, it was the rhythm with most preserved connections among temporal electrodes, exhibiting the shortest average distances among T 3 , T 4 , T 5 and T 6 . In addition, Theta emerged as the rhythm with the highest classification performances based on regional parameters according to a k = 5 cross-validation scheme (mean accuracy = 0 . 7 4 ± 0 . 0 3 , mean recall = 0 . 7 2 ± 0 . 0 5 and mean F 1- score = 0 . 7 2 ± 0 . 0 3 ). In general, regional parameters produced better classification performances for most of the rhythms, encouraging further investigation into GSA parameters with refined spatial and functional specificity.},
  archive      = {J_IJNS},
  author       = {María Paula Bonomini and Eduardo Ghiglioni and Noelia Belén Ríos},
  doi          = {10.1142/S0129065725500480},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2550048},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Graph spectral analysis using electroencephalography in alzheimer disease and frontotemporal dementia patients},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding of task-specific and subject-specific components in surface EMG. <em>IJNS</em>, <em>35</em>(9), 2550046. (<a href='https://doi.org/10.1142/S0129065725500467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface electromyogram (sEMG) signals are widely used in human–machine interfaces for gesture recognition and user identification, but existing models often struggle with generalization across different individuals due to subject-specific neuromuscular characteristics. This study introduced a disentanglement model to separate task-specific and subject-specific components from sEMG signals, thus improving the generalization and interpretability of gesture recognition and user identification systems. Experimental results demonstrate that disentangled task-specific components significantly improve the accuracy of both gesture classification and user identification across different subjects and days, outperforming conventional methods in the same scenario. Further analysis of the extracted components reveals that task-specific components capture consistent activation patterns for the same gestures across individuals. In contrast, subject-specific components reflect unique neuromuscular characteristics that can be used for user identification. Notably, subject-specific components show reduced similarity compared to task-specific components in inter-day scenarios, contributing to more accuracy decrease in user identification than in gesture recognition. These findings suggest that the disentanglement approach not only boosts classification performance but also provides deeper insights into the physiological mechanisms underlying sEMG signals. The model’s ability to isolate and interpret different neuromuscular components holds promise for enhancing the robustness of sEMG-based applications in real-world settings, such as rehabilitation and user authentication.},
  archive      = {J_IJNS},
  author       = {Yangyang Yuan and Jionghui Liu and Xinyu Jiang and Jiahao Fan and Chih-Hong Chou and Chenyun Dai},
  doi          = {10.1142/S0129065725500467},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2550046},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Understanding of task-specific and subject-specific components in surface EMG},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Post-movement beta rebound for longitudinal monitoring of motor rehabilitation in stroke patients using an exoskeleton-assisted paradigm. <em>IJNS</em>, <em>35</em>(9), 2550044. (<a href='https://doi.org/10.1142/S0129065725500443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task-oriented rehabilitation is essential for hand function recovery in stroke patients, and recent advancements in BCI-controlled exoskeletons and neural biomarkers — such as post-movement beta rebound (PMBR) — offer new pathways to optimize these therapies. Movement-related EEG signals from the sensorimotor cortex, particularly PMBR (post-movement) and event-related desynchronization (ERD, during movement), exhibit high task specificity and correlate with stroke severity. This study evaluated PMBR in 34 chronic stroke patients across two cohorts, along with a control group of 16 healthy participants, during voluntary and exoskeleton-assisted movement tasks. Longitudinal tracking in the second cohort enabled the analysis of PMBR changes, with EEG recordings acquired at three timepoints over a 30-session rehabilitation program. Findings revealed significant PMBR alterations in both passive and active movement tasks: patients with severe impairment lacked a PMBR dipole in the ipsilesional hemisphere, while moderately impaired patients showed a diminished response. The marked differences in PMBR patterns between stroke patients and controls highlight the extent of sensorimotor cortex disruption due to stroke. ERD showed minimal task-specific variation, underscoring PMBR as a more reliable biomarker of motor function impairment. These findings support the use of PMBR, particularly the PMBR/ERD ratio, as a biomarker for EEG-guided monitoring of motor recovery over time during exoskeleton-assisted rehabilitation.},
  archive      = {J_IJNS},
  author       = {Juan A. Barios and Yolanda Vales and Jose M. Catalán and Andrea Blanco-Ivorra and David Martínez-Pascual and Nicolás García-Aracil},
  doi          = {10.1142/S0129065725500443},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2550044},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Post-movement beta rebound for longitudinal monitoring of motor rehabilitation in stroke patients using an exoskeleton-assisted paradigm},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing dementia diagnosis through distance-correlation feature space and dimensionality reduction. <em>IJNS</em>, <em>35</em>(9), 2550042. (<a href='https://doi.org/10.1142/S012906572550042X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reduction of dimensionality in machine learning and artificial intelligence problems constitutes a pivotal element in the simplification of models, significantly enhancing both their performance and execution time. This process enables the generation of results more rapidly while also facilitating the scalability and optimization of systems that rely on such models. Two primary approaches are commonly employed to achieve dimensionality reduction: feature selection-based methods and those grounded in feature extraction. In this paper, we propose a distance-correlation feature space, upon which we define a dimensionality reduction algorithm based on space transformations and graph embeddings. This methodology is applied in the context of dementia diagnosis through learning models, with the overarching objective of optimizing the diagnostic process.},
  archive      = {J_IJNS},
  author       = {Pablo Zubasti and Miguel A. Patricio and Antonio Berlanga and Jose M. Molina},
  doi          = {10.1142/S012906572550042X},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2550042},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Optimizing dementia diagnosis through distance-correlation feature space and dimensionality reduction},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interactive EEG emotion recognition with incremental gaussian processes. <em>IJNS</em>, <em>35</em>(9), 2550041. (<a href='https://doi.org/10.1142/S0129065725500418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactivity is crucial for enabling models to adjust and optimize based on user feedback, thereby enhancing overall performance. However, existing electroencephalogram (EEG)-based emotion recognition models rely on static training paradigms, lack interactivity, and struggle to effectively handle uncertainty in predictions. To address this issue, we propose a novel paradigm for interactive emotion recognition based on incremental Gaussian processes (GP). Unlike existing methods, our approach introduces an expert interaction mechanism to correct samples with high predictive uncertainty and incrementally update the model accordingly, thereby optimizing its performance. First, we model the emotion recognition task as a GP-based framework, utilizing the variance of the GP to quantify the model’s uncertainty, thereby guiding experts in targeted interactions. Second, within the GP framework, we propose a novel incremental update strategy that allows the GP to incrementally update prediction results and uncertainties based only on new data obtained through expert interactions, without reprocessing all existing data. This effectively overcomes the shortcomings of traditional GP in updating efficiency. Third, to address the high computational complexity of GP, we use a sparse approximation strategy, selecting inducing points and performing variational inference to efficiently approximate the GP posterior, thereby reducing computational complexity. Subject-dependent and subject-independent experiments conducted on the DEAP and DREAMER datasets demonstrate that the proposed method exhibits significant advantages over state-of-the-art (SOTA) methods. In subject-dependent experiments, our method achieved the highest improvement (1.73%) in the Dominance dimension on the DREAMER dataset. In subject-independent experiments, it attained the largest performance improvement (2.96%) in the Arousal dimension on the DEAP dataset. These results further validate the proposed method’s effectiveness.},
  archive      = {J_IJNS},
  author       = {Xiangle Ping and Wenhui Huang},
  doi          = {10.1142/S0129065725500418},
  journal      = {International Journal of Neural Systems},
  number       = {9},
  pages        = {2550041},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Interactive EEG emotion recognition with incremental gaussian processes},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An explainable connectome convolutional transformer for multimodal autism spectrum disorder classification. <em>IJNS</em>, <em>35</em>(8), 2550043. (<a href='https://doi.org/10.1142/S0129065725500431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The diagnosis of autism spectrum disorder (ASD) is often hampered by its heterogeneity and reliance on time-consuming behavioral assessments. Automated neuroimaging-based diagnostic tools offer a promising alternative, but multi-site data integration often introduces variability, hindering the achievement of accurate and interpretable results. This study presents the Connectome Convolutional Transformer (CCTF), a multimodal deep learning framework that integrates functional and structural brain connectivity information from fMRI and sMRI modalities. The CCTF enriches feature representation by incorporating diverse functional connectivity metrics and structural covariance networks based on multiple morphological properties. It employs a connectome convolutional embedding module and transformer encoder to capture and refine brain connectivity patterns. In addition, a node-to-graph pooling layer facilitates the identification of potential ASD biomarkers. Evaluation on the multi-site ABIDE dataset demonstrated that CCTF outperformed state-of-the-art methods, achieving accuracies of 8 4 . 3 % for fMRI, 7 4 . 3 % for sMRI, and 8 8 . 2 % for the ensemble fMRI+sMRI model in intra-site cross-validation. In the inter-site leave-one-site-out cross-validation, the CCTF maintained its superiority, with the ensemble model reaching 8 9 . 2 % accuracy, underscoring its robustness and generalizability across different sites. The identified brain regions are consistent with established ASD neurobiology, underscoring CCTF’s potential to advance the understanding of the neural mechanisms underlying this complex disorder.},
  archive      = {J_IJNS},
  author       = {Reza Nazari and Mostafa Salehi and Afshin Shoeibi},
  doi          = {10.1142/S0129065725500431},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2550043},
  shortjournal = {Int. J. Neural Syst.},
  title        = {An explainable connectome convolutional transformer for multimodal autism spectrum disorder classification},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic regulation of the Serotonin–Dopamine interaction within a meta-reinforcement learning framework encompassing the prefrontal cortex and basal ganglia. <em>IJNS</em>, <em>35</em>(8), 2550040. (<a href='https://doi.org/10.1142/S0129065725500406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action inhibition is essential for cognitive control, enabling individuals to prioritize relevant information over internal urges in response to changing demands. While current artificial agents excel in repetitive tasks, real-world scenarios often require the handling of unexpected constraints, such as the suppression of unwanted actions. Meta-learning, acting as an outer loop that regulates the reinforcement learning scheme in the inner loop of learning, facilitates adaptation in dynamic environments. Building upon our previous work, 1 where we implemented a brain-inspired meta-reinforcement learning framework for conflictual inhibition decision-making encompassing brain regions of the prefrontal cortex and the basal ganglia circuit and tested it within the NoGo and Stop-Signal Paradigms, this study introduces the following novelties. We explored the effects of changes in concentration and efficacy of the D 1 -mesocorticolimbic and D 2 -nigrostriatal pathways externally modulated by serotonin release on meta-reinforcement learning rules, thus the extent to which they affect behavioral performance during action cancellation within the Stop-Signal Paradigm. Our findings suggest that external serotoninergic modulation on these pathways asymmetrically affects behavioral performance, revealing that inhibitory behavior is primarily mediated by serotonin acting on D 1 dopamine receptors and is therefore asymmetrically influenced by changes in D 1 and D 2 efficacy. These pathways exhibit synergistic effects in response inhibition, with a predominant role for reductions in D 1 efficacy. Furthermore, we extended the meta-reinforcement learning framework by designing brain-inspired meta-learning rules that replicate the serotonin–dopamine dynamic interactions during action inhibition in a closed-loop fashion by using the Wilson–Cowan formalism 2 enabling a dynamic regulation of the exploration/exploitation rate β meta-parameter. Our framework generates new predictive hypotheses and provides insights about the dynamic interaction between serotonin and dopamine D 1 and D 2 , understanding their impact in response inhibition and, consequently, how they might be involved in impulsive behaviors. This knowledge suggests potential neural mechanisms underlying cognitive control in the brain and, at the same time, could contribute to the development of more flexible and robust artificial systems capable of adapting in real-world applications.},
  archive      = {J_IJNS},
  author       = {Federica Robertazzi and Matteo Vissani and Egidio Falotico},
  doi          = {10.1142/S0129065725500406},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2550040},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Dynamic regulation of the Serotonin–Dopamine interaction within a meta-reinforcement learning framework encompassing the prefrontal cortex and basal ganglia},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-order extension codes for palmprint recognition. <em>IJNS</em>, <em>35</em>(8), 2550039. (<a href='https://doi.org/10.1142/S012906572550039X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Palmprint recognition is a pivotal biometric modality, renowned for its numerous advantages and applications in the field of biometrics. The Gabor filter is a classic and efficient texture feature extractor abstracted from the nervous system. The existing palmprint texture coding methods only focus on first-order texture features (1TFs), while neglecting discriminative second-order texture features (2TFs). Therefore, this paper proposes multi-order extensions for state-of-the-art (SOTA) palmprint texture coding methods, which makes full usage of 1TFs and 2TFs. A filter is used to extract 1TFs from the palmprint image, and the same filter is applied to extract 2TFs from 1TFs. Here, different methods employ various filters to extract diverse textures. Due to the simultaneous participations of 1TFs and 2TFs in multi-order extension codes, more discriminative features are extracted and fused. The experimental results on three public databases, including contact, noncontact and multispectral acquisition types, show that the accuracies of all the palmprint texture coding methods are remarkably improved by multi-order extension, establishing it as a general framework extendable to other texture-based recognition tasks.},
  archive      = {J_IJNS},
  author       = {Fengxiang Liao and Lu Leng and Ziyuan Yang and Bob Zhang},
  doi          = {10.1142/S012906572550039X},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2550039},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Multi-order extension codes for palmprint recognition},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced graph attention network by integrating transformer for epileptic EEG identification. <em>IJNS</em>, <em>35</em>(8), 2550037. (<a href='https://doi.org/10.1142/S0129065725500376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography signal classification is essential for the diagnosis and monitoring of neurological disorders, with significant implications for patient treatment. Despite the progress made, existing methods face challenges such as capturing the complex dynamics of Electroencephalogram (EEG) signals and generalizing across diverse patient populations. In this study, the graph attention network and the transformer model are integrated for EEG signal classification, leveraging the enhanced capability to dynamically compute attention weights and adapt to the variable relevance of brain regions. The proposed approach is capable of modeling the intricate relationships within EEG activities by learning context-dependent attention scores. We conducted a comprehensive evaluation of the proposed approach comparing with the state-of-the-art algorithms. Experimental outcomes show that it surpasses the competing models. The superior performance is attributed to the proposed approach’s dynamic attention mechanism, which better captures the nuanced patterns in EEG signals across different subjects and seizure types. In the experiments, the CHB-MIT dataset was exploited, which served as a benchmark for evaluating the performance of the proposed framework in distinguishing interictal, ictal, and normal EEG patterns. The results prove the usefulness of our work in advancing EEG signal classification. The findings suggest that the combination of graph attention and self-attention mechanisms is a promising approach for improving the accuracy and reliability of EEG-based diagnostics, potentially improving the management of neurological disorders.},
  archive      = {J_IJNS},
  author       = {Zhenhua Xie and Jian Lian and Dong Wang},
  doi          = {10.1142/S0129065725500376},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2550037},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Enhanced graph attention network by integrating transformer for epileptic EEG identification},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global–Local feature fusion network based on nonlinear spiking neural convolutional model for MRI brain tumor segmentation. <em>IJNS</em>, <em>35</em>(8), 2550036. (<a href='https://doi.org/10.1142/S0129065725500364'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the differences in size, shape, and location of brain tumors, brain tumor segmentation differs greatly from that of other organs. The purpose of brain tumor segmentation is to accurately locate and segment tumors from MRI images to assist doctors in diagnosis, treatment planning and surgical navigation. NSNP-like convolutional model is a new neural-like convolutional model inspired by nonlinear spiking mechanism of nonlinear spiking neural P (NSNP) systems. Therefore, this paper proposes a global–local feature fusion network based on NSNP-like convolutional model for MRI brain tumor segmentation. To this end, we have designed three characteristic modules that take full advantage of the NSNP-like convolution model: dilated SNP module (DSNP), multi-path dilated SNP pooling module (MDSP) and Poolformer module. The DSNP and MDSP modules are employed to construct the encoders. These modules help address the issue of feature loss and enable the fusion of more high-level features. On the other hand, the Poolformer module is used in the decoder. It processes features that contain global context information and facilitates the interaction between local and global features. In addition, channel spatial attention (CSA) module is designed at the skip connection between encoder and decoder to establish the long-range dependence between the same layers, thereby enhancing the relationship between channels and making the model have global modeling capabilities. In the experiments, our model achieves Dice coefficients of 85.71 % , 92.32 % , 87.75 % for ET, WT, and TC, respectively, on the N-BraTS2021 dataset. Moreover, our model achieves Dice coefficients of 83.91 % , 91.96 % , 90.14 % and 85.05 % , 92.30 % , 90.31 % on the BraTS2018 and BraTS2019 datasets respectively. Experimental results also indicate that our model not only achieves good brain tumor segmentation performance, but also has good generalization ability. The code is already available on GitHub: https://github.com/Li-JJ-1/NSNP-brain-tumor-segmentation .},
  archive      = {J_IJNS},
  author       = {Junjie Li and Hong Peng and Bing Li and Zhicai Liu and Rikong Lugu and Bingyan He},
  doi          = {10.1142/S0129065725500364},
  journal      = {International Journal of Neural Systems},
  number       = {8},
  pages        = {2550036},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Global–Local feature fusion network based on nonlinear spiking neural convolutional model for MRI brain tumor segmentation},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tiny convolutional neural network with supervised contrastive learning for epileptic seizure prediction. <em>IJNS</em>, <em>35</em>(7), 2550034. (<a href='https://doi.org/10.1142/S0129065725500340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic seizure prediction based on ElectroEncephaloGraphy (EEG) ensures the safety of patients with epilepsy and mitigates anxiety. In recent years, significant progress has been made in this field. However, the predictive performance of existing methods encounters a bottleneck that is difficult to overcome. Moreover, there are certain limitations such as significant differences in prediction efficacy among patients or intricate model structures. Given these considerations, Siamese Network (SiaNet) and Triplet Network (TriNet) are proposed based on tiny convolutional neural network and supervised contrastive learning. Short-Time Fourier Transform (STFT) is first applied to the pre-processed data. Then data tuples are constructed and fed into the networks for training. Both networks try to minimize the interval between samples of the same class while maximize the interval between samples of different classes. The two networks consist of multiple branches with shared weights, which can learn from each other via contrastive learning. Promising results are obtained on the CHB-MIT and Siena datasets, with a total of 35 patients. Meanwhile, both models have only 19.351K parameters.},
  archive      = {J_IJNS},
  author       = {Yongfeng Zhang and Hailing Feng and Shuai Wang and Hongbin Lv and Tiantian Xiao and Ziwei Wang and Yanna Zhao},
  doi          = {10.1142/S0129065725500340},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2550034},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Tiny convolutional neural network with supervised contrastive learning for epileptic seizure prediction},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolution of the motor symptoms in parkinson disease under auditory stimulation. <em>IJNS</em>, <em>35</em>(7), 2550030. (<a href='https://doi.org/10.1142/S0129065725500303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes a study that analyzes the effect of periodic binaural auditory stimulation in the beta band on two of the major motor symptoms of patients with Parkinson’s disease (PD), resting tremor and bradykinesia. Participants included two groups of PD patients ( n = 2 1 n = 2 1 n=21 , age 6 3 . 6 9 ± 7 . 4 3 6 3 . 6 9 ± 7 . 4 3 63.69±7.43 , stage 1 . 5 5 ± 0 . 5 5 1 . 5 5 ± 0 . 5 5 1.55±0.55 Hoehn & Yahr scale) that were exposed to an experimental (group A) or placebo (group B) auditory stimulation once a day, and a group of healthy controls ( n = 7 n = 7 n=7 , age 6 4 . 0 0 ± 5 . 4 5 6 4 . 0 0 ± 5 . 4 5 64.00±5.45 ) that was not exposed to any stimulation. The experimental stimulation consisted of 10 min of binaural beats at 14 Hz presented rhythmically and masked with pink noise, while the placebo stimulation consisted of pink noise only. All participants were monitored using wearable devices and mobile phones to assess the evolution of resting tremors and bradykinesia. Both indicators were obtained from accelerometer signals during the execution of specific motor tasks extracted from the MDS-UPDRS scale Part III once a week. The results show a significant difference between the group of healthy controls and PD patients for the resting tremor and bradykinesia indicators, suggesting the predictive validity of the monitoring system and the consistency of the indicators. Regarding the effect of auditory stimulation, a reduction in the level of resting tremor was observed in patients who received the experimental stimulation compared to those who received the placebo stimulation ( p = 0 . 0 0 4 ) ( p = 0 . 0 0 4 ) (p=0.004) over the course of the 8 weeks of monitoring. However, no improvement in bradykinesia was observed. The generalization of results is compromised due to a set of limitations that have been identified, so guidance is provided that might contribute to improving future experimental designs in similar studies.},
  archive      = {J_IJNS},
  author       = {David González and Luis Sigcha and Juan Manuel López and César Asensio and Ignacio Pavón and Nelson Costa and Susana Costa and Miguel Gago and Juan Carlos Martínez-Castrillo and Guillermo de Arcas},
  doi          = {10.1142/S0129065725500303},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2550030},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Evolution of the motor symptoms in parkinson disease under auditory stimulation},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding robot gesture perception in children with autism spectrum disorder during Human–Robot interaction. <em>IJNS</em>, <em>35</em>(7), 2550026. (<a href='https://doi.org/10.1142/S0129065725500261'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social robots are increasingly being used in therapeutic contexts, especially as a complement in the therapy of children with Autism Spectrum Disorder (ASD). Because of this, the aim of this study is to understand how children with ASD perceive and interpret the gestures made by the robot Pepper versus human instructor, which can also be influenced by verbal communication. This study analyzes the impact of both conditions (verbal and nonverbal communication) and types of gestures (conversational and emotional) on gesture recognition through the study of the accuracy rate and examines the physiological responses of children with the Empatica E4 device. The results reveal that verbal communication is more accessible to children with ASD and neurotypicals (NT), with emotional gestures being more interpretable than conversational gestures. The Pepper robot was found to generate lower responses of emotional arousal compared to the human instructor in both ASD and neurotypical children. This study highlights the potential of robots like Pepper to support the communication skills of children with ASD, especially in structured and predictable nonverbal gestures. However, the findings also point to challenges, such as the need for more reliable robotic communication methods, and highlight the importance of changing interventions tailored to individual needs.},
  archive      = {J_IJNS},
  author       = {Gema Benedicto-Rodríguez and Facundo Bosch and Carlos G. Juan and Maria Paula Bonomini and Antonio Fernández-Caballero and Eduardo Fernandez-Jover and Jose Manuel Ferrández-Vicente},
  doi          = {10.1142/S0129065725500261},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2550026},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Understanding robot gesture perception in children with autism spectrum disorder during Human–Robot interaction},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Electroencephalography decoding with conditional identification generator. <em>IJNS</em>, <em>35</em>(7), 2550024. (<a href='https://doi.org/10.1142/S0129065725500248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decoding Electroencephalography (EEG) signals are extremely useful for advancing and understanding human–artificial intelligence (AI) interaction systems. Recent advancements in deep neural networks (DNNs) have demonstrated significant promise in this respect due to their ability to model complex nonlinear relationships. However, DNNs face persistent challenges in addressing the inter-person variability inherent in EEG signals, which limits their generalizability. To tackle this limitation, we propose a novel framework that integrates conditional identification information, leveraging the interaction between EEG signals and individual traits to enhance the model’s internal representation and improve decoding accuracy. Building on this foundation, we further introduce a privacy-preserving conditional information generator — a generative model that derives embedding knowledge directly from raw EEG signals. This approach eliminates the need for personal identification via individual tests, ensuring both efficiency and privacy. Experimental evaluations conducted on WithMe dataset confirm that this framework outperforms baseline network architectures. Notably, our approach achieves substantial improvements in decoding accuracy for both familiar and unseen subjects, paving the way for efficient, robust, and privacy-conscious human–computer interface systems.},
  archive      = {J_IJNS},
  author       = {Pengfei Sun and Jorg De Winne and Malu Zhang and Paul Devos and Dick Botteldooren},
  doi          = {10.1142/S0129065725500248},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2550024},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Electroencephalography decoding with conditional identification generator},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient seizure detection by complementary integration of convolutional neural network and vision transformer. <em>IJNS</em>, <em>35</em>(7), 2550023. (<a href='https://doi.org/10.1142/S0129065725500236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy, as a prevalent neurological disorder, is characterized by its high incidence, sudden onset, and recurrent nature. The development of an accurate and real-time automatic seizure detection system is crucial for assisting clinicians in making precise diagnoses and providing timely treatment for epilepsy. However, conventional automatic seizure detection methods often face limitations in simultaneously capturing both local features and long-range correlations inherent in EEG signals, which constrains the accuracy of these existing detection systems. To address this challenge, we propose a novel end-to-end seizure detection framework, named CNN-ViT, which complementarily integrates a Convolutional Neural Network (CNN) for capturing local inductive bias of EEG and Vision Transformer (ViT) for further mining their long-range dependency. Initially, raw electroencephalogram (EEG) signals are filtered and segmented and then sent into the CNN-ViT model to learn their local and global feature representations and identify the seizure patterns. Meanwhile, we adopt a global max-pooling strategy to reduce the scale of the CNN-ViT model and make it focus on the most discriminative features. Given the occurrence of diverse artifacts in long-term EEG recordings, we further employ post-processing techniques to improve the seizure detection performance. The proposed CNN-ViT model, when evaluated using the publicly accessible CHB-MIT EEG dataset, reveals its outstanding performance with a sensitivity of 99.34% at a segment-based level and 99.70% at an event-based level. On the SH-SDU dataset we collected, our method yielded a segment-based sensitivity of 99.86%, specificity of 94.33%, and accuracy of 94.40%, along with an event-based sensitivity of 100%. The total processing time for 1 h EEG data was only 3.07 s. These exceptional results demonstrate the potential of our method as a reference for clinical real-time seizure detection applications.},
  archive      = {J_IJNS},
  author       = {Jiaqi Wang and Haotian Li and Chuanyu Li and Weisen Lu and Haozhou Cui and Xiangwen Zhong and Shuhao Ren and Zhida Shang and Weidong Zhou},
  doi          = {10.1142/S0129065725500236},
  journal      = {International Journal of Neural Systems},
  number       = {7},
  pages        = {2550023},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Efficient seizure detection by complementary integration of convolutional neural network and vision transformer},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting intraoperative burst suppression using preoperative EEG and patient characteristics. <em>IJNS</em>, <em>35</em>(6), 2550033. (<a href='https://doi.org/10.1142/S0129065725500339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Burst suppression (BS) is an electroencephalogram (EEG) pattern observed in patients undergoing general anesthesia. The occurrence of BS is associated with adverse outcomes such as postoperative delirium, extended recovery time, and increased postoperative mortality. The detection and prediction of BS can help expedite the evaluation of patient conditions, optimize anesthesia administration, and improve patient safety. This study explores the potential for automatic BS detection using intraoperative EEG and BS prediction using preoperative EEG signals and patient characteristics. A dataset comprising 287 patients who underwent carotid endarterectomy procedures at Maastricht University Medical Center+ was analyzed. An EEG toolbox developed by T. Zhan at the Massachusetts Institute of Technology was utilized for the automatic detection/annotation of BS, while five machine learning classifiers were employed to predict BS occurrence using preoperative data. Based on the 160 patients manually annotated by EEG experts (regarding the presence or absence of BS), the automatic detection tool demonstrated an accuracy of 0.75. For the BS prediction task, an initial subset of 120 patients was evaluated, showing modest performance, with the K -nearest neighbors ( K = 7 ) classifier achieving the best results, with an accuracy of 0.72. Subsequent experiments indicated that increasing the number of patients (by using Zhan’s Toolbox to annotate the unlabeled instances), applying SMOTE to balance the training set, and enriching the feature set was beneficial. The final experiment demonstrated a significant improvement, with Random Forest and Gradient Boosting outperforming other classifiers, achieving an accuracy of 0.86 and ROC–AUC of 0.94. Patient characteristics, including type of anesthetic agents, symptoms, age, mean absolute delta power, mean absolute theta power, and cognitive impairment, were identified by an xAI method as important features potentially indicating the predisposition to experience BS.},
  archive      = {J_IJNS},
  author       = {Jingyi He and Joël M. H. Karel and Marcus L. F. Janssen and Erik D. Gommer and Catherine J. Vossen and Enrique Hortal},
  doi          = {10.1142/S0129065725500339},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2550033},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Predicting intraoperative burst suppression using preoperative EEG and patient characteristics},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Directed weighted EEG connectogram insights of one-to-one causality for identifying developmental dyslexia. <em>IJNS</em>, <em>35</em>(6), 2550032. (<a href='https://doi.org/10.1142/S0129065725500327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developmental dyslexia (DD) affects approximately 5–12% of learners, posing persistent challenges in reading and writing. This study presents a novel electroencephalography (EEG)-based methodology for identifying DD using two auditory stimuli modulated at 4.8 Hz (prosodic) and 40 Hz (phonemic). EEG signals were processed to estimate one-to-one Granger causality, yielding directed and weighted connectivity matrices. A novel Mutually Informed Correlation Coefficient (MICC) feature selection method was employed to identify the most relevant causal links, which were visualized using connectograms. Under the 4.8 Hz stimulus, altered theta-band connectivity between frontal and occipital regions indicated compensatory frontal activation for prosodic processing and visual–auditory integration difficulties, while gamma-band anomalies between occipital and temporal regions suggested impaired visual–prosodic integration. Classification analysis under the 4.8 Hz stimulus yielded area under the ROC curve (AUC) values of 0.92 (theta) and 0.91 (gamma band). Under the 40 Hz stimulus, theta abnormalities reflected dysfunctions in integrating auditory phoneme signals with executive and motor regions, and gamma alterations indicated difficulties coordinating visual and auditory inputs for phonological decoding, with AUC values of 0.84 (theta) and 0.89 (gamma). These results support both the Temporal Sampling Framework and the Phonological Core Deficit Hypothesis. Future research should extend the range of stimuli frequencies and include more diverse cohorts to further validate these potential biomarkers.},
  archive      = {J_IJNS},
  author       = {Ignacio Rodríguez-Rodríguez and José Ignacio Mateo-Trujillo and Andrés Ortiz and Nicolás J. Gallego-Molina and Diego Castillo-Barnes and Juan L. Luque},
  doi          = {10.1142/S0129065725500327},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2550032},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Directed weighted EEG connectogram insights of one-to-one causality for identifying developmental dyslexia},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neuronal waveform classification in multielectrode recordings using machine learning techniques and multidimensional analysis. <em>IJNS</em>, <em>35</em>(6), 2550031. (<a href='https://doi.org/10.1142/S0129065725500315'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracellular recordings of neuronal spikes are crucial for studying brain activity. These signals are typically classified based on firing patterns and waveform shape, particularly trough-to-peak duration. While useful, this method oversimplifies the diversity of cortical neurons and discharge patterns. Recent advances in recording and analysis techniques allow for more precise waveform classification, though the main criteria remain waveform features. We aim to develop an automatic spike waveform classifier using advanced machine learning techniques selected from a range of candidate methods based on their optimized performance, such as Uniform Manifold Approximation and Projection (UMAP), Gaussian Mixture Model (GMM), and Random Forest (RF). The classifier is part of the working progress of a preprocessing pipeline previously developed. For the classifying step, we use all voltage samples that define each waveform, enabling a multi-dimensional analysis. To evaluate our approach, RF model was trained and tested on a subset of electrophysiological recordings from the human visual cortex achieving high F 1 -scores. The comparison of the classified neurons was carried out between our method and a waveform analysis toolbox described in the literature. Our method improves the characterization of the clusters of waveforms based on statistical measurements that found a third group while the accepted method categorizes just broad and narrow waveforms, labeling some as unclassifiable.},
  archive      = {J_IJNS},
  author       = {Rocío López-Peco and Mikel Val-Calvo and Cristina Soto-Sánchez and Adrián Villamarin-Ortiz and Gloria Ruiz-Boix and José Manuel Ferrández-Vicente and Eduardo Fernández},
  doi          = {10.1142/S0129065725500315},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2550031},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Neuronal waveform classification in multielectrode recordings using machine learning techniques and multidimensional analysis},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing laryngeal neuromotor activity from phonation. <em>IJNS</em>, <em>35</em>(6), 2550029. (<a href='https://doi.org/10.1142/S0129065725500297'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurodegenerative motor disorders affect the neuromuscular system challenging daily life and normal activity. Parkinson’s Disease (PD) is among the most prevalent ones, with a large impact and rising prevalence rates. Speech is most affected by PD as far as phonatory and articulatory performance is concerned. Neuromotor activity (NMA) alterations have an impact on larynx muscles responsible for vocal fold adduction and abduction, hampering phonation stability and regularity. The main muscular articulators involved in phonation control are the cricothyroid (tensor) and thyroarytenoid (relaxer) systems, regulated by two distinct direct neuromotor pathways, activated by the precentral gyrus laryngeal control areas. These articulations control the musculus vocalis , directly responsible for regular vocal fold vibration. An indirect estimation of the muscular tension produced by inverse filtering may split into two independent channels, assumed to be the tensor and relaxer neuromotor pathways such as the differential neuromotor activity (DNMA). The amplitude distributions of both DNMA channels allow comparing phonations from PD-affected persons (PDPs) and age-matched healthy control participants (HCPs) with respect to a set of reference mid-age normative participants (RSPs). The comparisons are carried out by Jensen–Shannon distributions of PDP and HCP phonations with respect to those of RSPs. A dataset of 96 phonation samples from participants balanced by gender is used to train a set of decision tree classifiers (DTCs) to distinguish PDP from HCP phonation. The best results from 10-fold cross-validation offered accumulated mismatches of 0.09 and 0.1292 for male and female subsets. The sensitivity, specificity, and accuracy of the classification results when separating PDP from HCP phonatios were 93.33%, 88.23%, and 90.63% (male PDP versus HCP) and 92.86%, 83.33%, and 87.50% (female PDP versus HCP), providing a stratification of PDPs and HCPs by objective disease grading from explainable AI (XAI) methods.},
  archive      = {J_IJNS},
  author       = {Pedro Gómez-Vilda and Andrés Gómez-Rodellar and Jiři Mekyska and Agustín Álvarez-Marquina and Daniel Palacios-Alonso and Irena Rektorová},
  doi          = {10.1142/S0129065725500297},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2550029},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Assessing laryngeal neuromotor activity from phonation},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal integration of EEG and near-infrared spectroscopy for robust cross-frequency coupling estimation. <em>IJNS</em>, <em>35</em>(6), 2550028. (<a href='https://doi.org/10.1142/S0129065725500285'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuroimaging techniques have had a major impact on medical science, allowing advances in the research of many neurological diseases and improving their diagnosis. In this context, multimodal neuroimaging approaches, based on the neurovascular coupling phenomenon, exploit their individual strengths to provide complementary information on the neural activity of the brain cortex. This work proposes a novel method for combining electroencephalography (EEG) and functional near–infrared spectroscopy (fNIRS) to explore the functional activity of the brain processes related to low-level language processing of skilled and dyslexic seven-year-old readers. We have transformed EEG signals into image sequences considering the interaction between different frequency bands by means of cross-frequency coupling (CFC), and applied an activation mask sequence obtained from the local functional brain activity inferred from simultaneously recorded fNIRS signals. Thus, the resulting image sequences preserve spatial and temporal information of the communication and interaction between different neural processes and provide discriminative information that allows differentiation between controls and dyslexic subjects with an AUC of 77.1%. Finally, explainability is improved by introducing an easily comprehensible representation of the SHAP values obtained for the classification method in the brainSHAP maps.},
  archive      = {J_IJNS},
  author       = {Nicolás J. Gallego-Molina and Andrés Ortiz and Francisco J. Martínez-Murcia and Wai Lok Woo},
  doi          = {10.1142/S0129065725500285},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2550028},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Multimodal integration of EEG and near-infrared spectroscopy for robust cross-frequency coupling estimation},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continual learning by contrastive learning of regularized classes in multivariate gaussian distributions. <em>IJNS</em>, <em>35</em>(6), 2550025. (<a href='https://doi.org/10.1142/S012906572550025X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks struggle with incremental updates due to catastrophic forgetting, where newly acquired knowledge interferes with the learned previously. Continual learning (CL) methods aim to overcome this limitation by effectively updating the model without losing previous knowledge, but they find it difficult to continuously maintain knowledge about previous tasks, resulting from overlapping stored information. In this paper, we propose a CL method that preserves previous knowledge as multivariate Gaussian distributions by independently storing the model’s outputs per class and continually reproducing them for future tasks. We enhance the discriminability between classes and ensure the plasticity for future tasks by exploiting contrastive learning and representation regularization. The class-wise spatial means and covariances, distinguished in the latent space, are stored in memory, where the previous knowledge is effectively preserved and reproduced for incremental tasks. Extensive experiments on benchmark datasets such as CIFAR-10, CIFAR-100, and ImageNet-100 demonstrate that the proposed method achieves accuracies of 93.21%, 77.57%, and 78.15%, respectively, outperforming state-of-the-art CL methods by 2.34 %p, 2.1 %p, and 1.91 %p. Additionally, it achieves the lowest mean forgetting rates across all datasets.},
  archive      = {J_IJNS},
  author       = {Hyung-Jun Moon and Sung-Bae Cho},
  doi          = {10.1142/S012906572550025X},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2550025},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Continual learning by contrastive learning of regularized classes in multivariate gaussian distributions},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Introduction. <em>IJNS</em>, <em>35</em>(6), 2502002. (<a href='https://doi.org/10.1142/S0129065725020022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJNS},
  author       = {José Manuel Ferrández},
  doi          = {10.1142/S0129065725020022},
  journal      = {International Journal of Neural Systems},
  number       = {6},
  pages        = {2502002},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Introduction},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive dynamic surface control of epileptor model based on nonlinear luenberger state observer. <em>IJNS</em>, <em>35</em>(5), 2550022. (<a href='https://doi.org/10.1142/S0129065725500224'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is a prevalent neurological disorder characterized by recurrent seizures, which are sudden bursts of electrical activity in the brain. The Epileptor model is a computational model specifically created to replicate the complex dynamics of epileptic seizures. The parameters of the Epileptor model can be adjusted to simulate activities associated with some seizure classes seen in patients. Due to the closeness of this model to nonlinear systems with nonstrict feedback form and the existence of uncertainties in the model, an adaptive dynamic surface controller is chosen for control of the system. Considering that the states in the Epileptor model are not measurable and the only measurable output is the Local Field Potentials signal, a nonlinear Luenberger state observer is developed to estimate the system states. It is the first time that the Luenberger state observer is used for the Epileptor model. In this approach, Radial Basis Neural Networks are utilized to estimate the system’s nonlinear dynamics. The stability of our proposed controller along with the observer is proved, and the performance is shown using simulation. Simulation results show that by using the suggested method, the output and states of the, system track their reference, value with an acceptable error.},
  archive      = {J_IJNS},
  author       = {Mahdi Kamali Dolatabadi and Marzieh Kamali and Farzaneh Shayegh},
  doi          = {10.1142/S0129065725500224},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2550022},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Adaptive dynamic surface control of epileptor model based on nonlinear luenberger state observer},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coherence-based graph convolution network to assess brain reorganization in spinal cord injury patients. <em>IJNS</em>, <em>35</em>(5), 2550021. (<a href='https://doi.org/10.1142/S0129065725500212'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motor imagery (MI) engages a broad network of brain regions to imagine a specific action. Investigating the mechanism of brain network reorganization during MI after spinal cord injury (SCI) is crucial because it reflects overall brain activity. Using electroencephalogram (EEG) data from SCI patients, we conducted EEG-based coherence analysis to examine different brain network reorganizations across different frequency bands, from resting to MI. Furthermore, we introduced a consistency calculation-based residual graph convolution (C-ResGCN) classification algorithm. The results show that the α - and β -band connectivity weakens, and brain activity decreases during the MI task compared to the resting state. In contrast, the γ -band connectivity increases in motor regions while the default mode network activity declines during MI. Our C-ResGCN algorithm showed excellent performance, achieving a maximum classification accuracy of 96.25%, highlighting its reliability and stability. These findings suggest that brain reorganization in SCI patients reallocates relevant brain resources from the resting state to MI, and effective network reorganization correlates with improved MI performance. This study offers new insights into the mechanisms of MI and potential biomarkers for evaluating rehabilitation outcomes in patients with SCI.},
  archive      = {J_IJNS},
  author       = {Jiancai Leng and Jiaqi Zhao and Yongjian Wu and Chengyan Lv and Zhixiao Lun and Yanzi Li and Chao Zhang and Bin Zhang and Yang Zhang and Fangzhou Xu and Changsong Yi and Tzyy-Ping Jung},
  doi          = {10.1142/S0129065725500212},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2550021},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Coherence-based graph convolution network to assess brain reorganization in spinal cord injury patients},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scene text detection based on text stroke components. <em>IJNS</em>, <em>35</em>(5), 2550020. (<a href='https://doi.org/10.1142/S0129065725500200'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of scene text holds significant importance across a variety of application scenarios. However, previous methods were insufficient for detecting and recognizing text instances, such as variations in text size, chaotic background and diverse text orientations. To address these challenges, this paper proposes a novel methodology based on Text Stroke Components (TSC). The method leverages Harris corner detection to identify critical points of text strokes, such as endpoints, turning points, and curvatures. By analyzing the clustered regions of these points, the approach effectively localizes text characters. To enhance the detection process, a transparency parameter α is introduced to control the fusion between original images and corner-detection images. This improves the localization of key stroke points, and reduces background noise interference. The proposed method is evaluated through extensive experiments, demonstrating superior performance compared to existing scene text detectors. Furthermore, the method is jointly trained with the ABINet recognition model across all stages. Comprehensive experiments conducted on 13 datasets reveal that this approach significantly outperforms SOTA methods. These results underscore the advantages of using text stroke components for key-point localization through the corner detection algorithm in scene text detection.},
  archive      = {J_IJNS},
  author       = {Xinyue Hou and Pengsen Cheng and Hongyu Gao and Xin Li and Jiayong Liu},
  doi          = {10.1142/S0129065725500200},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2550020},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Scene text detection based on text stroke components},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A heterogeneous attractor model for neural dynamical mechanism of movement preparation. <em>IJNS</em>, <em>35</em>(5), 2550019. (<a href='https://doi.org/10.1142/S0129065725500194'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preparatory activity is crucial for voluntary motor control, reducing reaction time and enhancing precision. To understand the neurodynamic mechanisms behind this, we construct a dynamical model within the motor cortex, which comprises coupled heterogeneous attractors to simulate delayed reaching tasks. This model replicates the neural activity patterns observed in the macaque motor cortex, within distinct attractor spaces for preparatory and executive activities. It can capture the transition from preparation to execution through shifts in an orthogonal subspace combined with a thresholding mechanism. Results show that the preparation duration modulates behavioral accuracy, with optimal preparation intervals enhancing performance. External inputs primarily shape the preparatory activity, while synaptic connections dominate execution. Our analysis of the network’s multi-stable dynamics reveals that external inputs reshape the stable points of the heterogeneous attractor modules both before and after preparation, while synaptic strength affects dynamical stability and input sensitivity, allowing rapid and precise actions. Additionally, sensitivity to external perturbations decreases as preparatory time increases, emphasizing the importance of external inputs during preparation. Overall, this study provides insights into the neurodynamic mechanisms underlying the transition from motor preparation to execution and underscores the significance of preparatory activity for accurate motor control.},
  archive      = {J_IJNS},
  author       = {Lining Yin and Lanyun Cui and Ying Yu and Qingyun Wang},
  doi          = {10.1142/S0129065725500194},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2550019},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A heterogeneous attractor model for neural dynamical mechanism of movement preparation},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding the spatio-temporal coupling of spikes and spindles in focal epilepsy through a network-level computational model. <em>IJNS</em>, <em>35</em>(5), 2550018. (<a href='https://doi.org/10.1142/S0129065725500182'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The electrophysiological findings have shown that epileptiform spikes triggering sleep spindles within 1 s across multiple channels are commonly observed during sleep in focal epilepsy (FE). Such spatio-temporal couplings of spikes and spindles (STCSSs) are defined as a kind of pathological waves, and frequent emergence of them may cause the degradation of cognitive function for FE patients. However, the neural mechanisms underlying STCSSs are not well understood. To this end, this work first develops a neural mass network model for focal epilepsy (FE-NMNM) with multiple thalamocortical columns being its nodes and the long-range synaptic interactions of thalamocortical columns being its edges, where each thalamocortical column is extended on the basis of Costa model and then they are connected through excitatory synapses between pyramidal cells. Then, how the cortico-cortical connectivity affects the evolution of STCSSs across the network is especially discussed by simulations in two cases, where the inter-ictal state and the ictal state are considered separately. Simulation results demonstrate that: (1) the more STCSSs occur in a more extensive area when the cortico-cortical connectivity becomes stronger, and the significant increase of coupling discharges is attributed to the presence of abundant spikes; (2) when the connectivity is excessively strong, the cortical hyperexcitability will happen, thereby inducing massive spike discharges which may further inhibit the occurrence of spindles, and hence, resulting in the disappearance of STCSSs. The obtained results provide a mechanistic insight into STCSSs, and suggest that such coupling patterns could reflect widespread network dysfunction in FE, thereby potentially advancing therapeutic strategies for FE.},
  archive      = {J_IJNS},
  author       = {Min Pan and Qiang Li and Jiangling Song and Bo Wang and Wenhua Wang and Rui Zhang},
  doi          = {10.1142/S0129065725500182},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2550018},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Understanding the spatio-temporal coupling of spikes and spindles in focal epilepsy through a network-level computational model},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised image segmentation using meta-learning and multi-backbone feature fusion. <em>IJNS</em>, <em>35</em>(5), 2550012. (<a href='https://doi.org/10.1142/S0129065725500121'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot segmentation (FSS) aims to reduce the need for manual annotation, which is both expensive and time-consuming. While FSS enhances model generalization to new concepts with only limited test samples, it still relies on a substantial amount of labeled training data for base classes. To address these issues, we propose a multi-backbone few shot segmentation (MBFSS) method. This self-supervised FSS technique utilizes unsupervised saliency for pseudo-labeling, allowing the model to be trained on unlabeled data. In addition, it integrates features from multiple backbones (ResNet, ResNeXt, and PVT v2) to generate a richer feature representation than a single backbone. Through extensive experimentation on PASCAL-5i and COCO-20i, our method achieves 54.3% and 25.1% on one-shot segmentation, exceeding the baseline methods by 13.5% and 4%, respectively. These improvements significantly enhance the model’s performance in real-world applications with negligible labeling effort.},
  archive      = {J_IJNS},
  author       = {Muhammad Shahroz Ajmal and Guohua Geng and Xiaofeng Wang and Mohsin Ashraf},
  doi          = {10.1142/S0129065725500121},
  journal      = {International Journal of Neural Systems},
  number       = {5},
  pages        = {2550012},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Self-supervised image segmentation using meta-learning and multi-backbone feature fusion},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-user confidence in artificial intelligence-based predictions applied to biomedical data. <em>IJNS</em>, <em>35</em>(4), 2550017. (<a href='https://doi.org/10.1142/S0129065725500170'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applications of Artificial Intelligence (AI) are revolutionizing biomedical research and healthcare by offering data-driven predictions that assist in diagnoses. Supervised learning systems are trained on large datasets to predict outcomes for new test cases. However, they typically do not provide an indication of the reliability of these predictions, even though error estimates are integral to model development. Here, we introduce a novel method to identify regions in the feature space that diverge from training data, where an AI model may perform poorly. We utilize a compact precompiled structure that allows for fast and direct access to confidence scores in real time at the point of use without requiring access to the training data or model algorithms. As a result, users can determine when to trust the AI model’s outputs, while developers can identify where the model’s applicability is limited. We validate our approach using simulated data and several biomedical case studies, demonstrating that our approach provides fast confidence estimates ( < 0 . 2 milliseconds per case), with high concordance to previously developed methods ( f - score > 0 . 9 6 5 ). These estimates can be easily added to real-world AI applications. We argue that providing confidence estimates should be a standard practice for all AI applications in public use.},
  archive      = {J_IJNS},
  author       = {Zvi Kam and Lorenzo Peracchio and Giovanna Nicora},
  doi          = {10.1142/S0129065725500170},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550017},
  shortjournal = {Int. J. Neural Syst.},
  title        = {End-user confidence in artificial intelligence-based predictions applied to biomedical data},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Minimal neural network conditions for encoding future interactions. <em>IJNS</em>, <em>35</em>(4), 2550016. (<a href='https://doi.org/10.1142/S0129065725500169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Space and time are fundamental attributes of the external world. Deciphering the brain mechanisms involved in processing the surrounding environment is one of the main challenges in neuroscience. This is particularly defiant when situations change rapidly over time because of the intertwining of spatial and temporal information. However, understanding the cognitive processes that allow coping with dynamic environments is critical, as the nervous system evolved in them due to the pressure for survival. Recent experiments have revealed a new cognitive mechanism called time compaction. According to it, a dynamic situation is represented internally by a static map of the future interactions between the perceived elements (including the subject itself). The salience of predicted interactions (e.g. collisions) over other spatiotemporal and dynamic attributes during the processing of time-changing situations has been shown in humans, rats, and bats. Motivated by this ubiquity, we study an artificial neural network to explore its minimal conditions necessary to represent a dynamic stimulus through the future interactions present in it. We show that, under general and simple conditions, the neural activity linked to the predicted interactions emerges to encode the perceived dynamic stimulus. Our results show that this encoding improves learning, memorization and decision making when dealing with stimuli with impending interactions compared to no-interaction stimuli. These findings are in agreement with theoretical and experimental results that have supported time compaction as a novel and ubiquitous cognitive process.},
  archive      = {J_IJNS},
  author       = {Sergio Diez-Hermano and Gonzalo Aparicio-Rodriguez and Paloma Manubens and Abel Sanchez-Jimenez and Carlos Calvo-Tapia and David Levcik and José Antonio Villacorta-Atienza},
  doi          = {10.1142/S0129065725500169},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550016},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Minimal neural network conditions for encoding future interactions},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-assisted local attention in lower layers of visual transformers. <em>IJNS</em>, <em>35</em>(4), 2550015. (<a href='https://doi.org/10.1142/S0129065725500157'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since vision transformers excel at establishing global relationships between features, they play an important role in current vision tasks. However, the global attention mechanism restricts the capture of local features, making convolutional assistance necessary. This paper indicates that transformer-based models can attend to local information without using convolutional blocks, similar to convolutional kernels, by employing a special initialization method. Therefore, this paper proposes a novel hybrid multi-scale model called Frequency-Assisted Local Attention Transformer (FALAT). FALAT introduces a Frequency-Assisted Window-based Positional Self-Attention (FWPSA) module that limits the attention distance of query tokens, enabling the capture of local contents in the early stage. The information from value tokens in the frequency domain enhances information diversity during self-attention computation. Additionally, the traditional convolutional method is replaced with a depth-wise separable convolution to downsample in the spatial reduction attention module for long-distance contents in the later stages. Experimental results demonstrate that FALAT-S achieves 83.0% accuracy on IN-1k with an input size of 2 2 4 × 2 2 4 using 29.9 M parameters and 5.6 G FLOPs. This model outperforms the Next-ViT-S by 0.9 AP b /0.8 AP m with Mask-R-CNN 1 × on COCO and surpasses the recent FastViT-SA36 by 3.1% mIoU with FPN on ADE20k.},
  archive      = {J_IJNS},
  author       = {Xin Zhou and Zeyu Jiang and Shihua Zhou and Zhaohui Ren and Yongchao Zhang and Tianzhuang Yu and Yulin Liu},
  doi          = {10.1142/S0129065725500157},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550015},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Frequency-assisted local attention in lower layers of visual transformers},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online and cross-user finger movement pattern recognition by decoding neural drive information from surface electromyogram. <em>IJNS</em>, <em>35</em>(4), 2550014. (<a href='https://doi.org/10.1142/S0129065725500145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-user variability is a well-known challenge that leads to severe performance degradation and impacts the robustness of practical myoelectric control systems. To address this issue, a novel method for myoelectric recognition of finger movement patterns is proposed by incorporating a neural decoding approach with unsupervised domain adaption (UDA) learning. In our method, the neural decoding approach is implemented by extracting microscopic features characterizing individual motor unit (MU) activities obtained from a two-stage online surface electromyogram (SEMG) decomposition. A specific deep learning model is designed and initially trained using labeled data from a set of existing users. The model can update adaptively when recognizing the movement patterns of a new user. The final movement pattern was determined by a fuzzy weighted decision strategy. SEMG signals were collected from the finger extensor muscles of 15 subjects to detect seven dexterous finger-movement patterns. The proposed method achieved a movement pattern recognition accuracy of ( 9 3 . 9 4 ± 1 . 5 4 )% over seven movements under cross-user testing scenarios, much higher than that of the conventional methods using global SEMG features. Our study presents a novel robust myoelectric pattern recognition approach at a fine-grained MU level, with wide applications in neural interface and prosthesis control.},
  archive      = {J_IJNS},
  author       = {Haowen Zhao and Yunfei Liu and Xinhui Li and Xiang Chen and Xu Zhang},
  doi          = {10.1142/S0129065725500145},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550014},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Online and cross-user finger movement pattern recognition by decoding neural drive information from surface electromyogram},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Architecture knowledge distillation for evolutionary generative adversarial network. <em>IJNS</em>, <em>35</em>(4), 2550013. (<a href='https://doi.org/10.1142/S0129065725500133'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) are effective for image generation, but their unstable training limits broader applications. Additionally, neural architecture search (NAS) for GANs with one-shot models often leads to insufficient subnet training, where subnets inherit weights from a supernet without proper optimization, further degrading performance. To address both issues, we propose Architecture Knowledge Distillation for Evolutionary GAN (AKD-EGAN). AKD-EGAN operates in two stages. First, architecture knowledge distillation (AKD) is used during supernet training to efficiently optimize subnetworks and accelerate learning. Second, a multi-objective evolutionary algorithm (MOEA) searches for optimal subnet architectures, ensuring efficiency by considering multiple performance metrics. This approach, combined with a strategy for architecture inheritance, enhances GAN stability and image quality. Experiments show that AKD-EGAN surpasses state-of-the-art methods, achieving a Fréchet Inception Distance (FID) of 7.91 and an Inception Score (IS) of 8.97 on CIFAR-10, along with competitive results on STL-10 (FID: 20.32, IS: 10.06). Code and models will be available at https://github.com/njit-ly/AKD-EGAN .},
  archive      = {J_IJNS},
  author       = {Yu Xue and Yan Lin and Ferrante Neri},
  doi          = {10.1142/S0129065725500133},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550013},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Architecture knowledge distillation for evolutionary generative adversarial network},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autism spectrum disorder detection using prominent connectivity features from electroencephalography. <em>IJNS</em>, <em>35</em>(3), 2550011. (<a href='https://doi.org/10.1142/S012906572550011X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism Spectrum Disorder (ASD) is a disorder of brain growth with great variability whose clinical presentation initially shows up during early stages or youth, and ASD follows a repetitive pattern of behavior in most cases. Accurate diagnosis of ASD has been difficult in clinical practice as there is currently no valid indicator of ASD. Since ASD is regarded as a neurodevelopmental disorder, brain signals specially electroencephalography (EEG) are an effective method for detecting ASD. Therefore, this research aims at developing a method of extracting features from EEG signal for discriminating between ASD and control subjects. This study applies six prominent connectivity features, namely Cross Correlation (XCOR), Phase Locking Value (PLV), Pearson’s Correlation Coefficient (PCC), Mutual Information (MI), Normalized Mutual Information (NMI) and Transfer Entropy (TE), for feature extraction. The Connectivity Feature Maps (CFMs) are constructed and used for classification through Convolutional Neural Network (CNN). As CFMs contain spatial information, they are able to distinguish ASD and control subjects better than other features. Rigorous experimentation has been performed on the EEG datasets collected from Italy and Saudi Arabia according to different criteria. MI feature shows the best result for categorizing ASD and control participants with increased sample size and segmentation.},
  archive      = {J_IJNS},
  author       = {Zahrul Jannat Peya and Mahfuza Akter Maria and Sk Imran Hossain and M. A. H. Akhand and Nazmul Siddique},
  doi          = {10.1142/S012906572550011X},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550011},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Autism spectrum disorder detection using prominent connectivity features from electroencephalography},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label zero-shot learning via contrastive label-based attention. <em>IJNS</em>, <em>35</em>(3), 2550010. (<a href='https://doi.org/10.1142/S0129065725500108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label zero-shot learning (ML-ZSL) strives to recognize all objects in an image, regardless of whether they are present in the training data. Recent methods incorporate an attention mechanism to locate labels in the image and generate class-specific semantic information. However, the attention mechanism built on visual features treats label embeddings equally in the prediction score, leading to severe semantic ambiguity. This study focuses on efficiently utilizing semantic information in the attention mechanism. We propose a contrastive label-based attention method (CLA) to associate each label with the most relevant image regions. Specifically, our label-based attention, guided by the latent label embedding, captures discriminative image details. To distinguish region-wise correlations, we implement a region-level contrastive loss. In addition, we utilize a global feature alignment module to identify labels with general information. Extensive experiments on two benchmarks, NUS-WIDE and Open Images, demonstrate that our CLA outperforms the state-of-the-art methods. Especially under the ZSL setting, our method achieves 2.0% improvements in mean Average Precision (mAP) for NUS-WIDE and 4.0% for Open Images compared with recent methods.},
  archive      = {J_IJNS},
  author       = {Shixuan Meng and Rongxin Jiang and Xiang Tian and Fan Zhou and Yaowu Chen and Junjie Liu and Chen Shen},
  doi          = {10.1142/S0129065725500108},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550010},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Multi-label zero-shot learning via contrastive label-based attention},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unraveling the differential efficiency of dorsal and ventral pathways in visual semantic decoding. <em>IJNS</em>, <em>35</em>(3), 2550009. (<a href='https://doi.org/10.1142/S0129065725500091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual semantic decoding aims to extract perceived semantic information from the visual responses of the human brain and convert it into interpretable semantic labels. Although significant progress has been made in semantic decoding across individual visual cortices, studies on the semantic decoding of the ventral and dorsal cortical visual pathways remain limited. This study proposed a graph neural network (GNN)-based semantic decoding model on a natural scene dataset (NSD) to investigate the decoding differences between the dorsal and ventral pathways in process various parts of speech, including verbs, nouns, and adjectives. Our results indicate that the decoding accuracies for verbs and nouns with motion attributes were significantly higher for the dorsal pathway as compared to those for the ventral pathway. Comparative analyses reveal that the dorsal pathway significantly outperformed the ventral pathway in terms of decoding performance for verbs and nouns with motion attributes, with evidence showing that this superiority largely stemmed from higher-level visual cortices rather than lower-level ones. Furthermore, these two pathways appear to converge in their heightened sensitivity toward semantic content related to actions. These findings reveal unique visual neural mechanisms through which the dorsal and ventral cortical pathways segregate and converge when processing stimuli with different semantic categories.},
  archive      = {J_IJNS},
  author       = {Wei Huang and Ying Tang and Sizhuo Wang and Jingpeng Li and Kaiwen Cheng and Hongmei Yan},
  doi          = {10.1142/S0129065725500091},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550009},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Unraveling the differential efficiency of dorsal and ventral pathways in visual semantic decoding},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel state space model with dynamic graphic neural network for EEG event detection. <em>IJNS</em>, <em>35</em>(3), 2550008. (<a href='https://doi.org/10.1142/S012906572550008X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) is a widely used physiological signal to obtain information of brain activity, and its automatic detection holds significant research importance, which saves doctors’ time, improves detection efficiency and accuracy. However, current automatic detection studies face several challenges: large EEG data volumes require substantial time and space for data reading and model training; EEG’s long-term dependencies test the temporal feature extraction capabilities of models; and the dynamic changes in brain activity and the non-Euclidean spatial structure between electrodes complicate the acquisition of spatial information. The proposed method uses range-EEG (rEEG) to extract time-frequency features from EEG to reduce data volume and resource consumption. Additionally, the next-generation state-space model Mamba is utilized as a temporal feature extractor to effectively capture the temporal information in EEG data. To address the limitations of state space models (SSMs) in spatial feature extraction, Mamba is combined with Dynamic Graph Neural Networks, creating an efficient model called DG-Mamba for EEG event detection. Testing on seizure detection and sleep stage classification tasks showed that the proposed method improved training speed by 10 times and reduced memory usage to less than one-seventh of the original data while maintaining superior performance. On the TUSZ dataset, DG-Mamba achieved an AUROC of 0.931 for seizure detection and in the sleep stage classification task, the proposed model surpassed all baselines.},
  archive      = {J_IJNS},
  author       = {Xinying Li and Shengjie Yan and Yonglin Wu and Chenyun Dai and Yao Guo},
  doi          = {10.1142/S012906572550008X},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550008},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A novel state space model with dynamic graphic neural network for EEG event detection},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the versatility of spiking neural networks: Applications across diverse scenarios. <em>IJNS</em>, <em>35</em>(3), 2550007. (<a href='https://doi.org/10.1142/S0129065725500078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last few decades, Artificial Neural Networks have become more and more important, evolving into a powerful tool to implement learning algorithms. Spiking neural networks represent the third generation of Artificial Neural Networks; they have earned growing significance due to their remarkable achievements in pattern recognition, finding extensive utility across diverse domains such as e.g. diagnostic medicine. Usually, Spiking Neural Networks are slightly less accurate than other Artificial Neural Networks, but they require a reduced amount of energy to perform calculations; this amount of energy further reduces in a very significant manner if they are implemented on hardware specifically designed for them, like neuromorphic hardware. In this work, we focus on exploring the versatility of Spiking Neural Networks and their potential applications across a range of scenarios by exploiting their adaptability and dynamic processing capabilities, which make them suitable for various tasks. A first rough network is designed based on the dataset’s general attributes; the network is then refined through an extensive grid search algorithm to identify the optimal values for hyperparameters. This dual-step process ensures that the Spiking Neural Network can be tailored to diverse and potentially very different situations in a direct and intuitive manner. We test this by considering three different scenarios: epileptic seizure detection, both considering binary and multi-classification tasks, as well as wine classification. The proposed methodology turned out to be highly effective in binary class scenarios: the Spiking Neural Networks models achieved significantly lower energy consumption compared to Artificial Neural Networks while approaching nearly 100% accuracy. In the case of multi-class classification, the model achieved an accuracy of approximately 90%, thus indicating that it can still be further improved.},
  archive      = {J_IJNS},
  author       = {Matteo Cavaleri and Claudio Zandron},
  doi          = {10.1142/S0129065725500078},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550007},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Exploring the versatility of spiking neural networks: Applications across diverse scenarios},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A context-dependent CNN-based framework for multiple sclerosis segmentation in MRI. <em>IJNS</em>, <em>35</em>(3), 2550006. (<a href='https://doi.org/10.1142/S0129065725500066'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite several automated strategies for identification/segmentation of Multiple Sclerosis (MS) lesions in Magnetic Resonance Imaging (MRI) being developed, they consistently fall short when compared to the performance of human experts. This emphasizes the unique skills and expertise of human professionals in dealing with the uncertainty resulting from the vagueness and variability of MS, the lack of specificity of MRI concerning MS, and the inherent instabilities of MRI. Physicians manage this uncertainty in part by relying on their radiological, clinical, and anatomical experience. We have developed an automated framework for identifying and segmenting MS lesions in MRI scans by introducing a novel approach to replicating human diagnosis, a significant advancement in the field. This framework has the potential to revolutionize the way MS lesions are identified and segmented, being based on three main concepts: (1) Modeling the uncertainty; (2) Use of separately trained Convolutional Neural Networks (CNNs) optimized for detecting lesions, also considering their context in the brain, and to ensure spatial continuity; (3) Implementing an ensemble classifier to combine information from these CNNs. The proposed framework has been trained, validated, and tested on a single MRI modality, the FLuid-Attenuated Inversion Recovery (FLAIR) of the MSSEG benchmark public data set containing annotated data from seven expert radiologists and one ground truth. The comparison with the ground truth and each of the seven human raters demonstrates that it operates similarly to human raters. At the same time, the proposed model demonstrates more stability, effectiveness and robustness to biases than any other state-of-the-art model though using just the FLAIR modality.},
  archive      = {J_IJNS},
  author       = {Giuseppe Placidi and Luigi Cinque and Gian Luca Foresti and Francesca Galassi and Filippo Mignosi and Michele Nappi and Matteo Polsinelli},
  doi          = {10.1142/S0129065725500066},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550006},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A context-dependent CNN-based framework for multiple sclerosis segmentation in MRI},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cloud detection network based on adaptive laplacian coordination enhanced cross-feature U-net. <em>IJNS</em>, <em>35</em>(2), 2550005. (<a href='https://doi.org/10.1142/S0129065725500054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud cover experiences rapid fluctuations, significantly impacting the irradiance reaching the ground and causing frequent variations in photovoltaic power output. Accurate detection of thin and fragmented clouds is crucial for reliable photovoltaic power generation forecasting. In this paper, we introduce a novel cloud detection method, termed Adaptive Laplacian Coordination Enhanced Cross-Feature U-Net (ALCU-Net). This method augments the traditional U-Net architecture with three innovative components: an Adaptive Feature Coordination (AFC) module, an Adaptive Laplacian Cross-Feature U-Net with a Multi-Grained Laplacian-Enhanced (MLE) feature module, and a Criss-Cross Feature Fused Detection (CCFE) module. The AFC module enhances spatial coherence and bridges semantic gaps across multi-channel images. The Adaptive Laplacian Cross-Feature U-Net integrates features from adjacent hierarchical levels, using the MLE module to refine cloud characteristics and edge details over time. The CCFE module, embedded in the U-Net decoder, leverages criss-cross features to improve detection accuracy. Experimental evaluations show that ALCU-Net consistently outperforms existing cloud detection methods, demonstrating superior accuracy in identifying both thick and thin clouds and in mapping fragmented cloud patches across various environments, including oceans, polar regions, and complex ocean-land mixtures.},
  archive      = {J_IJNS},
  author       = {Kaizheng Wang and Ruohan Zhou and Jian Wang and Ferrante Neri and Yitong Fu and Shunzhen Zhou},
  doi          = {10.1142/S0129065725500054},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2550005},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A cloud detection network based on adaptive laplacian coordination enhanced cross-feature U-net},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anomaly detection using complete cycle consistent generative adversarial network. <em>IJNS</em>, <em>35</em>(2), 2550004. (<a href='https://doi.org/10.1142/S0129065725500042'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research presents a robust adversarial method for anomaly detection in real-world scenarios, leveraging the power of generative adversarial neural networks (GANs) through cycle consistency in reconstruction error. Traditional approaches often falter due to high variance in class-wise accuracy, rendering them ineffective across different anomaly types. Our proposed model addresses these challenges by introducing an innovative flow of information in the training procedure and integrating it as a new discriminator into the framework, thereby optimizing the training dynamics. Furthermore, it employs a supplementary distribution in the input space to steer reconstructions toward the normal data distribution. This adjustment distinctly isolates anomalous instances and enhances detection precision. Also, two unique anomaly scoring mechanisms were developed to augment detection capabilities. Comprehensive evaluations on six varied datasets have confirmed that our model outperforms one-class anomaly detection benchmarks. The implementation is openly accessible to the academic community, available on Github. a},
  archive      = {J_IJNS},
  author       = {Zahra Dehghanian and Saeed Saravani and Maryam Amirmazlaghani and Mohamad Rahmati},
  doi          = {10.1142/S0129065725500042},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2550004},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Anomaly detection using complete cycle consistent generative adversarial network},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A modified transformer network for seizure detection using EEG signals. <em>IJNS</em>, <em>35</em>(2), 2550003. (<a href='https://doi.org/10.1142/S0129065725500030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seizures have a serious impact on the physical function and daily life of epileptic patients. The automated detection of seizures can assist clinicians in taking preventive measures for patients during the diagnosis process. The combination of deep learning (DL) model with convolutional neural network (CNN) and transformer network can effectively extract both local and global features, resulting in improved seizure detection performance. In this study, an enhanced transformer network named Inresformer is proposed for seizure detection, which is combined with Inception and Residual network extracting different scale features of electroencephalography (EEG) signals to enrich the feature representation. In addition, the improved transformer network replaces the existing Feedforward layers with two half-step Feedforward layers to enhance the nonlinear representation of the model. The proposed architecture utilizes discrete wavelet transform (DWT) to decompose the original EEG signals, and the three sub-bands are selected for signal reconstruction. Then, the Co-MixUp method is adopted to solve the problem of data imbalance, and the processed signals are sent to the Inresformer network for seizure information capture and recognition. Finally, discriminant fusion is performed on the results of three-scale EEG sub-signals to achieve final seizure recognition. The proposed network achieves the best accuracy of 100% on Bonn dataset and the average accuracy of 98.03%, sensitivity of 95.65%, and specificity of 98.57% on the long-term CHB-MIT dataset. Compared to the existing DL networks, the proposed method holds significant potential for clinical research and diagnosis applications with competitive performance.},
  archive      = {J_IJNS},
  author       = {Wenrong Hu and Juan Wang and Feng Li and Daohui Ge and Yuxia Wang and Qingwei Jia and Shasha Yuan},
  doi          = {10.1142/S0129065725500030},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2550003},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A modified transformer network for seizure detection using EEG signals},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SATEER: Subject-aware transformer for EEG-based emotion recognition. <em>IJNS</em>, <em>35</em>(2), 2550002. (<a href='https://doi.org/10.1142/S0129065725500029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a Subject-Aware Transformer-based neural network designed for the Electroencephalogram (EEG) Emotion Recognition task (SATEER), which entails the analysis of EEG signals to classify and interpret human emotional states. SATEER processes the EEG waveforms by transforming them into Mel spectrograms, which can be seen as particular cases of images with the number of channels equal to the number of electrodes used during the recording process; this type of data can thus be processed using a Computer Vision pipeline. Distinct from preceding approaches, this model addresses the variability in individual responses to identical stimuli by incorporating a User Embedder module. This module enables the association of individual profiles with their EEGs, thereby enhancing classification accuracy. The efficacy of the model was rigorously evaluated using four publicly available datasets, demonstrating superior performance over existing methods in all conducted benchmarks. For instance, on the AMIGOS dataset (A dataset for Multimodal research of affect, personality traits, and mood on Individuals and GrOupS), SATEER’s accuracy exceeds 99.8% accuracy across all labels and showcases an improvement of 0.47% over the state of the art. Furthermore, an exhaustive ablation study underscores the pivotal role of the User Embedder module and each other component of the presented model in achieving these advancements.},
  archive      = {J_IJNS},
  author       = {Romeo Lanzino and Danilo Avola and Federico Fontana and Luigi Cinque and Francesco Scarcello and Gian Luca Foresti},
  doi          = {10.1142/S0129065725500029},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2550002},
  shortjournal = {Int. J. Neural Syst.},
  title        = {SATEER: Subject-aware transformer for EEG-based emotion recognition},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse spike feature learning to recognize traceable interictal epileptiform spikes. <em>IJNS</em>, <em>35</em>(2), 2450071. (<a href='https://doi.org/10.1142/S0129065724500710'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interictal epileptiform spikes (spikes) and epileptogenic focus are strongly correlated. However, partial spikes are insensitive to epileptogenic focus, which restricts epilepsy neurosurgery. Therefore, identifying spike subtypes that are strongly associated with epileptogenic focus (traceable spikes) could facilitate their use as reliable signal sources for accurately tracing epileptogenic focus. However, the sparse firing phenomenon in the transmission of intracranial neuronal discharges leads to differences within spikes that cannot be observed visually. Therefore, neuro-electro-physiologists are unable to identify traceable spikes that could accurately locate epileptogenic focus. Herein, we propose a novel sparse spike feature learning method to recognize traceable spikes and extract discrimination information related to epileptogenic focus. First, a multilevel eigensystem feature representation was determined based on a multilevel feature representation module to express the intrinsic properties of a spike. Second, the sparse feature learning module expressed the sparse spike multi-domain context feature representation to extract sparse spike feature representations. Among them, a sparse spike encoding strategy was implemented to effectively simulate the sparse firing phenomenon for the accurate encoding of the activity of intracranial neurosources. The sensitivity of the proposed method was 97.1%, demonstrating its effectiveness and significant efficiency relative to other state-of-the-art methods.},
  archive      = {J_IJNS},
  author       = {Chenchen Cheng and Yunbo Shi and Yan Liu and Bo You and Yuanfeng Zhou and Ardalan Aarabi and Yakang Dai},
  doi          = {10.1142/S0129065724500710},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2450071},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Sparse spike feature learning to recognize traceable interictal epileptiform spikes},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning recognition of paroxysmal kinesigenic dyskinesia based on EEG functional connectivity. <em>IJNS</em>, <em>35</em>(1), 2550001. (<a href='https://doi.org/10.1142/S0129065725500017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Paroxysmal kinesigenic dyskinesia (PKD) is a rare neurological disorder marked by transient involuntary movements triggered by sudden actions. Current diagnostic approaches, including genetic screening, face challenges in identifying secondary cases due to symptom overlap with other disorders. This study introduces a novel PKD recognition method utilizing a resting-state electroencephalogram (EEG) functional connectivity matrix and a deep learning architecture (AT-1CBL). Resting-state EEG data from 44 PKD patients and 44 healthy controls (HCs) were collected using a 128-channel EEG system. Functional connectivity matrices were computed and transformed into graph data to examine brain network property differences between PKD patients and controls through graph theory. Source localization was conducted to explore neural circuit differences in patients. The AT-1CBL model, integrating 1D-CNN and Bi-LSTM with attentional mechanisms, achieved a classification accuracy of 93.77% on phase lag index (PLI) features in the Theta band. Graph theoretic analysis revealed significant phase synchronization impairments in the Theta band of the functional brain network in PKD patients, particularly in the distribution of weak connections compared to HCs. Source localization analyses indicated greater differences in functional connectivity in sensorimotor regions and the frontal-limbic system in PKD patients, suggesting abnormalities in motor integration related to clinical symptoms. This study highlights the potential of deep learning models based on EEG functional connectivity for accurate and cost-effective PKD diagnosis, supporting the development of portable EEG devices for clinical monitoring and diagnosis. However, the limited dataset size may affect generalizability, and further exploration of multimodal data integration and advanced deep learning architectures is necessary to enhance the robustness of PKD diagnostic models.},
  archive      = {J_IJNS},
  author       = {Liang Zhao and Renling Zou and Linpeng Jin},
  doi          = {10.1142/S0129065725500017},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2550001},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Deep learning recognition of paroxysmal kinesigenic dyskinesia based on EEG functional connectivity},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoding continuous tracking eye movements from cortical spiking activity. <em>IJNS</em>, <em>35</em>(1), 2450070. (<a href='https://doi.org/10.1142/S0129065724500709'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eye movements are the primary way primates interact with the world. Understanding how the brain controls the eyes is therefore crucial for improving human health and designing visual rehabilitation devices. However, brain activity is challenging to decipher. Here, we leveraged machine learning algorithms to reconstruct tracking eye movements from high-resolution neuronal recordings. We found that continuous eye position could be decoded with high accuracy using spiking data from only a few dozen cortical neurons. We tested eight decoders and found that neural network models yielded the highest decoding accuracy. Simpler models performed well above chance with a substantial reduction in training time. We measured the impact of data quantity (e.g. number of neurons) and data format (e.g. bin width) on training time, inference time, and generalizability. Training models with more input data improved performance, as expected, but the format of the behavioral output was critical for emphasizing or omitting specific oculomotor events. Our results provide the first demonstration, to our knowledge, of continuously decoded eye movements across a large field of view. Our comprehensive investigation of predictive power and computational efficiency for common decoder architectures provides a much-needed foundation for future work on real-time gaze-tracking devices.},
  archive      = {J_IJNS},
  author       = {Kendra K. Noneman and J. Patrick Mayo},
  doi          = {10.1142/S0129065724500709},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2450070},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Decoding continuous tracking eye movements from cortical spiking activity},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing motor imagery classification with residual graph convolutional networks and multi-feature fusion. <em>IJNS</em>, <em>35</em>(1), 2450069. (<a href='https://doi.org/10.1142/S0129065724500692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stroke, an abrupt cerebrovascular ailment resulting in brain tissue damage, has prompted the adoption of motor imagery (MI)-based brain–computer interface (BCI) systems in stroke rehabilitation. However, analyzing electroencephalogram (EEG) signals from stroke patients poses challenges. To address the issues of low accuracy and efficiency in EEG classification, particularly involving MI, the study proposes a residual graph convolutional network (M-ResGCN) framework based on the modified S -transform (MST), and introduces the self-attention mechanism into residual graph convolutional network (ResGCN). This study uses MST to extract EEG time-frequency domain features, derives spatial EEG features by calculating the absolute Pearson correlation coefficient (aPcc) between channels, and devises a method to construct the adjacency matrix of the brain network using aPcc to measure the strength of the connection between channels. Experimental results involving 16 stroke patients and 16 healthy subjects demonstrate significant improvements in classification quality and robustness across tests and subjects. The highest classification accuracy reached 94.91% and a Kappa coefficient of 0.8918. The average accuracy and F 1 scores from 10 times 10-fold cross-validation are 94.38% and 94.36%, respectively. By validating the feasibility and applicability of brain networks constructed using the aPcc in EEG signal analysis and feature encoding, it was established that the aPcc effectively reflects overall brain activity. The proposed method presents a novel approach to exploring channel relationships in MI-EEG and improving classification performance. It holds promise for real-time applications in MI-based BCI systems.},
  archive      = {J_IJNS},
  author       = {Fangzhou Xu and Weiyou Shi and Chengyan Lv and Yuan Sun and Shuai Guo and Chao Feng and Yang Zhang and Tzyy-Ping Jung and Jiancai Leng},
  doi          = {10.1142/S0129065724500692},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2450069},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Enhancing motor imagery classification with residual graph convolutional networks and multi-feature fusion},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural memory state space models for medical image segmentation. <em>IJNS</em>, <em>35</em>(1), 2450068. (<a href='https://doi.org/10.1142/S0129065724500680'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of deep learning, computer-aided diagnosis and treatment have become crucial in medicine. UNet is a widely used architecture for medical image segmentation, and various methods for improving UNet have been extensively explored. One popular approach is incorporating transformers, though their quadratic computational complexity poses challenges. Recently, State-Space Models (SSMs), exemplified by Mamba, have gained significant attention as a promising alternative due to their linear computational complexity. Another approach, neural memory Ordinary Differential Equations (nmODEs), exhibits similar principles and achieves good results. In this paper, we explore the respective strengths and weaknesses of nmODEs and SSMs and propose a novel architecture, the nmSSM decoder, which combines the advantages of both approaches. This architecture possesses powerful nonlinear representation capabilities while retaining the ability to preserve input and process global information. We construct nmSSM-UNet using the nmSSM decoder and conduct comprehensive experiments on the PH2, ISIC2018, and BU-COCO datasets to validate its effectiveness in medical image segmentation. The results demonstrate the promising application value of nmSSM-UNet. Additionally, we conducted ablation experiments to verify the effectiveness of our proposed improvements on SSMs and nmODEs.},
  archive      = {J_IJNS},
  author       = {Zhihua Wang and Jingjun Gu and Wang Zhou and Quansong He and Tianli Zhao and Jialong Guo and Li Lu and Tao He and Jiajun Bu},
  doi          = {10.1142/S0129065724500680},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2450068},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Neural memory state space models for medical image segmentation},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatially selective retinal ganglion cell activation using low invasive extraocular temporal interference stimulation. <em>IJNS</em>, <em>35</em>(1), 2450066. (<a href='https://doi.org/10.1142/S0129065724500667'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional retinal implants involve complex surgical procedures and require invasive implantation. Temporal Interference Stimulation (TIS) has achieved noninvasive and focused stimulation of deep brain regions by delivering high-frequency currents with small frequency differences on multiple electrodes. In this study, we conducted in silico investigations to evaluate extraocular TIS’s potential as a novel visual restoration approach. Different from the previously published retinal TIS model, the new model of extraocular TIS incorporated a biophysically detailed retinal ganglion cell (RGC) population, enabling a more accurate simulation of retinal outputs under electrical stimulation. Using this improved model, we made the following major discoveries: (1) the maximum value of TIS envelope electric potential ( EP max ) showed a strong correlation with TIS-induced RGC activation; (2) the preferred stimulating/return electrode (SE/RE) locations to achieve focalized TIS were predicted; (3) the performance of extraocular TIS was better than same-frequency sinusoidal stimulation (SSS) in terms of lower RGC threshold and more focused RGC activation; (4) the optimal stimulation parameters to achieve lower threshold and focused activation were identified; and (5) spatial selectivity of TIS could be improved by integrating current steering strategy and reducing electrode size. This study provides insights into the feasibility and effectiveness of a low-invasive stimulation approach in enhancing vision restoration.},
  archive      = {J_IJNS},
  author       = {Xiaoyu Song and Tianruo Guo and Saidong Ma and Feng Zhou and Jiaxin Tian and Zhengyang Liu and Jiao Liu and Heng Li and Yao Chen and Xinyu Chai and Liming Li},
  doi          = {10.1142/S0129065724500667},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2450066},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Spatially selective retinal ganglion cell activation using low invasive extraocular temporal interference stimulation},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
