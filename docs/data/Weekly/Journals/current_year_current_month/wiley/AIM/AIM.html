<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AIM</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aim">AIM - 13</h2>
<ul>
<li><details>
<summary>
(2025). From abstraction to reality: DARPA's vision for robust sim-to-real autonomy. <em>AIM</em>, <em>46</em>(2), e70015. (<a href='https://doi.org/10.1002/aaai.70015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The DARPA Transfer from Imprecise and Abstract Models to Autonomous Technologies (TIAMAT) program aims to address rapid and robust transfer of autonomy technologies across dynamic and complex environments, goals, and platforms. Existing methods for simulation-to-reality (sim-to-real) transfer often rely on high-fidelity simulations and struggle with broad adaptation, particularly in time-sensitive scenarios. Although many approaches have shown incredible performance at specific tasks, most techniques fall short when posed with unforeseen, complex, and dynamic real-world scenarios due to the inherent limitations of simulation. In contrast to current research that aims to bridge the gap between simulation environments and the real world through increasingly sophisticated simulations and a combination of methods typically assuming a small sim-to-real gap—such as domain randomization, domain adaptation, imitation learning, meta-learning, policy distillation, and dynamic optimization—TIAMAT takes a different approach by instead emphasizing transfer and adaptation of the autonomy stack directly to real-world environments by utilizing a breadth of low(er)-fidelity simulations to create broadly effective sim-to-real transfers. By abstractly learning from multiple simulation environments in reference to their shared semantics, TIAMAT's approaches aim to achieve abstract-to-real transfer for effective and rapid real-world adaptation. Furthermore, this program endeavors to improve the overall autonomy pipeline by addressing the inherent challenges in translating simulated behaviors into effective real-world performance.},
  archive      = {J_AIM},
  author       = {Erfaun Noorani and Zachary Serlin and Ben Price and Alvaro Velasquez},
  doi          = {10.1002/aaai.70015},
  journal      = {AI Magazine},
  month        = {Summer},
  number       = {2},
  pages        = {e70015},
  shortjournal = {AI Mag.},
  title        = {From abstraction to reality: DARPA's vision for robust sim-to-real autonomy},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attracting artificial intelligence talent in the time of generative AI. <em>AIM</em>, <em>46</em>(2), e70014. (<a href='https://doi.org/10.1002/aaai.70014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public statements by leading AI researchers and recognizable people in the computer world are suggesting that AI may soon replace many jobs, including software engineers. Some even state that soon, AI will be smarter than us. We believe such statements are unhelpful when it comes to attracting talent to our field. We document several such statements. We believe that the future need for AI talent is tremendous and that we should take extreme efforts to attract students to our field. We present a sample of the expected opportunities and needs. Some of these opportunities may be attractive to students who in the past may not have considered AI as a career option. We argue that even with the anticipated automation of AI work, there nevertheless will be a prodigious need for talent to develop good AI. We summarize work that argues that AI is going to be a fundamental skill and as such should be introduced to learners across many age groups and many backgrounds. We suggest that a well-reasoned statement of the anticipated needs be developed by experts in our field and communicated to future talent. We suggest that, as part of this message, pathways forward toward developing AI talent across a wide range of backgrounds be developed and communicated.},
  archive      = {J_AIM},
  author       = {Michael Wollowski},
  doi          = {10.1002/aaai.70014},
  journal      = {AI Magazine},
  month        = {Summer},
  number       = {2},
  pages        = {e70014},
  shortjournal = {AI Mag.},
  title        = {Attracting artificial intelligence talent in the time of generative AI},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence education in georgia middle schools. <em>AIM</em>, <em>46</em>(2), e70013. (<a href='https://doi.org/10.1002/aaai.70013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a partnership between four universities, the Georgia Department of Education, and nine Georgia school districts, we developed a 9-week middle school elective called “Living and Working with Artificial Intelligence,” and a professional development (PD) program for prospective middle school AI teachers. To ensure that our curriculum could meet the needs of all learners, we recruited a diverse set of districts that included rural districts serving mainly White students, urban districts that were majority African American, and suburban districts serving a mix of Hispanic and African American students. Now in its fourth year, our “AI for Georgia” project (AI4GA) has provided PD to 20 teachers and AI education to over 1600 students. The AI4GA curriculum does more than foster AI literacy: It empowers students to view themselves as creators of AI-powered technology and to think about future career options that involve the use of AI. The project is now expanding to schools in Texas and Florida. In this article, we review the history of the project, discuss our co-design process with our teachers, and present results from studies of teacher PD and student learning.},
  archive      = {J_AIM},
  author       = {David S. Touretzky and Christina Gardner-McCune and Bryan Cox and Judith Uchidiuno and Xueru Yu and William Gelder and Tom McKlin and Taneisha Lee Brown and Bejanae Kareem and Woojin Chung and Amber Jones and Janet Kolodner},
  doi          = {10.1002/aaai.70013},
  journal      = {AI Magazine},
  month        = {Summer},
  number       = {2},
  pages        = {e70013},
  shortjournal = {AI Mag.},
  title        = {Artificial intelligence education in georgia middle schools},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Navigating the new frontier: The role of AI-driven virtual influencers in consumer engagement. <em>AIM</em>, <em>46</em>(2), e70012. (<a href='https://doi.org/10.1002/aaai.70012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the evolving role of artificial intelligence (AI)-driven virtual influencers (VIs) in enhancing consumer engagement within the digital marketing landscape. Using qualitative case studies of notable VIs such as Lil Miquela and Ayayi, this research highlights critical factors influencing their effectiveness, including advanced technology, cultural significance, and shifts in consumer expectations. Findings indicate that VIs create authentic connections with younger demographics, particularly Millennials and Generation Z, by offering tailored content and reinforcing emotional ties. The study emphasizes the significance of authenticity and transparency for building consumer trust, alongside addressing ethical concerns such as representation and manipulation in marketing practices. It explores how VIs operate as cultural influencers, reshaping consumer identities within the digital realm. This research underscores the need for brands to adopt responsible practices that prioritize ethical engagement and inclusivity, enabling them to navigate the complexities of VI marketing while fostering meaningful consumer relationships.},
  archive      = {J_AIM},
  author       = {Bo-Chiuan Su},
  doi          = {10.1002/aaai.70012},
  journal      = {AI Magazine},
  month        = {Summer},
  number       = {2},
  pages        = {e70012},
  shortjournal = {AI Mag.},
  title        = {Navigating the new frontier: The role of AI-driven virtual influencers in consumer engagement},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligent disobedience: Rethinking the agency of our artificial teammates. <em>AIM</em>, <em>46</em>(2), e70011. (<a href='https://doi.org/10.1002/aaai.70011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The impressive advancements of AI in recent years are indisputable, and AI algorithms have already reached superhuman performance in many tasks. On the other hand, in most existing work on cooperative AI, artificial agents are bound to follow the instructions they are given by their human teammates and to comply with their users' expectations. This paper advocates for expanding the agency capabilities of AI teammates, enabling them to make genuine and unique contributions in human-AI teams. It presents a scale for AI agency levels and discusses the importance and inevitability of researching AI autonomy as an independent capability in cooperative AI, using a set of representative examples. The paper then presents how intelligent disobedience of artificial agents might look at each autonomy level. Finally, it outlines some initial boundaries that should be set when researching AI agency and its disobedience capabilities.},
  archive      = {J_AIM},
  author       = {Reuth Mirsky},
  doi          = {10.1002/aaai.70011},
  journal      = {AI Magazine},
  month        = {Summer},
  number       = {2},
  pages        = {e70011},
  shortjournal = {AI Mag.},
  title        = {Artificial intelligent disobedience: Rethinking the agency of our artificial teammates},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Governance in the age of artificial intelligence: A comparative analysis of policy framework in BRICS nations. <em>AIM</em>, <em>46</em>(2), e70010. (<a href='https://doi.org/10.1002/aaai.70010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the dynamic landscape of governance frameworks for emerging technologies, particularly artificial intelligence (AI), within the context of public policy in expanded BRICS nations (Brazil, Russia, India, China, South Africa, Egypt, Ethiopia, Iran, and the United Arab Emirates). Understanding the ethical implications and crafting policy tools to guide the development and deployment of AI is crucial. Analyzing findings from AI policy initiatives, this research delves into managing new technologies, emphasizing the evolving discourse on AI ethics. It stresses the importance of embedding ethical considerations into governance frameworks to address societal concerns and foster responsible AI advancement. Additionally, strong legal frameworks are essential, striking a balance between fostering innovation and ensuring accountability, thereby enhancing confidence and transparency in AI systems. This study underscores the significance of public policy in shaping AI governance, advocating for inclusive, participatory approaches involving stakeholders from diverse sectors. Adaptive governance frameworks capable of navigating the evolving AI landscape and its societal ramifications are emphasized. A holistic governance strategy based on insights from AI policy is recommended, aiming to reconcile innovation with ethical, legal, and societal considerations. Policymakers are urged to foster stakeholder engagement, ensuring that AI advancements benefit society while upholding ethical, just, and accountable standards.},
  archive      = {J_AIM},
  author       = {Animesh Kumar Sharma and Rahul Sharma},
  doi          = {10.1002/aaai.70010},
  journal      = {AI Magazine},
  month        = {Summer},
  number       = {2},
  pages        = {e70010},
  shortjournal = {AI Mag.},
  title        = {Governance in the age of artificial intelligence: A comparative analysis of policy framework in BRICS nations},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When science fiction collides with reality: The future of learning and the one after that. <em>AIM</em>, <em>46</em>(2), e70009. (<a href='https://doi.org/10.1002/aaai.70009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article provides a somewhat whimsical discussion of the impact that AI, or “robots”, will have on the future of education. Interwoven with numerous references to science fiction, and at least one to Alice Cooper, is a very serious consideration of the manner in which AI may completely redefine the way we learn and grow as humans. From Holistic Assessment of Learning (HAL) to a Yoda on Yer Shoulda, a future of life-embedding learning is described.},
  archive      = {J_AIM},
  author       = {Steve Joordens},
  doi          = {10.1002/aaai.70009},
  journal      = {AI Magazine},
  month        = {Summer},
  number       = {2},
  pages        = {e70009},
  shortjournal = {AI Mag.},
  title        = {When science fiction collides with reality: The future of learning and the one after that},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Systematically incorporating equity into design thinking for AI education. <em>AIM</em>, <em>46</em>(2), e70008. (<a href='https://doi.org/10.1002/aaai.70008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI-powered systems increasingly influence critical aspects of daily life, yet these systems often embed and reinforce biases, disproportionately disadvantaging marginalized communities. Addressing these challenges requires a fundamental shift in how we teach the development of these systems, ensuring that future professionals develop not only technical expertise but also are equipped with the skills needed for ethical AI design. This paper adopts a design science research (DSR) approach to develop the equity-aware design thinking for AI (EquiThink4AI) framework, a dual-component model that systematically embeds equity principles into AI education. EquiThink4AI's first component extends design thinking (DT) by incorporating principles from EquityXDesign (EXD) and liberatory design (LD), ensuring that equity concerns are proactively addressed throughout AI system development. The second component enhances the framework with pedagogical strategies, including problem-based learning (PBL), experiential learning, and interdisciplinary collaboration, fostering student engagement, real-world problem-solving, and ethical reasoning. EquityThink4AI provides educators and students with a structured methodology for teaching and applying equity-centered AI development. This study is explorative in nature, yet it presents concrete strategies for integrating EquiThink4AI into AI curricula, bridging the gap between design, AI ethics, and educational practices.},
  archive      = {J_AIM},
  author       = {Christelle Scharff and Andreea Cotoranu and Yves Wautelet and James Brusseau},
  doi          = {10.1002/aaai.70008},
  journal      = {AI Magazine},
  month        = {Summer},
  number       = {2},
  pages        = {e70008},
  shortjournal = {AI Mag.},
  title        = {Systematically incorporating equity into design thinking for AI education},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI literacy as a core component of AI education. <em>AIM</em>, <em>46</em>(2), e70007. (<a href='https://doi.org/10.1002/aaai.70007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As generative artificial intelligence (AI) becomes increasingly integrated into society and education, more institutions are implementing AI usage policies and offering introductory AI courses. These courses, however, should not replicate the technical focus typically found in introductory computer science (CS) courses like CS1 and CS2. In this paper, we use an adjustable, interdisciplinary socio-technical AI literacy framework to design and present an introductory AI literacy course. We present a refined version of this framework informed by the teaching of a 1-credit general education AI literacy course (primarily for freshmen and first-year students from various majors), a 3-credit course for CS majors at all levels, and a summer camp for high school students. Drawing from these teaching experiences and the evolving research landscape, we propose an introductory AI literacy course design framework structured around four cross-cutting pillars. These pillars encompass (1) understanding the scope and technical dimensions of AI technologies, (2) learning how to interact with (generative) AI technologies, (3) applying principles of critical, ethical, and responsible AI usage, and (4) analyzing implications of AI on society. We posit that achieving AI literacy is essential for all students, those pursuing AI-related careers, and those following other educational or professional paths. This introductory course, positioned at the beginning of a program, creates a foundation for ongoing and advanced AI education. The course design approach is presented as a series of modules and subtopics under each pillar. We emphasize the importance of thoughtful instructional design, including pedagogy, expected learning outcomes, and assessment strategies. This approach not only integrates social and technical learning but also democratizes AI education across diverse student populations and equips all learners with the socio-technical, multidisciplinary perspectives necessary to navigate and shape the ethical future of AI.},
  archive      = {J_AIM},
  author       = {Sri Yash Tadimalla and Mary Lou Maher},
  doi          = {10.1002/aaai.70007},
  journal      = {AI Magazine},
  month        = {Summer},
  number       = {2},
  pages        = {e70007},
  shortjournal = {AI Mag.},
  title        = {AI literacy as a core component of AI education},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Building trust: Foundations of security, safety, and transparency in AI. <em>AIM</em>, <em>46</em>(2), e70005. (<a href='https://doi.org/10.1002/aaai.70005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the rapidly evolving ecosystem of publicly available AI models and their potential implications on the security and safety landscape. Understanding their potential risks and vulnerabilities is crucial as AI models become increasingly prevalent. We review the current security and safety scenarios while highlighting challenges such as tracking issues, remediation, and the absence of AI model lifecycle and ownership processes. Comprehensive strategies to enhance security and safety for both model developers and end-users are proposed. This paper provides several foundational pieces for more standardized security, safety, and transparency in developing and operating generative AI models and the larger open ecosystems and communities forming around them.},
  archive      = {J_AIM},
  author       = {Huzaifa Sidhpurwala and Garth Mollett and Emily Fox and Mark Bestavros and Huamin Chen},
  doi          = {10.1002/aaai.70005},
  journal      = {AI Magazine},
  month        = {Summer},
  number       = {2},
  pages        = {e70005},
  shortjournal = {AI Mag.},
  title        = {Building trust: Foundations of security, safety, and transparency in AI},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). What is reproducibility in artificial intelligence and machine learning research?. <em>AIM</em>, <em>46</em>(2), e70004. (<a href='https://doi.org/10.1002/aaai.70004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the rapidly evolving fields of artificial intelligence (AI) and machine learning (ML), the reproducibility crisis underscores the urgent need for clear validation methodologies to maintain scientific integrity and encourage advancement. The crisis is compounded by the prevalent confusion over validation terminology. In response to this challenge, we introduce a framework that clarifies the roles and definitions of key validation efforts: repeatability, dependent and independent reproducibility, and direct and conceptual replicability. This structured framework aims to provide AI/ML researchers with the necessary clarity on these essential concepts, facilitating the appropriate design, conduct, and interpretation of validation studies. By articulating the nuances and specific roles of each type of validation study, we aim to enhance the reliability and trustworthiness of research findings and support the community's efforts to address reproducibility challenges effectively.},
  archive      = {J_AIM},
  author       = {Abhyuday Desai and Mohamed Abdelhamid and Nakul R. Padalkar},
  doi          = {10.1002/aaai.70004},
  journal      = {AI Magazine},
  month        = {Summer},
  number       = {2},
  pages        = {e70004},
  shortjournal = {AI Mag.},
  title        = {What is reproducibility in artificial intelligence and machine learning research?},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reproducibility in machine-learning-based research: Overview, barriers, and drivers. <em>AIM</em>, <em>46</em>(2), e70002. (<a href='https://doi.org/10.1002/aaai.70002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many research fields are currently reckoning with issues of poor levels of reproducibility. Some label it a “crisis,” and research employing or building machine learning (ML) models is no exception. Issues including lack of transparency, data or code, poor adherence to standards, and the sensitivity of ML training conditions mean that many papers are not even reproducible in principle. Where they are, though, reproducibility experiments have found worryingly low degrees of similarity with original results. Despite previous appeals from ML researchers on this topic and various initiatives from conference reproducibility tracks to the ACM's new Emerging Interest Group on Reproducibility and Replicability, we contend that the general community continues to take this issue too lightly. Poor reproducibility threatens trust in and integrity of research results. Therefore, in this article, we lay out a new perspective on the key barriers and drivers (both procedural and technical) to increased reproducibility at various levels (methods, code, data, and experiments). We then map the drivers to the barriers to give concrete advice for strategies for researchers to mitigate reproducibility issues in their own work, to lay out key areas where further research is needed in specific areas, and to further ignite discussion on the threat presented by these urgent issues.},
  archive      = {J_AIM},
  author       = {Harald Semmelrock and Tony Ross-Hellauer and Simone Kopeinik and Dieter Theiler and Armin Haberl and Stefan Thalmann and Dominik Kowald},
  doi          = {10.1002/aaai.70002},
  journal      = {AI Magazine},
  month        = {Summer},
  number       = {2},
  pages        = {e70002},
  shortjournal = {AI Mag.},
  title        = {Reproducibility in machine-learning-based research: Overview, barriers, and drivers},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Open issues in open world learning. <em>AIM</em>, <em>46</em>(2), e70001. (<a href='https://doi.org/10.1002/aaai.70001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meaningful progress has been made in open world learning (OWL), enhancing the ability of agents to detect, characterize, and incrementally learn novelty in dynamic environments. However, novelty remains a persistent challenge for agents relying on state-of-the-art learning algorithms. This article considers the current state of OWL, drawing on insights from a recent DARPA research program on this topic. We identify open issues that impede further advancements spanning theory, design, and evaluation. In particular, we emphasize the challenges posed by dynamic scenarios that are crucial to understand for ensuring the viability of agents designed for real-world environments. The article provides suggestions for setting a new research agenda that effectively addresses these open issues.},
  archive      = {J_AIM},
  author       = {Steve Cruz and Katarina Doctor and Christopher Funk and Walter Scheirer},
  doi          = {10.1002/aaai.70001},
  journal      = {AI Magazine},
  month        = {Summer},
  number       = {2},
  pages        = {e70001},
  shortjournal = {AI Mag.},
  title        = {Open issues in open world learning},
  volume       = {46},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
