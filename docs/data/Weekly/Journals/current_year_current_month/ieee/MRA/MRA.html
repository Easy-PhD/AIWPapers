<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MRA</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mra">MRA - 25</h2>
<ul>
<li><details>
<summary>
(2025). Call for IEEE robotics and automation society sustainability grant applications [Society news]. <em>MRA</em>, <em>32</em>(3), 219. (<a href='https://doi.org/10.1109/MRA.2025.3589833'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Provides society information that may include news, reviews or technical notes that should be of interest to practitioners and researchers.},
  archive  = {J},
  doi      = {10.1109/MRA.2025.3589833},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {219},
  title    = {Call for IEEE robotics and automation society sustainability grant applications [Society news]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RAS recognizes 2025 award recipients at IEEE international conference on robotics and automation [Society news]. <em>MRA</em>, <em>32</em>(3), 216-218. (<a href='https://doi.org/10.1109/MRA.2025.3589831'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Provides society information that may include news, reviews or technical notes that should be of interest to practitioners and researchers.},
  archive  = {J},
  doi      = {10.1109/MRA.2025.3589831},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {216-218},
  title    = {RAS recognizes 2025 award recipients at IEEE international conference on robotics and automation [Society news]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The IEEE robotics and automation society congratulates our elevated senior members of 2025 [Society news]. <em>MRA</em>, <em>32</em>(3), 214-216. (<a href='https://doi.org/10.1109/MRA.2025.3589832'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Provides society information that may include news, reviews or technical notes that should be of interest to practitioners and researchers.},
  archive  = {J},
  doi      = {10.1109/MRA.2025.3589832},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {214-216},
  title    = {The IEEE robotics and automation society congratulates our elevated senior members of 2025 [Society news]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mastering Research—Part 1/3: Choose smart, read smarter! [Student’s corner]. <em>MRA</em>, <em>32</em>(3), 210-212. (<a href='https://doi.org/10.1109/MRA.2025.3586428'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Dipam Patel},
  doi     = {10.1109/MRA.2025.3586428},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {9},
  number  = {3},
  pages   = {210-212},
  title   = {Mastering Research—Part 1/3: Choose smart, read smarter! [Student’s corner]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Women in robotics: Insights into the first international conference on intelligent robots and systems in the middle east [Women in engineering]. <em>MRA</em>, <em>32</em>(3), 205-209. (<a href='https://doi.org/10.1109/MRA.2025.3587857'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), held for the first time in the Middle East, featured two key events dedicated to Women in Engineering (WIE): the Empowering Diverse Voices in Robotics (EDVR) Forum and the 2024 IEEE Robotics and Automation Society (RAS) Women in Robotics Luncheon Panel. These events underscored the limited but growing number of women in robotics in the region [1], [2], prompting the development of a comprehensive survey to explore their experiences. This increased representation is particularly valuable given that diverse teams enhance collaboration, improve decision making, and foster greater creativity and performance [3].},
  archive  = {J},
  author   = {Reem Ashour and Sara Aldhaheri and J. Stephany Berrio Perez and Giulia De Masi},
  doi      = {10.1109/MRA.2025.3587857},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {205-209},
  title    = {Women in robotics: Insights into the first international conference on intelligent robots and systems in the middle east [Women in engineering]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CASE 2024: Pioneering innovations in automation and systems engineering [Conference highlights]. <em>MRA</em>, <em>32</em>(3), 201-220. (<a href='https://doi.org/10.1109/MRA.2025.3586662'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Mariagrazia Dotoli and Yu Sun and Carla Seatzu and Paolo Scarabaggio},
  doi     = {10.1109/MRA.2025.3586662},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {9},
  number  = {3},
  pages   = {201-220},
  title   = {CASE 2024: Pioneering innovations in automation and systems engineering [Conference highlights]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ABET’s new accreditation criteria for robotics and mechatronics engineering: A summary [Industry activities]. <em>MRA</em>, <em>32</em>(3), 198-212. (<a href='https://doi.org/10.1109/MRA.2025.3584823'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Joel M. Esposito},
  doi     = {10.1109/MRA.2025.3584823},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {9},
  number  = {3},
  pages   = {198-212},
  title   = {ABET’s new accreditation criteria for robotics and mechatronics engineering: A summary [Industry activities]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fostering innovation in robotics through open environments and standards [Standards]. <em>MRA</em>, <em>32</em>(3), 196-197. (<a href='https://doi.org/10.1109/MRA.2025.3586427'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Nico Peper},
  doi     = {10.1109/MRA.2025.3586427},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {9},
  number  = {3},
  pages   = {196-197},
  title   = {Fostering innovation in robotics through open environments and standards [Standards]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IEEE SA launched new working group p1955: Shaping the future of robotics with 6G [Standards]. <em>MRA</em>, <em>32</em>(3), 195-196. (<a href='https://doi.org/10.1109/MRA.2025.3586425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Mona Ghassemian and Periklis Chatzimisios and Howard Li and Sharief Oteafy and Edson Prestes},
  doi     = {10.1109/MRA.2025.3586425},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {9},
  number  = {3},
  pages   = {195-196},
  title   = {IEEE SA launched new working group p1955: Shaping the future of robotics with 6G [Standards]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GAFRO: Geometric algebra for robotics [Tutorial]. <em>MRA</em>, <em>32</em>(3), 184-194. (<a href='https://doi.org/10.1109/MRA.2024.3433109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Geometry is a fundamental part of robotics and there have been various frameworks of representation over the years. Recently, geometric algebra has gained attention for its property of unifying many of those previous ideas into one algebra. While there are already efficient open-source implementations of geometric algebra available, none of them is targeted at robotics applications. We want to address this shortcoming with our library gafro. This article presents an overview of the implementation details as well as a tutorial of gafro, an efficient C++ library targeting robotics applications using geometric algebra. The library focuses on using conformal geometric algebra. Hence, various geometric primitives are available for computation as well as rigid body transformations. The modeling of robotic systems is also an important aspect of the library. It implements various algorithms for calculating the kinematics and dynamics of such systems as well as objectives for optimization problems. The software stack is completed by Python bindings in pygafro and a ROS interface in gafro_ros.},
  archive  = {J},
  author   = {Tobias Löw and Philip Abbet and Sylvain Calinon},
  doi      = {10.1109/MRA.2024.3433109},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {184-194},
  title    = {GAFRO: Geometric algebra for robotics [Tutorial]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automation and artificial intelligence technology in surface mining: A brief introduction to open-pit operations in the pilbara [Survey]. <em>MRA</em>, <em>32</em>(3), 164-183. (<a href='https://doi.org/10.1109/MRA.2023.3328457'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This survey article provides a synopsis on some of the engineering problems, technological innovations, robotic development and automation efforts encountered in the mining industry—particularly in the Pilbara iron-ore region of Western Australia. The goal is to paint the technology landscape and highlight issues relevant to an engineering audience to raise awareness of AI and automation trends in mining. It assumes the reader has no prior knowledge of mining and builds context gradually through focused discussion and short summaries of common open-pit mining operations. The principal activities that take place may be categorized in terms of resource development, mine-, rail- and port operations. From mineral exploration to ore shipment, there are roughly nine steps in between. These include: geological assessment, mine planning and development, production drilling and assaying, blasting and excavation, transportation of ore and waste, crush and screen, stockpile and load-out, rail network distribution, and ore-car dumping. The objective is to describe these processes and provide insights on some of the challenges / opportunities from the perspective of a decade-long industry-university R&D partnership.},
  archive  = {J},
  author   = {Raymond Leung and Andrew J. Hill and Arman Melkumyan},
  doi      = {10.1109/MRA.2023.3328457},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {164-183},
  title    = {Automation and artificial intelligence technology in surface mining: A brief introduction to open-pit operations in the pilbara [Survey]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on small-scale testbeds for connected and automated vehicles and robot swarms: A guide for creating a new testbed [Survey]. <em>MRA</em>, <em>32</em>(3), 146-163. (<a href='https://doi.org/10.1109/MRA.2024.3505772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Connected and automated vehicles (CAVs) and robot swarms (RSs) hold transformative potential for enhancing safety, efficiency, and sustainability in the transportation and manufacturing sectors. Extensive testing and validation of these technologies are crucial for their deployment in the real world. While simulations are essential for initial testing, they often have limitations in capturing the complex dynamics of real-world interactions. This limitation underscores the importance of small-scale testbeds. These testbeds provide a realistic, cost-effective, and controlled environment for testing and validating algorithms, acting as an essential intermediary between simulation and full-scale experiments. This work serves to facilitate researchers’ efforts in identifying existing small-scale testbeds suitable for their experiments and provide insights for those who want to build their own. In addition, it delivers a comprehensive survey of the current landscape of these testbeds. We derive 62 characteristics of testbeds based on the well-known sense–plan–act paradigm and offer an online table comparing 23 small-scale testbeds based on these characteristics. The online table is hosted on our designated public webpage, https://bassamlab.github.io/testbeds-survey, and we invite testbed creators and developers to contribute to it. We closely examine nine testbeds in this article, demonstrating how the derived characteristics can be used to present testbeds. Furthermore, we discuss three ongoing challenges concerning small-scale testbeds that we identified, i.e., small-scale to full-scale transition, sustainability, and power and resource management.},
  archive  = {J},
  author   = {Armin Mokhtarian and Jianye Xu and Patrick Scheffe and Maximilian Kloock and Simon Schäfer and Heeseung Bang and Viet-Anh Le and Sangeet Ulhas and Johannes Betz and Sean Wilson and Spring Berman and Liam Paull and Amanda Prorok and Bassam Alrifaee},
  doi      = {10.1109/MRA.2024.3505772},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {146-163},
  title    = {A survey on small-scale testbeds for connected and automated vehicles and robot swarms: A guide for creating a new testbed [Survey]},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic importance-weighted fusion network based on dynamic convolutions for hand posture recognition: A technique based on red, green, blue plus depth cameras. <em>MRA</em>, <em>32</em>(3), 134-145. (<a href='https://doi.org/10.1109/MRA.2024.3415004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Hand posture recognition technology makes humancomputer interaction more natural and efficient. Existing hand posture recognition algorithms are mainly based on RGB images or depth data, each of which has its limitations: the former is susceptible to the interference of lighting and background color, while the latter is difficult to capture details and affects accuracy. To overcome these problems, fusion of RGB images and depth data has become a research trend. However, traditional static fusion methods use fixed modal weights, which are difficult to adapt to the complex relationships between modalities and lead to performance degradation. To cope with this problem, this paper proposes a Fusion module, including Multi-Scale Gated Extraction modules (MSGE) for multi-scale feature extraction and gating mechanism, Context Sensitive Dynamic Filtering modules (CSDF) for dynamically adjusting the weights according to the modal importance, and Importance Weighted Fusion modules (IWF) for adaptive weighting. Based on this, this paper proposes a network that fuses RGB information and depth data, named Dynamic Importance-Weighted Fusion Network (DIWFNet). This network utilizes a dual-branch YOLOv5 framework integrated with four Fusion modules, fully leveraging the complementary nature of RGB images and depth data. Through dynamic weight distribution and adaptive feature convolution, it precisely captures and models the complex interactions between different modalities, enhancing the accuracy and robustness of hand posture recognition. Our method has shown excellent performance on the CUG dataset, NTU dataset, and self-built dataset, and has been successfully applied to robots in real operational environments.},
  archive  = {J},
  author   = {Jing Qi and Li Ma and Yushu Yu},
  doi      = {10.1109/MRA.2024.3415004},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {134-145},
  title    = {Dynamic importance-weighted fusion network based on dynamic convolutions for hand posture recognition: A technique based on red, green, blue plus depth cameras},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An interactive augmented reality interface for personalized proxemics modeling: Comfort and Human–Robot interactions. <em>MRA</em>, <em>32</em>(3), 125-133. (<a href='https://doi.org/10.1109/MRA.2024.3415108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Understanding and respecting personal space preferences is essential for socially assistive robots designed for older adult users. This work introduces and evaluates a novel personalized context-aware method for modeling users’ proxemics preferences during human-robot interactions. Using an interactive augmented reality interface, we collected a set of user-preferred distances from the robot and employed an active transfer learning approach to fine-tune a specialized deep learning model. We evaluated this approach through two user studies: 1) a convenience population study (N = 24) to validate the efficacy of the active transfer learning approach; and 2) a user study involving older adults (N = 15) to assess the system’s usability. We compared the data collected with the augmented reality interface and with the physical robot to examine the relationship between proxemics preferences for a virtual robot versus a physically embodied robot. We found that fine-tuning significantly improved model performance: on average, the error in testing decreased by 26.97% after fine-tuning. The system was well-received by older adult participants, who provided valuable feedback and suggestions for future work.},
  archive  = {J},
  author   = {Massimiliano Nigro and Amy O’Connell and Thomas Groechel and Anna-Maria Velentza and Maja Matarić},
  doi      = {10.1109/MRA.2024.3415108},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {125-133},
  title    = {An interactive augmented reality interface for personalized proxemics modeling: Comfort and Human–Robot interactions},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HuBotVerse: Toward internet of human and intelligent robotic things with a digital twin-based mixed reality framework. <em>MRA</em>, <em>32</em>(3), 114-124. (<a href='https://doi.org/10.1109/MRA.2024.3417090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Although the Internet of Robotic Things (IoRT) has enhanced the productivity of robotic systems in conjunction with the Internet of Things (IoT), it does not inherently support seamless human-robot collaboration. This paper presents HuBotVerse, a unified framework designed to foster the evolution of the Internet of Human and Intelligent Robotic Things (IoHIRT). HuBotVerse is advantageous due to its unique features, including security, user-friendliness, manageability, and its open-source nature. Moreover, this framework can seamlessly integrate various Human-Robot Interaction (HRI) interfaces to facilitate collaborative control between humans and robots. Here, we emphasize a Digital Twin-Based Mixed Reality (MR) interface, which enhances teleoperation efficiency by offering users an intuitive and immersive way to interact. To evaluate the effectiveness of HuBotVerse, we conducted user studies based on a pick-and-place task. Feedback was gathered through questionnaires, complemented by a quantitative analysis of key performance metrics, user experience, and the NASA Task Load Index (NASA-TLX). Results indicate that the fusion of MR and HuBotVerse within a comprehensive framework significantly improves the efficiency and user experience of teleoperation. Moreover, the follow-up questionnaires reflect the advantages of the HuBotVerse framework in terms of evident user-friendliness, manageability, and usability in homecare or healthcare applications. For codes, project videos, tutorials, technical details, case studies, and Q&A, please check our website (https://sites.google.com/view/iohirtplusmr/home).},
  archive  = {J},
  author   = {Dandan Zhang and Ziniu Wu and Jin Zheng and Yifan Li and Zheng Dong and Jialin Lin},
  doi      = {10.1109/MRA.2024.3417090},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {114-124},
  title    = {HuBotVerse: Toward internet of human and intelligent robotic things with a digital twin-based mixed reality framework},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward industry 5.0: A neuroergonomic workstation for a human-centered, collaborative robot-supported manual assembly process. <em>MRA</em>, <em>32</em>(3), 103-113. (<a href='https://doi.org/10.1109/MRA.2024.3487323'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This article brings the concept of neuroergonomic workcell with its essential components (psychological and physical assessment, nonphysical, physical, and strategic support) for improving the well-being and productivity of workers at their workplaces. A proof-of-concept neuroergonomic human-centered workstation is demonstrated in a real factory environment for a typical industrial laborious task: assembly. The pilot workstation introduces a fully portable, noninvasive electroencephalogram (EEG)-based users’ mental workload assessment, a nonobtrusive human–machine interface, illustrative graphical assembly guidelines, a collaborative robot assistant, and an intelligent task scheduler. The subjects’ performance and workload were assessed using a NASA Task Load Index questionnaire, three EEG workload indices, hand gesture detection accuracy, the number of errors, and task duration. We identified a notable correlation between multiple EEG indices of workload and NASA score results. The new workstation boosts productivity with better performance and fewer errors on the assembly line while reducing mental demand. Its modular design ensures easy integration and adaptation into factory settings, optimizing manual assembly processes.},
  archive  = {J},
  author   = {Nikola Knežević and Andrej Savić and Zaviša Gordić and Arash Ajoudani and Kosta Jovanović},
  doi      = {10.1109/MRA.2024.3487323},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {103-113},
  title    = {Toward industry 5.0: A neuroergonomic workstation for a human-centered, collaborative robot-supported manual assembly process},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards fully integrated autonomous excavation: Autonomous excavator for precise earth cutting and onboard landscape inspection. <em>MRA</em>, <em>32</em>(3), 88-102. (<a href='https://doi.org/10.1109/MRA.2024.3400772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Autonomous excavator systems can alleviate the issues caused by the shortage of skilled labor forces and increasing labor costs. For autonomous excavation, real-time landscape estimation, excavation path generation, control, and precise landscape inspection are all essential. In this article, we propose and experimentally validate an integrated autonomous excavator system incorporating all these elements. Specifically, unlike previous research, we introduce a sensor arrangement capable of sufficiently covering the regions of interest regardless of the inclination of the target landscape, a motion planning method that satisfies geometric and physical constraints, and a precise postexcavation inspection module using only onboard sensors. The proposed methodology was experimentally validated using a real 30-ton hydraulic excavator. It successfully performed a cutting task on an upward slope with 45° inclination and achieved a centimeter-level accuracy through autonomous repetitive excavation; also, the proposed postexcavation inspection method demonstrated subcentimeter precision within seconds using onboard sensors only.},
  archive  = {J},
  author   = {Inkyu Jang and Junha Kim and Dongjae Lee and Changhyeon Kim and Changsuk Oh and Youngbum Kim and Sangwook Woo and Heejee Sung and H. Jin Kim},
  doi      = {10.1109/MRA.2024.3400772},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {88-102},
  title    = {Towards fully integrated autonomous excavation: Autonomous excavator for precise earth cutting and onboard landscape inspection},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Int-ball2: On-orbit demonstration of autonomous intravehicular flight and docking for image capturing and recharging. <em>MRA</em>, <em>32</em>(3), 76-87. (<a href='https://doi.org/10.1109/MRA.2024.3505776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This article presents the system architecture and the orbital demonstration results of the Int-Ball2, a free-flying camera robot developed by the Japan Aerospace Exploration Agency (JAXA). The purpose of the Int-Ball2 project is to assist astronauts and reduce their workload in the International Space Station (ISS). This robot is an upgrade from the first Int-Ball, enhancing the propulsion subsystem for greater maneuverability and adding a new docking station (DS) for autonomous battery recharging. This study performed comprehensive ground tests for autonomous maneuvering and docking, employing a combination of a fully software-based simulator, a hardware-in-the-loop (HIL) simulator, and a planar air-bearing facility. After a successful launch to the ISS, the Int-Ball2 demonstrated its ability to work in microgravity without relying on astronaut support. The results obtained from ground and orbital tests underscored the effectiveness of our system design and ground verification approach. Further, we present key technologies essential for the Int-Ball2’s successful implementation on board the ISS. We expect the insights from this project to be invaluable to future missions involving free-flying robots in microgravity.},
  archive  = {J},
  author   = {Daichi Hirano and Shinji Mitani and Keisuke Watanabe and Taisei Nishishita and Tatsuya Yamamoto and Seiko P. Yamaguchi},
  doi      = {10.1109/MRA.2024.3505776},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {76-87},
  title    = {Int-ball2: On-orbit demonstration of autonomous intravehicular flight and docking for image capturing and recharging},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large-scale vine robots for industrial inspection: Developing a new framework to overcome limitations with existing inspection methods. <em>MRA</em>, <em>32</em>(3), 64-75. (<a href='https://doi.org/10.1109/MRA.2024.3487326'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Industrial facilities such as chemical factories, gas terminals, and power plants can contain kilometers of piping that require meticulous inspection for leaks and defects prior to operation. This is a costly and time-consuming process that sometimes requires dismantling sections of pipe. While current internal inspection devices such as borescopes, “pipe inspection gadgets,” rovers, and drones serve specific purposes, none can effectively maneuver through multiple bends with large diameter changes while pulling a tethered sensor. As a first step in addressing this need, we tackled the mobility challenge without a sensor, developing a 33-m-long, 1-m-wide, soft, inflatable vine robot for accessing hard-to-reach spaces in dangerous industrial facilities. We also investigated ways to mount sensors to large-scale vine robots, identified key challenges in doing so, and provide the framework for a potential solution. Our work addresses many modeling, design, and scaling challenges, including frictional properties, gravitational effects, pneumatic control, and portability. To validate the device’s capabilities, we conducted testing at a Bechtel facility in Houston, TX, USA. Our portable device successfully navigated a 24-m-long section of oil and gas piping, negotiating a 90° bend, a vertical section, a blockage, and an open chamber. Our work not only represents a substantial advancement in addressing current pipe navigation challenges but also establishes a new benchmark as the world’s largest soft robot, showcasing the effectiveness of pneumatic principles at large scales.},
  archive  = {J},
  author   = {William E. Heap and Steven Man and Vedad Bassari and Steven Nguyen and Elvy B. Yao and Neel A. Tripathi and Nicholas D. Naclerio and Elliot W. Hawkes},
  doi      = {10.1109/MRA.2024.3487326},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {64-75},
  title    = {Large-scale vine robots for industrial inspection: Developing a new framework to overcome limitations with existing inspection methods},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robotic grape inspection and selective harvesting in vineyards: A multisensory robotic system with advanced cognitive capabilities. <em>MRA</em>, <em>32</em>(3), 51-63. (<a href='https://doi.org/10.1109/MRA.2024.3487324'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Driven by the increasing food demand and the need for higher-quality cultivation, precision agriculture grows steadily during the last decade. It involves the application of mobile robots and intelligent robotic technologies in various agricultural field tasks, concerning a variety of crop types. Aiming at compensating for the lack of selective robotic harvesting solutions regarding the high-value crop of grapes, the EU-funded project BACCHUS (https://cordis.europa.eu/project/id/871704 and https://bacchus-project.eu/) develops an intelligent mobile robotic system, comprising two independent and cooperative robots: one for the grape inspection and collection of valuable data regarding their maturity level, and one for the bimanual harvesting of grapes in a human-inspired manner. Validated via real-field trials, the proposed autonomous system pushes forward the precision agriculture application for a particularly sensitive crop type in the challenging and heavily cluttered environment of vineyards, facilitating the selective harvesting of high-quality grapes.},
  archive  = {J},
  author   = {Sotiris Stavridis and Leonidas Droukas and Zoe Doulgeri and Dimitrios Papageorgiou and Fotios Dimeas and Ángel Soriano and Sergi Molina and Sami Ahmed Deiri and Michael Hutchinson and Jaime Pulido-Fentanes and Ibrahim Hroob and Riccardo Polvara and Marc Hanheide and Grzegorz Cielniak and Nikiforos Samarinas and Dimitrios Kateris and Dionysis Bochtis and Georgia Peleka and Stefanos Papadam and Dimitra Triantafyllou and Alexios Papadimitriou and Christos Papadopoulos and Ioannis Mariolis and Dimitrios Giakoumis and Dimitrios Tzovaras},
  doi      = {10.1109/MRA.2024.3487324},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {51-63},
  title    = {Robotic grape inspection and selective harvesting in vineyards: A multisensory robotic system with advanced cognitive capabilities},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing campus mobility: Achievements and challenges of the snow lion autonomous shuttle. <em>MRA</em>, <em>32</em>(3), 40-50. (<a href='https://doi.org/10.1109/MRA.2024.3433168'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In recent years, the rapid evolution of autonomous vehicles (AVs) has reshaped global transportation systems, leading to an increase in autonomous shuttle applications in people’s daily lives. Leveraging the accomplishments of our earlier endeavor, particularly Hercules (Liu et al., 2021), an autonomous logistics vehicle for transporting goods, we introduce Snow Lion, an autonomous shuttle vehicle specifically designed to transform on-campus transportation, providing a safe and efficient mobility solution for students, faculty, and visitors.},
  archive  = {J},
  author   = {Yingbing Chen and Jie Cheng and Sheng Wang and Hongji Liu and Xiaodong Mei and Xiaoyang Yan and Mingkai Tang and Ge Sun and Ya Wen and Junwei Cai and Xupeng Xie and Lu Gan and Mandan Chao and Ren Xin and Lujia Wang and Ming Liu and Jianhao Jiao},
  doi      = {10.1109/MRA.2024.3433168},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {40-50},
  title    = {Enhancing campus mobility: Achievements and challenges of the snow lion autonomous shuttle},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward the deployment of an autonomous last-mile delivery robot in urban areas: The ona prototype platform. <em>MRA</em>, <em>32</em>(3), 26-39. (<a href='https://doi.org/10.1109/MRA.2024.3487321'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Nowadays, the skyrocketing last-mile freight transportation in urban areas is leading to very negative effects (e.g., pollution, noise, or traffic congestion), which could be minimized by using autonomous electric vehicles. In this sense, this article presents the first prototype of Ona, an autonomous last-mile delivery robot that, in contrast to existing platforms, has a medium-sized storage capacity with the capability of navigating in both street and pedestrian areas. Herein we describe the platform and position it with respect to other existing prototypes, providing its main software modules and the first validation experiments, carried out in the Barcelona Robot Lab (Universitat Politècnica de Catalunya); Esplugues de Llobregat (next to Barcelona); and Debrecen (Hungary), which are representative urban scenarios. In such validations, we focus our analysis on the key localization module, whose errors could cascade down the rest of the navigation pipeline (e.g., planning or control). Aside from robotic technical details, we also include the results of the technology acceptance by the public present in the Esplugues de Llobregat test, collected in situ through a survey.},
  archive  = {J},
  author   = {Angel Santamaria-Navarro and Sergi Hernández and Fernando Herrero and Alejandro López and Iván del Pino and Nicolás Rodríguez-Linares and Carlos Fernández and Albert Baldó and Clément Lemardelé and Anaís Garrell and Joan Vallvé and Hafsa Taher and Ana M. Puig-Pey and Laia Pagès and Alberto Sanfeliu},
  doi      = {10.1109/MRA.2024.3487321},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {26-39},
  title    = {Toward the deployment of an autonomous last-mile delivery robot in urban areas: The ona prototype platform},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Door-to-door parcel delivery from supply point to user’s home with heterogeneous robot team: The euROBIN first-year robotics hackathon. <em>MRA</em>, <em>32</em>(3), 8-25. (<a href='https://doi.org/10.1109/MRA.2024.3501954'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Logistics and service operations involving parcel preparation, delivery, and unpacking from a supply point to a user’s home could be carried out completely by robots in the near future, taking advantage of the capabilities of the different robot morphologies for the logistics, outdoor, and domestic environments. The use of robots for parcel delivery can contribute to the goals of sustainability and reduced emissions by exploiting their different locomotion modalities (wheeled, legged, and aerial). This article reports the development and results obtained from the first robotics hackathon celebrated as part of the European Robotics and Artificial Intelligence Network involving eight robotic platforms in three domains: 1) an industrial robotic arm for parcel preparation at the supply point, 2) a Centauro robot, a dual-arm aerial manipulator, and a wheeled-legged quadruped for parcel transportation, and 3) two humanoid robots and two commercial mobile manipulators for parcel delivery and unpacking in domestic scenarios. The article describes the joint operation and the evaluation scenario, the features and capabilities of the robots, particularly those involved in the realization of the tasks, and the lessons learned.},
  archive  = {J},
  author   = {Alejandro Suarez and Rainer Kartmann and Daniel Leidner and Luca Rossini and Johann Huber and Carlos Azevedo and Quentin Rouxel and Marko Bjelonic and Antonio Gonzalez-Morgado and Christian Dreher and Peter Schmaus and Arturo Laurenzi and François Hélénon and Rodrigo Serra and Jean-Baptiste Mouret and Lorenz Wellhausen and Vicente Perez-Sanchez and Jianfeng Gao and Adrian Simon Bauer and Alessio De Luca and Mouad Abrini and Rui Bettencourt and Olivier Rochel and Joonho Lee and Pablo Viana and Christoph Pohl and Nesrine Batti and Diego Vedelago and Vamsi Krishna Guda and Alexander Reske and Carlos Alvarez and Fabian Reister and Werner Friedl and Corrado Burchielli and Aline Baudry and Fabian Peller-Konrad and Thomas Gumpert and Luca Muratore and Philippe Gauthier and Franziska Krebs and Sebastian Jung and Lorenzo Baccelliere and Hippolyte Watrelot and Andre Meixner and Anne Köpken and Mohamed Chetouani and Pascal Weiner and Florian Lay and Felix Hundhausen and Anne Reichert and Noémie Jaquier and Florian Schmidt and Marco Sewtz and Freek Stulp and Lioba Suchenwirth and Rudolph Triebel and Xuwei Wu and Begoña Arrue and Rebecca Schedl-Warpup and Marco Hutter and Serena Ivaldi and Pedro U. Lima and Stéphane Doncieux and Nikos Tsagarakis and Tamim Asfour and Anibal Ollero and Alin Albu-Schäffer},
  doi      = {10.1109/MRA.2024.3501954},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  number   = {3},
  pages    = {8-25},
  title    = {Door-to-door parcel delivery from supply point to user’s home with heterogeneous robot team: The euROBIN first-year robotics hackathon},
  volume   = {32},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Humanoids and robot learning [President’s message]. <em>MRA</em>, <em>32</em>(3), 5-6. (<a href='https://doi.org/10.1109/MRA.2025.3588643'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Aude Billard},
  doi     = {10.1109/MRA.2025.3588643},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {9},
  number  = {3},
  pages   = {5-6},
  title   = {Humanoids and robot learning [President’s message]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New impact factor, new promises: Never a better time for robotics and automation [From the editor’s desk]. <em>MRA</em>, <em>32</em>(3), 4. (<a href='https://doi.org/10.1109/MRA.2025.3588644'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Yi Guo},
  doi     = {10.1109/MRA.2025.3588644},
  journal = {IEEE Robotics & Automation Magazine},
  month   = {9},
  number  = {3},
  pages   = {4},
  title   = {New impact factor, new promises: Never a better time for robotics and automation [From the editor’s desk]},
  volume  = {32},
  year    = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
