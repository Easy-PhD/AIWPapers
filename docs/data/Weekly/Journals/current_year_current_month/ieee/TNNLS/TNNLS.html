<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TNNLS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tnnls">TNNLS - 143</h2>
<ul>
<li><details>
<summary>
(2025). Double successive over-relaxation Q-learning with an extension to deep reinforcement learning. <em>TNNLS</em>, <em>36</em>(10), 19467-19472. (<a href='https://doi.org/10.1109/TNNLS.2025.3576581'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Q-learning (QL) is a widely used algorithm in reinforcement learning (RL), but its convergence can be slow, especially when the discount factor is close to one. Successive over-relaxation (SOR) QL, which introduces a relaxation factor to speed up convergence, addresses this issue but has two major limitations. In the tabular setting, the relaxation parameter depends on transition probability, making it not entirely model-free, and it suffers from overestimation bias. To overcome these limitations, we propose a sample-based, model-free double SORQL (MF-DSORQL) algorithm. Theoretically and empirically, this algorithm is shown to be less biased than SORQL. Furthermore, in the tabular setting, the convergence analysis under boundedness assumptions on iterates is discussed. The proposed algorithm is extended to large-scale problems using deep RL. Finally, both the tabular version of the proposed algorithm and its deep RL extension are tested on benchmark examples.},
  archive      = {J_TNNLS},
  author       = {S. R. Shreyas},
  doi          = {10.1109/TNNLS.2025.3576581},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19467-19472},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Double successive over-relaxation Q-learning with an extension to deep reinforcement learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frobenius norm-based robust dynamic neural network for time-dependent matrix inversion. <em>TNNLS</em>, <em>36</em>(10), 19460-19466. (<a href='https://doi.org/10.1109/TNNLS.2025.3583573'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-dependent matrix inversion (TDMI) is popularly utilized in scientific fields. Considering the low computing costs and simplified structure, this brief puts forward a Frobenius norm-based dynamic neural network (FNBDNN) model to address a TDMI problem for the first time, which achieves convergence within finite time and ensures strong robustness without using integral operations and element-wise nonlinear activation functions. Moreover, precise theoretical analyses are provided to display the property of finite-time convergence of the FNBDNN model in dealing with the TDMI problem. Simulation experiments are further conducted to verify the validity and preponderance of the FNBDNN model. Finally, an application of the devised FNBDNN model to the precise motion control of a two-axis manipulator is introduced.},
  archive      = {J_TNNLS},
  author       = {Hanyi Xu and Linyan Dai and Yinyan Zhang},
  doi          = {10.1109/TNNLS.2025.3583573},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19460-19466},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Frobenius norm-based robust dynamic neural network for time-dependent matrix inversion},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Copula density neural estimation. <em>TNNLS</em>, <em>36</em>(10), 19452-19459. (<a href='https://doi.org/10.1109/TNNLS.2025.3585755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probability density estimation from observed data constitutes a central task in statistics. In this brief, we focus on the problem of estimating the copula density associated with any observed data, as it fully describes the dependence between random variables. We separate univariate marginal distributions from the joint dependence structure in the data, the copula itself, and we model the latter with a neural network-based method referred to as copula density neural estimation (CODINE). Results show that the novel learning approach is capable of modeling complex distributions and can be applied for mutual information estimation and data generation.},
  archive      = {J_TNNLS},
  author       = {Nunzio A. Letizia and Nicola Novello and Andrea M. Tonello},
  doi          = {10.1109/TNNLS.2025.3585755},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19452-19459},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Copula density neural estimation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online self-training driven attention-guided self-mimicking network for semantic segmentation. <em>TNNLS</em>, <em>36</em>(10), 19437-19451. (<a href='https://doi.org/10.1109/TNNLS.2025.3577327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of semantic segmentation tasks, knowledge distillation (KD) has emerged as a prominent strategy, leveraging the transfer of mature knowledge from large teacher networks to enhance the performance of smaller student networks. However, existing methods often rely heavily on high-quality yet cumbersome teacher networks, leading to a complex training process. To address this challenge, we introduce a novel approach termed self-training driven attention-guided self-mimicking online ensemble network. Our proposed method begins by employing intermediate channel-joint attention maps to guide image augmentation. Both the original and augmented images are then input into the networks. Leveraging intermediate feature maps and predictive predictions generated from the two images, we employ KD to uncover invariant features. To further harness representation potential through learning from credible predictions, we introduce a self-training mechanism. This mechanism utilizes an exponential moving average (EMA)-teacher network constructed using the exponential moving average technique to generate feature maps and predicted posterior probabilities. The knowledge of the EMA-teacher is subsequently transferred to the student network through distillation. Extensive experiments and visualization analyses conducted on multiple benchmark datasets, including Cityscapes, Pascal VOC, CamVid, and ADE20k, validate the effectiveness of self-training driven attention-guided self-mimicking network (ST-ASMNet). The interpretability of our method is further validated through visualization and analysis. Our code will be publicly available.},
  archive      = {J_TNNLS},
  author       = {Shuchang Lyu and Qi Zhao and Hong Zhang and Guangliang Cheng and Chenguang Yang},
  doi          = {10.1109/TNNLS.2025.3577327},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19437-19451},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Online self-training driven attention-guided self-mimicking network for semantic segmentation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decentralized Actor–Critic algorithm with entropy regularization and its finite-time analysis. <em>TNNLS</em>, <em>36</em>(10), 19423-19436. (<a href='https://doi.org/10.1109/TNNLS.2025.3573801'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized actor-critic (AC) is one of the most dominant algorithms for dealing with multiagent reinforcement learning (MARL) problems. However, exploration-efficient, sample-efficient, and communication-efficient are difficult to achieve simultaneously by existing decentralized AC methods. For this reason, this article develops a decentralized multiagent AC algorithm by incorporating entropy regularization to improve exploration with theoretical guarantees, referred to as multi-agent AC algorithm with entropy regularization (MACE). Moreover, we rigorously prove that MACE can achieve sample complexity $\mathcal {O}(\epsilon ^{-2}\ln \epsilon ^{-1})$ and communication complexity of $\mathcal {O}(\epsilon ^{-1}\ln \epsilon ^{-1})$ , which match the best complexities at present. Finally, the performance of MACE is also evaluated on reinforcement learning (RL) tasks. The experimental results show that the proposed algorithm achieves better exploration efficiency than state-of-the-art decentralized AC-type algorithms.},
  archive      = {J_TNNLS},
  author       = {Tao Mao and Junlong Zhu and Mingchuan Zhang and Quanbo Ge and Ruijuan Zheng and Qingtao Wu},
  doi          = {10.1109/TNNLS.2025.3573801},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19423-19436},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A decentralized Actor–Critic algorithm with entropy regularization and its finite-time analysis},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward fine-grained 3-D visual grounding through referring textual phrases. <em>TNNLS</em>, <em>36</em>(10), 19411-19422. (<a href='https://doi.org/10.1109/TNNLS.2025.3571959'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent progress in 3-D scene understanding has explored visual grounding [3D visual grounding (3DVG)] to localize a target object through a language description. However, existing methods only consider the dependency between the entire sentence and the target object, ignoring fine-grained relationships between contexts and nontarget ones. In this article, we extend 3DVG to a more fine-grained task, called 3D phrase-aware grounding (3DPAG). The 3DPAG task aims to localize the target objects in a 3-D scene by explicitly identifying all phrase-related objects and then conducting the reasoning according to contextual phrases. To tackle this problem, we manually labeled about 227 K phrase-level annotations using a self-developed platform, from 88 K sentences of widely used 3DVG datasets, i.e., Natural Reference in 3-D (Nr3D), Spatial Reference in 3-D (Sr3D), and ScanRefer. By tapping on our datasets, we can extend previous 3DVG methods to the fine-grained phrase-aware scenario. It is achieved through the proposed novel phrase-object alignment (POA) optimization and phrase-specific pretraining (PSP), boosting conventional 3DVG performance as well. Extensive results confirm significant improvements, i.e., previous state-of-the-art method achieves 3.9%, 3.5%, and 4.6% overall accuracy gains on Nr3D, Sr3D, and ScanRefer, respectively. Our datasets and platform are released in https://github.com/CurryYuan/PhraseRefer},
  archive      = {J_TNNLS},
  author       = {Zhihao Yuan and Xu Yan and Zhuo Li and Xuhao Li and Yao Guo and Shuguang Cui and Zhen Li},
  doi          = {10.1109/TNNLS.2025.3571959},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19411-19422},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Toward fine-grained 3-D visual grounding through referring textual phrases},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variational hierarchical N-BEATS model for long-term time-series forecasting. <em>TNNLS</em>, <em>36</em>(10), 19398-19410. (<a href='https://doi.org/10.1109/TNNLS.2025.3571039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term time-series forecasting (LTSF) is gaining increasing attention due to its significant challenges and real-world applications. However, existing studies underexplore the role of hierarchical timestamp information in LTSF. We find this information crucial, as neglecting it may lead to the loss of broader perspectives necessary for understanding hierarchical effects, such as weekly and yearly patterns. Therefore, we propose VH-NBEATS, an interpretable variational hierarchical model that extends the N-BEATS architecture to address the challenges outlined above. VH-NBEATS consists of two blocks: the hierarchical timestamp block and the harmonic seasonal block, which are designed to capture hierarchical seasonal and trending effects. To tackle the high variability often observed in time series, VH-NBEATS incorporates a variational autoencoder (VAE), significantly enhancing the standard deterministic approach. The experimental results are evaluated on seven real-world datasets, demonstrating state-of-the-art (SOTA) performance for LTSF. We also prove that the hierarchical timestamp block can enable plug-and-play with any methods, such as PatchTST, Informer, and DLinear, for better performance.},
  archive      = {J_TNNLS},
  author       = {Runze Yang and Longbing Cao and Jianxun Li and Jie Yang},
  doi          = {10.1109/TNNLS.2025.3571039},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19398-19410},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Variational hierarchical N-BEATS model for long-term time-series forecasting},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained entity recognition via large language models. <em>TNNLS</em>, <em>36</em>(10), 19385-19397. (<a href='https://doi.org/10.1109/TNNLS.2025.3574197'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained entity recognition (FGER) attracts increasing attention in information extraction and many other natural language understanding applications. However, it is a quite challenging problem for a specific domain due to the lack of specific-domain labeled data. To address this challenge, recent advancements in language modeling such as generative pretrained transformer (GPT) offer promising alternatives. Since large language models (LLMs) can be used for various tasks, such as text generation, summarization, and information extraction without labeled data, we incorporated them into the FGER field. Nonetheless, when too many verbose labels are fed to LLMs simultaneously, LLMs occasionally generate content that diverges from user input, contradicts previously generated context, or misaligns with established world knowledge, also called the “hallucination” phenomenon. In this article, we propose a new method called FGER-GPT to address these issues. Our approach leverages multiple inference chains and incorporates a hierarchical strategy for recognizing fine-grained entities, resulting in a significant performance boost. Importantly, neither coarse-grained nor fine-grained entity annotations are used in our proposed approach, which avoids the heavy labor consumption of labeling. Extensive experiments conducted on widely used datasets have demonstrated that the proposed FGER-GPT achieves competitive performance compared to state-of-the-art approaches in low-resource scenarios, highlighting its feasibility for real-world applications.},
  archive      = {J_TNNLS},
  author       = {Xue Qiao and Shuang Gu and Jiayuan Cheng and Chen Peng and Zhiwei Xiong and Hong Shen and Gan Jiang},
  doi          = {10.1109/TNNLS.2025.3574197},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19385-19397},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Fine-grained entity recognition via large language models},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ODMTCNet: An interpretable multiview deep neural network architecture for feature representation. <em>TNNLS</em>, <em>36</em>(10), 19370-19384. (<a href='https://doi.org/10.1109/TNNLS.2025.3588327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep cascade architecture-based algorithms have attracted wide attention and have been applied to numerous application domains successfully. Nevertheless, the black-box structure of such algorithms has always been considered the Achilles’ heel by the machine learning community. Moreover, due to its data-driven nature, the deep cascade architecture likely causes over-fitting problems when there is no sufficient data available. In order to solve these pressing issues, this work proposes a novel multiview deep neural network (DNN) model, namely, optimal discriminant multiview tensor convolutional network (ODMTCNet), which integrates statistics-guided optimization (SGO) principles with the DNN architecture. Specifically, a discriminant multiview tensor convolution strategy is proposed and integrated with a deep cascade architecture. Different from the traditional DNN models, the parameters of the convolutional layers in ODMTCNet are determined by solving SGO problems. Based on the SGO principles, the relation between the optimal performance and parameters (e.g., the number of convolutional filters) can be analytically predicted, with each layer generating justified knowledge representations. In addition, information quality (IQ) is adopted to further improve multiview feature representation. Because of its unique design, ODMTCNet is able to handle different types of features (e.g., raw, hand-crafted, prior knowledge-based, and DNN-generated features), forming a general platform for multiview feature representation. To validate the genericness and effectiveness of the ODMTCNet model, we conducted experiments on five datasets of different scales: The Olivetti Research Lab (ORL) database, the Facial Recognition Technology (FERET) database, the ETH-80 database, the Caltech 256 database, and the nanyang technological university (NTU) red green blue-depth (RGB+D) 120 database. Experimental results show the superiority of the presented solution over the state-of-the-art. Implementation codes will be made available in the final version.},
  archive      = {J_TNNLS},
  author       = {Lei Gao and Zheng Guo and Ling Guan},
  doi          = {10.1109/TNNLS.2025.3588327},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19370-19384},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {ODMTCNet: An interpretable multiview deep neural network architecture for feature representation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FX-DARTS: Designing topology-unconstrained architectures with differentiable architecture search and entropy-BasedSuper-network shrinking. <em>TNNLS</em>, <em>36</em>(10), 19356-19369. (<a href='https://doi.org/10.1109/TNNLS.2025.3575505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strong priors are imposed on the search space of differentiable architecture search (DARTS), such that cells of the same type share the same topological structure and each intermediate node retains two operators from distinct nodes. While these priors reduce optimization difficulties and improve the applicability of searched architectures, they hinder the subsequent development of automated machine learning (auto-ML) and prevent the optimization algorithm from exploring more powerful neural networks through improved architectural flexibility. This article aims to reduce these prior constraints by eliminating restrictions on cell topology and modifying the discretization mechanism for super-networks. Specifically, the flexible DARTS (FX-DARTS) method, which leverages an entropy-based super-network shrinking (ESS) framework, is presented to address the challenges arising from the elimination of prior constraints. Notably, FX-DARTS enables the derivation of neural architectures without strict prior rules while maintaining the stability in the enlarged search space. Experimental results on image classification benchmarks demonstrate that FX-DARTS is capable of exploring a set of neural architectures with competitive trade-offs between performance and computational complexity within a single search procedure.},
  archive      = {J_TNNLS},
  author       = {Xuan Rao and Bo Zhao and Derong Liu and Cesare Alippi},
  doi          = {10.1109/TNNLS.2025.3575505},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19356-19369},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {FX-DARTS: Designing topology-unconstrained architectures with differentiable architecture search and entropy-BasedSuper-network shrinking},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NACHOS: Neural architecture search for hardware-constrained early-exit neural networks. <em>TNNLS</em>, <em>36</em>(10), 19342-19355. (<a href='https://doi.org/10.1109/TNNLS.2025.3588558'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early-exit neural networks (EENNs) endow a standard deep neural network (DNN) with early-exit classifiers (EECs) to provide predictions at intermediate points of the processing when enough confidence in classification is achieved. This leads to many benefits in terms of effectiveness and efficiency. Currently, the design of EENNs is carried out manually by experts, a complex and time-consuming task that requires accounting for many aspects, including the correct placement, the thresholding, and the computational overhead of the EECs. For this reason, the research is exploring the use of neural architecture search (NAS) to automate the design of EENNs. Currently, few comprehensive NAS solutions for EENNs have been proposed in the literature, and a fully automated, joint design strategy taking into consideration both the backbone and the EECs remains an open problem. To this end, this work presents neural architecture search for hardware-constrained early exit neural networks (NACHOS), the first NAS framework for the design of optimal EENNs satisfying constraints on the accuracy and the number of multiply and accumulate (MAC) operations performed by the EENNs at inference time. In particular, this provides the joint design of backbone and EECs to select a set of admissible (i.e., respecting the constraints) Pareto optimal solutions in terms of the best trade-off between the accuracy and the number of MACs. The results show that the models designed by NACHOS are competitive with the state-of-the-art EENNs. Additionally, this work investigates the effectiveness of two novel regularization terms designed for the optimization of the auxiliary classifiers of the EENN.},
  archive      = {J_TNNLS},
  author       = {Matteo Gambella and Jary Pomponi and Simone Scardapane and Manuel Roveri},
  doi          = {10.1109/TNNLS.2025.3588558},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19342-19355},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {NACHOS: Neural architecture search for hardware-constrained early-exit neural networks},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust dynamic material handling via adaptive constrained evolutionary reinforcement learning. <em>TNNLS</em>, <em>36</em>(10), 19327-19341. (<a href='https://doi.org/10.1109/TNNLS.2025.3582299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic material handling (DMH) involves the assignment of dynamically arriving material transporting tasks to suitable vehicles in real time for minimizing makespan and tardiness. In real-world scenarios, historical task records are usually available, which enables the training of a decision policy on multiple instances consisting of historical records. Recently, reinforcement learning (RL) has been applied to solve DMH. Due to the occurrence of dynamic events such as new tasks, adaptability is highly required. Solving DMH is challenging since constraints, including task delay, should be satisfied. A feedback is received only when all tasks are served, which leads to sparse reward. Besides, making the best use of limited computational resources and historical records for training a robust policy is crucial. The time allocated to different problem instances would highly impact the learning process. To tackle those challenges, this article proposes a novel adaptive constrained evolutionary RL (ACERL) approach, which maintains a population of actors for diverse exploration. ACERL accesses each actor for tackling sparse rewards and constraint violation to restrict the behavior of the policy. Moreover, ACERL adaptively selects the most beneficial training instances for improving the policy. Extensive experiments on eight training and eight unseen test instances demonstrate the outstanding performance of ACERL compared with several state-of-the-art algorithms. Policies trained by ACERL can schedule the vehicles while fully satisfying the constraints. Additional experiments on 40 unseen noised instances show the robust performance of ACERL. Cross validation further presents the overall effectiveness of ACREL. Besides, a rigorous ablation study highlights the coordination and benefits of each ingredient of ACERL.},
  archive      = {J_TNNLS},
  author       = {Chengpeng Hu and Ziming Wang and Bo Yuan and Jialin Liu and Chengqi Zhang and Xin Yao},
  doi          = {10.1109/TNNLS.2025.3582299},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19327-19341},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust dynamic material handling via adaptive constrained evolutionary reinforcement learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Branch-tuning: Balancing stability and plasticity for continual self-supervised learning. <em>TNNLS</em>, <em>36</em>(10), 19312-19326. (<a href='https://doi.org/10.1109/TNNLS.2025.3579928'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The self-supervised learning (SSL) has emerged as an effective paradigm for deriving general representations from vast amounts of unlabeled data. However, as real-world applications continually integrate new content, the high computational and resource demands of SSL necessitate continual learning (CL) rather than complete retraining. This poses a challenge in balancing between stability and plasticity when adapting to new information. In this article, we employ centered kernel alignment (CKA) for quantitatively analyzing model stability and plasticity, revealing the critical roles of batch normalization (BN) layers for stability and convolutional layers for plasticity. Motivated by this, we propose branch-tuning (BT), an efficient and straightforward method that achieves a balance between stability and plasticity in continual SSL. BT consists of branch expansion and compression and can be easily applied to various SSL methods without the need of modifying the original methods, retaining old data or models. We validate our method through experiments on various benchmark datasets, demonstrating its effectiveness and practical value in real-world scenarios. We hope our work offers new insights for future continual SSL research. The code will be made publicly available.},
  archive      = {J_TNNLS},
  author       = {Wenzhuo Liu and Fei Zhu and Cheng-Lin Liu},
  doi          = {10.1109/TNNLS.2025.3579928},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19312-19326},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Branch-tuning: Balancing stability and plasticity for continual self-supervised learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multihop reconstruction for generalized zero-shot node classification. <em>TNNLS</em>, <em>36</em>(10), 19297-19311. (<a href='https://doi.org/10.1109/TNNLS.2025.3574252'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs in the real world keep evolving with the integration of new nodes, and it is often infeasible to manually label all the new nodes promptly. In this case, graph learning algorithms can come in handy and perform classification on these newly emerging nodes. Typically, if unseen classes exist (i.e., no training samples from these classes), one can perform zero-shot learning (ZSL) or generalized ZSL (GZSL). During testing, ZSL aims to classify samples within unseen classes, whereas GZSL aims to classify samples within both seen and unseen classes, which is even more challenging. In our previous work, we proposed a decomposed graph prototype network (DGPN) to decompose the graph convolution operation for handling the zero-shot node classification (ZNC) problem. However, DGPN is not well-suited for the generalized ZNC (GZNC) problem. To this end, in this article, we propose a novel graph generative model, multihop reconstruction graph autoencoder (MHR-GAE). Unlike DGPN, MHR-GAE utilizes a multihop encoder with class semantic descriptions (CSDs) (as condition signals) to reconstruct the information and generate nodes of unseen classes. Thus, it can handle both the ZNC and GZNC problems and obtain competitive performance. We evaluate our model on real-world datasets, and the experimental results demonstrate that MHR-GAE outperforms other baseline methods.},
  archive      = {J_TNNLS},
  author       = {Jialong Wang and Zheng Wang and Zhiguo Gong},
  doi          = {10.1109/TNNLS.2025.3574252},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19297-19311},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multihop reconstruction for generalized zero-shot node classification},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-discriminator generative adversarial network for anomaly detection. <em>TNNLS</em>, <em>36</em>(10), 19285-19296. (<a href='https://doi.org/10.1109/TNNLS.2025.3585978'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series anomaly detection has shown potential in various fields, such as finance, aerospace, and security. The fuzzy definition of data anomalies, the complexity of data patterns, and the scarcity of abnormal data samples pose significant challenges to anomaly detection. Researchers have extensively employed autoencoders (AEs) and generative adversarial networks (GANs) in studying time series anomaly detection methods. However, relying on reconstruction error, the AE-based anomaly detection algorithm needs more effective regularization methods, rendering it susceptible to the problem of overfitting. Meanwhile, GAN-based anomaly detection algorithms require high-quality training data, significantly impacting their practical deployment. We propose a novel GAN based on a dual-discriminator structure to address these issues. The model first processes the data with the generator to obtain the reconstruction error and then calculates pseudo-labels to divide the data into two categories. One data category is input into the first discriminator, where a minor loss between the data and its reconstructed counterpart is better. The other data category is input into the second discriminator, where a larger loss between the data and its reconstructed counterpart is better. Through this process, the model can effectively constrain the generator, retaining information on normal data during data reconstruction while discarding information on abnormal data. After conducting experiments on multiple benchmark datasets, the proposed GAN based on a dual-discriminator structure achieved good results in anomaly detection, outperforming several advanced methods. Additionally, the model also performed well in practical transformer data.},
  archive      = {J_TNNLS},
  author       = {Da Ding and Youquan Wang and Haicheng Tao and Jia Wu and Jie Cao},
  doi          = {10.1109/TNNLS.2025.3585978},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19285-19296},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A dual-discriminator generative adversarial network for anomaly detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning approach for dynamic distribution network reconfiguration based on sequential masking. <em>TNNLS</em>, <em>36</em>(10), 19270-19284. (<a href='https://doi.org/10.1109/TNNLS.2025.3574208'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic distribution network reconfiguration (DDNR) is a widely used technique for the secure and economic operation of power distribution networks (PDNs), especially in the presence of high-penetration renewable energy sources (RESs). DDNR is realized by controlling the on/off status of remotely controlled switches (RCSs) equipped at power lines in PDNs to optimize power flows. Thanks to the enhanced data availability of PDNs, data-driven solutions to DDNR, such as deep reinforcement learning (DRL), have gained growing attention recently. However, DDNR solves a sequence of combinatorial problems featuring a vast and sparse action space incurred by a so-called “radiality constraint,” which is highly challenging for DRLs to handle. Existing DRL methods are either unscalable to large-scale problems or potentially restrict optimality. Hence, we propose a sequential masking strategy to decompose its complex action space into a sequence of maskable sub-action spaces. A gated recurrent unit (GRU)-based agent and an adapted soft actor critic (SAC) algorithm are designed accordingly, producing a data-efficient, safety-guaranteed, and scalable DRL solution to the DDNR problem. Comprehensive comparisons with existing data-driven methods and model-based benchmarks are conducted via various case studies, demonstrating the advantages of the proposed method in both algorithmic performance and scalability.},
  archive      = {J_TNNLS},
  author       = {Ruoheng Wang and Xiaowen Bi and Siqi Bu and Zhixian Tang},
  doi          = {10.1109/TNNLS.2025.3574208},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19270-19284},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Deep reinforcement learning approach for dynamic distribution network reconfiguration based on sequential masking},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing graph neural networks for out-of-distribution graph detection. <em>TNNLS</em>, <em>36</em>(10), 19255-19269. (<a href='https://doi.org/10.1109/TNNLS.2025.3584090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have shown promise in graph classification tasks, but they struggle to identify out-of-distribution (OOD) graphs often encountered in real-world scenarios, posing a significant obstacle for their open-world deployment. Due to the unpredictable nature of the various distributions to which OOD graphs adhere, the challenge of OOD graph detection lies in enabling models to capture distribution differences between in-distribution (ID) and OOD graphs. Current methods often introduce a subset of OOD patterns, such as synthetic OOD graphs, to facilitate learning the discrimination between ID and OOD graphs. However, these OOD patterns may not sufficiently encapsulate the entire range of OOD graphs, leading to inadequate learning of the distribution differences between ID and OOD graphs. In this article, we propose a novel OOD graph detection algorithm, ODGNN. The ODGNN does not expose GNNs to any OOD patterns during model training, thus reducing bias toward specific types of OOD graph samples and enhancing OOD graph detection. The algorithm differentiates graphs by evaluating whether the input graphs conform to established ID graph class-conditioned distributions. Specifically, during model training, the ODGNN integrates a Gaussian encoder into GNNs to characterize ID graph classes using distinct class-conditioned distributions. During inference, OOD graphs are mapped to a representation space distant from ID graphs due to their divergence from any known class-conditioned distribution. Extensive experiments conducted on real-world datasets validate the effectiveness of the ODGNN in enhancing OOD detection performance across various GNN-based graph classification models. The ODGNN also demonstrates superior performance compared to state-of-the-art OOD graph detection competitors.},
  archive      = {J_TNNLS},
  author       = {Ge Zhang and Zhenyu Yang and Jia Wu and Pengfei Jiao and Jian Yang},
  doi          = {10.1109/TNNLS.2025.3584090},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19255-19269},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Enhancing graph neural networks for out-of-distribution graph detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic-aligned code summarization: Bridging the gap between code and natural language through data flow analysis. <em>TNNLS</em>, <em>36</em>(10), 19240-19254. (<a href='https://doi.org/10.1109/TNNLS.2025.3581792'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code summarization is designed to generate descriptive natural language for code snippets, facilitating understanding and increasing productivity for developers. Previous research often overlooks the semantic connection between code and its natural language description, resulting in a noticeable gap and suboptimal solution. To address this issue, we introduce a semantic-aligned code summarization framework that leverages crucial data flow information from code for semantic analysis, ensuring alignment between code and summaries. Specifically, we utilize a semantic extraction module (SEM) to decipher the meaning of code and align it with natural language through a semantic alignment module. In the SEM, we construct a code graph that includes data flow edges using static program analysis techniques. Then, on this well-constructed code graph, we innovatively adopt a walking algorithm guided by data flow to extract the semantics of the code. This walking algorithm understands code semantics by analyzing the information transfer between variables during the program execution process. In the semantic alignment module, we integrate a contrastive learning loss mechanism for semantic alignment, which cohesively maps the semantic domains of code and natural language into a unified vector space. We further theoretically analyzed that the data-flow-guided walking algorithm can ensure capturing semantically highly related nodes in shorter paths. Extensive experiments on two benchmark datasets demonstrate the efficacy and broad applicability of the framework.},
  archive      = {J_TNNLS},
  author       = {Yuze Zhao and Zhenya Huang and Kai Zhang and Weibo Gao and Qi Liu and Xukai Liu and Fangzhou Yao and Enhong Chen},
  doi          = {10.1109/TNNLS.2025.3581792},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19240-19254},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Semantic-aligned code summarization: Bridging the gap between code and natural language through data flow analysis},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reachable polyhedral marching (RPM): An exact analysis tool for deep-learned control systems. <em>TNNLS</em>, <em>36</em>(10), 19225-19239. (<a href='https://doi.org/10.1109/TNNLS.2025.3571720'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks are increasingly used in robotics as policies, state transition models, state estimation models, or all of the above. With these components being learned from data, it is important to be able to analyze what behaviors were learned and how this affects closed-loop performance. In this article, we take steps toward this goal by developing methods for computing control invariant sets and regions of attraction (ROAs) of dynamical systems represented as neural networks. We focus our attention on feedforward neural networks with the rectified linear unit (ReLU) activation, which are known to implement continuous piecewise-affine (PWA) functions. We describe the reachable polyhedral marching (RPM) algorithm for enumerating the affine pieces of a neural network through an incremental connected walk. We then use this algorithm to compute exact forward and backward reachable sets, from which we provide methods for computing control invariant sets and ROAs. Our approach is unique in that we find these sets incrementally, without Lyapunov-based tools. In our examples, we demonstrate the ability of our approach to find nonconvex control invariant sets and ROAs on tasks with learned van der Pol oscillator and pendulum models. Further, we provide an accelerated algorithm for computing ROAs that leverages the incremental and connected enumeration of affine regions that RPM provides. We show this acceleration to lead to a $15\times $ speedup in our examples. Finally, we apply our methods to find a set of states that are stabilized by an image-based controller for an aircraft runway control problem.},
  archive      = {J_TNNLS},
  author       = {Joseph A. Vincent and Mac Schwager},
  doi          = {10.1109/TNNLS.2025.3571720},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19225-19239},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Reachable polyhedral marching (RPM): An exact analysis tool for deep-learned control systems},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple influences maximization under dynamic link strength in multi-agent systems: The competitive and cooperative cases. <em>TNNLS</em>, <em>36</em>(10), 19210-19224. (<a href='https://doi.org/10.1109/TNNLS.2025.3588236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the issue of multiple influences maximization under dynamic link strength (MIMDLS) in multi-agent systems (MASs). Initially, a novel model for dynamic link strength within MASs is suggested to facilitate the simulation of multiple influences diffusion. Subsequently, the MIMDLS problem is formulated with both competitive and cooperative scenarios being examined. In response, two diffusion models, specifically the competitive multiple influences independent cascade (Cp-MIIC) model and the cooperative multiple influences linear threshold (Cr-MILT) model, are designed for MASs. Furthermore, a distributed deep reinforcement learning (DRL) framework is established based on MASs by incorporating asynchronous training and updating processes for seed selection in the context of multiple influences. Moreover, the developed distributed DRL algorithm encompasses the estimation of Q value as well as the management of constraints within Cp-MIIC and Cr-MILT models. Finally, comprehensive experiments are conducted to: 1) validate the effectiveness and efficiency of the proposed models and algorithms in terms of multiple influence diffusion and 2) benchmark their performance against state-of-the-art methods.},
  archive      = {J_TNNLS},
  author       = {Mincan Li and Zidong Wang and Simon J. E. Taylor and Kenli Li and Xiangke Liao and Xiaohui Liu},
  doi          = {10.1109/TNNLS.2025.3588236},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19210-19224},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multiple influences maximization under dynamic link strength in multi-agent systems: The competitive and cooperative cases},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long short-term financial time series forecasting based on residual multiscale TCN sparse expert network and informer. <em>TNNLS</em>, <em>36</em>(10), 19200-19209. (<a href='https://doi.org/10.1109/TNNLS.2025.3584369'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the inherent high volatility and complexity of financial markets, traditional time series forecasting models face numerous challenges in handling both short- and long-term predictions in the stock market. Most traditional neural network-based financial prediction models are limited to short-term forecasting and struggle to capture long-term trends and global dependencies in the market fully. To address this, we propose a novel network architecture called ResMMoT-Informer. This model combines the strengths of the residual multiscale temporal convolutional network (TCN) sparse expert network (ResMMoT) and the Informer, enabling it to effectively capture multiscale local features and global dependencies in the stock market. ResMMoT achieves stable training through a residual structure and a sparse multiscale TCN expert network, allowing it to flexibly model complex temporal features and learn trends across different time-step scales. Meanwhile, the Informer optimizes long-sequence forecasting performance through an improved self-attention mechanism. Additionally, we introduce the wavelet noise reduction (WNR) method, further enhancing the model’s robustness and prediction accuracy. In the experimental section, ablation experiments first validate the effectiveness and necessity of the proposed strategies and network structure. Subsequent comparison experiments on the NASDAQ100 dataset demonstrate that ResMMoT-Informer excels in both long- and short-term time series forecasting tasks in the stock market, with significantly better prediction accuracy and generalization ability than existing models. Compared to other popular neural network-based financial forecasting models, ResMMoT-Informer leads in prediction accuracy, time robustness, and interpretability, showcasing its cutting-edge advantage in contemporary research.},
  archive      = {J_TNNLS},
  author       = {Wuzhida Bao and Yuting Cao and Yin Yang and Shiping Wen},
  doi          = {10.1109/TNNLS.2025.3584369},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19200-19209},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Long short-term financial time series forecasting based on residual multiscale TCN sparse expert network and informer},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Protecting deep learning model copyrights with adversarial example-free reuse detection. <em>TNNLS</em>, <em>36</em>(10), 19187-19199. (<a href='https://doi.org/10.1109/TNNLS.2025.3578664'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model reuse techniques can reduce the resource requirements for training high-performance deep neural networks (DNNs) by leveraging existing models. However, unauthorized reuse and replication of DNNs can lead to copyright infringement and economic loss to the model owner. This underscores the need to analyze the reuse relation between DNNs and develop copyright protection techniques to safeguard intellectual property rights. Existing DNN copyright protection approaches suffer from several inherent limitations hindering their effectiveness in practical scenarios. For instance, existing white-box fingerprinting approaches cannot address the common heterogeneous reuse case where the model architecture is changed, and DNN fingerprinting approaches heavily rely on generating adversarial examples with good transferability, which is known to be challenging in the black-box setting. To bridge the gap, we propose a neuron functionality analysis-based reuse detector (NFARD), a neuron functionality (NF) analysis-based reuse detector, which only requires normal test samples to detect reuse relations by measuring the models’ differences on a newly proposed model characterization, i.e., NF. A set of NF-based distance metrics is designed to make NFARD applicable to both white-box and black-box settings. Moreover, we devise a linear transformation method to handle heterogeneous reuse cases by constructing the optimal projection matrix for dimension consistency, significantly extending the application scope of NFARD. To the best of our knowledge, this is the first adversarial example-free method that exploits NF for DNN copyright protection. As a side contribution, we constructed a reuse detection benchmark named Reuse Zoo that covers various practical reuse techniques and popular datasets. Extensive evaluations on this comprehensive benchmark show that NFARD achieves $F1$ scores of 0.984 and 1.0 for detecting reuse relationships in black-box and white-box settings, respectively, while generating test suites $2{\sim } 99$ times faster than previous methods.},
  archive      = {J_TNNLS},
  author       = {Xiaokun Luan and Xiyue Zhang and Jingyi Wang and Meng Sun},
  doi          = {10.1109/TNNLS.2025.3578664},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19187-19199},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Protecting deep learning model copyrights with adversarial example-free reuse detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). You never walk alone: A generalizable and nonparametric structure learning framework. <em>TNNLS</em>, <em>36</em>(10), 19175-19186. (<a href='https://doi.org/10.1109/TNNLS.2025.3580101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The graph-structured learning (GSL) aims to assist graph neural networks (GNNs) to yield effective node embeddings for downstream tasks, especially in scenarios with the absence of structures or the existence of unreliable edges. Most GSL models are built on i.i.d. assumption across training and testing data. However, this assumption can be violated, where testing data contain out-of-distribution (OOD) samples. Consequently, those models are limited in generalization, which will lead to a poor structure. On the other hand, while they have made great progress, additional optimized parameters are required due to their implementation with parametric models. To tackle the above problems, we propose a novel generalizable and nonparametric structure learning framework named GNS, which can be easily and effectively applied to various tasks. GNS neither relies on i.i.d. assumption nor even involves any parameters being optimized, instead to find an appropriate similarity between nodes and an associated threshold to establish desirable structures. Specifically, we first incorporate the candidate neighbor distributions for nodes to refine the similarity. Then, we introduce an adaptive threshold discovery method inspired by Fisher’s criterion to determine final structures. Extensive experiments demonstrate that GNS excels not only in OOD scenarios but also in the general classification and regression prediction tasks.},
  archive      = {J_TNNLS},
  author       = {Jiaqiang Zhang and Xinrui Wang and Songcan Chen},
  doi          = {10.1109/TNNLS.2025.3580101},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19175-19186},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {You never walk alone: A generalizable and nonparametric structure learning framework},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decentralized personalized federated learning based on a conditional “Sparse-to-sparser” scheme. <em>TNNLS</em>, <em>36</em>(10), 19160-19174. (<a href='https://doi.org/10.1109/TNNLS.2025.3580277'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized federated learning (DFL) has gained popularity due to its robustness and elimination of centralized coordination requirements. In this paradigm, clients actively participate in training by exchanging models with neighboring nodes in their network. However, DFL introduces significant overhead in both training and communication costs. While existing methods focus primarily on reducing communication costs, they often overlook training efficiency and the challenges of data heterogeneity. We address these limitations by introducing DA-DPFL, a novel sparse-to-sparser training scheme that initializes with a subset of model parameters which progressively decrease during training through dynamic aggregation. This approach substantially reduces energy consumption while preserving adequate information during critical learning periods. Our experimental results demonstrate that DA-DPFL significantly outperforms DFL baselines in test accuracy while achieving up to 5x reduction in energy costs. We provide theoretical convergence analysis that validates the applicability of our approach in decentralized and personalized learning contexts. The code is available at: https://github.com/EricLoong/da-dpfl},
  archive      = {J_TNNLS},
  author       = {Qianyu Long and Qiyuan Wang and Christos Anagnostopoulos and Daning Bi},
  doi          = {10.1109/TNNLS.2025.3580277},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19160-19174},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Decentralized personalized federated learning based on a conditional “Sparse-to-sparser” scheme},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MoNetV2: Enhanced motion network for freehand 3-D ultrasound reconstruction. <em>TNNLS</em>, <em>36</em>(10), 19145-19159. (<a href='https://doi.org/10.1109/TNNLS.2025.3573210'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional ultrasound (US) aims to provide sonographers with the spatial relationships of anatomical structures, playing a crucial role in clinical diagnosis. Recently, deep-learning-based freehand 3-D US has made significant advancements. It reconstructs volumes by estimating transformations between images without external tracking. However, image-only reconstruction poses difficulties in reducing cumulative drift and further improving reconstruction accuracy, particularly in scenarios involving complex motion trajectories. In this context, we propose an enhanced motion network (MoNetV2) to enhance the accuracy and generalizability of reconstruction under diverse scanning velocities and tactics. First, we propose a sensor-based temporal and multibranch structure (TMS) that fuses image and motion information from a velocity perspective to improve image-only reconstruction accuracy. Second, we devise an online multilevel consistency constraint (MCC) that exploits the inherent consistency of scans to handle various scanning velocities and tactics. This constraint exploits scan-level velocity consistency (SVC), path-level appearance consistency (PAC), and patch-level motion consistency (PMC) to supervise interframe transformation estimation. Third, we distill an online multimodal self-supervised strategy (MSS) that leverages the correlation between network estimation and motion information to further reduce cumulative errors. Extensive experiments clearly demonstrate that MoNetV2 surpasses existing methods in both reconstruction quality and generalizability performance across three large datasets.},
  archive      = {J_TNNLS},
  author       = {Mingyuan Luo and Xin Yang and Zhongnuo Yan and Yan Cao and Yuanji Zhang and Xindi Hu and Jin Wang and Haoxuan Ding and Wei Han and Litao Sun and Dong Ni},
  doi          = {10.1109/TNNLS.2025.3573210},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19145-19159},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {MoNetV2: Enhanced motion network for freehand 3-D ultrasound reconstruction},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lifelong active inference of gait control. <em>TNNLS</em>, <em>36</em>(10), 19133-19144. (<a href='https://doi.org/10.1109/TNNLS.2025.3579814'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sustaining the robot’s longevity becomes challenging in dynamic deployments characterized by new unknown environments and embodiments outside of the prior knowledge. Hence, the knowledge of robot-environment interactions needs to be continually updated for system adaptation. It can be implemented through self-verification as a continual comparison of predictions with observations using the predictive coding (PC) principle. The principle has been further extended into the active inference control (AIC) in biomimetic robotics to drive the control, state estimation, and model update. However, continually updating one model leads to catastrophic forgetting in the long term. Therefore, we propose an autonomously expanding self-verifying world model (WM) of sensorimotor dynamics utilized in model-based gait control. The model combines PC with the incremental knowledge representation based on the internal model (IM) principle. The proposed method is experimentally validated in virtual and real scenarios, where the hexapod walking robot has to recognize and adapt to leg paralysis and then recognize the recovery. The method generates novel behaviors in real time, improving the performance and outperforming the examined state-of-the-art methods. Furthermore, the robot’s decisions and gained knowledge are interpretable and promise further functional scalability.},
  archive      = {J_TNNLS},
  author       = {Rudolf Szadkowski and Jan Faigl},
  doi          = {10.1109/TNNLS.2025.3579814},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19133-19144},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Lifelong active inference of gait control},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New WTOD protocol-based fault detection filter design for interval type-2 fuzzy systems via an adaptive differential evolution algorithm. <em>TNNLS</em>, <em>36</em>(10), 19119-19132. (<a href='https://doi.org/10.1109/TNNLS.2025.3579254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is concerned with the design problem of an $H_{\infty }$ optimal fault detection (FD) filter for networked interval type-2 (IT2) fuzzy systems that are subjected to stochastic cyberattacks. To effectively reduce the utilization of constrained network resources, a new dynamically adjusted event-triggered weighted try-once-discard (DAET-WTOD) protocol is developed, in which two adaptive rules are constructed based on the measured output and the probability of denial-of-service (DoS) attacks. Furthermore, a fuzzy switched-like FD filter is designed with the purpose of detecting system fault signals, while simultaneously considering the DAET-WTOD protocol and stochastic cyberattacks. Subsequently, by utilizing an imperfect premise matching (IPM) scheme, an opposition-based learning adaptive differential evolution algorithm is proposed to deal with the networked IT2 fuzzy systems. This algorithm is capable of iteratively searching the membership function values of the fuzzy filter in real time, thereby achieving improved $H_{\infty }$ performance. Finally, some simulation results are provided to verify the feasibility and advantages of the proposed $H_{\infty }$ optimal FD technique.},
  archive      = {J_TNNLS},
  author       = {Wei Qian and Yanmin Wu and Zidong Wang},
  doi          = {10.1109/TNNLS.2025.3579254},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19119-19132},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {New WTOD protocol-based fault detection filter design for interval type-2 fuzzy systems via an adaptive differential evolution algorithm},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Video prediction of dynamic physical simulations with pixel-space spatiotemporal transformers. <em>TNNLS</em>, <em>36</em>(10), 19106-19118. (<a href='https://doi.org/10.1109/TNNLS.2025.3585949'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the performance and scalability of autoregressive large language models (LLMs), transformer-based models have seen recent success in the visual domain. This study investigates a transformer adaptation for video prediction with a simple end-to-end approach, comparing various spatiotemporal self-attention layouts. Focusing on causal modeling of physical simulations over time; a common shortcoming of existing video-generative approaches, we attempt to isolate spatiotemporal reasoning via physical object tracking metrics and unsupervised training on physical simulation datasets. We introduce a simple yet effective pure transformer model for autoregressive video prediction, utilizing continuous pixel-space representations for video prediction. Without the need for complex training strategies or latent feature-learning components, our approach significantly extends the time horizon for physically accurate predictions by up to 50% when compared with existing latent-space approaches, while maintaining comparable performance on common video quality metrics. In addition, we conduct interpretability experiments to identify network regions that encode information useful to perform accurate estimations of PDE simulation parameters via probing models, and find that this generalizes to the estimation of out-of-distribution simulation parameters. This work serves as a platform for further attention-based spatiotemporal modeling of videos via a simple, parameter efficient, and interpretable approach.},
  archive      = {J_TNNLS},
  author       = {Dean L. Slack and G. Thomas Hudson and Thomas Winterbottom and Noura Al Moubayed},
  doi          = {10.1109/TNNLS.2025.3585949},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19106-19118},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Video prediction of dynamic physical simulations with pixel-space spatiotemporal transformers},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust rank-one matrix completion via explicit regularizer. <em>TNNLS</em>, <em>36</em>(10), 19092-19105. (<a href='https://doi.org/10.1109/TNNLS.2025.3571594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In robust matrix completion (MC), the Welsch function, also referred to as the maximum correntropy criterion with Gaussian kernel, has been widely employed. However, it suffers from the drawback of down-weighing normal data. This work is the first to uncover the explicit regularizer (ER) for the Welsch function based on the multiplicative form of half-quadratic (HQ) minimization. Leveraging this discovery, we develop a new function called t-Welsch, also with ER, which provides unity weight to normal data and exhibits stronger robustness against large-magnitude outliers compared to Huber’s weight. We apply the t-Welsch to rank-one matching pursuit, enabling accurate and robust low-rank matrix recovery without the need of rank information and singular value decomposition (SVD). The resultant MC algorithm is realized via block coordinate descent (BCD), whose analyses of convergence and computational complexity are produced. Experiments are conducted using synthetic random data, as well as real-world images with salt-and-pepper noise and multiple-input multiple-output (MIMO) radar signals in the presence of Gaussian mixture disturbances. In all three scenarios, the proposed algorithm outperforms the state-of-the-art robust MC methods in terms of recovery accuracy. The code is available at https://github.com/ShuDun23/t-Welsch-and-RAR1MC.},
  archive      = {J_TNNLS},
  author       = {Hao Nan Sheng and Zhi-Yong Wang and Hing Cheung So},
  doi          = {10.1109/TNNLS.2025.3571594},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19092-19105},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust rank-one matrix completion via explicit regularizer},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evidential deep learning for open-set active domain adaptation. <em>TNNLS</em>, <em>36</em>(10), 19081-19091. (<a href='https://doi.org/10.1109/TNNLS.2025.3571943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open-set domain adaptation (OSDA) seeks to transfer knowledge from a labeled source domain to an unlabeled target domain containing novel classes. Traditional OSDA methods rarely account for the uncertainty in predictions and typically require additional training overhead. Evidential deep learning (EDL) transforms the model’s predictions from point estimates to distributions over the probability simplex by replacing the standard softmax output of classification neural networks with Dirichlet distributions. Considering the presence of out-of-distribution novel classes in OSDA and the additional overhead of existing methods, we propose EDL for open-set active domain adaptation (EOSADA). Leveraging EDL, we construct an open-set classifier and employ a two-round selection strategy guided by the data uncertainty of target domain samples and semantic similarity scores with known classes. This strategy balances the selection of samples from known and novel classes while identifying informative samples, thereby maximizing the performance of the model in OSDA scenarios without modifying the model structure and utilizing a limited annotation budget. Extensive experiments demonstrate the superiority of our approach.},
  archive      = {J_TNNLS},
  author       = {Qing Tian and Jiangsen Yu and Yi Zhao and Wen Li and Zhen Lei},
  doi          = {10.1109/TNNLS.2025.3571943},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19081-19091},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Evidential deep learning for open-set active domain adaptation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MonOri: Orientation-guided PnP for monocular 3-D object detection. <em>TNNLS</em>, <em>36</em>(10), 19068-19080. (<a href='https://doi.org/10.1109/TNNLS.2025.3577618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monocular 3-D object detection is a challenging task in the field of autonomous driving and has made great progress. However, current monocular image methods tend to incorporate additional information such as pseudolabels to improve algorithm performance while overlooking the geometric relationship between the object’s keypoints, resulting in low performance for occluded object detection. To address this issue, we find that introducing the orientation information of objects in the 3-D detection pipeline can help improve the detection performance of occluded objects. An orientation-guided perspective-n-point (PnP) for monocular 3-D object detection method named MonOri is presented in this article, which uses object’s orientation to guide keypoints’ optimization. Considering the existence of different deformation objects in the scene, we design the feature aggregation detection module (FADM), which consists of the feature focus fusion module (FFFM) and CondConv detection module (CCDM). First, FFFM can highlight signals from irregularly occluded objects, effectively modeling features of elongated and small-sized objects. This module enhances the model’s ability to recognize elongated and small-sized objects in complex scenes. Then, the CCDM is designed to improve the network’s ability to estimate object keypoints’ location regression under occlusion conditions and minimize the network computational overhead. Finally, considering that the unoccluded portions of occluded objects are closely related to the orientation of the objects, an orientation-guided keypoints’ selection module (OGKSM) is proposed to enhance the accuracy of objected optimization for keypoint positions and spatial location inference of the object. Experimental results indicate that the MonOri method achieves competitive results; it is also demonstrated that the orientation information is introduced in the PnP algorithm to estimate the object’s spatial position that can mitigate the impact of occlusion on object detection, thus improving the recognition rate of occluded objects. Our code is available at https://github.com/DL-YHD/MonOri},
  archive      = {J_TNNLS},
  author       = {Hongdou Yao and Pengfei Han and Jun Chen and Zheng Wang and Yansheng Qiu and Xiao Wang and Yimin wang and Xiaoyu Chai and Chenglong Cao and Wei Jin},
  doi          = {10.1109/TNNLS.2025.3577618},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19068-19080},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {MonOri: Orientation-guided PnP for monocular 3-D object detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The risk of federated learning to skew fine-tuning features and underperform robustness. <em>TNNLS</em>, <em>36</em>(10), 19054-19067. (<a href='https://doi.org/10.1109/TNNLS.2025.3585063'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To tackle the scarcity and privacy issues associated with domain-specific datasets, the integration of federated learning in conjunction with fine-tuning (FT) has emerged as a practical solution. However, our findings reveal that federated learning has the risk of skewing FT features and compromising the out-of-distribution (OOD) robustness of pretrained models. By introducing three robustness indicators and conducting experiments across diverse robust datasets, we elucidate these phenomena by scrutinizing the ability of data representations, transferability, and deviations within the model. To mitigate the negative impact of practical federated learning on model robustness, we introduce a general noisy projection (GNP)-based robust algorithm, ensuring no deterioration of accuracy on the target distribution. Specifically, the key strategy for enhancing model robustness entails the transfer of robustness from the pretrained model to the fine-tuned model, coupled with adding a small amount of Gaussian noise to augment the representative capacity of the model. The comprehensive experimental results demonstrate that our approach markedly enhances the robustness across diverse scenarios, encompassing various parameter-efficient FT (PEFT) methods and confronting different levels of label distribution skew and quantity distribution skew.},
  archive      = {J_TNNLS},
  author       = {Mengyao Du and Miao Zhang and Yuwen Pu and Qingming Li and Shouling Ji and Quanjun Yin},
  doi          = {10.1109/TNNLS.2025.3585063},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19054-19067},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {The risk of federated learning to skew fine-tuning features and underperform robustness},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensively adaptive architectural optimization-ingrained quantum neural network model for cloud workloads prediction. <em>TNNLS</em>, <em>36</em>(10), 19039-19053. (<a href='https://doi.org/10.1109/TNNLS.2025.3577721'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate workload prediction and advanced resource reservation are indispensably crucial for managing dynamic cloud services. Traditional neural networks and deep learning models frequently encounter challenges with diverse, high-dimensional workloads, especially during sudden resource demand changes, leading to inefficiencies. This issue arises from their limited optimization during training, relying only on parametric (interconnection weights) adjustments using conventional algorithms. To address this issue, this work proposes a novel comprehensively adaptive architectural optimization-based variable quantum neural network (CA-QNN), which combines the efficiency of quantum computing with complete structural and qubit vector parametric learning. The model converts workload data into qubits, processed through qubit neurons with controlled not-gated activation functions for intuitive pattern recognition. In addition, a comprehensive architecture optimization algorithm for networks is introduced to facilitate the learning and propagation of the structure and parametric values in variable-sized quantum neural networks (VQNNs). This algorithm incorporates quantum adaptive modulation (QAM) and size-adaptive recombination during the training process. The performance of the CA-QNN model is thoroughly investigated against seven state-of-the-art methods across four benchmark datasets of heterogeneous cloud workloads. The proposed model demonstrates superior prediction accuracy, reducing prediction errors by up to 93.40% and 91.27% compared to existing deep learning and QNN-based approaches.},
  archive      = {J_TNNLS},
  author       = {Jitendra Kumar and Deepika Saxena and Kishu Gupta and Satyam Kumar and Ashutosh Kumar Singh},
  doi          = {10.1109/TNNLS.2025.3577721},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19039-19053},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A comprehensively adaptive architectural optimization-ingrained quantum neural network model for cloud workloads prediction},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chain-of-situation aware progressive inference learning. <em>TNNLS</em>, <em>36</em>(10), 19024-19038. (<a href='https://doi.org/10.1109/TNNLS.2025.3576486'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The grounded situation recognition (GSR) task aims to recognize the structured semantics of an image to achieve “human-like” event understanding. Most previous studies primarily focus on the visual features of the situation, overlooking the step-by-step cognitive reasoning process that humans employ in complex task settings. Recently, the emergence of multimodal large language models (MLLMs) has provided novel directions for addressing complex problems. However, directly deploying MLLMs on the GSR task is suboptimal due to their tendency to exhibit “hallucination” issues. Additionally, fine-tuning MLLMs for the GSR task incurs high training costs. To address these challenges, inspired by human cognitive theory and the chain-of-thought (CoT) strategy, we propose the chain-of-situation progressive inference learning (CoS-PIL) framework, a lightweight approach that progressively completes verb prediction, noun prediction, and role grounding. The prediction of each step depends on the historical information of the previous step. Specifically, we first design situation prompts tailored to the GSR task and utilize MLLMs to analyze the input image and language prompts, generating heuristic response text for the current situation in the image. Instead of fine-tuning the MLLM, we activate the reasoning capabilities of the frozen MLLM and adapt its generated responses into three lightweight modules: CoS-Verb, CoS-Noun, and CoS-Ground. Considering that MLLMs may generate redundant content, we carefully design the chain-of-interest predictor (CoI-Predictor) to extract key information from the extensive response text and inject it into the model as prompts to enhance the performance. Extensive experiments on the challenging SWiG benchmark demonstrate that CoS-PIL outperforms other state-of-the-art methods. The code is publically available at https://github.com/XDLiuyyy/CoS-PIL},
  archive      = {J_TNNLS},
  author       = {Yang Liu and Fang Liu and Licheng Jiao and Qianyue Bao and Shuo Li and Lingling Li and Xu Liu and Puhua Chen and Wenping Ma},
  doi          = {10.1109/TNNLS.2025.3576486},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19024-19038},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Chain-of-situation aware progressive inference learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RealignDiff: Boosting text-to-image diffusion model with coarse-to-fine semantic realignment. <em>TNNLS</em>, <em>36</em>(10), 19010-19023. (<a href='https://doi.org/10.1109/TNNLS.2025.3584554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in text-to-image diffusion models have achieved remarkable success in generating high-quality, realistic images from textual descriptions. However, these approaches have faced challenges in precisely aligning the generated visual content with the textual concepts described in the prompts. In this article, we propose a two-stage coarse-to-fine semantic realignment method, named RealignDiff, aimed at improving the alignment between text and images in text-to-image diffusion models. In the coarse semantic realignment phase, a novel caption reward, leveraging the BLIP-2 model, is proposed to evaluate the semantic discrepancy between the generated image caption and the given text prompt. Subsequently, the fine semantic realignment stage uses a local dense caption generation module and a reweighting attention modulation module to refine the previously generated images from a local semantic view. Experimental results on the MS-COCO and ViLG-300 datasets demonstrate that the proposed two-stage coarse-to-fine semantic realignment method outperforms other baseline realignment techniques by a substantial margin in both visual quality and semantic similarity with the input prompt.},
  archive      = {J_TNNLS},
  author       = {Zutao Jiang and Guian Fang and Jianhua Han and Guansong Lu and Hang Xu and Shengcai Liao and Xiaojun Chang and Xiaodan Liang},
  doi          = {10.1109/TNNLS.2025.3584554},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {19010-19023},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {RealignDiff: Boosting text-to-image diffusion model with coarse-to-fine semantic realignment},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust spatiotemporal prototype learning for spiking neural networks. <em>TNNLS</em>, <em>36</em>(10), 18995-19009. (<a href='https://doi.org/10.1109/TNNLS.2025.3583747'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) leverage their spike-driven nature to achieve high energy efficiency, positioning them as a promising alternative to traditional artificial neural networks (ANNs). The spiking decoder, a crucial component for output, significantly affects the performance of SNNs. However, current rate coding schemes for decoding of SNNs often lack robustness and do not have a training framework suitable for robust learning, while alternatives to rate coding generally produce worse overall performance. To address these challenges, we propose spatiotemporal prototype (STP) learning for SNNs, which uses multiple learnable binarized prototypes for distance-based decoding. In addition, we introduce a cotraining framework that jointly optimizes prototypes and model parameters, enabling mutual adaptation of the two components. STP learning clusters feature centers through supervised learning to ensure effective aggregation around the prototypes, while maintaining enough spacing between prototypes to handle noise and interference. This dual capability results in superior stability and robustness. On eight benchmark datasets with diverse challenges, the STP-SNN model achieves performance comparable to or superior to state-of-the-art methods. Notably, STP learning demonstrates exceptional robustness and stability in multitask experiments. Overall, these findings reveal that STP learning is an effective means of improving the performance and robustness of SNNs.},
  archive      = {J_TNNLS},
  author       = {Wuque Cai and Hongze Sun and Qianqian Liao and Jiayi He and Duo Chen and Dezhong Yao and Daqing Guo},
  doi          = {10.1109/TNNLS.2025.3583747},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18995-19009},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust spatiotemporal prototype learning for spiking neural networks},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NetEventCause: Event-driven root cause analysis for large network system without topology. <em>TNNLS</em>, <em>36</em>(10), 18983-18994. (<a href='https://doi.org/10.1109/TNNLS.2025.3574316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Root cause analysis (RCA) is a crucial technique in network systems for uncovering the abnormal nodes that lead to the network alarm flood. Within private cloud network systems, the calling chains and topologies among entities, such as hosts, routes, and services, are always incomplete due to nonstandardized management. Existing topology-free RCA techniques, which rely on the casual discovery, are inapplicable when the scale of the network system is extremely large or the number of triggered alarms is sparse. This article proposes NetEventCause (NEC), an event-driven, unsupervised, and nonintrusive RCA algorithm for large network systems, where the network topology is unknown. NEC learns from historical alarm events to model the occurrences of various alarm types using a multivariate neural temporal point process (TPP). Based on the conditional intensity predicted by the learned TPP, NEC can identify the root alarms from a cascade of alarm events and locate the causal alarms of derivative alarms using the attribution method. The experimental section evaluates the NEC using both a synthetic event dataset and a large real-world dataset. The real-world dataset is exported from the Huawei Shennong Intelligent Maintenance and Operation Center (IMOC), a platform deployed at one of China’s largest airports and manages over 200000 entities. Results obtained from the two datasets demonstrate that NEC outperforms most state of the art (SOTA) TPP models in modeling alarm events and surpasses general RCA methods in terms of identifying root alarms and recovering transmission chains of anomalies.},
  archive      = {J_TNNLS},
  author       = {Zhaolin Yuan and Long Ma and Wenjia Wei and Xia Zhu and Mingjie Sun and Duxin Chen and Xiaojuan Ban},
  doi          = {10.1109/TNNLS.2025.3574316},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18983-18994},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {NetEventCause: Event-driven root cause analysis for large network system without topology},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multilevel reliable guidance for unpaired multiview clustering. <em>TNNLS</em>, <em>36</em>(10), 18968-18982. (<a href='https://doi.org/10.1109/TNNLS.2025.3586306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we address the challenging problem of unpaired multiview clustering (UMC), which aims to achieve effective joint clustering using unpaired samples observed across multiple views. Traditional incomplete multiview clustering (IMC) methods typically rely on paired samples to capture complementary information between views. However, such strategies become impractical in the UMC due to the absence of paired samples. Although some researchers have attempted to address this issue by preserving consistent cluster structures across views, effectively mining such consistency remains challenging when the cluster structures with low confidence. Therefore, we propose a novel method, multilevel reliable guidance for UMC (MRG-UMC), which integrates multilevel clustering and reliable view guidance to learn consistent and confident cluster structures from three perspectives. Specifically, inner view multilevel clustering exploits high-confidence sample pairs across different levels to reduce the impact of boundary samples, resulting in more confident cluster structures. Synthesized-view alignment leverages a synthesized view to mitigate cross-view discrepancies and promote consistency. Cross-view guidance employs a reliable view guidance strategy to enhance the clustering confidence of poorly clustered views. These three modules are jointly optimized across multiple levels to achieve consistent and confident cluster structures. Furthermore, theoretical analyses verify the effectiveness of MRG-UMC in enhancing clustering confidence. Extensive experimental results show that MRG-UMC outperforms state-of-the-art UMC methods, achieving an average NMI improvement of 12.95% on multiview datasets. The source code is available at https://anonymous.4open.science/r/MRG-UMC-5E20},
  archive      = {J_TNNLS},
  author       = {Like Xin and Wanqi Yang and Lei Wang and Ming Yang},
  doi          = {10.1109/TNNLS.2025.3586306},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18968-18982},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multilevel reliable guidance for unpaired multiview clustering},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying outliers via local granular-ball density. <em>TNNLS</em>, <em>36</em>(10), 18956-18967. (<a href='https://doi.org/10.1109/TNNLS.2025.3578074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing density-based outlier detection methods process data at the single-granularity level of individual samples, requiring pairwise distance calculations between all samples and exhibiting high sensitivity to noise. The single-granularity-based processing paradigm fails to mine the information at multiple levels of granularity in data, and most of these methods ignore the potential uncertainty information in data, such as fuzziness, resulting in an inability to effectively detect potential outliers in data. As a novel granular computing method, Granular-Ball Computing (GBC) is characterized by its multi-granularity and robustness, which makes it able to make up for the above drawbacks well. In this study, we propose local Granular-Ball Density-based Outlier (GBDO) detection to improve the performance of the density-based methods. In GBDO, we first identify the $k\text {-}$ similarity Granular-Ball (GB) neighborhoods of each GB via the fuzzy relations among them. Subsequently, the local reachability similarity density of the GBs is calculated through the reachability similarity we defined. Finally, the local GB outlier factors of the samples are calculated based on the local reachability similarity density of the GBs. We adopt a multi-granularity processing paradigm using GBs as the basic units, which reduces computational complexity and improves robustness to noisy data by leveraging the multi-granularity nature of GBs. The experimental results demonstrate the effectiveness of GBDO by comparing it with state-of-the-art methods. The source code and datasets are publicly available at https://github.com/Mxeron/GBDO.},
  archive      = {J_TNNLS},
  author       = {Xinyu Su and Xiwen Wang and Dezhong Peng and Xiaomin Song and Huiming Zheng and Zhong Yuan},
  doi          = {10.1109/TNNLS.2025.3578074},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18956-18967},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Identifying outliers via local granular-ball density},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Asynchronous boundary stabilization of stochastic markovian Reaction–Diffusion neural networks with mode-dependent delays. <em>TNNLS</em>, <em>36</em>(10), 18945-18955. (<a href='https://doi.org/10.1109/TNNLS.2025.3574214'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article tackles asynchronous control issue for a class of stochastic Markovian reaction-diffusion neural networks with mode-dependent delays (MDDs). Taking into account the spatio-temporal distribution of such networks, we propose a boundary control (BC) scheme combined with asynchronous control to reduce control implementation cost and overcome environmental constraint. By incorporating a hidden Markov model to manage the mode asynchrony, we develop an integral asynchronous boundary controller for Neumann boundary conditions, as well as an innovative one for Dirichlet boundary conditions. We then derive an exponential stability criterion specific to MDDs and introduce a novel asynchronous BC synthesis approach. Additionally, we extend our findings to the leader-follower synchronization of these neural networks. The validity, superiority, and practicality of the proposed control design approach are demonstrated via three numerical examples, respectively.},
  archive      = {J_TNNLS},
  author       = {Xin-Xin Han and Kai-Ning Wu and Xin Yuan},
  doi          = {10.1109/TNNLS.2025.3574214},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18945-18955},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Asynchronous boundary stabilization of stochastic markovian Reaction–Diffusion neural networks with mode-dependent delays},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised multimanifold cross-guided diffusion deformable registration for cardiac MRI. <em>TNNLS</em>, <em>36</em>(10), 18930-18944. (<a href='https://doi.org/10.1109/TNNLS.2025.3577483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion networks demonstrate remarkable robustness in extracting complex structural features across various domains of medical image processing. In the task of cardiac image registration, diffusion networks excel at reconstructing intricate structural details, thereby enabling effective representation of cardiac anatomical motion. In this article, we propose an unsupervised diffusion registration framework named MCG-Reg for 3-D cardiac magnetic resonance (MR) image registration, employing a multimanifold cross-fusion strategy. MCG-Reg comprises two components: the multimanifold cross-fusion (MCF) module and the weighted fusion codec (WFC) module. MCF module decouples the cardiac image, leveraging multifrequency and multiscale features for cross-attention (CA) calculation, and fuses with the edge image to enable adaptive focus gathering and edge perception capabilities in the model, thereby enhancing the effective aggregation of local and global features. WFC module further processes cardiac features by utilizing offset attention to capture large displacement information, while employing feature energy maps for residual connections to enhance the model’s attention perception ability, thus facilitating better topology maintenance and boundary constraint realization. The registration accuracy and model generalization of the proposed MCG-Reg are validated in publicly available ACDC, M&Ms, and CAP datasets. The experimental results verify that it achieves state-of-the-art performance in comparison to related methods, highlighting the significant potential of the proposed framework in cardiac image analysis applications.},
  archive      = {J_TNNLS},
  author       = {Qifeng Zhao and Xuchu Wang},
  doi          = {10.1109/TNNLS.2025.3577483},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18930-18944},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Unsupervised multimanifold cross-guided diffusion deformable registration for cardiac MRI},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multigranularity information fused contrastive learning with multiview clustering. <em>TNNLS</em>, <em>36</em>(10), 18915-18929. (<a href='https://doi.org/10.1109/TNNLS.2025.3574885'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive multiview clustering (MVC) has emerged as a mainstream approach in MVC due to its superior representation learning capabilities. Traditional contrastive multiview learning methods extract both low- and high-level information from raw data. However, only high-level information is utilized for clustering. Since both types of information are essential for effective clustering, this limitation hampers performance. Moreover, effectively quantifying the importance of different views remains a critical challenge in contrastive MVC. Additionally, the absence of structural information during clustering further weakens clustering performance. To address these issues, this article proposes a multigranularity (MG) information fused contrastive learning with MVC (MGCMVC). Inspired by the concept of MG, low- and high-level features are reconstructed into fine- and coarse-granularity features. First, an MG adaptive weighting sample-level contrastive learning mechanism is introduced to fuse MG features to enhance clustering performance and mitigate clustering performance degradation caused by variations in view quality. Second, a structure-oriented cluster-level contrastive learning approach is designed to preserve structural information and enforce cross-view clustering consistency. Extensive and comprehensive experiments on ten widely used datasets demonstrate that MGCMVC achieves the state-of-the-art performance. The source code is available at https://github.com/Luyangabc/MGCMVC},
  archive      = {J_TNNLS},
  author       = {Hengrong Ju and Yang Lu and Weiping Ding and Wei Zhang and Xibei Yang},
  doi          = {10.1109/TNNLS.2025.3574885},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18915-18929},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multigranularity information fused contrastive learning with multiview clustering},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distance-aware attention reshaping for enhancing generalization of neural solvers. <em>TNNLS</em>, <em>36</em>(10), 18900-18914. (<a href='https://doi.org/10.1109/TNNLS.2025.3588209'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural solvers (NSs) based on the attention mechanism have demonstrated remarkable effectiveness in solving routing problems like traveling salesman problems (TSPs) and vehicle routing problems (VRPs). However, in the generalization process, we find a phenomenon of the dispersion of attention scores in existing NSs, which leads to poor performance. To improve the generalization ability of NSs, this article proposes a distance-aware attention reshaping (DAR) method. Specifically, without increasing any parameter of the neural network (NN), we utilize the distance information between nodes to adjust attention scores. This enables an NS trained on small-scale instances with a certain distribution to make rational choices when solving large-scale problems with different distributions. Its effectiveness is verified both theoretically and empirically. Extensive experiments on the TSP, asymmetric TSP (ATSP), capacitated VRP (CVRP), VRP with time windows (VRPTW), capacitated arc routing problem (CARP), and knapsack problem (KP) demonstrate the advantages of our method. Our code is available at https://github.com/ftwangyang/DAR},
  archive      = {J_TNNLS},
  author       = {Yang Wang and Ya-Hui Jia and Wei-Neng Chen and Yi Mei},
  doi          = {10.1109/TNNLS.2025.3588209},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18900-18914},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Distance-aware attention reshaping for enhancing generalization of neural solvers},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design of hopfield neural network based on DNA strand displacement circuits and its application in sudoku conjecture. <em>TNNLS</em>, <em>36</em>(10), 18889-18899. (<a href='https://doi.org/10.1109/TNNLS.2025.3576888'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, biological neural networks have developed rapidly due to their advantages of fast parallel computing processing speed and strong fault tolerance. This article is dedicated to explore innovation in this field and successfully constructing a Hopfield neural network model based on DNA strand displacement (DSD) circuits. First, this article constructs four core functional modules based on DSD, including an encoder module, weighted sum module, comparator module, and decoder module. These functional modules together form the design foundation of the DSD circuit, achieving effective circuit construction. Second, the construction of the Hopfield neural network is achieved through DSD circuits. The construction of this network achieves the integration of DSD technology and neural networks. Finally, the Sudoku conjecture problem is solved through the neural network. This article conducts a simulation in visual DSD, which verifies the feasibility of Sudoku conjecture. Our work integrates DSD technology with neural networks and uses them to solve practical problems. This fusion broadens the research field of neural networks and demonstrates the potential of biotechnology in practical applications.},
  archive      = {J_TNNLS},
  author       = {Junwei Sun and Haojie Wang and Yi Yue and Dan Ling and Yanfeng Wang},
  doi          = {10.1109/TNNLS.2025.3576888},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18889-18899},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Design of hopfield neural network based on DNA strand displacement circuits and its application in sudoku conjecture},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multilabel transfer learning method with dynamic multimetric for coupling fault diagnosis. <em>TNNLS</em>, <em>36</em>(10), 18874-18888. (<a href='https://doi.org/10.1109/TNNLS.2025.3573090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial practice, as systems become increasingly complex and integrated, the simultaneous failure of multicomponents, namely, coupling faults, has become more prevalent, which can be viewed as multilabel data. In addition, due to the changing industrial tasks, coupling fault diagnosis problems under varying operating conditions can be treated as cross-domain multilabel learning problems, which can be solved by multilabel transfer learning methods. However, existing multilabel transfer learning methods are all preliminary explorations lacking an in-depth exploring the multilevel similarity and complex features of coupling faults. To address this challenging problem, we propose a novel multilabel transfer learning method for coupling fault diagnosis, which achieves dual domain alignment at two levels. At the global feature level, the hypothesis space is reduced by minimizing the maximum mean discrepancy (MMD) at multistages of the network to align the global distribution. Furthermore, we decomposed the overall similarity into a combination of multiple local similarities and innovatively designed a dynamic multimetric structure to capture the diverse similarity characteristics of the data. By integrating the multimetric structure and dynamic mapping selection technique to form mathematical representations of this diverse similarity, this approach constrains the consistency of the local spatial structure of the two domains to achieve local space structure alignment. This method performs high superiority in multiple transfer tasks on the public and laboratory datasets, strongly demonstrating its effectiveness.},
  archive      = {J_TNNLS},
  author       = {Yaqi Xiao and Haiyin Zhou and Xuanying Zhou and Jiongqi Wang},
  doi          = {10.1109/TNNLS.2025.3573090},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18874-18888},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multilabel transfer learning method with dynamic multimetric for coupling fault diagnosis},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HVLF: A holistic visual localization framework across diverse scenes. <em>TNNLS</em>, <em>36</em>(10), 18859-18873. (<a href='https://doi.org/10.1109/TNNLS.2025.3580405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, integrating the multitask learning (MTL) paradigm into scene coordinate regression (SCoRe) techniques has achieved significant success in visual localization tasks. However, the feature extraction ability of existing frameworks is inherently constrained by the rigid weight activation strategy, which prevents each layer from concurrently capturing scene-universal features across diverse scenes and scene-particular attributes unique to each individual scene. In addition, the straightforward network architecture further exacerbates the issue of insufficient feature representation. To address these limitations, we introduce HVLF, a holistic framework that ensures flexible identification of both scene-universal and scene-particular attributes while integrating various attention mechanisms to enhance feature representation effectively. Technically, for the first issue, HVLF proposes a soft weight activation strategy (SWAS) equipped with polyhedral convolution to concurrently optimize scene-shared and scene-specific weights within each layer, which facilitates sufficient discernment of both scene-universal features and scene-particular attributes, thereby boosting the network’s capability for comprehensive scene perception. For the second issue, HVLF introduces a mixed attention perception module (MAPM) that incorporates channelwise, spatialwise, and elementwise attention mechanisms to perform multilevel feature fusion, hence extracting discriminative features to regress precise scene coordinates. Extensive experiments on indoor and outdoor datasets prove that HVLF realizes impressive localization performance. In addition, experiments conducted on 3-D object detection and feature matching tasks prove that the two proposed techniques are universal and can be seamlessly inserted into other methods.},
  archive      = {J_TNNLS},
  author       = {Kun Dai and Zhiqiang Jiang and Fuyuan Qiu and Dedong Liu and Tao Xie and Ke Wang and Ruifeng Li and Lijun Zhao},
  doi          = {10.1109/TNNLS.2025.3580405},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18859-18873},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {HVLF: A holistic visual localization framework across diverse scenes},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Near-optimal algorithms for instance-level constrained k-center clustering. <em>TNNLS</em>, <em>36</em>(10), 18844-18858. (<a href='https://doi.org/10.1109/TNNLS.2025.3574268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many practical applications impose a new challenge of utilizing instance-level background knowledge (e.g., subsets of similar or dissimilar data points) within their input data to improve clustering results. In this work, we build on the widely adopted k-center clustering, modeling its input instance-level background knowledge as must-link (ML) and cannot-link (CL) constraint sets, and formulate the constrained k-center problem. Given the long-standing challenge of developing efficient algorithms for constrained clustering problems, we first derive an efficient approximation algorithm for constrained k-center at the best possible approximation ratio of 2 with linear programming (LP)-rounding technology. Recognizing the limitations of LP-rounding algorithms including high runtime complexity and challenges in parallelization, we subsequently develop a greedy algorithm that does not rely on the LP and can be efficiently parallelized. This algorithm also achieves the same approximation ratio 2 but with lower runtime complexity. Lastly, we empirically evaluate our approximation algorithm against baselines on various real datasets, validating our theoretical findings and demonstrating significant advantages of our algorithm in terms of clustering cost, quality, and runtime complexity.},
  archive      = {J_TNNLS},
  author       = {Longkun Guo and Chaoqi Jia and Kewen Liao and Zhigang Lu and Minhui Xue},
  doi          = {10.1109/TNNLS.2025.3574268},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18844-18858},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Near-optimal algorithms for instance-level constrained k-center clustering},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DefectSAM: Hierarchically adapting SAM for pixel-wise surface defect detection. <em>TNNLS</em>, <em>36</em>(10), 18830-18843. (<a href='https://doi.org/10.1109/TNNLS.2025.3585887'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segment anything model (SAM) has recently demonstrated powerful segmentation ability for natural scene images (NSIs). However, the SAM exhibits limited performance in defect detection owing to the weak appearance of defects and cluttered backgrounds in industrial images. In this article, we propose a hierarchically adapting SAM for pixel-wise surface defect detection, named DefectSAM, which effectively modulates and decodes multilevel features of the encoder to capture defect information. Specifically, we introduce a learnable feature adaptation component between the image encoder and the decoder to modulate each level of features via the dual-feature adaptation unit. The dual-feature adaptation unit mainly includes the correlation-gated feature adaptation (CGFA) module and the mask-guided feature adaptation (MGFA) module. The CGFA exploits cross correlation spatial gating maps to adaptively incorporate a convolutional feature pyramid and Transformer features during feature adaptation, which is beneficial for capturing defect details. Moreover, the MGFA utilizes the mask prediction of high-level features as semantic guidance to select top-confidence foreground and background tokens for feature adaptation, focusing more on defect details and suppressing background noise. Extensive experiments on three defect detection datasets (i.e., MVTec AD, CrackSeg9k, ZJU-Leaper, and Magnetic tile) demonstrate that the proposed method achieves state-of-the-art performance with few learnable parameters, which greatly improves the generalization of SAM in defect detection.},
  archive      = {J_TNNLS},
  author       = {Feng Yan and Xiaoheng Jiang and Yang Lu and Jiale Cao and Mingliang Xu},
  doi          = {10.1109/TNNLS.2025.3585887},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18830-18843},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DefectSAM: Hierarchically adapting SAM for pixel-wise surface defect detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pixel-level noise mining for weakly supervised salient object detection. <em>TNNLS</em>, <em>36</em>(10), 18815-18829. (<a href='https://doi.org/10.1109/TNNLS.2025.3575255'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training a deep model for visual saliency detection requires the collection and labor-intensive annotation of overwhelmingly large data. We propose to learn saliency detection in a weakly supervised manner from single noisy label, which is easy to obtain from unsupervised handcrafted feature-based methods. However, deep networks tend to overfit such noises leading to a dramatic drop in accuracy. Given our goal, we address a natural question: can we identify outliers during network prediction and rectify the label noises? To this end, we propose a pixel-level noise mining framework for robust salient object detection (SOD) by exploiting its own knowledge, and without the need for external models. Specifically, during the early training stage, we progressively identify the outliers from a novel perspective during saliency detection, before the network overfits to the noisy labels, and generate a selection matrix in each iteration. Next, we adaptively rectify the label noises under the guidance of the selection matrix for better supervision in the later training stage. Extensive experiments on multiple benchmark datasets demonstrate the superiority of our method showing its ability to learn saliency detection comparable to state-of-the-art fully supervised methods. Furthermore, our approach outperforms existing weakly supervised methods utilizing single noisy label and surpasses the half of existing weakly supervised methods employing multiple noisy labels. Our approach, which trains with multiple noisy labels, outperforms all other methods employing multiple noisy labels across four major datasets. Furthermore, we also evaluate the generalization ability of our method on the multiclass semantic segmentation (SS) task. Our code is available at https://github.com/kendongdong/NoiseMining},
  archive      = {J_TNNLS},
  author       = {Kendong Liu and Mingtao Feng and Wei Zhao and Jingtao Sun and Weisheng Dong and Yaonan Wang and Ajmal Mian},
  doi          = {10.1109/TNNLS.2025.3575255},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18815-18829},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Pixel-level noise mining for weakly supervised salient object detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generating simple cyclic memristive neural network circuit with controllable multiscroll attractors and multivariable amplitude control. <em>TNNLS</em>, <em>36</em>(10), 18805-18814. (<a href='https://doi.org/10.1109/TNNLS.2025.3581229'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to their synaptic-like characteristics and memory properties, memristors are often used in neuromorphic circuits, particularly neural network circuits. However, most of the existing neural network circuits that can generate complex dynamics have high dimensions and excessive connections, which is not conducive to implementation. This article introduces a memristor containing an arctangent function into a simple cyclic neural network (SCNN) circuit to design a simple cyclic memristive neural network (SCMNN) circuit capable of generating complex multiscroll chaotic attractors. The designed SCMNN contains an external stimulus current and generates multiscroll attractors, with the number of scrolls expanding as the switches in the memristor equivalent circuit are activated. By varying the parameters, the multiscroll attractors can be broken into different numbers of coexisting attractors, which also depends on the switch, and it can achieve multivariable amplitude control when there is only one scroll. The anti-interference ability of the circuit is tested. A low-cost circuit-based microcontroller suitable for engineering applications is designed for it, and multiscroll attractors are successfully captured in an oscilloscope. The National Institute of Standards and Technology (NIST) test is carried out to verify its application value.},
  archive      = {J_TNNLS},
  author       = {Qiang Lai and Yudi Xu and Luigi Fortuna},
  doi          = {10.1109/TNNLS.2025.3581229},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18805-18814},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Generating simple cyclic memristive neural network circuit with controllable multiscroll attractors and multivariable amplitude control},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SFAN: Selective filter and alignment network for cross-modal retrieval. <em>TNNLS</em>, <em>36</em>(10), 18792-18804. (<a href='https://doi.org/10.1109/TNNLS.2025.3577292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bridging the gap between visual and textual modalities effectively has consistently been a key challenge in cross-modal retrieval. Fine-grained matching approaches improve performance by precisely aligning salient region features in visual modality with word embeddings in textual modality. However, how to effectively and efficiently filter out irrelevant features (e.g., irrelevant background regions and nonmeaningful prepositions) in multimodality remains a significant challenge. Furthermore, capturing key cross-modal relationships while minimizing misalignment interference is crucial for effective cross-modal retrieval. In this work, we propose a novel approach called the selective filter and alignment network (SFAN) to tackle these challenges. First, we propose modality-specific selective filter modules (SFMs) to selectively and implicitly filter out redundant information within each modality. We then propose the state-space models (SSMs)-based selective alignment module (SAM) to selectively capture key correspondences and reduce the disturbance of irrelevant associations. Finally, we utilize a fusion operation to combine these embeddings from both SFM and SAM to derive the final embeddings for similarity computation. Extensive experiments on the Flickr30k, MS-COCO, and MSR-VTT datasets reveal that our proposed SFAN can effectively learn robust patterns, significantly outperforming the state-of-the-art (SOTA) cross-modal retrieval methods by a wide margin.},
  archive      = {J_TNNLS},
  author       = {Yongle Huang and Zedong Liu and Shijie Sun and Ningning Cui and Jianxin Li},
  doi          = {10.1109/TNNLS.2025.3577292},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18792-18804},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SFAN: Selective filter and alignment network for cross-modal retrieval},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ADP-based orbit tracking control for deep space probe flying around unknown asteroid. <em>TNNLS</em>, <em>36</em>(10), 18780-18791. (<a href='https://doi.org/10.1109/TNNLS.2025.3578863'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the orbit tracking control problem for the deep space probe flying around an unknown asteroid under completely unknown dynamics. First, an orbit tracking control model for the relative motion of the probe to the asteroid is established. Then, a model-based controller is designed for the optimal tracking control problem and the asymptotic stability of the closed-loop system is proved. Next, an adaptive dynamic programming (ADP) algorithm based on policy iteration is adopted to obtain a model-free suboptimal controller that approximates the previous model-based controller, followed by the convergence analysis. Specifically, by collecting some data online, a system of high-order linear equations is constructed and then solved to obtain parameters utilized in controller construction. Finally, numerical simulations are provided to validate the effectiveness and the performance of the proposed control method.},
  archive      = {J_TNNLS},
  author       = {Zebin Chen and Yanwei Ding and Wenjian Tao and Jinxiu Zhang and Hui-Jie Sun},
  doi          = {10.1109/TNNLS.2025.3578863},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18780-18791},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {ADP-based orbit tracking control for deep space probe flying around unknown asteroid},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Utilizing TOP2 class for hybrid decision-making to enhance TOP1 accuracy of ensemble models. <em>TNNLS</em>, <em>36</em>(10), 18765-18779. (<a href='https://doi.org/10.1109/TNNLS.2025.3579732'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of deep learning for visual tasks, ensemble models combine several less accurate models to form a more precise composite model, improving overall performance. Traditionally, majority voting and average probabilities have been the main decision-making techniques in ensemble learning, focusing only on the TOP1 Class of base models, hence overlooking other significant information. This article introduces a new algorithm, TOP2 hybrid decision (TOP2 HD), which enhances the TOP1 accuracy of the ensemble model. TOP2 HD categorizes base models into hierarchies based on their TOP1 Class and uses the TOP2 Class for ranking, leading to better performance. Extensive experiments across various models and datasets demonstrate that TOP2 HD not only surpasses traditional ensemble methods, such as majority voting, average probabilities, and stacking, but also exceeds many of the latest ensemble strategies in the image domain. In addition, our experiments revealed a functional relationship between the test accuracy of the ensemble model and the number of base models. This enables us to predict the upper limit of the ensemble model’s performance using only a fraction of the models, providing a crucial reference for the performance after the deployment of the ensemble model.},
  archive      = {J_TNNLS},
  author       = {Jiqing Li and Zhendong Yin and Dasen Li and Yanlong Zhao},
  doi          = {10.1109/TNNLS.2025.3579732},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18765-18779},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Utilizing TOP2 class for hybrid decision-making to enhance TOP1 accuracy of ensemble models},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamics theory of RMSProp-based implicit regularization in deep low-rank matrix factorization. <em>TNNLS</em>, <em>36</em>(10), 18750-18764. (<a href='https://doi.org/10.1109/TNNLS.2025.3574683'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implicit regularization induced by gradient optimization is an important way to understand generalization in neural networks. Recent theory explains implicit regularization over the deep matrix factorization (DMF) model and analyzes the trajectory of discrete gradient dynamics in the optimization process. These discrete gradient dynamics can mathematically characterize the practical learning rate of adaptive gradient (AdaGrad) optimization, such as root-mean-square propagation (RMSProp). Discrete gradient dynamics analysis has been successfully applied to shallow networks but encounters difficulty in complex computation for deep networks. In this work, we introduce another discrete gradient dynamics, landscape analysis, to theoretically and experimentally explain the implicit regularization of RMSProp-based deep networks. It mainly focuses on gradient regions like saddle points and local minima. We investigate the benefits of increasing learning rates in saddle point escaping (SPE) stages. We prove that, for a rank-R matrix reconstruction, DMF will converge to a second-order critical point after R stages of SPE. Besides, we analyze the time it takes to escape from the plateau of the SPE stage. These conclusions are further experimentally verified on low-rank matrix, image reconstruction, and Hankel matrix reconstruction problems. Our proof is also applicable to gradient descent (GD) and adaptive moment estimation (Adam) but cannot apply to AdaGrad, further showing experimentally that the implicit regularization capability of RMSProp is stronger than GD and AdaGrad and weaker than Adam.},
  archive      = {J_TNNLS},
  author       = {Jian Cao and Chen Qian and Yihui Huang and Dicheng Chen and Yuncheng Gao and Jiyang Dong and Di Guo and Xiaobo Qu},
  doi          = {10.1109/TNNLS.2025.3574683},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18750-18764},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A dynamics theory of RMSProp-based implicit regularization in deep low-rank matrix factorization},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A trust-region projection neural network for nonlinear programming. <em>TNNLS</em>, <em>36</em>(10), 18737-18749. (<a href='https://doi.org/10.1109/TNNLS.2025.3576600'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The trust-region method and projection neural networks are two branches of optimization approaches with different operational principles and characteristics. In this article, a trust-region projection neural network (TRPNN) is proposed by integrating the trust-region method and projection neural networks. TRPNN is a discrete-time neurodynamic optimization model that inherits the exploration–exploitation capability of the trust-region method and the local search capability of projection neural networks. TRPNN is theoretically proven to be convergent to a Karush–Kuhn–Tuchker (KKT) point of nonlinear programming problems. The efficacy of TRPNNs leveraged in a collaborative neurodynamic framework is numerically demonstrated for global optimization in the presence of nonconvexity in objective functions or constraints.},
  archive      = {J_TNNLS},
  author       = {Haoen Huang and Zhigang Zeng and Jun Wang},
  doi          = {10.1109/TNNLS.2025.3576600},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18737-18749},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A trust-region projection neural network for nonlinear programming},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Object detection with physical prior and AWConv in foggy weather for traffic scenes. <em>TNNLS</em>, <em>36</em>(10), 18722-18736. (<a href='https://doi.org/10.1109/TNNLS.2025.3577791'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite significant advances in object detection methods for traffic scenes, object detection under adverse weather conditions is still a challenging task. Especially in foggy weather, the presence of fog reduces visibility, thus weakening the feature information of traffic objects in images, and foggy weather occurs frequently. To cope with this problem, we propose an object detection method with physical prior and adaptive weight convolution (AWConv), and evaluate it on datasets such as Foggy Cityscapes and RTTS. We apply gamma correction in the improved defogging algorithm to enhance the key regions in the image, thus improving the separability of the features. Meanwhile, the feature extraction and representation ability of the model is enhanced by an adaptive weighting mechanism, which in turn improves the model detection performance. In addition, we explore the relationship between image quality and detection accuracy and observe that they are not linearly positively correlated. Due to the complexity of traffic objects in foggy weather, we conduct experiments on Foggy Cityscapes (synthetic fog), RTTS (real-world multiple adverse weather), Cityscapes (normal weather), and extended dataset (different fog concentrations) to validate the model’s effectiveness, generalization ability, and robustness. Experimental results show that the small model alone improves mean average precision (mAP) by 1.4% with only 24.6 giga floating point operations per second (GFLOPs) on the Foggy Cityscapes dataset, reduces GFLOPs by 3.8 and improves recall (R) by 1.1% on the RTTS dataset.},
  archive      = {J_TNNLS},
  author       = {Xue-Juan Han and Zhong Qu and Shi-Yan Wang and Shu-Fang Xia},
  doi          = {10.1109/TNNLS.2025.3577791},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18722-18736},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Object detection with physical prior and AWConv in foggy weather for traffic scenes},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prescribed-time human-in-the-loop optimal synchronization control for multiagent systems under DoS attacks via reinforcement learning. <em>TNNLS</em>, <em>36</em>(10), 18711-18721. (<a href='https://doi.org/10.1109/TNNLS.2025.3583248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prescribed-time (PT) human-in-the-loop (HiTL) optimal synchronization control problem for multiagent systems (MASs) under link-based denial-of-service (DoS) attacks is investigated. First, the HiTL framework enables the human operator to govern the MASs by transmitting commands to the leader. The link-based DoS attacks cause communication blockages between agents, resulting in topology switching. Under the switching communication topology, a fully distributed observer is proposed for each follower, which simultaneously integrates a prescribed finite-time function to estimate the leader’s output within the PT. This observer is characterized by a bounded gain at the PT point and guarantees global practical PT convergence, while avoiding the use of global topology information. By combining the follower dynamics with the proposed observer, an augmented system is developed. Subsequently, the model-free Q-learning algorithm is used to learn the optimal synchronization policy directly from real system data. To reduce computational burden, the Q-learning algorithm is implemented using a single critic neural network (NN) structure, with the least-squares method applied to train the NN weights. The convergence of the Q-functions generated by the proposed Q-learning algorithm is proven. Finally, simulation results verify the effectiveness of the proposed control scheme.},
  archive      = {J_TNNLS},
  author       = {Zongsheng Huang and Tieshan Li and Yue Long and Hongjing Liang},
  doi          = {10.1109/TNNLS.2025.3583248},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18711-18721},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Prescribed-time human-in-the-loop optimal synchronization control for multiagent systems under DoS attacks via reinforcement learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An advanced optimal tracking control for nonlinear discrete-time systems based on (N + 1)-step gradient learning. <em>TNNLS</em>, <em>36</em>(10), 18696-18710. (<a href='https://doi.org/10.1109/TNNLS.2025.3588259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, to address the issue of accelerating convergence performance and eliminating the tracking error, an advanced optimal control method for nonlinear discrete-time systems is investigated based on an improved N-step [( ${N} +1$ )-step] gradient learning algorithm. Independent of the discount factor, this article introduces a novel tracking error index without quadratic input terms for the steady-state and convergence performances, which obtains the optimal control policy without calculating the reference control input. Compared with classic N-step gradient learning algorithms with infinite future reward assumption, the proposed algorithm investigates the (N +1)-step return with a fixed N and a step forward for finite tracking problems based on a long-term weighting parameter. Based on the above theory, value iteration (VI) and policy iteration (PI) methods are utilized to derive the convergence, monotonicity, optimality, and stability properties of the proposed algorithm, which can be conducted without the traditional assumption of zero initial functions. In the implementation of the algorithms, the actor–critic structure, constructed by four neural networks, is established to approximate the states, the value functions, and the control policy, respectively. Three simulation experiments on a helicopter system validate the efficacy and practicality of the control methods in addressing nonlinear optimal tracking challenges.},
  archive      = {J_TNNLS},
  author       = {Zeyu Zhou and Yuhui Wang and Qingxian Wu},
  doi          = {10.1109/TNNLS.2025.3588259},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18696-18710},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {An advanced optimal tracking control for nonlinear discrete-time systems based on (N + 1)-step gradient learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HCG: Streaming DCNN accelerator with a hybrid computational granularity scheme on FPGA. <em>TNNLS</em>, <em>36</em>(10), 18681-18695. (<a href='https://doi.org/10.1109/TNNLS.2025.3587694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growth of field-programmable gate array (FPGA) hardware resources, streaming DCNN accelerators leverage interconvolutional-layer parallelism to enhance throughput. In existing streaming accelerators, convolution nodes typically adopt layer- or column-based tiling methods, where the tiled input feature map (Ifmap) encompasses all input channels. This approach facilitates the comprehensive calculation of the output feature map (Ofmap) and maximizes interlayer parallelism. The computational granularity, defined in this study as the calculated rows or columns of Ofmap based on each tiled Ifmap data, significantly influences on-chip Ifmap storage and off-chip weight bandwidth (BW). The uniform application of computational granularity across all nodes inevitably impacts the memory-BW tradeoff. This article introduces a novel streaming accelerator with a hybrid computational granularity (HCG) scheme. Each node employs an independently optimized computational granularity, enabling a more flexible memory-BW tradeoff and more effective utilization of FPGA resources. However, this hybrid scheme can introduce pipeline bubbles and increase system pipeline complexity and control logic. To address these challenges, this article theoretically analyzes the impact of computational granularity on individual computing nodes and the overall system, aiming to establish a seamless system pipeline without pipeline bubbles and simplify system design. Furthermore, the article develops a hardware overhead model and employs a heuristic algorithm to optimize computational granularity for each computing node, achieving optimal memory-BW tradeoff and higher throughput. Finally, the effectiveness of the proposed design and optimization methodology is validated through the implementation of a 3-TOPS ResNet-18 accelerator on the Alveo U250 development board under BW constraints of 25, 20, and 15 GB/s. Additionally, accelerators for 4-TOPS VGG-16, 4-TOPS ResNet-34, 5-TOPS ResNet-50, 3-TOPS MobileNetV1, 4-TOPS ConvNeXt-T, and 4-TOPS ResNeXt-50 are implemented, surpassing the performance of most existing works.},
  archive      = {J_TNNLS},
  author       = {Wenjin Huang and Conghui Luo and Baoze Zhao and Han Jiao and Yihua Huang},
  doi          = {10.1109/TNNLS.2025.3587694},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18681-18695},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {HCG: Streaming DCNN accelerator with a hybrid computational granularity scheme on FPGA},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IncTSVD: Incremental tensor singular value decomposition of multidimensional streaming data. <em>TNNLS</em>, <em>36</em>(10), 18666-18680. (<a href='https://doi.org/10.1109/TNNLS.2025.3578117'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we develop an online method called IncTSVD to incrementally compute the tensor singular value decomposition (TSVD) of a given sequence of third-order tensors based on the tensor-tensor concept. This can be considered an extension of incremental SVD based on updating matrices to tensors. IncTSVD is suitable for streamed tensor data and where memory resources are limited. Most existing methods to compute TSVD focus on approximating it using randomized or sketching techniques in a batch setting to decrease the storage and computational costs required. The IncTSVD extends the computation of TSVD to streaming by maintaining the basis tensors of previously arrived data and incrementally updating the approximation using the tensor of incoming data. The computational cost and approximation error of the proposed method were analyzed theoretically and through extensive numerical experiments, which included using synthetic and real-world datasets under streaming scenarios. The IncTSVD method was superior to existing deterministic and randomized tensor decompositions (TDs) based on the t-product for computational and storage costs, and had comparable accuracy to the standard TSVD method.},
  archive      = {J_TNNLS},
  author       = {Muhammad A. A. Abdelgawad and Ray C. C. Cheung and Hong Yan},
  doi          = {10.1109/TNNLS.2025.3578117},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18666-18680},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {IncTSVD: Incremental tensor singular value decomposition of multidimensional streaming data},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online self-triggered transmission control with critic learning for discrete nonlinear systems. <em>TNNLS</em>, <em>36</em>(10), 18653-18665. (<a href='https://doi.org/10.1109/TNNLS.2025.3574484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a novel online self-triggered transmission control (STTC) framework is constructed based on the critic learning technique, which aims at tackling the optimal regulation issue of discrete-time nonlinear systems. On the premise of ensuring the system stability, a self-sampling function is designed only related to the sampling state, so that the next triggering moment can be determined. This not only effectively reduces the computational burden, but also avoids continuous judgment for the triggering condition similar to traditional event-based methods. Furthermore, the developed control method can be found to possess excellent triggering performance through theoretical analysis. Then, the model, critic, and action networks are established to execute the online critic learning algorithm, which make the control policy is adjusted in real-time to the optimal level. Finally, an experimental plant with nonlinear characteristics is given to illustrate the overall performance of the proposed online STTC method.},
  archive      = {J_TNNLS},
  author       = {Lingzhi Hu and Ding Wang and Jin Ren and Junfei Qiao},
  doi          = {10.1109/TNNLS.2025.3574484},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18653-18665},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Online self-triggered transmission control with critic learning for discrete nonlinear systems},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoupling neural networks to leverage uniform representation and balance personalization and collaboration in federated learning. <em>TNNLS</em>, <em>36</em>(10), 18642-18652. (<a href='https://doi.org/10.1109/TNNLS.2025.3586600'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL), a distributed learning paradigm focused on preserving data privacy, faces challenges due to varying data distributions among clients, impacting global model performance. To mitigate data heterogeneity, we propose FedUB—a personalized FL framework leveraging uniform feature representation and balancing personalization and collaboration in the classifier. Specifically, the uniform representation (UR) in FedUB provides all clients with a shared feature extractor and a common representation centroid (RC). Achieving this uniformity involves incorporating a regularization term to reduce the gap between global and local RCs. Additionally, an importance estimation of the parameters in the classifier is provided to partition the parameters into two parts: the personalized component and the collaborated component. Specifically, the personalized component adapts to local data, while the collaborated component prevents the classifier from overfitting local data. Theoretically, we establish the existence of the UR, demonstrating its effectiveness in reducing the average generalization bound. Experiments on benchmark datasets consistently demonstrate the performance gains and improved generalization behavior of FedUB.},
  archive      = {J_TNNLS},
  author       = {Zhangmin Huang and Pengcheng Wang and Shaojie Tang and Bo Lyu and Lingfang Zeng},
  doi          = {10.1109/TNNLS.2025.3586600},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18642-18652},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Decoupling neural networks to leverage uniform representation and balance personalization and collaboration in federated learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward disentangled and controllable deep metric learning with human-like concept decomposition. <em>TNNLS</em>, <em>36</em>(10), 18628-18641. (<a href='https://doi.org/10.1109/TNNLS.2025.3587907'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep metric learning (DML) has shown significant advancements in learning discriminative embeddings for images, playing a crucial role in various vision tasks. However, existing methods typically rely on deep neural networks to extract holistic embeddings, which are challenging to disentangle and interpret. To address this issue, we take inspiration from human cognition, where objects are decomposed into distinct concepts for better understanding. Specifically, we propose the concept metrics network (CMNs) to achieve disentangled and controllable DML. CMN begins by initializing learnable concept vectors to represent various visual concepts. These vectors are then associated with regional visual features via cross-attention mechanism, ensuring each vector corresponds to specific visual properties. Finally, the concept values, determined by their presence in the image, form the output embedding. Comprehensive experiments demonstrate that CMN effectively disentangles visual concepts, with each embedding dimension corresponding to a specific concept. Our method not only outperforms existing state-of-the-art methods in conventional DML application (i.e., image retrieval), but also enables more flexible and controllable application. The code is available at https://github.com/shchen0001/CMN},
  archive      = {J_TNNLS},
  author       = {Shuhuang Chen and Shiming Chen and Shuo Ye and Yuetian Wang and Xinge You},
  doi          = {10.1109/TNNLS.2025.3587907},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18628-18641},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Toward disentangled and controllable deep metric learning with human-like concept decomposition},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The diversity bonus: Learning from dissimilar clients in personalized federated learning. <em>TNNLS</em>, <em>36</em>(10), 18613-18627. (<a href='https://doi.org/10.1109/TNNLS.2025.3585927'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized federated learning (PFL) allows clients to collaboratively train their personalized models to handle situations where data from different clients are not independent and identically distributed (non-IID). Previous PFL research implicitly assumes that clients benefit most from those with similar data distributions. Correspondingly, methods such as personalized weight aggregation assign higher weights to similar clients during aggregation. We pose a question: can a client benefit from other clients with dissimilar data distributions, and if so, how? This question is particularly relevant in scenarios with a high degree of non-IID, where clients have widely different distributions, and learning from only similar clients will result in a loss of knowledge from many other clients. We note that when dealing with clients with similar distributions, current methods tend to enforce their models to be close in the parameter space. It is reasonable to conjecture that a client can benefit from dissimilar clients if we allow their models to depart from each other. Based on this idea, we propose DiversiFed, which allows each client to learn from clients with diversified distribution. DiversiFed pushes personalized models of clients with dissimilar distributions apart in the parameter space while pulling together those with similar distributions. In addition, to achieve the above effect without using prior knowledge of distribution, we design a loss function that leverages model similarity to determine the degree of attraction and repulsion between any two models. Experiments on benchmark and medical datasets show that DiversiFed can outperform the state-of-the-art (SOTA) methods by up to 3.19%.},
  archive      = {J_TNNLS},
  author       = {Xinghao Wu and Jianwei Niu and Xuefeng Liu and Guogang Zhu and Shaojie Tang and Wanyu Lin and Jiannong Cao},
  doi          = {10.1109/TNNLS.2025.3585927},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18613-18627},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {The diversity bonus: Learning from dissimilar clients in personalized federated learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertain interruptibility multiobjective flexible job shop via deep reinforcement learning based on heterogeneous graph self-attention. <em>TNNLS</em>, <em>36</em>(10), 18598-18612. (<a href='https://doi.org/10.1109/TNNLS.2025.3578368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although an increasing number of studies have focused on the flexible job shop problem, there has been insufficient consideration of realistic constraints, such as the working hours of employees and the noninterruptible nature of certain operations. To address this issue, here an improved deep reinforcement learning (DRL) approach is presented that utilizes end-to-end multidecision-intelligent body proximal policy optimization (m-PPO). In the proposed framework, a heterogeneous graph self-attention neural network (HGAN) model is embedded, which efficiently extracts valuable features from the original state in heterogeneous graphs to capture intricate relationships. Within this framework, agents are divided into five rule-driven job decision agents and data-driven operation-machine ( $\mathcal {O}\text {-}\mathcal {M}$ ) pair decision agents, which incorporate problem-specific knowledge. To optimize the makespan, total costs, and total lateness concurrently, the weight parameters for the objectives are generated by the network and self-updated based on the current state. Numerical experiments demonstrate the effectiveness of the proposed method.},
  archive      = {J_TNNLS},
  author       = {Zunxun Wang and Junqing Li and Xiaolong Chen and Peiyong Duan and Jiake Li},
  doi          = {10.1109/TNNLS.2025.3578368},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18598-18612},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Uncertain interruptibility multiobjective flexible job shop via deep reinforcement learning based on heterogeneous graph self-attention},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiffCL: A diffusion-based contrastive learning framework with semantic alignment for multimodal recommendations. <em>TNNLS</em>, <em>36</em>(10), 18587-18597. (<a href='https://doi.org/10.1109/TNNLS.2025.3583509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal recommendation systems integrate diverse multimodal information into the feature representations of both items and users, thereby enabling a more comprehensive modeling of user preferences. However, existing methods are hindered by data sparsity and the inherent noise within multimodal data, which impedes the accurate capture of users’ interest preferences. Additionally, discrepancies in the semantic representations of items across different modalities can adversely impact the prediction accuracy of recommendation models. To address these challenges, we introduce a novel diffusion-based contrastive learning (DiffCL) framework for multimodal recommendation. DiffCL employs a diffusion model (DM) to generate contrastive views that effectively mitigate the impact of noise during the contrastive learning phase. Furthermore, it improves semantic consistency across modalities by aligning distinct visual and textual semantic information through stable ID embeddings. Finally, the introduction of the item-item graph (I-I graph) enhances multimodal feature representations, thereby alleviating the adverse effects of data sparsity on the overall system performance. We conduct extensive experiments on three public datasets, and the results demonstrate the superiority and effectiveness of the DiffCL.},
  archive      = {J_TNNLS},
  author       = {Qiya Song and Jiajun Hu and Lin Xiao and Bin Sun and Xieping Gao and Shutao Li},
  doi          = {10.1109/TNNLS.2025.3583509},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18587-18597},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DiffCL: A diffusion-based contrastive learning framework with semantic alignment for multimodal recommendations},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSFuse: A dual-diffusion structure for feature fidelity infrared and visible image fusion. <em>TNNLS</em>, <em>36</em>(10), 18572-18586. (<a href='https://doi.org/10.1109/TNNLS.2025.3584834'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image fusion aims to combine the complementary features of different modalities to produce an informative fused image. Due to the different imaging mechanisms, information conflicts may arise from infrared and visible source images. Existing infrared and visible fusion methods are devoted to preserving the features of source images as much as possible. However, handling conflicting information is often overlooked. Thus, we leverage the powerful generative priors of diffusion and propose a dual-diffusion structure, termed DSFuse, to handle conflicting information and achieve feature fidelity during image fusion processing. Diffusion modules are introduced to guide the fusion network to understand the meaningful information of the source image easily. First, the fusion network is used to retain features in the fused image as much as possible. Then, diffusion modules are used to reconstruct source images from noise based on the output of the fusion network. Finally, feedback from the diffusion modules forces the fusion network to aggregate modality information to ensure fidelity; the high quality of the fusion result is also profitable for a better reconstruction of diffusion modules, forming a positive feedback loop. In addition, we release a new dataset for infrared/visible fusion to support the fusion network training and evaluation, named the multiscene infrared and visible (MSIV) images dataset. Extensive experiments demonstrate that DSFuse outperforms other state-of-the-art (SOTA) fusion methods.},
  archive      = {J_TNNLS},
  author       = {Zhijia Yang and Kun Gao and Yanzheng Zhang and Xiaodian Zhang and Zibo Hu and Junwei Wang and Jingyi Wang and Wei Li},
  doi          = {10.1109/TNNLS.2025.3584834},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18572-18586},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DSFuse: A dual-diffusion structure for feature fidelity infrared and visible image fusion},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PADiff: Reconstruction from patch to pixel with normality-guided diffusion model for unsupervised anomaly localization. <em>TNNLS</em>, <em>36</em>(10), 18558-18571. (<a href='https://doi.org/10.1109/TNNLS.2025.3572438'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly localization (AL) is an indispensable and challenging task in manufacturing. Recently, diffusion models have been widely used to localize anomalies through discrepancies between original and reconstructed representations, which is based on the hypothesis that diffusion models regard anomalies as noise and reconstruct them to normal representations. However, anomalies usually deviate from prior standard Gaussian distribution and diffusion models cannot reconstruct anomaly parts as normal patterns well due to powerful generalization. These issues hinder the application of diffusion models in AL and lead to suboptimal performance. As a remedy, we present a novel framework for AL based on the diffusion model, dubbed PADiff. To enable the diffusion model to reconstruct abnormal regions to normal regions in an anomaly image, we propose to guide the diffusion model in the reconstruction process using its normal counterpart. High-quality guided normal counterpart plays a key role in our method. Therefore, we propose a patch-substitution strategy to obtain a high-quality-guided normal counterpart. Specifically, we first construct a normal patch memory bank using normal training samples. With a normal memory bank, we find potential anomaly patches in testing images and substitute them with most similar normal patches in the memory bank. After substitution, pseudo-normal images are generated to guide the diffusion model. To make our method more data-efficient, we divide an image into patches and propose patch-wise training and reconstruction. As one of our innovations, we propose to encode each patch into positional embedding and add it on time embedding, which introduces patch-level representation and position information in the diffusion model. Extensive experiments are conducted on three commonly used anomaly detection datasets (MVTec-AD, VisA, and BTAD) to showcase the state-of-the-art (SOTA) performance of the proposed PADiff. The source code is publicly available at https://github.com/Jay-zzcoder/padiff},
  archive      = {J_TNNLS},
  author       = {Zuo Zuo and Jiahao Dong and Yao Wu and Yanyun Qu and Zongze Wu},
  doi          = {10.1109/TNNLS.2025.3572438},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18558-18571},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {PADiff: Reconstruction from patch to pixel with normality-guided diffusion model for unsupervised anomaly localization},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MOOD: Leveraging out-of-distribution data to enhance imbalanced semi-supervised learning. <em>TNNLS</em>, <em>36</em>(10), 18545-18557. (<a href='https://doi.org/10.1109/TNNLS.2025.3573963'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The imbalanced semi-supervised learning (SSL) has emerged as a critical research area due to the prevalence of class imbalanced and partially labeled data in real-world scenarios. As the requirement for data volume increases, naturally collected datasets inevitably contain out-of-distribution (OOD) samples. However, the performance of existing imbalanced SSL methods experiences a marked deterioration with OOD data. In this article, we propose an imbalanced SSL method called mixup-OOD (MOOD) to address this issue. The core idea is to “turn waste into treasure,” exploring the potential of leveraging seemingly detrimental OOD data to expand the feature space, particularly for tail classes. Specifically, we first filter OOD data from unlabeled data, and then fuse it with labeled data to boost feature diversity for the tail classes. To avoid feature overlapping with OOD data, we develop a push-and-pull (PaP) loss to attract in-distribution (ID) instances toward respective class centroids while repelling OOD samples from them. Extensive experiments show that MOOD achieves superior performance compared with other state-of-the-art methods and exhibits robustness across data with different imbalanced ratios and OOD proportions. The source code is available at: https://github.com/xlhuang132/MOODv2},
  archive      = {J_TNNLS},
  author       = {Yang Lu and Xiaolin Huang and Yizhou Chen and Mengke Li and Yan Yan and Chen Gong and Hanzi Wang},
  doi          = {10.1109/TNNLS.2025.3573963},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18545-18557},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {MOOD: Leveraging out-of-distribution data to enhance imbalanced semi-supervised learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deformation-resilient multigranularity learning for unaligned RGB–T semantic segmentation. <em>TNNLS</em>, <em>36</em>(10), 18530-18544. (<a href='https://doi.org/10.1109/TNNLS.2025.3585105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB–Thermal semantic segmentation (SS) aims to combine visual light and thermal images to determine the semantic category for each pixel and create an object mask. While existing methods typically rely on well-aligned RGB–T image pairs, real-world RGB–T pairs are often unaligned, and pixel-by-pixel alignment is both challenging and time-consuming. To address this critical issue, we introduce a new unaligned RGB–T SS benchmark and propose the deformation-resilient multigranularity learning (DML) method. DML explores the spatial consistency and modal complementarity of RGB–T and mitigates the interference of warped modalities by aligning multimodal features in a coarse-to-fine multigranularity strategy. Specifically, DML constructs a deformation-aware complementary feature enhancer (DCFE), which consists of deformation-aware feature alignment (DFA) and complementary feature aggregation (CFA) modules. DFA enhances the spatial alignment of RGB–T by estimating the deformation field of warped features. Then, CFA aggregates complementary contexts of modal differences across multiple scales to produce deformation-resilient and robust RGB–T feature representations. Finally, we design the multigranularity mask refinement engine (MMFE), which combines class-agnostic saliency prediction (CSP) and class-aware edge generation (CEG) auxiliary tasks to provide useful boundary and positional cues for SS decoders. The MMFE enhances semantic alignment and interclass separability, yielding object masks with sharp boundaries. Quantitative and qualitative experiments on aligned and unaligned datasets validate the effectiveness of our proposed DML, consistently outperforming existing methods designed for aligned RGB–T data. The new unaligned RGB–T SS benchmark and code are available at https://github.com/VisionVerse/Unaligned-RGBT-Semantic-Segmentation},
  archive      = {J_TNNLS},
  author       = {Heng Zhou and Zhenxi Zhang and Chengyang Li and Chunna Tian and Yongqiang Xie and Zhongbo Li and Xiao-Jun Wu},
  doi          = {10.1109/TNNLS.2025.3585105},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18530-18544},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Deformation-resilient multigranularity learning for unaligned RGB–T semantic segmentation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AQE-RF: An adaptive quantifier extension and rule-filtering graph network for logical reasoning of text. <em>TNNLS</em>, <em>36</em>(10), 18517-18529. (<a href='https://doi.org/10.1109/TNNLS.2025.3588525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logical reasoning of text requires neural models to possess strong contextual comprehension and logical reasoning ability to draw conclusions from limited information. To improve the logical reasoning capabilities of pretrained language models (PLMs), existing approaches can be broadly categorized into neural architecture-based methods and large language model (LLM)-driven strategies. While neural methods struggle with fine-grained logic that fails to capture detailed semantic roles and constraints, LLM-driven approaches, despite generating multistep reasoning sequences, lack explicit inference control and suffer from error accumulation due to their implicit and stochastic nature. Some works have tried using logical expressions, like first-order logic, but these approaches often fail to handle quantifiers systematically or support clear reasoning processes. Inspired by first-order logic and generalized quantifier (GQ) theory, we propose AQE-RF, a model based on an adaptive quantifier extension and rule-filtering graph network to address this challenge. The first component constructs a fine-grained text logical graph (FTLG) and then performs GQ instantiation based on option attention. The second component performs rule-filtered deductive reasoning, using conflict scores and dynamic programming (DP) to select coherent, interpretable inference paths. Extensive experiments on the LogiQA, ReClor, and AR-LSAT datasets demonstrate the effectiveness and robustness of AQE-RF.},
  archive      = {J_TNNLS},
  author       = {Meng Wang and Jinshuo Liu and Víctor Gutiérrez-Basulto and Lina Wang and Jeff Z. Pan},
  doi          = {10.1109/TNNLS.2025.3588525},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18517-18529},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {AQE-RF: An adaptive quantifier extension and rule-filtering graph network for logical reasoning of text},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Off-OAB: Off-policy policy gradient method with optimal action-dependent baseline. <em>TNNLS</em>, <em>36</em>(10), 18505-18516. (<a href='https://doi.org/10.1109/TNNLS.2025.3588881'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The policy-based methods have achieved remarkable success in solving challenging reinforcement learning (RL) problems. Among these methods, the off-policy policy gradient (OPPG) methods are particularly important because they can benefit from off-policy data. However, these methods suffer from the high variance of the OPPG estimator, which results in poor sample efficiency during training. In this article, we propose an off-policy policy gradient method with the optimal action-dependent baseline (Off-OAB) to mitigate this variance issue. Specifically, this baseline maintains the OPPG estimator’s unbiasedness while theoretically minimizing its variance. To enhance practical computational efficiency, we design an approximated version of this optimal baseline. Utilizing this approximation, our method (Off-OAB) aims to decrease the OPPG estimator’s variance during policy optimization. We evaluate the proposed Off-OAB method on six representative tasks from OpenAI Gym and MuJoCo, where it demonstrably surpasses the state-of-the-art methods on the majority of these tasks.},
  archive      = {J_TNNLS},
  author       = {Wenjia Meng and Qian Zheng and Long Yang and Yilong Yin and Gang Pan},
  doi          = {10.1109/TNNLS.2025.3588881},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18505-18516},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Off-OAB: Off-policy policy gradient method with optimal action-dependent baseline},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EMWQ: An efficient mixed precision weight quantization method for large language models. <em>TNNLS</em>, <em>36</em>(10), 18492-18504. (<a href='https://doi.org/10.1109/TNNLS.2025.3585677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have gained a lot of attention and achievements recently because of their significant comprehension and generative abilities. However, the large-scale parameters of LLMs require considerable computational resources in the training and inference process, which restricts their wide application. To overcome this challenge, we propose an efficient mixed precision weight quantization (EMWQ) method for LLMs in this article. Specifically, we introduce a new outlier detection method by analyzing the weight distribution instead of the conventional weight magnitude. Then, we propose a dual-quantization strategy that quantizes both the outlier critical columns and the residual matrices with different precision. Besides, we introduce two effective EMWQ-based application frameworks, the EMWQ-R and EMWQ-O in our study. Comprehensive experiments are conducted on the Penn Treebank (PTB), C4, ARC-Easy datasets, and MMLU benchmark across various tasks. The comparison results demonstrate that the proposed EMWQ achieves state-of-the-art performance in mixed precision quantization and further reduces computational memory cost. Besides, it has higher generalizability compared with conventional methods.},
  archive      = {J_TNNLS},
  author       = {Yuning Yang and Xiurui Xie and Guowei Peng and Malu Zhang and Guangchun Luo and Yang Yang and Guisong Liu},
  doi          = {10.1109/TNNLS.2025.3585677},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18492-18504},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {EMWQ: An efficient mixed precision weight quantization method for large language models},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A-SDM: Accelerating stable diffusion through model assembly and feature inheritance strategies. <em>TNNLS</em>, <em>36</em>(10), 18478-18491. (<a href='https://doi.org/10.1109/TNNLS.2025.3587724'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stable diffusion model (SDM) is a prevalent and effective model for text-to-image (T2I) and image-to-image (I2I) generation. Despite various attempts at sampler optimization, model distillation, and network quantification, these approaches typically maintain the original network architecture. The extensive parameter scale and substantial computational demands have limited research into adjusting the model architecture. This study focuses on reducing redundant computation in SDM and optimizes the model through both tuning and tuning-free methods: 1) for the tuning method, we design a model assembly strategy to reconstruct a lightweight model while preserving performance and ensuring semantic stability through distillation and 2) for the tuning-free method, we propose a feature inheritance strategy to accelerate inference by skipping local computations at the block, layer, or unit level within the network structure. We also examine multiple sampling modes for feature inheritance at the time-step level. Experiments demonstrate that both the proposed tuning and the tuning-free methods can improve the speed and performance of the SDM. The lightweight model reconstructed by the model assembly strategy increases generation speed by 22.4%, while the feature inheritance strategy enhances the SDM generation speed by 40.0%.},
  archive      = {J_TNNLS},
  author       = {Jinchao Zhu and Yuxuan Wang and Siyuan Pan and Pengfei Wan and Di Zhang and Gao Huang},
  doi          = {10.1109/TNNLS.2025.3587724},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18478-18491},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A-SDM: Accelerating stable diffusion through model assembly and feature inheritance strategies},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty-aware graph neural networks: A multihop evidence fusion approach. <em>TNNLS</em>, <em>36</em>(10), 18463-18477. (<a href='https://doi.org/10.1109/TNNLS.2025.3581083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) excel in graph representation learning by integrating graph structure and node features. Existing GNNs, unfortunately, fail to account for the uncertainty of class probabilities that vary with the depth of the model, leading to unreliable and risky predictions in real-world scenarios. To bridge the gap, in this article, we propose a novel evidence-fusing graph neural network (EFGNN) to achieve trustworthy prediction, enhance node classification accuracy, and make explicit the risk of wrong predictions. In particular, we integrate the evidence theory with multihop propagation-based GNN architecture to quantify the prediction uncertainty of each node with the consideration of multiple receptive fields. Moreover, a parameter-free cumulative belief fusion (CBF) mechanism is developed to leverage the changes in prediction uncertainty and fuse the evidence to improve the trustworthiness of the final prediction. To effectively optimize the EFGNN model, we carefully design a joint learning objective composed of evidence cross-entropy, dissonance coefficient, and false confident penalty. The experimental results on various datasets and theoretical analyses demonstrate the effectiveness of the proposed model in terms of accuracy and trustworthiness, as well as its robustness to potential attacks.},
  archive      = {J_TNNLS},
  author       = {Qingfeng Chen and Shiyuan Li and Yixin Liu and Shirui Pan and Geoffrey I. Webb and Shichao Zhang},
  doi          = {10.1109/TNNLS.2025.3581083},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18463-18477},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Uncertainty-aware graph neural networks: A multihop evidence fusion approach},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GBPG-net: Global background prior-guided rain and snow image restoration. <em>TNNLS</em>, <em>36</em>(10), 18448-18462. (<a href='https://doi.org/10.1109/TNNLS.2025.3579050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of image restoration in the presence of rain and snow effects is to eliminate these disturbances while retaining the underlying background structure. Most existing methods tend to directly learn the mapping from corrupted images to clean ones, often resulting in residual rain or snow artifacts and compromised background structures. In this work, both theoretical analysis and experimental findings confirm the robustness of the hue channel in HSV color space to rain and snow disturbances, even when extracted from corrupted images. Motivated by this insight, we propose to leverage the global clean background cues inherent in the hue channel to guide the network in preserving the image background structure and removing interference. To this end, we introduce the global background prior-guided network (GBPG-Net) for restoring rain and snow-affected images, which employs a triangular formation to facilitate continuous interaction and updating of the global background prior (GBP) with the image feature within the GBPG-unit, resulting in improved interference removal and background structure preservation. Specifically, the GBPG-Net incorporates the global clean background prior injector (GCBPI) to inject the GBP into the network. Subsequently, the prior-guided local detail excavation (PGLDE) module, built on GCBPI, further refines interference removal and structure preservation to process local details intricately. Finally, the prior-guided local-global aggregation (PGLGA) module aggregates global background features with local detailed features, enabling the network to better understand the overall content and subtle interference for more accurate reconstruction. Quantitative and qualitative evaluations on synthetic and real datasets demonstrate the effectiveness of the proposed GBPG-Net in deraining and desnowing tasks, highlighting its advantages over existing methods. The code and supplementary documentation are available at https://github.com/liux520/GBPG-Net},
  archive      = {J_TNNLS},
  author       = {Xiao Liu and Xiaofeng Wang and Shouyi Wang and Haosong Gou and Zhengyong Wang and Chao Ren},
  doi          = {10.1109/TNNLS.2025.3579050},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18448-18462},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {GBPG-net: Global background prior-guided rain and snow image restoration},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Layer-wise training of graph neural networks with self-supervised learning. <em>TNNLS</em>, <em>36</em>(10), 18437-18447. (<a href='https://doi.org/10.1109/TNNLS.2025.3577702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training graph neural networks (GNNs) on large graphs is challenging due to both the high memory and computational costs of end-to-end training and the scarcity of detailed node-level annotations. To address these challenges, we propose layer-wise regularized graph infomax (LRGI), a self-supervised learning algorithm inspired by predictive coding, a biologically motivated principle in which each layer is trained locally to predict its future inputs. LRGI trains GNNs layer by layer, decoupling their memory and time complexity from the network depth, thereby enabling scalable training on large graphs. In LRGI, each layer learns to predict the features propagated from its neighbors, allowing independent training of each layer. This approach, combined with regularization that promotes diverse representations, also helps mitigate oversmoothing in deep GNNs. Experiments on large inductive graph benchmarks demonstrate that LRGI achieves competitive performance compared to state-of-the-art end-to-end methods, while substantially improving efficiency.},
  archive      = {J_TNNLS},
  author       = {Oscar Pina and Verónica Vilaplana},
  doi          = {10.1109/TNNLS.2025.3577702},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18437-18447},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Layer-wise training of graph neural networks with self-supervised learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HierSpeech++: Bridging the gap between semantic and acoustic representation of speech by hierarchical variational inference for zero-shot speech synthesis. <em>TNNLS</em>, <em>36</em>(10), 18422-18436. (<a href='https://doi.org/10.1109/TNNLS.2025.3584944'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language model (LLM)-based speech synthesis has been widely adopted in zero-shot speech synthesis. However, they require a large-scale data and possess the same limitations as previous autoregressive speech models, including slow inference speed and lack of robustness. This article proposes HierSpeech++, a fast and strong zero-shot speech synthesizer for text-to-speech (TTS) and voice conversion (VC). We verified that hierarchical speech synthesis frameworks could significantly improve the robustness and expressiveness of the synthetic speech. Furthermore, we significantly improve the naturalness and speaker similarity of synthetic speech even in zero-shot speech synthesis scenarios. For TTS, we adopt the text-to-vec (TTV) framework, which generates a self-supervised speech representation and an F0 representation based on text representations and prosody prompts. Then, HierSpeech++ generates speech from the generated vector, F0, and voice prompt. We further introduce a high-efficient speech super-resolution (SpeechSR) framework from 16 to 48 kHz. The experimental results demonstrated that the hierarchical variational autoencoder could be a strong zero-shot speech synthesizer given that it outperforms LLM-based and diffusion-based models. Moreover, we achieved the first human-level quality zero-shot speech synthesis. Audio samples and source code are available at https://github.com/hierspeechpp/code},
  archive      = {J_TNNLS},
  author       = {Sang-Hoon Lee and Ha-Yeong Choi and Seung-Bin Kim and Seong-Whan Lee},
  doi          = {10.1109/TNNLS.2025.3584944},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18422-18436},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {HierSpeech++: Bridging the gap between semantic and acoustic representation of speech by hierarchical variational inference for zero-shot speech synthesis},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward open-world domain adaptation via iteratively contrastive learning and clustering. <em>TNNLS</em>, <em>36</em>(10), 18408-18421. (<a href='https://doi.org/10.1109/TNNLS.2025.3584072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The open-set domain adaptation (DA) aims to address both covariate shift and category shift between a labeled source domain and an unlabeled target domain. Nevertheless, existing open-set DA methods always ignore the demand for discovering novel classes that are not present in the source domain and simply reject them as “unknown” sets without further exploration, which motivates us to understand the unknown sets more specifically. In this article, we present a more challenging open-world DA problem that recognizes seen classes while discovering novel classes in the target domain. To address this problem, we propose a novel framework that converts this problem into a clustering task via contrastive learning to learn pairwise relationships among the instances. More specifically, our method consists of two iterative steps. The semi-supervised clustering step clusters the unlabeled target data and separates it into seen and novel classes. In the contrastive learning step, based on the cluster assignments, we design tailored contrastive losses that learn pairwise relationships to reduce domain discrepancy and discover novel classes. Our method can be optimized as an example of expectation maximization (EM). We establish several baselines by extending related work. Our method obtains the superior performance on five public datasets, benchmarking this challenging setting for future research.},
  archive      = {J_TNNLS},
  author       = {Jingzheng Li and Hailong Sun and Jiyi Li and Pengpeng Chen and Shikui Wei},
  doi          = {10.1109/TNNLS.2025.3584072},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18408-18421},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Toward open-world domain adaptation via iteratively contrastive learning and clustering},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep multimanifold transformation-based multivariate time series fault detection. <em>TNNLS</em>, <em>36</em>(10), 18397-18407. (<a href='https://doi.org/10.1109/TNNLS.2025.3584988'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised fault detection in multivariate time series (MTS) plays a vital role in ensuring the stable operation of complex systems. Traditional methods often assume that normal data follow a single Gaussian distribution and identify anomalies as deviations from this distribution. However, this simplified assumption fails to capture the diversity and structural complexity of real-world time series, which can lead to misjudgments and reduced detection performance in practical applications. To address this issue, we propose a new method that combines a neighborhood-driven data augmentation strategy with a multimanifold representation learning framework. By incorporating information from local neighborhoods, the augmentation module can simulate contextual variations of normal data, enhancing the model’s adaptability to distributional changes. In addition, we design a structure-aware feature learning approach that encourages natural clustering of similar patterns in the feature space while maintaining sufficient distinction between different operational states. Extensive experiments on several public benchmark datasets demonstrate that our method achieves superior performance in terms of both accuracy and robustness, showing strong potential for generalization and real-world deployment.},
  archive      = {J_TNNLS},
  author       = {Hong Liu and Xiuxiu Qiu and Yiming Shi and Miao Xu and Zelin Zang and Zhen Lei},
  doi          = {10.1109/TNNLS.2025.3584988},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18397-18407},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Deep multimanifold transformation-based multivariate time series fault detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiview temporal graph clustering. <em>TNNLS</em>, <em>36</em>(10), 18383-18396. (<a href='https://doi.org/10.1109/TNNLS.2025.3584384'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging task, temporal graph clustering (TGC) is committed to clustering nodes on temporal graphs through interaction sequence-based batch-processing patterns. These patterns allow for more flexibility in finding a balance between time and space requirements than adjacency matrix-based static graph clustering. However, as a new task, TGC still has important unresolved challenges, such as insufficient information. This challenge manifests itself in a variety of problems in real-world datasets, including missing features (eigenvalues are missing or even nonexistent), long-tail nodes (most inactive nodes have little interaction), and noisy data (data is subject to anomalies, errors, and sparsity). These problems occur before training, making it difficult for the model to train well with insufficient information. To solve the challenge, we propose a method that introduces multiview clustering (MVC) into TGC, called MVTGC. Our method aims to perform data augmentation on the temporal graph by constructing multiple views to increase the information richness. In particular, we utilize different techniques to model a certain part of the temporal graph to generate enhanced views focusing on different angles. These views are combined into training through early fusion and late fusion and ultimately enhance the model’s receptive field and information richness. Comparative experiments and a case study on real-world datasets demonstrate the significance and effectiveness of MVTGC, which achieves at most 10.48% performance improvement. The code and data are available at https://github.com/MGitHubL/MVTGC},
  archive      = {J_TNNLS},
  author       = {Meng Liu and Ke Liang and Hao Yu and Lingyuan Meng and Siwei Wang and Sihang Zhou and Xinwang Liu},
  doi          = {10.1109/TNNLS.2025.3584384},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18383-18396},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multiview temporal graph clustering},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed projection neurodynamic approaches in continuous and discrete time for BP with block decomposition of measurement matrix. <em>TNNLS</em>, <em>36</em>(10), 18369-18382. (<a href='https://doi.org/10.1109/TNNLS.2025.3579161'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the situation where the measurement matrix B has a flexible block decomposition, this article designs two novel distributed continuous- and discrete-time projection neurodynamic approaches to solve the basis pursuit (BP) problem for sparse recovery. These approaches only require information from each flexible block of the measurement matrix B, rather than from each row, column, or the entire matrix. First, with the aid of the primal–dual dynamical approach, projection operator, and second-order multiagent consensus condition, a novel distributed projection neurodynamic approach in continuous time (DPNA-CT-B) is proposed, and its optimality and global asymptotic stability are rigorously proved. Moreover, based on the forward and backward Euler methods and variable substitution methods, a corresponding distributed projection neurodynamic approach in discrete time (DPNA-DT-B) is designed. Finally, through sparse signal and image reconstruction experiments, the effectiveness and superiority of the proposed neurodynamic approaches are verified.},
  archive      = {J_TNNLS},
  author       = {You Zhao and Xing He and Mingliang Zhou and Junzhi Yu and Tingwen Huang},
  doi          = {10.1109/TNNLS.2025.3579161},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18369-18382},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Distributed projection neurodynamic approaches in continuous and discrete time for BP with block decomposition of measurement matrix},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Counterfactual explanation through latent adjustment in disentangled space of diffusion model. <em>TNNLS</em>, <em>36</em>(10), 18355-18368. (<a href='https://doi.org/10.1109/TNNLS.2025.3580118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of explainable artificial intelligence (XAI), counterfactual (CF) explanations have gained significant attention. Effective CFs must be valid (classified as the CF class), practical (minimally deviated from the input), and plausible (close to the CF data manifold). However, practicality and plausibility often conflict, making valid CF generation challenging. To address this, we propose a novel framework that generates CFs by adjusting only semantic information in the disentangled latent space of a diffusion model. This shifts the sample closer to the CF manifold and across the decision boundary. In our framework, the latent vector mapping step occasionally produces invalid CFs or CFs insufficiently close to the decision boundary, resulting in dissimilarity to the input. Our method overcomes this with a two-stage latent vector adjustment: 1) linear interpolation and 2) time-step-wise optimization during reverse diffusion within the space accommodating linear changes in class information from the input. Experiments demonstrate that our approach generates more valid, plausible, and practical CFs by effectively leveraging the properties of the disentangled latent space.},
  archive      = {J_TNNLS},
  author       = {Seung-Hyup Na and Seong-Whan Lee},
  doi          = {10.1109/TNNLS.2025.3580118},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18355-18368},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Counterfactual explanation through latent adjustment in disentangled space of diffusion model},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Draw what you hear: High-fidelity image generation and manipulation via SoundAdapter. <em>TNNLS</em>, <em>36</em>(10), 18342-18354. (<a href='https://doi.org/10.1109/TNNLS.2025.3581455'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the text-to-image (T2I) generation has established itself as a cornerstone within the realm of AI-generated content (AIGC), due its remarkable success to the availability of extensive datasets comprising paired text-vision samples. Nevertheless, the absence of audio-visual pairs hinders the growth of audio-to-image (A2I). Although prior approaches have pioneered the A2I task, the tight entanglement between initial audio and image encoders imposes the challenge of gathering audio-visual samples, resulting in degraded performance and limited sound flexibility. Therefore, this article proposes a novel SoundAdapter to draw what you hear. Specifically, the SoundAdapter’s structure is meticulously designed around transformer blocks, which are critical for capturing overarching patterns and dependencies within the data. In addition, it integrates a sophisticated multigranularity approach coupled with a hybrid supervisory signal, ensuring both fine-grained semantic alignment and seamless optimization across various levels of representation. Extensive tests demonstrate that the SoundAdapter excels in training, setting new benchmarks in zero-shot audio classification, as well as in creating and modifying images across a variety of datasets. The implementation code and several demos supporting this study are openly accessible at https://github.com/CV-MM-Lab/SoundAdapter, facilitating reproducibility and further research.},
  archive      = {J_TNNLS},
  author       = {Mingjie Wang and Song Yuan and Xian-Feng Han and Zili Yi},
  doi          = {10.1109/TNNLS.2025.3581455},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18342-18354},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Draw what you hear: High-fidelity image generation and manipulation via SoundAdapter},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ArmBCIsys: Robot arm BCI system with Time–Frequency network for multiobject grasping. <em>TNNLS</em>, <em>36</em>(10), 18327-18341. (<a href='https://doi.org/10.1109/TNNLS.2025.3579332'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain–computer interface (BCI) offers a direct communication and control channel between the human brain and external devices, presenting new pathways for individuals with physical disabilities to operate robotic arms for complex tasks. However, achieving multiobject grasping tasks under low signal-to-noise ratio (SNR) consumer-grade EEG signals is a significant challenge due to the lack of robust decoding algorithms and precise visual tracking methods. This article proposes, ArmBCIsys, an integrated robotic arm system that combines a novel dual-branch frequency-enhanced network (DBFENet) to robustly decode EEG signals under noisy conditions with the high-precision vision-guided grasping module. The proposed DBFENet designs the scaling temporal convolution block (STCB) to extract multiscale spatiotemporal features from the time domain, while the designed DropScale projected Transformer (DSPT) utilizes discrete cosine transform (DCT) to capture key frequency-domain features, significantly improving decoding robustness. We fine-tune the masked-attention mask Transformer (Mask2Former) model on the Jacquard dataset and incorporate the multiframe centroid-intersection over union (IoU) tracking algorithm to build visual grasp segmenter (VisGraspSeg), enabling reliable segmentation and dynamic tracking for diverse daily objects. Experimental validations on both self-built code-modulated visual evoked potential (c-VEP) dataset (1344 samples) and two public c-VEP datasets demonstrate that DBFENet achieves the state-of-the-art recognition performance, and the system integrates the DBFENet and proposed vision-guided module and ensures stable multiobject selecting and automatic object grasping in dynamic environments, extending promising applications in healthcare robotics, assistive technology, and industrial automation. The self-built dataset has been made publicly accessible at https://github.com/wtu1020/ ArmBCIsys-Self-built-cVEP-Dataset},
  archive      = {J_TNNLS},
  author       = {Feng Yu and Zhongrui Rao and Neng Chen and Li Liu and Minghua Jiang},
  doi          = {10.1109/TNNLS.2025.3579332},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18327-18341},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {ArmBCIsys: Robot arm BCI system with Time–Frequency network for multiobject grasping},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-to-end abnormal subgraph detection via subgraph-level contrastive learning. <em>TNNLS</em>, <em>36</em>(10), 18312-18326. (<a href='https://doi.org/10.1109/TNNLS.2025.3573922'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abnormal subgraph (AS) detection plays a significant role in ensuring the security of many high-impact domains. Unlike node anomaly detection, identifying subgraph anomalies is extremely challenging due to the exponentially large subgraph space caused by various combinations of nodes and edges. Moreover, in the absence of supervisory signals, how to quantify the abnormality of subgraphs poses another pressing challenge. Traditional methods typically rely on handcrafted subgraph anomaly measures, making it hard to handle potential unknown anomalies with limited prior knowledge. Recent deep learning-based techniques are predominantly designed to discover individual node anomalies, which could be suboptimal for AS detection due to the inconsideration of collaborative behaviors between nodes in the subgraph. In fact, existing studies have put very little effort into this task, and even dedicated performance evaluation metrics are not yet available. To address the above challenges and promote related research, in this article, we propose a end-to-end unsupervised subgraph anomaly detection framework (EndSubG), which jointly models subgraph partition and AS detection as a whole instead of treating them as two separate stages. Specifically, EndSubG uncovers potential AS boundaries that violate the Homophily assumption by modeling the edge existence probability, then achieves anomaly-aware graph embedding and subgraph partition based on the refined topology. By forming a coarsened subgraph network, EndSubG picks out subgraph anomalies by learning the “subgraph-vicinity” matching patterns. Additionally, we design an evaluation metric weighted normalized mutual information centered on AS (AS-WNMI) specifically for subgraph anomaly detection, which is a variant of vanilla NMI and quantifies detection performance from both subgraph partition and anomaly recognition. The experimental results on synthetic and real-world datasets corroborate the superiority of end-to-end unsupervised subgraph anomaly detection framework (EndSubG) in terms of area under the curve (AUC), average precision (AP), and AS-WNMI. We also provide an intuitive analysis of the detected subgraphs through visualization for better understanding.},
  archive      = {J_TNNLS},
  author       = {Zhen Peng and Yunfan Wang and Qika Lin and Bin Shi and Chen Chen and Bo Dong and Chao Shen},
  doi          = {10.1109/TNNLS.2025.3573922},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18312-18326},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {End-to-end abnormal subgraph detection via subgraph-level contrastive learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VB-adapter: Variational bayesian adapter for cross-domain speech representation learning. <em>TNNLS</em>, <em>36</em>(10), 18300-18311. (<a href='https://doi.org/10.1109/TNNLS.2025.3589086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To leverage the abundant speech data available for pretraining, current models excel in generalization across diverse tasks. Nevertheless, real-world challenges emerge when addressing unfamiliar speech scenarios far from the pretrained speech, owing to the domain shift between pretraining (source) and fine-tuning (target) data. To overcome this barrier, we propose a variational Bayesian adapter (VB-Adapter) for cross-domain speech representation learning during fine-tuning. First, we establish a latent variable model to construct a desired posterior distribution after incorporating domain-specific knowledge to bridge the gap between the source and target domains. Then, an adaptive objective is presented to maximize the mutual information of the latent variables with and without domain-specific knowledge to facilitate model adaptation. Finally, we introduce contrastive learning on samples to optimize the lower bound of the above adaptive objective. Our experiments apply the VB-Adapter on transformers for dysarthric speech recognition (DSR) and the integration of Whisper-encoder and Llama for Mandarin speech recognition (MSR). The results reveal the effectiveness of VB-Adapter in modeling the uncertainties arising from domain shift and enhancing the robustness of speech representations.},
  archive      = {J_TNNLS},
  author       = {Jing Zhao and Qimin Huang and Shanhu Wang and Shiliang Sun},
  doi          = {10.1109/TNNLS.2025.3589086},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18300-18311},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {VB-adapter: Variational bayesian adapter for cross-domain speech representation learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiattentive perception and multilayer transfer network using knowledge distillation for RGB-D indoor scene parsing. <em>TNNLS</em>, <em>36</em>(10), 18287-18299. (<a href='https://doi.org/10.1109/TNNLS.2025.3575088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene parsing has gained wide attention in the field of computer vision, with emerging methods and techniques providing superior solutions. Although some methods have improved performance, they tend to neglect the number of model parameters and computational size, which makes achieving real-time operation in practical applications challenging. To address these limitations, we propose a multiattentive perception and multilayer transfer network that employs knowledge distillation (MPMTNet-KD), which is generated by a student network (MPMTNet-S) under the guidance of a teacher network (MPMTNet-T) with the aid of our proposed multilayer transfer knowledge distillation (KD) methods. To capture complete information from different modalities, a multiattentive perception module (MAPM) is introduced to mine features from various perspectives, and hetero-oriented sensing (HOS) convolution is utilized to integrate cross-layer features in a single and holistic manner. Importantly, we introduce multilayer transfer KD to explore the different knowledge types between layers, as well as intraclass and interclass correlations. In addition, we use the discrete cosine transform (DCT) approach combined with filtering during the KD process to mitigate noise that may be induced by the depth map, thereby improving the depth information and further enhancing the knowledge transfer effect. We conducted comprehensive experiments on two challenging indoor benchmark datasets, namely NYUDv2 and SUN RGB-D. Compared with existing methods, the proposed MPMTNet-KD reduces the number of parameters from 125.8 M in MPMTNet-T to 28.3 M in MPMTNet-S, achieving a mean intersection over union (mIoU) of 54.9% in the indoor scene parsing task. MPMTNet-KD was also evaluated on two additional public datasets, namely MFNet and PST900, to demonstrate its generalization capacity. The source code is available at https://github.com/XUEXIKUAIL/MPMTNet},
  archive      = {J_TNNLS},
  author       = {Wujie Zhou and Bitao Jian and Yuanyuan Liu and Qiuping Jiang},
  doi          = {10.1109/TNNLS.2025.3575088},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18287-18299},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multiattentive perception and multilayer transfer network using knowledge distillation for RGB-D indoor scene parsing},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Highly condensed all-MLP architecture for long-term human motion prediction. <em>TNNLS</em>, <em>36</em>(10), 18274-18286. (<a href='https://doi.org/10.1109/TNNLS.2025.3583597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In artificial intelligence (AI) scenarios where computational resources are constrained, such as in autonomous driving systems, it is challenging to construct a lightweight model that can accurately predict human motion overextended duration. To tackle this challenge, we introduce a highly condensed all-multilayer perceptron (HCMLP) architecture that is engineered for supreme lightweight efficiency. This design facilitates extended-range motion predictions while maintaining uncompromised performance. First, the spatiotemporal dynamic perception (STDP) block enhances operational efficiency while maintaining a simple structure. In STDP, the distinct but parallel spatial multilayer perceptron (SMLP) and temporal multilayer perceptron (TMLP) simultaneously capture the spatial correlations between pose joints and the temporal dynamics of each joint. The subsequent dynamic aggregation (DA), coupled with the channel multilayer perceptron (CMLP), dynamically consolidates and refines spatial and temporal features, leading to improved predictive accuracy. Second, the multiterm union prediction (MTUP) block directly delivers precise predictions for periods ranging from 0 to 4000 ms, eliminating the need for repetitive short-term (ST) prediction iterations. Our experimental results on the Human3.6M, AMASS, 3DPW, and CMU-Mocap datasets demonstrate that HCMLP outperforms existing state-of-the-art (SOTA) methods in ST prediction, long-term (LT) prediction, and especially in extended and extra extended LT (ELT) predictions, all while utilizing the fewest parameters.},
  archive      = {J_TNNLS},
  author       = {Sheng Liu and Shaobo Zhang and Fei Gao and Yuan Feng},
  doi          = {10.1109/TNNLS.2025.3583597},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18274-18286},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Highly condensed all-MLP architecture for long-term human motion prediction},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topology-preserved information bottleneck for multiview anomaly detection. <em>TNNLS</em>, <em>36</em>(10), 18259-18273. (<a href='https://doi.org/10.1109/TNNLS.2025.3579412'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection (AD) techniques are widely used in various fields. Existing techniques primarily focus on learning a normal region from single-view data, which may be not suitable for multiview data that provides more comprehensive information from multiple perspectives. Therefore, AD techniques designed for multiview data are necessary. Straightforwardly, one can concatenate the features learned from multiple single-view data into a joint representation to conduct AD. However, this may overlook the inevitable overlaps between views, potentially masking view-specific information due to the repetitive calculations of these overlaps. Among the various possible methods, one way to address this is to compress redundant information while maintaining comprehensive information across views. Following this way, in this article, we leverage the principle of information bottleneck (IB) to extract concise and comprehensive representations for multiview data. But it is problematic to directly use these representations for AD, since the multiview fusion process may disturb the intrinsic structure of the original data. That is, samples distributed at the edges/center of the original normal data distribution are mapped closer to the center/edges. This might cause abnormal samples (close to the normal data at the edges) to be incorrectly mapped into the normal region during inference. In the AD scenario, the absence of abnormal training samples makes it unfeasible to preserve this structure using supervised information. In this article, we design a topology-preserved regularization that unsupervisedly constrains the latent representations to preserve the original data’s intrinsic structure, to improve the AD performance. Overall, we propose a topology-preserved multiview information bottleneck (TMVIB) feature extraction method to extract concise, comprehensive, and topology-preserved latent representations from multiview data. Interestingly, we find that the TMVIB feature extraction method itself can be viewed as a regularized anomaly detector, allowing it to output anomaly scores directly. Experiments on synthetic and real-world multiview datasets demonstrate the effectiveness of the proposed TMVIB.},
  archive      = {J_TNNLS},
  author       = {Tengfei Yan and Jiankai Tu and Chunguang Li and Fan Zhang},
  doi          = {10.1109/TNNLS.2025.3579412},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18259-18273},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Topology-preserved information bottleneck for multiview anomaly detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAWN+: Wavelet-based image deraining meets direction-aware attention and mutual representation. <em>TNNLS</em>, <em>36</em>(10), 18244-18258. (<a href='https://doi.org/10.1109/TNNLS.2025.3587248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The single-image deraining aims to restore clean scenes from rainy inputs by eliminating precipitation artifacts. Current methods often neglect the directional nature of rain streaks—a critical oversight that causes heterogeneous degradation, particularly in texture regions aligned with rain orientations. To address this issue and advance image deraining, we propose a novel direction-aware attention wavelet network (DAWN) for rain streaks removal. DAWN has several key distinctions and innovative features compared with existing wavelet transform-based methods: 1) introducing vector decomposition to parameterize rain distribution through vertical (V) and horizontal (H) component decomposition, enabling explicit direction-aware representation; 2) devising a novel direction-aware attention module (DAM) to learn projection/transformation parameters via coordinate attention mechanisms for precise rain removal and texture preservation; and 3) exploring practical composite constraints to jointly optimize structural coherence, detail fidelity, and chrominance accuracy. Building upon the conference version (DAWN), we devise DAWN+ with enhanced capabilities: 1) decoupling diagonal coefficient learning to eliminate frequency aliasing by characterizing diagonal components with dedicated projection parameters; 2) dividing vector decomposition and parameter fitting into multiple stages to reduce error accumulation; and 3) applying cross-frequency mutual representation to boost training and performance. Experiments across six tasks (deraining, raindrop/rainhaze removal, dehazing, and low-light/underwater enhancement) demonstrate the portability and reusability of these strategies. Meanwhile, DAWN+ delivers significant performance gains over DAWN, achieving an average peak signal to noise ratio (PSNR) increase of 1.17 dB with an acceptable complexity increase. Meanwhile, DAWN+ achieves the competitive performance to the state-of-the-art DRSformer (gaining 0.15 dB in PSNR) while saving 94.4% and 95% model parameters and inference time, respectively.},
  archive      = {J_TNNLS},
  author       = {Kui Jiang and Junjun Jiang and Zheng Wang and Zihan Geng and Xianming Liu},
  doi          = {10.1109/TNNLS.2025.3587248},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18244-18258},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DAWN+: Wavelet-based image deraining meets direction-aware attention and mutual representation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decentralized consensus inference-based hierarchical reinforcement learning for multiconstrained UAV pursuit-evasion game. <em>TNNLS</em>, <em>36</em>(10), 18229-18243. (<a href='https://doi.org/10.1109/TNNLS.2025.3582909'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple quadrotor uncrewed aerial vehicles (UAVs) systems have garnered widespread research interest and fostered tremendous interesting applications, especially in multiconstrained pursuit-evasion games (MC-PEGs). The cooperative evasion and formation coverage (CEFC) task, where the UAV swarm aims to maximize formation coverage across multiple target zones while collaboratively evading predators, belongs to one of the most challenging issues in MC-PEGs, especially under communication-limited constraints. This multifaceted problem, which intertwines responses to obstacles, adversaries, target zones, and formation dynamics, brings up significant high-dimensional complications in locating a solution. In this article, we propose a novel two-level framework [i.e., consensus inference-based hierarchical reinforcement learning (CI-HRL)], which delegates target localization to a high-level policy, while adopting a low-level policy to manage obstacle avoidance, navigation, and formation. Specifically, in the high-level policy, we develop a novel multiagent reinforcement learning (RL) module, consensus-oriented multiagent communication (ConsMAC), to enable agents to perceive global information and establish consensus from local states by effectively aggregating neighbor messages. Meanwhile, we leverage an alternative training-based MAPPO (AT-M) and policy distillation to accomplish the low-level control. The experimental results, including the high-fidelity software-in-the-loop (SITL) simulations, validate that CI-HRL provides a superior solution with enhanced swarm’s collaborative evasion and task completion capabilities.},
  archive      = {J_TNNLS},
  author       = {Yuming Xiang and Sizhao Li and Rongpeng Li and Zhifeng Zhao and Honggang Zhang},
  doi          = {10.1109/TNNLS.2025.3582909},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18229-18243},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Decentralized consensus inference-based hierarchical reinforcement learning for multiconstrained UAV pursuit-evasion game},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing graph reconstruction: Uniting dual-level graph structure with graph reinforcement learning. <em>TNNLS</em>, <em>36</em>(10), 18218-18228. (<a href='https://doi.org/10.1109/TNNLS.2025.3585906'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A combinatorial optimization problem is typically regarded as a 1-D sorting problem in most existing research. The representation ignores some information about the problem because of dimension compression. When applying reinforcement learning (RL) to this problem, convolutional neural networks (CNNs) used in conventional RL cannot directly extract the connection information between two elements in the feature matrix. A typical class of combinatorial optimization problems, the job shop scheduling problem (JSSP), is used in this article as an example. Considering the limitations in previous research, this article reexamines the task from the perspective of graph reconstruction and proposes a graph RL (GRL) method that combines a double deep Q-network (DDQN) and graph attention network (GAT) to achieve breakthroughs beyond the constraints of CNN performance. Moreover, a dual-level graph representation structure is constructed to comprehensively learn the features of scheduling information and overcome the difficulty of learning dynamic graphs. Experiments show that the quality of the obtained solution and generalization performance are both improved compared with models based on original deep RL (DRL) algorithms.},
  archive      = {J_TNNLS},
  author       = {Dazi Li and Yanyang Bao and Xin Xu},
  doi          = {10.1109/TNNLS.2025.3585906},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18218-18228},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Enhancing graph reconstruction: Uniting dual-level graph structure with graph reinforcement learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiffusionMOT: A diffusion-based multiple object tracker. <em>TNNLS</em>, <em>36</em>(10), 18203-18217. (<a href='https://doi.org/10.1109/TNNLS.2025.3579729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, researchers have introduced diffusion models into multiple object tracking (MOT) tasks. However, existing diffusion-based MOT methods, such as DiffusionTrack, have significant limitations, including frequent ID switching, reduced performance when tracking nonlinear motion objects, and long inference time. To this end, we propose a more effective diffusion-based multiple object tracker named DiffusionMOT. In particular, we propose a mixed intersection over union (IoU) and Re-Identification (ReID) method for trajectory matching, which effectively reduces incorrect matches. Meanwhile, we propose a secondary calibration method for trajectory boxes, improving the accuracy of the generated detection boxes. Moreover, we introduce the parallel sampling technique from the field of image generation into object tracking and propose a parallel sampling module to enhance the model’s inference speed while maintaining tracking accuracy. Furthermore, we design a pair-based two-stage matching (PTM) pipeline to more effectively utilize potential detection information. Extensive experiments on several public MOT benchmarks, including DanceTrack, SportsMOT, MOT20, and MOT17, demonstrate that our approach achieves state-of-the-art (SOTA) performance. The code and models are available at https://github.com/sad123-yx/DiffusionMOT},
  archive      = {J_TNNLS},
  author       = {Yaxuan Hu and Jie Hua and Zhen Han and Hua Zou and Gang Wu and Zhongyuan Wang},
  doi          = {10.1109/TNNLS.2025.3579729},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18203-18217},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DiffusionMOT: A diffusion-based multiple object tracker},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neighboring state-aware policy for deep reinforcement learning. <em>TNNLS</em>, <em>36</em>(10), 18188-18202. (<a href='https://doi.org/10.1109/TNNLS.2025.3581217'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) methods, which train a policy to obtain the sequence of actions required to complete a task, have achieved remarkable success across diverse applications. It is a long-standing open issue in the DRL community to make the trained policy gradually approach the theoretically globally optimal policy, and existing research has also explored several challenges, such as exploration-exploitation, to improve the quality of the obtained policy. However, most DRL methods rely solely on the current state for decision-making, leading to short-sightedness and suboptimal learning. To overcome this, we propose a neighboring state-aware policy that enhances existing DRL methods by incorporating a neighboring state sequence in the decision-making process. Specifically, our approach saves multiple past and future states and concatenates them as the neighboring state sequence, along with the current state, and inputs them to the actor to generate an action during the training process. This global perspective, provided by neighboring states, is similar to human decision-making and helps the agent better understand state evolution, leading to improved policy learning. We present two specific implementations of our approach and demonstrate through extensive experiments that it effectively enhances ten representative DRL methods across nine tasks, based on three metrics, including return.},
  archive      = {J_TNNLS},
  author       = {Meng Xu and Xinhong Chen and Guanyi Zhao and Zihao Wen and Weiwei Fu and Jianping Wang},
  doi          = {10.1109/TNNLS.2025.3581217},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18188-18202},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Neighboring state-aware policy for deep reinforcement learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Granular-ball regeneration clustering with principle of justifiable granularity. <em>TNNLS</em>, <em>36</em>(10), 18173-18187. (<a href='https://doi.org/10.1109/TNNLS.2025.3579376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classical clustering algorithms such as k-means face limitations in handling clusters with heterogeneous shapes, densities, and sizes, while exhibiting sensitivity to initial centroid selection. To overcome these challenges, this article proposes a novel clustering framework based on regenerated granular ball (RGGB) with the principle of justifiable granularity. Unlike existing granular-ball (GB) techniques that overemphasize purity criteria at the expense of uncontrolled ball sizes, RGGB dynamically adjusts granularity levels through iterative regeneration, achieving an optimal balance between detailed data representation and computational efficiency. This adaptability enhances stability in capturing data similarities while mitigating sensitivity to initialization. To validate the method, we integrate RGGB with a novel k-nearest neighbor (KNN) classifier using regenerated GBs to evaluate classification performance and demonstrate practical applications. Experiments on diverse public and realistic datasets demonstrate that the RGGB-based KNN algorithm consistently outperforms existing techniques, including traditional KNN and other methods, making a promising advancement in clustering and classification tasks.},
  archive      = {J_TNNLS},
  author       = {Wentao Li and Lingwei Wei and Witold Pedrycz and Weiping Ding and Chao Zhang and Tao Zhan and Shuyin Xia},
  doi          = {10.1109/TNNLS.2025.3579376},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18173-18187},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Granular-ball regeneration clustering with principle of justifiable granularity},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pose error prediction, compensation method, and applicable condition determination of parallel motion platform based on transfer learning. <em>TNNLS</em>, <em>36</em>(10), 18158-18172. (<a href='https://doi.org/10.1109/TNNLS.2025.3586458'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collecting a large amount of measured configuration data for robots entails high costs and time, which restricts the widespread use of neural networks for robot error prediction and compensation. In this study, a “transfer network” is established by taking the motion transmission characteristics inherent in the ideal kinematic model as prior knowledge and transferring it to a network trained based on the actual poses. Compared with the traditional back propagation (BP) neural network trained by actual poses alone, the transfer network shows significant performance advantages, effectively solving the problems of low prediction accuracy and weak generalization ability in the case of the small-sample measured data. Considering this, a method for determining the applicability of transfer learning is proposed. This method is achieved by evaluating the similarity between the learning tasks and then revealing the coupling effect of task similarity and the sample number of actual poses on the performance of the transfer network. Experiments are conducted on a six degrees of freedom (6-DOF) parallel robot. The results verify the superiority of transfer learning applied in robot precision compensation and the effectiveness of the proposed determination method.},
  archive      = {J_TNNLS},
  author       = {Wenjie Tian and Xu Guo and Min Xu and Xiangpeng Zhang},
  doi          = {10.1109/TNNLS.2025.3586458},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18158-18172},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Pose error prediction, compensation method, and applicable condition determination of parallel motion platform based on transfer learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diverse representations embedding for lifelong person re-identification. <em>TNNLS</em>, <em>36</em>(10), 18145-18157. (<a href='https://doi.org/10.1109/TNNLS.2025.3571768'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lifelong person re-identification (LReID) aims to continuously learn from sequential data streams, enabling cross-camera matching of individuals over time. A critical challenge in LReID lies in balancing the preservation of previously acquired knowledge with the incremental acquisition of new information, due to task-level gaps and limited representation capacity. Conventional methods relying on CNN backbones struggle to fully capture the diverse perspectives of each instance, leading to suboptimal model performance. To tackle these limitations, we propose a diverse representation embedding (DRE) framework that balances preserving old knowledge with adapting to new information. Specifically, our DRE incorporates a robust Transformer-based backbone that utilizes maximum embedding (ME) and multiple class tokens to generate overlapping representations for each instance. To further enhance the model’s representation capacity, we design an adaptive constraint module (ACM), which performs integration and discrimination operations on overlapping representations to yield diverse yet diverse representations. Furthermore, we propose two strategies: knowledge update (KU) and knowledge preservation (KP), implemented within the adjustment and learner models, respectively. The KU strategy enhances the learner model’s ability to adapt to new information by leveraging prior knowledge from the adjustment model. The KP strategy ensures the retention of historical knowledge while maintaining the model’s adaptability. Extensive experiments validate that our DRE surpasses state-of-the-art approaches across large-scale, occluded, and holistic datasets, demonstrating significant performance gains. Our code is available at https://github.com/LiuShiBen/DRE},
  archive      = {J_TNNLS},
  author       = {Shiben Liu and Huijie Fan and Qiang Wang and Xiai Chen and Zhi Han and Yandong Tang},
  doi          = {10.1109/TNNLS.2025.3571768},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18145-18157},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Diverse representations embedding for lifelong person re-identification},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inducing neural collapse via anticlasses and one-cold cross-entropy loss. <em>TNNLS</em>, <em>36</em>(10), 18133-18144. (<a href='https://doi.org/10.1109/TNNLS.2025.3580892'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While softmax cross-entropy (CE) loss is the standard objective for supervised classification, it primarily focuses on the ground-truth classes, ignoring the relationships between the nontarget, complementary classes. This leaves valuable information unexploited during optimization. In this work, we propose a novel loss function, one-cold CE (OCCE) loss, which addresses this limitation by structuring the activations of these complementary classes. Specifically, for each class, we define an anticlass, which consists of everything that is not part of the target class—this includes all complementary classes as well as out-of-distribution (OOD) samples, noise, or in general any instance that does not belong to the true class. By setting a uniform one-cold encoded distribution over the complementary classes as a target for each anticlass, we encourage the model to equally distribute activations across all nontarget classes. This approach promotes a symmetric geometric structure of classes in the final feature space, increases the degree of neural collapse (NC) during training, addresses the independence deficit problem of neural networks, and improves generalization. Our extensive evaluation shows that incorporating OCCE loss in the optimization objective consistently enhances performance across multiple settings, including classification, open-set recognition, and OOD detection.},
  archive      = {J_TNNLS},
  author       = {Dimitrios Katsikas and Nikolaos Passalis and Anastasios Tefas},
  doi          = {10.1109/TNNLS.2025.3580892},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18133-18144},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Inducing neural collapse via anticlasses and one-cold cross-entropy loss},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust multi-agent reinforcement learning by mutual information regularization. <em>TNNLS</em>, <em>36</em>(10), 18118-18132. (<a href='https://doi.org/10.1109/TNNLS.2025.3577259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cooperative multi-agent reinforcement learning (MARL), ensuring robustness against cooperative agents making unpredictable or worst-case adversarial actions is crucial for real-world deployment. In multi-agent settings, each agent may be perturbed or unperturbed, leading to an exponential increase in potential threat scenarios as the number of agents grows. Existing robust MARL methods either enumerate, or approximate all possible threat scenarios, leading to intense computation and insufficient robustness. In contrast, humans develop robust behaviors by maintaining a general level of caution rather than preparing for every possible threat. Inspired by human decision making, we frame robust MARL as a control-as-inference problem, and optimize worst-case robustness across all threat scenarios implicitly optimized through off-policy evaluation. Specifically, we introduce mutual information regularization as robust regularization (MIR3), which maximizes a lower bound on robustness during routine training, serving as a kind of caution for MARL without adversarial inputs. Further insights show that MIR3 acts as an information bottleneck, preventing agents from over-reacting to others and aligning policies with robust action priors. In the presence of worst-case adversaries, our MIR3 significantly surpasses baseline methods in robustness and training efficiency, and maintaining cooperative performance in StarCraft II, quadrotor swarm control, and robot swarm control. When deploying the robot swarm control algorithm in the real world, our method also outperforms the best baseline by 14.29% in reward. See code and demo videos at https://github.com/DIG-Beihang/MIR3},
  archive      = {J_TNNLS},
  author       = {Simin Li and Ruixiao Xu and Jingqiao Xiu and Yuwei Zheng and Pu Feng and Yuqing Ma and Bo An and Yaodong Yang and Xianglong Liu},
  doi          = {10.1109/TNNLS.2025.3577259},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18118-18132},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust multi-agent reinforcement learning by mutual information regularization},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated scientific machine learning for approximating functions and solving differential equations with data heterogeneity. <em>TNNLS</em>, <em>36</em>(10), 18104-18117. (<a href='https://doi.org/10.1109/TNNLS.2025.3580409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By leveraging neural networks, the emerging field of scientific machine learning (SciML) offers novel approaches to address complex problems governed by partial differential equations (PDEs). In practical applications, challenges arise due to the distributed essence of data, concerns about data privacy, or the impracticality of transferring large volumes of data. Federated learning (FL), a decentralized framework that enables the collaborative training of a global model while preserving data privacy, offers a solution to the challenges posed by isolated data pools and sensitive data issues. Here, this article explores the integration of FL and SciML to approximate complex functions and solve differential equations. We propose two novel models: federated physics-informed neural networks (FedPINNs) and federated deep operator networks (FedDeepONets). We further introduce various data generation methods to control the degree of nonindependent and identically distributed (non-i.i.d.) data and utilize the 1-Wasserstein distance to quantify data heterogeneity in function approximation and PDE learning. We systematically investigate the relationship between data heterogeneity and federated model performance. In addition, we propose a measure of weight divergence and develop a theoretical framework to establish growth bounds for weight divergence in FL compared with centralized learning. To demonstrate the effectiveness of our methods, we conducted ten experiments, including two on function approximation, five PDE problems on FedPINN, and four PDE problems on FedDeepONet. These experiments demonstrate that proposed federated methods surpass the models trained only using local data and achieve competitive accuracy of centralized models trained using all data.},
  archive      = {J_TNNLS},
  author       = {Handi Zhang and Langchen Liu and Kangyu Weng and Lu Lu},
  doi          = {10.1109/TNNLS.2025.3580409},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18104-18117},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Federated scientific machine learning for approximating functions and solving differential equations with data heterogeneity},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GMM enhanced anchor-based spectral clustering for large-scale data. <em>TNNLS</em>, <em>36</em>(10), 18089-18103. (<a href='https://doi.org/10.1109/TNNLS.2025.3571473'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anchor-based methods are proposed to make use of anchors to produce an affinity matrix of objects to improve the scalability of traditional spectral clustering (SC). Nevertheless, the membership heterogeneity of objects inside a cluster, which would bring about low quality of anchors and hurt the clustering accuracy, is commonly neglected by existing anchor-based algorithms. To address this problem, this article proposes a novel approach to adopt the Gaussian mixture model (GMM) to enhance anchor-based SC for large-scale data in a two-stage divide-and-conquer manner. In the first stage, GMM with expectation maximization (EM) algorithm is employed to divide the objects into two categories as prior-consistent objects and prior-uncertain objects in considering the membership heterogeneity of objects. In the second stage, anchor-based SC is conducted on the prior-uncertain objects by sampling the anchors from the Gaussian components derived from the first stage. Then, the produced clusters in the second stage are aligned with those Gaussian components by maximizing the membership of objects with respect to clusters. The computation complexity of the proposed GMM-SC approach is much smaller than that of the anchor-based SC. The experiments on large-scale datasets also validate the superiority of the proposed GMM-SC approach over state-of-the-art techniques.},
  archive      = {J_TNNLS},
  author       = {Wen Zhang and Jiangpeng Zhao and Lean Yu and Song Wang},
  doi          = {10.1109/TNNLS.2025.3571473},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18089-18103},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {GMM enhanced anchor-based spectral clustering for large-scale data},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time network latency estimation with pretrained generative models. <em>TNNLS</em>, <em>36</em>(10), 18075-18088. (<a href='https://doi.org/10.1109/TNNLS.2025.3573200'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network latency estimation is critical for network performance monitoring and management. However, with the escalating demand for real-time performance monitoring and rapid network adjustments in contemporary networks, existing latency estimation methodologies fall short of meeting the need for instantaneous estimation. In this article, we propose a pretrained generative model-based scheme (PGM) for real-time network latency estimation. PGM operates in two stages. First, we employ a pretrained generative model to relax the low-rank constraint typically associated with latency matrix completion (MC). The pretrained generative model well learns the low-rank characteristics of latency matrices in the pretraining stage and can map a condensed latent representation to the matrix space. Second, instead of directly optimizing the matrix, we turn to optimizing the latent representation. Leveraging the low-rank structure achieved by the pretrained generative model simplifies our optimization process, enabling real-time estimation. We also provide a theoretical recovery guarantee to reveal the error bound of PGM. Experimental results on real-world datasets show that the proposed scheme can achieve accurate latency estimation within 50 ms while maintaining the relative squared error (RSE) of estimation at no more than 0.11 (as evidenced using the PlanetLab dataset).},
  archive      = {J_TNNLS},
  author       = {Lei Deng and Xiao-Yang Liu and Danny H. K. Tsang},
  doi          = {10.1109/TNNLS.2025.3573200},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18075-18088},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Real-time network latency estimation with pretrained generative models},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MetaIndux-TS: Frequency-aware AIGC foundation model for industrial time series. <em>TNNLS</em>, <em>36</em>(10), 18062-18074. (<a href='https://doi.org/10.1109/TNNLS.2025.3577203'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implementing advanced AI techniques in industrial manufacturing requires large volumes of annotated sensor data. Unfortunately, collecting such data is often impractical due to extreme environments and the manual burden of expert annotation. Recent advancements in artificial intelligence generated content (AIGC) have inspired the exploration of industrial time-series generation to mitigate data shortages. However, existing AIGC models encounter difficulties in generating industrial time series due to their complex temporal dynamics, multichannel intercolumn correlations, and diverse frequency characteristics. To address these challenges, we propose MetaIndux-TS, a frequency-informed AIGC foundation model based on diffusion model frameworks. This model is designed to generate industrial time-series data under a variety of working conditions, across different types of equipment, and with variable lengths. Specifically, MetaIndux-TS integrates dual-frequency cross-attention networks, transforming time series into the frequency domain to model multivariate dependencies and capture intricate temporal details. In addition, the contrastive synthesis layer is constructed to generate high-fidelity time series by comparing periodic and long-term trends with initial noisy sequences. Comprehensive experiments show that MetaIndux-TS outperforms state-of-the-art models (SSSD, Dit, and TabDDPM), achieving a 57.5% improvement in fidelity and 20.4% in predictive score. MetaIndux-TS exhibits zero-shot generation capabilities for samples under unseen conditions, offering the potential to address data collection challenges in extreme environments. Codes are available at: https://github.com/Dolphin-wang/MetaIndux},
  archive      = {J_TNNLS},
  author       = {Haiteng Wang and Lei Ren and Yikang Li and Yuqing Wang},
  doi          = {10.1109/TNNLS.2025.3577203},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18062-18074},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {MetaIndux-TS: Frequency-aware AIGC foundation model for industrial time series},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian neural networks with physics-informed priors with application to boundary layer velocity. <em>TNNLS</em>, <em>36</em>(10), 18048-18061. (<a href='https://doi.org/10.1109/TNNLS.2025.3577508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most popular recent areas of machine learning predicates the use of neural networks (NNs) augmented by information about the underlying process in the form of partial differential equations (PDEs). These physics-informed NNs (PINNs) are obtained by penalizing the inference with a PDE and have been cast as a minimization problem currently lacking a formal approach to quantify the uncertainty. In this work, we propose a novel model-based framework that regards the PDE as a prior information of a deep Bayesian NN (BNN), physics-informed prior (PIP)-BNN. The prior is calibrated without data to resemble the PDE solution in the prior mean, while our degree of confidence in the PDE with respect to the data is expressed in terms of the prior variance. The information embedded in the PDE are then propagated to the posterior yielding physics-informed forecasts with uncertainty quantification. We apply our approach to a simulated viscous fluid and to an experimentally obtained turbulent boundary layer velocity in a water tunnel using an appropriately simplified Navier–Stokes (NS) equation. Our approach requires very few observations to produce physically consistent forecasts as opposed to nonphysical forecasts stemming from noninformed priors, thereby allowing forecasting complex systems, where some amount of data as well as some contextual knowledge is available.},
  archive      = {J_TNNLS},
  author       = {Luca Menicali and David H. Richter and Stefano Castruccio},
  doi          = {10.1109/TNNLS.2025.3577508},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18048-18061},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Bayesian neural networks with physics-informed priors with application to boundary layer velocity},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical sparse representation clustering for high-dimensional data streams. <em>TNNLS</em>, <em>36</em>(10), 18035-18047. (<a href='https://doi.org/10.1109/TNNLS.2025.3582380'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data stream clustering reveals patterns within continuously arriving, potentially unbounded data sequences. Numerous data stream algorithms have been proposed to cluster data streams. The existing data stream clustering algorithms still face significant challenges when addressing high-dimensional data streams. First, it is intractable to measure the similarities among high-dimensional data objects via Euclidean distances when constructing and merging microclusters. Second, these algorithms are highly sensitive to the noise contained in high-dimensional data streams. In this article, we propose a hierarchical sparse representation clustering (HSRC) framework for clustering high-dimensional data streams. HSRC first employs a sparse representation-based technique to learn an affinity matrix for data objects in individual landmark windows with a fixed size, where the number of neighboring data objects is automatically selected. The sparse representation-based technique ensures that highly correlated data samples within clusters are grouped together. Then, HSRC applies a spectral clustering technique to the affinity matrix to generate microclusters. These microclusters are subsequently merged into macroclusters based on their sparse similarity degrees (SSDs). In addition, HSRC introduces sparsity residual values (SRVs) to adaptively select representative data objects from the current landmark window. These representatives serve as dictionary samples for the next landmark window. Finally, HSRC refines each macrocluster through fine-tuning. In particular, HSRC enables the detection of outliers in high-dimensional data streams via the associated SRVs. The experimental results obtained on several benchmark datasets demonstrate the effectiveness and robustness of the proposed HSRC framework.},
  archive      = {J_TNNLS},
  author       = {Jie Chen and Hua Mao and Yuanbiao Gou and Xi Peng},
  doi          = {10.1109/TNNLS.2025.3582380},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18035-18047},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Hierarchical sparse representation clustering for high-dimensional data streams},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised heterogeneous graph attention model based on adaptable step-size metapaths. <em>TNNLS</em>, <em>36</em>(10), 18020-18034. (<a href='https://doi.org/10.1109/TNNLS.2025.3587020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs are widely used to model networks in real-world applications, with heterogeneous graph neural networks gaining increasing attention in recent years. Existing methods generally rely on first-order or high-order neighbors to capture semantic relationships, where metapath-based approaches are the most popular ones. However, existing metapath-based models not only require predefined metapaths based on prior knowledge, but also lack the consideration of metapath sequence modeling. Additionally, labeled data are scarce in massive graph data, and existing self-supervised or semisupervised models heavily rely on data enhancement strategies and complex frameworks. To address these limitations, we propose a self-supervised heterogeneous graph attention model (HGAM) based on adaptable step-size metapaths. Our model requires no prior knowledge to select the type of metapath and can adaptively capture the specific step-size metapath with high importance. The adaptable step-size metapaths module not only considers the attention weight in different step sizes, but also pays attention to the changing trend of attention, which expands the receptive field of the model and integrates global information preferably. To alleviate labeled data scarcity, our model employs a dual contrastive learning strategy. HGAM learns global representations by contrasting a high-order meta-graph against nodes, while preserving local structure through a cross-view comparison of first-order and high-order semantics. Extensive experiments on three different types of tasks, including node classification, clustering, and link prediction, are conducted on real-world datasets. Experimental results demonstrate that HGAM achieves superior performance compared to state-of-the-art methods.},
  archive      = {J_TNNLS},
  author       = {Xiangyi Teng and Minghao Zhong and Jing Liu},
  doi          = {10.1109/TNNLS.2025.3587020},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18020-18034},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A self-supervised heterogeneous graph attention model based on adaptable step-size metapaths},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Alpha and prejudice: Improving α-sized worst case fairness via intrinsic reweighting. <em>TNNLS</em>, <em>36</em>(10), 18005-18019. (<a href='https://doi.org/10.1109/TNNLS.2025.3586609'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving worst case group fairness typically relies on maximizing the utility of the worst-off demographic group. However, in practice, demographic information is often unavailable, making direct max-min formulations infeasible. To address this, recent work introduces a relaxed setting, using a lower bound $\alpha $ on the minimal group size—referred to as “ $\alpha $ -sized worst case fairness” in this article. We first motivate the importance of this setting by highlighting its relevance to data privacy, a critical yet underexplored perspective. Rather than simply retraining on worst-off samples, we propose a reweighting approach that assigns sample weights based on their intrinsic contributions to fairness. To handle the global nature of worst case objectives efficiently, we develop a stochastic learning algorithm that simplifies training without sacrificing performance. We also address the impact of outliers by introducing a robust variant of our method. Through theoretical analysis and extensive experiments on standard fairness benchmarks, we show that our methods not only connect naturally to existing fairness-through-reweighting approaches but also outperform strong baselines.},
  archive      = {J_TNNLS},
  author       = {Jing Li and Yinghua Yao and Yuangang Pan and Xuanqian Wang and Ivor W. Tsang and Xiuju Fu},
  doi          = {10.1109/TNNLS.2025.3586609},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {18005-18019},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Alpha and prejudice: Improving α-sized worst case fairness via intrinsic reweighting},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Game-theoretic constrained policy optimization for safe reinforcement learning. <em>TNNLS</em>, <em>36</em>(10), 17990-18004. (<a href='https://doi.org/10.1109/TNNLS.2025.3586603'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safe reinforcement learning (RL) aims to optimize the task performance with safety guarantees. One common modeling scheme to study safe RL problems is the constrained Markov decision process (CMDP). However, current safe RL methods within the CMDP framework face challenges in tradeoffs among various objectives and gradient conflicts of policy updating. To cope with these challenges, this article presents a novel safe RL approach called game-theoretic constrained policy optimization (GCPO). The proposed approach formulates the CMDP problem as a general-sum Markov game with multiple players, where a task player seeks to maximize the reward objective, while constraint players aim to minimize constraint objectives until they are fulfilled. By doing so, GCPO adopts the learning mode with multiple subpolicies, each aligned with a distinct objective, that collectively constitute the overall behavior of the agent. The learning convergence of the GCPO can be ensured with the contraction mapping to the Nash equilibrium. Furthermore, a novel dominant timescale update rule is presented for multiplayer policy learning to guarantee constraint satisfaction. The learning convergence and constraint satisfaction of GCPO are theoretically analyzed. Consequently, GCPO eliminates the necessity of tuning tradeoff parameters and mitigates gradient conflicts during multiobjective policy updating. Experimental results show that GCPO outperforms state-of-the-art safe RL algorithms in a quadrotor trajectory tracking task and various high-dimensional robot locomotion benchmarks. Moreover, GCPO exhibits robustness to diverse scales of task rewards and constraint costs without the need for intricate tradeoffs.},
  archive      = {J_TNNLS},
  author       = {Changxin Zhang and Xinglong Zhang and Yixing Lan and Hao Gao and Xin Xu},
  doi          = {10.1109/TNNLS.2025.3586603},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17990-18004},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Game-theoretic constrained policy optimization for safe reinforcement learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ABNN: Adaptive-gating binary neural network with dynamic activation quantization for industrial health status prediction. <em>TNNLS</em>, <em>36</em>(10), 17978-17989. (<a href='https://doi.org/10.1109/TNNLS.2025.3577620'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex industrial equipment plays a critical role in specific tasks within industrial edge scenarios. Predicting their health status accurately is essential to ensuring safety and reliability in the production process. However, real-world industrial edge scenarios often have limited resources and stringent real-time requirements, making it difficult to deploy high-precision deep learning models directly at the edge. To address this issue, this article proposes an efficient adaptive-gating binary neural network (ABNN). First, a trend-aware encoder (TAE) is proposed to optimize the binarization process of the input layer. Next, a learnable precision indicator (LPI) is proposed to adjust the inference precision level. Finally, an adaptive-gating convolution is proposed to improve the representational capabilities while maintaining the fitting ability without significantly increasing the computational cost. Additionally, a field-programmable gate array (FPGA) hardware accelerator is designed for the proposed network. ABNN achieves approximately a 7% improvement in accuracy and a 45% gain in efficiency compared to the baseline model.},
  archive      = {J_TNNLS},
  author       = {Lei Ren and Shixiang Li and Haiteng Wang and Yuanjun Laili},
  doi          = {10.1109/TNNLS.2025.3577620},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17978-17989},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {ABNN: Adaptive-gating binary neural network with dynamic activation quantization for industrial health status prediction},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised anomaly detection using restricted distribution transformation. <em>TNNLS</em>, <em>36</em>(10), 17966-17977. (<a href='https://doi.org/10.1109/TNNLS.2025.3583320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection (AD) is typically regarded as an unsupervised learning task, where the training data either do not contain any anomalous samples or contain only a few unlabeled anomalous samples. In fact, in many real scenarios such as fault diagnosis and disease detection, a small number of anomalous samples labeled by domain experts are often available during the training phase, which makes semi-supervised AD (SAD) more appealing, though the related study is quite limited. Existing semi-supervised AD methods directly add optimization terms of anomalous samples to the optimization objective of unsupervised AD (UAD), where the effects of the limited labeled anomalous data on the optimization process become trivial and they cannot fully contribute to the detection task. To cover the shortage, in this work, we propose a novel semi-supervised AD method to fully use the limited labeled anomalous data and further to boost detection performance. The proposed method learns a nonlinear transformation to project normal data into a compact target distribution and simultaneously to project exposed anomalous samples into another target distribution, where the two target distributions do not overlap each other. The goal is difficult to achieve because of the scarcity of anomalous samples. To address this problem, we propose to generate a large number of intermediate samples interpolating between normal and anomalous data and project them into a third target distribution lying between the aforementioned two target distributions. Empirical results on multiple benchmarks with varying domains demonstrate the superiority of our method over existing supervised and semi-supervised AD methods.},
  archive      = {J_TNNLS},
  author       = {Feng Xiao and Youqing Wang and S. Joe Qin and Jicong Fan},
  doi          = {10.1109/TNNLS.2025.3583320},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17966-17977},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Semi-supervised anomaly detection using restricted distribution transformation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TC3Net: Transformer and convolution coupled contrastive network for single image super-resolution. <em>TNNLS</em>, <em>36</em>(10), 17953-17965. (<a href='https://doi.org/10.1109/TNNLS.2025.3577669'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The convolutional neural network (CNN) and transformer have gained significant attention in the field of single image super-resolution (SISR), owing to their powerful capacity in nonlinear feature extraction. Nonetheless, these two types of approaches hold their own limitations. For instance, the interaction between convolutional kernels and image content is agnostic in CNN, while the computational complexity increases quadratically along with the spatial resolution in the transformer. To address these concerns, in this article, we propose a novel unified framework named transformer and convolution coupled contrastive network (TC3Net) for SISR, which holds a triple-branch structure to integrate the merits of both CNN and transformer. The proposed TC3Net is mainly composed of several stacked CNN feature extraction (CFE) blocks, transformer feature extraction (TFE) blocks, and coupled contrastive blocks (CCBs) for diverse feature extraction. Particularly, the CCB that consists of the coupled attention block (CAB) and the local-global feature extraction (LGFE) block is designed to fuse feature maps and extract coupled information for better image reconstruction. Moreover, a contrastive loss between the transformer and CNN feature maps is further introduced to enhance their discriminative characteristics and complement the fused features. Experimental results demonstrate that TC3Net outperforms several state-of-the-art (SOTA) methods in the aspect of achieving a better balance between model size and performance.},
  archive      = {J_TNNLS},
  author       = {Licheng Liu and Qibin Zhang and Tingyun Liu and C. L. Philip Chen},
  doi          = {10.1109/TNNLS.2025.3577669},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17953-17965},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {TC3Net: Transformer and convolution coupled contrastive network for single image super-resolution},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DashFusion: Dual-stream alignment with hierarchical bottleneck fusion for multimodal sentiment analysis. <em>TNNLS</em>, <em>36</em>(10), 17941-17952. (<a href='https://doi.org/10.1109/TNNLS.2025.3578618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis (MSA) integrates various modalities, such as text, image, and audio, to provide a more comprehensive understanding of sentiment. However, effective MSA is challenged by alignment and fusion issues. Alignment requires synchronizing both temporal and semantic information across modalities, while fusion involves integrating these aligned features into a unified representation. Existing methods often address alignment or fusion in isolation, leading to limitations in performance and efficiency. To tackle these issues, we propose a novel framework called dual-stream alignment with hierarchical bottleneck fusion (DashFusion). First, the dual-stream alignment module synchronizes multimodal features through temporal and semantic alignment. Temporal alignment employs cross-modal attention (CA) to establish frame-level correspondences among multimodal sequences. Semantic alignment ensures consistency across the feature space through contrastive learning. Second, supervised contrastive learning (SCL) leverages label information to refine the modality features. Finally, hierarchical bottleneck fusion (HBF) progressively integrates multimodal information through compressed bottleneck tokens, which achieves a balance between performance and computational efficiency. We evaluate DashFusion on three datasets: CMU-MOSI, CMU-MOSEI, and CH-SIMS. Experimental results demonstrate that DashFusion achieves state-of-the-art (SOTA) performance across various metrics, and ablation studies confirm the effectiveness of our alignment and fusion techniques. The codes for our experiments are available at https://github.com/ultramarineX/DashFusion},
  archive      = {J_TNNLS},
  author       = {Yuhua Wen and Qifei Li and Yingying Zhou and Yingming Gao and Zhengqi Wen and Jianhua Tao and Ya Li},
  doi          = {10.1109/TNNLS.2025.3578618},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17941-17952},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DashFusion: Dual-stream alignment with hierarchical bottleneck fusion for multimodal sentiment analysis},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Facilitating multiagent coordination relying on graph information representation. <em>TNNLS</em>, <em>36</em>(10), 17929-17940. (<a href='https://doi.org/10.1109/TNNLS.2025.3575196'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The popular multiagent reinforcement learning (MARL) methods primarily focus on exploring the capability of value functions to facilitate multiagent coordination. These MARL methods, following the centralized training with decentralized execution (CTDE) paradigm, tend to design ingenious network architectures while overlooking the impact of coordination through expanding local observation information. To tackle this deficiency, we model the multiagent systems (MASs) as a graph and use a graph neural network (GNN) to extract rich information between one agent and the others efficiently. Moreover, we propose a multigraph-neural-network information representation (MGIR) method that uses the power of GNN in local observation information extraction, enabling the acquisition of higher quality information. Specifically, multiple GNNs are used during centralized training to characterize the MAS from different perspectives and extract representations of latent variables. During distributed execution, these latent variables are leveraged to expand local observation information. Extensive comparative experiments substantiate that our proposed MGIR demonstrates superior coordination performance when compared with baseline methods. In addition, it can be flexibly integrated into various value function decomposition methods of MARL.},
  archive      = {J_TNNLS},
  author       = {Ye Wang and Jingjing Wang and Ruijie Zhu and Hang Fu and Jianrui Chen and C. L. Philip Chen},
  doi          = {10.1109/TNNLS.2025.3575196},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17929-17940},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Facilitating multiagent coordination relying on graph information representation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LCwmcaR: Learning cross-window cross-modality correlation-aware representation for human activity recognition. <em>TNNLS</em>, <em>36</em>(10), 17914-17928. (<a href='https://doi.org/10.1109/TNNLS.2025.3581226'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL)-based human activity recognition (HAR) has attracted considerable attention owing to its vast potential across various applications. Currently, HAR still faces two challenges. For one thing, existing methods neglect the spatial distribution information embedded in HAR signals and lack the ability to comprehensively model the spatial–temporal (ST) dependencies within HAR data, restricting them from effectively decoding human activity. For another thing, previous models generate feature representations for a sliding window of the sequence solely based on this window itself, without cross-window interaction learning, posing challenges to classifiers, such as perceptual aliasing or feature inconsistency issues. For that, we propose a novel cross-window and cross-modality correlation-aware framework, namely LCwmcaR, which is a dual-branch network that simultaneously models temporal- and spatial-level information using Mamba and convolutional neural network (CNN), respectively. Additionally, a learnable temporal 2-dimensionalization (LT2D) strategy is designed to encode low-level temporal patterns into high-level learnable image-liked 2-D space representations that integrate both local and global ST dependencies. Moreover, a cross-window correlation-aware feature representation generation (CrwcaFRGen) module, which correlates multiple windows representations within a batch at the attention level, is introduced to produce more robust features for the classifier. Experimental results on four public datasets demonstrate that the LCwmcaR outperforms state-of-the-art (SOTA) methods by a large margin.},
  archive      = {J_TNNLS},
  author       = {Zhuang Li and Jing Tao and Xintao Liu and Dahua Shou},
  doi          = {10.1109/TNNLS.2025.3581226},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17914-17928},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {LCwmcaR: Learning cross-window cross-modality correlation-aware representation for human activity recognition},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DVGMAE: Self-supervised dynamic variational graph masked autoencoder. <em>TNNLS</em>, <em>36</em>(10), 17901-17913. (<a href='https://doi.org/10.1109/TNNLS.2025.3583045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although contrastive self-supervised learning (SSL) on dynamic graphs has made significant success, the issue of heavy reliance on data augmentation and training tricks has been a persistent pain point. Generative SSL, especially masked autoencoders (MAEs) have recently produced promising results and can avoid these issues. However, the research on MAE in dynamic graphs remains largely unexplored due to the following challenges: 1) how to design an effective masking strategy for dynamic graphs? and 2) how to design a decoder to retain temporal dependency when graphs are perturbed? In this article, we propose DVGMAE, a novel dynamic variational graph masked autoencoder model to solve these challenges. DVGMAE simultaneously captures the evolving behaviors and topological features via an innovative masking strategy and an elaborate decoder. Specifically, we first implement a temporal-aware masking strategy on the edges of each snapshot based on the updated probabilities derived from historical mask information. This strategy mitigates potential masking bias in dynamic graphs. We then design a globally enhanced decoder to recover the temporal and spatial information of each snapshot. Extensive experiments demonstrate that DVGMAE outperforms the existing state-of-the-art on various tasks across different datasets.},
  archive      = {J_TNNLS},
  author       = {Mengzhou Gao and Xinxun Zhang and Pengfei Jiao and Tianpeng Li and Zhidong Zhao},
  doi          = {10.1109/TNNLS.2025.3583045},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17901-17913},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DVGMAE: Self-supervised dynamic variational graph masked autoencoder},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary neural architecture search for remote sensing image classification. <em>TNNLS</em>, <em>36</em>(10), 17886-17900. (<a href='https://doi.org/10.1109/TNNLS.2025.3579517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing scene classification is a vital task in remote sensing image analysis with significant application potential. In recent years, convolutional neural network (CNN)-based methods have shown remarkable promise in classifying remote sensing scene images. However, these methods often require extensive trial and error and rely heavily on expert knowledge. To address these challenges, this article proposes a novel neural architecture search (NAS) approach that automatically designs CNNs for remote sensing scene classification. Specifically, an evolutionary algorithm (EA) is employed to search for well-structured basic modules, which are then combined to construct a new architecture. To further enhance the search process, a new population generation strategy is introduced to promote diversity and mitigate premature convergence. Additionally, a random forest-based selection mechanism is utilized to identify high-quality individuals based on estimated fitness values, effectively reducing computational complexity. The proposed approach is evaluated on three benchmark remote sensing scene datasets and compared with several widely used CNNs. The experimental results demonstrate that the proposed approach can discover CNN architectures that not only surpass state-of-the-art performance but also achieve this with fewer parameters and lower search cost.},
  archive      = {J_TNNLS},
  author       = {Jing Liang and Genyue Liu and Ying Bi and Mingyuan Yu and Mengnan Liu and Yaochu Jin},
  doi          = {10.1109/TNNLS.2025.3579517},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17886-17900},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Evolutionary neural architecture search for remote sensing image classification},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). D2Fed: Federated semi-supervised learning with dual-role additive local training and dual-perspective global aggregation. <em>TNNLS</em>, <em>36</em>(10), 17871-17885. (<a href='https://doi.org/10.1109/TNNLS.2025.3587942'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated semi-supervised learning (FSSL) has recently emerged as a promising approach for enhancing the performance of federated learning (FL) using ubiquitous unlabeled data. However, this approach encounters challenges when learning a global model using both fully labeled and fully unlabeled clients. Previous works overlook the dissimilarities between labeled and unlabeled clients, predominantly using shared parameters for local training across these two types of clients, thereby inducing intertask interference during local training. Moreover, these works typically adopt a single-perspective aggregation strategy, primarily focusing on data-volume-aware aggregation (i.e., FedAvg), leading to a lack of comprehensive consideration in model aggregation. In this article, we propose a novel FSSL method termed $\text {D}^{{2}}\text {Fed}$ , which addresses these issues by rethinking the roles of labeled clients and unlabeled ones to mitigate intertask interference during local training and by integrating client-type-aware with data-volume-aware to provide a more comprehensive perspective for model aggregation. Specifically, in local training, our proposed $\text {D}^{{2}}\text {Fed}$ distinguishes between the primary and accessory roles of labeled and unlabeled clients, respectively, performing dual-role additive local training (DALT) accordingly. In global aggregation, $\text {D}^{{2}}\text {Fed}$ uses a dual-perspective global aggregation (DGA) strategy, transitioning from data-volume-aware aggregation to client-type-aware aggregation. The proposed method simultaneously improves both local training and global model aggregation for FSSL without compromising privacy. We demonstrate the effectiveness and robustness of the proposed method through extensive experiments and elaborate ablation studies conducted on the CIFAR-10/100, SVHN, FMNIST, and STL-10 datasets. Experimental results show that $\text {D}^{{2}}\text {Fed}$ outperforms state-of-the-arts on five datasets under diverse data settings.},
  archive      = {J_TNNLS},
  author       = {Jingxin Mao and Yu Yang and Zhiwei Wei and Yanlong Bi and Rongqing Zhang},
  doi          = {10.1109/TNNLS.2025.3587942},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17871-17885},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {D2Fed: Federated semi-supervised learning with dual-role additive local training and dual-perspective global aggregation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive weighted metric learning network based on fractional domain decoupling for hyperspectral change detection. <em>TNNLS</em>, <em>36</em>(10), 17856-17870. (<a href='https://doi.org/10.1109/TNNLS.2025.3586714'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image change detection (HSI-CD) possesses strong capabilities in exploring subtle changes in land cover. Due to sensor noise and imaging conditions, different semantic land covers in the same spatial location may exhibit similar spectral characteristics, leading to pseudoinvariant phenomena (identification of changed areas as unchanged areas) and causing a higher rate of false negatives in the model. Existing methods primarily focus on obtaining auxiliary discriminative information from spatial correlations or temporal dependencies. However, the frequency domain, which possesses rich global gradient distribution information, is often overlooked. The fractional Fourier transform (FrFT) is an extension of the Fourier transform (FT), representing a temporal-frequency local transformation suitable for processing nonstationary signals. Furthermore, multiorder fractional Fourier domains provide more observable domains for change discrimination. In this work, the application of FrFT is extended to the field of HSI-CD, and an adaptive weighted metric learning network based on fractional domain decoupling (FrFTML) is proposed. Specifically, the fractional domain decoupling (FrDD) module transforms the original HSI into multiorder FrFT domains and extracts their rich spatial-frequency mixed information, effectively suppressing noise while enhancing the representation of subtle differences. In addition, an adaptive weighted metric learning (AWML) framework is designed to merge multiorder fractional Fourier domain information in an adaptively weighted fusion manner. It introduces deep metric learning to explore the distances between samples of different categories that have relatively high similarity, so as to guide the direction of adaptive weighted fusion. Finally, the differential mask attention (DMA) module is designed to explore global contextual differences between bitemporal HSIs, obtaining change features with well-represented differences. Some experiments conducted on three public datasets indicate that FrFTML outperforms other state-of-the-art methods. Furthermore, the proposed method exhibits superiority in dealing with land cover that may lead to pseudoinvariant phenomena (identification of changed areas as unchanged areas).},
  archive      = {J_TNNLS},
  author       = {Shou Feng and Tianyu Lan and Yuanze Fan and Mengmeng Zhang and Chunhui Zhao and Wei Li and Ran Tao},
  doi          = {10.1109/TNNLS.2025.3586714},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17856-17870},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {An adaptive weighted metric learning network based on fractional domain decoupling for hyperspectral change detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). M4CXR: Exploring multitask potentials of multimodal large language models for chest X-ray interpretation. <em>TNNLS</em>, <em>36</em>(10), 17841-17855. (<a href='https://doi.org/10.1109/TNNLS.2025.3587687'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid evolution of artificial intelligence, especially in large language models (LLMs), has significantly impacted various domains, including healthcare. In chest X-ray (CXR) analysis, previous studies have employed LLMs, but with limitations: either underutilizing the LLMs’ capability for multitask learning or lacking clinical accuracy. This article presents M4CXR, a multimodal LLM designed to enhance CXR interpretation. The model is trained on a visual instruction-following dataset that integrates various task-specific datasets in a conversational format. As a result, the model supports multiple tasks such as medical report generation (MRG), visual grounding, and visual question answering (VQA). M4CXR achieves state-of-the-art clinical accuracy in MRG by employing a chain-of-thought (CoT) prompting strategy, in which it identifies findings in CXR images and subsequently generates corresponding reports. The model is adaptable to various MRG scenarios depending on the available inputs, such as single-image, multiimage, and multistudy contexts. In addition to MRG, M4CXR performs visual grounding at a level comparable to specialized models and demonstrates outstanding performance in VQA. Both quantitative and qualitative assessments reveal M4CXR’s versatility in MRG, visual grounding, and VQA, while consistently maintaining clinical accuracy.},
  archive      = {J_TNNLS},
  author       = {Jonggwon Park and Soobum Kim and Byungmu Yoon and Jihun Hyun and Kyoyun Choi},
  doi          = {10.1109/TNNLS.2025.3587687},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17841-17855},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {M4CXR: Exploring multitask potentials of multimodal large language models for chest X-ray interpretation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated fine-tuning on heterogeneous LoRAs with error-compensated aggregation. <em>TNNLS</em>, <em>36</em>(10), 17826-17840. (<a href='https://doi.org/10.1109/TNNLS.2025.3586545'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) has recently been applied to the parameter-efficient fine-tuning (PEFT) of large language models (LLMs). While promising, client resource heterogeneity has imposed the challenge of the “bucket effect” to FL, where model configuration must cater to the client with the fewest resources. To tackle this issue, heterogeneous low-rank adaptation (LoRA) has recently emerged in FL, which enables clients to do local fine-tuning with different LoRA ranks. However, existing works in this area typically adopt zero-padding, stacking, or singular value decomposition (SVD) for LoRA aggregation, which often incur precision loss or significant overhead, limiting their practicality. In this article, we propose ECLoRA, a novel method for federated fine-tuning with heterogeneous LoRA settings across clients. ECLoRA employs randomized SVD (RSVD) to dramatically reduce aggregation overhead while introducing an error compensation (EC) mechanism that incorporates the decomposition error from previous rounds to improve aggregation precision. Extensive experiments on four widely used foundation models across six public tasks demonstrate the effectiveness of ECLoRA. Specifically, ECLoRA is: (1) accurate, significantly improving the final model performance; (2) fast, accelerating convergence with an average speedup of $1.54\times $ to $3.01\times $ ; and (3) practical, reducing aggregation time by approximately $40\times $ compared to classical SVD.},
  archive      = {J_TNNLS},
  author       = {Wanyi Ning and Jingyu Wang and Qi Qi and Haifeng Sun and Daixuan Cheng and Cong Liu and Lei Zhang and Zirui Zhuang and Jianxin Liao},
  doi          = {10.1109/TNNLS.2025.3586545},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17826-17840},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Federated fine-tuning on heterogeneous LoRAs with error-compensated aggregation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PolicyMamba: Localized policy attention with state space model for land cover classification. <em>TNNLS</em>, <em>36</em>(10), 17814-17825. (<a href='https://doi.org/10.1109/TNNLS.2025.3586836'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multihead self-attention and cross-attention mechanisms often suffer from computational inefficiencies, limited scalability, and suboptimal contextual understanding, particularly in hyperspectral image (HSI) classification. These mechanisms struggle to effectively capture long-range dependencies while maintaining computational feasibility due to the quadratic complexity of self-attention. To address these challenges, this work proposes PolicyMamba, a spectral–spatial mamba model enhanced with a localized policy attention mechanism. This mechanism reduces computational overhead by restricting attention to nonoverlapping localized regions and enforcing sparsity constraints, ensuring that only the most informative interactions are retained. A hierarchical aggregation strategy further integrates patch-wise attention outputs, preserving spectral–spatial correlations across scales. In addition, a sliding window patch process enhances local feature continuity while mitigating information loss. The PolicyMamba framework integrates spectral–spatial token generation, token enhancement, localized attention, and state transition modules, significantly improving HSI feature representation. Extensive experiments demonstrate that PolicyMamba achieves superior classification accuracy, outperforming conventional and state-of-the-art methods in land cover classification (LCC) by efficiently modeling intricate dependencies in HSI data.},
  archive      = {J_TNNLS},
  author       = {Muhammad Ahmad and Manuel Mazzara and Salvatore Distefano and Adil Mehmood Khan and Muhammad Hassaan Farooq Butt and Danfeng Hong},
  doi          = {10.1109/TNNLS.2025.3586836},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17814-17825},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {PolicyMamba: Localized policy attention with state space model for land cover classification},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive learning framework with cross-sensor adaptive signal representation for fault diagnosis. <em>TNNLS</em>, <em>36</em>(10), 17801-17813. (<a href='https://doi.org/10.1109/TNNLS.2025.3582858'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although multisource sensor (MS) signal-based mechanical fault diagnosis (MFD) can significantly improve the diagnostic performance, the existing methods often lack sufficient adaptability and generalization when retraining on single-sensor signals or inferring from partial sensor signals. Thus, a general two-stage signal representation contrastive learning fault diagnosis framework (T-SCF) is proposed to adapt the trained model to varying numbers of sensor signals. This framework enhances model robustness and data fusion by comparing sensor signal views, offering a new approach for information fusion, fault detection, and classification in MFD. In the first stage, an adaptive contrastive algorithm is proposed to generate contrastive samples (C-Ss) and contrastive labels (C-Ls) for MS signals. Then, a supervised contrastive loss (SCL) is designed to minimize the similarity between different fault MS signals while maximizing the similarity between identical ones. By designing a parallel encoder architecture, SCL enables it to merge contrasting the features of different sensor signals during training. This strategy preserves the time-domain dimension properties of different sensors during the training of the second-stage classifier, thereby improving the adaptability of the model to different sensor signals without affecting the global information. The effectiveness of the method was verified from multiple different evaluation dimensions using two public datasets and one self-built dataset.},
  archive      = {J_TNNLS},
  author       = {Wenbin He and Jianxu Mao and Yaonan Wang and Zhe Li and Hui Zhang},
  doi          = {10.1109/TNNLS.2025.3582858},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17801-17813},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Contrastive learning framework with cross-sensor adaptive signal representation for fault diagnosis},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed model-free adaptive learning control of discrete-time nonlinear multiagent systems. <em>TNNLS</em>, <em>36</em>(10), 17791-17800. (<a href='https://doi.org/10.1109/TNNLS.2025.3575423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the distributed control problem for nonlinear multiagent systems (MASs) with unknown system models. A novel distributed model-free adaptive learning algorithm is developed to learn a controller from the online system data. Notably, a significant advancement over conventional methods is that the proposed algorithm requires only local interaction data from neighboring agents, eliminating dependencies on both a priori system structural knowledge and global topology information. Comprehensive simulations validate the theoretical results and demonstrate the superior efficacy of the devised algorithm.},
  archive      = {J_TNNLS},
  author       = {Yong-Sheng Ma and Wei-Wei Che and Shi-Xu Xu and Chao Deng and Zheng-Guang Wu},
  doi          = {10.1109/TNNLS.2025.3575423},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17791-17800},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Distributed model-free adaptive learning control of discrete-time nonlinear multiagent systems},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SFBM: Shared feature bias mitigating for long-tailed image recognition. <em>TNNLS</em>, <em>36</em>(10), 17781-17790. (<a href='https://doi.org/10.1109/TNNLS.2025.3586215'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-tailed distribution exists in real-world scenario and compromises the performance of recognition models. In this article, we point out that a neural network classifier has a shared feature bias, which tends to regard the shared features among different classes as head-class discriminative features, leading to misclassifications on tail-class samples under long-tailed scenarios. To solve this issue, we propose a shared feature bias mitigating (SFBM) framework. Specifically, we create two parallel classifiers trained concurrently with the baseline classifier, using our special training loss. The parallel classifier weight sums are then used for estimating the shared feature components in baseline classifier weights. Finally, we rectify the baseline classifier by removing the estimated shared feature components from it while supplementing the parallel classifier weights class by class to the rectified classifier weights, mitigating shared feature bias. Our proposed SFBM demonstrates broad compatibility with nearly all recognition methods while maintaining high computational efficiency, as it introduces no additional computation during inference. Extensive experiments on CIFAR10/100-LT, ImageNet-LT, and iNaturalist 2018 demonstrate that simply incorporating SFBM during the training phase consistently boosts the performance of various state-of-the-art methods by significant margins. The complete source code will be made publicly available at https://github.com/bzbz-bot/SFBM},
  archive      = {J_TNNLS},
  author       = {Xinqiao Zhao and Mingjie Sun and Eng Gee Lim and Yao Zhao and Jimin Xiao},
  doi          = {10.1109/TNNLS.2025.3586215},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17781-17790},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SFBM: Shared feature bias mitigating for long-tailed image recognition},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial–Spectral heterogeneity-aware network for hyperspectral and LiDAR joint classification. <em>TNNLS</em>, <em>36</em>(10), 17766-17780. (<a href='https://doi.org/10.1109/TNNLS.2025.3577231'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of hyperspectral (HS) imagery and light detection and ranging (LiDAR) data for land cover classification has emerged as a prominent research focus. Despite the satisfactory classification accuracies achieved by existing methodologies, several unaddressed issues that remain warrant consideration. First, current approaches overlook the pronounced spectral and spatial heterogeneities in remote sensing (RS) images designated for multiclassification tasks, limiting the performance of classification models. Moreover, most existing studies amalgamate elevation features with other characteristics through simple addition and interaction operations, and they do not delve deeply into exploiting elevation height information, leading to an imbalance in the representation of elevation height. In light of the aforementioned issues, this article introduces a spatial–spectral heterogeneity-aware network (S2HANet) for the joint classification of HS and LiDAR data. Specifically, a shared spectral correction module (SSCM) is designed in the spectral branch to preliminarily alleviate the problem of large intraclass variance, followed by the use of a contrastive learning framework to enhance the intraclass compactness and interclass separability of spectral features. A multichannel signed distance discrimination module (MCSDDM) is developed to learn the distance relationships between intra- and interclass pixels and boundaries, and using prior boundary information to improve spatial boundary information. In addition, an elevation boost module (EBM) and an elevation injection module (EIM) are meticulously designed to phase-in elevation height information, further enhancing the utilization of elevation data and better facilitating the fusion of the two modalities. The proposed S2HANet has demonstrated exceptional classification performance across three opening benchmark datasets.},
  archive      = {J_TNNLS},
  author       = {Shenfu Zhang and Qiang Liu and Zhenhua Zhang and Rui Zhao and Liang Chen and Feng Shao and Xiangchao Meng},
  doi          = {10.1109/TNNLS.2025.3577231},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17766-17780},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Spatial–Spectral heterogeneity-aware network for hyperspectral and LiDAR joint classification},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EEG-based emotion monitoring and regulation system by learning the discriminative brain network manifold. <em>TNNLS</em>, <em>36</em>(10), 17751-17765. (<a href='https://doi.org/10.1109/TNNLS.2025.3576182'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition based on electroencephalogram (EEG) is fundamentally associated with human-like intelligence system. However, due to the noise-sensitive characteristics of EEGs and the individual variability of emotions, it is very challenging to extract inherent emotion dependent patterns from emotional EEG signals. In this work, we propose a L1-norm space defined discriminative brain network manifold learning model (L1-SGL), in which the EEG noise outliers can be effectively separated and the pseudolabeled samples caused by subjective feelings can be automatically corrected. Off-line experimental results consistently indicate that the L1-SGL can effectively suppress the influence of noise and achieve an incomparable superiority performance over other existing methods in EEG emotion recognition. Besides, benefiting from the time efficiency of the L1-SGL, an online emotion monitoring and regulation system is further implemented in this work. On-line emotion decoding experimental results (86.30%) of 25 participants prove that the L1-SGL can effectively satisfy the real-time requirements of on-line emotional monitoring applications, and the significant negative emotion regulation experimental results ( $p \lt 0.001$ ) further confirm the feasibility and effectiveness of L1-SGL model in real-time emotion regulation and interactive applications. Overall, the L1-SGL provides a promising solution for the real-time online affective brain-computer interfaces (aBCIs) and the intelligent clinical closed-loop treatments.},
  archive      = {J_TNNLS},
  author       = {Cunbo Li and Zehong Cao and Yue Pan and Pengcheng Zhu and Peiyang Li and Fali Li and Huafu Chen and Bao-Liang Lu and Feng Wan and Dezhong Yao and Peng Xu},
  doi          = {10.1109/TNNLS.2025.3576182},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17751-17765},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {EEG-based emotion monitoring and regulation system by learning the discriminative brain network manifold},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AFSPrompt: An axiomatic fuzzy set prompt pipeline for knowledge-based VQA. <em>TNNLS</em>, <em>36</em>(10), 17738-17750. (<a href='https://doi.org/10.1109/TNNLS.2025.3573267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the impressive few-shot performance of in-context learning (ICL) in knowledge-based visual question answering (VQA), existing research often prioritizes addressing the image information gap in VQA, while placing less emphasis on organizing appropriate demonstrations (e.g., in-context examples) to support this task. Recent studies, however, have shown that ICL performance is sensitive to the organization of demonstrations. To address this, we introduce axiomatic fuzzy set (AFS) theory into knowledge-based VQA, leveraging its unsupervised and interpretable nature to effectively organize demonstrations by describing each candidate with semantic concepts, thereby enhancing both the understanding and trustworthiness of the decision-making process. In this article, we propose AFSPrompt, a train-free example selection and ranking framework based on AFS theory for knowledge-based VQA tasks. After filtering irrelevant examples using multimodal embeddings, we apply AFS logic to integrate comparison information from candidates with multidimensional features. Furthermore, to reduce reliance on large-scale language model APIs such as OpenAI and facilitate model deployment, we employ a smaller 7B LLM as the knowledge engine to answer questions based on the optimized prompt. Through extensive evaluations of two datasets, we demonstrate the effectiveness of AFSPrompt within a lightweight pipeline for knowledge-based VQA tasks. Our code is publicly available at https://github.com/afs001/AFSPrompt},
  archive      = {J_TNNLS},
  author       = {Zhiwei Wang and Qi Lang and Xiaodong Liu and Hao Zhang},
  doi          = {10.1109/TNNLS.2025.3573267},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17738-17750},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {AFSPrompt: An axiomatic fuzzy set prompt pipeline for knowledge-based VQA},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on text-guided 3-D visual grounding: Elements, recent advances, and future directions. <em>TNNLS</em>, <em>36</em>(10), 17717-17737. (<a href='https://doi.org/10.1109/TNNLS.2025.3584895'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-guided 3-D visual grounding (T-3DVG), which aims to locate a specific object that semantically corresponds to a language query from a complicated 3-D scene, has drawn increasing attention in the 3-D research community over the past few years. Compared to 2-D visual grounding, this task presents great potential and challenges due to its closer proximity to the real world, the complexity of data collection, and 3-D point cloud source processing. In this survey, we attempt to provide a comprehensive overview of the T-3DVG progress, including its fundamental elements, recent research advances, and future research directions. To the best of our knowledge, this is the first systematic survey on the T-3DVG task. Specifically, we first provide a general structure of the T-3DVG pipeline with detailed components in a tutorial style, presenting a complete background overview. Then, we summarize the existing T-3DVG approaches into different categories and analyze their strengths and weaknesses. We also present the benchmark datasets and evaluation metrics to assess their performances. Finally, we discuss the potential limitations of existing T-3DVG and share some insights on several promising research directions.},
  archive      = {J_TNNLS},
  author       = {Daizong Liu and Yang Liu and Wencan Huang and Wei Hu},
  doi          = {10.1109/TNNLS.2025.3584895},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17717-17737},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A survey on text-guided 3-D visual grounding: Elements, recent advances, and future directions},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypergraph foundation model for brain disease diagnosis. <em>TNNLS</em>, <em>36</em>(10), 17702-17716. (<a href='https://doi.org/10.1109/TNNLS.2025.3554755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of the hypergraph foundation model (HGFM) is to learn an encoder based on the hypergraph computational paradigm through self-supervised pretraining on high-order correlation structures, enabling the encoder to rapidly adapt to various downstream tasks in scenarios, where no labeled data or only a small amount of labeled data are available. The initial exploratory work has been applied to brain disease diagnosis tasks. However, existing methods primarily rely on graph-based approaches to learn low-order correlation patterns between brain regions in brain networks, neglecting the modeling and learning of complex correlations between different brain diseases and patients. This article proposes an HGFM for brain disease diagnosis, which conducts multidimensional pretraining tasks to explore latent cross-dimensional high-order correlation patterns on various brain disease datasets. HGFM is a high-order correlation-driven foundation model for brain disease diagnosis and effectively improves prediction performance. Specifically, HGFM first performs brain functional network link prediction tasks on individual brain networks and group interaction network link prediction tasks on group brain networks, constructing an HGFM for brain disease diagnosis. In downstream tasks, it achieves predictions for different brain disease diagnosis tasks through few-shot learning fine-tuning methods. The proposed method is evaluated on functional magnetic resonance imaging (fMRI) data from 4409 patients across four brain diseases. Results show that it outperforms existing state-of-the-art methods in all brain disease diagnosis tasks, demonstrating its potential value in clinical applications.},
  archive      = {J_TNNLS},
  author       = {Xiangmin Han and Rundong Xue and Jingxi Feng and Yifan Feng and Shaoyi Du and Jun Shi and Yue Gao},
  doi          = {10.1109/TNNLS.2025.3554755},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17702-17716},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Hypergraph foundation model for brain disease diagnosis},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retrieval-augmented few-shot medical image segmentation with foundation models. <em>TNNLS</em>, <em>36</em>(10), 17693-17701. (<a href='https://doi.org/10.1109/TNNLS.2025.3568479'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation is crucial for clinical decision-making, but the scarcity of annotated data presents significant challenges. Few-shot segmentation (FSS) methods show promise but often require training on the target domain and struggle to generalize across different modalities. Similarly, adapting foundation models such as the segment anything model (SAM) for medical imaging has limitations, including the need for fine-tuning and domain-specific adaptation. To address these issues, we propose a novel method that adapts DINOv2 and SAM 2 for retrieval-augmented few-shot medical image segmentation. Our approach uses DINOv2’s feature as query to retrieve similar samples from limited annotated data, which are then encoded as memories and stored in memory bank. With the memory attention mechanism of SAM 2, the model leverages these memories as conditions to generate accurate segmentation of the target image. We evaluated our framework on three medical image segmentation tasks, demonstrating superior performance and generalizability across various modalities without the need for any retraining or fine-tuning. Overall, this method offers a practical and effective solution for few-shot medical image segmentation and holds significant potential as a valuable annotation tool in clinical applications.},
  archive      = {J_TNNLS},
  author       = {Lin Zhao and Xiao Chen and Eric Z. Chen and Yikang Liu and Terrence Chen and Shanhui Sun},
  doi          = {10.1109/TNNLS.2025.3568479},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17693-17701},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Retrieval-augmented few-shot medical image segmentation with foundation models},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Argus: Leveraging multiview images for improved 3-D scene understanding with large language models. <em>TNNLS</em>, <em>36</em>(10), 17679-17692. (<a href='https://doi.org/10.1109/TNNLS.2025.3581411'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in foundation models have made it possible to conduct applications in various downstream tasks. Especially, the new era has witnessed a remarkable capability to extend large language models (LLMs) for tackling tasks of 3-D scene understanding. Current methods rely heavily on 3-D point clouds, but the 3-D point cloud reconstruction of an indoor scene often results in information loss. Some textureless planes or repetitive patterns are prone to omission and manifest as voids within the reconstructed 3-D point clouds. Besides, objects with complex structures tend to introduce distortion of details caused by misalignments between the captured images and the dense reconstructed point clouds. The 2-D multiview images present visual consistency with 3-D point clouds and provide more detailed representations of scene components, which can naturally compensate for these deficiencies. Based on these insights, we propose Argus, a novel 3-D multimodal framework that leverages multiview images for enhanced 3-D scene understanding with LLMs. In general, Argus can be treated as a 3-D large multimodal foundation model (3D-LMM) since it takes various modalities as input (text instructions, 2-D multiview images, and 3-D point clouds) and expands the capability of LLMs to tackle 3-D tasks. Argus involves fusing and integrating multiview images and camera poses into view-as-scene features, which interact with the 3-D features to create comprehensive and detailed 3-D-aware scene embeddings. Our approach compensates for the information loss while reconstructing 3-D point clouds and helps LLMs better understand the 3-D world. Extensive experiments demonstrate that our method outperforms existing 3D-LMMs in various downstream tasks.},
  archive      = {J_TNNLS},
  author       = {Yifan Xu and Chao Zhang and Hanqi Jiang and Xiaoyan Wang and Ruifei Ma and Yiwei Li and Zihao Wu and Zeju Li and Xiangde Liu},
  doi          = {10.1109/TNNLS.2025.3581411},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17679-17692},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Argus: Leveraging multiview images for improved 3-D scene understanding with large language models},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DMAE-EEG: A pretraining framework for EEG spatiotemporal representation learning. <em>TNNLS</em>, <em>36</em>(10), 17664-17678. (<a href='https://doi.org/10.1109/TNNLS.2025.3581991'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) plays a crucial role in neuroscience research and clinical practice, but it remains limited by nonuniform data, noise, and difficulty in labeling. To address these challenges, we develop a pretraining framework named DMAE-EEG, a denoising masked autoencoder for mining generalizable spatiotemporal representation from massive unlabeled EEG. First, we propose a novel brain region topological heterogeneity (BRTH) division method to partition the nonuniform data into fixed patches based on neuroscientific priors. Second, we design a denoised pseudo-label generator (DPLG), which utilizes a denoising reconstruction pretext task to enable the learning of generalizable representations from massive unlabeled EEG, suppressing the influence of noise and artifacts. Furthermore, we utilize an asymmetric autoencoder with self-attention as the backbone in the proposed DMAE-EEG, which captures long-range spatiotemporal dependencies and interactions from unlabeled EEG data across 14 public datasets. The proposed DMAE-EEG is validated on both generative (signal quality enhancement) and discriminative tasks (motion intention recognition). In the quality enhancement, DMAE-EEG outperforms existing statistical methods with normalized mean squared error (nMSE) reduction of 27.78%–50.00% under corruption levels of 25%, 50%, and 75%, respectively. In motion intention recognition, DMAE-EEG achieves a relative improvement of 2.71%–6.14% in intrasession classification balanced accuracy across 2–6 class motor execution and imagery tasks, outperforming state-of-the-art methods. Overall, the results suggest that the pretraining framework DMAE-EEG can capture generalizable spatiotemporal representations from massive unlabeled EEG and enhance the knowledge transferability across sessions, subjects, and tasks in various downstream scenarios, advancing EEG-aided diagnosis and brain–computer communication and control, and other clinical practice.},
  archive      = {J_TNNLS},
  author       = {Yifan Zhang and Yang Yu and Hao Li and Anqi Wu and Xin Chen and Jinfang Liu and Ling-Li Zeng and Dewen Hu},
  doi          = {10.1109/TNNLS.2025.3581991},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17664-17678},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DMAE-EEG: A pretraining framework for EEG spatiotemporal representation learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CPST-GAN: Conditional probabilistic state transition generative adversarial network with the biomedical large foundation models. <em>TNNLS</em>, <em>36</em>(10), 17650-17663. (<a href='https://doi.org/10.1109/TNNLS.2025.3539006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The risk prediction of Alzheimer’s disease (AD) is crucial for its early prevention and treatment. However, current risk prediction methods face challenges in effectively extracting and fusing multiomics features, particularly overlooking the multilevel evolutionary mechanisms of AD. This article combines biomedical large foundation models with the conditional generative adversarial network (GAN) to mine the evolutionary patterns of AD by considering the regulatory effect of genes on brain lesions. Specifically, we first use biomedical large foundation models to effectively construct high-quality imaging genetic features. Next, a conditional probabilistic state transition mathematical model is constructed to describe AD progression as state transitions of brain regions under genetic regulations. Based on the mathematical model, a conditional probabilistic state transition GAN (CPST-GAN) is proposed. This algorithm can mine the dynamic evolutionary patterns of AD by fusing brain imaging and genetic features to achieve risk prediction of AD. Finally, experiments on the public imaging genetics datasets validate the effectiveness and superiority of CPST-GAN in evolutionary pattern mining and risk prediction of AD. This article not only provides a reliable intelligence algorithm for early intervention of AD but also offers new insights for future research on AD pathogenesis. The code has been published at github.com/fmri123456/CPST-GAN.},
  archive      = {J_TNNLS},
  author       = {Qiong Wang and Luyun Xu and Yinglu Shan and Wenzhuo Shen and Lou Li and Xia-An Bi and Zhonghua Liu},
  doi          = {10.1109/TNNLS.2025.3539006},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17650-17663},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {CPST-GAN: Conditional probabilistic state transition generative adversarial network with the biomedical large foundation models},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ChatABL: Abductive learning via natural language interaction with ChatGPT. <em>TNNLS</em>, <em>36</em>(10), 17635-17649. (<a href='https://doi.org/10.1109/TNNLS.2025.3567945'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) such as ChatGPT have recently demonstrated significant potential in mathematical abilities, providing a valuable reasoning paradigm consistent with human natural language. However, LLMs currently have difficulty in bridging perception, language understanding, and reasoning (PLR) capabilities due to incompatibility of the underlying information flow among them, making their reasoning ability not fully elicited and challenging to accomplish complicated reasoning tasks autonomously. To resolve the above problem, a novel method called ChatABL is proposed by integrating LLMs into an abductive learning (ABL) framework, capable of unifying the three abilities effectively in a more user-friendly and understandable manner. Initially, the proposed method uses LLMs to correct the incomplete logical facts for optimizing the perception module, by summarizing and reorganizing domain knowledge represented in natural language format. Then, the perception module also provides necessary logical reasoning materials for feeding LLMs. Finally, these parts are integrated into a dynamic closed-loop system by introducing the feedback form and automatic learning strategies to mutually promote their performance. As a testbed, the variable-length handwritten equation decipherment (HED), an abstract expression of the Mayan calendar decoding, is used to demonstrate that ChatABL has reasoning ability beyond most existing state-of-the-art methods, which has been well-supported by comparative studies. To the best of authors’ knowledge, the proposed ChatABL is the first attempt to explore a possible and novel avenue to approaching human-level cognitive ability via natural language interaction by means of ChatGPT.},
  archive      = {J_TNNLS},
  author       = {Tianyang Zhong and Yi Pan and Yutong Zhang and Yaonai Wei and Li Yang and Zhengliang Liu and Xiaozheng Wei and Wenjun Li and Junjie Yao and Chong Ma and Xi Jiang and Dinggang Shen and Junwei Han and Tuo Zhang},
  doi          = {10.1109/TNNLS.2025.3567945},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17635-17649},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {ChatABL: Abductive learning via natural language interaction with ChatGPT},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond the hype: A dispassionate look at Vision–Language models in medical scenario. <em>TNNLS</em>, <em>36</em>(10), 17623-17634. (<a href='https://doi.org/10.1109/TNNLS.2025.3558857'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in large vision-language models (LVLMs) have demonstrated remarkable capabilities across diverse tasks, garnering significant attention in AI communities. However, their performance and reliability in specialized domains such as medicine remain insufficiently assessed. In particular, most assessments overconcentrate on evaluating VLMs based on simple visual question answering (VQA) on multimodality data while ignoring the in-depth characteristics of LVLMs. In this study, we introduce RadVUQA, a novel radiological visual understanding and question answering benchmark, to comprehensively evaluate existing LVLMs. RadVUQA mainly validates LVLMs across five dimensions: 1) anatomical understanding, assessing the models’ ability to visually identify biological structures; 2) multimodal comprehension, which involves the capability of interpreting linguistic and visual instructions to produce desired outcomes; 3) quantitative and spatial reasoning, evaluating the models’ spatial awareness and proficiency in combining quantitative analysis with visual and linguistic information; 4) physiological knowledge, measuring the models’ capability to comprehend functions and mechanisms of organs and systems; and 5) robustness, which assesses the models’ capabilities against unharmonized and synthetic data. The results indicate that both generalized LVLMs and medical-specific LVLMs have critical deficiencies with weak multimodal comprehension and quantitative reasoning capabilities. Our findings reveal the large gap between existing LVLMs and clinicians, highlighting the urgent need for more robust and intelligent LVLMs. The code is available at https://github.com/Nandayang/RadVUQA},
  archive      = {J_TNNLS},
  author       = {Yang Nan and Huichi Zhou and Xiaodan Xing and Guang Yang},
  doi          = {10.1109/TNNLS.2025.3558857},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17623-17634},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Beyond the hype: A dispassionate look at Vision–Language models in medical scenario},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RadCLIP: Enhancing radiologic image analysis through contrastive Language–Image pretraining. <em>TNNLS</em>, <em>36</em>(10), 17613-17622. (<a href='https://doi.org/10.1109/TNNLS.2025.3568036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of artificial intelligence (AI) with radiology signifies a transformative era in medicine. Vision foundation models have been adopted to enhance radiologic imaging analysis. However, the inherent complexities of 2D and 3D radiologic data present unique challenges that existing models, which are typically pretrained on general nonmedical images, do not adequately address. To bridge this gap and harness the diagnostic precision required in radiologic imaging, we introduce radiologic contrastive language–image pretraining (RadCLIP): a cross-modal vision-language foundational model that utilizes a vision-language pretraining (VLP) framework to improve radiologic image analysis. Building on the contrastive language–image pretraining (CLIP) approach, RadCLIP incorporates a slice pooling mechanism designed for volumetric image analysis and is pretrained using a large, diverse dataset of radiologic image-text pairs. This pretraining effectively aligns radiologic images with their corresponding text annotations, resulting in a robust vision backbone for radiologic imaging. Extensive experiments demonstrate RadCLIP’s superior performance in both unimodal radiologic image classification and cross-modal image-text matching, underscoring its significant promise for enhancing diagnostic accuracy and efficiency in clinical settings. Our key contributions include curating a large dataset featuring diverse radiologic 2D/3D image-text pairs, pretraining RadCLIP as a vision-language foundation model on this dataset, developing a slice pooling adapter with an attention mechanism for integrating 2D images, and conducting comprehensive evaluations of RadCLIP on various radiologic downstream tasks.},
  archive      = {J_TNNLS},
  author       = {Zhixiu Lu and Hailong Li and Nehal A. Parikh and Jonathan R. Dillman and Lili He},
  doi          = {10.1109/TNNLS.2025.3568036},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17613-17622},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {RadCLIP: Enhancing radiologic image analysis through contrastive Language–Image pretraining},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAM-Med3D: A vision foundation model for general-purpose segmentation on volumetric medical images. <em>TNNLS</em>, <em>36</em>(10), 17599-17612. (<a href='https://doi.org/10.1109/TNNLS.2025.3586694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing volumetric medical image segmentation models are typically task-specific, excelling at specific targets but struggling to generalize across anatomical structures or modalities. This limitation restricts their broader clinical use. In this article, we introduce segment anything model (SAM)-Med3D, a vision foundation model (VFM) for general-purpose segmentation on volumetric medical images. Given only a few 3-D prompt points, SAM-Med3D can accurately segment diverse anatomical structures and lesions across various modalities. To achieve this, we gather and preprocess a large-scale 3-D medical image segmentation dataset, SA-Med3D-140K, from 70 public datasets and 8K licensed private cases from hospitals. This dataset includes 22K 3-D images and 143K corresponding masks. SAM-Med3D, a promptable segmentation model characterized by its fully learnable 3-D structure, is trained on this dataset using a two-stage procedure and exhibits impressive performance on both seen and unseen segmentation targets. We comprehensively evaluate SAM-Med3D on 16 datasets covering diverse medical scenarios, including different anatomical structures, modalities, targets, and zero-shot transferability to new/unseen tasks. The evaluation demonstrates the efficiency and efficacy of SAM-Med3D, as well as its promising application to diverse downstream tasks as a pretrained model. Our approach illustrates that substantial medical resources can be harnessed to develop a general-purpose medical AI for various potential applications. Our dataset, code, and models are available at: https://github.com/uni-medical/SAM-Med3D},
  archive      = {J_TNNLS},
  author       = {Haoyu Wang and Sizheng Guo and Jin Ye and Zhongying Deng and Junlong Cheng and Tianbin Li and Jianpin Chen and Yanzhou Su and Ziyan Huang and Yiqing Shen and Bin Fu and Shaoting Zhang and Junjun He},
  doi          = {10.1109/TNNLS.2025.3586694},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17599-17612},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SAM-Med3D: A vision foundation model for general-purpose segmentation on volumetric medical images},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SRViT: Self-supervised relation-aware vision transformer for hyperspectral unmixing. <em>TNNLS</em>, <em>36</em>(10), 17585-17598. (<a href='https://doi.org/10.1109/TNNLS.2025.3571798'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision transformer (ViT) has recently been a popular topic in the foundation model field, taking advantage of its strong scalability and outstanding representation capabilities. As a deep model, ViT introduces a new architecture for achieving hyperspectral image (HSI) unmixing. However, traditional ViTs overlook pixel-level spatial continuity by partitioning the input image into nonoverlapping fixed-size patches. This approach disrupts local structural relationships and hinders the model’s ability to capture fine-grained spatial dependencies, resulting in suboptimal feature representation for dense prediction tasks in unmixing. To address these challenges, this article proposes the development of a self-supervised relation-aware ViT (SRViT). SRViT incorporates a self-embedded module comprising encoders, a pixel-level position encoder (PLPE), a self-supervised contrastive mechanism (SCM), and a decoder. The self-embedded module and PLPE preserve local correlations in HSI across different views, facilitating cross-view learning through SCM to ensure generalization. In addition, the decoder incorporates Kronecker-factored approximate curvature (K-FAC) to capture the local geometric structure of spectral information. Ultimately, SRViT learns endmembers and fractional abundance as the unmixing result. The effectiveness and competitiveness of SRViT have been systematically validated through comparative experiments, demonstrating its superior performance. The source code is available at the following link: https://github.com/yuanchaosu/TNNLS-SRViT},
  archive      = {J_TNNLS},
  author       = {Yuanchao Su and Lianru Gao and Antonio Plaza and Xu Sun and Mengying Jiang and Guang Yang},
  doi          = {10.1109/TNNLS.2025.3571798},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17585-17598},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SRViT: Self-supervised relation-aware vision transformer for hyperspectral unmixing},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncovering large language model weaknesses in character and word understanding and manipulating. <em>TNNLS</em>, <em>36</em>(10), 17570-17584. (<a href='https://doi.org/10.1109/TNNLS.2025.3575818'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, large language models (LLMs) have showcased remarkable capabilities across a diverse range of applications, including general natural language processing (NLP) and domain-specific tasks. Empirical evidence indicates that LLMs have matched or even surpassed human performance in various areas, such as language translation, reading comprehension, and logical reasoning. However, preliminary research reveals that LLMs struggle with basic character and word editing, which is crucial for practical tasks such as creating 1000-word articles or modifying specific text information. To comprehensively assess the capabilities of LLMs in character and word understanding and manipulation (CWUM), we introduce the CWUM benchmark in Chinese and English. CWUM comprises 23 tasks focusing on text editions, including counting, identification, insertion, and reversal. A comprehensive evaluation of nine advanced LLMs on CWUM is conducted, which highlights significant failures of existing LLMs on CWUM tasks that humans can solve perfectly with 100% accuracy. Meanwhile, specific deficiencies of LLMs in basic language understanding and manipulation are revealed by performing quality and quantity analysis. Furthermore, in the experiment part, various methods are investigated to improve model performance, demonstrating the effectiveness of supervised fine-tuning (SFT) in enhancing model performance on CWUM while maintaining generalization abilities on unseen tasks.},
  archive      = {J_TNNLS},
  author       = {Yidan Zhang and Zhenan He and Gary G. Yen},
  doi          = {10.1109/TNNLS.2025.3575818},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17570-17584},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Uncovering large language model weaknesses in character and word understanding and manipulating},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fed-HeLLo: Efficient federated foundation model fine-tuning with heterogeneous LoRA allocation. <em>TNNLS</em>, <em>36</em>(10), 17556-17569. (<a href='https://doi.org/10.1109/TNNLS.2025.3580495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) has recently been used to collaboratively fine-tune foundation models (FMs) across multiple clients. Notably, federated low-rank adaptation (LoRA)-based fine-tuning methods have recently gained attention, which allows clients to fine-tune FMs with a small portion of trainable parameters locally. However, most existing methods do not account for the heterogeneous resources of clients or lack an effective local training strategy to maximize global fine-tuning performance under limited resources. In this work, we propose federated LoRA-based fine-tuning framework with heterogeneous LoRA allocation (Fed-HeLLo), a novel federated LoRA-based fine-tuning framework that enables clients to collaboratively fine-tune an FM with different local trainable LoRA layers. To ensure its effectiveness, we develop several heterogeneous LoRA allocation (HLA) strategies that adaptively allocate local trainable LoRA layers based on clients’ resource capabilities and the layer importance. Specifically, based on the dynamic layer importance, we design a Fisher information matrix score-based HLA (FIM-HLA) that leverages dynamic gradient norm information. To better stabilize the training process, we consider the intrinsic importance of LoRA layers and design a geometrically defined HLA (GD-HLA) strategy. It shapes the collective distribution of trainable LoRA layers into specific geometric patterns, such as triangle, inverted triangle, bottleneck, and uniform. Moreover, we extend GD-HLA into a randomized version, named randomized GD-HLA (RGD-HLA), for enhanced model accuracy with randomness. By codesigning the proposed HLA strategies, we incorporate both the dynamic and intrinsic layer importance into the design of our HLA strategy. To thoroughly evaluate our approach, we simulate various complex federated LoRA-based fine-tuning settings using five datasets and three levels of data distributions ranging from independent identically distributed (i.i.d.) to extreme non-i.i.d. The experimental results demonstrate the effectiveness and efficiency of Fed-HeLLo with the proposed HLA strategies. The code is available at https://github.com/ TNI-playground/Fed_HeLLo},
  archive      = {J_TNNLS},
  author       = {Zikai Zhang and Ping Liu and Jiahao Xu and Rui Hu},
  doi          = {10.1109/TNNLS.2025.3580495},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17556-17569},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Fed-HeLLo: Efficient federated foundation model fine-tuning with heterogeneous LoRA allocation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSAFF: Multi-way soft attention fusion framework with the large foundation models for the diagnosis of alzheimer’s disease. <em>TNNLS</em>, <em>36</em>(10), 17541-17555. (<a href='https://doi.org/10.1109/TNNLS.2025.3545101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complementary information in multi-omics data are crucial for understanding the pathogenesis of Alzheimer’s Disease (AD). However, existing studies face challenges in addressing the high-level noise and heterogeneity in multi-omics data. This article presents a novel approach that combines large foundation models (LFMs) with soft attention mechanisms to enhance, select, and fuse multi-omics features, thereby improving the performance of disease classification. Specifically, we first propose a mathematical model based on soft attention mechanisms. This model employs multi-head attention (MHA) and self-attention (SA) for feature selection, and uses cross-attention (CA) for feature fusion. Then, a multi-way soft attention fusion framework (MSAFF) with LFMs is proposed. In this approach, biomedical LFMs are used to construct low-noise biomedical features. The multi-way soft attention algorithm implements effective feature selection and fusion described in the mathematical model. Experimental results on the public imaging genetics datasets demonstrate the advanced performances of MSAFF in both disease classification and AD-related pathogeny discrimination. This article provides intelligent support for the diagnosis and pathogenesis research of AD. Our code can be accessed at github.com/fmri123456/MSAFF.},
  archive      = {J_TNNLS},
  author       = {Xia-An Bi and Wenzhuo Shen and Yinglu Shan and Dayou Chen and Luyun Xu and Ke Chen and Zhonghua Liu},
  doi          = {10.1109/TNNLS.2025.3545101},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17541-17555},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {MSAFF: Multi-way soft attention fusion framework with the large foundation models for the diagnosis of alzheimer’s disease},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal modeling with frozen Vision–Language foundation models for parameter-efficient Text–Video retrieval. <em>TNNLS</em>, <em>36</em>(10), 17527-17540. (<a href='https://doi.org/10.1109/TNNLS.2025.3605657'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal modeling plays an important role in the effective adaption of the powerful pretrained text–image foundation model into text–video retrieval. However, existing methods often rely on additional heavy trainable modules, such as transformer or BiLSTM, which are inefficient. In contrast, we avoid introducing such heavy components by leveraging frozen foundation models. To this end, we propose temporal modeling with frozen vision–language foundation models (TFVL) to model the temporal dynamics with fixed encoders. Specifically, text encoder temporal modeling (TextTemp) and image encoder temporal modeling (ImageTemp) apply frozen text and image encoders within the video head and video backbone, respectively. TextTemp uses a frozen text encoder to interpret frame representations as “visual words” within a temporal “sentence,” capturing temporal dependencies. On the other hand, ImageTemp uses a frozen image encoder to treat all frame tokens as a unified visual entity, learning spatiotemporal information. The total trainable parameters of our method, comprising a lightweight projection and several prompt tokens, are significantly fewer than those in other existing methods. We evaluate the effectiveness of our method on MSR-VTT, DiDeMo, ActivityNet, and LSMDC. Compared with full fine-tuning on MSR-VTT, our TFVL achieves an average 3.25% gain in R@1 with merely 0.35% of the parameters. Extensive experiments demonstrate that the proposed TFVL outperforms state-of-the-art methods with significantly fewer parameters.},
  archive      = {J_TNNLS},
  author       = {Leqi Shen and Tianxiang Hao and Tao He and Yifeng Zhang and Pengzhang Liu and Sicheng Zhao and Jungong Han and Guiguang Ding},
  doi          = {10.1109/TNNLS.2025.3605657},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  number       = {10},
  pages        = {17527-17540},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Temporal modeling with frozen Vision–Language foundation models for parameter-efficient Text–Video retrieval},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
