<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TROB</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="trob">TROB - 165</h2>
<ul>
<li><details>
<summary>
(2025). Human-like robot action policy through game-theoretic intent inference for Human–Robot collaboration. <em>TROB</em>, <em>41</em>, 5411-5430. (<a href='https://doi.org/10.1109/TRO.2025.3603556'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Harmonious human–robot collaboration requires the robot to behave like a human partner, which raises the critical question of what factors make the robot do so. This article proposes a series of policies based on empathetic and nonempathetic intent inference, proactive and reactive action planning, and ego and nonego action styles to examine, which modules enable robots to exhibit human-like behaviors. Two series of experiments are conducted with human subjects to test the performance of the proposed controllers. In Experiment 1, the participant must identify whether the collaborating partner is a human, similar to a turing test. The classification results empirically verify that the designed empathetic proactive policies enable the robot to exhibit human-like behaviors. Experiment 2 indicates that the proposed policy can be applied to complex collaborative tasks, and this result is consistent with the findings of Experiment 1. From empirical evidence from the experiments, we believe that empathy and proactive policies are essential elements to enable robots to perform human-like actions.},
  archive      = {J_TROB},
  author       = {Yubo Sheng and Yiwei Wang and Haoyuan Cheng and Huan Zhao and Han Ding},
  doi          = {10.1109/TRO.2025.3603556},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5411-5430},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Human-like robot action policy through game-theoretic intent inference for Human–Robot collaboration},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HDVIO2.0: Wind and disturbance estimation with hybrid dynamics VIO. <em>TROB</em>, <em>41</em>, 5396-5410. (<a href='https://doi.org/10.1109/TRO.2025.3603551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual-inertial odometry (VIO) is widely used for state estimation in autonomous micro aerial vehicles using onboard sensors. Current methods improve VIO by incorporating a model of the translational vehicle dynamics, yet their performance degrades when faced with low-accuracy vehicle models or continuous external disturbances, like wind. Additionally, incorporating rotational dynamics in these models is computationally intractable when they are deployed in online applications, e.g., in a closed-loop control system. We present HDVIO2.0, which models full 6-DoF, translational and rotational, vehicle dynamics and tightly incorporates them into a VIO system with minimal impact on the runtime. HDVIO2.0 builds upon the previous work, HDVIO, and addresses these challenges through a hybrid dynamics model combining a point-mass vehicle model with a learning-based component, with access to control commands and inertial measurement unit (IMU) history, to capture complex aerodynamic effects. The key idea behind modeling the rotational dynamics is to represent them with continuous-time functions. HDVIO2.0 leverages the divergence between the actual motion and the predicted motion from the hybrid dynamics model to estimate external forces as well as the robot state. Our system surpasses the performance of state-of-the-art methods in experiments using public and new drone dynamics datasets, as well as real-world flights in winds up to 25 km/h. Unlike existing approaches, we also show that accurate vehicle dynamics predictions are achievable without precise knowledge of the vehicle state.},
  archive      = {J_TROB},
  author       = {Giovanni Cioffi and Leonard Bauersfeld and Davide Scaramuzza},
  doi          = {10.1109/TRO.2025.3603551},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5396-5410},
  shortjournal = {IEEE Trans. Robot.},
  title        = {HDVIO2.0: Wind and disturbance estimation with hybrid dynamics VIO},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online pareto-optimal decision-making for complex tasks using active inference. <em>TROB</em>, <em>41</em>, 5378-5395. (<a href='https://doi.org/10.1109/TRO.2025.3600155'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When a robot autonomously performs a complex task, it frequently must balance competing objectives while maintaining safety. This becomes more difficult in uncertain environments with stochastic outcomes. Enhancing transparency in the robot’s behavior and aligning with user preferences are also crucial. This article introduces a novel framework for multiobjective reinforcement learning that ensures safe task execution, optimizes tradeoffs between objectives, and adheres to user preferences. The framework has two main layers: a multiobjective task planner and a high-level selector. The planning layer generates a set of optimal tradeoff plans that guarantee satisfaction of a temporal logic task. The selector uses active inference to decide which generated plan best complies with user preferences and aids learning. Operating iteratively, the framework updates a parameterized learning model based on collected data. Case studies and benchmarks on both manipulation and mobile robots show that our framework outperforms other methods and (i) learns multiple optimal tradeoffs, (ii) adheres to a user preference, and (iii) allows the user to adjust the balance between (i) and (ii).},
  archive      = {J_TROB},
  author       = {Peter Amorese and Shohei Wakayama and Nisar Ahmed and Morteza Lahijanian},
  doi          = {10.1109/TRO.2025.3600155},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5378-5395},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Online pareto-optimal decision-making for complex tasks using active inference},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward physician-level performance in robot-assisted ankle rehabilitation via imitation learning with empirical and temporal adaptation. <em>TROB</em>, <em>41</em>, 5360-5377. (<a href='https://doi.org/10.1109/TRO.2025.3600162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot-assisted ankle rehabilitation training imitating physician’s professional techniques is highly important for promoting personalized training and improving clinical outcomes. In this work, we propose a two-level kernelized movement primitives (2-level-KMP) imitation learning algorithm under the kernelized movement primitives (KMP) framework, which reproduces physician’s experience and optimizes the imitation trajectory during rehabilitation, to realize physician-level performance in robot-assisted ankle rehabilitation training. First, a KMP process combined with a Bayesian optimizer is used to imitate the rehabilitation trajectory. Second, the other KMP process is used to smooth the imitation trajectory further. Then the two KMP processes combined with patient-in-the-loop optimization (PILO) realize temporal rehabilitation adaptation. Finally, the 2-level-KMP algorithm is reproduced on a parallel ankle rehabilitation robot (PARR), which enables the patient’s passive rehabilitation training to be empirical and adaptive. Ten ankle dysfunction patients were involved in clinical experiments, with the results showing that the proposed algorithm can accurately reproduce physician’s trajectories and modulate trajectories based on patient’s feedback. After ten rehabilitation exercises, the number of modulation points calculated from patient’s torque feedback decreases by 85.19% on average compared with the beginning stage. A comparison between the 2-level KMP algorithm and existing algorithms shows that the 2-level-KMP algorithm can better ensure smoothness and retain the shape of the trajectory during trajectory modulation, ensuring the safety of ankle rehabilitation and retaining the experience of the physician.},
  archive      = {J_TROB},
  author       = {Mingjie Dong and Hanwei Ruan and Zeyu Wang and Chenyang Sun and Shiping Zuo and Yifeng Chen and Jianfeng Li and Mingming Zhang},
  doi          = {10.1109/TRO.2025.3600162},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5360-5377},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Toward physician-level performance in robot-assisted ankle rehabilitation via imitation learning with empirical and temporal adaptation},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic charging rendezvous and motion planning for a multi-AGV team including a mobile charging host. <em>TROB</em>, <em>41</em>, 5344-5359. (<a href='https://doi.org/10.1109/TRO.2025.3603501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Teams of automated battery-powered electric vehicles have the potential to execute complex mission tasks in off-road environments for agriculture, military, and other applications. Limited onboard energy reserves hinder their adoption in large-scale resource-constrained environments, where recharging is a necessity. It may be infeasible to install a network of static charging stations in off-road environments. For this reason, dedicated mobile host vehicles with charging capabilities are proposed as a means to increase range and capabilities of the multivehicle team. Here, we consider an ad hoc planning framework, where results from a high-confidence trajectory planner are leveraged to plan charging rendezvous between a host and other worker vehicles in a receding horizon fashion to provide high confidence that energy reserves will not be prematurely exhausted. The core problem is posed so as to minimize the impact of recharging on the mission in terms of task delays, overall energy utilization, and costs of fast charging. Through extensive Monte Carlo simulations of an off-road mission, we show a decrease in task delays without substantial increases in energy needs by updating the charging rendezvous plan during the mission. However, if updates are made too often, model mismatch may cause unnecessary cycling and mission failure.},
  archive      = {J_TROB},
  author       = {Nathan Goulet and Beshah Ayalew},
  doi          = {10.1109/TRO.2025.3603501},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5344-5359},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Dynamic charging rendezvous and motion planning for a multi-AGV team including a mobile charging host},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast and robust visuomotor riemannian flow matching policy. <em>TROB</em>, <em>41</em>, 5327-5343. (<a href='https://doi.org/10.1109/TRO.2025.3601293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion-based visuomotor policies excel at learning complex robotic tasks by effectively combining visual data with high-dimensional, multimodal action distributions. However, diffusion models often suffer from slow inference due to costly denoising processes or require complex sequential training arising from recent distilling approaches. This article introduces Riemannian flow matching policy (RFMP), a model that inherits the easy training and fast inference capabilities of flow matching. Moreover, RFMP inherently incorporates geometric constraints commonly found in realistic robotic applications, as the robot state resides on a Riemannian manifold. To enhance the robustness of RFMP, we propose stable RFMP (SRFMP), which leverages LaSalle’s invariance principle to equip the dynamics of FM with stability to the support of a target Riemannian distribution. Rigorous evaluation on ten simulated and real-world tasks show that RFMP successfully learns and synthesizes complex sensorimotor policies on Euclidean and Riemannian spaces with efficient training and inference phases, outperforming diffusion policies and consistency policies.},
  archive      = {J_TROB},
  author       = {Haoran Ding and Noémie Jaquier and Jan Peters and Leonel Rozo},
  doi          = {10.1109/TRO.2025.3601293},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5327-5343},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Fast and robust visuomotor riemannian flow matching policy},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A high-payload robotic hopper powered by bidirectional thrusters. <em>TROB</em>, <em>41</em>, 5307-5326. (<a href='https://doi.org/10.1109/TRO.2025.3600127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile robots have revolutionized various fields, offering solutions for manipulation, environmental monitoring, and exploration. However, payload capacity remains a limitation. This article presents a novel thrust-based robotic hopper capable of carrying payloads up to nine times its own weight while maintaining agile mobility over less structured terrain. The 220 g robot carries upto 2 kg while hopping—–a capability that bridges the gap between high-payload ground robots and agile aerial platforms. Key advancements that enable this high-payload capacity include the integration of bidirectional thrusters, allowing for both upward and downward thrust generation to enhance energy management while hopping. In addition, we present a refined model of dynamics that accounts for heavy payload conditions, particularly for large jumps. To address the increased computational demands, we employ a neural network compression technique, ensuring real-time onboard control. The robot’s capabilities are demonstrated through a series of experiments, including leaping over a high obstacle, executing sharp turns with large steps, as well as performing simple autonomous navigation while carrying a 730 g LiDAR payload. This showcases the robot’s potential for applications, such as mobile sensing and mapping, in challenging environments.},
  archive      = {J_TROB},
  author       = {Song Li and Songnan Bai and Ruihan Jia and Yixi Cai and Runze Ding and Yu Shi and Fu Zhang and Pakpong Chirarattananon},
  doi          = {10.1109/TRO.2025.3600127},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5307-5326},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A high-payload robotic hopper powered by bidirectional thrusters},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time sampling-based safe motion planning for robotic manipulators in dynamic environments. <em>TROB</em>, <em>41</em>, 5287-5306. (<a href='https://doi.org/10.1109/TRO.2025.3598119'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present the main features of the dynamic rapidly-exploring generalized bur tree (DRGBT) algorithm, a sampling-based planner for dynamic environments. We provide a detailed time analysis and appropriate scheduling to facilitate a real-time operation. To this end, an extensive analysis is conducted to identify the time-critical routines and their dependence on the number of obstacles. Furthermore, information about the distance to obstacles is used to compute a structure called dynamic expanded bubble of free configuration space, which is then utilized to establish sufficient conditions for a guaranteed safe motion of the robot while satisfying all kinematic constraints. An extensive comparative study is conducted to compare the proposed algorithm to competing state-of-the-art methods. Finally, an experimental study on a real robot is carried out covering a variety of scenarios including those with human presence. The results show the effectiveness and feasibility of real-time execution of the proposed motion planning algorithm within a typical sensor-based arrangement, using cheap hardware and sequential architecture, without the necessity for GPUs or heavy parallelization.},
  archive      = {J_TROB},
  author       = {Nermin Covic and Bakir Lacevic and Dinko Osmankovic and Tarik Uzunovic},
  doi          = {10.1109/TRO.2025.3598119},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5287-5306},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Real-time sampling-based safe motion planning for robotic manipulators in dynamic environments},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SA-TP$^{2}$: A safety-aware trajectory prediction and planning model for autonomous driving. <em>TROB</em>, <em>41</em>, 5267-5286. (<a href='https://doi.org/10.1109/TRO.2025.3600144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory prediction and planning remain key challenges for autonomous vehicles, particularly in complex and dynamic environments. Existing methods, typically based on static safety metrics like time-to-collision, fail to account for the evolving nature of risk in real-world traffic. This article proposes a novel safety-aware trajectory prediction and planning (SA-TP$^{2}$) model, which introduces an adaptive driver risk field to simulate human-like risk perception and decision-making. By dynamically modeling risk as a continuous variable, SA-TP$^{2}$ adjusts vehicle trajectories in real time, accounting for interactions with other agents, road conditions, and environmental uncertainties. The model integrates imitation learning, rule-based strategies, and physics-informed neural networks to ensure safe, efficient, and human-compatible behavior. A Linformer-based architecture and temporal hypergraph convolution network are introduced to optimize computational efficiency, enabling real-time operation in resource-constrained environments. Experimental results on benchmark datasets including next generation simulation (NGSIM), highway drone dataset (HighD), Macao connected autonomous driving (MoCAD), and NuScenes demonstrate that SA-TP$^{2}$ achieves the state-of-the-art performance in trajectory prediction. In addition, extensive closed-loop testing on the NuPlan and CommonRoad platforms further confirms that SA-TP$^{2}$ outperforms existing baselines, paving the way for safer navigation of autonomous driving systems.},
  archive      = {J_TROB},
  author       = {Haicheng Liao and Zhenning Li and Kaiqun Zhu and Keqiang Li and Chengzhong Xu},
  doi          = {10.1109/TRO.2025.3600144},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5267-5286},
  shortjournal = {IEEE Trans. Robot.},
  title        = {SA-TP$^{2}$: A safety-aware trajectory prediction and planning model for autonomous driving},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust and agile quadrotor flight via adaptive unwinding-free quaternion sliding-mode control. <em>TROB</em>, <em>41</em>, 5246-5266. (<a href='https://doi.org/10.1109/TRO.2025.3600157'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a new adaptive sliding-mode control (SMC) framework for quadrotors that achieves robust and agile flight under tight computational constraints. The proposed controller addresses key limitations of prior SMC formulations, including, first, the slow convergence and almost-global stability of $\mathrm{SO(3)}$-based methods, second, the oversimplification of rotational dynamics in Euler-based controllers, third, the unwinding phenomenon in quaternion-based formulations, and fourth, the gain overgrowth problem in adaptive SMC schemes. Leveraging nonsmooth stability analysis, we provide rigorous global stability proofs for both the nonsmooth attitude sliding dynamics defined on $\mathbb {S}^{3}$ and the position sliding dynamics. Our controller is computationally efficient and runs reliably on a resource-constrained nano quadrotor, achieving 250 Hz and 500 Hz refresh rates for position and attitude control, respectively. In an extensive set of hardware experiments with over 130 flight trials, the proposed controller consistently outperforms three benchmark methods, demonstrating superior trajectory tracking accuracy and robustness with relatively low control effort. The controller enables aggressive maneuvers, such as dynamic throw launches, flip maneuvers, and accelerations exceeding 3 g, which is remarkable for a 32-gram nano quadrotor. These results highlight promising potential for real-world applications, particularly in scenarios requiring robust, high-performance flight control under significant external disturbances and tight computational constraints.},
  archive      = {J_TROB},
  author       = {Amin Yazdanshenas and Reza Faieghi},
  doi          = {10.1109/TRO.2025.3600157},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5246-5266},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robust and agile quadrotor flight via adaptive unwinding-free quaternion sliding-mode control},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward predicting collective performance in multirobot teams. <em>TROB</em>, <em>41</em>, 5229-5245. (<a href='https://doi.org/10.1109/TRO.2025.3600164'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increased deployment of multirobot systems (MRS) in various fields has led to the need to analyze system-level performance. However, creating consistent metrics for MRS is challenging due to the wide range of team and task parameters, such as the number of robots and the size of the environment. This article presents a new analytical framework for MRS based on dimensionless variable analysis that effectively condenses the complex relationships between the team and task parameters that influence MRS performance into a manageable set of dimensionless variables. Then, we use these dimensionless variables to fit a predictive parameteric model of team performance. We apply our methodology to two MRS applications: multirobot multitarget tracking and multiagent path finding. The application of dimensionless variable analysis to MRS offers a promising method for MRS analysis that effectively reduces complexity, improves understanding of system behavior, and can inform the design and management of future MRS deployments.},
  archive      = {J_TROB},
  author       = {Pujie Xin and Zhanteng Xie and Philip Dames},
  doi          = {10.1109/TRO.2025.3600164},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5229-5245},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Toward predicting collective performance in multirobot teams},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deadlock-aware control for multirobot coordination with multiple safety constraints. <em>TROB</em>, <em>41</em>, 5209-5228. (<a href='https://doi.org/10.1109/TRO.2025.3600159'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multirobot coordination in shared workspaces is prone to deadlocks, which can compromise operational capabilities and task efficiency. Accurately determining the timing and spatial locations of deadlocks is essential for effective resolution, yet remains challenging due to dynamic robot interactions and growing system complexity. To this end, a distributed deadlock-aware control framework is proposed for robots to detect and avoid deadlocks while maintaining safe task execution. First, deadlocks are characterized by analyzing undesired equilibria in robot dynamics under safety constraints imposed by multiple stacked control barrier functions (CBFs). Our analysis reveals two critical properties: 1) deadlocks occur at intersections of all active CBF boundaries; and 2) deadlocks arise when robot stabilizing force are confined within the conical hull formed by active safety forces. These theoretical insights underpin a new detection method that identifies potential deadlocks from conflicts between safety requirements and task objectives. Furthermore, a reactive deadlock avoidance method is designed to help robots escape and prevent entry into potential deadlock regions by adaptively modulating the stabilizing force. A generalized workflow is established to systematically address deadlocks across various multirobot tasks. Simulation and hardware experiments are conducted on robots collaborating in dense environments to validate the framework’s effectiveness in preventing task failures caused by deadlocks.},
  archive      = {J_TROB},
  author       = {Zhenwei Zhang and Yuhao Zhang and Xingwei Zhao and Bo Tao and Han Ding},
  doi          = {10.1109/TRO.2025.3600159},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5209-5228},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Deadlock-aware control for multirobot coordination with multiple safety constraints},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SCALER: Versatile multilimbed robot for free-climbing in extreme terrains. <em>TROB</em>, <em>41</em>, 5189-5208. (<a href='https://doi.org/10.1109/TRO.2025.3588446'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents Spine-enhanced Climbing Autonomous Limbed Exploration Robot (SCALER), a versatile free-climbing multilimbed robot that is designed to achieve tightly coupled simultaneous locomotion and dexterous grasping. While existing quadrupedal-limbed robots have demonstrated impressive dexterous capabilities, achieving a balance between power-demanding locomotion and precise grasping remains a critical challenge. We design a torso mechanism and a parallel–serial limb to meet the conflicting requirements that pose unique challenges in hardware design. SCALER employs underactuated two-fingered GOAT grippers that can mechanically adapt and offer seven modes of grasping, enabling SCALER to traverse extreme terrains with multimodal grasping strategies. We study the whole-body approach, where SCALER utilizes its body and limbs to generate additional forces for stable grasping in various environments, thereby further enhancing its versatility. Furthermore, we improve the GOAT gripper actuation speed to realize more dynamic climbing in a closed-loop control fashion. With these proposed technologies, SCALER can traverse vertical, overhanging, upside-down, slippery terrains and bouldering walls with nonconvex-shaped climbing holds under the Earth’s gravity.},
  archive      = {J_TROB},
  author       = {Yusuke Tanaka and Yuki Shirai and Alexander Schperberg and Xuan Lin and Dennis Hong},
  doi          = {10.1109/TRO.2025.3588446},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5189-5208},
  shortjournal = {IEEE Trans. Robot.},
  title        = {SCALER: Versatile multilimbed robot for free-climbing in extreme terrains},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). URPlanner: A universal paradigm for collision-free robotic motion planning based on deep reinforcement learning. <em>TROB</em>, <em>41</em>, 5169-5188. (<a href='https://doi.org/10.1109/TRO.2025.3600138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collision-free motion planning for redundant robot manipulators in complex environments is yet to be explored. Although recent advancements at the intersection of deep reinforcement learning (DRL) and robotics have highlighted its potential to handle versatile robotic tasks, current DRL-based collision-free motion planners for manipulators are highly costly, hindering their deployment and application. This is due to an overreliance on the minimum distance between the manipulator and obstacles, inadequate exploration and decision making by DRL, and inefficient data acquisition and utilization. In this article, we propose URPlanner, a universal paradigm for collision-free robotic motion planning based on DRL. URPlanner offers several advantages over existing approaches: it is platform agnostic, cost-effective in both training and deployment, and applicable to arbitrary manipulators without solving inverse kinematics. To achieve this, we first develop a parameterized task space and a universal obstacle avoidance reward that is independent of minimum distance. Second, we introduce an augmented policy exploration and evaluation algorithm that can be applied to various DRL algorithms to enhance their performance. Third, we propose an expert data diffusion strategy for efficient policy learning, which can produce a large-scale trajectory dataset from only a few expert demonstrations. Finally, the superiority of the proposed methods is comprehensively verified through experiments.},
  archive      = {J_TROB},
  author       = {Fengkang Ying and Hanwen Zhang and Haozhe Wang and Huishi Huang and Marcelo H. Ang},
  doi          = {10.1109/TRO.2025.3600138},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5169-5188},
  shortjournal = {IEEE Trans. Robot.},
  title        = {URPlanner: A universal paradigm for collision-free robotic motion planning based on deep reinforcement learning},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parallel MPPI with gradient-velocity modulated SDF cost for high-performance real-time dynamic obstacle avoidance by robot manipulators. <em>TROB</em>, <em>41</em>, 5149-5168. (<a href='https://doi.org/10.1109/TRO.2025.3600125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time motion planning in dynamic environments presents a significant challenge for robotic manipulators. This article introduces an innovative parallel model predictive path integral (MPPI) algorithm enabling the robot to navigate swiftly and safely in such environments. Unlike the conventional MPPI methods that rely on a single sequence of Gaussian means for trajectory sampling, the proposed parallel MPPI (PMPPI) concurrently runs multiple planners with different strategies and adaptively integrates planned paths based on the current state, leveraging the advantages of different strategies and greatly improving the MPPI’s exploration capability. Moreover, a gradient-velocity modulated signed distance field (SDF) cost function that dynamically adjusts costs based on the robot’s velocity and the SDF gradient is defined, thereby promoting safer and purposeful motion planning. In the implementation, techniques like utilizing inverse kinematics solver for path guidance and sparse reward to expedite reaching time are integrated into the MPPI cost function design. Comparative evaluations against the traditional MPPI architecture and standard SDF cost designs demonstrate the superiority of the new method. Real-world experiments, including human–robot interaction, obstacle-crossing, and grasping tasks, validate the robustness and universality of our methodology, with average and maximum end effector speeds of 0.523 m/s and 1.225 m/s respectively.},
  archive      = {J_TROB},
  author       = {Lelai Zhou and Zhengmao Li and Yibin Li and Shaoping Bai},
  doi          = {10.1109/TRO.2025.3600125},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5149-5168},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Parallel MPPI with gradient-velocity modulated SDF cost for high-performance real-time dynamic obstacle avoidance by robot manipulators},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coil-reinforced flat tube actuators for robotic applications. <em>TROB</em>, <em>41</em>, 5130-5148. (<a href='https://doi.org/10.1109/TRO.2025.3598148'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft pneumatic actuators (SPAs) are widely used in robotic applications due to their inherent compliance and outstanding mechanical performance. However, a tradeoff between load capacity and deformation capacity is required when selecting material hardness for SPAs. Too hard material usually results in limited deformation, such as small extension, bending, and twisting, while too soft a material decreases robustness. This study introduces coil-reinforced flat tube actuators (CFTAs) that exhibit excellent flexibility and high load capacity by braiding flat tubes in coil springs. By adjusting the braiding pattern of the flat tube, the CFTAs can realize extending, in-plane bending, and out-of-plane helical bending motions. In addition, analytical models are proposed to predict the deformation behavior of the CFTAs and verified by experiments. The bending type CFTA deforms with an excellent curvature (0.516 mm−1) under 160 kPa input pressure, five times larger than the reported SPAs on the same scale. The CFTAs show high design flexibility by programming the flat tube pattern and using multiple coiled springs for wide application scenarios. Based on the CFTAs, this study shows wearable upper limb robots, a soft entanglement gripper, and a rob-climbing robot. CFTAs provide design insight for applications requiring dexterous and versatile deformations.},
  archive      = {J_TROB},
  author       = {Hao Liu and Changchun Wu and Senyuan Lin and Yunquan Li and Yonghua Chen and James Lam and Ning Xi},
  doi          = {10.1109/TRO.2025.3598148},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5130-5148},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Coil-reinforced flat tube actuators for robotic applications},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning enhanced LQR and control lyapunov functions for spacecraft proximity operations. <em>TROB</em>, <em>41</em>, 5117-5129. (<a href='https://doi.org/10.1109/TRO.2025.3600160'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spacecraft autonomy is a major barrier to increasing the scope, ambition, and affordability of both Earth-based and deep-space missions. Reinforcement learning (RL) offers huge potential in solving this problem, however, their adoption is hampered by the lack of stability guarantees, search space size and the complexity of spacecraft optimal control problems. Control techniques, such as control Lyapunov functions and linear quadratic regulators can help the RL frameworks find the optimal solution. The combination of these controllers with RL is investigated in Clohessy-Wiltshire–Hill dynamics. Several different greedy control approaches, as well as a novel nongreedy formulation, are considered for time-optimal and fuel-optimal transfers. Comparisons with optimal control theory, particle swarm optimisation and RL-only simulations are presented, demonstrating the effectiveness of RL-enhanced control approaches.},
  archive      = {J_TROB},
  author       = {Harry Holt and Roberto Armellin},
  doi          = {10.1109/TRO.2025.3600160},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5117-5129},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Reinforcement learning enhanced LQR and control lyapunov functions for spacecraft proximity operations},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RGBlimp-Q: Robotic gliding blimp with moving mass control based on a bird-inspired continuum arm. <em>TROB</em>, <em>41</em>, 5097-5116. (<a href='https://doi.org/10.1109/TRO.2025.3600135'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic blimps, as lighter-than-air aerial platforms, offer extended operational duration and enhanced safety in human–robot interactions due to their buoyant lift. However, achieving robust flight performance under environmental airflow disturbances remains a critical challenge, thereby limiting their broader deployment. Inspired by avian flight mechanics, particularly the ability of birds to perch and stabilize in turbulent wind conditions, this article introduces RGBlimp-Q—a robotic gliding blimp equipped with a bird-inspired continuum arm featuring a novel moving mass actuation mechanism. This continuum arm enables flexible attitude regulation through internal mass redistribution, significantly enhancing the system’s resilience to external disturbances. In addition, it facilitates aerial manipulation by employing end-effector claws that interact with the environment in a manner analogous to avian perching behavior. This article presents the design, modeling, and prototyping of RGBlimp-Q, supported by comprehensive experimental evaluation and comparative analysis. To the best of the authors’ knowledge, this represents the first interdisciplinary integration of continuum mechanisms into a lighter-than-air robotic platform, where the continuum arm simultaneously functions as both an actuation and manipulation module. This design establishes a novel paradigm for robotic blimps, expanding their applicability to complex and dynamic environments.},
  archive      = {J_TROB},
  author       = {Hao Cheng and Feitian Zhang},
  doi          = {10.1109/TRO.2025.3600135},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5097-5116},
  shortjournal = {IEEE Trans. Robot.},
  title        = {RGBlimp-Q: Robotic gliding blimp with moving mass control based on a bird-inspired continuum arm},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new quantitative measure for separation and penetration between convex primitives and a point cloud or a triangle mesh. <em>TROB</em>, <em>41</em>, 5080-5096. (<a href='https://doi.org/10.1109/TRO.2025.3600128'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a new efficient way to quantitatively measure separation and penetration between a collection of convex primitives (including ellipsoids, capsules, cylinders, convex polyhedra, and triangles) and a point cloud or a triangle mesh. First, the minimum scaling factor of a convex primitive with respect to its centroid to contact a point or a triangle is proposed as a new distance metrics, which can be greater than, equal to, or less than one, implying that the point or the triangle is separated from, just contacts, or penetrates into the convex primitive. It can be computed mostly in closed form or occasionally with a 1-D gradient descent search, which is much faster than computing the Euclidean distance. Furthermore, an efficient algorithm is proposed to compute the smallest minimum scaling factor of convex primitives in a collection to a point cloud or a triangle mesh. It is based on the discovery that computing the minimum scaling factor of a convex primitive to a point or a triangle yields a plane separating more points or triangles from this or other convex primitives. Then, the overall smallest scaling factor can be found by checking only a few pairs of primitives and points or triangles, being significantly faster than the exhaustive search. In various numerical examples and comparison with the existing algorithms, the proposed metrics and algorithm show superior or comparable efficiency.},
  archive      = {J_TROB},
  author       = {Yu Zheng},
  doi          = {10.1109/TRO.2025.3600128},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5080-5096},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A new quantitative measure for separation and penetration between convex primitives and a point cloud or a triangle mesh},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Precise control for intrinsically sensing soft robotic tentacle with free-stroke TCA. <em>TROB</em>, <em>41</em>, 5060-5079. (<a href='https://doi.org/10.1109/TRO.2025.3600153'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Twisted and coiled actuators (TCAs) are promising in soft robotics for their high energy density, light weight, and low voltage. However, current TCA-based soft robots face challenges of limited deformation and control precision, mainly due to the preloading requirement of TCAs and the lack of suitable intrinsic sensing capabilities. To address these issues, we designed a TCA with high load capacity, free stroke, and self-sensing capabilities, proposed flexible optical fiber-based posture and tactile sensing methods, and developed a multiloop feedback controller. Collectively, these enable millimeter-level tracking accuracy in a soft tentacle robot. The TCA, with an optimized manufacturing process, achieves a 30% free stroke without preloading, a 32% improvement in ultimate stress, and temperature self-sensing capabilities with a maximum error of less than 6% . Combining the TCAs with compliant macro-bend optical fibers and soft optical waveguides, we created a soft robotic tentacle with intrinsic posture and tactile sensing, and designed a multiinput–multioutput closed-loop and feedforward controller. Experiments demonstrate that the model-based feedforward significantly improves the control performance, reducing the rise time by 15.3% . The trajectory tracking error remains within the millimeter range, and the repetitive positioning error for hexagonal trajectories reaches submillimeter precision. The tactile sensor of the robot enables real-time perception of the object’s modulus and pressing states. These findings highlight the soft robotic tentacle’s potential for various applications, including underwater exploration, detection, and sampling.},
  archive      = {J_TROB},
  author       = {Hongxin Huang and Qingqing Wang and Zhongtian Liu and Zhetian Ding and Fanghao Zhou and Zheng Chen and Tiefeng Li},
  doi          = {10.1109/TRO.2025.3600153},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5060-5079},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Precise control for intrinsically sensing soft robotic tentacle with free-stroke TCA},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simultaneous task allocation and planning for multirobots under hierarchical temporal logic specifications. <em>TROB</em>, <em>41</em>, 5040-5059. (<a href='https://doi.org/10.1109/TRO.2025.3598139'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research in robotic planning with temporal logic specifications, such as linear temporal logic (LTL), has relied on single formulas. However, as task complexity increases, LTL formulas become lengthy, making them difficult to interpret and generate, and straining the computational capacities of planners. To address this, we introduce a hierarchical structure for a widely used specification type—LTL on finite traces (LTL$_{f}$). The resulting language, termed H-LTL$_{f}$, is defined with both its syntax and semantics. We further prove that H-LTL$_{f}$ is more expressive than its standard “flat” counterparts. Moreover, we conducted a user study that compared the standard LTL$_{f}$ with our hierarchical version and found that users could more easily comprehend complex tasks using the hierarchical structure. We develop a search-based approach to synthesize plans for multirobot systems, achieving simultaneous task allocation and planning. This method approximates the search space by loosely interconnected subspaces, each corresponding to an LTL$_{f}$ specification. The search primarily focuses on a single subspace, transitioning to another under conditions determined by the decomposition of automata. We develop multiple heuristics to significantly expedite the search. Our theoretical analysis, conducted under mild assumptions, addresses completeness and optimality. Compared to existing methods used in various simulators for service tasks, our approach improves planning times while maintaining comparable solution quality.},
  archive      = {J_TROB},
  author       = {Xusheng Luo and Changliu Liu},
  doi          = {10.1109/TRO.2025.3598139},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5040-5059},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Simultaneous task allocation and planning for multirobots under hierarchical temporal logic specifications},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AsynEIO: Asynchronous monocular event-inertial odometry using gaussian process regression. <em>TROB</em>, <em>41</em>, 5020-5039. (<a href='https://doi.org/10.1109/TRO.2025.3598145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event cameras, when combined with inertial sensors, show significant potential for motion estimation in challenging scenarios, such as high-speed maneuvers and low-light environments. While numerous methods exist for producing such estimations, most boil down to solving a synchronous discrete-time fusion problem. However, the asynchronous nature of event cameras and their unique fusion mechanism with inertial sensors remain underexplored. In this article, we introduce a monocular event-inertial odometry method called asynchronous event-inertial odometry (AsynEIO), designed to fuse asynchronous event and inertial data within a unified Gaussian process (GP) regression framework. Our approach incorporates an event-driven front-end that tracks feature trajectories directly from raw event streams at a high temporal resolution. These tracked feature trajectories, along with various inertial factors, are integrated into the same GP regression framework to enable asynchronous fusion. With deriving analytical residual Jacobians and noise models, our method constructs a factor graph that is iteratively optimized and pruned using a sliding-window optimizer. Comparative assessments highlight the performance of different inertial fusion strategies, suggesting optimal choices for varying conditions. Experimental results on both public datasets and our own event-inertial sequences indicate that AsynEIO outperforms existing methods, especially in high-speed and low-illumination scenarios.},
  archive      = {J_TROB},
  author       = {Zhixiang Wang and Xudong Li and Yizhai Zhang and Fan Zhang and Panfeng Huang},
  doi          = {10.1109/TRO.2025.3598145},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5020-5039},
  shortjournal = {IEEE Trans. Robot.},
  title        = {AsynEIO: Asynchronous monocular event-inertial odometry using gaussian process regression},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision-based proximity and tactile sensing for robot arms: Design, perception, and control. <em>TROB</em>, <em>41</em>, 5000-5019. (<a href='https://doi.org/10.1109/TRO.2025.3593087'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft-bodied robots with multimodal sensing capabilities hold promise for versatile and user-friendly robotics. However, seamlessly integrating multiple sensing functionalities into soft artificial skins remains a challenge due to compatibility issues between soft materials and conventional electronics. While vision-based tactile sensing has enabled simple and effective sensor designs for robotic touch, there has been limited exploration of this technique for intrinsic multimodal sensing in large-sized soft robot bodies. To address this gap, this article introduces a novel vision-based soft sensing technique, named ProTac, capable of operating either in tactile or proximity sensing modes. This vision-based sensing technology relies on a soft functional skin that can actively switch its optical properties between opaque and transparent states. Furthermore, this article develops efficient learning pipelines for proximity and tactile perceptions, as well as sensing strategies enabled through the timing activation of the two sensing modes. The effectiveness of the soft sensing technology is demonstrated through a soft ProTac link, which can be integrated into newly constructed or existing commercial robot arms. Results suggest that robots integrated with the ProTac link, along with rigorous control formulation can perform safe and purposeful control actions, which enhances human–robot interaction scenarios and facilitates motion control tasks that are challenging to achieve with conventional rigid links.},
  archive      = {J_TROB},
  author       = {Quan Khanh Luu and Dinh Quang Nguyen and Nhan Huu Nguyen and Nam Phuong Dam and Van Anh Ho},
  doi          = {10.1109/TRO.2025.3593087},
  journal      = {IEEE Transactions on Robotics},
  pages        = {5000-5019},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Vision-based proximity and tactile sensing for robot arms: Design, perception, and control},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continuous-time state estimation methods in robotics: A survey. <em>TROB</em>, <em>41</em>, 4975-4999. (<a href='https://doi.org/10.1109/TRO.2025.3593079'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate, efficient, and robust state estimation is more important than ever in robotics as the variety of platforms and complexity of tasks continue to grow. Historically, discrete-time filters and smoothers have been the dominant approach, in which the estimated variables are states at discrete sample times. The paradigm of continuous-time state estimation proposes an alternative strategy by estimating variables that express the state as a continuous function of time, which can be evaluated at any query time. Not only can this benefit downstream tasks such as planning and control, but it also significantly increases estimator performance and flexibility, as well as reduces sensor preprocessing and interfacing complexity. Despite this, continuous-time methods remain underutilized, potentially because they are less well-known within robotics. To remedy this, this work presents a unifying formulation of these methods and the most exhaustive literature review to date, systematically categorizing prior work by methodology, application, state variables, historical context, and theoretical contribution to the field. By surveying splines and Gaussian process together and contextualizing works from other research domains, this work identifies and analyzes open problems in continuous-time state estimation and suggests new research directions.},
  archive      = {J_TROB},
  author       = {William Talbot and Julian Nubert and Turcan Tuna and Cesar Cadena and Frederike Dümbgen and Jesús Tordesillas and Timothy D. Barfoot and Marco Hutter},
  doi          = {10.1109/TRO.2025.3593079},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4975-4999},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Continuous-time state estimation methods in robotics: A survey},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structure-exploiting sequential quadratic programming for model-predictive control. <em>TROB</em>, <em>41</em>, 4960-4974. (<a href='https://doi.org/10.1109/TRO.2025.3595674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The promise of model-predictive control (MPC) in robotics has led to extensive development of efficient numerical optimal control solvers in line with differential dynamic programming because it exploits the sparsity induced by time. In this work, we argue that this effervescence has hidden the fact that sparsity can be equally exploited by standard nonlinear optimization. In particular, we show how a tailored implementation of sequential quadratic programming (QP) achieves state-of-the-art MPC. Then, we clarify the connections between popular algorithms from the robotics community and well-established optimization techniques. Further, the sequential quadratic program formulation naturally encompasses the constrained case, a notoriously difficult problem in the robotics community. Specifically, we show that it only requires a sparsity-exploiting implementation of a state-of-the-art QP solver. We illustrate the validity of this approach in a comparative study and experiments on a torque-controlled manipulator. To the best of our knowledge, this is the first demonstration of closed loop nonlinear MPC with constraints on a real robot.},
  archive      = {J_TROB},
  author       = {Armand Jordana and Sébastien Kleff and Avadesh Meduri and Justin Carpentier and Nicolas Mansard and Ludovic Righetti},
  doi          = {10.1109/TRO.2025.3595674},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4960-4974},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Structure-exploiting sequential quadratic programming for model-predictive control},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online adaptation framework enables personalization of exoskeleton assistance during locomotion in patients affected by stroke. <em>TROB</em>, <em>41</em>, 4941-4959. (<a href='https://doi.org/10.1109/TRO.2025.3595701'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic exoskeletons can transform mobility for individuals with lower limb disabilities. However, their widespread adoption is limited by controller degradation caused by varying gait dynamics across different users and environments. Here, we propose an online adaptation framework that leverages real-time data streams to continuously update the user state estimator model. This approach allows the exoskeleton to learn the user-specific gait patterns, effectively customizing the model for each new user. In addition, we demonstrate a sensor signal transformation technique that enables model transfer across different exoskeleton hardware (from a research-grade exoskeleton to a commercial device). With less than one minute of adaptation, our framework improved gait phase estimation, which directly affects assistance timing, by 40.9% for able-bodied subjects and 65.9% for stroke survivors ($p$ $&lt; $ 0.05), and reduced torque profile error by 32.7% compared to the baseline model ($p$ $&lt; $ 0.05). Furthermore, in a pilot test, we applied our adaptation framework with human-in-the-loop optimization for control tuning. In a single stroke survivor, this approach led to a 21.8% increase in walking speed and a 6.5% reduction in metabolic cost compared to walking without exoskeleton. While preliminary, these results suggest the potential for personalized exoskeleton assistance in clinical populations.},
  archive      = {J_TROB},
  author       = {Inseung Kang and Dean D. Molinaro and Dongho Park and Dawit Lee and Pratik Kunapuli and Kinsey R. Herrin and Aaron J. Young},
  doi          = {10.1109/TRO.2025.3595701},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4941-4959},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Online adaptation framework enables personalization of exoskeleton assistance during locomotion in patients affected by stroke},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonrepetitive-path iterative learning and control for human-guided robotic operations on unknown surfaces. <em>TROB</em>, <em>41</em>, 4922-4940. (<a href='https://doi.org/10.1109/TRO.2025.3588453'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automation of abrasive machining operations has become a challenging aspect in the remanufacturing industry where it is required to conduct operations on a surface of which the exact dimensions are unknown. In such cases, skilled human workers have to step in to perform labor-intensive tasks with inconsistent quality. In existing research work, collaborative robots are used to partially automate such operations under human supervision. However, these methods do not perform learning and control simultaneously and are often affected by the interactions of the human operator. In this article, a novel learning and control scheme is proposed where the robot explores an unknown surface iteratively while achieving the desired contact control performance under supervision and occasional interference from the human operator. The unknown surface is divided into subregions, and the learning and control parameters are updated each time the robot visits each subregion. This method is independent of the path of the robot and, thus, is unaffected by the irregularities introduced by a human operator’s interactions. The proposed method is applied to force control, stiffness learning, and orientation adaptation cases. The validity of this method is shown via simulations as well as experiments conducted using a Kinova Gen3 7-degrees of freedom robot.},
  archive      = {J_TROB},
  author       = {Kithmi N. D. Widanage and Jingkang Xia and Rizuwana Parween and Hareesh Godaba and Nicolas Herzig and Romeo Glovnea and Deqing Huang and Yanan Li},
  doi          = {10.1109/TRO.2025.3588453},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4922-4940},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Nonrepetitive-path iterative learning and control for human-guided robotic operations on unknown surfaces},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sensor model identification via simultaneous model selection and state variable determination. <em>TROB</em>, <em>41</em>, 4902-4921. (<a href='https://doi.org/10.1109/TRO.2025.3588445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a method for the unattended gray-box identification of sensor models commonly used by localization algorithms in the field of robotics. The objective is to determine the most likely sensor model for a time series of unknown measurement data, given an extendable catalog of predefined sensor models. Sensor model definitions may require states for rigid-body calibrations and dedicated reference frames to replicate a measurement based on the robot’s localization state. A health metric is introduced, which verifies the outcome of the selection process in order to detect false positives and facilitate reliable decision-making. In the second stage, an initial guess for identified calibration states is generated, and the necessity of sensor world reference frames is evaluated. The identified sensor model with its parameter information is then used to parameterize and initialize a state estimation application, thus ensuring a more accurate and robust integration of new sensor elements. This method is helpful for inexperienced users who want to identify the source and type of a measurement, sensor calibrations, or sensor reference frames. It will also be important in the field of modular multiagent scenarios and modularized robotic platforms that are augmented by sensor modalities during runtime. Overall, this work aims to provide a simplified integration of sensor modalities to downstream applications and circumvent common pitfalls in the usage and development of localization approaches.},
  archive      = {J_TROB},
  author       = {Christian Brommer and Alessandro Fornasier and Jan Steinbrener and Stephan Weiss},
  doi          = {10.1109/TRO.2025.3588445},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4902-4921},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Sensor model identification via simultaneous model selection and state variable determination},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Motion planning diffusion: Learning and adapting robot motion planning with diffusion models. <em>TROB</em>, <em>41</em>, 4881-4901. (<a href='https://doi.org/10.1109/TRO.2025.3593109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of optimization-based robot motion planning algorithms is highly dependent on the initial solutions, commonly obtained by running a sampling-based planner to obtain a collision-free path. However, these methods can be slow in high-dimensional and complex scenes and produce nonsmooth solutions. Given previously solved path-planning problems, it is highly desirable to learn their distribution and use it as a prior for new similar problems. Several works propose utilizing this prior to bootstrap the motion planning problem, either by sampling initial solutions from it, or using its distribution in a maximum-a-posterior formulation for trajectory optimization. In this work, we introduce motion planning diffusion (MPD), an algorithm that learns trajectory distribution priors with diffusion models. These generative models have shown increasing success in encoding multimodal data and have desirable properties for gradient-based motion planning, such as cost guidance. Given a motion planning problem, we construct a cost function and sample from the posterior distribution using the learned prior combined with the cost function gradients during the denoising process. Instead of learning the prior on all trajectory waypoints, we propose learning a lower dimensional representation of a trajectory using linear motion primitives, particularly B-spline curves. This parametrization guarantees that the generated trajectory is smooth, can be interpolated at higher frequencies, and needs fewer parameters than a dense waypoint representation. We demonstrate the results of our method ranging from simple 2-D to more complex tasks using a 7-DOF robot arm manipulator. In addition to learning from simulated data, we also use human demonstrations on a real-world pick-and-place task. The experiment results show that diffusion models are strong priors for encoding multimodal trajectory distributions for optimization-based motion planning.},
  archive      = {J_TROB},
  author       = {João Carvalho and An Thai Le and Piotr Kicki and Dorothea Koert and Jan Peters},
  doi          = {10.1109/TRO.2025.3593109},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4881-4901},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Motion planning diffusion: Learning and adapting robot motion planning with diffusion models},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ROEVO: Robust organized edge feature-based visual odometry using RGB-D cameras. <em>TROB</em>, <em>41</em>, 4860-4880. (<a href='https://doi.org/10.1109/TRO.2025.3595702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a visual odometry (VO) system that leverages image edge features. Edges are spatially expressive cues commonly present across diverse environments, offering rich textural and structural information. However, existing edge-based VO methods often fail to fully exploit this potential. To this end, we introduce a novel feature representation termed organized edges, which transforms disjoint edge pixels into sequentialized clusters, enabling more effective retention and utilization of the underlying textural and structural information. Another nice property of this formulation is that organized edges can perform edge-level association across multiple frames, enabling the establishment of a covisibility graph. To achieve precise and efficient pose estimation, we propose a range of particularly designed tracking and joint optimization methods based on the characteristics of organized edges. For tracking, we formulate edge-wise rather than pixel-wise residuals to achieve robust and accurate interframe registration. For joint optimization, we introduce a novel shape-preserving edge-fitting method and an organized edge-based bundle adjustment (BA) approach, which decomposes the traditional BA problem into fitting and registration to preserve the structural integrity. Based on these novel techniques, we develop a complete VO system that exclusively employs organized edge features, achieving efficient tracking and precise local mapping. Extensive experiments demonstrate its accuracy and robustness in indoor environments, outperforming or achieving comparable performance to state-of-the-art methods.},
  archive      = {J_TROB},
  author       = {Mingrui Liu and Xingxing Zuo and Renlang Huang and Minglei Zhao and Jiming Chen and Liang Li},
  doi          = {10.1109/TRO.2025.3595702},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4860-4880},
  shortjournal = {IEEE Trans. Robot.},
  title        = {ROEVO: Robust organized edge feature-based visual odometry using RGB-D cameras},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design, control, and evaluation of a novel soft everting robot for colonoscopy. <em>TROB</em>, <em>41</em>, 4843-4859. (<a href='https://doi.org/10.1109/TRO.2025.3595696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colonoscopy is a medical procedure used to examine the inside of the colon for abnormalities, such as polyps or cancer. Traditionally, this is done by manually inserting a long, flexible tube called a colonoscope into the colon. However, this method can cause pain, discomfort, and even the risk of perforation. To address these shortcomings, advancements in technology are needed to develop safer, more intelligent colonoscopes. This article presents the design, control, and evaluation of a self-growing soft robotic colonoscope, leveraging the evertion principle. The device features a tube with an 18 mm diameter, constructed from stretchable fabric, which grows 1.6 m at the tip under pressurization. A pneumatically driven, elastomer-based manipulator enables omni-directional steering over 180° at the tip. An airtight base houses motors and spools that control the material and regulate growth speed. The robot operates in two modes: teleoperation via joysticks and autonomous navigation using sensor inputs, such as a tip-mounted camera. Thorough in-vitro experiments are conducted to assess the system’s functionality and performance. Results illustrate that the robot can achieve locomotion in confined spaces such as a colon phantom, while exerting contact forces averaging less than 0.3 N. Our soft robot shows potential for improving the safety and autonomy of colonoscopies, while reducing discomfort to patients.},
  archive      = {J_TROB},
  author       = {Jialei Shi and Korn Borvorntanajanya and Kaiwen Chen and Enrico Franco and Ferdinando Rodriguez y Baena},
  doi          = {10.1109/TRO.2025.3595696},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4843-4859},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Design, control, and evaluation of a novel soft everting robot for colonoscopy},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fourigami: A 4-degree-of-freedom, force-controlled, origami, finger pad haptic device. <em>TROB</em>, <em>41</em>, 4829-4842. (<a href='https://doi.org/10.1109/TRO.2025.3593084'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin deformation haptic devices worn on the finger pad provide realistic touch feedback during interactions with virtual objects. Two primary challenges in creating such devices are: first, making a multidegree-of-freedom device (DoF) that is small and lightweight so it does not encumber the wearer and second, providing accurate control of forces displayed to the finger pad. This work presents a 4-DoF finger pad haptic device, called Fourigami, that addresses these challenges. We address the first challenge using origami manufacturing methods and pneumatic actuation to fabricate a 25 g prototype that displays normal, shear, and twist and can be easily worn on the finger pad. We address the second challenge using a low-profile, 6-DoF, force/torque sensor to control forces displayed to the finger. Fourigami has a bandwidth ranging from 2 to 4 Hz depending on direction, and when acting on a human finger, it exerts forces ranging from $\pm$ 1.0 N in shear, 4.2 N in normal, and $\pm$ 4.2 N $\cdot$ mm of twist. Finally, we demonstrate the device’s efficacy when rendering haptic feedback to a user tracking a sinusoidal trajectory and a trajectory representing interactions with a virtual object.},
  archive      = {J_TROB},
  author       = {Crystal E. Winston and Hojung Choi and Rianna Jitosho and Zhenishbek Zhakypov and Jasmin E. Palmer and Mark R. Cutkosky and Allison M. Okamura},
  doi          = {10.1109/TRO.2025.3593084},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4829-4842},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Fourigami: A 4-degree-of-freedom, force-controlled, origami, finger pad haptic device},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monolithic programmable fabric-stacking enables multifunctional soft robots. <em>TROB</em>, <em>41</em>, 4810-4828. (<a href='https://doi.org/10.1109/TRO.2025.3593118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by natural organisms, soft robots have showcased remarkable performance across various functions. However, creating multifunctional soft robotic systems typically increases manufacturing complexity, resulting in a cumbersome fabrication workflow with low programmability. Here, we present a monolithic fabric-based approach for the programmable fabrication of multifunctional soft robots. Our method involves programming bonding paths and sequentially attaching fabric layers to directly manufacture monolithic robots. The fabric is precisely shaped using a laser cutter, while a 3-D printer follows predesigned bonding paths to ensure repeatable manufacturing. By programming the contours of each fabric layer and their corresponding bonding paths, we create versatile soft robots that integrate expected functionalities, including large-range manipulation, multimodal locomotion, and their harmonious combination. Our approach offers a promising avenue to efficiently create multifunctional soft robots via monolithic and customized fabrication, which will accelerate the proliferation of soft robots and open the doors to a wide range of applications.},
  archive      = {J_TROB},
  author       = {Jiaxi Wu and Mingxin Wu and Chen Wang and Guangming Xie},
  doi          = {10.1109/TRO.2025.3593118},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4810-4828},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Monolithic programmable fabric-stacking enables multifunctional soft robots},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time LSTM-driven dynamic gait mode detection for enhanced control of actuated ankle-foot orthosis. <em>TROB</em>, <em>41</em>, 4794-4809. (<a href='https://doi.org/10.1109/TRO.2025.3593111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The implementation of real-time gait mode detection is paramount for providing tailored support to individuals utilizing actuated ankle-foot orthoses (AAFOs), enhancing their walking and mobility. However, existing systems often rely on multiple sensors and struggle with accurate and prompt detection of gait transitions, especially in varied environments. This study develops a novel real-time gait mode detection system that accurately identifies five daily living gait modes including level walking, ramp ascent and descent, and stair ascent and descent using only two foot-mounted inertial measurement units. A long short-term memory based algorithm, trained on data from ten healthy subjects, extracts six kinematic features to predict gait modes. The proposed method integrates this detection system with a taskoriented control strategy to adapt AAFO control according to identified gait modes. Real-time experiments with three healthy participants demonstrated robust gait mode detection, achieving an average accuracy of $98 \pm 1$% across the five modes, even under assistive torque. In trials mimicking abnormal gait, the system maintained an accuracy of $93 \pm 3$%. Additionally, transition delays were analyzed, showing detection can occur between transitions of the leading and trailing foot. The control strategy reduced dorsiflexor and plantar-flexor muscle activation, measured by electromyography, and improved swing phase tracking performance. Detection robustness was further evaluated by walking with obstacles and changes in environmental dimensions.},
  archive      = {J_TROB},
  author       = {Huiseok Moon and Oussama Bey and Abderrahmane Boubezoul and Latifa Oukhellou and Samer Mohammed},
  doi          = {10.1109/TRO.2025.3593111},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4794-4809},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Real-time LSTM-driven dynamic gait mode detection for enhanced control of actuated ankle-foot orthosis},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic approach to feedback control enhances multilegged locomotion on rugged landscapes. <em>TROB</em>, <em>41</em>, 4776-4793. (<a href='https://doi.org/10.1109/TRO.2025.3593133'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving robust legged locomotion on complex terrains poses challenges due to the high uncertainty in robot–environment interactions. Recent advances in bipedal and quadrupedal robots demonstrate good mobility on rugged terrains but rely heavily on sensors for stability due to low static stability from a high center of mass and a narrow base of support (Ijspeert and Daley, 2023).We hypothesize that a multilegged robotic system can leverage morphological redundancy from additional legs to minimize sensing requirements when traversing challenging terrains. Studies suggest (Chong et al., 2023), (Chong et al., 2023) that a multilegged system with sufficient legs can reliably navigate noisy landscapes without sensing and control, albeit at a low speed of up to 0.1 body lengths per cycle (BLC). However, the feedback control framework to enhance speed of multilegged robots on challenging terrains remains underexplored due to diverse environmental interactions. Such complexity makes it difficult to identify the key parameters to control in these high-degree-of-freedom systems. Here, using laboratory and field experiments, we demonstrate that a vertical body undulation wave helps mitigate environmental disturbances that affect robot speed. These findings are supported by probabilistic models. Using such insights, we introduce a control framework, which monitors foot–ground contact patterns on rugose landscapes using binary foot–ground contact sensors to estimate terrain rugosity. The controller adjusts the vertical body wave based on the deviation of the limb’s averaged actual-to-ideal foot–ground contact ratio, achieving a significant enhancement of up to 0.235 BLC on rugose laboratory terrain. We observed a 50% to 60% increase in speed and a 30% to 50% reduction in speed variance compared to the open-loop controller. In addition, the controller operates in complex terrains outside the lab, including pine straw, robot-sized rocks, mud, and leaves.},
  archive      = {J_TROB},
  author       = {Juntao He and Baxi Chong and Jianfeng Lin and Zhaochen Xu and Hosain Bagheri and Esteban Flores and Daniel I. Goldman},
  doi          = {10.1109/TRO.2025.3593133},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4776-4793},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Probabilistic approach to feedback control enhances multilegged locomotion on rugged landscapes},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonmotorized hand exoskeleton for rescue and beyond: Substantially elevating grip endurance and strength. <em>TROB</em>, <em>41</em>, 4761-4775. (<a href='https://doi.org/10.1109/TRO.2025.3588750'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic hand exoskeletons hold immense potential for enhancing human hand functionality, addressing the hand’s strength limitations and fatigue during physically-demanding tasks. However, most existing hand exoskeletons are motorized, being weak in generating high supporting force for gripping augmentation. We present a nonmotorized hand exoskeleton based on magnetorheological (MR) actuators to provide high gripping support and elevate grip endurance. Meanwhile, it ingeniously harnesses human energy for actuation and energy storage, enhancing grip strength without external power. The MR actuator demonstrates a peak holding force of 1046 N with merely 5 W power input, boasting a force-to-power ratio one-order-of-magnitude higher than conventional approaches, and 97.7% energy reduction for same holding force compared to other approaches. Participants wearing the hand exoskeletons experience a 41.8% enhancement in grip strength without external power and reduced hand muscle fatigue during prolonged physical labor. In rescuing scenarios such as postearthquake rescue, debris clearance, and casualty evacuation, our exoskeleton effectively supports gripping and improves working efficiency.},
  archive      = {J_TROB},
  author       = {Xianlong Mai and Jian Yang and Lei Li and Bin Zi and Shiwu Zhang and Xinglong Gong and Weihua Li and Guolin Yun and Shuaishuai Sun},
  doi          = {10.1109/TRO.2025.3588750},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4761-4775},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Nonmotorized hand exoskeleton for rescue and beyond: Substantially elevating grip endurance and strength},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Co-optimizing reconfigurable environments and policies for decentralized multiagent navigation. <em>TROB</em>, <em>41</em>, 4741-4760. (<a href='https://doi.org/10.1109/TRO.2025.3588449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work views the multiagent system and its surrounding environment as a coevolving system, where the behavior of one affects the other. The goal is to take both agent actions and environment configurations as decision variables, and optimize these two components in a coordinated manner to improve some measure of interest. Toward this end, we consider the problem of decentralized multiagent navigation in a cluttered environment, where we assume that the layout of the environment is reconfigurable. By introducing two subobjectives—multiagent navigation and environment optimization—we propose an agent-environment co-optimization problem and develop a coordinated algorithm that alternates between these subobjectives to search for an optimal synthesis of agent actions and environment configurations; ultimately, improving the navigation performance. Due to the challenge of explicitly modeling the relation between the agents, the environment and their performance therein, we leverage policy gradient to formulate a model-free learning mechanism within the coordinated framework. A formal convergence analysis shows that our coordinated algorithm tracks the local minimum solution of an associated time-varying nonconvex optimization problem. Experiments corroborate theoretical findings and show the benefits of co-optimization. Interestingly, the results also indicate that optimized environments can offer structural guidance to deconflict agents in motion.},
  archive      = {J_TROB},
  author       = {Zhan Gao and Guang Yang and Amanda Prorok},
  doi          = {10.1109/TRO.2025.3588449},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4741-4760},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Co-optimizing reconfigurable environments and policies for decentralized multiagent navigation},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Can not touch this: Real-time, safe motion planning and control for manipulators under uncertainty. <em>TROB</em>, <em>41</em>, 4719-4740. (<a href='https://doi.org/10.1109/TRO.2025.3584557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring safe, real-time motion planning in arbitrary environments requires a robotic manipulator to avoid collisions, obey joint limits, and account for uncertainties in the mass and inertia of objects and the robot itself. This article proposes autonomous robust manipulation via optimization with uncertainty-aware reachability (ARMOUR), a provably-safe, receding-horizon trajectory planner and tracking controller framework for robotic manipulators to address these challenges. ARMOUR first constructs a robust controller that tracks desired trajectories with bounded error despite uncertain dynamics. ARMOUR then uses a novel recursive Newton–Euler method to compute all inputs required to track any trajectory within a continuum of desired trajectories. Finally, ARMOUR overapproximates the swept volume of the manipulator; this enables one to formulate an optimization problem that can be solved in real time to synthesize provably-safe motions. This article compares ARMOUR to state of the art methods on a set of challenging manipulation examples in simulation and demonstrates its ability to ensure safety on real hardware in the presence of model uncertainty without sacrificing performance.},
  archive      = {J_TROB},
  author       = {Jonathan Michaux and Patrick Holmes and Bohao Zhang and Che Chen and Baiyue Wang and Shrey Sahgal and Tiancheng Zhang and Sidhartha Dey and Shreyas Kousik and Ram Vasudevan},
  doi          = {10.1109/TRO.2025.3584557},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4719-4740},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Can not touch this: Real-time, safe motion planning and control for manipulators under uncertainty},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Innovative design of multifunctional supernumerary robotic limbs with ellipsoid workspace optimization. <em>TROB</em>, <em>41</em>, 4699-4718. (<a href='https://doi.org/10.1109/TRO.2025.3588763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supernumerary robotic limbs (SRLs) offer substantial potential in both the rehabilitation of hemiplegic patients and the enhancement of functional capabilities for healthy individuals. Designing a general-purpose SRL device is inherently challenging, particularly when developing a unified theoretical framework that meets the diverse functional requirements of both upper and lower limbs. In this article, we propose a multiobjective optimization (MOO) design theory that integrates grasping workspace similarity, walking workspace similarity, braced force for sit-to-stand (STS) movements, and overall mass and inertia. A geometric vector quantification method is developed using an ellipsoid to represent the workspace, aiming to reduce computational complexity and address quantification challenges. The ellipsoid envelope transforms workspace points into ellipsoid attributes, providing a parametric description of the workspace. Furthermore, the STS static braced force assesses the effectiveness of force transmission. The overall mass and inertia restricts excessive link length. To facilitate rapid and stable convergence of the model to high-dimensional irregular Pareto fronts, we introduce a multisubpopulation correction firefly algorithm. This algorithm incorporates a strategy involving attractive and repulsive domains to effectively handle the MOO task. The optimized solution is utilized to redesign the prototype for experimentation to meet specified requirements. Six healthy participants and two hemiplegia patients participated in real experiments. Compared to the preoptimization results, the average grasp success rate improved by 7.2%, while the muscle activity during walking and STS tasks decreased by an average of 12.7% and 25.1%, respectively. The proposed design theory offers an efficient option for the design of multifunctional SRL mechanisms.},
  archive      = {J_TROB},
  author       = {Jun Huo and Jian Huang and Jie Zuo and Bo Yang and Zhongzheng Fu and Xi Li and Samer Mohammed},
  doi          = {10.1109/TRO.2025.3588763},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4699-4718},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Innovative design of multifunctional supernumerary robotic limbs with ellipsoid workspace optimization},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust bipedal walking with closed-loop MPC: Adios stabilizers. <em>TROB</em>, <em>41</em>, 4679-4698. (<a href='https://doi.org/10.1109/TRO.2025.3588452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a novel walking control scheme based on the dynamics of the linear inverted pendulum (LIP) model. Pattern generation incorporates a model of contact forces, enabling closed-loop control of the humanoid robot’s state, including the center-of-mass position, velocity, and zero moment point. No additional control policies are required to maintain static and dynamic balance. Our approach also includes dynamic replanning of step locations and timings, thus preserving the LIP’s boundedness condition. We validated this controller on five different humanoid robots, testing its robustness through various disturbances, including sudden pushes during walking and static phases. In addition, our controller demonstrated effective locomotion over uneven and compliant terrain. Both simulation and experimental results confirm the effectiveness and robustness of this controller.},
  archive      = {J_TROB},
  author       = {Antonin Dallard and Mehdi Benallegue and Nicola Scianca and Fumio Kanehiro and Abderrahmane Kheddar},
  doi          = {10.1109/TRO.2025.3588452},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4679-4698},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robust bipedal walking with closed-loop MPC: Adios stabilizers},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). C$^{*}$: A new bounding approach for the moving-target traveling salesman problem. <em>TROB</em>, <em>41</em>, 4663-4678. (<a href='https://doi.org/10.1109/TRO.2025.3588754'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new bounding approach called Continuity* (C$^{*}$), which provides optimality guarantees for the moving-target traveling salesman problem (MT-TSP). Our approach relaxes the continuity constraints on the agent’s tour by partitioning the targets’ trajectories into smaller segments. This allows the agent to arrive at any point within a segment and depart from any point in the same segment when visiting each target. This formulation enables us to pose the bounding problem as a generalized traveling salesman problem on a graph, where the cost of traveling along an edge requires solving a new problem called the shortest feasible travel (SFT). We present various methods for computing bounds for the SFT problem, leading to several variants of C$^{*}$. We first prove that the proposed algorithms provide valid lower bounds for the MT-TSP. In addition, we provide computational results to validate the performance of all C$^{*}$ variants on instances with up to 15 targets. For the special case where targets move along straight lines, we compare our C$^{*}$ variants with a mixed-integer second order conic program (SOCP)-based method, the current state-of-the-art solver for the MT-TSP. While the SOCP-based method performs well on instances with five and ten targets, C$^{*}$ outperforms it on instances with 15 targets. For the general case, on average, our approaches find feasible solutions within approximately 4.5$\%$ of the lower bounds for the tested instances.},
  archive      = {J_TROB},
  author       = {Allen George Philip and Zhongqiang Ren and Sivakumar Rathinam and Howie Choset},
  doi          = {10.1109/TRO.2025.3588754},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4663-4678},
  shortjournal = {IEEE Trans. Robot.},
  title        = {C$^{*}$: A new bounding approach for the moving-target traveling salesman problem},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-to-end 2D-3D registration between image and LiDAR point cloud for vehicle localization. <em>TROB</em>, <em>41</em>, 4643-4662. (<a href='https://doi.org/10.1109/TRO.2025.3588454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot localization using a built map is essential for a variety of tasks including accurate navigation and mobile manipulation. A popular approach to robot localization is based on image-to-point cloud registration, which combines illumination-invariant LiDAR-based mapping with economical image-based localization. However, the recent works for image-to-point cloud registration either divide the registration into separate modules or project the point cloud to the depth image to register the RGB and depth images. In this article, we present I2PNet, a novel end-to-end 2D-3D registration network, which directly registers the raw 3-D point cloud with the 2-D RGB image using differential modules with a united target. The 2D-3D cost volume module for differential 2D-3D association is proposed to bridge feature extraction and pose regression. The soft point-to-pixel correspondence is implicitly constructed on the intrinsic-independent normalized plane in the 2D-3D cost volume module. Moreover, we introduce an outlier mask prediction module to filter the outliers in the 2D-3D association before pose regression. Furthermore, we propose the coarse-to-fine 2D-3D registration architecture to increase localization accuracy. Extensive localization experiments are conducted on the KITTI, nuScenes, M2DGR, Argoverse, Waymo, and Lyft5 datasets. The results demonstrate that I2PNet outperforms the state-of-the-art by a large margin and has a higher efficiency than the previous works. Moreover, we extend the application of I2PNet to the camera-LiDAR online calibration and demonstrate that I2PNet outperforms recent approaches on the online calibration task.},
  archive      = {J_TROB},
  author       = {Guangming Wang and Yu Zheng and Yuxuan Wu and Yanfeng Guo and Zhe Liu and Yixiang Zhu and Wolfram Burgard and Hesheng Wang},
  doi          = {10.1109/TRO.2025.3588454},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4643-4662},
  shortjournal = {IEEE Trans. Robot.},
  title        = {End-to-end 2D-3D registration between image and LiDAR point cloud for vehicle localization},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging probabilistic meshes for robust LiDAR mapping. <em>TROB</em>, <em>41</em>, 4622-4642. (<a href='https://doi.org/10.1109/TRO.2025.3582812'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although a good variety of successful LiDAR-based mapping schemes have been developed, these methods present shortcomings when mapping geometrically poor environments. In these scenarios, the chosen map structure and the consideration of map uncertainty are particularly relevant for providing a robust robot motion estimation, critically affecting the quality of the resulting map. This article introduces the use of probabilistic 3-D triangle meshes in LiDAR-based mapping. Our approach combines: 1) meshes, which consistently represent planar surfaces and enable the use of decimation techniques to reduce the influence of the measurement noise in the map and improve map fidelity, while strongly reducing the map size; with 2) a probabilistic on-manifold formulation of planar objects, which naturally reflects the measurement uncertainty in the mesh map avoiding inconsistencies in state estimation. The proposed methods are experimentally evaluated both individually and jointly integrated in a generic mapping scheme in different scenarios, showing the improvement in robustness and accuracy in geometrically poor environments and providing strong reductions in map size over existing schemes. We release the used datasets and C++ implementations of the proposed methods.},
  archive      = {J_TROB},
  author       = {Julio Paneque and J. Ramiro Martínez-de Dios and Aníbal Ollero},
  doi          = {10.1109/TRO.2025.3582812},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4622-4642},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Leveraging probabilistic meshes for robust LiDAR mapping},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning thin deformable object manipulation with a multisensory integrated soft hand. <em>TROB</em>, <em>41</em>, 4606-4621. (<a href='https://doi.org/10.1109/TRO.2025.3588448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic manipulation has made significant advancements, with systems demonstrating high precision and repeatability. However, this remarkable precision often fails to translate into efficient manipulation of thin deformable objects. Current robotic systems lack imprecise dexterity, the ability to perform dexterous manipulation through robust and adaptive behaviors that do not rely on precise control. This article explores the singulation and grasping of thin, deformable objects. Here, we propose a novel solution that incorporates passive compliance, touch, and proprioception into thin, deformable object manipulation. Our system employs a soft, underactuated hand that provides passive compliance, facilitating adaptive and gentle interactions to dexterously manipulate deformable objects without requiring precise control. The tactile and force/torque sensors equipped on the hand, along with a depth camera, gather sensory data required for manipulation via the proposed slip module. The manipulation policies are learned directly from raw sensory data via model-free reinforcement learning, bypassing explicit environmental and object modeling. We implement a hierarchical double-loop learning process to enhance learning efficiency by decoupling the action space. Our method was deployed on real-world robots and trained in a self-supervised manner. The resulting policy was tested on a variety of challenging tasks that were beyond the capabilities of prior studies, ranging from displaying suit fabric like a salesperson to turning pages of sheet music for violinists.},
  archive      = {J_TROB},
  author       = {Chao Zhao and Chunli Jiang and Lifan Luo and Shuai Yuan and Qifeng Chen and Hongyu Yu},
  doi          = {10.1109/TRO.2025.3588448},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4606-4621},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Learning thin deformable object manipulation with a multisensory integrated soft hand},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the fully decoupled rigid-body dynamics identification of serial industrial robots. <em>TROB</em>, <em>41</em>, 4588-4605. (<a href='https://doi.org/10.1109/TRO.2025.3578229'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate rigid-body dynamics is crucial for serial industrial robot applications, such as force control and physical human–robot interaction. Despite decades of research, the precise identification of dynamic parameters—particularly low-magnitude inertia parameters—remains a challenge for serial industrial robots. Researchers usually focus on developing various parameter estimation methods, while optimizing exciting trajectories in similar ways, typically minimizing the condition number of the information matrix. However, such optimization usually fails to ensure sufficient excitation for each parameter, due to nonconvex coupling effects. To address this limitation, we propose a fully decoupled rigid-body dynamics identification (FDRDI) method in this article. This approach innovatively eliminates coupling effects by using novel symmetrical exciting trajectories based on reciprocating S-curve. This innovation enables the independent identification of dynamic parameters associated with joint friction, as well as the gravity and inertia of links and payloads. Comparative experiments show that FDRDI achieves superior identification accuracy, evidenced by reduced joint torque prediction errors and payload parameter estimation errors.},
  archive      = {J_TROB},
  author       = {Jinfei Hu and Zelong Chen and Yinjie Lin and Zheng Chen and Bin Yao and Xin Ma},
  doi          = {10.1109/TRO.2025.3578229},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4588-4605},
  shortjournal = {IEEE Trans. Robot.},
  title        = {On the fully decoupled rigid-body dynamics identification of serial industrial robots},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Baseline policy adapting and abstraction of shared autonomy for high-level robot operations. <em>TROB</em>, <em>41</em>, 4574-4587. (<a href='https://doi.org/10.1109/TRO.2025.3588455'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel shared autonomy and baseline policy adapting framework for human–robot interactions in high-level context-aware robotic tasks. With a unique methodology that leverages hierarchies in decision-making as well as variational analysis of human policy, we propose a mathematical model of shared autonomy policy. The framework aims at interpretable high-level decision-making for efficient robot operation with human in the loop. We modeled the decision-making process using hierarchical Markov decision processes in an algorithm we called policy adapting, where the autonomous system policy is adapted, and hence shaped by incorporating design variables contextual to the robot, human, task, and pretraining. By integrating deep reinforcement learning within a multiagent hierarchical context, we present an end-to-end algorithm to train a baseline policy designed for shared autonomy. We showcase the effectiveness of our framework, and particularly the interplay between different design elements and human’s skill level, in a pilot study with a human user in a simulated sequence of high-level pick-and-place tasks. The proposed framework advances the state of the art in shared autonomy for robotic tasks, but can also be applied to other domains of autonomous operation.},
  archive      = {J_TROB},
  author       = {Ehsan Yousefi and Mo Chen and Inna Sharf},
  doi          = {10.1109/TRO.2025.3588455},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4574-4587},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Baseline policy adapting and abstraction of shared autonomy for high-level robot operations},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalizable motion policies through keypoint parameterization and transportation maps. <em>TROB</em>, <em>41</em>, 4557-4573. (<a href='https://doi.org/10.1109/TRO.2025.3582821'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from Interactive Demonstrations has revolutionized the way nonexpert humans teach robots. It is enough to kinesthetically move the robot around to teach pick-and-place, dressing, or cleaning policies. However, the main challenge is correctly generalizing to novel situations, e.g., different surfaces to clean or different arm postures to dress. This article proposes a novel task parameterization and generalization to transport the original robot policy, i.e., position, velocity, orientation, and stiffness. Unlike the state of the art, only a set of keypoints is tracked during the demonstration and the execution, e.g., a point cloud of the surface to clean. We then propose to fit a nonlinear transformation that would deform the space and then the original policy using the paired source and target point sets. The use of function approximators like Gaussian Processes allows us to generalize, or transport, the policy from every space location while estimating the uncertainty of the resulting policy due to the limited task keypoints and the reduced number of demonstrations. We compare the algorithm’s performance with state-of-the-art task parameterization alternatives and analyze the effect of different function approximators. We also validated the algorithm on robot manipulation tasks, i.e., different posture arm dressing, different location product reshelving, and different shape surface cleaning.},
  archive      = {J_TROB},
  author       = {Giovanni Franzese and Ravi Prakash and Cosimo Della Santina and Jens Kober},
  doi          = {10.1109/TRO.2025.3582821},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4557-4573},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Generalizable motion policies through keypoint parameterization and transportation maps},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CURL-SLAM: Continuous and compact LiDAR mapping. <em>TROB</em>, <em>41</em>, 4538-4556. (<a href='https://doi.org/10.1109/TRO.2025.3588442'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies 3-D light detection and ranging (LiDAR) mapping with a focus on developing an updatable and localizable map representation that enables continuity, compactness, and consistency in 3-D maps. Traditional LiDAR simultaneous localization and mapping (SLAM) systems often rely on 3-D point cloud maps, which typically require extensive storage to preserve structural details in large-scale environments. In this article, we propose a novel paradigm for LiDAR SLAM by leveraging the continuous and ultracompact representation of LiDAR (CURL). Our proposed LiDAR mapping approach, CURL-SLAM, produces compact 3-D maps capable of continuous reconstruction at variable densities using CURL’s spherical harmonics implicit encoding, and achieves global map consistency after loop closure. Unlike popular iterative-closest-point-based LiDAR odometry techniques, CURL-SLAM formulates LiDAR pose estimation as a unique optimization problem tailored for CURL and extends it to local bundle adjustment, enabling simultaneous pose refinement and map correction. Experimental results demonstrate that CURL-SLAM achieves state of the art 3-D mapping quality and competitive LiDAR trajectory accuracy, delivering sensor-rate real-time performance (10 Hz) on a CPU. We will release the CURL-SLAM implementation to the community.},
  archive      = {J_TROB},
  author       = {Kaicheng Zhang and Shida Xu and Yining Ding and Xianwen Kong and Sen Wang},
  doi          = {10.1109/TRO.2025.3588442},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4538-4556},
  shortjournal = {IEEE Trans. Robot.},
  title        = {CURL-SLAM: Continuous and compact LiDAR mapping},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Perceptive mixed-integer footstep control for underactuated bipedal walking on rough terrain. <em>TROB</em>, <em>41</em>, 4518-4537. (<a href='https://doi.org/10.1109/TRO.2025.3587998'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traversing rough terrain requires dynamic bipeds to stabilize themselves through foot placement without stepping into unsafe areas. Planning these footsteps online is challenging given the nonconvexity of the safe terrain and imperfect perception and state estimation. This article addresses these challenges with a full-stack perception and control system for achieving underactuated walking on discontinuous terrain. First, we develop model-predictive footstep control, a single mixed-integer quadratic program, which assumes a convex polygon terrain decomposition to optimize over discrete foothold choice, footstep position, ankle torque, template dynamics, and footstep timing at over 100 Hz. We then propose a novel approach for generating convex polygon terrain decompositions online. Our perception stack decouples safe-terrain classification from fitting planar polygons, generating a temporally consistent terrain segmentation in real time using a single CPU thread. We demonstrate the performance of our perception and control stack through outdoor experiments with the underactuated biped Cassie, achieving state of the art perceptive bipedal walking on discontinuous terrain.},
  archive      = {J_TROB},
  author       = {Brian Acosta and Michael Posa},
  doi          = {10.1109/TRO.2025.3587998},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4518-4537},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Perceptive mixed-integer footstep control for underactuated bipedal walking on rough terrain},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed multiagent reinforcement learning for distributed multirobot problems. <em>TROB</em>, <em>41</em>, 4499-4517. (<a href='https://doi.org/10.1109/TRO.2025.3582836'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The networked nature of multirobot systems presents challenges in the context of multiagent reinforcement learning. Centralized control policies do not scale with increasing numbers of robots, whereas independent control policies do not exploit the information provided by other robots, exhibiting poor performance in cooperative-competitive tasks. In this work, we propose a physics-informed reinforcement learning approach able to learn distributed multirobot control policies that are both scalable and make use of all the available information to each robot. Our approach has three key characteristics. First, it imposes a port-Hamiltonian structure on the policy representation, respecting energy conservation properties of physical robot systems and the networked nature of robot team interactions. Second, it uses self-attention to ensure a sparse policy representation able to handle time-varying information at each robot from the interaction graph. Third, we present a soft actor–critic reinforcement learning algorithm parameterized by our self-attention port-Hamiltonian control policy, which accounts for the correlation among robots during training while overcoming the need of value function factorization. Extensive simulations in different multirobot scenarios demonstrate the success of the proposed approach, surpassing previous multirobot reinforcement learning solutions in scalability, while achieving similar or superior performance (with averaged cumulative reward up to $\times {\text{2}}$ greater than the state-of-the-art with robot teams $\times {\text{6}}$ larger than the number of robots at training time). We also validate our approach on multiple real robots in the Georgia Tech Robotarium under imperfect communication, demonstrating zero-shot sim-to-real transfer and scalability across number of robots.},
  archive      = {J_TROB},
  author       = {Eduardo Sebastián and Thai Duong and Nikolay Atanasov and Eduardo Montijano and Carlos Sagüés},
  doi          = {10.1109/TRO.2025.3582836},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4499-4517},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Physics-informed multiagent reinforcement learning for distributed multirobot problems},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BEVPlace++: Fast, robust, and lightweight LiDAR global localization for autonomous ground vehicles. <em>TROB</em>, <em>41</em>, 4479-4498. (<a href='https://doi.org/10.1109/TRO.2025.3585385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces BEVPlace++, a novel, fast, and robust light detection and ranging (LiDAR) global localization method for autonomous ground vehicles (AGV). It uses lightweight convolutional neural networks (CNNs) on bird’s eye view (BEV) image-like representations of LiDAR data to achieve accurate global localization through place recognition, followed by 3-degrees of freedom (DoF) pose estimation. Our detailed analyses reveal an interesting fact that CNNs are inherently effective at extracting distinctive features from LiDAR BEV images. Remarkably, keypoints of two BEV images with large translations can be effectively matched using CNN-extracted features. Building on this insight, we design a rotation equivariant module (REM) to obtain distinctive features while enhancing robustness to rotational changes. A rotation equivariant and invariant network (REIN) is then developed by cascading REM and a descriptor generator, NetVLAD, to sequentially generate rotation equivariant local features and rotation invariant global descriptors. The global descriptors are used first to achieve robust place recognition, and then local features are used for accurate pose estimation. Experimental results on seven public datasets and our AGV platform demonstrate that BEVPlace++, even when trained on a small dataset (3000 frames of KITTI) only with place labels, generalizes well to unseen environments, performs consistently across different days and years, and adapts to various types of LiDAR scanners. BEVPlace++ achieves state-of-the-art performance in multiple tasks, including place recognition, loop closure detection, and global localization. In addition, BEVPlace++ is lightweight, runs in real-time, and does not require accurate pose supervision, making it highly convenient for deployment.},
  archive      = {J_TROB},
  author       = {Lun Luo and Si-Yuan Cao and Xiaorui Li and Jintao Xu and Rui Ai and Zhu Yu and Xieyuanli Chen},
  doi          = {10.1109/TRO.2025.3585385},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4479-4498},
  shortjournal = {IEEE Trans. Robot.},
  title        = {BEVPlace++: Fast, robust, and lightweight LiDAR global localization for autonomous ground vehicles},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Seeing through uncertainty: Robot pose estimation based on imperfect prior kinematic knowledge. <em>TROB</em>, <em>41</em>, 4459-4478. (<a href='https://doi.org/10.1109/TRO.2025.3577030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present prior knowledge robot keypoint detection (PK-ROKED), a learning-based pipeline for probabilistic robot pose estimation relative to a camera, addressing inaccuracies in forward kinematics, particularly in systems with elastic and lightweight modules. Our approach integrates a probabilistic 2-D keypoint detection mechanism that leverages prior knowledge derived from the robot’s imprecise kinematics. We further improve the detection accuracy and geometric understanding by incorporating segmentation of the robot arm. The method computes reliable uncertainty estimates, enabling a robust 2D–6D fusion for precise robot arm pose estimation from a single detected keypoint. PK-ROKED requires only synthetic training data, effectively exploits imperfect kinematics as valuable prior knowledge, and introduces a novel fusion framework for enhanced robot pose estimation. We validate our method on the Panda-Orb dataset, demonstrating competitive performance against state-of-the-art approaches. In addition, we evaluate on two other robotic systems in real-world scenarios and show its practicality by using the predictions to initialize a tracking algorithm. Code and pretrained models are available.},
  archive      = {J_TROB},
  author       = {Leonard Klüpfel and Lukas Burkhard and Anne Elisabeth Reichert and Maximilian Durner and Rudolph Triebel},
  doi          = {10.1109/TRO.2025.3577030},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4459-4478},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Seeing through uncertainty: Robot pose estimation based on imperfect prior kinematic knowledge},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-based visual-inertial state estimation for high-speed maneuvers. <em>TROB</em>, <em>41</em>, 4439-4458. (<a href='https://doi.org/10.1109/TRO.2025.3584544'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuromorphic event-based cameras are bioinspired visual sensors with asynchronous pixels and extremely high temporal resolution. Such favorable properties make them an excellent choice for solving state estimation tasks under high-speed maneuvers. However, failures of camera pose tracking are frequently witnessed in state-of-the-art event-based visual odometry systems when the local map cannot be updated timely or feature matching is unreliable. One of the biggest roadblocks in this field is the absence of efficient and robust methods for data association without imposing any assumptions on the environment. This problem seems, however, unlikely to be addressed as in standard vision because of the motion-dependent nature of event data. To address this, we propose a map-free design for event-based visual-inertial state estimation in this article. Instead of estimating camera position, we find that recovering the instantaneous linear velocity aligns better with event cameras’ differential working principle. The proposed system uses raw data from a stereo event camera and an inertial measurement unit (IMU) as input, and adopts a dual-end architecture. The front-end preprocesses raw events and executes the computation of normal flow and depth information. To handle the temporally nonequispaced event data and establish association with temporally nonaligned IMU’s measurements, the back-end employs a continuous-time formulation and a sliding-window scheme that can progressively estimate the linear velocity and IMU’s bias. Experiments on synthetic and real data show our method achieves low-latency, metric-scale velocity estimation. To the best of the authors’ knowledge, this is the first real-time, purely event-based visual-inertial state estimator for high-speed maneuvers, requiring only sufficient textures and imposing no additional constraints on either the environment or motion pattern.},
  archive      = {J_TROB},
  author       = {Xiuyuan Lu and Yi Zhou and Jiayao Mai and Kuan Dai and Yang Xu and Shaojie Shen},
  doi          = {10.1109/TRO.2025.3584544},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4439-4458},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Event-based visual-inertial state estimation for high-speed maneuvers},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning multimodal latent dynamics for Human–Robot interaction. <em>TROB</em>, <em>41</em>, 4418-4438. (<a href='https://doi.org/10.1109/TRO.2025.3582829'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a method for learning well-coordinated human–robot interaction (HRI) from human–human interactions (HHI). We devise a hybrid approach using hidden Markov models (HMMs) as the latent space priors for a variational autoencoder to model a joint distribution over the interacting agents. We leverage the interaction dynamics learned from HHI to learn HRI and incorporate the conditional generation of robot motions from human observations into the training, thereby predicting more accurate robot trajectories. The generated robot motions are further adapted with inverse kinematics to ensure the desired physical proximity with a human, combining the ease of joint space learning and accurate task space reachability. For contact-rich interactions, we modulate the robot’s stiffness using HMM segmentation for a compliant interaction. We verify the effectiveness of our approach deployed on a humanoid robot via a user study. Our method generalizes well to various humans despite being trained on data from just two humans. We find that users perceive our method as more human-like, timely, and accurate and rank our method with a higher degree of preference over other baselines. We additionally show the ability of our approach to generate successful interactions in a more complex scenario of bimanual robot-to-human handovers.},
  archive      = {J_TROB},
  author       = {Vignesh Prasad and Lea Heitlinger and Dorothea Koert and Ruth Stock-Homburg and Jan Peters and Georgia Chalvatzaki},
  doi          = {10.1109/TRO.2025.3582829},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4418-4438},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Learning multimodal latent dynamics for Human–Robot interaction},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A closed-chain approach to generating affordance joint trajectories for robotic manipulators. <em>TROB</em>, <em>41</em>, 4398-4417. (<a href='https://doi.org/10.1109/TRO.2025.3582832'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots operating in unpredictable environments require versatile, hardware-agnostic frameworks capable of adapting to various tasks. While a recent screw-based affordance approach shows promise, it faces challenges in avoiding undesirable configurations, singularity navigation, and task success prediction. To address these limitations, we propose a novel framework that incorporates gripper orientation control and generates complete joint trajectories in real time for screw-based task affordance execution. Our method models the affordance and manipulator as a closed-chain mechanism, introducing an innovative approach to solving closed-chain inverse kinematics. It encapsulates task constraints and simplifies task definitions, while remaining hardware and robot agnostic, robust to errors, and invariant to the initial grasp. We validate our framework with simulations on a UR5 robot and real-world implementation on a Boston Dynamics Spot robot. Our experiments demonstrate rapid joint trajectory generation (0.0077–0.098 s) for various tasks, including a 420$^\circ$ valve turn with consideration of the gripper orientation. Comparison with the state-of-the-art methods shows a 4x improvement in planning time, reduced joint movement, and achievement of greater task goals. Video demonstrations and the open-source code for this project are available online.},
  archive      = {J_TROB},
  author       = {Janak Panthi and Farshid Alambeigi and Mitch Pryor},
  doi          = {10.1109/TRO.2025.3582832},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4398-4417},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A closed-chain approach to generating affordance joint trajectories for robotic manipulators},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Let us make a splan: Risk-aware trajectory optimization in a normalized gaussian splat. <em>TROB</em>, <em>41</em>, 4380-4397. (<a href='https://doi.org/10.1109/TRO.2025.3584559'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural radiance fields and Gaussian splatting have recently transformed computer vision by enabling photorealistic representations of complex scenes. However, they have seen limited applications in real-world robotics tasks, such as trajectory optimization. This is due to the difficulty in reasoning about collisions in radiance models and the computational complexity associated with operating in dense models. This article addresses these challenges by proposing SPLANNING, a risk-aware trajectory optimizer operating in a Gaussian Splatting model. This article first derives a method to rigorously upper bound the probability of collision between a robot and a radiance field. Then, this article introduces a normalized reformulation of Gaussian splatting that enables efficient computation of this collision bound. Finally, this article presents a method to optimize trajectories that avoid collisions in a Gaussian splat. Experiments show that SPLANNING outperforms state-of-the-art methods in generating collision-free trajectories in cluttered environments. The proposed system is also tested on a real-world robot manipulator.},
  archive      = {J_TROB},
  author       = {Jonathan Michaux and Seth Isaacson and Challen Enninful Adu and Adam Li and Rahul Kashyap Swayampakula and Parker Ewen and Sean Rice and Katherine A. Skinner and Ram Vasudevan},
  doi          = {10.1109/TRO.2025.3584559},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4380-4397},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Let us make a splan: Risk-aware trajectory optimization in a normalized gaussian splat},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DexSim2Real$^{\mathbf{2}}$: Building explicit world model for precise articulated object dexterous manipulation. <em>TROB</em>, <em>41</em>, 4360-4379. (<a href='https://doi.org/10.1109/TRO.2025.3584504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Articulated objects are ubiquitous in daily life. In this article, we present DexSim2Real$^{\mathbf{2}}$, a novel framework for goal-conditioned articulated object manipulation. The core of our framework is constructing an explicit world model of unseen articulated objects through active interactions, which enables sampling-based model-predictive control to plan trajectories achieving different goals without requiring demonstrations or reinforcement learning. It first predicts an interaction using an affordance network trained on self-supervised interaction data or videos of human manipulation. After executing the interactions on the real robot to move the object parts, we propose a novel modeling pipeline based on 3-D artificial intelligence generated content to build a digital twin of the object in simulation from multiple frames of observations. For dexterous hands, we utilize eigengrasp to reduce the action dimension, enabling more efficient trajectory searching. Experiments validate the framework’s effectiveness for precise manipulation using a suction gripper, a two-finger gripper, and two dexterous hands. The generalizability of the explicit world model also enables advanced manipulation strategies, such as manipulating with tools.},
  archive      = {J_TROB},
  author       = {Taoran Jiang and Yixuan Guan and Liqian Ma and Jing Xu and Jiaojiao Meng and Weihang Chen and Zecui Zeng and Lusong Li and Dan Wu and Rui Chen},
  doi          = {10.1109/TRO.2025.3584504},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4360-4379},
  shortjournal = {IEEE Trans. Robot.},
  title        = {DexSim2Real$^{\mathbf{2}}$: Building explicit world model for precise articulated object dexterous manipulation},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of an electromagnetic coil array system for large-scale ferrofluid droplet robots programmable control. <em>TROB</em>, <em>41</em>, 4342-4359. (<a href='https://doi.org/10.1109/TRO.2025.3584430'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Programmable manipulation of fluid-based soft robots has recently attracted considerable attention. Achieving parallel control of large-scale ferrofluid droplet robots (FDRs) is still one of the major challenges that remain unsolved. In this article, we develop a distributed magnetic field control platform to generate a series of localized magnetic fields that enable the simultaneous control of many FDRs, allowing teams of FDRs to collaborate in parallel for multifunctional manipulation tasks. Based on the mathematical model using the finite element method, we first evaluate the distribution properties of the local magnetic fields as well as the gradients generated by individual electromagnets. Meanwhile, the locomotion and deformation behavior of the FDR is also characterized to verify the actuation performance of the developed system. Subsequently, a vision-based closed-loop feedback control strategy is then presented, which aims to achieve path tracking of multiple robot formations. Thermal analysis shows that the system’s low output power enables reliable and sustained long-term operation. Finally, the developed system is tested through extensive physical experiments with different numbers of FDRs. The results demonstrate the potential of the designed setup in manipulating dozens of FDRs for digital display, message encoding, and microfluidic logistics. To the best of authors’ knowledge, this is the first attempt that allows independent control of such scale droplet robots (up to 72) for cooperative applications.},
  archive      = {J_TROB},
  author       = {Guangming Cui and Haozhi Huang and Xianrui Zhang and Yueyue Liu and Qigao Fan and Yining Xu and Ang Liu and Baijin Mao and Tian Qiu and Juntian Qu},
  doi          = {10.1109/TRO.2025.3584430},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4342-4359},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Development of an electromagnetic coil array system for large-scale ferrofluid droplet robots programmable control},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simultaneous system identification and model predictive control with no dynamic regret. <em>TROB</em>, <em>41</em>, 4322-4341. (<a href='https://doi.org/10.1109/TRO.2025.3576969'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide an algorithm for the simultaneous system identification and model predictive control of nonlinear systems. The algorithm has finite-time near-optimality guarantees and asymptotically converges to the optimal (noncausal) controller. Particularly, the algorithm enjoys sublinear dynamic regret, defined herein as the suboptimality against an optimal clairvoyant controller that knows how the unknown disturbances and system dynamics will adapt to its actions. The algorithm is self-supervised and applies to control-affine systems with unknown dynamics and disturbances that can be expressed in reproducing kernel Hilbert spaces. Such spaces can model external disturbances and modeling errors that can even be adaptive to the system’s state and control input. For example, they can model wind and wave disturbances to aerial and marine vehicles, or inaccurate model parameters such as inertia of mechanical systems. We are motivated by the future of autonomy where robots will autonomously perform complex tasks despite real-world unknown disturbances such as wind gusts. The algorithm first generates random Fourier features that are used to approximate the unknown dynamics or disturbances. Then, it employs model predictive control based on the current learned model of the unknown dynamics (or disturbances). The model of the unknown dynamics is updated online using least squares based on the data collected while controlling the system. We validate our algorithm in both hardware experiments and physics-based simulations. The simulations include a cart-pole aiming to maintain the pole upright despite inaccurate model parameters and a quadrotor aiming to track reference trajectories despite unmodeled aerodynamic drag effects. The hardware experiments include a quadrotor aiming to track a circular trajectory despite unmodeled aerodynamic drag effects, ground effects, and wind disturbances.},
  archive      = {J_TROB},
  author       = {Hongyu Zhou and Vasileios Tzoumas},
  doi          = {10.1109/TRO.2025.3576969},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4322-4341},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Simultaneous system identification and model predictive control with no dynamic regret},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust-locomotion-by-logic: Perturbation-resilient bipedal locomotion via signal temporal logic guided model predictive control. <em>TROB</em>, <em>41</em>, 4300-4321. (<a href='https://doi.org/10.1109/TRO.2025.3582820'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a robust planning framework that utilizes a model predictive control (MPC) approach, enhanced by incorporating signal temporal logic (STL) specifications. This marks the first-ever study to apply STL-guided trajectory optimization for bipedal locomotion, specifically designed to handle both translational and orientational perturbations. Existing recovery strategies often struggle with reasoning complex task logic and evaluating locomotion robustness systematically, making them susceptible to failures caused by inappropriate recovery strategies or lack of robustness. To address these issues, we design an analytical stability metric for bipedal locomotion and quantify this metric using STL specifications, which guide the generation of recovery trajectories to achieve maximum robustness degree. To enable safe and computational-efficient crossed-leg maneuver, we design data-driven self-leg-collision constraints that are 1000 times faster than the traditional inverse-kinematics-based approach. Our framework outperforms a state-of-the-art locomotion controller, a standard MPC without STL, and a linear-temporal-logic-based planner in a high-fidelity dynamic simulation, especially in scenarios involving crossed-leg maneuvers. In addition, the Cassie bipedal robot achieves robust performance under horizontal and orientational perturbations, such as those observed in ship motions. These environments are validated in simulations and deployed on hardware. Furthermore, our proposed method demonstrates versatility on stepping stones and terrain-agnostic features on inclined terrains.},
  archive      = {J_TROB},
  author       = {Zhaoyuan Gu and Yuntian Zhao and Yipu Chen and Rongming Guo and Jennifer K. Leestma and Gregory S. Sawicki and Ye Zhao},
  doi          = {10.1109/TRO.2025.3582820},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4300-4321},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robust-locomotion-by-logic: Perturbation-resilient bipedal locomotion via signal temporal logic guided model predictive control},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LUDO: Low-latency understanding of deformable objects using point cloud occupancy functions. <em>TROB</em>, <em>41</em>, 4283-4299. (<a href='https://doi.org/10.1109/TRO.2025.3582837'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately determining the shape of deformable objects and the location of their internal structures is crucial for medical tasks that require precise targeting, such as robotic biopsies. We introduce a method for accurate low-latency understanding of deformable objects (LUDO). LUDO reconstructs objects in their deformed state, including their internal structures, from a single-view point cloud observation in under 30 ms using occupancy networks. LUDO provides uncertainty estimates for its predictions. In addition, it provides explainability by highlighting key features in its input observations. Both uncertainty and explainability are important for safety-critical applications, such as surgery. We evaluate LUDO in real-world robotic experiments, achieving a success rate of 98.9% for puncturing various regions of interest (ROIs) inside deformable objects. We compare LUDO to a popular baseline and show its superior ROI localization accuracy, training time, and memory requirements. LUDO demonstrates the potential to interact with deformable objects without the need for deformable registration methods.},
  archive      = {J_TROB},
  author       = {Pit Henrich and Franziska Mathis-Ullrich and Paul Maria Scheikl},
  doi          = {10.1109/TRO.2025.3582837},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4283-4299},
  shortjournal = {IEEE Trans. Robot.},
  title        = {LUDO: Low-latency understanding of deformable objects using point cloud occupancy functions},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A versatile neural network configuration space planning and control strategy for modular soft robot arms. <em>TROB</em>, <em>41</em>, 4269-4282. (<a href='https://doi.org/10.1109/TRO.2025.3582807'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modular soft robot arms (MSRAs) are composed of multiple modules connected in a sequence, and they can bend at different angles in various directions. This capability allows MSRAs to perform more intricate tasks than single-module robots. However, the modular structure also induces challenges in accurate planning and control. Nonlinearity and hysteresis complicate the physical model, while the modular structure and increased degrees of freedom further lead to cumulative errors along the sequence. To address these challenges, we propose a versatile configuration space planning and control strategy for MSRAs, named state to configuration to action. Our approach formulates an optimization problem, state to configuration planning, which integrates various loss functions and a forward model based on biLSTM to generate configuration trajectories based on target states. A configuration controller configuration to action control based on biLSTM is implemented to follow the planned configuration trajectories, leveraging only inaccurate internal sensing feedback. We validate our strategy using a cable-driven MSRA, demonstrating its ability to perform diverse offline tasks such as position and orientation control and obstacle avoidance. Furthermore, our strategy endows MSRA with online interaction capability with targets and obstacles. Future work focuses on addressing MSRA challenges, such as more accurate physical models.},
  archive      = {J_TROB},
  author       = {Zixi Chen and Qinghua Guan and Josie Hughes and Arianna Menciassi and Cesare Stefanini},
  doi          = {10.1109/TRO.2025.3582807},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4269-4282},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A versatile neural network configuration space planning and control strategy for modular soft robot arms},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GS-LIVO: Real-time LiDAR, inertial, and visual multisensor fused odometry with gaussian mapping. <em>TROB</em>, <em>41</em>, 4253-4268. (<a href='https://doi.org/10.1109/TRO.2025.3582809'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, 3-D Gaussian splatting (3D-GS) has emerged as a novel scene representation approach. However, existing vision-only 3D-GS methods often rely on hand-crafted heuristics for point-cloud densification and face challenges in handling occlusions and high graphics processing unit (GPU) memory and computation consumption. Light detection and ranging (LiDAR)-inertial-visual sensor configuration has demonstrated superior performance in precise localization and dense mapping by leveraging complementary sensing characteristics: rich texture information from cameras, precise geometric measurements from LiDAR, and high-frequency motion data from inertial measurement unit. Inspired by this, we propose a novel real-time Gaussian-based simultaneous localization and mapping system. Our map system comprises a global Gaussian map and a sliding window of Gaussians, along with an iterative error state Kalman filter (IESKF)-based real-time odometry utilizing Gaussian maps. The structure of the global Gaussian map consists of hash-indexed voxels organized in a recursive octree. This hierarchical structure effectively covers sparse spatial volumes while adapting to different levels of detail and scales in the environment. The Gaussian map is efficiently initialized through multisensor fusion and optimized with photometric gradients. Our system incrementally maintains a sliding window of Gaussians with minimal graphics memory usage, significantly reducing GPU computation and memory consumption by only optimizing the map within the sliding window, enabling real-time optimization. Moreover, we implement a tightly coupled multisensor fusion odometry with an IESKF, which leverages real-time updating and rendering of the Gaussian map to achieve competitive localization accuracy. Our system represents the first real-time Gaussian-based SLAM framework deployable on resource-constrained embedded systems (all implemented in C++/CUDA for efficiency), demonstrated on the NVIDIA Jetson Orin NX platform. The framework achieves real-time performance while maintaining robust multisensor fusion capabilities. All implementation algorithms, hardware designs, and CAD models and demo video of our GPU-accelerated system will be publicly available.},
  archive      = {J_TROB},
  author       = {Sheng Hong and Chunran Zheng and Yishu Shen and Changze Li and Fu Zhang and Tong Qin and Shaojie Shen},
  doi          = {10.1109/TRO.2025.3582809},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4253-4268},
  shortjournal = {IEEE Trans. Robot.},
  title        = {GS-LIVO: Real-time LiDAR, inertial, and visual multisensor fused odometry with gaussian mapping},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Help me through: Imitation learning based active view planning to avoid SLAM tracking failures. <em>TROB</em>, <em>41</em>, 4236-4252. (<a href='https://doi.org/10.1109/TRO.2025.3582817'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale evaluation of state-of-the-art visual simultaneous localization and mapping (SLAM) has shown that its tracking performance degrades considerably if the camera view is not adjusted to avoid the low-texture areas. Deep reinforcement learning (RL)-based approaches have been proposed to improve the robustness of visual tracking in such unsupervised settings. Our extensive analysis reveals the fundamental limitations of RL-based active view planning, especially in transition scenarios (entering/exiting the room, texture-less walls, and lobbies). In challenging transition scenarios, the agent generally remains unable to cross the transition during training, limiting its ability to learn the maneuver. We propose human-supervised RL training (imitation learning) and achieve significantly improved performance after $\sim$50 h of supervised training. To reduce longer human supervision requirements, we also explore fine-tuning our network with an online learning policy. Here, we use limited human-supervised training ($\sim$20 h), and fine-tune the network with unsupervised training ($\sim$45 h), obtaining encouraging results. We also release our multimodel, human supervised training dataset. The dataset contains challenging and diverse transition scenarios and can aid the development of imitation learning policies for consistent visual tracking. We also release our implementation.},
  archive      = {J_TROB},
  author       = {Kanwal Naveed and Wajahat Hussain and Irfan Hussain and Donghwan Lee and Muhammad Latif Anjum},
  doi          = {10.1109/TRO.2025.3582817},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4236-4252},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Help me through: Imitation learning based active view planning to avoid SLAM tracking failures},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). To lead or to follow? adaptive robot task planning in Human–Robot collaboration. <em>TROB</em>, <em>41</em>, 4215-4235. (<a href='https://doi.org/10.1109/TRO.2025.3582816'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive task planning is fundamental to ensuring effective and seamless human–robot collaboration. This article introduces a robot task planning framework that takes into account both human leading/following preferences and performance, specifically focusing on task allocation and scheduling in collaborative settings. We present a proactive task allocation approach with three primary objectives: 1) enhancing team performance; 2) incorporating human preferences; and 3) upholding a positive human perception of the robot and the collaborative experience. Through a user study, involving an autonomous mobile manipulator robot working alongside participants in a collaborative scenario, we confirm that the task planning framework successfully attains all three intended goals, thereby contributing to the advancement of adaptive task planning in human–robot collaboration. This article mainly focuses on the first two objectives, and we discuss the third objective, participants’ perception of the robot, tasks, and collaboration in a companion article.},
  archive      = {J_TROB},
  author       = {Ali Noormohammadi-Asl and Stephen L. Smith and Kerstin Dautenhahn},
  doi          = {10.1109/TRO.2025.3582816},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4215-4235},
  shortjournal = {IEEE Trans. Robot.},
  title        = {To lead or to follow? adaptive robot task planning in Human–Robot collaboration},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EeLsT: An energy-efficient long-short term approach for sustainable sailboat autonomy in disturbed marine environment. <em>TROB</em>, <em>41</em>, 4195-4214. (<a href='https://doi.org/10.1109/TRO.2025.3577058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sailboats are purely wind-driven, and thus, have great potential for long-term voyaging. For robotic sailboats, the constraints on the energy of the control boards, sensors, communication modules, and actuators are crucial to the sustainability of automation. Reducing the control frequency of actuators is crucial for energy conservation. This study proposes an energy-efficient long-short term (EeLsT) approach for sustainable sailing. In EeLsT, long-term and short-term observers are designed to adaptively take control decisions for time-varying environmental influences (e.g., waves and currents). Our approach can be generally applied as an energy management module in sailing robots. It explicitly leverages the sailing motion characteristics and the dynamic model of the robot considering marine disturbances. We have designed an experimental enhanced simulation platform to evaluate motion performance and energy consumption. Both baseline approach and the scheme incorporating EeLsT method (refered to as EeLsT approach in the subsequent sections) have been conducted. In simulation, the EeLsT approach saves 31.8% energy. In the real marine environment, experiments are conducted with OceanVoy, a catamaran sailing robot. The results show that 27.4% of the energy is saved during stable sailing. In long-term sailing, compared to the standby mode when the motors are not working, the average power of the full automation mode has increased by no more than 1 W, i.e., 4% relatively.},
  archive      = {J_TROB},
  author       = {Qinbo Sun and Weimin Qi and Huihuan Qian},
  doi          = {10.1109/TRO.2025.3577058},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4195-4214},
  shortjournal = {IEEE Trans. Robot.},
  title        = {EeLsT: An energy-efficient long-short term approach for sustainable sailboat autonomy in disturbed marine environment},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Behavior cloning-based active scene recognition via generated expert data with revision and prediction for domestic robots. <em>TROB</em>, <em>41</em>, 4180-4194. (<a href='https://doi.org/10.1109/TRO.2025.3582814'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the limitations of current methods in terms of accuracy and efficiency for robot scene recognition (SR) in domestic environments, this article proposes an active scene recognition (ASR) approach that allows the robot to recognize scenes correctly using less images, even when the robot’s position and observation direction are uncertain. ASR includes a behavior cloning-based action classification model, which can adjust the robot view actively to capture beneficial images for SR. To address the lack of essential expert data for training the action model, we introduce an expert data generation method that avoids time-consuming and inefficient manual data collection. In addition, we present a multiview SR method to handle the multiple images resulting from view changes. This method includes an SR model that scores each image and a revision and prediction method to mitigate the compounding error introduced by behavior cloning as well as output the finial recognition result. We conducted numerous comparative experiments and an ablation study in various domestic environments using a publicly simulated platform to validate our ASR method. The experimental results demonstrate that our proposed approach outperforms state-of-the-art methods in terms of both accuracy and efficiency for SR. Furthermore, our method, trained in simulated environments, demonstrates excellent generalization capabilities, allowing it to be directly transferred to the real world without the need for fine-tuning. When deployed on a TurtleBot 4 robot, it achieves precise and efficient SR in diverse real-world environments.},
  archive      = {J_TROB},
  author       = {Shaopeng Liu and Chao Huang and Hailong Huang},
  doi          = {10.1109/TRO.2025.3582814},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4180-4194},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Behavior cloning-based active scene recognition via generated expert data with revision and prediction for domestic robots},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time multilevel terrain-aware path planning for ground mobile robots in large-scale rough terrains. <em>TROB</em>, <em>41</em>, 4159-4179. (<a href='https://doi.org/10.1109/TRO.2025.3577015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous ground mobile robots rely on their configuration characteristics to prevent tip-overs and collisions, ensuring safe navigation in complex environments. However, complex configurations with specially designed links and joints produce a higher dimensional workspace and bring significant challenges for path planning, especially in large-scale rough terrains. To address this, we propose a real-time multilevel terrain-aware path planning framework that integrates different levels of terrain awareness into the global and local layers. An implicit map representation is introduced at the global layer to enable efficient terrain analysis and path planning, while an iterative geometric evaluation is designed at the local layer to estimate configuration stability and improve path smoothness. By sharing the global layer information with the local layer, the framework enhances path planning efficiency and adaptability in complex environments. Its modular design supports diverse robot configurations and pathfinding algorithms, enabling effective autonomous navigation in large-scale 3-D terrains with online or offline maps. Simulations and real-world experiments demonstrated that our approach outperforms state of the art across diverse environments, including uneven terrains, multilayered structures, and complex debris fields. The results highlighted that our approach provides faster and safer path planning, more accurate and robust configuration-stability estimation, and higher success rates in traversing complex 3-D environments.},
  archive      = {J_TROB},
  author       = {Yuxiang Li and Kun Chen and Yifei Wang and Weifan Zhang and Jiancheng Wang and Haoyao Chen and Yunhui Liu},
  doi          = {10.1109/TRO.2025.3577015},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4159-4179},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Real-time multilevel terrain-aware path planning for ground mobile robots in large-scale rough terrains},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SCOPE: Stochastic cartographic occupancy prediction engine for uncertainty-aware dynamic navigation. <em>TROB</em>, <em>41</em>, 4139-4158. (<a href='https://doi.org/10.1109/TRO.2025.3578234'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a family of Stochastic Cartographic Occupancy Prediction Engines that enable mobile robots to predict the future states of complex dynamic environments. They do this by accounting for the motion of the robot itself, the motion of dynamic objects, and the geometry of static objects in the scene, and they generate a range of possible future states of the environment. These prediction engines are software-optimized for real-time performance for navigation in crowded dynamic scenes, achieving up to 89 times faster inference speed and 8 times less memory usage than other state-of-the-art engines. Three simulated and real-world datasets collected by different robot models are used to demonstrate that these proposed prediction algorithms are able to achieve more accurate and robust stochastic prediction performance than other algorithms. Furthermore, a series of simulation and hardware navigation experiments demonstrate that the proposed predictive uncertainty-aware navigation framework with these stochastic prediction engines is able to improve the safe navigation performance of current state-of-the-art model- and learning-based control policies.},
  archive      = {J_TROB},
  author       = {Zhanteng Xie and Philip Dames},
  doi          = {10.1109/TRO.2025.3578234},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4139-4158},
  shortjournal = {IEEE Trans. Robot.},
  title        = {SCOPE: Stochastic cartographic occupancy prediction engine for uncertainty-aware dynamic navigation},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SDPRLayers: Certifiable backpropagation through polynomial optimization problems in robotics. <em>TROB</em>, <em>41</em>, 4120-4138. (<a href='https://doi.org/10.1109/TRO.2025.3578228'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recent set of techniques in the robotics community, known as certifiably correct methods, frames robotics problems as polynomial optimization problems and applies convex, semidefinite programming (SDP) relaxations to either find or certify their global optima. In parallel, differentiable optimization allows optimization problems to be embedded into end-to-end learning frameworks and has received considerable attention in the robotics community. In this article, we consider the ill effect of convergence to spurious local minima in the context of learning frameworks that use differentiable optimization. We present SDPRLayers, an approach that seeks to address this issue by combining convex relaxations with implicit differentiation techniques to provide certifiably correct solutions and gradients throughout the training process. We provide theoretical results that outline conditions for the correctness of these gradients and provide efficient means for their computation. Our approach is first applied to two simple-but-demonstrative simulated examples, which expose the potential pitfalls of reliance on local optimization in existing, state-of-the-art, differentiable optimization methods. We then apply our method in a real-world application: we train a deep neural network to detect image keypoints for robot localization in challenging lighting conditions. We provide our open-source, PyTorch implementation of SDPRLayers and our differentiable localization pipeline.},
  archive      = {J_TROB},
  author       = {Connor Holmes and Frederike Dümbgen and Timothy D. Barfoot},
  doi          = {10.1109/TRO.2025.3578228},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4120-4138},
  shortjournal = {IEEE Trans. Robot.},
  title        = {SDPRLayers: Certifiable backpropagation through polynomial optimization problems in robotics},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time, travel, and energy in the uniform dispersion problem. <em>TROB</em>, <em>41</em>, 4100-4119. (<a href='https://doi.org/10.1109/TRO.2025.3577409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the algorithmic problem of uniformly dispersing a swarm of robots in an unknown, grid-like environment. In this setting, our goal is to study the relationships between performance metrics and robot capabilities. We introduce a formal model comparing dispersion algorithms based on makespan, traveled distance, energy consumption, sensing, communication, and memory. Using this framework, we classify uniform dispersion algorithms according to their capability requirements and performance. We prove that while makespan and travel can be minimized in all environments, energy cannot, if the swarm’s sensing range is bounded. In contrast, we show that energy can be minimized by “ant-like” robots in synchronous settings and asymptotically minimized in asynchronous settings, provided the environment is topologically simply connected, by using our “find-corner depth-first search” (FCDFS) algorithm. Our theoretical and experimental results show that FCDFS significantly outperforms known algorithms. Our findings reveal key limitations in designing swarm robotics systems for unknown environments, emphasizing the role of topology in energy-efficient dispersion.},
  archive      = {J_TROB},
  author       = {Michael Amir and Alfred M. Bruckstein},
  doi          = {10.1109/TRO.2025.3577409},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4100-4119},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Time, travel, and energy in the uniform dispersion problem},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the passive virtual viscous element injection method for elastic joint robots. <em>TROB</em>, <em>41</em>, 4078-4099. (<a href='https://doi.org/10.1109/TRO.2025.3576949'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasing the viscosity of elastic joints can significantly improve the performance of elastic joint robots during physical human–robot interactions. However, current approaches for injecting viscous elements require an additional damper to be added in parallel with the elastic elements. In this article, we propose a new concept called virtual viscous element injection (VVI), which enables a robot to exhibit viscoelasticity without altering its mechanical structure. VVI relies only on motor-side dynamics reshaping and state feedback. Interestingly, the VVI method allows high-resolution joint torque measurements in elastic joint robots, unlike in physical viscoelastic joint robots, which measure joint torque using higher-order derivatives of the positions. Furthermore, the VVI method is proved to preserve the passivity of robot dynamics, which provides numerous possibilities for the applications of combined passivity-based controllers. Specifically, we first emphasize the impedance control method using VVI. The results demonstrate that the VVI-DF method, which combines the direct feedback method with VVI, addresses the issue of excessive acceleration feedback in the controller. This provides looser constraints for achieving a high-gain torque loop in impedance control. Moreover, this article also provides examples of the application of VVI combined with passivity-based position and torque controllers. Experiments and simulations demonstrate the effectiveness of the proposed methods. The proposed method can be extended to various robots, such as exoskeletons, and collaborative robots.},
  archive      = {J_TROB},
  author       = {Jiexin Zhang and Tengyu Hou and Ye Ding and Bo Zhang and Honghai Liu},
  doi          = {10.1109/TRO.2025.3576949},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4078-4099},
  shortjournal = {IEEE Trans. Robot.},
  title        = {On the passive virtual viscous element injection method for elastic joint robots},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Occupancy-SLAM: An efficient and robust algorithm for simultaneously optimizing robot poses and occupancy map. <em>TROB</em>, <em>41</em>, 4057-4077. (<a href='https://doi.org/10.1109/TRO.2025.3578227'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint optimization of poses and features has been extensively studied and demonstrated to yield more accurate results in feature-based SLAM problems. However, research on jointly optimizing poses and non-feature-based maps remains limited. Occupancy maps are widely used non-feature-based environment representations because they effectively classify spaces into obstacles, free, and uknown regions, providing robots with spatial information for various tasks. In this article, we propose Occupancy-SLAM, a novel optimization-based SLAM method enabling the joint optimization of robot trajectory and the occupancy map through a parameterized map representation. The key novelty lies in optimizing both robot poses and occupancy values at different cell vertices simultaneously, a significant departure from existing methods, where the robot poses need to be optimized first before the map can be estimated. In our formulation, the state variables in optimization include both robot poses and occupancy values at cell vertices in the map. Moreover, a multi-resolution optimization framework utilizing occupancy maps with varying resolutions in different stages is introduced. A variation of GaussNewton method is proposed to solve the optimization problem at different stages. The proposed algorithm efficiently converges with initialization from odometry inputs. Furthermore, we propose an occupancy submap joining method within Occupancy-SLAM framework to handle large-scale problems effectively. Evaluations using simulations and practical 2D datasets demonstrate that the proposed approach can robustly obtain more accurate results than state-of-the-art techniques, with comparable computational time. Preliminary 3D results further confirm the potential of the proposed method in practical 3D applications, achieving more accurate results than existing methods.},
  archive      = {J_TROB},
  author       = {Yingyu Wang and Liang Zhao and Shoudong Huang},
  doi          = {10.1109/TRO.2025.3578227},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4057-4077},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Occupancy-SLAM: An efficient and robust algorithm for simultaneously optimizing robot poses and occupancy map},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal on-the-fly route planning with rich transportation requests. <em>TROB</em>, <em>41</em>, 4041-4056. (<a href='https://doi.org/10.1109/TRO.2025.3577010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers the route planning problem for a vehicle with limited capacity operating in a road network. The vehicle is assigned a set of transportation requests that are more complex than traveling between two locations, may involve dependencies between their subtasks, and include deadlines and priorities. The requests arrive gradually over the deployment time-horizon, and thus replanning is needed for new requests. We address cases when not all requests can be serviced by their deadlines despite car sharing. We introduce multiple quality measures for plans that account for requests’ delays with respect to deadlines and priorities. We formalize the problem as planning in a weighted transition system under syntactically cosafe LTL formulas. We develop an online planning and replanning algorithm based on the automata-based approach to least-violating plan synthesis and on translation to a mixed integer linear program (MILP). Furthermore, we show that the MILP reduces to graph search for a subclass of quality measures that satisfy a monotonicity property. We show the approach in simulations, including a case study on the mid-Manhattan road network over the span of 24 h.},
  archive      = {J_TROB},
  author       = {Cristian-Ioan Vasile and Jana Tumova and Sertac Karaman and Calin Belta and Daniela Rus},
  doi          = {10.1109/TRO.2025.3577010},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4041-4056},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Optimal on-the-fly route planning with rich transportation requests},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Goal-conditioned model simplification for 1-D and 2-D deformable object manipulation. <em>TROB</em>, <em>41</em>, 4023-4040. (<a href='https://doi.org/10.1109/TRO.2025.3577052'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion planning for deformable object manipulation has been a challenge for a long time in robotics due to its high computational cost. In this work, we propose to mitigate this cost by limiting the number of picking points on a deformable object within the action space and simplifying the dynamics model. We do this first by identifying a minimal geometric model that closely approximates the original model at the goal state; specifically, we implement this general approach for 1-D linear deformable objects (e.g., ropes) using a piece-wise line-fitted model, and for 2-D surface deformable objects (e.g., cloth) using a mesh-simplified model. Then a small number of key particles are extracted as the pickable points in the action space which are sufficient to represent and reach the given goal. In addition, a simplified dynamics model is constructed based on the simplified geometric model, containing much fewer particles and thus being much faster to simulate than the original dynamics model, albeit with some loss of precision. We further refine this model iteratively by adding more details from the actually achieved final state of the original model until a satisfactory trajectory is generated. Extensive simulation experiments are conducted on a set of representative tasks for ropes and cloth, which show a significant decrease in time cost while achieving similar or better trajectory costs. Finally, we establish a closed-loop system of perception, planning, and control with a real robot for cloth folding, which validates the effectiveness of our proposed method.},
  archive      = {J_TROB},
  author       = {Shengyin Wang and Matteo Leonetti and Mehmet Dogar},
  doi          = {10.1109/TRO.2025.3577052},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4023-4040},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Goal-conditioned model simplification for 1-D and 2-D deformable object manipulation},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ROVER: A multiseason dataset for visual SLAM. <em>TROB</em>, <em>41</em>, 4005-4022. (<a href='https://doi.org/10.1109/TRO.2025.3577026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust simultaneous localization and mapping (SLAM) is a crucial enabler for autonomous navigation in natural, semistructured environments such as parks and gardens. However, these environments present unique challenges for SLAM due to frequent seasonal changes, varying light conditions, and dense vegetation. These factors often degrade the performance of visual SLAM algorithms originally developed for structured urban environments. To address this gap, we present robot outdoor visual SLAM dataset for environmental robustness (ROVER), a comprehensive benchmark dataset tailored for evaluating visual SLAM algorithms under diverse environmental conditions and spatial configurations. We captured the dataset with a robotic platform equipped with monocular, stereo, and RGBD cameras, as well as inertial sensors. It covers 39 recordings across five outdoor locations, collected through all seasons and various lighting scenarios, i.e., day, dusk, and night with and without external lighting. With this novel dataset, we evaluate several traditional and deep learning-based SLAM methods and study their performance in diverse challenging conditions. The results demonstrate that while stereo-inertial and RGBD configurations generally perform better under favorable lighting and moderate vegetation, most SLAM systems perform poorly in low-light and high-vegetation scenarios, particularly during summer and autumn. Our analysis highlights the need for improved adaptability in visual SLAM algorithms for outdoor applications, as current systems struggle with dynamic environmental factors affecting scale, feature extraction, and trajectory consistency. This dataset provides a solid foundation for advancing visual SLAM research in real-world, semistructured environments, fostering the development of more resilient SLAM systems for long-term outdoor localization and mapping.},
  archive      = {J_TROB},
  author       = {Fabian Schmidt and Julian Daubermann and Marcel Mitschke and Constantin Blessing and Stephan Meyer and Markus Enzweiler and Abhinav Valada},
  doi          = {10.1109/TRO.2025.3577026},
  journal      = {IEEE Transactions on Robotics},
  pages        = {4005-4022},
  shortjournal = {IEEE Trans. Robot.},
  title        = {ROVER: A multiseason dataset for visual SLAM},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rhythm-based power allocation strategy of bionic tail-flapping for propulsion enhancement. <em>TROB</em>, <em>41</em>, 3986-4004. (<a href='https://doi.org/10.1109/TRO.2025.3577985'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the vast demand in marine development, robotic fish show promising potential in underwater exploration for their high-performance propulsion ability. However, fish-inspired robots are yet to utilize the structural flexibility of rhythmic actuation such as bony fish (Osteichthyes). The Body and Caudal Fin (BCF) locomotion in fish optimizes the use of muscle power and body flexibility by synchronizing muscle activation with the undulating-oscillatory tail-flapping, such as Thunniform, while robotic fish are primarily designed as motion trackers rather than as efficient swimmers. In this article, we propose a power allocation strategy (PAS) that imitates muscle rhythmic actuation, which increases the flapping amplitude by the coupling of the peduncle motion and the tail deformation. Inspired by this peduncle-tail mechanism, we developed a direct-drive fish robot (DDRFishBot). The DDRFishBot is enhanced by our developed PAS in tail-elastic potential energy release by 228%, in propulsion by 45.6%, and in efficiency coefficient by 16.3%. This study establishes the performance enhancement principle of exploiting tail flexibility through a simple scotch yoke mechanism, expanding the performance space of fish-inspired tail-flapping swimming robot.},
  archive      = {J_TROB},
  author       = {Biao Wu and Chaoyi Huang and Xiangru Li and Jiahao Xu and Sicong Liu and James Lam and Zheng Wang and Jiansheng Dai},
  doi          = {10.1109/TRO.2025.3577985},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3986-4004},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Rhythm-based power allocation strategy of bionic tail-flapping for propulsion enhancement},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TacFlex: Multimode tactile imprints simulation for visuotactile sensors with coating patterns. <em>TROB</em>, <em>41</em>, 3965-3985. (<a href='https://doi.org/10.1109/TRO.2025.3576970'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visuotactile sensors have been shown to provide rich contact information for robots. However, how to build a high-fidelity visuotactile simulator that supports multimode tactile imprints and various sensor configurations (such as coating patterns) remains a challenging problem. In this article, we present TacFlex, an efficient and flexible simulator for visuotactile sensors, which physically simulates the elastomer deformation using finite element methods, and focuses on linking the deformed elastomer mesh to diverse tactile imprints, including tactile images with arbitrary coating patterns and tactile 3-D point clouds. We further propose a ray tracing-based rectification method to deal with multimedium refraction effects to make the simulated tactile images more realistic. Extensive qualitative and quantitative experiments are conducted to demonstrate the effectiveness of TacFlex on several visuotactile sensors. Furthermore, we explore the Sim2Real performance of different tactile imprints provided by TacFlex in tactile perception and manipulation tasks, such as cylindrical object pose estimation and peg-in-hole. The perception/policy models trained in simulation are successfully deployed in the real world. Finally, we present the outlook on the potential of TacFlex in visuotactile manipulation learning. The TacFlex simulator is open-sourced to the community (https://sites.google.com/view/tacflex/).},
  archive      = {J_TROB},
  author       = {Chaofan Zhang and Shaowei Cui and Jingyi Hu and Tianyu Jiang and Tiandong Zhang and Rui Wang and Shuo Wang},
  doi          = {10.1109/TRO.2025.3576970},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3965-3985},
  shortjournal = {IEEE Trans. Robot.},
  title        = {TacFlex: Multimode tactile imprints simulation for visuotactile sensors with coating patterns},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A learning-based quadcopter controller with extreme adaptation. <em>TROB</em>, <em>41</em>, 3948-3964. (<a href='https://doi.org/10.1109/TRO.2025.3577037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a learning-based low-level controller for quadcopters, which adaptively controls quadcopters with significant variations in mass, size, and actuator capabilities. Our approach leverages a combination of imitation learning and reinforcement learning, creating a fast-adapting and general control framework for quadcopters that eliminates the need for precise model estimation or manual tuning. The controller estimates a latent representation of the vehicle’s system parameters from sensor-action history, enabling it to adapt swiftly to diverse dynamics. Extensive evaluations in simulation demonstrate the controller’s ability to generalize to unseen quadcopter parameters, with an adaptation range up to 16 times broader than the training set. In real-world tests, the controller is successfully deployed on quadcopters with mass differences of 3.7 times and propeller constants varying by more than 100 times, while also showing rapid adaptation to disturbances such as off-center payloads and motor failures. These results highlight the potential of our controller to simplify the design process and enhance the reliability of autonomous drone operations in unpredictable environments.},
  archive      = {J_TROB},
  author       = {Dingqi Zhang and Antonio Loquercio and Jerry Tang and Ting-Hao Wang and Jitendra Malik and Mark W. Mueller},
  doi          = {10.1109/TRO.2025.3577037},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3948-3964},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A learning-based quadcopter controller with extreme adaptation},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tracking and control of multiple objects during nonprehensile manipulation in clutter. <em>TROB</em>, <em>41</em>, 3929-3947. (<a href='https://doi.org/10.1109/TRO.2025.3577437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a method for 6-D pose tracking and control of multiple objects during nonprehensile manipulation by a robot. The tracking system estimates objects’ poses by integrating physics predictions, derived from robotic joint state information, with visual inputs from an RGB-D camera. Specifically, the methodology is based on particle filtering, which fuses control information from the robot as an input for each particle movement and with real-time camera observations to track the pose of objects. Comparative analyses reveal that this physics-based approach substantially improves pose tracking accuracy over baseline methods that rely solely on visual data, particularly during manipulation in clutter, where occlusions are a frequent problem. The tracking system is integrated with a model predictive control approach which shows that the probabilistic nature of our tracking system can help robust manipulation planning and control of multiple objects in clutter, even under heavy occlusions.},
  archive      = {J_TROB},
  author       = {Zisong Xu and Rafael Papallas and Jaina Modisett and Markus Billeter and Mehmet R. Dogar},
  doi          = {10.1109/TRO.2025.3577437},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3929-3947},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Tracking and control of multiple objects during nonprehensile manipulation in clutter},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel iterative solution to the perspective-$n$-point problem via cost function approximation. <em>TROB</em>, <em>41</em>, 3908-3928. (<a href='https://doi.org/10.1109/TRO.2025.3577061'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The perspective-$n$-point (P$n$P) problem, which estimates the camera pose through $N$ 2-D/3-D point correspondences, has been extensively studied. Although minimizing the reprojection cost is regarded as the gold standard for solving the P$n$P problem, this cost lacks an analytic solution, leading previous works to focus on developing simpler costs. State-of-the-art P$n$P solutions are generally considered to be close to the gold-standard solution. However, this perception is based on limited experimental setups. Our extensive evaluations show that these solutions generally deviate from the gold-standard solution as the depth range of 3-D points increases. This article investigates two noise models of the P$n$P problem and provides a unified, accurate, and efficient solution. The main contributions of this article are threefold. First, we propose an efficient initialization method that compresses $ 2N$ constraints to three quadratic equations for rotation using principal component analysis. Second, we prove that our initialization algorithm provides a solution to the P3P problem, making it applicable to the full range $N \geq 3$ of the P$n$P problem. Third, we propose a novel iterative algorithm that approximates reprojection residuals using second-order polynomials and determines the optimal step size analytically, ensuring fast convergence. Extensive experiments on synthetic and real data demonstrate that our algorithm outperforms state-of-the-art methods in terms of accuracy and robustness, while achieving comparable efficiency.},
  archive      = {J_TROB},
  author       = {Lipu Zhou and Zhenzhong Wei and Xu Wang},
  doi          = {10.1109/TRO.2025.3577061},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3908-3928},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A novel iterative solution to the perspective-$n$-point problem via cost function approximation},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing grasping diversity with a pinch-suction and soft-rigid hybrid multimodal gripper. <em>TROB</em>, <em>41</em>, 3890-3907. (<a href='https://doi.org/10.1109/TRO.2025.3577014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal grasping has emerged as a promising strategy to enhance the grasping diversity of grippers in response to the rapid expansion of application scenarios. Among various designs, the pinch-suction hybrid mechanism and the soft-rigid hybrid structure have proved to be two practical strategies to achieve multimodality. However, existing research on these two strategies still lacks simple and effective collaborative mechanisms to fully leverage the advantages of each mode while ensuring mutual noninterference. In this article, we propose a pinch-suction and soft-rigid hybrid multimodal gripper (HMG), integrating four operating modes into a compact structure. Two simple and effective collaborative mechanisms are introduced to coordinate between pinch and suction operation and between soft and rigid components, respectively. Through the collaboration of different modes, the HMG exhibits a competitive grasping diversity across four aspects, including weight (from 0.2 g to 10 kg), fragility (from jelly to aluminum profile), size scale (from 0.46 mm to 0.55 m), and shape (from poorly pinchable to poorly suckable). We further demonstrate its adaptability and robustness in handling irregular-shaped objects, and its proficiency in executing complex real-world manipulation tasks, underwater operations, and closed-loop grasping. Its enhanced grasping diversity is poised to accelerate diverse applications in daily life, industrial settings, and underwater scenarios.},
  archive      = {J_TROB},
  author       = {Yuwen Zhao and Jiaqi Zhu and Jie Zhang and Siyuan Zhang and Maosen Shao and Zhiping Chai and Yimu Liu and Jianing Wu and Zhigang Wu and Jinxiu Zhang},
  doi          = {10.1109/TRO.2025.3577014},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3890-3907},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Enhancing grasping diversity with a pinch-suction and soft-rigid hybrid multimodal gripper},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SG-reg: Generalizable and efficient scene graph registration. <em>TROB</em>, <em>41</em>, 3870-3889. (<a href='https://doi.org/10.1109/TRO.2025.3577020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the challenges of registering two rigid semantic scene graphs, an essential capability when an autonomous agent needs to register its map against a remote agent, or against a prior map. The handcrafted descriptors in classical semantic-aided registration, or the ground-truth annotation reliance in learning-based scene graph registration, impede their application in practical real-world environments. To address the challenges, we design a scene graph network to encode multiple modalities of semantic nodes: open-set semantic feature, local topology with spatial awareness, and shape feature. These modalities are fused to create compact semantic node features. The matching layers then search for correspondences in a coarse-to-fine manner. In the back end, we employ a robust pose estimator to decide transformation according to the correspondences. We manage to maintain a sparse and hierarchical scene representation. Our approach demands fewer GPU resources and fewer communication bandwidth in multiagent tasks. Moreover, we design a new data generation approach using vision foundation models and a semantic mapping module to reconstruct semantic scene graphs. It differs significantly from previous works, which rely on ground-truth semantic annotations to generate data. We validate our method in a two-agent simultaneous localization and mapping benchmark. It significantly outperforms the handcrafted baseline in terms of registration success rate. Compared to visual loop closure networks, our method achieves a slightly higher registration recall while requiring only 52 kB of communication bandwidth for each query frame.},
  archive      = {J_TROB},
  author       = {Chuhao Liu and Zhijian Qiao and Jieqi Shi and Ke Wang and Peize Liu and Shaojie Shen},
  doi          = {10.1109/TRO.2025.3577020},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3870-3889},
  shortjournal = {IEEE Trans. Robot.},
  title        = {SG-reg: Generalizable and efficient scene graph registration},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variations of augmented lagrangian for robotic multicontact simulation. <em>TROB</em>, <em>41</em>, 3852-3869. (<a href='https://doi.org/10.1109/TRO.2025.3577410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multicontact nonlinear complementarity problem (NCP) is a naturally arising challenge in robotic simulations. Achieving high performance in terms of both accuracy and efficiency remains a significant challenge, particularly in scenarios involving intensive contacts and stiff interactions. In this article, we introduce a new class of multicontact NCP solvers based on the theory of the augmented Lagrangian (AL). We detail how the standard derivation of AL in convex optimization can be adapted to handle multicontact NCP through the iteration of surrogate problem solutions and the subsequent update of primal-dual variables. Specifically, we present two tailored variations of AL for robotic simulations: the cascaded Newton-based augmented Lagrangian (CANAL) and the subsystem-based alternating direction method of multipliers (SubADMM). We demonstrate how CANAL can manage multicontact NCP in an accurate and robust manner, while SubADMM offers superior computational speed, scalability, and parallelizability for high degrees-of-freedom multibody systems with numerous contacts. Our results showcase the effectiveness of the proposed solver framework, illustrating its advantages in various robotic manipulation scenarios.},
  archive      = {J_TROB},
  author       = {Jeongmin Lee and Minji Lee and Sunkyung Park and Jinhee Yun and Dongjun Lee},
  doi          = {10.1109/TRO.2025.3577410},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3852-3869},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Variations of augmented lagrangian for robotic multicontact simulation},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active inference for bandit-based autonomous robotic exploration with dynamic preferences. <em>TROB</em>, <em>41</em>, 3841-3851. (<a href='https://doi.org/10.1109/TRO.2025.3577041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous selection of optimal options for data collection from multiple alternatives is challenging in uncertain environments. When secondary information about options is accessible, such problems can be framed as contextual multiarmed bandits (CMABs). Neuroinspired active inference (AIF) has gained interest for its ability to balance exploration and exploitation using the expected free energy objective function. Unlike previous studies that showed the effectiveness of AIF-based strategy for CMABs using synthetic data, this study aims to apply AIF to realistic scenarios, using a simulated mineralogical survey site selection problem. Hyperspectral data from the next generation airborne visible–infrared imaging spectrometer at Cuprite, Nevada, serves as contextual information for predicting outcome probabilities, while geologists’ mineral labels represent outcomes. Monte Carlo simulations assess the robustness of AIF against changing expert preferences. Results show AIF requires fewer iterations than standard bandit approaches with real-world noisy and biased data, and performs better when outcome preferences vary online by adapting the selection strategy to align with expert shifts.},
  archive      = {J_TROB},
  author       = {Shohei Wakayama and Alberto Candela and Paul Hayne and Nisar Ahmed},
  doi          = {10.1109/TRO.2025.3577041},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3841-3851},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Active inference for bandit-based autonomous robotic exploration with dynamic preferences},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid long short-term motor optimization and control of a walking exoskeleton. <em>TROB</em>, <em>41</em>, 3820-3840. (<a href='https://doi.org/10.1109/TRO.2025.3576971'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a hybrid long short-term motor (HLSM) optimization and control approach for a walking exoskeleton. It consists of long-term global optimization, short-term local optimization, human-in-the-loop trajectory adaptation, and hybrid cerebellar model articulation controller (HCMAC). In the long-term global optimization, a graphic spiking neural network (SNN) is utilized for an optimal global path. Along the path, the short-term motor optimization includes footstep optimization and obtains a sequence of footsteps. While in response to the unexpected obstacles along the footstep sequence, a human-in-the-loop planning strategy is designed by a virtual impedance model between the centers of mass (COMs) of the human and the exoskeleton, regulating the COM of the exoskeleton and generating footstep adaptation of the exoskeleton such that the exoskeleton can avoid obstacles and maintain its original global trajectory. Moreover, considering the unmodeled dynamics, we propose an HCMAC based on an integral Lyapunov function, which is exploited to counteract the system’s nonlinear uncertainties, external disturbances, and reduces a relatively high computational cost. We validate the effectiveness of the HLSM planner and controller in a practical indoor setting. The results demonstrate the effectiveness of HLSM planning and control in a real scenario for a walking exoskeleton.},
  archive      = {J_TROB},
  author       = {Pengbo Huang and Zhijun Li and Mengchu Zhou and Guoxin Li and Yang Song and Rongxin Cui},
  doi          = {10.1109/TRO.2025.3576971},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3820-3840},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Hybrid long short-term motor optimization and control of a walking exoskeleton},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ERPoT: Effective and reliable pose tracking for mobile robots using lightweight polygon maps. <em>TROB</em>, <em>41</em>, 3799-3819. (<a href='https://doi.org/10.1109/TRO.2025.3577028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an effective and reliable pose tracking solution, termed ERPoT, for mobile robots operating in large-scale outdoor and challenging indoor environments, underpinned by an innovative prior polygon map. Especially, to overcome the challenge that arises as the map size grows with the expansion of the environment, the novel form of a prior map composed of multiple polygons is proposed. Benefiting from the use of polygons to concisely and accurately depict environmental occupancy, the prior polygon map achieves long-term reliable pose tracking while ensuring a compact form. More importantly, pose tracking is carried out under pure LiDAR mode, and the dense 3-D point cloud is transformed into a sparse 2-D scan through ground removal and obstacle selection. On this basis, a novel cost function for pose estimation through point-polygon matching is introduced, encompassing two distinct constraint forms: point-to-vertex and point-to-edge. In this study, our primary focus lies on two crucial aspects: lightweight and compact prior map construction, as well as effective and reliable robot pose tracking. Both aspects serve as the foundational pillars for future navigation across diverse mobile platforms equipped with different LiDAR sensors in varied environments. Comparative experiments based on the publicly available datasets and our self-recorded datasets are conducted, and evaluation results show the superior performance of ERPoT on reliability, prior map size, pose estimation error, and runtime over the other six approaches. The corresponding code can be accessed online.},
  archive      = {J_TROB},
  author       = {Haiming Gao and Qibo Qiu and Hongyan Liu and Dingkun Liang and Chaoqun Wang and Xuebo Zhang},
  doi          = {10.1109/TRO.2025.3577028},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3799-3819},
  shortjournal = {IEEE Trans. Robot.},
  title        = {ERPoT: Effective and reliable pose tracking for mobile robots using lightweight polygon maps},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constraint-guided online data selection for scalable data-driven safety filters in uncertain robotic systems. <em>TROB</em>, <em>41</em>, 3779-3798. (<a href='https://doi.org/10.1109/TRO.2025.3577022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the use of autonomous robots expands in tasks that are complex and challenging to model, the demand for robust data-driven control methods that can certify safety and stability in uncertain conditions is increasing. However, the practical implementation of these methods often faces scalability issues due to the growing amount of data points with system complexity and a significant reliance on high-quality training data. In response to these challenges, this study presents a scalable data-driven controller that efficiently identifies and infers from the most informative data points for implementing data-driven safety filters. Our approach is grounded in the integration of a model-based certificate function-based method and Gaussian Process regression, reinforced by a novel online data selection algorithm that reduces time complexity from quadratic to linear relative to dataset size. Empirical evidence, gathered from successful real-world cart–pole swing-up experiments and simulated locomotion of a five-link bipedal robot, demonstrates the efficacy of our approach. Our findings reveal that our efficient online data selection algorithm, which strategically selects key data points, enhances the practicality and efficiency of data-driven certifying filters in complex robotic systems, significantly mitigating scalability concerns inherent in nonparametric learning-based control methods.},
  archive      = {J_TROB},
  author       = {Jason J. Choi and Fernando Castañeda and Wonsuhk Jung and Bike Zhang and Claire J. Tomlin and Koushil Sreenath},
  doi          = {10.1109/TRO.2025.3577022},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3779-3798},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Constraint-guided online data selection for scalable data-driven safety filters in uncertain robotic systems},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BotVIO: A lightweight transformer-based Visual–Inertial odometry for robotics. <em>TROB</em>, <em>41</em>, 3760-3778. (<a href='https://doi.org/10.1109/TRO.2025.3577054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual–inertial odometry (VIO) provides a robust localization solution for simultaneous localization and mapping systems. Self-supervised VIO, a leading approach, has the advantage of not requiring extensive ground-truth labels. Regrettably, this method still poses challenges for robotic applications, particularly uncrewed aerial vehicles, due to its computational complexity arising from inadequate model designs. To address this bottleneck, we introduce BotVIO (where “Bot” refers to “robotics”), a transformer-based self-supervised VIO model, offering an excellent solution to alleviate computational burdens for robotics. Our lightweight backbone combines shallow CNNs with spatial–temporal-enhanced transformers to replace conventional architectures, while the minimalist cross-fusion module uses single-layer cross-attention to enhance multimodal interaction. Extensive experiments show that, during pose estimation, BotVIO achieves a remarkable 70.37% reduction in trainable parameters and a 74.85% decrease in inference speed, reaching up to 57.80 fps on an NVIDIA Jetson NX (10W&2CORE), while improving pose accuracy and robustness. For the benefit of the community, we make public the source code.1},
  archive      = {J_TROB},
  author       = {Wenhui Wei and Yangfan Zhou and Yimin Hu and Zhi Li and Sen Wang and Xin Liu and Jiadong Li},
  doi          = {10.1109/TRO.2025.3577054},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3760-3778},
  shortjournal = {IEEE Trans. Robot.},
  title        = {BotVIO: A lightweight transformer-based Visual–Inertial odometry for robotics},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning wrist policies for anthropomorphic soft power grasping in handle and door manipulation. <em>TROB</em>, <em>41</em>, 3738-3759. (<a href='https://doi.org/10.1109/TRO.2025.3576950'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we advance robotic grasping by incorporating wrist compliance in a unified hand–arm system inspired by human limb coordination. This integration improves grasping reliability and robustness through impedance and force learning in robotic arms. The compliant wrist system effectively compensates for uncertainties in object position and orientation. Employing a combined impedance-force control approach, we address diverse grasping and manipulation tasks in simulation. Successfully transferring the learned policy to a service humanoid mobile robot enables the seamless execution of grasping and opening tasks for various doors and handles without additional learning, using both fully actuated and underactuated robotic hands. Remarkably, our robust strategies yielded only one failure in 30 trials for the underactuated hand, even with up to 8 cm translation normal to the handle and $33^\circ$ rotation errors, and no failures for the fully actuated one with up to 12 cm translation and $30^\circ$ rotation. This significantly outperforms state-of-the-art end-to-end reinforcement learning approaches. Furthermore, we successfully tested and validated our approach across various constrained everyday tasks in different environments. Our proposed framework represents an advancement in the learning and execution of power grasping with compliant manipulation, achieving practically relevant performance.},
  archive      = {J_TROB},
  author       = {Florian Voigt and Abdeldjallil Naceri and Sami Haddadin},
  doi          = {10.1109/TRO.2025.3576950},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3738-3759},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Learning wrist policies for anthropomorphic soft power grasping in handle and door manipulation},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tactile elastography. <em>TROB</em>, <em>41</em>, 3722-3737. (<a href='https://doi.org/10.1109/TRO.2025.3577024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Elasticity is one of the representative parameters that reflect the mechanical properties of soft materials. Detecting the underneath elasticity distribution called elastography is a key step for understanding and interacting with objects. Existing solutions for capturing the interior elasticity distribution typically rely on expensive apparatus. In this work, the dense tactile signal captured by the high-resolution vision-based tactile sensor is introduced as a new modality for reconstructing 3-D elasticity distribution. We propose a model-based method, which exploits the tactile maps from active pressing trials for the elastography task. The interior elasticity distribution for nonrigid objects is reconstructed from an inverse physics model. We analyze the credibility of the estimated elasticity distribution obtained from our method. Varying design factors are also discussed. We experiment our method on a set of synthesized 3-D models and physical models in robot-assisted scenes. Various experimental results have been gathered, demonstrating the efficacy of our approach in perceiving elasticity distribution.},
  archive      = {J_TROB},
  author       = {Yichen Xiang and Lifeng Zhu and Aiguo Song and Yongjie Jessica Zhang},
  doi          = {10.1109/TRO.2025.3577024},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3722-3737},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Tactile elastography},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic hysteresis compensation for tendon-sheath mechanism in flexible surgical robots without distal perception. <em>TROB</em>, <em>41</em>, 3703-3721. (<a href='https://doi.org/10.1109/TRO.2025.3577011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate position transmission of tendon-sheath mechanisms (TSMs) is challenging but of significance to the flexible robot for minimally invasive surgery. The challenges are mainly attributed to the following: first, the tendon-elongation and its caused hysteresis that depend on the route configuration of the TSM and could result in misaligned position transmission; second, realistic surgical scenarios requiring the TSM with arbitrary and even time-varying route configurations; and third the absence of distal sensory feedback due to strict spatial constraints. Existing works are always devoted to tackling the first challenge yet evade the second and third. Here, a route-related tendon-elongation model is formulated to resolve the first challenge, and in response to the second, a route-sensing optical fiber is used. Obeying the third challenge, a feedforward hysteresis compensator is then developed to align the distal position of the tendon with the desired position. Our final contribution gives an application-oriented remedy for the foregoing methodologies. Applying our compensator on the challenging position transmission tasks subject to second and third challenges, the positional accuracy can be still maintained at around 97.50%; guided by the provided remedy, the surgical end-effector achieves submillimeter tip position accuracy. Extensive tests demonstrate that the pending concerns yet of great practical importance in existing related works are well resolved.},
  archive      = {J_TROB},
  author       = {Qian Gao and Guanglin Ji and Minyi Sun and Yin Xiao and Huaiyuan Rao and Zhenglong Sun},
  doi          = {10.1109/TRO.2025.3577011},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3703-3721},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Dynamic hysteresis compensation for tendon-sheath mechanism in flexible surgical robots without distal perception},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RoTipBot: Robotic handling of thin and flexible objects using rotatable tactile sensors. <em>TROB</em>, <em>41</em>, 3684-3702. (<a href='https://doi.org/10.1109/TRO.2025.3576951'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces RoTipBot, a novel robotic system for handling thin, flexible objects. Different from previous works that are limited to singulating them using suction cups or soft grippers, RoTipBot can count multiple layers and then grasp them simultaneously in a single grasp closure. Specifically, we first develop a vision-based tactile sensor named RoTip that can rotate and sense contact information around its tip. Equipped with two RoTip sensors, RoTipBot rolls and feeds multiple layers of thin, flexible objects into the centre between its fingers, enabling effective grasping. Moreover, we design a tactile-based grasping strategy that uses RoTip’s sensing ability to ensure both fingers maintain secure contact with the object while accurately counting the number of fed objects. Extensive experiments demonstrate the efficacy of the RoTip sensor and the RoTipBot approach. The results show that RoTipBot not only achieves a higher success rate but also grasps and counts multiple layers simultaneously—capabilities not possible with previous methods. Furthermore, RoTipBot operates up to three times faster than state-of-the-art methods. The success of RoTipBot paves the way for future research in object manipulation using mobilized tactile sensors.},
  archive      = {J_TROB},
  author       = {Jiaqi Jiang and Xuyang Zhang and Daniel Fernandes Gomes and Thanh-Toan Do and Shan Luo},
  doi          = {10.1109/TRO.2025.3576951},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3684-3702},
  shortjournal = {IEEE Trans. Robot.},
  title        = {RoTipBot: Robotic handling of thin and flexible objects using rotatable tactile sensors},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stable object placement planning from contact point robustness. <em>TROB</em>, <em>41</em>, 3669-3683. (<a href='https://doi.org/10.1109/TRO.2025.3577049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a planner designed to guide robot manipulators in stably placing objects within complex scenes. Our proposed method reverses the traditional approach to object placement: our planner selects contact points first and then determines a placement pose that solicits the selected points. This is instead of sampling poses, identifying contact points, and evaluating pose quality. Our algorithm facilitates stability-aware object placement planning, imposing no restrictions on object shape, convexity, or mass density homogeneity, while avoiding combinatorial computational complexity. Our proposed stability heuristic enables our planner to find a solution about 20 times faster when compared to the same algorithm not making use of the heuristic and eight times faster than a state-of-the-art method that uses the traditional sample-and-evaluate approach. The proposed planner is also more successful in finding stable placements than the five other benchmarked algorithms. Derived from first principles and validated in ten real robot experiments, our approach provides a general and scalable solution to the problem of rigid object placement planning.},
  archive      = {J_TROB},
  author       = {Philippe Nadeau and Jonathan Kelly},
  doi          = {10.1109/TRO.2025.3577049},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3669-3683},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Stable object placement planning from contact point robustness},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous collaborative pursuit via coverage control driven by Fokker–Planck equations. <em>TROB</em>, <em>41</em>, 3649-3668. (<a href='https://doi.org/10.1109/TRO.2025.3559420'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by common features found in collaborative behaviors in nature, we investigate a general collaborative pursuit framework enabling heterogeneous multi-robot systems to adapt to dynamic environments and diverse tasks. A class of augmented Fokker–Planck equations is formulated to characterize dynamic environmental conditions, and the resulting time-varying density functions drive a novel coverage-based controller, with provable stability properties, for the participating robots to perform tasks in real time. The developed framework is decentralized and incorporates heterogeneity among different robots in task suitability, relative performance in a specific task, and safe operating regions. To demonstrate its adaptivity and effectiveness, the framework is implemented across four experimental applications ranging from multi-robot coordination to collaboration, namely forest firefighting, pursuit–evasion, monitoring of various environmental phenomena, and phoretic interactions.},
  archive      = {J_TROB},
  author       = {Ruoyu Lin and Soobum Kim and Magnus Egerstedt},
  doi          = {10.1109/TRO.2025.3559420},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3649-3668},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Heterogeneous collaborative pursuit via coverage control driven by Fokker–Planck equations},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Primitive-swarm: An ultra-lightweight and scalable planner for large-scale aerial swarms. <em>TROB</em>, <em>41</em>, 3629-3648. (<a href='https://doi.org/10.1109/TRO.2025.3573667'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving large-scale aerial swarms is challenging due to the inherent contradictions in balancing computational efficiency and scalability. This article introduces primitive-swarm, an ultra-lightweight and scalable planner designed specifically for large-scale autonomous aerial swarms. The proposed approach adopts a decentralized and asynchronous replanning strategy. Within it is a novel motion primitive library consisting of time-optimal and dynamically feasible trajectories. They are generated utilizing a novel time-optimal path parameterization algorithm based on reachability analysis. Then, a rapid collision checking mechanism is developed by associating the motion primitives with the discrete surrounding space according to conflicts. By considering both spatial and temporal conflicts, the mechanism handles robot-obstacle and robot–robot collisions simultaneously. Then, during a replanning process, each robot selects the safe and minimum cost trajectory from the library based on user-defined requirements. Both the time-optimal motion primitive library and the occupancy information are computed offline, turning a time-consuming optimization problem into a linear-complexity selection problem. This enables the planner to comprehensively explore the nonconvex, discontinuous 3-D safe space filled with numerous obstacles and robots, effectively identifying the best hidden path. Benchmark comparisons demonstrate that our method achieves the shortest flight time and traveled distance with a computation time of less than 1 ms in dense environments. Super large-scale swarm simulations, involving up to 1000 robots, running in real time, verify the scalability of our method. Real-world experiments validate the feasibility and robustness of our approach. The code will be released to foster community collaboration.},
  archive      = {J_TROB},
  author       = {Jialiang Hou and Xin Zhou and Neng Pan and Ang Li and Yuxiang Guan and Chao Xu and Zhongxue Gan and Fei Gao},
  doi          = {10.1109/TRO.2025.3573667},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3629-3648},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Primitive-swarm: An ultra-lightweight and scalable planner for large-scale aerial swarms},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autonomous tomato harvesting with Top–Down fusion network for limited data. <em>TROB</em>, <em>41</em>, 3609-3628. (<a href='https://doi.org/10.1109/TRO.2025.3567544'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using robots for tomato truss harvesting represents a promising approach to agricultural production. However, incomplete acquisition of perception information and clumsy operations often results in low harvest success rates or crop damage. To addressthis issue, we designed a new method for tomato truss perception, an autonomous harvesting method, and a novel circular rotary cutting end-effector. The robot performs object detection and keypoint detection on tomato trusses using the proposed top–down fusion network, making decisions on suitable targets for harvesting based on phenotyping and pose estimation. The designed end-effector moves gradually from the bottom up to wrap around the tomato truss, cutting the peduncle to complete the harvest. Experiments conducted in real-world scenarios for robotic perception and autonomous harvesting of tomato trusses show that the proposed method increases accuracy by up to 11.42% and 22.29% for complete and limited dataset conditions, compared to baseline models. Furthermore, we have implemented an automatic tomato harvesting system based on TDFNet, which reaches an average harvest success rate of 89.58% in the greenhouse.},
  archive      = {J_TROB},
  author       = {Xingxu Li and Yiheng Han and Nan Ma and Yongjin Liu and Jia Pan and Shun Yang and Siyi Zheng},
  doi          = {10.1109/TRO.2025.3567544},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3609-3628},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Autonomous tomato harvesting with Top–Down fusion network for limited data},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-learning enhanced model predictive contouring control for agile and precise quadrotor flight. <em>TROB</em>, <em>41</em>, 3590-3608. (<a href='https://doi.org/10.1109/TRO.2025.3567491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In agile quadrotor flight, accurately modeling the varying aerodynamic drag forces encountered at different speeds is critical. These drag forces significantly impact the performance and maneuverability of the quadrotor, especially during high-speed maneuvers. Traditional control models based on first principles struggle to capture these dynamics due to the complexity and variability of aerodynamic effects, which are challenging to model accurately. To address these challenges, this study proposes a meta-learning-based control strategy for accurately modeling quadrotor dynamics under varying speeds, treating each velocity condition as an independent learning task with a specifically trained neural network to ensure precise dynamic predictions. The meta-learning framework rapidly generates task-specific parameters adapted to speed variations by solving an optimization problem and employs an online incremental learning strategy to integrate real-time data for continuous model updates, enhancing system robustness. Regularization is introduced to prevent overfitting and improve generalizability. The integration of the meta-learned model into Model Predictive Contouring Control (MPCC) allows the system to achieve optimal control across different velocity levels, ensuring efficient and accurate flight control even during sharp turns and high-speed maneuvers. Extensive simulations and real-world experiments confirm that the proposed algorithm maintains a high level of control precision despite the nonlinear effects of rapid speed changes, complex flight trajectories and wind disturbances. The results highlight the advantages of combining meta-learning with adaptive control strategies, providing a robust framework for quadrotors operating in diverse and dynamic environments.},
  archive      = {J_TROB},
  author       = {Mingxin Wei and Lanxiang Zheng and Ying Wu and Ruidong Mei and Hui Cheng},
  doi          = {10.1109/TRO.2025.3567491},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3590-3608},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Meta-learning enhanced model predictive contouring control for agile and precise quadrotor flight},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Open-loop control of electrically conductive materials in an oscillating magnetic field. <em>TROB</em>, <em>41</em>, 3575-3589. (<a href='https://doi.org/10.1109/TRO.2025.3562451'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Control of objects using remotely generated magnetic fields has established itself as a viable option for 3-D position control, though the objects being manipulated to date have largely been limited to soft and hard-magnetic objects that react to a static magnetic field. This limits the application to a small subset of materials. This work presents the first analytically derived model for 3-D position control of any electrically conductive material subject to a time-varying magnetic field. By leveraging the induced eddy current and subsequent induced dipole, this model shows that conductive materials behave equivalently to diamagnetic materials and are, therefore, not subject to the limitations of the Earnshaw’s theorem, making stable, open-loop levitation possible. This is demonstrated by open-loop position control of a semibuoyant aluminum sphere.},
  archive      = {J_TROB},
  author       = {Seth Stewart and Joseph Pawelski and Steve Ward and Andrew J. Petruska},
  doi          = {10.1109/TRO.2025.3562451},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3575-3589},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Open-loop control of electrically conductive materials in an oscillating magnetic field},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Embedded hierarchical MPC for autonomous navigation. <em>TROB</em>, <em>41</em>, 3556-3574. (<a href='https://doi.org/10.1109/TRO.2025.3567529'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To efficiently deploy robotic systems in society, mobile robots must move autonomously and safely through complex environments. Nonlinear model predictive control (MPC) methods provide a natural way to find a dynamically feasible trajectory through the environment without colliding with nearby obstacles. However, the limited computation power available on typical embedded robotic systems, such as quadrotors, poses a challenge to running MPC in real time, including its most expensive tasks: constraints generation and optimization. To address this problem, we propose a novel hierarchical MPC scheme that consists of a planning and a tracking layer. The planner constructs a trajectory with a long prediction horizon at a slow rate, while the tracker ensures trajectory tracking at a relatively fast rate. We prove that the proposed framework avoids collisions and is recursively feasible. Furthermore, we demonstrate its effectiveness in simulations and lab experiments with a quadrotor that needs to reach a goal position in a complex static environment. The code is efficiently implemented on the quadrotor's embedded computer to ensure real-time feasibility. Compared to a state-of-the-art single-layer MPC formulation, this allows us to increase the planning horizon by a factor of 5, which results in significantly better performance.},
  archive      = {J_TROB},
  author       = {Dennis Benders and Johannes Köhler and Thijs Niesten and Robert Babuška and Javier Alonso-Mora and Laura Ferranti},
  doi          = {10.1109/TRO.2025.3567529},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3556-3574},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Embedded hierarchical MPC for autonomous navigation},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-order regularization dealing with ILL-conditioned robot localization problems. <em>TROB</em>, <em>41</em>, 3539-3555. (<a href='https://doi.org/10.1109/TRO.2025.3562487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a high-order regularization method to solve the ill-conditioned problems in robot localization. Numerical solutions to robot localization problems are often unstable when the problems are ill-conditioned. A typical way to solve ill-conditioned problems is regularization, and a classical regularization method is the Tikhonov regularization. It is shown that the Tikhonov regularization is a low-order case of our method. We find that the proposed method is superior to the Tikhonov regularization in approximating some ill-conditioned inverse problems, such as some basic robot localization problems. The proposed method overcomes the oversmoothing problem in the Tikhonov regularization as it uses more than one term in the approximation of the matrix inverse, and an explanation for the oversmoothing of the Tikhonov regularization is given. Moreover, one a priori criterion, which improves the numerical stability of the ill-conditioned problem, is proposed to obtain an optimal regularization matrix. As most of the regularization solutions are biased, we also provide two bias-correction techniques for the proposed high-order regularization. The simulation and experimental results using an ultra-wideband sensor network in a 3-D environment are discussed, demonstrating the performance of the proposed method.},
  archive      = {J_TROB},
  author       = {Xinghua Liu and Ming Cao},
  doi          = {10.1109/TRO.2025.3562487},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3539-3555},
  shortjournal = {IEEE Trans. Robot.},
  title        = {High-order regularization dealing with ILL-conditioned robot localization problems},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Versatile tasks on integrated aerial platforms using only onboard sensors: Control, estimation, and validation. <em>TROB</em>, <em>41</em>, 3518-3538. (<a href='https://doi.org/10.1109/TRO.2025.3568531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Connecting multiple aerial vehicles to a rigid central platform through passive spherical joints holds the potential to construct a fully actuated aerial platform. The integration of multiple vehicles enhances efficiency in tasks like mapping and object reconnaissance. This article proposes a control and state estimation framework for the integrated aerial platform (IAP), enabling it to perform versatile tasks like object reconnaissance and physical interactive tasks with only onboard sensors. In the framework, the 6-D motion control serves as the low-level controller, while the high-level controller comprises a 6-D admittance filter and a perception-aware attitude correction module. The 6-D admittance filter, serving as the interaction controller, is adaptable for aerial interaction tasks. The perception-aware attitude correction algorithm is carefully designed by adopting a geometric model predictive controller (MPC). This algorithm, incorporating both offline and online calculations, proves to be well-suited for the intricate dynamics of an IAP. A 6-D direct wrench controller is also developed for the IAP. Notably, both the interaction controller and the direct wrench controller operate without reliance on force/torque sensors. Instead, a wrench observer algorithm is devised, considering external disturbances. In addition, based on the kinematics constraints of the multiple aerials in the platform, a fusion algorithm for multiple visual-inertial odometry and kinematics constraints is developed, providing more accurate localization. A prototype of the IAP is constructed, and its capabilities are demonstrated through experiments including perception-aware object reconnaissance, aerial mapping, aerial peg-in-hole task, and 6-D contact wrench generation. All experiments are conducted exclusively with onboard sensors. These tasks exemplify the merits of the proposed IAP and validate the effectiveness of the proposed control framework and fusion algorithm.},
  archive      = {J_TROB},
  author       = {Kaidi Wang and Ganghua Lai and Yushu Yu and Jianrui Du and Jiali Sun and Bin Xu and Antonio Franchi and Fuchun Sun},
  doi          = {10.1109/TRO.2025.3568531},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3518-3538},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Versatile tasks on integrated aerial platforms using only onboard sensors: Control, estimation, and validation},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CornerVINS: Accurate localization and layout mapping for structural environments leveraging hierarchical geometric representations. <em>TROB</em>, <em>41</em>, 3500-3517. (<a href='https://doi.org/10.1109/TRO.2025.3567532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A compact and consistent map of surroundings is critical for intelligent robots to understand their situations and realize robust navigation. Most existing techniques rely on infinite planes, which are sensitive to pose drift and may lead to confusing maps. Toward high-level perception in indoor environments, we propose CornerVINS, an innovative RGB-D inertial localization and layout mapping method leveraging hierarchical geometric features, i.e., points, planes, and box corners. Specifically, points are enhanced by fusing depth information, and planes are modeled as bounded patches using convex hulls to increase their discriminability. More importantly, box corners, lying at the intersection of three orthogonal planes, are parameterized with a 6-D vector and integrated into the extended Kalman filter for the first time. We introduce a hierarchical mechanism to effectively extract and associate planes and corners, which are considered as layout components of scenes and serve as long-term landmarks to correct camera poses. Extensive experiments prove that the proposed box corners bring significant improvements, enabling accurate localization and consistent layout mapping at low computational cost. Overall, the proposed CornerVINS outperforms state-of-the-art systems in both accuracy and efficiency.},
  archive      = {J_TROB},
  author       = {Yidi Zhang and Fulin Tang and Yihong Wu},
  doi          = {10.1109/TRO.2025.3567532},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3500-3517},
  shortjournal = {IEEE Trans. Robot.},
  title        = {CornerVINS: Accurate localization and layout mapping for structural environments leveraging hierarchical geometric representations},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Communication- and computation-efficient distributed submodular optimization in robot mesh networks. <em>TROB</em>, <em>41</em>, 3480-3499. (<a href='https://doi.org/10.1109/TRO.2025.3567540'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we provide a communication- and computation-efficient method for distributed submodular optimization in robot mesh networks. Submodularity is a property of diminishing returns that arises in active information gathering such as mapping, surveillance, and target tracking. Our method, resource-aware distributed greedy (RAG), introduces a new distributed optimization paradigm that enables scalable and near-optimal action coordination. To this end, RAG requires each robot to make decisions based only on information received from and about their neighbors. In contrast, the current paradigms allow the relay of information about all robots across the network. As a result, RAG’s decision-time scales linearly with the network size, while state-of-the-art near-optimal submodular optimization algorithms scale cubically. We also characterize how the designed mesh-network topology affects RAG’s approximation performance. Our analysis implies that sparser networks favor scalability without proportionally compromising approximation performance: while RAG’s decision-time scales linearly with network size, the gain in approximation performance scales sublinearly. We demonstrate RAG’s performance in simulated scenarios of area detection with up to 45 robots, simulating realistic robot-to-robot (r2r) communication speeds such as the 0.25 Mb/s speed of the Digi XBee 3 Zigbee 3.0. In the simulations, RAG enables real-time planning, up to three orders of magnitude faster than competitive near-optimal algorithms, while also achieving superior mean coverage performance. To enable the simulations, we extend the high-fidelity and photo-realistic simulator AirSim by integrating a scalable collaborative autonomy pipeline to tens of robots and simulating r2r communication delays.},
  archive      = {J_TROB},
  author       = {Zirui Xu and Sandilya Sai Garimella and Vasileios Tzoumas},
  doi          = {10.1109/TRO.2025.3567540},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3480-3499},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Communication- and computation-efficient distributed submodular optimization in robot mesh networks},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging geometric modeling-based computer vision for context aware control in a hip exosuit. <em>TROB</em>, <em>41</em>, 3462-3479. (<a href='https://doi.org/10.1109/TRO.2025.3567489'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human beings adapt their motor patterns in response to their surroundings, utilizing sensory modalities such as visual inputs. This context-informed adaptive motor behavior has increased interest in integrating computer vision (CV) algorithms into robotic assistive technologies, marking a shift toward context aware control. However, such integration has rarely been achieved so far, with current methods mostly relying on data-driven approaches. In this study, we introduce a novel control framework for a soft hip exosuit, employing instead a physics-informed CV method grounded on geometric modeling of the captured scene for assistance tuning during stairs and level walking. This approach promises to provide a viable solution that is more computationally efficient and does not depend on training examples. Evaluating the controller with six subjects on a path comprising level walking and stairs, we achieved an overall detection accuracy of $93.0\pm 1.1\%$. CV-based assistance provided significantly greater metabolic benefits compared to non-vision-based assistance, with larger energy reductions relative to being unassisted during stair ascent ($-18.9 \pm 4.1\%$ versus $-5.2 \pm 4.1\%$) and descent ($-10.1 \pm 3.6\%$ versus $-4.7 \pm 4.8\%$). Such a result is a consequence of the adaptive nature of the device, enabled by the context aware controller that allowed for more effective walking support, i.e., the assistive torque showed a significant increase while ascending stairs ($+33.9\pm 8.8\%$) and decrease while descending stairs ($-17.4\pm 6.0\%$) compared to a condition without assistance modulation enabled by vision. These results highlight the potential of the approach, promoting effective real-time embedded applications in assistive robotics.},
  archive      = {J_TROB},
  author       = {Enrica Tricomi and Giuseppe Piccolo and Federica Russo and Xiaohui Zhang and Francesco Missiroli and Sandro Ferrari and Letizia Gionfrida and Fanny Ficuciello and Michele Xiloyannis and Lorenzo Masia},
  doi          = {10.1109/TRO.2025.3567489},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3462-3479},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Leveraging geometric modeling-based computer vision for context aware control in a hip exosuit},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Safe reinforcement learning on the constraint manifold: Theory and applications. <em>TROB</em>, <em>41</em>, 3442-3461. (<a href='https://doi.org/10.1109/TRO.2025.3567477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating learning-based techniques, especially reinforcement learning, into robotics is promising for solving complex problems in unstructured environments. Most of the existing approaches rely on training in carefully calibrated simulators before being deployed on real robots, often without real-world fine-tuning. While effective in controlled settings, this framework falls short in applications where precise simulation is unavailable or the environment is too complex to model. Instead, on-robot learning, which learns by interacting directly with the real world, offers a promising alternative. One major problem for on-robot reinforcement learning is ensuring safety, as uncontrolled exploration can cause catastrophic damage to the robot or the environment. Indeed, safety specifications, often represented as constraints, can be complex and nonlinear, making safety challenging to guarantee in learning systems. In this article, we show how we can impose complex safety constraints on learning-based robotics systems in a principled manner, both from theoretical and practical points of view. Our approach is based on the concept of the constraint manifold, representing the set of safe robot configurations. Exploiting differential geometry techniques, i.e., the tangent space, we can construct a safe action space, allowing learning agents to sample arbitrary actions while ensuring safety. We demonstrate the method's effectiveness in a real-world robot air hockey task, showing that our method can handle high-dimensional tasks with complex constraints.},
  archive      = {J_TROB},
  author       = {Puze Liu and Haitham Bou-Ammar and Jan Peters and Davide Tateo},
  doi          = {10.1109/TRO.2025.3567477},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3442-3461},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Safe reinforcement learning on the constraint manifold: Theory and applications},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From extended environment perception toward real-time dynamic modeling for long-range underwater robot. <em>TROB</em>, <em>41</em>, 3423-3441. (<a href='https://doi.org/10.1109/TRO.2025.3567531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater robots are critical observation platforms for diverse ocean environments. However, existing robotic designs often lack long-range and deep-sea observation capabilities and overlook the effects of environmental uncertainties on robotic operations. This article presents a novel long-range underwater robot for extreme ocean environments, featuring a low-power dual-circuit buoyancy adjustment system, an efficient mass-based attitude adjustment system, flying wings, and an open sensor cabin. After that, an extended environment perception strategy with incremental updating is proposed to understand and predict full hydrological dynamics based on sparse observations. On this basis, a real-time dynamic modeling approach integrates multibody dynamics, perceived hydrological dynamics, and environment-robot interactions to provide accurate dynamics predictions and enhance motion efficiency. Extensive simulations and field experiments covering 600 km validated the reliability and autonomy of the robot in long-range ocean observations, highlighting the accuracy of the extended perception and real-time dynamics modeling methods.},
  archive      = {J_TROB},
  author       = {Lei Lei and Yu Zhou and Jianxing Zhang},
  doi          = {10.1109/TRO.2025.3567531},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3423-3441},
  shortjournal = {IEEE Trans. Robot.},
  title        = {From extended environment perception toward real-time dynamic modeling for long-range underwater robot},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and control of a musculoskeletal bionic leg with optimized and sensorized soft artificial muscles. <em>TROB</em>, <em>41</em>, 3402-3422. (<a href='https://doi.org/10.1109/TRO.2025.3567801'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of high-performance bionic legged robots can benefit from the continued advancements in various actuation methods, such as artificial muscles. This work presents a musculoskeletal bionic leg driven by fluidic elastomer actuators (FEAs), showcasing their potential as artificial muscles for legged robots. Our approach integrates three key innovations: First, we established a mechanics model using thin plate theory to optimize the bellows shell structure of the FEAs, achieving high force output while maintaining inherent compliance. Second, we developed a lightweight embedded optoelectronic sensing system that enables closed-loop control without significantly increasing mass. Third, we designed a two-joint leg in the sagittal plane that utilizes a bionic configuration incorporating both monoarticular and biarticular FEAs. The leg demonstrated robust performance across various tasks including extreme positional movements, load-bearing squats supporting up to 2.45 times its body weight, vertical jumping with 147 mm ground clearance, and stable walking. Notably, our embedded sensing system successfully detected ground contact states without additional foot sensors, enabling reliable gait control while minimizing complexity and weight. The experimental results validate both the mechanical capabilities of the optimized FEAs and their controllability through embedded sensing, laying a foundation for developing full legged robots with muscle-like actuation.},
  archive      = {J_TROB},
  author       = {Xuguang Dong and Yixin Wang and Jingyi Zhou and Xin An and Yinglei Zhu and Fugui Xie and Xin-Jun Liu and Huichan Zhao},
  doi          = {10.1109/TRO.2025.3567801},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3402-3422},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Design and control of a musculoskeletal bionic leg with optimized and sensorized soft artificial muscles},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). R-FAC: Resilient value function factorization for multirobot efficient search with individual failure probabilities. <em>TROB</em>, <em>41</em>, 3385-3401. (<a href='https://doi.org/10.1109/TRO.2025.3567478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the resilient multirobot efficient search problem (R-MuRES), which aims at coordinating multiple robots to detect a “nonadversarial” moving target with the minimal expected time. One unique characteristic of R-MuRES among others is the possibility of individual robot's malfunction and withdrawal from the team during task execution, which results in a variable number of searchers in the deployment phase and entails that the possibility of team member failures must be considered during the planning stage, particularly in the training phase. We propose a resilient value function factorization (R-FAC) paradigm, which constructs the central value function from individual ones in a resilient manner, taking into account individual robots' failures, and ensures that the constructed central value function has the minimal mean squared temporal difference error across various team compositions. R-FAC stipulates that the individual global maximum principle is satisfied for whichever team configuration and thus any functioning robot contributes positively to the remaining team, as long as it executes the greedy policy with respect to the factorized individual value function. Subsequently, we introduce the variational value decomposition network (V2DN) as one of the instantiated R-FAC algorithms. V2DN employs the $\log$-sum-$\exp$ mechanism to construct the central value function from individual ones, enabling it to take a varying number of robots' individual value functions as inputs. Then, we explain why, specifically for the multirobot search task, the $\log$-sum-$\exp$ mechanism is superior to the brute-force summation operation used in the canonical value decomposition network (VDN), and compare V2DN with state-of-the-art MuRES solutions as well as the vanilla VDN algorithm in two canonical MuRES testing environments and show that it achieves the best resiliency score when one or several individual robots quit the team during task execution. Furthermore, we validate V2DN with a real multirobot system in a self-constructed indoor environment as the proof of concept.},
  archive      = {J_TROB},
  author       = {Hongliang Guo and Qi Kang and Wei-Yun Yau and Chee-Meng Chew and Daniela Rus},
  doi          = {10.1109/TRO.2025.3567478},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3385-3401},
  shortjournal = {IEEE Trans. Robot.},
  title        = {R-FAC: Resilient value function factorization for multirobot efficient search with individual failure probabilities},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AiDT: Toward radar-based joint anti-interference detection and tracking for weak extended targets under zero-trust autonomous perception tasks. <em>TROB</em>, <em>41</em>, 3368-3384. (<a href='https://doi.org/10.1109/TRO.2025.3567522'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extended object detection and tracking (EODT) is becoming a promising alternative for autonomous perception, which provides not only common motion states but also accurate spatial extent information, such as shape and size estimations. However, due to uncoordinated radar transmissions in zero-trust autonomous driving scenarios, radar-based EODT systems suffer from mutual radio frequency (RF) interference launched by attackers, leading to ghost targets and increased noise. On this account, a novel joint anti-interference detection and tracking system for weak extended targets is presented in this article. In contrast to pioneering works that treat object detection and tracking as two separate steps, the proposed method handles them jointly by integrating a continuous detection process into tracking, improving the detectability of weak targets. More specifically, to accommodate the time-varying number and extended size of radar reflections, an adaptive spatial distribution model representing the deformable extents is incorporated to capture the contour evolution over time. The key insight is that by accumulating the reflected power, all backscattered points are regarded as one entity to match the real target so that the intractable data association problem can be circumvented in the proposed method. Unlike the prominent random matrix model-based approaches that split motion and extent states into independent parts, this study explores the interdependencies between the states and updates them simultaneously. In addition, the proposed system has been deployed on a low-cost automotive radar platform. Experimental results confirm that the proposed approach can achieve accurate and resilient EODT against RF interference attacks, especially in occlusion, dynamic motion switching, and complex multiple extended target tracking scenarios.},
  archive      = {J_TROB},
  author       = {Zhenyuan Zhang and Yu Zhang and Darong Huang and Xin Fang and Mu Zhou and Ying Zhang},
  doi          = {10.1109/TRO.2025.3567522},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3368-3384},
  shortjournal = {IEEE Trans. Robot.},
  title        = {AiDT: Toward radar-based joint anti-interference detection and tracking for weak extended targets under zero-trust autonomous perception tasks},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large-scale multirobot coverage path planning on grids with path deconfliction. <em>TROB</em>, <em>41</em>, 3348-3367. (<a href='https://doi.org/10.1109/TRO.2025.3567476'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we study multirobot coverage path planning (MCPP) on a four-neighbor 2-D grid $G$, which aims to compute paths for multiple robots to cover all cells of $G$. Traditional approaches are limited as they first compute coverage trees on a quadrant coarsened grid $\mathcal {H}$ and then employ the spanning tree coverage (STC) paradigm to generate paths on $G$, making them inapplicable to grids with partially obstructed $2 \times 2$ blocks. To address this limitation, we reformulate the problem directly on $G$, revolutionizing grid-based MCPP solving and establishing new NP-hardness results. We introduce extended STC (ESTC), a novel paradigm that extends STC to ensure complete coverage with bounded suboptimality, even when $\mathcal {H}$ includes partially obstructed blocks. Furthermore, we present LS-MCPP, a new algorithmic framework that integrates ESTC with three novel types of neighborhood operators within a local search strategy to optimize coverage paths directly on $G$. Unlike prior grid-based MCPP work, our approach also incorporates a versatile postprocessing procedure that applies multiagent path finding (MAPF) techniques to MCPP for the first time, enabling a fusion of these two important fields in multirobot coordination. This procedure effectively resolves inter-robot conflicts and accommodates turning costs by solving an MAPF variant, making our MCPP solutions more practical for real-world applications. Extensive experiments demonstrate that our approach significantly improves solution quality and efficiency, managing up to 100 robots on grids as large as $\text{256} \times \text{256}$ within minutes of runtime. Validation with physical robots confirms the feasibility of our solutions under real-world conditions.},
  archive      = {J_TROB},
  author       = {Jingtao Tang and Zining Mao and Hang Ma},
  doi          = {10.1109/TRO.2025.3567476},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3348-3367},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Large-scale multirobot coverage path planning on grids with path deconfliction},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Formulating the unicycle on the sphere path planning problem as a linear time-varying system. <em>TROB</em>, <em>41</em>, 3335-3347. (<a href='https://doi.org/10.1109/TRO.2025.3567525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The kinematics, dynamics, and control of a unicycle moving without slipping on a plane has been extensively studied in the literature of nonholonomic mechanical systems. However, since planar motion can be seen as a limiting case of the motion on a sphere, we focus our analysis on the more general spherical case. This article introduces a novel approach to path planning for a unicycle rolling on a sphere while satisfying the nonslipping constraint. Our method is based on a simple yet effective idea: first, we model the system as a linear time-varying dynamic system. Then, leveraging the fact that certain such systems can be integrated under specific algebraic conditions, we derive a closed-form expression for the control variables. This formulation includes three free parameters, which can be tuned to generate a path connecting any two configurations of the unicycle. Notably, our approach requires no prior knowledge of nonholonomic system analysis, making it accessible to a broader audience.},
  archive      = {J_TROB},
  author       = {Federico Thomas and Jaume Franch},
  doi          = {10.1109/TRO.2025.3567525},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3335-3347},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Formulating the unicycle on the sphere path planning problem as a linear time-varying system},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of bioinspired five-DOF origami for robotic spine assistive exoskeleton. <em>TROB</em>, <em>41</em>, 3317-3334. (<a href='https://doi.org/10.1109/TRO.2025.3567530'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequent and high-load manual material handling (MMH) tasks often cause back injuries to the workers, and back-support exoskeletons are developed for individuals with MMH tasks. However, these exoskeletons usually cannot adapt well to the movements of the wearer's spine. This article introduces a new bioinspired five degree of freedom (DOF) origami, and via mechanical design, a unique rigid-flexible coupled bioinspired origami mechanism is proposed. This origami mechanism is compact and lightweight, and it has stable kinematic behaviors. With the designed origami mechanisms, a novel active origami-based robotic spine assistive exoskeleton (OSAE) is developed to assist individuals with MMH tasks during the symmetric and asymmetric lifting. The OSAE is actuated by a cable-driven module through an underactuated spine module that consists of seven origami mechanisms. With the designed spine module, the OSAE can adapt well to the wearer's spine motions during MMH tasks. Modeling of the five-DOF origami is described, and an adaptive control strategy is proposed for the exoskeleton to adapt to different lifting methods and objects with different weights. The experimental results demonstrate the effectiveness of the proposed OSAE. During the symmetric lifting of a 10-kg object, a reduction of 41.28% of the average muscle activity of the wearer's lumbar erector spinae muscle (LES) is observed, and reductions of 30.15% and 39.54% of the average muscle activities of the wearer's left and right LES are observed, respectively, during the asymmetric lifting of a 10-kg object.},
  archive      = {J_TROB},
  author       = {Bing Chen and Xiang Ni and Lei Zhou and Bin Zi and Eric Li and Dan Zhang},
  doi          = {10.1109/TRO.2025.3567530},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3317-3334},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Development of bioinspired five-DOF origami for robotic spine assistive exoskeleton},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A model predictive capture point control framework for robust humanoid balancing via ankle, hip, and stepping strategies. <em>TROB</em>, <em>41</em>, 3297-3316. (<a href='https://doi.org/10.1109/TRO.2025.3567546'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The robust balancing capability of humanoids is essential for mobility in real environments. Many studies focus on implementing human-inspired ankle, hip, and stepping strategies to achieve human-level balance. In this article, a robust balance control framework for humanoids is proposed. First, a model predictive control (MPC) framework is proposed for capture point (CP) tracking control, enabling the integration of ankle, hip, and stepping strategies within a single framework. In addition, a variable weighting method is introduced that adjusts the weighting parameters of the centroidal angular momentum damping control. Second, a hierarchical structure of the MPC and a stepping controller was proposed, allowing for the step time optimization. The robust balancing performance of the proposed method is validated through simulations and real robot experiments. Furthermore, a superior balancing performance is demonstrated compared to a state-of-the-art quadratic programming-based CP controller that employs the ankle, hip, and stepping strategies.},
  archive      = {J_TROB},
  author       = {Myeong-Ju Kim and Daegyu Lim and Gyeongjae Park and Kwanwoo Lee and Jaeheung Park},
  doi          = {10.1109/TRO.2025.3567546},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3297-3316},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A model predictive capture point control framework for robust humanoid balancing via ankle, hip, and stepping strategies},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Representation of human arm dynamic intents with an electrical impedance tomography (EIT)-driven musculoskeletal model for Human–Robot interaction. <em>TROB</em>, <em>41</em>, 3278-3296. (<a href='https://doi.org/10.1109/TRO.2025.3567547'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representing human arm dynamic intent is essential for effective human–robot interaction. Accurately and robustly decoding these intentions through mathematical modeling of neuromuscular processes poses significant challenges. This study introduces an electrical impedance tomography (EIT)-driven musculoskeletal model, which integrates an EIT sensing system with methods for muscle identification, parameter estimation, and musculoskeletal system modeling. Unlike existing muscle-signal techniques, EIT captures muscle activities from the anatomical cross-sectional plane, providing both activation dynamics and morphological features. We validated our method through multiDoF wrist kinematics estimation under varying contraction intensities, arm endpoint stiffness estimation, and robotic variable admittance control. Our approach achieves accuracy comparable to state-of-the-art methods while requiring fewer training samples and a more compact sensing system. The model incorporates physiological constraints, minimizing decoding errors, and ensuring interaction safety. This method enables reliable intent decoding with practical training demands. Future work will enhance the EIT system for complex tasks.},
  archive      = {J_TROB},
  author       = {Enhao Zheng and Xiaodong Liu and Chenfeng Xu and Zhihao Zhou and Qining Wang},
  doi          = {10.1109/TRO.2025.3567547},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3278-3296},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Representation of human arm dynamic intents with an electrical impedance tomography (EIT)-driven musculoskeletal model for Human–Robot interaction},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FlowSight: Vision-based artificial lateral line sensor for water flow perception. <em>TROB</em>, <em>41</em>, 3260-3277. (<a href='https://doi.org/10.1109/TRO.2025.3567551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel vision-based artificial lateral line (ALL) sensor, FlowSight, enhancing the perception capabilities of underwater robots. Through an autonomous vision system, FlowSight allows for simultaneous sensing the speed and direction of local water flow without relying on external auxiliary equipment. Inspired by the lateral line neuromast of fish, a flexible bionic tentacle is designed to sense water flow. Deformation and motion characteristics of the tentacle are modeled and analyzed using bidirectional fluid-structure interaction (FSI) simulation. Upon contact with water flow, the tentacle converts water flow information into elastic deformation information, which is captured and processed into an image sequence by the autonomous vision system. Subsequently, a water flow perception method based on deep neural networks is proposed to estimate the flow speed and direction from the captured image sequence. The perception network is trained and tested using data collected from practical experiments conducted in a controllable swim tunnel. Finally, the FlowSight sensor is integrated into the bionic underwater robot RoboDact, and a closed-loop motion control experiment based on water flow perception is conducted. Experiments conducted in the swim tunnel and water pool demonstrate the feasibility and effectiveness of FlowSight sensor and the water flow perception method.},
  archive      = {J_TROB},
  author       = {Tiandong Zhang and Rui Wang and Qiyuan Cao and Shaowei Cui and Gang Zheng and Shuo Wang},
  doi          = {10.1109/TRO.2025.3567551},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3260-3277},
  shortjournal = {IEEE Trans. Robot.},
  title        = {FlowSight: Vision-based artificial lateral line sensor for water flow perception},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double oracle algorithm for game-theoretic robot allocation on graphs. <em>TROB</em>, <em>41</em>, 3244-3259. (<a href='https://doi.org/10.1109/TRO.2025.3567506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we study the problem of game-theoretic robot allocation where two players strategically allocate robots to compete for multiple sites of interest. Robots possess offensive or defensive capabilities to interfere and weaken their opponents to take over a competing site. This problem belongs to the conventional an acronym colonel blotto game (CBG). Considering the robots' heterogeneous capabilities and environmental factors, we generalize the conventional Blotto game by incorporating heterogeneous robot types and graph constraints that capture the robot transitions between sites. Then, we employ the double oracle algorithm (DOA) to solve for the Nash equilibrium of the generalized Blotto game. Particularly, for cyclic-dominance-heterogeneous (CDH) robots that inhibit each other, we define a new transformation rule between any two robot types. Building on the transformation, we design a novel utility function to measure the game's outcome quantitatively. Moreover, we rigorously prove the correctness of the designed utility function. Finally, we conduct extensive simulations to demonstrate the effectiveness of DOA on computing Nash equilibrium for homogeneous, linear heterogeneous, and CDH robot allocation on graphs.},
  archive      = {J_TROB},
  author       = {Zijian An and Lifeng Zhou},
  doi          = {10.1109/TRO.2025.3567506},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3244-3259},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Double oracle algorithm for game-theoretic robot allocation on graphs},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast iterative region inflation for computing large 2-d/3-D convex regions of obstacle-free space. <em>TROB</em>, <em>41</em>, 3223-3243. (<a href='https://doi.org/10.1109/TRO.2025.3562482'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convex polytopes have compact representations and exhibit convexity, which makes them suitable for abstracting obstacle-free spaces from various environments. Existing generation methods struggle with balancing high-quality output and efficiency. Moreover, another crucial requirement for convex polytopes to accurately contain certain seed point sets, such as a robot or a front-end path, is proposed in various tasks, which we refer to as manageability. In this article, we propose fast iterative regional inflation (FIRI) to generate high-quality convex polytope while ensuring efficiency and manageability simultaneously. FIRI consists of two iteratively executed submodules: restrictive inflation (RsI) and maximum volume inscribed ellipsoid (MVIE) computation. By explicitly incorporating constraints that include the seed point set, RsI guarantees manageability. Meanwhile, iterative MVIE optimization ensures high-quality result through monotonic volume bound improvement. In terms of efficiency, we design methods tailored to the low-dimensional and multiconstrained nature of both modules, resulting in orders of magnitude improvement compared to generic solvers. Notably, in 2-D MVIE, we present the first linear complexity analytical algorithm for maximum area inscribed ellipse, further enhancing the performance in 2-D cases. Extensive benchmarks conducted against state-of-the-art methods validate the superior performance of FIRI in terms of quality, manageability, and efficiency. Furthermore, various real-world applications showcase the generality and practicality of FIRI. The high-performance code of FIRI will be open-sourced.},
  archive      = {J_TROB},
  author       = {Qianhao Wang and Zhepei Wang and Mingyang Wang and Jialin Ji and Zhichao Han and Tianyue Wu and Rui Jin and Yuman Gao and Chao Xu and Fei Gao},
  doi          = {10.1109/TRO.2025.3562482},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3223-3243},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Fast iterative region inflation for computing large 2-d/3-D convex regions of obstacle-free space},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model predictive inferential control of neural state-space models for autonomous vehicle motion planning. <em>TROB</em>, <em>41</em>, 3202-3222. (<a href='https://doi.org/10.1109/TRO.2025.3566198'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model predictive control (MPC) has proven useful in enabling safe and optimal motion planning for autonomous vehicles. In this article, we investigate how to achieve MPC-based motion planning when a neural state-space model represents the vehicle dynamics. As the neural state-space model will lead to highly complex, nonlinear, and nonconvex optimization landscapes, mainstream gradient-based MPC methods will struggle to provide viable solutions due to heavy computational load. In a departure, we propose the idea of model predictive inferential control (MPIC), which seeks to infer the best control decisions from the control objectives and constraints. Following this idea, we convert the MPC problem for motion planning into a Bayesian state estimation problem. Then, we develop a new implicit particle filtering/smoothing approach to perform the estimation. This approach is implemented as banks of unscented Kalman filters/smoothers and offers high sampling efficiency, fast computation, and estimation accuracy. We evaluate the MPIC approach through a simulation study of autonomous driving in different scenarios, along with an exhaustive comparison with gradient-based MPC. The simulation results show that the MPIC approach has considerable computational efficiency despite complex neural network architectures and the capability to solve large-scale MPC problems for neural state-space models.},
  archive      = {J_TROB},
  author       = {Iman Askari and Ali Vaziri and Xuemin Tu and Shen Zeng and Huazhen Fang},
  doi          = {10.1109/TRO.2025.3566198},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3202-3222},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Model predictive inferential control of neural state-space models for autonomous vehicle motion planning},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SceneFactory: A workflow-centric and unified framework for incremental scene modeling. <em>TROB</em>, <em>41</em>, 3183-3201. (<a href='https://doi.org/10.1109/TRO.2025.3562479'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present SceneFactory, a workflow-centric and unified framework for incremental scene modeling that conveniently supports a wide range of applications, such as (unposed and/or uncalibrated) multiview depth estimation, LiDAR completion, (dense) RGB-D/RGB-LiDAR (RGB-L)/Mono/Depth-only reconstruction, and simultaneous localization and mapping (SLAM). The workflow-centric design uses multiple blocks as the basis for constructing different production lines. The supported applications, i.e., productions avoid redundancy in their designs. Thus, the focus is placed on each block itself for independent expansion. To support all input combinations, our implementation consists of four building blocks that form SceneFactory: first, tracking, second, flexion, third, depth estimation, and fourth, scene reconstruction. The tracking block is based on Mono SLAM and is extended to support RGB-D and RGB-L inputs. Flexion is used to convert the depth image (untrackable) into a trackable image. For general-purpose depth estimation, we propose an unposed and uncalibrated multiview depth estimation model (U$^{2}$-MVD) to estimate dense geometry. U$^{2}$-MVD exploits dense bundle adjustment to solve for poses, intrinsics, and inverse depth. A semantic-aware ScaleCov step is then introduced to complete the multiview depth. Relying on U$^{2}$-MVD, SceneFactory both supports user-friendly 3-D creation (with just images) and bridges the applications of Dense RGB-D and Dense Mono. For high-quality surface and color reconstruction, we propose dual-purpose multiresolutional neural points for the first surface accessible surface color field design, where we introduce improved point rasterization for point cloud-based surface query. We implement and experiment with SceneFactory to demonstrate its broad applicability and high flexibility. Its quality also competes or exceeds the tightly-coupled state of the art approaches in all tasks.},
  archive      = {J_TROB},
  author       = {Yijun Yuan and Michael Bleier and Andreas Nüchter},
  doi          = {10.1109/TRO.2025.3562479},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3183-3201},
  shortjournal = {IEEE Trans. Robot.},
  title        = {SceneFactory: A workflow-centric and unified framework for incremental scene modeling},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aerial robots carrying flexible cables: Dynamic shape optimal control via spectral method model. <em>TROB</em>, <em>41</em>, 3162-3182. (<a href='https://doi.org/10.1109/TRO.2025.3562459'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a model-based optimal boundary control design for an aerial robotic system composed of a quadrotor carrying a flexible cable. The whole system is modeled by partial differential equations combined with boundary conditions described by ordinary differential equations. The proper orthogonal decomposition (POD) method is adopted to project the original infinite-dimensional system on a finite low-dimensional space spanned by orthogonal basis functions. Based on such a reduced-order model, nonlinear model predictive control is implemented online to realize both position and shape trajectory tracking of the flexible cable in an optimal predictive fashion. The proposed POD-based reduced modeling and optimal control paradigms are verified in simulation using an accurate high-dimensional finite difference method-based model and experimentally using a real quadrotor and a cable. The results show the viability of the POD-based predictive control approach (allowing to close the control loop on the full system state) and its superior performance compared to an optimally tuned proportional–integral–derivative (PID) controller (allowing to close the control loop on the quadrotor state only).},
  archive      = {J_TROB},
  author       = {Yaolei Shen and Antonio Franchi and Chiara Gabellieri},
  doi          = {10.1109/TRO.2025.3562459},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3162-3182},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Aerial robots carrying flexible cables: Dynamic shape optimal control via spectral method model},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From concept to field trials: Design, analysis, and evaluation of a novel quadruped robot with deformable Wheel–Foot structure. <em>TROB</em>, <em>41</em>, 3143-3161. (<a href='https://doi.org/10.1109/TRO.2025.3562449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel quadruped robot, the TerraAdapt, furnished with an innovative deformable wheel–foot integrated structure. This unique design grants the robot the flexibility to alternate between wheeled and footed modes of locomotion, making it efficient in traversing diverse terrains, from smooth indoor floors to challenging outdoor landscapes laden with obstacles. The study delineates an in-depth design and analysis of the deformable wheel and its integrated wheel–foot structure using screw theory. We engineer a 2 R: Rotational, P: Prismatic (RRR-RP) wheel–foot mode-switching mechanism by modifying a 2RRR spatial six-bar mechanism with an additional RP branch. This mechanism aids in seamless transitioning between different movement modes. Moreover, a 2RRR parallel structure is employed to construct the footed mode structure.To substantiate the viability and efficacy of the proposed design, we carry out extensive motion simulations and construct an experimental prototype for field testing. The field trials reveal the robot's adeptness in adapting to varied terrains, highlighting the possible advantages of incorporating the proposed deformable wheel into micro mobile robot designs.},
  archive      = {J_TROB},
  author       = {Zhongjin Ju and Ke Wei and Yundou Xu},
  doi          = {10.1109/TRO.2025.3562449},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3143-3161},
  shortjournal = {IEEE Trans. Robot.},
  title        = {From concept to field trials: Design, analysis, and evaluation of a novel quadruped robot with deformable Wheel–Foot structure},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast and accurate 6-D object pose refinement via implicit surface optimization. <em>TROB</em>, <em>41</em>, 3129-3142. (<a href='https://doi.org/10.1109/TRO.2025.3562484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aligning a point cloud to a fixed 3-D model is a crucial task in many applications, such as 6-D pose estimation for robotic grasping. Typically, an initial pose is estimated by analyzing both the point cloud and the 3-D model, after which the iterative closest point (ICP) algorithm is used to refine the pose, reducing large errors and improving accuracy. In this article, we propose an accurate and efficient alternative to the ICP. Our method encodes the fixed 3-D model into an implicit neural network, which is trained offline as a one-time process in just a few minutes, requiring only the CAD model of the object. The network takes the point cloud and pose as inputs and outputs the signed distance field (SDF) value. By minimizing the absolute SDF value with the fixed point cloud and network weights, while optimizing the pose, we obtain the final precise alignment. The key advantage of our method is that it eliminates the need to explicitly establish one-to-one correspondences between the point cloud and the 3-D model, a necessary step in the ICP and its variants. This enables our framework to avoid local optima and makes it more robust to challenging conditions such as large initial pose gaps, noisy data, variations in scale, occlusions, and reflections. Furthermore, the end-to-end network of our framework offers significant runtime efficiency. We validate the superior performance of our approach through extensive comparisons with various ICP variants on both synthetic and real-world datasets.},
  archive      = {J_TROB},
  author       = {Bo Pang and Deming Zhai and Jianan Zhen and Long Wang and Xianming Liu},
  doi          = {10.1109/TRO.2025.3562484},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3129-3142},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Fast and accurate 6-D object pose refinement via implicit surface optimization},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Shear-based grasp control for multifingered underactuated tactile robotic hands. <em>TROB</em>, <em>41</em>, 3113-3128. (<a href='https://doi.org/10.1109/TRO.2025.3563046'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a shear-based control scheme for grasping and manipulating delicate objects with a Pisa/IIT anthropomorphic SoftHand equipped with soft biomimetic tactile sensors on all five fingertips. These “microTac” tactile sensors are miniature versions of the TacTip vision-based tactile sensor, and can extract precise contact geometry and force information at each fingertip for use as feedback into a controller to modulate the grasp while a held object is manipulated. Using a parallel processing pipeline, we asynchronously capture tactile images and predict contact pose and force from multiple tactile sensors. Consistent pose and force models across all sensors are developed using supervised deep learning with transfer learning techniques. We then develop a grasp control framework that uses contact force feedback from all fingertip sensors simultaneously, allowing the hand to safely handle delicate objects even under external disturbances. This control framework is applied to several grasp-manipulation experiments: First, retaining a flexible cup in a grasp without crushing it under changes in object weight; Second, a pouring task where the center of mass of the cup changes dynamically; and third, a tactile-driven leader-follower task where a human guides a held object. These manipulation tasks demonstrate more human-like dexterity with underactuated robotic hands by using fast reflexive control from tactile sensing.},
  archive      = {J_TROB},
  author       = {Christopher J. Ford and Haoran Li and Manuel G. Catalano and Matteo Bianchi and Efi Psomopoulou and Nathan F. Lepora},
  doi          = {10.1109/TRO.2025.3563046},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3113-3128},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Shear-based grasp control for multifingered underactuated tactile robotic hands},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A biomimetic rigid-soft hybrid underwater gripper with compliance, stability, precise control, and high load capacity. <em>TROB</em>, <em>41</em>, 3099-3112. (<a href='https://doi.org/10.1109/TRO.2025.3562458'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex underwater environment presents numerous challenges for the design of soft grippers, which often suffer from limited load capacity, poor stability, low portability, and imprecise control. This article proposes a novel rigid-soft hybrid gripper specifically designed for underwater use. The gripper's finger is constructed from silicone, reinforced with a multilink rigid exoskeleton on the outside, and actuated by tendons. This design provides three key advantages: compliance (capable of handling fragile objects such as a piece of tofu), heavy lifting (demonstrated by lifting an 80-kg barbell with three fingers), and precise, stable operation (the hybrid gripper maintains its shape despite water flow disturbances). In addition, the gripper is compact and lightweight, with the driving system powered by just four 23-g servo motors, making it easy to mount on various underwater robots. To enable precise control, both specialized kinematic and mechanics models were developed, allowing accurate predictions of the relationships among tendon displacement, exoskeleton deformation, soft material deformation, and tendon tension. This study thoroughly considers the challenges of underwater environments, offering new insights for advancing the field of underwater soft grasping.},
  archive      = {J_TROB},
  author       = {Fei Suo and Xiaolong Hui and Peixin Hua and Xuejian Bai and Jin Ma and Min Tan and Yu Wang},
  doi          = {10.1109/TRO.2025.3562458},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3099-3112},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A biomimetic rigid-soft hybrid underwater gripper with compliance, stability, precise control, and high load capacity},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging the gap between semantics and geometry in SLAM: A semantic-geometric tight-coupling monocular visual object SLAM system. <em>TROB</em>, <em>41</em>, 3078-3098. (<a href='https://doi.org/10.1109/TRO.2025.3562440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing object-level simultaneous localization and mapping (SLAM) methods often overlook the correspondence between semantic information and geometric features, resulting in a significant gap between them within SLAM frameworks. To tackle this issue, this article proposes, a semantic-geometric tight-coupling monocular visual object SLAM system, (TiMoSLAM), which considers a rigorous correspondence between semantics and geometry across all steps of SLAM. Initially, a general semantic relation graph (SRG) is developed to consistently represent semantic information alongside geometric features. Detailed analyzes on complete constraints of the geometric feature combinations on estimation of 3-D cuboid model are performed. Subsequently, a compound hypothesis tree is proposed to incrementally construct the object-specific SRG and concurrently estimate the 3-D cuboid model of an object, ensuing semantic-geometric consistency in object representation and estimation. Special attention is given to the matching errors between geometric features and objects during the optimization of camera poses and object parameters. The effectiveness of this method is validated on various datasets, as well as in real-world environments.},
  archive      = {J_TROB},
  author       = {Wenbin Zhu and Jing Yuan and Xuebo Zhang and Fei Chen},
  doi          = {10.1109/TRO.2025.3562440},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3078-3098},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Bridging the gap between semantics and geometry in SLAM: A semantic-geometric tight-coupling monocular visual object SLAM system},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Load-transfer suspended backpack with bioinspired vibration isolation for shoulder pressure reduction across diverse terrains. <em>TROB</em>, <em>41</em>, 3059-3077. (<a href='https://doi.org/10.1109/TRO.2025.3562488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active suspended backpacks represent a promising solution to mitigate the impact of inertial forces on individuals engaged in load carriage. However, identifying effective control objectives aimed at enhancing human carrying capacity remains a significant challenge. In this study, we introduce a novel approach by integrating a limb-like structure-type (LLS) bioinspired vibration isolator, modeled using Lagrangian mechanics, into an active load-transfer suspended backpack to primarily alleviate human shoulder pressure, thereby constructing a human–robot interaction control framework for the system. Drawing from a double-mass coupled oscillator model, this approach formulates a vertical dynamics model for the human-backpack system, systematically exploring the principles of both static load transfer and dynamic load reduction on the human shoulder. Subsequently, a series-elastic-actuator-based controller with prescribed performance is proposed to simultaneously achieve trajectory tracking and ensure load motion within the limited range. Theoretically, we validate the input–output stability of the LLS model and guarantee the ultimate uniform boundedness of the closed-loop system. Simulation and experimental trials conducted across different terrain scenarios validate the effectiveness of the proposed method, highlighting reductions of 18.68% in metabolic rate during level ground walking, 9.58% in a staircase scenario, and 12.35% in a complex terrain, involving uphill, downstairs, and flat ground walking.},
  archive      = {J_TROB},
  author       = {Yu Cao and Mengshi Zhang and Jian Huang and Samer Mohammed},
  doi          = {10.1109/TRO.2025.3562488},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3059-3077},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Load-transfer suspended backpack with bioinspired vibration isolation for shoulder pressure reduction across diverse terrains},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sensitivity-aware model predictive control for robots with parametric uncertainty. <em>TROB</em>, <em>41</em>, 3039-3058. (<a href='https://doi.org/10.1109/TRO.2025.3554415'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a computationally efficient robust model predictive control (MPC) scheme for controlling nonlinear systems affected by parametric uncertainties in their models. The approach leverages the recent notion of closed-loop state sensitivity and the associated ellipsoidal tubes of perturbed trajectories for taking into account online time-varying restrictions on state and input constraints. This makes the MPC controller “aware” of potential additional requirements needed to cope with parametric uncertainty, thus significantly improving the tracking performance and success rates during navigation in constrained environments. One key contribution lies in the introduction of a computationally efficient robust MPC formulation with a comparable computational complexity to a standard MPC (i.e., an MPC not explicitly dealing with parametric uncertainty). An extensive simulation campaign is presented to demonstrate the effectiveness of the proposed approach in handling parametric uncertainties and enhancing task performance, safety, and overall robustness. Furthermore, we also provide an experimental validation that shows the feasibility of the approach in real-world conditions and corroborates the statistical findings of the simulation campaign. The versatility and efficiency of the proposed method make it therefore a valuable tool for real-time control of robots subject to nonnegligible uncertainty in their models.},
  archive      = {J_TROB},
  author       = {Tommaso Belvedere and Marco Cognetti and Giuseppe Oriolo and Paolo Robuffo Giordano},
  doi          = {10.1109/TRO.2025.3554415},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3039-3058},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Sensitivity-aware model predictive control for robots with parametric uncertainty},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). General place recognition survey: Toward real-world autonomy. <em>TROB</em>, <em>41</em>, 3019-3038. (<a href='https://doi.org/10.1109/TRO.2025.3550771'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of robotics, the quest for achieving real-world autonomy, capable of executing large-scale and long-term operations, has positioned place recognition (PR) as a cornerstone technology. Despite the PR community's remarkable strides over the past two decades, garnering attention from fields like computer vision and robotics, the development of PR methods that sufficiently support real-world robotic systems remains a challenge. This article aims to bridge this gap by highlighting the crucial role of PR within the framework of simultaneous localization and mapping 2.0. This new phase in robotic navigation calls for scalable, adaptable, and efficient PR solutions by integrating advanced artificial intelligence technologies. For this goal, we provide a comprehensive review of the current state-of-the-art advancements in PR, alongside the remaining challenges, and underscore its broad applications in robotics. This article begins with an exploration of PR's formulation and key research challenges. We extensively review literature, focusing on related methods on place representation and solutions to various PR challenges. Applications showcasing PR's potential in robotics, key PR datasets, and open-source libraries are discussed.},
  archive      = {J_TROB},
  author       = {Peng Yin and Jianhao Jiao and Shiqi Zhao and Lingyun Xu and Guoquan Huang and Howie Choset and Sebastian Scherer and Jianda Han},
  doi          = {10.1109/TRO.2025.3550771},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3019-3038},
  shortjournal = {IEEE Trans. Robot.},
  title        = {General place recognition survey: Toward real-world autonomy},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient unified algorithm for the minimum euclidean distance between two collections of compact convex sets. <em>TROB</em>, <em>41</em>, 3004-3018. (<a href='https://doi.org/10.1109/TRO.2025.3562478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present an efficient unified algorithm for the minimum Euclidean distance between two collections of compact convex sets, each of which can be a collection of convex primitives, such as ellipsoids, capsules, and cylinders, or a collection of triangles (i.e., triangle mesh) or a collection of points (i.e., point cloud) as special cases. The Euclidean distance between two compact convex sets is defined to be the smallest translation to bring them into intersection if they are separated or to separate them if they intersect, which can be computed by the well-known Gilbert–Johnson–Keerthi and expanding polytope algorithms, respectively. While existing algorithms are aimed at computing the minimum Euclidean distance for a specific type of collections, algorithms for mixed situations always remain vacant. We discover that the smallest translation direction between any two compact convex sets determines the planes to bound and separate some other sets in two collections and can help quickly identify sets that do not have the minimum distance. In this way, the minimum distance between two collections can be efficiently computed, hundreds to thousands of times faster than the brute-force search. The computational efficiency of the proposed algorithm is verified with a number of numerical experiments in various scenarios.},
  archive      = {J_TROB},
  author       = {Yu Zheng},
  doi          = {10.1109/TRO.2025.3562478},
  journal      = {IEEE Transactions on Robotics},
  pages        = {3004-3018},
  shortjournal = {IEEE Trans. Robot.},
  title        = {An efficient unified algorithm for the minimum euclidean distance between two collections of compact convex sets},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-based automatic control of magnetic diatom biohybrid microrobots for targeted delivery. <em>TROB</em>, <em>41</em>, 2990-3003. (<a href='https://doi.org/10.1109/TRO.2025.3562452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biohybrid microrobots with autonomous movement capabilities have broad application prospects in targeted delivery, attracting researchers to study their movement characteristics. However, its automatic control is still challenging, and exploring real-time detection of its environment for path planning to achieve stable closed-loop control is highly important for its practical application. Here, we applied deep learning for the detection of biohybrid microrobots and their targets and obstacles, followed by real-time path planning and trajectory tracking of biohybrid microrobots for targeted delivery. The proposed detection algorithm introduces attention and multiscale feature fusion mechanisms in YOLOv7 algorithm (AM-YOLOv7) with the aim of enhancing the precision of detecting small-scale targets when robots, obstacles and targets are displayed globally, and the detection capabilities are verified through simulations and experiments. The proposed planning algorithm introduces a turning penalty function and a path smoothing strategy into A* algorithm (PS-A*) to make the planned path short and smooth, which has been verified through simulation and experiments. The adaptive fuzzy PID method is used to track the robot's trajectory, and experiments and simulations show that the biohybrid microrobot can move according to the preset trajectory better. The final cell scene experimental results show that the biohybrid microrobot using this system can effectively avoid obstacle cells and be delivered to target cells. The system can detect biohybrid microrobots, obstacle cells and target cells, plan short and smooth trajectories, and track them accurately. The proposed method has certain generalizability and broad application prospects in targeted delivery.},
  archive      = {J_TROB},
  author       = {Mengyue Li and Liang Li and Junjian Zhou and Lianqing Liu and Niandong Jiao},
  doi          = {10.1109/TRO.2025.3562452},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2990-3003},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Deep learning-based automatic control of magnetic diatom biohybrid microrobots for targeted delivery},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ACSim: A novel acoustic camera simulator with recursive ray tracing, artifact modeling, and ground truthing. <em>TROB</em>, <em>41</em>, 2970-2989. (<a href='https://doi.org/10.1109/TRO.2025.3562048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel acoustic camera simulator that generates realistic sonar images by incorporating recursive ray tracing and sonar artifact modeling and provides various ground truth labels, enabling benchmarking and learning purposes. The 2-D forward-looking sonar, also known as the acoustic camera, produces high-quality 2-D images. Conducting real-world underwater experiments is challenging, making realistic sonar image simulation a necessary alternative. However, existing simulators often lack sufficient realism or are limited to specific scenes and phenomena. As a result, training on simulations and testing on real sonar images (i.e., sim-to-real) remain open problems for deep learning-based applications. Our work introduces a novel sonar simulator with a customized rendering engine. We use recursive ray tracing to model multipath reflections in arbitrary scenes and propose physics-based shading for intensity computation. We propose a resampling method for antialiasing and model significant artifacts, such as rolling shutter distortions and crosstalk noise. The simulator provides various ground truths for benchmarking and deep learning applications. We tested several tasks by training on synthetic images and demonstrated that the models also work on real images. We developed a Blender add-on for an enhanced user interface and will make the simulator open-source to advance future research.},
  archive      = {J_TROB},
  author       = {Yusheng Wang and Yonghoon Ji and Hiroshi Tsuchiya and Jun Ota and Hajime Asama and Atsushi Yamashita},
  doi          = {10.1109/TRO.2025.3562048},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2970-2989},
  shortjournal = {IEEE Trans. Robot.},
  title        = {ACSim: A novel acoustic camera simulator with recursive ray tracing, artifact modeling, and ground truthing},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CAT-ORA: Collision-aware time-optimal formation reshaping for efficient robot coordination in 3-D environments. <em>TROB</em>, <em>41</em>, 2950-2969. (<a href='https://doi.org/10.1109/TRO.2025.3547296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we introduce an algorithm designed to address the problem of time-optimal formation reshaping in three-dimensional environments while preventing collisions between agents. The utility of the proposed approach is particularly evident in mobile robotics, where agents benefit from being organized and navigated in formation for a variety of real-world applications requiring frequent alterations in formation shape for efficient navigation or task completion. Given the constrained operational time inherent to battery-powered mobile robots, the time needed to complete the formation reshaping process is crucial for their efficient operation, especially in case of multi-rotor uncrewed aerial vehicles (UAVs). The proposed collision-aware time-optimal formation reshaping algorithm (CAT-ORA) builds upon the Hungarian algorithm for the solution of the robot-to-goal assignment implementing the interagent collision avoidance through direct constraints on mutually exclusive robot-goal pairs combined with a trajectory generation approach minimizing the duration of the reshaping process. Theoretical validations confirm the optimality of CAT-ORA, with its efficacy further showcased through simulations, and a real-world outdoor experiment involving 19 UAVs. Thorough numerical analysis shows the potential of CAT-ORA to decrease the time required to perform complex formation reshaping tasks by up to 49%, and 12% on average compared to commonly used methods in randomly generated scenarios.},
  archive      = {J_TROB},
  author       = {Vit Kratky and Robert Penicka and Jiri Horyna and Petr Stibinger and Tomas Baca and Matej Petrlik and Petr Stepan and Martin Saska},
  doi          = {10.1109/TRO.2025.3547296},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2950-2969},
  shortjournal = {IEEE Trans. Robot.},
  title        = {CAT-ORA: Collision-aware time-optimal formation reshaping for efficient robot coordination in 3-D environments},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relative localizability and localization for multirobot systems. <em>TROB</em>, <em>41</em>, 2931-2949. (<a href='https://doi.org/10.1109/TRO.2025.3544103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inter-robot relative positions are crucial for executing various multirobot missions, such as formation maneuvering and collaborative inspection. However, the current sensing technology usually provides part of relative position information, such as inter-robot distances, bearings and angles. This prompts the study of determining inter-robot relative positions, i.e., relative localization, from these partial measurements. Based on the existing results of static networks' localizability and mobile robots' relative localization, we propose a novel concept, relative localizability to describe whether a multirobot system is relatively localizable. Given each robot's self-displacement measurements and inter-robot partial measurements in $d$ ($d\leq 4$) sampling instants, we show that a multirobot system's relative localization can be achieved in a purely algebraic and distributed manner, in which the multirobot system is said to be $d$-step relatively localizable. To make the results more general, we consider that the multirobot system consists of landmarks, leaders, and followers, and that the inter-robot measurements can be distances, bearings or angles. When robots' coordinate frames have different orientations, we show that the given local measurements can be used to determine robots' relative positions and their coordinate frames' relative orientations simultaneously. Simulations and experiments of relative localization for ground robots are conducted to validate the obtained results.},
  archive      = {J_TROB},
  author       = {Liangming Chen and Chenyang Liang and Shenghai Yuan and Muqing Cao and Lihua Xie},
  doi          = {10.1109/TRO.2025.3544103},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2931-2949},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Relative localizability and localization for multirobot systems},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CoverLib: Classifiers-equipped experience library by iterative problem distribution coverage maximization for domain-tuned motion planning. <em>TROB</em>, <em>41</em>, 2911-2930. (<a href='https://doi.org/10.1109/TRO.2025.3552346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Library-based methods are known to be very effective for fast motion planning by adapting an experience retrieved from a precomputed library. This article presents CoverLib, a principled approach for constructing and utilizing such a library. CoverLib iteratively adds an experience-classifier-pair to the library, where each classifier corresponds to an adaptable region of the experience within the problem space. This iterative process is an active procedure, as it selects the next experience based on its ability to effectively cover the uncovered region. During the query phase, these classifiers are utilized to select an experience that is expected to be adaptable for a given problem. Experimental results demonstrate that CoverLib effectively mitigates the tradeoff between plannability and speed observed in global (e.g., sampling-based) and local (e.g., optimization-based) methods. As a result, it achieves both fast planning and high success rates over the problem domain. Moreover, due to its adaptation-algorithm-agnostic nature, CoverLib seamlessly integrates with various adaptation methods, including nonlinear programming-based and sampling-based algorithms.},
  archive      = {J_TROB},
  author       = {Hirokazu Ishida and Naoki Hiraoka and Kei Okada and Masayuki Inaba},
  doi          = {10.1109/TRO.2025.3552346},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2911-2930},
  shortjournal = {IEEE Trans. Robot.},
  title        = {CoverLib: Classifiers-equipped experience library by iterative problem distribution coverage maximization for domain-tuned motion planning},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ultrarobust and lightweight electro-pneumatic actuators for soft robotics. <em>TROB</em>, <em>41</em>, 2894-2910. (<a href='https://doi.org/10.1109/TRO.2025.3559430'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rigid robots can achieve precise motions but expose shortcomings in system complexity, fabrication cost, and human–robot interaction, which motivates researchers to develop various soft robots to fill these gaps. Electro-hydraulic actuators (EHAs) have received widespread attention and been used in many soft robots due to impressive high-strain, fast-speed, and rapid-response characteristics. However, existing EHAs face challenges in achieving large-deformation, high-robustness, and low-weight simultaneously. This limits the application of EHAs in robotic systems that are weight-sensitive or require fail-safe and fault-tolerant behavior. Here, we present a lightweight (0.98 g) electro-pneumatic actuator (EPA) filled with air and only 0.1-mL liquid dielectric, which achieves high-speed bending from 11° to 93.5° in 60 ms, large-angle bending from 11° to 104° in 2 s (the largest in current EHAs), and high-frequency swing at 20 Hz. The EPA is ultrarobust and can operate properly after being punctured by four needles or crushed twice by a 1500-kg vehicle. Furthermore, to validate the above features of EPAs, three applications are demonstrated at a voltage of 6 kV, including four-finger grippers, fast-crawling robots, and water-walking robots. This work pushes the boundaries of robustness and lightweight for EHAs, providing a foundation for the application of electro-pneumatic actuation in soft robotics.},
  archive      = {J_TROB},
  author       = {Zean Yuan and Jiaxing Li and Lifu Liu and Xinyu Zhu and Wenbiao Wang and Michael D. Dickey and Guo Zhan Lum and Pakpong Chirarattananon and Jun Luo and Rui Chen},
  doi          = {10.1109/TRO.2025.3559430},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2894-2910},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Ultrarobust and lightweight electro-pneumatic actuators for soft robotics},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A learning-based method for computing self-motion manifolds of redundant robots for real-time fault-tolerant motion planning. <em>TROB</em>, <em>41</em>, 2879-2893. (<a href='https://doi.org/10.1109/TRO.2025.3559404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The focus of this research is to develop a learning-based method that computes self-motion manifolds (SMMs) efficiently and accurately to enable real-time global fault-tolerant motion planning. The proposed method first develops a learnable, closed-form representation of SMMs based on Fourier series. A cellular automaton is then applied to cluster workspace locations having the same number of SMMs and group SMMs with similar shape by homotopy classes, such that the SMMs of each homotopy class can be accurately learned by a neural network. To approximate the SMMs of an arbitrary workspace location, a neural network is first trained to predict the set of homotopy classes belonging to this workspace location. For each set of homotopy classes, another neural network is trained to approximate the Fourier series coefficients of the SMMs, and the joint configurations along the SMMs can be retrieved using the inverse Fourier transform. The proposed method is validated on planar 3R positioning, spatial 4R positioning, and spatial 7R positioning and orienting robots, using 10 000 randomly sampled workspace locations each. The results show that the proposed method can approximate SMMs with high accuracy and is much faster than the traditionally used nullspace projection method, a sampling-based method, and a grid-based method. The performance of the proposed method in real-time fault-tolerant motion planning applications is also demonstrated using the simulation of the spatial 7R robot and physical experiments on a planar 3R robot. Due to the computational efficiency of the proposed method, both robots are able to quickly plan trajectories which maximize the likelihood of task completion after the failure of one arbitrary joint.},
  archive      = {J_TROB},
  author       = {Charles L. Clark and Biyun Xie},
  doi          = {10.1109/TRO.2025.3559404},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2879-2893},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A learning-based method for computing self-motion manifolds of redundant robots for real-time fault-tolerant motion planning},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized multispeed dubins motion model. <em>TROB</em>, <em>41</em>, 2861-2878. (<a href='https://doi.org/10.1109/TRO.2025.3554436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article develops a novel motion model, called generalized multispeed Dubins motion model (GMDM), which extends the Dubins model by considering multiple speeds. While the Dubins model produces time-optimal paths under a constant-speed constraint, these paths could be suboptimal if this constraint is relaxed to include multiple speeds. This is because a constant speed results in a large minimum turning radius, thus producing paths with longer maneuvers and larger travel times. In contrast, multispeed relaxation allows for slower speed sharp turns, thus producing more direct paths with shorter maneuvers and smaller travel times. Furthermore, the inability of the Dubins model to reduce speed could result in fast maneuvers near obstacles, thus producing paths with high collision risks. In this regard, GMDM provides the motion planners the ability to jointly optimize time and risk by allowing the change of speed along the path. GMDM is built upon the six Dubins path types considering the change of speed on path segments. It is theoretically established that GMDM provides full reachability of the configuration space for any speed selections. Furthermore, it is shown that the Dubins model is a specific case of GMDM for constant speeds. The solutions of GMDM are analytical and suitable for real-time applications. The performance of GMDM in terms of solution quality (i.e., time/time-risk cost) and computation time is comparatively evaluated against the existing motion models in obstacle-free as well as obstacle-rich environments via extensive Monte Carlo simulations. The results show that in obstacle-free environments, GMDM produces near time-optimal paths with significantly lower travel times than the Dubins model while having similar computation times. In obstacle-rich environments, GMDM produces time-risk optimized paths with substantially lower collision risks.},
  archive      = {J_TROB},
  author       = {James P. Wilson and Shalabh Gupta and Thomas A. Wettergren},
  doi          = {10.1109/TRO.2025.3554436},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2861-2878},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Generalized multispeed dubins motion model},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiquery robotic manipulator task sequencing with gromov-hausdorff approximations. <em>TROB</em>, <em>41</em>, 2843-2860. (<a href='https://doi.org/10.1109/TRO.2025.3554404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic manipulator applications often require efficient online motion planning. When completing multiple tasks, sequence order and choice of goal configuration can have a drastic impact on planning performance. This is well known as the robot task sequencing problem (RTSP). Existing general-purpose RTSP algorithms are susceptible to producing poor-quality solutions or failing entirely when available computation time is restricted. We propose a new multiquery task sequencing method designed to operate in semistructured environments with a combination of static and nonstatic obstacles. Our method intentionally trades off workspace generality for planning efficiency. Given a user-defined task space with static obstacles, we compute a subspace decomposition. The key idea is to establish approximate isometries known as $\epsilon$-Gromov-Hausdorff approximations that identify points that are close to one another in both task and configuration space. Importantly, we prove bounded suboptimality guarantees on the lengths of paths within these subspaces. These bounding relations further imply that paths within the same subspace can be smoothly concatenated, which we show is useful for determining efficient task sequences. We evaluate our method with several kinematic configurations in a complex simulated environment, achieving up to 3× faster motion planning and 5× lower maximum trajectory jerk compared to baselines.},
  archive      = {J_TROB},
  author       = {Fouad Sukkar and Jennifer Wakulicz and Ki Myung Brian Lee and Weiming Zhi and Robert Fitch},
  doi          = {10.1109/TRO.2025.3554404},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2843-2860},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Multiquery robotic manipulator task sequencing with gromov-hausdorff approximations},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CURE: Simulation-augmented autotuning in robotics. <em>TROB</em>, <em>41</em>, 2825-2842. (<a href='https://doi.org/10.1109/TRO.2025.3548546'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic systems are typically composed of various subsystems, such as localization and navigation, each encompassing numerous configurable components (e.g., selecting different planning algorithms). Once an algorithm has been selected for a component, its associated configuration options must be set to the appropriate values. Configuration options across the system stack interact nontrivially. Finding optimal configurations for highly configurable robots to achieve desired performance poses a significant challenge due to the interactions between configuration options across software and hardware that result in an exponentially large and complex configuration space. These challenges are further compounded by the need for transferability between different environments and robotic platforms. Data efficient optimization algorithms (e.g., Bayesian optimization) have been increasingly employed to automate the tuning of configurable parameters in cyber-physical systems. However, such optimization algorithms converge at later stages, often after exhausting the allocated budget (e.g., optimization steps, allotted time) and lacking transferability. This article proposes causal understanding and remediation for enhancing robot performance (CURE)—a method that identifies causally relevant configuration options, enabling the optimization process to operate in a reduced search space, thereby enabling faster optimization of robot performance. CURE abstracts the causal relationships between various configuration options and the robot performance objectives by learning a causal model in the source (a low-cost environment such as the Gazebo simulator) and applying the learned knowledge to perform optimization in the target (e.g., Turtlebot 3 physical robot). We demonstrate the effectiveness and transferability of CURE by conducting experiments that involve varying degrees of deployment changes in both physical robots and simulation.},
  archive      = {J_TROB},
  author       = {Md Abir Hossen and Sonam Kharade and Jason M. O'Kane and Bradley Schmerl and David Garlan and Pooyan Jamshidi},
  doi          = {10.1109/TRO.2025.3548546},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2825-2842},
  shortjournal = {IEEE Trans. Robot.},
  title        = {CURE: Simulation-augmented autotuning in robotics},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NeuPAN: Direct point robot navigation with end-to-end model-based learning. <em>TROB</em>, <em>41</em>, 2804-2824. (<a href='https://doi.org/10.1109/TRO.2025.3554252'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Navigating a nonholonomic robot in a cluttered, unknown environment requires accurate perception and precise motion control for real-time collision avoidance. This article presents neural proximal alternating-minimization network (NeuPAN): a real-time, highly accurate, map-free, easy-to-deploy, and environment-invariant robot motion planner. Leveraging a tightly coupled perception-to-control framework, NeuPAN has two key innovations compared to existing approaches: first, it directly maps raw point cloud data to a latent distance feature space for collision-free motion generation, avoiding error propagation from the perception to control pipeline; second, it is interpretable from an end-to-end model-based learning perspective. The crux of NeuPAN is solving an end-to-end mathematical model with numerous point-level constraints using a plug-and-play proximal alternating-minimization network, incorporating neurons in the loop. This allows NeuPAN to generate real-time, physically interpretable motions. It seamlessly integrates data and knowledge engines, and its network parameters can be fine-tuned via backpropagation. We evaluate NeuPAN on a ground mobile robot, a wheel-legged robot, and an autonomous vehicle, in extensive simulated and real-world environments. Results demonstrate that NeuPAN outperforms existing baselines in terms of accuracy, efficiency, robustness, and generalization capabilities across various environments, including the cluttered sandbox, office, corridor, and parking lot. We show that NeuPAN works well in unknown and unstructured environments with arbitrarily shaped objects, transforming impassable paths into passable ones.},
  archive      = {J_TROB},
  author       = {Ruihua Han and Shuai Wang and Shuaijun Wang and Zeqing Zhang and Jianjun Chen and Shijie Lin and Chengyang Li and Chengzhong Xu and Yonina C. Eldar and Qi Hao and Jia Pan},
  doi          = {10.1109/TRO.2025.3554252},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2804-2824},
  shortjournal = {IEEE Trans. Robot.},
  title        = {NeuPAN: Direct point robot navigation with end-to-end model-based learning},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AQUA-SLAM: Tightly coupled underwater acoustic-visual-inertial SLAM with sensor calibration. <em>TROB</em>, <em>41</em>, 2785-2803. (<a href='https://doi.org/10.1109/TRO.2025.3554396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater environments pose significant challenges for visual simultaneous localization and mapping (SLAM) systems due to limited visibility, inadequate illumination, and sporadic loss of structural features in images. Addressing these challenges, this article introduces a novel, tightly coupled acoustic-visual-inertial SLAM approach, termed AQUA-SLAM, to fuse a Doppler velocity log (DVL), a stereo camera, and an inertial measurement unit (IMU) within a graph optimization framework. Moreover, we propose an efficient sensor calibration technique, encompassing the multisensor extrinsic calibration (among the DVL, camera, and IMU) and the DVL transducer misalignment calibration, with a fast linear approximation procedure for real-time online execution. The proposed methods are extensively evaluated in a tank environment with ground truth, and validated for offshore applications in the North Sea. The results demonstrate that our method surpasses current state-of-the-art underwater and visual-inertial SLAM systems in terms of localization accuracy and robustness. The proposed system will be made open-source for the community.},
  archive      = {J_TROB},
  author       = {Shida Xu and Kaicheng Zhang and Sen Wang},
  doi          = {10.1109/TRO.2025.3554396},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2785-2803},
  shortjournal = {IEEE Trans. Robot.},
  title        = {AQUA-SLAM: Tightly coupled underwater acoustic-visual-inertial SLAM with sensor calibration},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Splat-nav: Safe real-time robot navigation in gaussian splatting maps. <em>TROB</em>, <em>41</em>, 2765-2784. (<a href='https://doi.org/10.1109/TRO.2025.3552348'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present Splat-Nav, a real-time robot navigation pipeline for Gaussian splatting (GSplat) scenes, a powerful new 3-D scene representation. Splat-Nav consists of two components: first, Splat-Plan, a safe planning module, and second, Splat-Loc, a robust vision-based pose estimation module. Splat-Plan builds a safe-by-construction polytope corridor through the map based on mathematically rigorous collision constraints and then constructs a Bézier curve trajectory through this corridor. Splat-Loc provides real-time recursive state estimates given only an RGB feed from an on-board camera, leveraging the point-cloud representation inherent in GSplat scenes. Working together, these modules give robots the ability to recursively replan smooth and safe trajectories to goal locations. Goals can be specified with position coordinates, or with language commands by using a semantic GSplat. We demonstrate improved safety compared to point cloud-based methods in extensive simulation experiments. In a total of 126 hardware flights, we demonstrate equivalent safety and speed compared to motion capture and visual odometry, but without a manual frame alignment required by those methods. We show online replanning at more than 2 Hz and pose estimation at about 25 Hz, an order of magnitude faster than neural radiance field-based navigation methods, thereby enabling real-time navigation.},
  archive      = {J_TROB},
  author       = {Timothy Chen and Ola Shorinwa and Joseph Bruno and Aiden Swann and Javier Yu and Weijia Zeng and Keiko Nagami and Philip Dames and Mac Schwager},
  doi          = {10.1109/TRO.2025.3552348},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2765-2784},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Splat-nav: Safe real-time robot navigation in gaussian splatting maps},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strategic decision-making in multiagent domains: A weighted constrained potential dynamic game approach. <em>TROB</em>, <em>41</em>, 2749-2764. (<a href='https://doi.org/10.1109/TRO.2025.3552325'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In interactive multiagent settings, decision-making and planning are challenging mainly due to the agents' interconnected objectives. Dynamic game theory offers a formal framework for analyzing such intricacies. Yet, solving constrained dynamic games and determining the interaction outcome in the form of generalized Nash equilibria (GNE) pose computational challenges due to the need for solving constrained coupled optimal control problems. In this article, we address this challenge by proposing to leverage the special structure of many real-world multiagent interactions. More specifically, our key idea is to leverage constrained dynamic potential games, which are games for which GNE can be found by solving a single constrained optimal control problem associated with minimizing the potential function. We argue that constrained dynamic potential games can effectively facilitate interactive decision-making in many multiagent interactions. We will identify structures in realistic multiagent interactive scenarios that can be transformed into weighted constrained potential dynamic games (WCPDGs). We will show that the GNE of the resulting WCPDG can be obtained by solving a single constrained optimal control problem. We will demonstrate the effectiveness of the proposed method through various simulation studies and show that we achieve significant improvements in solve time compared to state-of-the-art game solvers. We further provide experimental validation of our proposed method in a navigation setup involving two quadrotors carrying a rigid object while avoiding collisions with two humans.},
  archive      = {J_TROB},
  author       = {Maulik Bhatt and Yixuan Jia and Negar Mehr},
  doi          = {10.1109/TRO.2025.3552325},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2749-2764},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Strategic decision-making in multiagent domains: A weighted constrained potential dynamic game approach},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CODEI: Resource-efficient task-driven codesign of perception and decision making for mobile robots applied to autonomous vehicles. <em>TROB</em>, <em>41</em>, 2727-2748. (<a href='https://doi.org/10.1109/TRO.2025.3552347'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article discusses the integration challenges and strategies for designing mobile robots, by focusing on the task-driven, optimal selection of hardware and software to balance safety, efficiency, and minimal usage of resources such as costs, energy, computational requirements, and weight. We emphasize the interplay between perception and motion planning in decision-making by introducing the concept of occupancy queries to quantify the perception requirements for sampling-based motion planners. Sensor and algorithm performance are evaluated using false negative rate and false positive rate across various factors such as geometric relationships, object properties, sensor resolution, and environmental conditions. By integrating perception requirements with perception performance, an integer linear programming approach is proposed for efficient sensor and algorithm selection and placement. This forms the basis for a codesign optimization that includes the robot body, motion planner, perception pipeline, and computing unit. We refer to this framework for solving the codesign problem of mobile robots as CODEI, short for codesign of embodied intelligence. A case study on developing an autonomous vehicle for urban scenarios provides actionable information for designers, and shows that complex tasks escalate resource demands, with task performance affecting choices of the autonomy stack. The study demonstrates that resource prioritization influences sensor choice: cameras are preferred for cost-effective and lightweight designs, while lidar sensors are chosen for better energy and computational efficiency.},
  archive      = {J_TROB},
  author       = {Dejan Milojevic and Gioele Zardini and Miriam Elser and Andrea Censi and Emilio Frazzoli},
  doi          = {10.1109/TRO.2025.3552347},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2727-2748},
  shortjournal = {IEEE Trans. Robot.},
  title        = {CODEI: Resource-efficient task-driven codesign of perception and decision making for mobile robots applied to autonomous vehicles},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ILoc: An adaptive, efficient, and robust visual localization system. <em>TROB</em>, <em>41</em>, 2709-2726. (<a href='https://doi.org/10.1109/TRO.2025.3530273'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we introduce iLoc, an innovative visual localization system designed to enhance the autonomy and adaptability of robotic agents in long-term and large-scale applications. iLoc specializes in: 1) extracting stable and consistent descriptors for place recognition, unaffected by changes in viewpoint and illumination; 2) performing swift and precise global relocalization to establish a robot's position within a large and complex environment; and 3) generating real-time tracking trajectories aligned with reference maps, ensuring continual orientation within known spaces. Distinctively, iLoc incorporates a transformer-based learning module and an attention-enhanced recognition approach, enabling it to adapt to diverse environmental and viewpoint conditions. iLoc leverages a coarse-to-fine global feature matching technique for enhanced localization and integrates robust state estimation combining visual odometry and loop closures through local refinement and pose graph optimization. iLoc demonstrates remarkable proficiency in place recognition, achieving localization over distances of up to 2 km within 0.5 s with average accuracy at 1 m. It maintains stable localization accuracy, even under variable conditions. Its versatile design allows integration across various environments, significantly broadening the scope of universal localization capabilities in robotics. iLoc represents a substantial step forward in visual-based localization systems, delivering unparalleled speed and accuracy in place recognition. Its ability to adapt and respond to diverse environmental stimuli marks it as a crucial tool in advancing the field of robotic localization.},
  archive      = {J_TROB},
  author       = {Peng Yin and Shiqi Zhao and Jing Wang and Ruohai Ge and Jianmin Ji and Yeping Hu and Huaping Liu and Jianda Han},
  doi          = {10.1109/TRO.2025.3530273},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2709-2726},
  shortjournal = {IEEE Trans. Robot.},
  title        = {ILoc: An adaptive, efficient, and robust visual localization system},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerated Reeds–Shepp and underspecified Reeds–Shepp algorithms for mobile robot path planning. <em>TROB</em>, <em>41</em>, 2691-2708. (<a href='https://doi.org/10.1109/TRO.2025.3554406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we present a simple and intuitive method for accelerating optimal Reeds–Shepp path computation. Our approach uses geometrical reasoning to analyze the behavior of optimal paths, resulting in a new partitioning of the state space and a further reduction in the minimal set of viable paths. We revisit and reimplement classic methodologies from literature, which lack contemporary open-source implementations, to serve as benchmarks for evaluating our method. In addition, we address the underspecified Reeds–Shepp planning problem where the final orientation is unspecified. We perform exhaustive experiments to validate our solutions. Compared to the modern C++ implementation of the original Reeds–Shepp solution in the Open Motion Planning Library, our method demonstrates a $15\times$ speedup, while classic methods achieve a $5.79\times$ speedup. Both approaches exhibit machine-precision differences in path lengths compared to the original solution. We release our proposed C++ implementations for both the accelerated and underspecified Reeds–Shepp problems as open-source code.},
  archive      = {J_TROB},
  author       = {Ibrahim Ibrahim and Wilm Decré and Jan Swevers},
  doi          = {10.1109/TRO.2025.3554406},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2691-2708},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Accelerated Reeds–Shepp and underspecified Reeds–Shepp algorithms for mobile robot path planning},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simultaneous trajectory optimization and contact selection for contact-rich manipulation with high-fidelity geometry. <em>TROB</em>, <em>41</em>, 2677-2690. (<a href='https://doi.org/10.1109/TRO.2025.3554380'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contact-implicit trajectory optimization (CITO) is an effective method to plan complex trajectories for various contact-rich systems including manipulation and locomotion. CITO formulates a mathematical program with complementarity constraints (MPCC) that enforces that contact forces must be zero when points are not in contact. However, MPCC solve times increase steeply with the number of allowable points of contact, which limits CITO's applicability to problems in which only a few, simple geometries are allowed us to make contact. This article introduces simultaneous trajectory optimization and contact selection (STOCS), as an extension of CITO that overcomes this limitation. The innovation of STOCS is to identify salient contact points and times inside the iterative trajectory optimization process. This effectively reduces the number of variables and constraints in each MPCC invocation. The STOCS framework, instantiated with key contact identification subroutines, renders the optimization of manipulation trajectories computationally tractable even for high-fidelity geometries consisting of tens of thousands of vertices.},
  archive      = {J_TROB},
  author       = {Mengchao Zhang and Devesh K. Jha and Arvind U. Raghunathan and Kris Hauser},
  doi          = {10.1109/TRO.2025.3554380},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2677-2690},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Simultaneous trajectory optimization and contact selection for contact-rich manipulation with high-fidelity geometry},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic control of multimodal motion for bistable soft millirobots in complex environments. <em>TROB</em>, <em>41</em>, 2662-2676. (<a href='https://doi.org/10.1109/TRO.2025.3551541'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft millirobots are highly promising for biomedical applications due to their reconfigurability and multifunctionality within physiological environments. However, the diverse and narrow biological cavity environments pose significant adaptability challenges for these millirobots. Here, we present a dual-morphology, thin-film millirobot equipped with a magnetic drive head and a functional tail to facilitate multimodal motion and targeted cell delivery. The millirobot can reversibly switch between two distinct morphologies in response to environmental stimuli through the deformation of its hydrogel body. Utilizing these dual morphologies, the millirobot can perform robust multimodal fundamental motions controlled by magnetic fields. We encapsulate fundamental motions with specific programmable magnetic field parameters into motion primitives, allowing easy invocation and adjustment of motion modes on demand. A knowledge graph is established to map terrain features to motion units, enabling the identification of optimal motion modes based on typical terrain characteristics. Experimental results indicate that the millirobot can effectively switch its morphology and movement modes to navigate various terrains, including narrow and curved channels as small as 1 mm, 0.8 mm high stairs with a 15° incline, and even the complex environment of a swine intestinal lumen. Its functional tail can carry immune cells to target and kill cancer cells. This robot can transport drugs and cells while navigating complex terrains through multimodal motion, paving the way for targeted medical tasks in intricate human environments in the future.},
  archive      = {J_TROB},
  author       = {Zhengyuan Xin and Shihao Zhong and Anping Wu and Zhiqiang Zheng and Qing Shi and Qiang Huang and Toshio Fukuda and Huaping Wang},
  doi          = {10.1109/TRO.2025.3551541},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2662-2676},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Dynamic control of multimodal motion for bistable soft millirobots in complex environments},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TacSL: A library for visuotactile sensor simulation and learning. <em>TROB</em>, <em>41</em>, 2645-2661. (<a href='https://doi.org/10.1109/TRO.2025.3547267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For both humans and robots, the sense of touch, known as tactile sensing, is critical for performing contact-rich manipulation tasks. Three key challenges in robotic tactile sensing are interpreting sensor signals, generating sensor signals in novel scenarios, and learning sensor-based policies. For visuotactile sensors, interpretation has been facilitated by their close relationship with vision sensors (e.g., RGB cameras). However, generation is still difficult, as visuotactile sensors typically involve contact, deformation, illumination, and imaging, all of which are expensive to simulate; in turn, policy learning has been challenging, as simulation cannot be leveraged for large-scale data collection. We present TacSL (taxel), a library for GPU-based visuotactile sensor simulation and learning. TacSL can be used to simulate visuotactile images and extract contact-force distributions over $200\times$ faster than the prior state-of-the-art, all within the widely used Isaac simulator. Furthermore, TacSL provides a learning toolkit containing multiple sensor models, contact-intensive training environments, and online/offline algorithms that can facilitate policy learning for sim-to-real applications. On the algorithmic side, we introduce a novel online reinforcement-learning algorithm called asymmetric actor-critic distillation, designed to effectively and efficiently learn tactile-based policies in simulation that can transfer to the real world. Finally, we demonstrate the utility of our library and algorithms by evaluating the benefits of distillation and multimodal sensing for contact-rich manipulation tasks, and most critically, performing sim-to-real transfer.},
  archive      = {J_TROB},
  author       = {Iretiayo Akinola and Jie Xu and Jan Carius and Dieter Fox and Yashraj Narang},
  doi          = {10.1109/TRO.2025.3547267},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2645-2661},
  shortjournal = {IEEE Trans. Robot.},
  title        = {TacSL: A library for visuotactile sensor simulation and learning},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wrench control of dual-arm robot on flexible base with supporting contact surface. <em>TROB</em>, <em>41</em>, 2625-2644. (<a href='https://doi.org/10.1109/TRO.2025.3554411'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel high-force/high-precision interaction control framework of a dual-arm robot system on a flexible base, with one arm holding, or making contact with, a supporting surface, while the other arm can exert any arbitrary wrench in a certain polytope through a desired pose against environments or objects. Our proposed framework can achieve high-force/precision tasks by utilizing the supporting surface just as we humans do while taking into account various important constraints (e.g., system stability, joint angle/torque limits, friction-cone constraint, etc.) and the passive compliance of the flexible base. We first design the control as a combination of: 1) nominal control; 2) active stiffness control; and 3) feedback wrench control. We then sequentially perform optimizations of the nominal configuration (and its related wrenches) and the active stiffness control gain. We also design the proportional–integral type feedback wrench control to improve the robustness and precision of the control. The key theoretical enabler for our framework is a novel stiffness analysis of the dual-arm system with flexibility, which, when combined with certain constraints, provides some peculiar relations, that can effectively be used to significantly simplify the optimization problem-solving and to facilitate the feedback wrench control design by manifesting the compliance relation at the interaction port. The efficacy of the theory is then validated and demonstrated through simulations and experiments.},
  archive      = {J_TROB},
  author       = {Jeongseob Lee and Doyoon Kong and Hojun Cha and Jeongmin Lee and Dongseok Ryu and Hocheol Shin and Dongjun Lee},
  doi          = {10.1109/TRO.2025.3554411},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2625-2644},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Wrench control of dual-arm robot on flexible base with supporting contact surface},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ProxDDP: Proximal constrained trajectory optimization. <em>TROB</em>, <em>41</em>, 2605-2624. (<a href='https://doi.org/10.1109/TRO.2025.3554437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory optimization has been a popular choice for motion generation and control in robotics for at least a decade. Several numerical approaches have exhibited the required speed to enable online computation of trajectories for real-time of various systems, including complex robots. Many of these said are based on the differential dynamic programming (DDP) algorithm—initially designed for unconstrained trajectory optimization problems—and its variants, which are relatively easy to implement and provide good runtime performance. However, several problems in robot control call for using constrained formulations (e.g., torque limits, obstacle avoidance), from which several difficulties arise when trying to adapt DDP-type methods: numerical stability, computational efficiency, and constraint satisfaction. In this article, we leverage proximal methods for constrained optimization and introduce a DDP-type method for fast, constrained trajectory optimization suited for model-predictive control (MPC) applications with easy warm-starting. Compared to earlier solvers, our approach effectively manages hard constraints without warm-start limitations and exhibits good convergence behavior. We provide a complete implementation as part of an open-source and flexible C++ trajectory optimization library called aligator. These algorithmic contributions are validated through several trajectory planning scenarios from the robotics literature and the real-time whole-body MPC of a quadruped robot.},
  archive      = {J_TROB},
  author       = {Wilson Jallet and Antoine Bambade and Etienne Arlaud and Sarah El-Kazdadi and Nicolas Mansard and Justin Carpentier},
  doi          = {10.1109/TRO.2025.3554437},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2605-2624},
  shortjournal = {IEEE Trans. Robot.},
  title        = {ProxDDP: Proximal constrained trajectory optimization},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linearized virtual energy tank for passivity-based bilateral teleoperation using linear MPC. <em>TROB</em>, <em>41</em>, 2589-2604. (<a href='https://doi.org/10.1109/TRO.2025.3554447'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bilateral teleoperation systems are often used in safety–critical scenarios where human operators may interact with the environment remotely, as in robotic-assisted surgery or nuclear plant maintenance. Teleoperation's stability and transparency are the two most important properties to be satisfied, but they cannot be optimized independently since they are in contrast. This article presents a passive linear MPC control scheme to implement bilateral teleoperation that optimizes the tradeoff between stability and transparency (a.k.a. performance). First, we introduce a linear virtual energy tank with a novel energy-sharing policy, allowing us to define a passive linear model predictive control (MPC). Second, we provide conditions to guarantee the stability of the nonlinear closed-loop system. We validate the proposed approach in a teleoperation scheme using two 7-degree of freedom manipulators while performing an assembly task. This novel passivity-based bilateral teleoperation using linear MPC and linearized energy tank reduces the computational effort of existing passive nonlinear MPC controllers.},
  archive      = {J_TROB},
  author       = {Nicola Piccinelli and Riccardo Muradore},
  doi          = {10.1109/TRO.2025.3554447},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2589-2604},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Linearized virtual energy tank for passivity-based bilateral teleoperation using linear MPC},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SLIM: Scalable and lightweight LiDAR mapping in urban environments. <em>TROB</em>, <em>41</em>, 2569-2588. (<a href='https://doi.org/10.1109/TRO.2025.3554400'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Light detection and ranging (LiDAR) point cloud maps are extensively utilized on roads for robot navigation due to their high consistency. However, dense point clouds face challenges of high memory consumption and reduced maintainability for long-term operations. In this study, we introduce scalable and lightweight LiDAR mapping (SLIM), a scalable and lightweight mapping system for long-term LiDAR mapping in urban environments. The system begins by parameterizing structural point clouds into lines and planes. These lightweight and structural representations meet the requirements of map merging, pose graph optimization, and bundle adjustment, ensuring incremental management and local consistency. For long-term operations, a map-centric nonlinear factor recovery method is designed to sparsify poses while preserving mapping accuracy. We validate the SLIM system with multisession real-world LiDAR data from classical LiDAR mapping datasets, including KITTI, NCLT, HeLiPR, and M2DGR. The experiments demonstrate its capabilities in mapping accuracy, lightweightness, and scalability. Map reuse is also verified through map-based robot localization. Finally, with multisession LiDAR data, the SLIM system provides a globally consistent map with low memory consumption ($\sim$ 130 KB/km on KITTI).},
  archive      = {J_TROB},
  author       = {Zehuan Yu and Zhijian Qiao and Wenyi Liu and Huan Yin and Shaojie Shen},
  doi          = {10.1109/TRO.2025.3554400},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2569-2588},
  shortjournal = {IEEE Trans. Robot.},
  title        = {SLIM: Scalable and lightweight LiDAR mapping in urban environments},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human-inspired active compliant and passive shared control framework for robotic contact-rich tasks in medical applications. <em>TROB</em>, <em>41</em>, 2549-2568. (<a href='https://doi.org/10.1109/TRO.2025.3548493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a compliant and passive shared control framework for teleoperated robot-assisted tasks. Inspired by the human operator's capability of continuously regulating the arm impedance to perform contact-rich tasks, a novel control schema, exploiting the variable impedance control framework for force tracking is proposed. Moreover, bilateral teleoperation and shared control strategies are implemented to alleviate the human operator's workload. Furthermore, a global energy tank-based approach is integrated to enforce the system's passivity. The proposed framework is first evaluated to assess the force-tracking capability when the robot autonomously performs contact-rich tasks, e.g., in an ultrasound scanning scenario. Then, a validation experiment is conducted utilizing the proposed shared control framework. Finally, the system's usability is investigated with 12 users. The experiment results in system assessment revealed a maximum median error of 0.25 N across all the force-tracking experiment setups, i.e., constant and time-varying ones. Then, the validation experiment demonstrated significant improvements regarding the force tracking tasks compared to conventional control methods, and the system passivity was preserved during the task execution. Finally, the usability experiment shows that the human operator workload is significantly reduced by $54.6 \%$ compared to the other two control modalities. The proposed framework holds significant potential for the execution of remote robot-assisted medical procedures, such as palpation and ultrasound scanning, particularly in addressing deformation challenges while ensuring safety, compliance, and system passivity.},
  archive      = {J_TROB},
  author       = {Junling Fu and Giorgia Maimone and Elisa Iovene and Jianzhuang Zhao and Alberto Redaelli and Giancarlo Ferrigno and Elena De Momi},
  doi          = {10.1109/TRO.2025.3548493},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2549-2568},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Human-inspired active compliant and passive shared control framework for robotic contact-rich tasks in medical applications},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simulation-aided policy tuning for black-box robot learning. <em>TROB</em>, <em>41</em>, 2533-2548. (<a href='https://doi.org/10.1109/TRO.2025.3539192'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How can robots learn and adapt to new tasks and situations with little data? Systematic exploration and simulation are crucial tools for efficient robot learning. We present a novel black-box policy search algorithm focused on data-efficient policy improvements. The algorithm learns directly on the robot and treats simulation as an additional information source to speed up the learning process. At the core of the algorithm, a probabilistic model learns the dependence between the policy parameters and the robot learning objective not only by performing experiments on the robot, but also by leveraging data from a simulator. This substantially reduces interaction time with the robot. Using the model, we can guarantee improvements with high probability for each policy update, thereby facilitating fast, goal-oriented learning. We evaluate our algorithm on simulated fine-tuning tasks and demonstrate the data-efficiency of the proposed dual-information source optimization algorithm. In a real robot learning experiment, we show fast and successful task learning on a robot manipulator with the aid of an imperfect simulator.},
  archive      = {J_TROB},
  author       = {Shiming He and Alexander von Rohr and Dominik Baumann and Ji Xiang and Sebastian Trimpe},
  doi          = {10.1109/TRO.2025.3539192},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2533-2548},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Simulation-aided policy tuning for black-box robot learning},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic path planning for wheel-legged rover in dense environment based on extended MDP and configuration topology analysis. <em>TROB</em>, <em>41</em>, 2512-2532. (<a href='https://doi.org/10.1109/TRO.2025.3546789'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wheel-legged planetary rovers possess superb locomotion capabilities. This article combines an offline predefined motion planning library with online path planning, integrating energy consumption and probabilistic aspects of the robotic system. The primary focus is on addressing the planning challenges in dense environments, where the distance between any adjacent obstacles is smaller than the width of the prototype. Therefore, it is necessary to consider the interaction between the prototype and the environment. First, the generalized function set theory and the configuration topology theory are utilized to mathematically describe the motions of multilimbed systems. Based on the representation, an offline planning library is established. Second, the Markov-decision-process-based path planning method is extended by incorporating the platform's geometry and locomotion capabilities. The concept of “limb-travel relevant nodes” is introduced. To address the numerous iteration problems, the informed value iteration algorithm is proposed. Third, a multilayered map is evaluated to further enhance computational efficiency. Finally, the proposed algorithm is implemented on the terrain adaptive wheel-legged rover. Experimental results demonstrate that the proposed algorithm is capable of finding the optimal path with high computational efficiency, and it exhibits excellent adaptability on nonuniform maps.},
  archive      = {J_TROB},
  author       = {Bike Zhu and Jun He and Zhicheng Yuan and Feng Gao},
  doi          = {10.1109/TRO.2025.3546789},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2512-2532},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Probabilistic path planning for wheel-legged rover in dense environment based on extended MDP and configuration topology analysis},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AVOCADO: Adaptive optimal collision avoidance driven by opinion. <em>TROB</em>, <em>41</em>, 2495-2511. (<a href='https://doi.org/10.1109/TRO.2025.3552350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present AdaptiVe Optimal Collision Avoidance Driven by Opinion (AVOCADO), a novel navigation approach to address holonomic robot collision avoidance when the robot does not know how cooperative the other agents in the environment are. AVOCADO departs from a velocity obstacle's (VO) formulation akin to the optimal reciprocal collision avoidance method. However, instead of assuming reciprocity, it poses an adaptive control problem to adapt to the cooperation level of other robots and agents in real time. This is achieved through a novel nonlinear opinion dynamics design that relies solely on sensor observations. As a by-product, we leverage tools from the opinion dynamics formulation to naturally avoid the deadlocks in geometrically symmetric scenarios that typically suffer VO-based planners. Extensive numerical simulations show that AVOCADO surpasses existing motion planners in mixed cooperative/noncooperative navigation environments in terms of success rate, time to goal and computational time. In addition, we conduct multiple real experiments that verify that AVOCADO is able to avoid collisions in environments crowded with other robots and humans.},
  archive      = {J_TROB},
  author       = {Diego Martinez-Baselga and Eduardo Sebastián and Eduardo Montijano and Luis Riazuelo and Carlos Sagüés and Luis Montano},
  doi          = {10.1109/TRO.2025.3552350},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2495-2511},
  shortjournal = {IEEE Trans. Robot.},
  title        = {AVOCADO: Adaptive optimal collision avoidance driven by opinion},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High resolution, large area vision-based tactile sensing based on a novel piezoluminescent skin. <em>TROB</em>, <em>41</em>, 2477-2494. (<a href='https://doi.org/10.1109/TRO.2025.3552327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to precisely perceive external physical interactions would enable robots to interact effectively with the environment and humans. While vision-based tactile sensing has improved robotic grippers, it is challenging to realize high resolution vision-based tactile sensing in robot arms due to presence of curved surfaces, difficulty in uniform illumination, and large distance of sensing area from the cameras. In this article, we propose a novel piezoluminescent skin that transduces external applied pressures into changes in light intensity on the other side for viewing by a camera for pressure estimation. By engineering elastomer layers with specific optical properties and integrating a flexible electroluminescent panel as a light source, we develop a compact tactile sensing layer that resolves the layout issues in curved surfaces. We achieved multipoint pressure estimation over an expansive area of 502 cm2 with high spatial resolution, a two-point discrimination distance of 3 mm horizontally and 5 mm vertically which is comparable to that of human fingers as well as a high localization accuracy (RMSE of 1.92 mm). These promising attributes make this tactile sensing technique suitable for use in robot arms and other applications requiring high resolution tactile information over a large area.},
  archive      = {J_TROB},
  author       = {Ruxiang Jiang and Lanhui Fu and Yanan Li and Hareesh Godaba},
  doi          = {10.1109/TRO.2025.3552327},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2477-2494},
  shortjournal = {IEEE Trans. Robot.},
  title        = {High resolution, large area vision-based tactile sensing based on a novel piezoluminescent skin},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A wearable isokinetic training robot for enhanced bedside knee rehabilitation. <em>TROB</em>, <em>41</em>, 2460-2476. (<a href='https://doi.org/10.1109/TRO.2025.3552332'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knee pain is prevalent in over 20% of the population, limiting the mobility of those affected. In turn, isokinetic dynamometers and robots have been used to facilitate rehabilitation for those still capable of ambulation. However, there are at most only a few wearable robots capable of delivering isokinetic training for bedridden patients. Here, we developed a wearable robot that provides bedside isokinetic training by utilizing a variable stiffness actuator and dynamic energy regeneration. The efficacy of this device was validated in a study involving six subjects with debilitating knee injuries. During two courses of rehabilitation over a total of three weeks, the average peak torque, average torque, and average work produced by their affected knees increased significantly by 81.0%, 101.4%, and 117.6%, respectively. Furthermore, the device's energy regeneration features were found capable of extending its operating time to 198 days under normal usage, representing a 57.8% increase over the same device without regeneration. These results suggest potential methodologies for delivering isokinetic joint rehabilitation to bedridden patients in areas with limited infrastructure.},
  archive      = {J_TROB},
  author       = {Yanggang Feng and Xingyu Hu and Yuebing Li and Ke Ma and Jiaxin Ren and Zhihao Zhou and Fuzhen Yuan and Yan Huang and Liu Wang and Qining Wang and Wuxiang Zhang and Xilun Ding},
  doi          = {10.1109/TRO.2025.3552332},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2460-2476},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A wearable isokinetic training robot for enhanced bedside knee rehabilitation},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling, embedded control, and design of soft robots using a learned condensed FEM model. <em>TROB</em>, <em>41</em>, 2441-2459. (<a href='https://doi.org/10.1109/TRO.2025.3552353'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The finite element method (FEM) is a powerful modeling tool for predicting soft robots' behavior, but its computation time can limit practical applications. In this article, a learning-based approach based on condensation of the FEM model is detailed. The proposed method handles several kinds of actuators and contacts with the environment. We demonstrate that this compact model can be learned as a unified model across several designs and remains very efficient in terms of modeling since we can deduce the direct and inverse kinematics of the robot. Building upon the intuition introduced in (Ménager et al., 2023), the learned model is presented as a general framework for modeling, controlling, and designing soft manipulators. First, the method's adaptability and versatility are illustrated through optimization-based control problems involving positioning and manipulation tasks with mechanical contact-based coupling. Second, the low-memory consumption and the high prediction speed of the learned condensed model are leveraged for real-time embedding control without relying on costly online FEM simulation. Finally, the ability of the learned condensed FEM model to capture soft robot design variations and its differentiability are leveraged in calibration and design optimization applications.},
  archive      = {J_TROB},
  author       = {Tanguy Navez and Etienne Ménager and Paul Chaillou and Olivier Goury and Alexandre Kruszewski and Christian Duriez},
  doi          = {10.1109/TRO.2025.3552353},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2441-2459},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Modeling, embedded control, and design of soft robots using a learned condensed FEM model},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Safe start regions for medical steerable needle automation. <em>TROB</em>, <em>41</em>, 2424-2440. (<a href='https://doi.org/10.1109/TRO.2025.3552323'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Steerable needles are minimally invasive devices that can enable novel medical procedures by following curved paths to avoid critical anatomical obstacles. We introduce a new start pose robustness metric for steerable needle motion plans. A steerable needle deployment typically consists of a physician manually placing a steerable needle at a precomputed start pose on the surface of tissue and handing off control to a robot, which then autonomously steers the needle through the tissue to the target. The handoff between humans and robots is critical for procedure success, as even small deviations from a planned start pose change the steerable needle's reachable workspace. Our metric is based on a novel geometric method to efficiently compute how far the physician can deviate from the planned start pose in both position and orientation such that the steerable needle can still reach the target. We evaluate our metric through simulation in liver and lung scenarios. Our evaluation shows that our metric can be applied to plans computed by different steerable needle motion planners and that it can be used to efficiently select plans with large safe start regions.},
  archive      = {J_TROB},
  author       = {Janine Hoelscher and Inbar Fried and Spiros Tsalikis and Jason Akulian and Robert J. Webster and Ron Alterovitz},
  doi          = {10.1109/TRO.2025.3552323},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2424-2440},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Safe start regions for medical steerable needle automation},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inspection planning under execution uncertainty. <em>TROB</em>, <em>41</em>, 2406-2423. (<a href='https://doi.org/10.1109/TRO.2025.3548528'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous inspection tasks require path-planning algorithms to efficiently gather observations from points of interest (POIs). However, localization errors in urban environments introduce execution uncertainty, posing challenges to successfully completing such tasks. The existing inspection-planning algorithms do not explicitly address this uncertainty, which can hinder their performance. To overcome this, in this article, we introduce incremental random inspection-roadmap search (IRIS)-under uncertainty (IRIS-U$^{2}$), an inspection-planning algorithm that provides statistical assurances regarding coverage, path length, and collision probability. Our approach builds upon IRIS—our framework for deterministic, highly efficient, and provably asymptotically optimal framework. This extension adapts IRIS to uncertain settings using a refined search procedure that estimates POI coverage probabilities through Monte Carlo (MC) sampling. We demonstrate IRIS-U$^{2}$ through a case study on bridge inspections, achieving improved expected coverage, reduced collision probability, and increasingly precise statistical guarantees as MC samples grow. In addition, we explore bounded suboptimal solutions to reduce computation time while preserving statistical assurances.},
  archive      = {J_TROB},
  author       = {Shmuel David Alpert and Kiril Solovey and Itzik Klein and Oren Salzman},
  doi          = {10.1109/TRO.2025.3548528},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2406-2423},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Inspection planning under execution uncertainty},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active iterative optimization for aerial visual reconstruction of wide-area natural environment. <em>TROB</em>, <em>41</em>, 2374-2390. (<a href='https://doi.org/10.1109/TRO.2024.3475213'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous, accurate, and dynamic 3-D reconstruction for wide-area environments is crucial for unmanned aerial vehicle monitoring and rescue tasks, however, when conducted in an unknown complex terrain, the reconstruction result obtained from a single flight suffers poor quality. In this article, we present an Active Iterative Optimization framework for trajectory planning and visual reconstruction. Firstly, the trajectory is planned under the photogrammetric constraints based on rough terrain. Due to the visual field deviation caused by pose error during actual flight, the view loss evaluation is established and keyframes are selected to conduct 3-D reconstruction. A comprehensive metric is designed to quantitatively evaluate reconstruction effect without ground truth. The point cloud is then rasterized and divided into normal or low-scoring region according to the evaluation metric. In the next iteration, trajectory is replanned in low-scoring region to purposefully optimize the point cloud of local area. Thus the reconstruction result can be iteratively optimized. We validated the effectiveness of the proposed framework in simulation and physical experiments.},
  archive      = {J_TROB},
  author       = {Hongpeng Wang and Zhongzhi Cao and Yue Fei and Peizhao Wang and Yaojing Li and Chuanyu Sun and Ming He and Jianda Han},
  doi          = {10.1109/TRO.2024.3475213},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2374-2390},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Active iterative optimization for aerial visual reconstruction of wide-area natural environment},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IDb-a*: Iterative search and optimization for optimal kinodynamic motion planning. <em>TROB</em>, <em>41</em>, 2031-2049. (<a href='https://doi.org/10.1109/TRO.2024.3502505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion planning for robotic systems with complex dynamics is a challenging problem. While recent sampling-based algorithms achieve asymptotic optimality by propagating random control inputs, their empirical convergence rate is often poor, especially in high-dimensional systems such as multirotors. An alternative approach is to first plan with a simplified geometric model and then use trajectory optimization to follow the reference path while accounting for the true dynamics. However, this approach may fail to produce a valid trajectory if the initial guess is not close to a dynamically feasible trajectory. In this article, we present Iterative Discontinuity Bounded A* (iDb-A*), a novel kinodynamic motion planner that combines search and optimization iteratively. The search step utilizes a finite set of short trajectories (motion primitives) that are interconnected while allowing for a bounded discontinuity between them. The optimization step locally repairs the discontinuities with trajectory optimization. By progressively reducing the allowed discontinuity and incorporating more motion primitives, our algorithm achieves asymptotic optimality with excellent any-time performance. We provide a benchmark of 43 problems across eight different dynamical systems, including different versions of unicycles and multirotors. Compared to state-of-the-art methods, iDb-A* consistently solves more problem instances and finds lower-cost solutions more rapidly.},
  archive      = {J_TROB},
  author       = {Joaquim Ortiz-Haro and Wolfgang Hönig and Valentin N. Hartmann and Marc Toussaint},
  doi          = {10.1109/TRO.2024.3502505},
  journal      = {IEEE Transactions on Robotics},
  pages        = {2031-2049},
  shortjournal = {IEEE Trans. Robot.},
  title        = {IDb-a*: Iterative search and optimization for optimal kinodynamic motion planning},
  volume       = {41},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
