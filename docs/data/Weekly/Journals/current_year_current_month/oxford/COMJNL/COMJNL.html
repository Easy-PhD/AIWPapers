<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>COMJNL</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="comjnl">COMJNL - 15</h2>
<ul>
<li><details>
<summary>
(2025). A dual protection technology to thwart hardware trojan insertion based on observability. <em>COMJNL</em>, <em>68</em>(8), 1074-1085. (<a href='https://doi.org/10.1093/comjnl/bxaf050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The globalization of the integrated circuit design industry makes it easier for the adversary to pirate intellectual property and insert hardware Trojans (HTs). Although many HT protection methods have been proposed, some malicious elements can still be inserted into vulnerable nodes. Trojans are usually inserted in the rare nodes with the lowest observability, which makes it hard for testers to discover them. In this paper, we propose a dual-protection technology to protect the circuit against HT attacks based on observability. First, we propose an algorithm to increase the low observabilities of the circuit, so as to make it difficult for attackers to implant HTs. Several existing approaches try to identify the low observability by setting a threshold artificially, which is not generic. We do not need to set thresholds when targeting the low observability. Second, we present another logic locking algorithm to enhance the entire circuit’s security further. Simulation results on ISCAS85 benchmark and several larger circuits show that the proposed HT protection method has increased the lowest observability of the circuit by an average of 370.76 times. Furthermore, the logic locking technique maximizes the ambiguity for an attacker. Compared with the state of the art, the proposed logic locking can obtain better results, achieving a Hamming distance that is closer to 50% between the correct and incorrect outputs when a wrong key is applied.},
  archive      = {J_COMJNL},
  author       = {Wang, Zhen and Lv, Jinfeng and Zhou, Yuhao and Jiang, Jianhui and Wang, Yong},
  doi          = {10.1093/comjnl/bxaf050},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {1074-1085},
  shortjournal = {Comput. J.},
  title        = {A dual protection technology to thwart hardware trojan insertion based on observability},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compression cryptosystem. <em>COMJNL</em>, <em>68</em>(8), 1062-1073. (<a href='https://doi.org/10.1093/comjnl/bxaf023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A compression cryptosystem is a single coding process, the output of which is both reduced in space and secure against unauthorized decoding. Considering both Huffman and arithmetic coding, this paper proposes to apply repeatedly minor changes to the compression model, with negligible deterioration of its optimality. The cumulative impact of a large number of such changes leads to completely different ciphertexts, which can be decrypted only if a given secret key is known. The security of the system is based on the NP-completeness of a problem related to breaking the code. Several variants are suggested, and their results are tested in various settings, including for security against chosen plaintext attacks.},
  archive      = {J_COMJNL},
  author       = {Gross, Yoav and Klein, Shmuel T and Opalinsky, Elina and Revivo, Rivka and Shapira, Dana},
  doi          = {10.1093/comjnl/bxaf023},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {1062-1073},
  shortjournal = {Comput. J.},
  title        = {Compression cryptosystem},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel curriculum learning framework for multi-label emotion classification. <em>COMJNL</em>, <em>68</em>(8), 1050-1061. (<a href='https://doi.org/10.1093/comjnl/bxaf022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Curriculum learning (CL) is a training strategy that imitates how humans learn, by gradually introducing more complex samples and information to the model. However, in multi-label emotion classification (MEC) tasks, using a traditional CL approach can result in overfitting on easy samples and lead to biased training. Additionally, the sample difficulty varies as the model trains. To address these challenges, we propose a novel CL framework for MEC tasks called CLF-MEC. Unlike traditional approaches that assess difficulty at the sample level, we utilize category-level assessment to determine the difficulty level of samples. As the model identifies a category well, the score for that category’s samples is reduced, ensuring dynamic changes in the sample difficulty are accounted for. Our CL framework employs two training modes, namely “learning” and “tackling.” These two processes are trained alternatively to imitate the “learning-tackling” process in human learning. This ensures that samples from hard-to-learn categories receive more attention. During the “tackling” process, our method transforms the task of dealing with hard samples into an “easy” learning task by utilizing contrastive learning to enhance the semantic representation of those hard samples. Experimental results demonstrate that our CLF-MEC framework has achieved significant improvements in MEC.},
  archive      = {J_COMJNL},
  author       = {Lin, Nankai and Wu, Hongyan and Zeng, Peijian and Bai, Qifeng and Zhou, Dong and Yang, Aimin},
  doi          = {10.1093/comjnl/bxaf022},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {1050-1061},
  shortjournal = {Comput. J.},
  title        = {A novel curriculum learning framework for multi-label emotion classification},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new DDoS attack detection model based on improved stacked autoencoder and gated recurrent unit for software defined network. <em>COMJNL</em>, <em>68</em>(8), 1028-1049. (<a href='https://doi.org/10.1093/comjnl/bxaf021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread adoption of Software Defined Networking (SDN), detecting Distributed Denial of Service (DDoS) attacks has become an urgent challenge in SDN maintenance and Security. Given the diversity of DDoS attack types, we face significant challenges. This paper proposes a model called ARSAE-QGRU, which is based on integrating attention mechanisms and residual connections within a stacked autoencoder for DDoS attack detection. By introducing attention mechanisms and residual connections into the stacked autoencoder (SAE), the model effectively conveys more valuable information and facilitates gradient propagation, allowing it to learn low-dimensional representations better. It also combines the learned low-dimensional representations with traffic features to generate data for DDoS attack training. Furthermore, incorporating Gated Recurrent Unit aids in a more in-depth understanding of the temporal characteristics of traffic data, resulting in improved detection accuracy. This model demonstrates outstanding performance on the CICDDoS2019 and CICIDS2017 datasets, achieving accuracy rates of 97.2% and 97.9%, respectively. Moreover, when applied to datasets in SDN environments, it reaches an even higher accuracy rate of 99.8%. This research provides a reliable solution for high-dimensional data processing and DDoS attack detection within SDN, addressing the urgent challenges in these domains.},
  archive      = {J_COMJNL},
  author       = {Wang, Haizhen and Jia, Na and He, Yang and Lian, Zuozheng},
  doi          = {10.1093/comjnl/bxaf021},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {1028-1049},
  shortjournal = {Comput. J.},
  title        = {A new DDoS attack detection model based on improved stacked autoencoder and gated recurrent unit for software defined network},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted twin support vector machine with rescaled hinge loss. <em>COMJNL</em>, <em>68</em>(8), 1013-1027. (<a href='https://doi.org/10.1093/comjnl/bxaf020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weighted twin support vector machine (WTSVM) has been proved to be effective for classification problems. However, it is sensitive to noises, especially for data corrupted by outliers. In this paper, we propose an improved classifier termed as weighted twin support vector machine with rescaled hinge loss (RHWTSVM). Similar to WTSVM, it uses the intra-class KNN technique to extract structural information in the same class. It uses the inter-class KNN technique to reduce the redundant constraints to improve the computational speed. Furthermore, we introduce the regularization term into the objective function to make the proposed RHWTSVM implement the principles of structural risk minimization and empirical risk minimization simultaneously. Besides, we use the rescaled hinge loss function which is a monotonic, bounded, and nonconvex loss to replace the traditional hinge loss function in WTSVM to make the proposed classifier more robust. Therefore, the RHWTSVM is less sensitive to outliers. Because the model is a nonconvex optimization problem, we use the half-quadratic optimization method to solve it and find that the new method is equivalent to an iterative WTSVM. Numerical experiments on datasets with various levels of noise demonstrate that RHWTSVM is reasonable and effective.},
  archive      = {J_COMJNL},
  author       = {Zhang, Siyuan and Zhang, Yixuan and Feng, Jianying},
  doi          = {10.1093/comjnl/bxaf020},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {1013-1027},
  shortjournal = {Comput. J.},
  title        = {Weighted twin support vector machine with rescaled hinge loss},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). F2PQNN: A fast and secure two-party inference on quantized convolutional neural networks. <em>COMJNL</em>, <em>68</em>(8), 998-1012. (<a href='https://doi.org/10.1093/comjnl/bxaf019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The machine learning as a service (MLaaS) paradigm has been widely adopted across various applications. However, it also raises significant privacy concerns, particularly regarding the exposure of input data and trained models. Two-party computation in convolutional neural network (CNN) inference has emerged as a promising solution to address these privacy issues in MLaaS. Nevertheless, most existing privacy-preserving CNN architectures rely on computationally expensive encryption methods, resulting in prolonged inference times and increased communication overhead. In this paper, we propose F2PQNN, a fast and secure two-party inference framework for quantized CNNs. To minimize reliance on computationally intensive encryption, F2PQNN utilizes two non-colluding servers and integrates secret sharing with oblivious transfer techniques. Furthermore, F2PQNN incorporates quantization techniques, along with batching and asynchronous computation, to significantly accelerate inference predictions. We evaluate the performance of F2PQNN on the MNIST, Fashion-MNIST, CIFAR-10, and STL-10 datasets. Experimental results demonstrate that F2PQNN outperforms existing solutions, achieving a 9.14 × speedup and reducing communication overhead by 59.8 × on the MNIST dataset.},
  archive      = {J_COMJNL},
  author       = {Li, Jinguo and Yuan, Peichun and Zhang, Jin and Shen, Sheng and He, Yin and Xiao, Ruyang},
  doi          = {10.1093/comjnl/bxaf019},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {998-1012},
  shortjournal = {Comput. J.},
  title        = {F2PQNN: A fast and secure two-party inference on quantized convolutional neural networks},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault tolerance assessment of the data center network DPCell based on g-good-neighbor conditions. <em>COMJNL</em>, <em>68</em>(8), 985-997. (<a href='https://doi.org/10.1093/comjnl/bxaf018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data center networks (DCNs) provide critical data storage and computing services for cloud computing. The continuous increase in demand for cloud computing has led to a surge in data volume, necessitating the continual expansion of DCNs. However, this expansion also heightens the risk of device failures. Therefore, it is particularly important to study the fault tolerance of DCNs, which refers to their ability to ensure reliable communication even in the presence of device failures. Among DCNs constructed using dual-port servers, DPCell achieves higher scalability and bisection width while maintaining a smaller diameter. This paper assesses the fault tolerance of DPCell using two metrics: connectivity and diagnosability. Recognizing the limitations of traditional connectivity and diagnosability, we investigate the connectivity and diagnosability of DPCell under the condition that each fault-free node in the network has at least |$g$| fault-free neighbors. The results indicate that, under this condition, the connectivity and diagnosability of DPCell exceed its traditional metrics by more than |$g$| times.},
  archive      = {J_COMJNL},
  author       = {Dong, Hui and Wang, Huaqun and Lv, Mengjie and Fan, Weibei},
  doi          = {10.1093/comjnl/bxaf018},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {985-997},
  shortjournal = {Comput. J.},
  title        = {Fault tolerance assessment of the data center network DPCell based on g-good-neighbor conditions},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Developing an intelligent framework with blockchain capabilities for environmental monitoring using a CubeSat. <em>COMJNL</em>, <em>68</em>(8), 968-984. (<a href='https://doi.org/10.1093/comjnl/bxaf017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Satellites have revolutionised the way that the planet’s environment is monitored via a unique perspective from above. Indeed, environmental monitoring is crucial for understanding and addressing the complex challenges facing the planet, which helps in decision-making and ensuring a sustainable future. Thus, this work aims to develop an intelligent model that includes artificial neural networks and deep learning approaches that are coupled with Blockchain capabilities for secure environmental monitoring using a CubeSat. The CubeSat, which is a small satellite platform, is equipped with a designed communication payload, including an adaptive Multiple-Input Multiple-Output antenna as well as an High Definition (HD) camera for better connectivity and precision aerial imaging. The proposed solution is simulated, tested, and validated from four scenarios, namely, water detection, tree counting and vegetation assessment, and oil spill detection. Ensuring the security and integrity of the data transmitted between the CubeSat and the ground station is of paramount importance; this is where Blockchain technology comes into play. The obtained results show high accuracy in monitoring environmental surfaces like water, trees, and coasts in an effective and rapid deployment fashion. Also, performance indicators of the Blockchain ensure data integrity and retrieval efficiency. Combining these technologies provides a valuable contribution to environmental monitoring.},
  archive      = {J_COMJNL},
  author       = {Almalki, Faris A},
  doi          = {10.1093/comjnl/bxaf017},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {968-984},
  shortjournal = {Comput. J.},
  title        = {Developing an intelligent framework with blockchain capabilities for environmental monitoring using a CubeSat},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BLFair: Enabling proportional I/O sharing for NVMe SSD in SPDK para-virtualization architecture. <em>COMJNL</em>, <em>68</em>(8), 953-967. (<a href='https://doi.org/10.1093/comjnl/bxaf016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data centers, the Storage Performance Development Kit (SPDK) para-virtualization architecture is an efficient solution for non-volatile memory express (NVMe) solid-state drive (SSD) virtualization but faces challenges in maintaining performance fairness and isolation due to storage resource competition among multi-tenants. However, the existing Quality of Service method in SPDK fails to ensure proportional I/O sharing among multi-tenants. Providing fairness and isolation while maintaining high storage utilization in SPDK remains a challenge. In this paper, we propose BLFair to address this problem. Specifically, BLFair implements proportional I/O sharing for multi-tenants in the SPDK. The design of BLFair can effectively reduce the high time complexity caused by the ordering and the overhead of maintaining the virtual clock. Moreover, BLFair allows for achieving a trade-off between proportional I/O sharing and maximizing storage utilization. BLFair also uses the lockless ring mechanism to achieve scalability for cross-core operation. We have implemented a prototype system of BLFair in SPDK. Finally, we conduct evaluations with different workloads in both local storage and NVMe over RDMA fabric environments. The results show that our method can achieve fairness and scalability. BLFair can achieve up to 7.09x 99.99th latency reduction compared to the system with no fairness. Evaluation results in realistic workloads also show that BLFair outperforms other methods.},
  archive      = {J_COMJNL},
  author       = {Feng, Yanchang and Ma, Junchao and Xia, Haojun and Zhang, Da and Tu, Bibo},
  doi          = {10.1093/comjnl/bxaf016},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {953-967},
  shortjournal = {Comput. J.},
  title        = {BLFair: Enabling proportional I/O sharing for NVMe SSD in SPDK para-virtualization architecture},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards effective privacy preservation in federated learning with automatic gradient clipping and gradient transformation perturbation. <em>COMJNL</em>, <em>68</em>(8), 939-952. (<a href='https://doi.org/10.1093/comjnl/bxaf015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential privacy can effectively help federated learning resist privacy attacks from various parties. However, existing approaches that use differential privacy for privacy protection greatly decrease the model performance of federated learning, especially in scenarios with complex model structures and large parameters. In this paper, we propose a novel privacy preservation scheme for federated learning that combines automatic gradient clipping and gradient transformation perturbation. Our approach primarily reduces the impact of differential privacy on federated learning from two aspects. Firstly, we efficiently control the gradient sensitivity by using automatic gradient clipping instead of traditional threshold clipping. Secondly, we utilize the space transformation technique to alleviate the dramatic accuracy degradation of the model caused by the insertion noise. Extensive experiments on various benchmark datasets demonstrate that our approach achieves a good trade-off between data privacy and effectiveness under the same privacy budget.},
  archive      = {J_COMJNL},
  author       = {Wang, Chuanyin and Zhang, Yifei and Gao, Neng},
  doi          = {10.1093/comjnl/bxaf015},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {939-952},
  shortjournal = {Comput. J.},
  title        = {Towards effective privacy preservation in federated learning with automatic gradient clipping and gradient transformation perturbation},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DuoSQL: Towards elastic data warehousing via separated data management and processing. <em>COMJNL</em>, <em>68</em>(8), 926-938. (<a href='https://doi.org/10.1093/comjnl/bxaf014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Moving data warehouses (DWs) to the cloud is what today’s companies consider a trend towards cost-effective data management. To fully achieve the goal, the cloud DW system is supposed to adjust its resource provisioning to adapt to changing workload requirements. However, traditional data warehousing architecture lacks the flexibility for on-demand resource control, which severely restricts cost optimization and quality of service for both cloud providers and users. To build cloud DWs, new architectures are needed. This paper explores an architecture that decouples data management and processing to enable on-demand resource control. This optimized design enhances system elasticity and adaptability. However, this separation design is not without cost, as cooperation overhead can be high if not well optimized. For proof of concept, we build a prototype system, DuoSQL, using PostgreSQL for data management and Spark for data processing. To optimize cooperation, we conduct joint parameter tuning to improve overall system performance. We validate the system with the TPC-H benchmark. Results show the decoupling approach is flexible and offers significant performance potential.},
  archive      = {J_COMJNL},
  author       = {zhang, Weikang and Liu, Zhi and Bai, Tongxin and Zheng, Furong and Jin, Wenming and Wang, Yang},
  doi          = {10.1093/comjnl/bxaf014},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {926-938},
  shortjournal = {Comput. J.},
  title        = {DuoSQL: Towards elastic data warehousing via separated data management and processing},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to optimize based on rate decay. <em>COMJNL</em>, <em>68</em>(8), 908-925. (<a href='https://doi.org/10.1093/comjnl/bxaf012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning to optimize (L2O) is a technique that uses neural networks to learn optimization algorithms automatically. While it holds promise for diverse optimization problems, achieving consistently ideal results remains a challenge. Typically, L2O through a parameterized optimization method (i.e. “ optimizer”) learns from training samples and generalizes to test tasks with the same distribution. However, the new test tasks usually have some deviation from the training set distribution. In this case, the generic L2O methods may not produce good optimization results. Thus, we introduce a step-size control mechanism based on the generic L2O to solve the common problem of insufficient control of the iteration amplitude in L2O and adopt different update strategies for various optimization problems to adapt to complex optimization scenarios. Additionally, we also innovatively use the gated recurrent unit network as the core model of the optimizer to achieve better optimization results. Finally, the experimental outcomes from numerical simulations and real-world datasets show that our proposed methods are significantly better than other optimization algorithms.},
  archive      = {J_COMJNL},
  author       = {Ma, Wenmin},
  doi          = {10.1093/comjnl/bxaf012},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {908-925},
  shortjournal = {Comput. J.},
  title        = {Learning to optimize based on rate decay},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MuST-GAN MFAS: Multi-semantic spoof tracer GAN with transformer layers for multi-modal face anti-spoofing. <em>COMJNL</em>, <em>68</em>(8), 891-907. (<a href='https://doi.org/10.1093/comjnl/bxaf011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of multi-modal face anti-spoofing (MFAS), where RGB, depth, and infrared data are integrated, remarkable advancements have been seen. However, despite the advancement, there still exist challenges when it comes to adaptability, particularly in dealing with unseen attacks. In this paper, a novel model called MuST-GAN MFAS is presented. This model employs a generative network that incorporates modality-specific encoders and transformer layers. It is significant that the model efficiently disentangles multi-semantic spoof traces by utilizing the power of cross-modal attention mechanisms and a transformer-based spoof trace generator. The training process involves bidirectional adversarial learning, ensuring identity consistency, intensity, center, and classification losses are taken into consideration. Through precise evaluations, it has been shown that the proposed model surpasses existing frameworks, showing remarkable performance when evaluating several modal samples. In the end, MuST-GAN MFAS makes an impressive contribution to the field of face anti-spoofing by offering results that are easy to interpret and emphasizing how important it is to learn multi-semantic spoof traces in order to improve generalization and adaptability to unseen attacks. The code is available at https://github.com/ZainUlAbideenMalik/Must-GAN-MFAS .},
  archive      = {J_COMJNL},
  author       = {Liu, Shu and Ul Abideen, Zain and Wan, Tongming and Shahzad, Inzamam and Waseem, Abbas and Pan, Yushan},
  doi          = {10.1093/comjnl/bxaf011},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {891-907},
  shortjournal = {Comput. J.},
  title        = {MuST-GAN MFAS: Multi-semantic spoof tracer GAN with transformer layers for multi-modal face anti-spoofing},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zk-DCIAExchange: SGX protected fair exchange with distributed zero knowledge proof for data confidentiality and authentication. <em>COMJNL</em>, <em>68</em>(8), 872-890. (<a href='https://doi.org/10.1093/comjnl/bxaf010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain-based data transaction protocols augmented with zero-knowledge proofs offer fairness to the participants, yet they encounter challenges pertaining to both security and efficiency. We propose the zk-DSTARK, a zk-STARK-based protocol that enables distributed generation of zero-knowledge proofs, significantly reducing the computational burden. And zk-DSTARK inherits zk-STARK’s feature of single proof generation for multiple uses, improving the efficiency of successive transactions. Furthermore, we propose a fair exchange system named zk-DCIAExchange for off-chain verification, which is based on zk-DSTARK and intel software guard extensions (SGX). This system not only minimizes on-chain overhead but also ensures the security and fairness of the transaction. Experimental results show that, in continuous transactions scenarios, the time overhead for subsequent transactions is diminished by 99.9% compared to the first transaction; compared to zero knowledge contingent payment (ZKCSP), our scheme achieves a remarkable 92% reduction in time overhead, and a 26.3% reduction when compared to FairSwap; with 32 distributed nodes and a trace length of 2 16 , the proof generation time is reduced by ~85.45%; the additional verification time introduced by the SGX is ~0.45 s, which is deemed acceptable, and the on-chain verification overhead is reduced by ~7.2% compared to the ZKCSP and ~54.4% compared to FairSwap.},
  archive      = {J_COMJNL},
  author       = {Zhan, Jing and Li, Bo and Zhao, Jiang and Zhao, Yong},
  doi          = {10.1093/comjnl/bxaf010},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {872-890},
  shortjournal = {Comput. J.},
  title        = {Zk-DCIAExchange: SGX protected fair exchange with distributed zero knowledge proof for data confidentiality and authentication},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing arrhythmia identification using chaos theory and deep learning analysis. <em>COMJNL</em>, <em>68</em>(8), 859-871. (<a href='https://doi.org/10.1093/comjnl/bxaf009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal heart function is crucial for quality life. Electrocardiograms are indispensable for diagnosing cardiac irregularities and analyzing heartbeat signals. This study unveils three novel machine learning (ML) techniques enhancing diagnostic precision. The first method scrutinizes raw ECG data and its time-series metrics, while the second incorporates historical patient health data for direct ECG classification. The third technique transforms ECG signals into insightful features, focusing on QRS complex waves. Uniquely combining these strategies, our research pioneers in advanced feature selection for cardiac diagnosis. Experiments were conducted to compare the integration of clinical data, QRS characteristics, and chaos preprocessing impact on the diagnosis. For classification assessment, five algorithms were utilized: Support Vector Machine, Decision Tree, Naïve Bayes, Neural Network, and Convolutional Neural Networks (CNNs). Implementing chaos theory, we converted QRS features into deterministic metrics. Notably, our Chaos-Enhanced CNN model exhibited outstanding performance, achieving a remarkable 99.8% accuracy rate, outshining other models.},
  archive      = {J_COMJNL},
  author       = {Eldakhly, Nabil M},
  doi          = {10.1093/comjnl/bxaf009},
  journal      = {The Computer Journal},
  month        = {8},
  number       = {8},
  pages        = {859-871},
  shortjournal = {Comput. J.},
  title        = {Optimizing arrhythmia identification using chaos theory and deep learning analysis},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
