<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JMLR</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jmlr">JMLR - 194</h2>
<ul>
<li><details>
<summary>
(2025). Linear separation capacity of self-supervised representation learning. <em>JMLR</em>, <em>26</em>(194), 1-48. (<a href='https://jmlr.org/papers/v26/24-2032.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in self-supervised learning have highlighted the efficacy of data augmentation in learning data representation from unlabeled data. Training a linear model atop these enhanced representations can yield an adept classifier. Despite the remarkable empirical performance, the underlying mechanisms that enable data augmentation to unravel nonlinear data structures into linearly separable representations remain elusive. This paper seeks to bridge this gap by investigating under what conditions learned representations can linearly separate manifolds when data is drawn from a multi-manifold model. Our investigation reveals that data augmentation offers additional information beyond observed data and can thus improve the information-theoretic optimal rate of linear separation capacity. In particular, we show that self-supervised learning can linearly separate manifolds with a smaller distance than unsupervised learning, underscoring the additional benefits of data augmentation. Our theoretical analysis further underscores that the performance of downstream linear classifiers primarily hinges on the linear separability of data representations rather than the size of the labeled data set, reaffirming the viability of constructing efficient classifiers with limited labeled data amid an expansive unlabeled data set.},
  archive      = {J_JMLR},
  author       = {Shulei Wang},
  journal      = {Journal of Machine Learning Research},
  number       = {194},
  pages        = {1-48},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Linear separation capacity of self-supervised representation learning},
  url          = {https://jmlr.org/papers/v26/24-2032.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the convergence of projected policy gradient for any constant step sizes. <em>JMLR</em>, <em>26</em>(193), 1-35. (<a href='https://jmlr.org/papers/v26/24-1530.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Projected policy gradient (PPG) is a basic policy optimization method in reinforcement learning. Given access to exact policy evaluations, previous studies have established the sublinear convergence of PPG for sufficiently small step sizes based on the smoothness and the gradient domination properties of the value function. However, as the step size goes to infinity, PPG reduces to the classic policy iteration method, which suggests the convergence of PPG even for large step sizes. In this paper, we fill this gap and show that PPG admits a sublinear convergence for any constant step sizes. Due to the existence of the state-wise visitation measure in the expression of policy gradient, the existing optimization-based analysis framework for a preconditioned version of PPG (i.e., projected Q-ascent) is not applicable, to the best of our knowledge. Instead, we proceed the proof by computing the state-wise improvement lower bound of PPG based on its inherent structure. In addition, the finite iteration convergence of PPG for any constant step size is further established, which is also new.},
  archive      = {J_JMLR},
  author       = {Jiacai Liu and Wenye Li and Dachao Lin and Ke Wei and Zhihua Zhang},
  journal      = {Journal of Machine Learning Research},
  number       = {193},
  pages        = {1-35},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On the convergence of projected policy gradient for any constant step sizes},
  url          = {https://jmlr.org/papers/v26/24-1530.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning with linear function approximations in mean-field control. <em>JMLR</em>, <em>26</em>(192), 1-53. (<a href='https://jmlr.org/papers/v26/24-1221.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper focuses on mean-field type multi-agent control problems with finite state and action spaces where the dynamics and cost structures are symmetric and homogeneous, and are affected by the distribution of the agents. A standard solution method for these problems is to consider the infinite population limit as an approximation and use symmetric solutions of the limit problem to achieve near optimality. The control policies, and in particular the dynamics, depend on the population distribution in the finite population setting, or the marginal distribution of the state variable of a representative agent for the infinite population setting. Hence, learning and planning for these control problems generally require estimating the reaction of the system to all possible state distributions of the agents. To overcome this issue, we consider linear function approximation for the control problem and provide coordinated and independent learning methods. We rigorously establish error upper bounds for the performance of learned solutions. The performance gap stems from (i) the mismatch due to estimating the true model with a linear one, and (ii) using the infinite population solution in the finite population problem as an approximate control. The provided upper bounds quantify the impact of these error sources on the overall performance.},
  archive      = {J_JMLR},
  author       = {Erhan Bayraktar and Ali Devran Kara},
  journal      = {Journal of Machine Learning Research},
  number       = {192},
  pages        = {1-53},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Learning with linear function approximations in mean-field control},
  url          = {https://jmlr.org/papers/v26/24-1221.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new random reshuffling method for nonsmooth nonconvex finite-sum optimization. <em>JMLR</em>, <em>26</em>(191), 1-46. (<a href='https://jmlr.org/papers/v26/24-0891.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random reshuffling techniques are prevalent in large-scale applications, such as training neural networks. While the convergence and acceleration effects of random reshuffling-type methods are fairly well understood in the smooth setting, much less studies seem available in the nonsmooth case. In this work, we design a new normal map-based proximal random reshuffling (norm-PRR) method for nonsmooth nonconvex finite-sum problems. We show that norm-PRR achieves the iteration complexity ${\cal O}(n^{-1/3}T^{-2/3})$ where $n$ denotes the number of component functions $f(\cdot,i)$ and $T$ counts the total number of iterations. This improves the currently known complexity bounds for this class of problems by a factor of $n^{-1/3}$ in terms of the number of gradient evaluations. Additionally, we prove that norm-PRR converges linearly under the (global) Polyak-Łojasiewicz condition and in the interpolation setting. We further complement these non-asymptotic results and provide an in-depth analysis of the asymptotic properties of norm-PRR. Specifically, under the (local) Kurdyka-Łojasiewicz inequality, the whole sequence of iterates generated by norm-PRR is shown to converge to a single stationary point. Moreover, we derive last-iterate convergence rates that can match those in the smooth, strongly convex setting. Finally, numerical experiments are performed on nonconvex classification tasks to illustrate the efficiency of the proposed approach.},
  archive      = {J_JMLR},
  author       = {Junwen Qiu and Xiao Li and Andre Milzarek},
  journal      = {Journal of Machine Learning Research},
  number       = {191},
  pages        = {1-46},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A new random reshuffling method for nonsmooth nonconvex finite-sum optimization},
  url          = {https://jmlr.org/papers/v26/24-0891.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-free change-point detection using AUC of a classifier. <em>JMLR</em>, <em>26</em>(190), 1-50. (<a href='https://jmlr.org/papers/v26/24-0365.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In contemporary data analysis, it is increasingly common to work with non-stationary complex data sets. These data sets typically extend beyond the classical low-dimensional Euclidean space, making it challenging to detect shifts in their distribution without relying on strong structural assumptions. This paper proposes a novel offline change-point detection method that leverages classifiers developed in the statistics and machine learning community. With suitable data splitting, the test statistic is constructed through sequential computation of the Area Under the Curve (AUC) of a classifier, which is trained on data segments on both ends of the sequence. It is shown that the resulting AUC process attains its maxima at the true change-point location, which facilitates the change-point estimation. The proposed method is characterized by its complete nonparametric nature, high versatility, considerable flexibility, and absence of stringent assumptions on the underlying data or any distributional shifts. Theoretically, we derive the limiting pivotal distribution of the proposed test statistic under null, as well as the asymptotic behaviors under both local and fixed alternatives. The localization rate of the change-point estimator is also provided. Extensive simulation studies and the analysis of two real-world data sets illustrate the superior performance of our approach compared to existing model-free change-point detection methods.},
  archive      = {J_JMLR},
  author       = {Rohit Kanrar and Feiyu Jiang and Zhanrui Cai},
  journal      = {Journal of Machine Learning Research},
  number       = {190},
  pages        = {1-50},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Model-free change-point detection using AUC of a classifier},
  url          = {https://jmlr.org/papers/v26/24-0365.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EF21 with bells & whistles: Six algorithmic extensions of modern error feedback. <em>JMLR</em>, <em>26</em>(189), 1-50. (<a href='https://jmlr.org/papers/v26/24-0059.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {First proposed by Seide (2014) as a heuristic, error feedback (EF) is a very popular mechanism for enforcing convergence of distributed gradient-based optimization methods enhanced with communication compression strategies based on the application of contractive compression operators. However, existing theory of EF relies on very strong assumptions (e.g., bounded gradients), and provides pessimistic convergence rates (e.g., while the best known rate for EF in the smooth nonconvex regime, and when full gradients are compressed, is $O(1/T^{2/3})$, the rate of gradient descent in the same regime is $O(1/T)$). Recently, Richtàrik et al. (2021) proposed a new error feedback mechanism, EF21, based on the construction of a Markov compressor induced by a contractive compressor. EF21 removes the aforementioned theoretical deficiencies of EF and at the same time works better in practice. In this work we propose six practical extensions of EF21, all supported by strong convergence theory: partial participation, stochastic approximation, variance reduction, proximal setting, momentum, and bidirectional compression. To the best of our knowledge, several of these techniques have not been previously analyzed in combination with EF, and in cases where prior analysis exists---such as for bidirectional compression---our theoretical convergence guarantees significantly improve upon existing results.},
  archive      = {J_JMLR},
  author       = {Ilyas Fatkhullin and Igor Sokolov and Eduard Gorbunov and Zhize Li and Peter Richtárik},
  journal      = {Journal of Machine Learning Research},
  number       = {189},
  pages        = {1-50},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {EF21 with bells & whistles: Six algorithmic extensions of modern error feedback},
  url          = {https://jmlr.org/papers/v26/24-0059.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple instance verification. <em>JMLR</em>, <em>26</em>(188), 1-46. (<a href='https://jmlr.org/papers/v26/23-1590.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore multiple instance verification, a problem setting in which a query instance is verified against a bag of target instances with heterogeneous, unknown relevancy. We show that naive adaptations of attention-based multiple instance learning (MIL) methods and standard verification methods like Siamese neural networks are unsuitable for this setting: directly combining state-of-the-art (SOTA) MIL methods and Siamese networks is shown to be no better, and sometimes significantly worse, than a simple baseline model. Postulating that this may be caused by the failure of the representation of the target bag to incorporate the query instance, we introduce a new pooling approach named “cross-attention pooling” (CAP). Under the CAP framework, we propose two novel attention functions to address the challenge of distinguishing between highly similar instances in a target bag. Through empirical studies on three different verification tasks, we demonstrate that CAP outperforms adaptations of SOTA MIL methods and the baseline by substantial margins, in terms of both classification accuracy and the ability to detect key instances. The superior ability to identify key instances is attributed to the new attention functions by ablation studies.},
  archive      = {J_JMLR},
  author       = {Xin Xu and Eibe Frank and Geoffrey Holmes},
  journal      = {Journal of Machine Learning Research},
  number       = {188},
  pages        = {1-46},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Multiple instance verification},
  url          = {https://jmlr.org/papers/v26/23-1590.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning from similar linear representations: Adaptivity, minimaxity, and robustness. <em>JMLR</em>, <em>26</em>(187), 1-125. (<a href='https://jmlr.org/papers/v26/23-0902.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation multi-task learning (MTL) has achieved tremendous success in practice. However, the theoretical understanding of these methods is still lacking. Most existing theoretical works focus on cases where all tasks share the same representation, and claim that MTL almost always improves performance. Nevertheless, as the number of tasks grows, assuming all tasks share the same representation is unrealistic. Furthermore, empirical findings often indicate that a shared representation does not necessarily improve single-task learning performance. In this paper, we aim to understand how to learn from tasks with similar but not exactly the same linear representations, while dealing with outlier tasks. Assuming a known intrinsic dimension, we propose a penalized empirical risk minimization method and a spectral method that are adaptive to the similarity structure and robust to outlier tasks. Both algorithms outperform single-task learning when representations across tasks are sufficiently similar and the proportion of outlier tasks is small. Moreover, they always perform at least as well as single-task learning, even when the representations are dissimilar. We provide information-theoretic lower bounds to demonstrate that both methods are nearly minimax optimal in a large regime, with the spectral method being optimal in the absence of outlier tasks. Additionally, we introduce a thresholding algorithm to adapt to an unknown intrinsic dimension. We conduct extensive numerical experiments to validate our theoretical findings.},
  archive      = {J_JMLR},
  author       = {Ye Tian and Yuqi Gu and Yang Feng},
  journal      = {Journal of Machine Learning Research},
  number       = {187},
  pages        = {1-125},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Learning from similar linear representations: Adaptivity, minimaxity, and robustness},
  url          = {https://jmlr.org/papers/v26/23-0902.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exponential family graphical models: Correlated replicates and unmeasured confounders, with applications to fMRI data. <em>JMLR</em>, <em>26</em>(186), 1-66. (<a href='https://jmlr.org/papers/v26/22-1421.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphical models have been used extensively for modeling brain connectivity networks. However, unmeasured confounders and correlations among measurements are often overlooked during model fitting, which may lead to spurious scientific discoveries. Motivated by functional magnetic resonance imaging (fMRI) studies, we propose a novel method for constructing brain connectivity networks with correlated replicates and latent effects. In a typical fMRI study, each participant is scanned and fMRI measurements are collected across a period of time. In many cases, subjects may have different states of mind that cannot be measured during the brain scan: for instance, some subjects may be awake during the first half of the brain scan, and may fall asleep during the second half of the brain scan. To model the correlation among replicates and latent effects induced by the different states of mind, we assume that the correlated replicates within each independent subject follow a one-lag vector autoregressive model, and that the latent effects induced by the unmeasured confounders are piecewise constant. Theoretical guarantees are established for parameter estimation. We demonstrate via extensive numerical studies that our method is able to estimate latent variable graphical models with correlated replicates more accurately than existing methods.},
  archive      = {J_JMLR},
  author       = {Yanxin Jin and Yang Ning and Kean Ming Tan},
  journal      = {Journal of Machine Learning Research},
  number       = {186},
  pages        = {1-66},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Exponential family graphical models: Correlated replicates and unmeasured confounders, with applications to fMRI data},
  url          = {https://jmlr.org/papers/v26/22-1421.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing return distributions with distributional dynamic programming. <em>JMLR</em>, <em>26</em>(185), 1-90. (<a href='https://jmlr.org/papers/v26/25-0210.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce distributional dynamic programming (DP) methods for optimizing statistical functionals of the return distribution, with standard reinforcement learning as a special case. Previous distributional DP methods could optimize the same class of expected utilities as classic DP. To go beyond, we combine distributional DP with stock augmentation, a technique previously introduced for classic DP in the context of risk-sensitive RL, where the MDP state is augmented with a statistic of the rewards obtained since the first time step. We find that a number of recently studied problems can be formulated as stock-augmented return distribution optimization, and we show that we can use distributional DP to solve them. We analyze distributional value and policy iteration, with bounds and a study of what objectives these distributional DP methods can or cannot optimize. We describe a number of applications outlining how to use distributional DP to solve different stock-augmented return distribution optimization problems, for example maximizing conditional value-at-risk, and homeostatic regulation. To highlight the practical potential of stock-augmented return distribution optimization and distributional DP, we introduce an agent that combines DQN and the core ideas of distributional DP, and empirically evaluate it for solving instances of the applications discussed.},
  archive      = {J_JMLR},
  author       = {Bernardo Ávila Pires and Mark Rowland and Diana Borsa and Zhaohan Daniel Guo and Khimya Khetarpal and André Barreto and David Abel and Rémi Munos and Will Dabney},
  journal      = {Journal of Machine Learning Research},
  number       = {185},
  pages        = {1-90},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Optimizing return distributions with distributional dynamic programming},
  url          = {https://jmlr.org/papers/v26/25-0210.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Imprecise multi-armed bandits: Representing irreducible uncertainty as a zero-sum game. <em>JMLR</em>, <em>26</em>(184), 1-75. (<a href='https://jmlr.org/papers/v26/24-2001.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel multi-armed bandit framework, where each arm is associated with a fixed unknown credal set over the space of outcomes (which can be richer than just the reward). The arm-to-credal-set correspondence comes from a known class of hypotheses. We then define a notion of regret corresponding to the lower prevision defined by these credal sets. Equivalently, the setting can be regarded as a two-player zero-sum game, where, on each round, the agent chooses an arm and the adversary chooses the distribution over outcomes from a set of options associated with this arm. The regret is defined with respect to the value of game. For certain natural hypothesis classes, loosely analogous to stochastic linear bandits (which are a special case of the resulting setting), we propose an algorithm and prove a corresponding upper bound on regret.},
  archive      = {J_JMLR},
  author       = {Vanessa Kosoy},
  journal      = {Journal of Machine Learning Research},
  number       = {184},
  pages        = {1-75},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Imprecise multi-armed bandits: Representing irreducible uncertainty as a zero-sum game},
  url          = {https://jmlr.org/papers/v26/24-2001.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Early alignment in two-layer networks training is a two-edged sword. <em>JMLR</em>, <em>26</em>(183), 1-75. (<a href='https://jmlr.org/papers/v26/24-1523.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training neural networks with first order optimisation methods is at the core of the empirical success of deep learning. The scale of initialisation is a crucial factor, as small initialisations are generally associated to a feature learning regime, for which gradient descent is implicitly biased towards simple solutions. This work provides a general and quantitative description of the early alignment phase, originally introduced by Maennel et al. (2018). For small initialisation and one hidden ReLU layer networks, the early stage of the training dynamics leads to an alignment of the neurons towards key directions. This alignment induces a sparse representation of the network, which is directly related to the implicit bias of gradient flow at convergence. This sparsity inducing alignment however comes at the expense of difficulties in minimising the training objective: we also provide a simple data example for which overparameterised networks fail to converge towards global minima and only converge to a spurious stationary point instead.},
  archive      = {J_JMLR},
  author       = {Etienne Boursier and Nicolas Flammarion},
  journal      = {Journal of Machine Learning Research},
  number       = {183},
  pages        = {1-75},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Early alignment in two-layer networks training is a two-edged sword},
  url          = {https://jmlr.org/papers/v26/24-1523.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical decision making based on structural information principles. <em>JMLR</em>, <em>26</em>(182), 1-55. (<a href='https://jmlr.org/papers/v26/24-1184.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical Reinforcement Learning (HRL) is a promising approach for managing task complexity across multiple levels of abstraction and accelerating long-horizon agent exploration. However, the effectiveness of hierarchical policies heavily depends on prior knowledge and manual assumptions about skill definitions and task decomposition. In this paper, we propose a novel Structural Information principles-based framework, namely SIDM, for hierarchical Decision Making in both single-agent and multi-agent scenarios. Central to our work is the utilization of structural information embedded in the decision-making process to adaptively and dynamically discover and learn hierarchical policies through environmental abstractions. Specifically, we present an abstraction mechanism that processes historical state-action trajectories to construct abstract representations of states and actions. We define and optimize directed structural entropy—a metric quantifying the uncertainty in transition dynamics between abstract states—to discover skills that capture key transition patterns in RL environments. Building on these findings, we develop a skill-based learning method for single-agent scenarios and a role-based collaboration method for multi-agent scenarios, both of which can flexibly integrate various underlying algorithms for enhanced performance. Extensive evaluations on challenging benchmarks demonstrate that our framework significantly and consistently outperforms state-of-the-art baselines, improving the effectiveness, efficiency, and stability of policy learning by up to 32.70%, 64.86%, and 88.26%, respectively, as measured by average rewards, convergence timesteps, and standard deviations.},
  archive      = {J_JMLR},
  author       = {Xianghua Zeng and Hao Peng and Dingli Su and Angsheng Li},
  journal      = {Journal of Machine Learning Research},
  number       = {182},
  pages        = {1-55},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Hierarchical decision making based on structural information principles},
  url          = {https://jmlr.org/papers/v26/24-1184.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative adversarial networks: Dynamics. <em>JMLR</em>, <em>26</em>(181), 1-30. (<a href='https://jmlr.org/papers/v26/24-0848.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study quantitatively the overparametrization limit of the original Wasserstein-GAN algorithm. Effectively, we show that the algorithm is a stochastic discretization of a system of continuity equations for the parameter distributions of the generator and discriminator. We show that parameter clipping to satisfy the Lipschitz condition in the algorithm induces a discontinuous vector field in the mean field dynamics, which gives rise to blow-up in finite time of the mean field dynamics. We look into a specific toy example that shows that all solutions to the mean field equations converge in the long time limit to time periodic solutions, this helps explain the failure to converge of the algorithm.},
  archive      = {J_JMLR},
  author       = {Matias G. Delgadino and Bruno B. Suassuna and Rene Cabrera},
  journal      = {Journal of Machine Learning Research},
  number       = {181},
  pages        = {1-30},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Generative adversarial networks: Dynamics},
  url          = {https://jmlr.org/papers/v26/24-0848.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). “What is different between these datasets?” a framework for explaining data distribution shifts. <em>JMLR</em>, <em>26</em>(180), 1-64. (<a href='https://jmlr.org/papers/v26/24-0352.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of machine learning models relies heavily on the quality of input data, yet real-world applications often face significant data-related challenges. A common issue arises when curating training data or deploying models: two datasets from the same domain may exhibit differing distributions. While many techniques exist for detecting such distribution shifts, there is a lack of comprehensive methods to explain these differences in a human-understandable way beyond opaque quantitative metrics. To bridge this gap, we propose a versatile framework of interpretable methods for comparing datasets. Using a variety of case studies, we demonstrate the effectiveness of our approach across diverse data modalities—including tabular data, text data, images, time-series signals – in both low and high-dimensional settings. These methods complement existing techniques by providing actionable and interpretable insights to better understand and address distribution shifts.},
  archive      = {J_JMLR},
  author       = {Varun Babbar* and Zhicheng Guo* and Cynthia Rudin},
  journal      = {Journal of Machine Learning Research},
  number       = {180},
  pages        = {1-64},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {“What is different between these datasets?” a framework for explaining data distribution shifts},
  url          = {https://jmlr.org/papers/v26/24-0352.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assumption-lean and data-adaptive post-prediction inference. <em>JMLR</em>, <em>26</em>(179), 1-31. (<a href='https://jmlr.org/papers/v26/24-0056.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A primary challenge facing modern scientific research is the limited availability of gold-standard data, which can be costly, labor-intensive, or invasive to obtain. With the rapid development of machine learning (ML), scientists can now employ ML algorithms to predict gold-standard outcomes using variables that are easier to obtain. However, these predicted outcomes are often used directly in subsequent statistical analyses, ignoring imprecision and heterogeneity introduced by the prediction procedure. This will likely result in false positive findings and invalid scientific conclusions. In this work, we introduce PoSt-Prediction Adaptive inference (PSPA) that allows valid and powerful inference based on ML-predicted data. Its “assumption-lean” property guarantees reliable statistical inference without assumptions on the ML prediction. Its “data-adaptive” feature guarantees an efficiency gain over existing methods, regardless of the accuracy of ML prediction. We demonstrate the statistical superiority and broad applicability of our method through simulations and real-data applications.},
  archive      = {J_JMLR},
  author       = {Jiacheng Miao and Xinran Miao and Yixuan Wu and Jiwei Zhao and Qiongshi Lu},
  journal      = {Journal of Machine Learning Research},
  number       = {179},
  pages        = {1-31},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Assumption-lean and data-adaptive post-prediction inference},
  url          = {https://jmlr.org/papers/v26/24-0056.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bagged regularized k-distances for anomaly detection. <em>JMLR</em>, <em>26</em>(178), 1-59. (<a href='https://jmlr.org/papers/v26/23-1519.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the paradigm of unsupervised anomaly detection, which involves the identification of anomalies within a dataset in the absence of labeled examples. Though distance-based methods are top-performing for unsupervised anomaly detection, they suffer heavily from the sensitivity to the choice of the number of the nearest neighbors. In this paper, we propose a new distance-based algorithm called bagged regularized $k$-distances for anomaly detection (BRDAD), converting the unsupervised anomaly detection problem into a convex optimization problem. Our BRDAD algorithm selects the weights by minimizing the surrogate risk, i.e., the finite sample bound of the empirical risk of the bagged weighted $k$-distances for density estimation (BWDDE). This approach enables us to successfully address the sensitivity challenge of the hyperparameter choice in distance-based algorithms. Moreover, when dealing with large-scale datasets, the efficiency issues can be addressed by the incorporated bagging technique in our BRDAD algorithm. On the theoretical side, we establish fast convergence rates of the AUC regret of our algorithm and demonstrate that the bagging technique significantly reduces the computational complexity. On the practical side, we conduct numerical experiments to illustrate the insensitivity of the parameter selection of our algorithm compared with other state-of-the-art distance-based methods. Furthermore, our method achieves superior performance on real-world datasets with the introduced bagging technique compared to other approaches.},
  archive      = {J_JMLR},
  author       = {Yuchao Cai and Hanfang Yang and Yuheng Ma and Hanyuan Hang},
  journal      = {Journal of Machine Learning Research},
  number       = {178},
  pages        = {1-59},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Bagged regularized k-distances for anomaly detection},
  url          = {https://jmlr.org/papers/v26/23-1519.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Four axiomatic characterizations of the integrated gradients attribution method. <em>JMLR</em>, <em>26</em>(177), 1-31. (<a href='https://jmlr.org/papers/v26/23-0671.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have produced significant progress among machine learning models in terms of accuracy and functionality, but their inner workings are still largely unknown. Attribution methods seek to shine a light on these "black box" models by indicating how much each input contributed to a model's outputs. The Integrated Gradients (IG) method is a state of the art baseline attribution method in the axiomatic vein, meaning it is designed to conform to particular principles of attributions. We present four axiomatic characterizations of IG, establishing IG as the unique method satisfying four different sets of axioms.},
  archive      = {J_JMLR},
  author       = {Daniel Lundstrom and Meisam Razaviyayn},
  journal      = {Journal of Machine Learning Research},
  number       = {177},
  pages        = {1-31},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Four axiomatic characterizations of the integrated gradients attribution method},
  url          = {https://jmlr.org/papers/v26/23-0671.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast algorithm for constrained linear inverse problems. <em>JMLR</em>, <em>26</em>(176), 1-41. (<a href='https://jmlr.org/papers/v26/22-1380.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the constrained Linear Inverse Problem (LIP), where a certain atomic norm (like the $\ell_1 $ norm) is minimized subject to a quadratic constraint. Typically, such cost functions are non-differentiable, which makes them not amenable to the fast optimization methods existing in practice. We propose two equivalent reformulations of the constrained LIP with improved convex regularity: (i) a smooth convex minimization problem, and (ii) a strongly convex min-max problem. These problems could be solved by applying existing acceleration-based convex optimization methods which provide better $ O \left( \frac{1}{k^2} \right)$ theoretical convergence guarantee, improving upon the current best rate of $O \left( \frac{1}{k} \right)$. We also provide a novel algorithm named the Fast Linear Inverse Problem Solver (FLIPS), which is tailored to maximally exploit the structure of the reformulations. We demonstrate the performance of FLIPS on the classical problems of Binary Selection, Compressed Sensing, and Image Denoising. We also provide open source \texttt{MATLAB} and \texttt{PYTHON} packages for these three examples, which can be easily adapted to other LIPs.},
  archive      = {J_JMLR},
  author       = {Mohammed Rayyan Sheriff and Floor Fenne Redel and Peyman Mohajerin Esfahani},
  journal      = {Journal of Machine Learning Research},
  number       = {176},
  pages        = {1-41},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Fast algorithm for constrained linear inverse problems},
  url          = {https://jmlr.org/papers/v26/22-1380.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-rank irreducible cartesian tensor decomposition and bases of equivariant spaces. <em>JMLR</em>, <em>26</em>(175), 1-53. (<a href='https://jmlr.org/papers/v26/25-0134.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Irreducible Cartesian tensors (ICTs) play a crucial role in the design of equivariant graph neural networks, as well as in theoretical chemistry and chemical physics. Meanwhile, the design space of available linear operations on tensors that preserve symmetry presents a significant challenge. The ICT decomposition and a basis of this equivariant space are difficult to obtain for high-rank tensors. After decades of research, Bonvicini (2024) has recently achieved an explicit ICT decomposition for $n=5$ with factorial time/space complexity. In this work we, for the first time, obtain decomposition matrices for ICTs up to rank $n=9$ with reduced and affordable complexity, by constructing what we call path matrices. The path matrices are obtained via performing chain-like contractions with Clebsch-Gordan matrices following the parentage scheme. We prove and leverage that the concatenation of path matrices is an orthonormal change-of-basis matrix between the Cartesian tensor product space and the spherical direct sum spaces. Furthermore, we identify a complete orthogonal basis for the equivariant space, rather than a spanning set (Pearce-Crump, 2023b), through this path matrices technique. Our method avoids the RREF algorithm and maintains a fully analytical derivation of each ICT decomposition matrix, thereby significantly improving the algorithm’s speed to obtain arbitrary rank orthogonal ICT decomposition matrices and orthogonal equivariant bases. We further extend our result to the arbitrary tensor product and direct sum spaces, enabling free design between different spaces while keeping symmetry. The Python code is available at https://github.com/ShihaoShao-GH/ICT-decomposition-and-equivariant-bases, where the $n=6,\dots,9$ ICT decomposition matrices are obtained in 1s, 3s, 11s, and 4m32s on 28-core Intel Xeon Gold 6330 CPU @ 2.00GHz, respectively.},
  archive      = {J_JMLR},
  author       = {Shihao Shao and Yikang Li and Zhouchen Lin and Qinghua Cui},
  journal      = {Journal of Machine Learning Research},
  number       = {175},
  pages        = {1-53},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {High-rank irreducible cartesian tensor decomposition and bases of equivariant spaces},
  url          = {https://jmlr.org/papers/v26/25-0134.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Best linear unbiased estimate from privatized contingency tables. <em>JMLR</em>, <em>26</em>(174), 1-41. (<a href='https://jmlr.org/papers/v26/24-1962.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In differential privacy (DP) mechanisms, it can be beneficial to release "redundant" outputs, where some quantities can be estimated in multiple ways by combining different privatized values. Indeed, the DP 2020 Decennial Census products published by the U.S. Census Bureau consist of such redundant noisy counts. When redundancy is present, the DP output can be improved by enforcing self-consistency (i.e., estimators obtained using different noisy counts result in the same value), and we show that the minimum variance processing is a linear projection. However, standard projection algorithms require excessive computation and memory, making them impractical for large-scale applications such as the Decennial Census. We propose the Scalable Efficient Algorithm for Best Linear Unbiased Estimate (SEA BLUE), based on a two-step process of aggregation and differencing that 1) enforces self-consistency through a linear and unbiased procedure, 2) is computationally and memory efficient, 3) achieves the minimum variance solution under certain structural assumptions, and 4) is empirically shown to be robust to violations of these structural assumptions. We propose three methods of calculating confidence intervals from our estimates, under various assumptions. Finally, we apply SEA BLUE to two 2010 Census demonstration products, illustrating its scalability and validity.},
  archive      = {J_JMLR},
  author       = {Jordan Awan and Adam Edwards and Paul Bartholomew and Andrew Sillers},
  journal      = {Journal of Machine Learning Research},
  number       = {174},
  pages        = {1-41},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Best linear unbiased estimate from privatized contingency tables},
  url          = {https://jmlr.org/papers/v26/24-1962.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable global minima of deep ReLU neural networks on sequentially separable data. <em>JMLR</em>, <em>26</em>(173), 1-31. (<a href='https://jmlr.org/papers/v26/24-1516.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explicitly construct zero loss neural network classifiers. We write the weight matrices and bias vectors in terms of cumulative parameters, which determine truncation maps acting recursively on input space. The configurations for the training data considered are $(i)$ sufficiently small, well separated clusters corresponding to each class, and $(ii)$ equivalence classes which are sequentially linearly separable. In the best case, for $Q$ classes of data in $\mathbb{R}^{M}$, global minimizers can be described with $Q(M+2)$ parameters.},
  archive      = {J_JMLR},
  author       = {Thomas Chen and Patrícia Muñoz Ewald},
  journal      = {Journal of Machine Learning Research},
  number       = {173},
  pages        = {1-31},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Interpretable global minima of deep ReLU neural networks on sequentially separable data},
  url          = {https://jmlr.org/papers/v26/24-1516.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced feature learning via regularisation: Integrating neural networks and kernel methods. <em>JMLR</em>, <em>26</em>(172), 1-56. (<a href='https://jmlr.org/papers/v26/24-1178.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new method for feature learning and function estimation in supervised learning via regularised empirical risk minimisation. Our approach considers functions as expectations of Sobolev functions over all possible one-dimensional projections of the data. This framework is similar to kernel ridge regression, where the kernel is E_w(k(B)(wx, wx')), with k(B)(a, b) := min(|a|, |b|)1_{ab>0} the Brownian kernel, and the distribution of the projections w is learnt. This can also be viewed as an infinite-width one-hidden layer neural network, optimising the first layer’s weights through gradient descent and explicitly adjusting the non-linearity and weights of the second layer. We introduce a gradient-based computational method for the estimator, called Brownian Kernel Neural Network (BKerNN), using particles to approximate the expectation, where the positive homogeneity of the Brownian kernel leads to improved robustness to local minima. Using Rademacher complexity, we show that BKerNN’s expected risk converges to the minimal risk with explicit high-probability rates of O(min((d/n)^1/2, n^−1/6)) (up to logarithmic factors). Numerical experiments confirm our optimisation intuitions, and BKerNN outperforms kernel ridge regression, and favourably compares to a one-hidden layer neural network with ReLU activations in various settings and real datasets.},
  archive      = {J_JMLR},
  author       = {Bertille FOLLAIN and Francis BACH},
  journal      = {Journal of Machine Learning Research},
  number       = {172},
  pages        = {1-56},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Enhanced feature learning via regularisation: Integrating neural networks and kernel methods},
  url          = {https://jmlr.org/papers/v26/24-1178.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven performance guarantees for classical and learned optimizers. <em>JMLR</em>, <em>26</em>(171), 1-49. (<a href='https://jmlr.org/papers/v26/24-0755.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a data-driven approach to analyze the performance of continuous optimization algorithms using generalization guarantees from statistical learning theory. We study classical and learned optimizers to solve families of parametric optimization problems. We build generalization guarantees for classical optimizers, using a sample convergence bound, and for learned optimizers, using the Probably Approximately Correct (PAC)-Bayes framework. To train learned optimizers, we use a gradient-based algorithm to directly minimize the PAC-Bayes upper bound. Numerical experiments in signal processing, control, and meta-learning showcase the ability of our framework to provide strong generalization guarantees for both classical and learned optimizers given a fixed budget of iterations. For classical optimizers, our bounds which hold with high probability are much tighter than those that worst-case guarantees provide. For learned optimizers, our bounds outperform the empirical outcomes observed in their non-learned counterparts.},
  archive      = {J_JMLR},
  author       = {Rajiv Sambharya and Bartolomeo Stellato},
  journal      = {Journal of Machine Learning Research},
  number       = {171},
  pages        = {1-49},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Data-driven performance guarantees for classical and learned optimizers},
  url          = {https://jmlr.org/papers/v26/24-0755.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contextual bandits with stage-wise constraints. <em>JMLR</em>, <em>26</em>(170), 1-57. (<a href='https://jmlr.org/papers/v26/24-0267.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study contextual bandits in the presence of a stage-wise constraint when the constraint must be satisfied both with high probability and in expectation. We start with the linear case where both the reward function and the stage-wise constraint (cost function) are linear. In each of the high probability and in expectation settings, we propose an upper-confidence bound algorithm for the problem and prove a $T$-round regret bound for it. We also prove a lower-bound for this constrained problem, show how our algorithms and analyses can be extended to multiple constraints, and provide simulations to validate our theoretical results. In the high probability setting, we describe the minimum requirements for the action set for our algorithm to be tractable. In the setting that the constraint is in expectation, we specialize our results to multi-armed bandits and propose a computationally efficient algorithm for this setting with regret analysis. Finally, we extend our results to the case where the reward and cost functions are both non-linear. We propose an algorithm for this case and prove a regret bound for it that characterize the function class complexity by the eluder dimension.},
  archive      = {J_JMLR},
  author       = {Aldo Pacchiano and Mohammad Ghavamzadeh and Peter Bartlett},
  journal      = {Journal of Machine Learning Research},
  number       = {170},
  pages        = {1-57},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Contextual bandits with stage-wise constraints},
  url          = {https://jmlr.org/papers/v26/24-0267.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boosting causal additive models. <em>JMLR</em>, <em>26</em>(169), 1-49. (<a href='https://jmlr.org/papers/v26/24-0052.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a boosting-based method to learn additive Structural Equation Models (SEMs) from observational data, with a focus on the theoretical aspects of determining the causal order among variables. We introduce a family of score functions based on arbitrary regression techniques, for which we establish sufficient conditions that guarantee consistent identification of the true causal ordering. Our analysis reveals that boosting with early stopping meets these criteria and thus offers a consistent score function for causal orderings. To address the challenges posed by high-dimensional data sets, we adapt our approach through a component-wise gradient descent in the space of additive SEMs. Our simulation study supports the theoretical findings in low-dimensional settings and demonstrates that our high-dimensional adaptation is competitive with state-of-the-art methods. In addition, it exhibits robustness with respect to the choice of hyperparameters, thereby simplifying the tuning process.},
  archive      = {J_JMLR},
  author       = {Maximilian Kertel and Nadja Klein},
  journal      = {Journal of Machine Learning Research},
  number       = {169},
  pages        = {1-49},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Boosting causal additive models},
  url          = {https://jmlr.org/papers/v26/24-0052.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequentist guarantees of distributed (Non)-bayesian inference. <em>JMLR</em>, <em>26</em>(168), 1-65. (<a href='https://jmlr.org/papers/v26/23-1504.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish frequentist properties, i.e., posterior consistency, asymptotic normality, and posterior contraction rates, for the distributed (non-)Bayesian inference problem for a set of agents connected over a network. These results are motivated by the need to analyze large, decentralized datasets, where distributed (non)-Bayesian inference has become a critical research area across multiple fields, including statistics, machine learning, and economics. Our results show that, under appropriate assumptions on the communication graph, distributed (non)-Bayesian inference retains parametric efficiency while enhancing robustness in uncertainty quantification. We also explore the trade-off between statistical efficiency and communication efficiency by examining how the design and size of the communication graph impact the posterior contraction rate. Furthermore, we extend our analysis to time-varying graphs and apply our results to exponential family models, distributed logistic regression, and decentralized detection models.},
  archive      = {J_JMLR},
  author       = {Bohan Wu and César A. Uribe},
  journal      = {Journal of Machine Learning Research},
  number       = {168},
  pages        = {1-65},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Frequentist guarantees of distributed (Non)-bayesian inference},
  url          = {https://jmlr.org/papers/v26/23-1504.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Asymptotic inference for multi-stage stationary treatment policy with variable selection. <em>JMLR</em>, <em>26</em>(167), 1-50. (<a href='https://jmlr.org/papers/v26/23-0660.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic treatment regimes or policies are a sequence of decision functions over multiple stages that are tailored to individual features. One important class of treatment policies in practice, namely multi-stage stationary treatment policies, prescribes treatment assignment probabilities using the same decision function across stages, where the decision is based on the same set of features consisting of time-evolving variables (e.g., routinely collected disease biomarkers). Although there has been extensive literature on constructing valid inference for the value function associated with dynamic treatment policies, little work has focused on the policies themselves, especially in the presence of high-dimensional features. We aim to fill the gap in this work. Specifically, we first obtain the multi-stage stationary treatment policy by minimizing the negative augmented inverse probability weighted estimator of the value function to increase asymptotic efficiency. An $L_1$ penalty is applied on the policy parameters to select important features. We then construct one-step improvements of the policy parameter estimators for valid inference. Theoretically, we show that the improved estimators are asymptotically normal, even if nuisance parameters are estimated at a slow convergence rate and the dimension of the features increases with the sample size. Our numerical studies demonstrate that the proposed method estimates a sparse policy with a near-optimal value function and conducts valid inference for the policy parameters.},
  archive      = {J_JMLR},
  author       = {Daiqi Gao and Yufeng Liu and Donglin Zeng},
  journal      = {Journal of Machine Learning Research},
  number       = {167},
  pages        = {1-50},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Asymptotic inference for multi-stage stationary treatment policy with variable selection},
  url          = {https://jmlr.org/papers/v26/23-0660.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EMaP: Explainable AI with manifold-based perturbations. <em>JMLR</em>, <em>26</em>(166), 1-35. (<a href='https://jmlr.org/papers/v26/22-1157.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last few years, many explanation methods based on the perturbations of input data have been introduced to shed light on the predictions generated by black-box models. The goal of this work is to introduce a novel perturbation scheme so that more faithful and robust explanations can be obtained. Our study focuses on the impact of perturbing directions on the data topology. We show that perturbing along the orthogonal directions of the input manifold better preserves the data topology, both in the worst-case analysis of the discrete Gromov-Hausdorff distance and in the average-case analysis via persistent homology. From those results, we introduce EMaP algorithm, realizing the orthogonal perturbation scheme. Our experiments show that EMaP not only improves the explainers' performance but also helps them overcome a recently developed attack against perturbation-based explanation methods.},
  archive      = {J_JMLR},
  author       = {Minh Nhat Vu and Huy Quang Mai and My T. Thai},
  journal      = {Journal of Machine Learning Research},
  number       = {166},
  pages        = {1-35},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {EMaP: Explainable AI with manifold-based perturbations},
  url          = {https://jmlr.org/papers/v26/22-1157.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autoencoders in function space. <em>JMLR</em>, <em>26</em>(165), 1-54. (<a href='https://jmlr.org/papers/v26/25-0035.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autoencoders have found widespread application in both their original deterministic form and in their variational formulation (VAEs). In scientific applications and in image processing it is often of interest to consider data that are viewed as functions; while discretisation (of differential equations arising in the sciences) or pixellation (of images) renders problems finite dimensional in practice, conceiving first of algorithms that operate on functions, and only then discretising or pixellating, leads to better algorithms that smoothly operate between resolutions. In this paper function-space versions of the autoencoder (FAE) and variational autoencoder (FVAE) are introduced, analysed, and deployed. Well-definedness of the objective governing VAEs is a subtle issue, particularly in function space, limiting applicability. For the FVAE objective to be well defined requires compatibility of the data distribution with the chosen generative model; this can be achieved, for example, when the data arise from a stochastic differential equation, but is generally restrictive. The FAE objective, on the other hand, is well defined in many situations where FVAE fails to be. Pairing the FVAE and FAE objectives with neural operator architectures that can be evaluated on any mesh enables new applications of autoencoders to inpainting, superresolution, and generative modelling of scientific data.},
  archive      = {J_JMLR},
  author       = {Justin Bunker and Mark Girolami and Hefin Lambley and Andrew M. Stuart and T. J. Sullivan},
  journal      = {Journal of Machine Learning Research},
  number       = {165},
  pages        = {1-54},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Autoencoders in function space},
  url          = {https://jmlr.org/papers/v26/25-0035.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonparametric regression on random geometric graphs sampled from submanifolds. <em>JMLR</em>, <em>26</em>(164), 1-65. (<a href='https://jmlr.org/papers/v26/24-1960.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the nonparametric regression problem when the covariates are located on an unknown compact submanifold of a Euclidean space. Under defining a random geometric graph structure over the covariates we analyse the asymptotic frequentist behaviour of the posterior distribution arising from Bayesian priors designed through random basis expansion in the graph Laplacian eigenbasis. Under Hölder smoothness assumption on the regression function and the density of the covariates over the submanifold, we prove that the posterior contraction rates of such methods are minimax optimal (up to logarithmic factors) for any positive smoothness index.},
  archive      = {J_JMLR},
  author       = {Paul Rosa and Judith Rousseau},
  journal      = {Journal of Machine Learning Research},
  number       = {164},
  pages        = {1-65},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Nonparametric regression on random geometric graphs sampled from submanifolds},
  url          = {https://jmlr.org/papers/v26/24-1960.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). System neural diversity: Measuring behavioral heterogeneity in multi-agent learning. <em>JMLR</em>, <em>26</em>(163), 1-27. (<a href='https://jmlr.org/papers/v26/24-1477.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary science provides evidence that diversity confers resilience in natural systems. Yet, traditional multi-agent reinforcement learning techniques commonly enforce homogeneity to increase training sample efficiency. When a system of learning agents is not constrained to homogeneous policies, individuals may develop diverse behaviors, resulting in emergent complementarity that benefits the system. Despite this, there is a surprising lack of tools that quantify behavioral diversity. Such techniques would pave the way towards understanding the impact of diversity in collective artificial intelligence and enabling its control. In this paper, we introduce System Neural Diversity (SND): a measure of behavioral heterogeneity in multi-agent systems. We discuss and prove its theoretical properties, and compare it with alternate, state-of-the-art behavioral diversity metrics used in the robotics domain. Through simulations of a variety of cooperative multi-robot tasks, we show how our metric constitutes an important tool that enables measurement and control of behavioral heterogeneity. In dynamic tasks, where the problem is affected by repeated disturbances during training, we show that SND allows us to measure latent resilience skills acquired by the agents, while other proxies, such as task performance (reward), fail to. Finally, we show how the metric can be employed to control diversity, allowing us to enforce a desired heterogeneity set-point or range. We demonstrate how this paradigm can be used to bootstrap the exploration phase, finding optimal policies faster, thus enabling novel and more efficient MARL paradigms.},
  archive      = {J_JMLR},
  author       = {Matteo Bettini and Ajay Shankar and Amanda Prorok},
  journal      = {Journal of Machine Learning Research},
  number       = {163},
  pages        = {1-27},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {System neural diversity: Measuring behavioral heterogeneity in multi-agent learning},
  url          = {https://jmlr.org/papers/v26/24-1477.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distribution estimation under the infinity norm. <em>JMLR</em>, <em>26</em>(162), 1-30. (<a href='https://jmlr.org/papers/v26/24-1166.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present novel bounds for estimating discrete probability distributions under the $\ell_\infty$ norm. These are nearly optimal in various precise senses, including a kind of instance-optimality. Our data-dependent convergence guarantees for the maximum likelihood estimator significantly improve upon the currently known results. A variety of techniques are utilized and innovated upon, including Chernoff-type inequalities and empirical Bernstein bounds. We illustrate our results in synthetic and real-world experiments. Finally, we apply our proposed framework to a basic selective inference problem, where we estimate the most frequent probabilities in a sample.},
  archive      = {J_JMLR},
  author       = {Aryeh Kontorovich and Amichai Painsky},
  journal      = {Journal of Machine Learning Research},
  number       = {162},
  pages        = {1-30},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Distribution estimation under the infinity norm},
  url          = {https://jmlr.org/papers/v26/24-1166.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extending temperature scaling with homogenizing maps. <em>JMLR</em>, <em>26</em>(161), 1-46. (<a href='https://jmlr.org/papers/v26/24-0700.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As machine learning models continue to grow more complex, poor calibration significantly limits the reliability of their predictions. Temperature scaling learns a single temperature parameter to scale the output logits, and despite its simplicity, remains one of the most effective post-hoc recalibration methods. We identify one of temperature scaling's defining attributes, that it increases the uncertainty of the predictions in a manner that we term homogenization, and propose to learn the optimal recalibration mapping from a larger class of functions that satisfies this property. We demonstrate the advantage of our method over temperature scaling in both calibration and out-of-distribution detection. Additionally, we extend our methodology and experimental evaluation to recalibration in the Bayesian setting.},
  archive      = {J_JMLR},
  author       = {Christopher Qian and Feng Liang and Jason Adams},
  journal      = {Journal of Machine Learning Research},
  number       = {161},
  pages        = {1-46},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Extending temperature scaling with homogenizing maps},
  url          = {https://jmlr.org/papers/v26/24-0700.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Density estimation using the perceptron. <em>JMLR</em>, <em>26</em>(160), 1-51. (<a href='https://jmlr.org/papers/v26/24-0261.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new density estimation algorithm. Given $n$ i.i.d. observations from a distribution belonging to a class of densities on $\mathbb{R}^d$, our estimator outputs any density in the class whose “perceptron discrepancy” with the empirical distribution is at most $O(\sqrt{d/n})$. The perceptron discrepancy is defined as the largest difference in mass two distribution place on any halfspace. It is shown that this estimator achieves the expected total variation distance to the truth that is almost minimax optimal over the class of densities with bounded Sobolev norm and Gaussian mixtures. This suggests that the regularity of the prior distribution could be an explanation for the efficiency of the ubiquitous step in machine learning that replaces optimization over large function spaces with simpler parametric classes (such as discriminators of GANs). We also show that replacing the perceptron discrepancy with the generalized energy distance of Székely and Rizzo (2013) further improves total variation loss. The generalized energy distance between empirical distributions is easily computable and differentiable, which makes it especially useful for fitting generative models. To the best of our knowledge, it is the first “simple” distance with such properties that yields minimax optimal statistical guarantees. In addition, we shed light on the ubiquitous method of representing discrete data in domain $[k]$ via embedding vectors on a unit ball in $\mathbb{R}^d$. We show that taking $d \asymp \log(k)$ allows one to use simple linear probing to evaluate and estimate total variation distance, as well as recovering minimax optimal sample complexity for the class of discrete distributions on $[k]$.},
  archive      = {J_JMLR},
  author       = {Patrik Róbert Gerber and Tianze Jiang and Yury Polyanskiy and Rui Sun},
  journal      = {Journal of Machine Learning Research},
  number       = {160},
  pages        = {1-51},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Density estimation using the perceptron},
  url          = {https://jmlr.org/papers/v26/24-0261.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simplex constrained sparse optimization via tail screening. <em>JMLR</em>, <em>26</em>(159), 1-38. (<a href='https://jmlr.org/papers/v26/24-0010.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the probabilistic simplex-constrained sparse recovery problem. The commonly used Lasso-type penalty for promoting sparsity is ineffective in this context since it is a constant within the simplex. Despite this challenge, fortunately, simplex constraint itself brings a self-regularization property, i.e., the empirical risk minimizer without any sparsity-promoting procedure obtains the usual Lasso-type estimation error. Moreover, we analyze the iterates of a projected gradient descent method and show its convergence to the ground truth sparse solution in the geometric rate until a satisfied statistical precision is attained. Although the estimation error is statistically optimal, the resulting solution is usually more dense than the sparse ground truth. To further sparsify the iterates, we propose a method called PERMITS via embedding a tail screening procedure, i.e., identifying negligible components and discarding them during iterations, into the projected gradient descent method. Furthermore, we combine tail screening and the special information criterion to balance the trade-off between fitness and complexity. Theoretically, the proposed PERMITS method can exactly recover the ground truth support set under mild conditions and thus obtain the oracle property. We demonstrate the statistical and computational efficiency of PERMITS with both synthetic and real data. The implementation of the proposed method can be found in https://github.com/abess-team/PERMITS.},
  archive      = {J_JMLR},
  author       = {Peng Chen and Jin Zhu and Junxian Zhu and Xueqin Wang},
  journal      = {Journal of Machine Learning Research},
  number       = {159},
  pages        = {1-38},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Simplex constrained sparse optimization via tail screening},
  url          = {https://jmlr.org/papers/v26/24-0010.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Score-based diffusion models in function space. <em>JMLR</em>, <em>26</em>(158), 1-62. (<a href='https://jmlr.org/papers/v26/23-1472.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have recently emerged as a powerful framework for generative modeling. They consist of a forward process that perturbs input data with Gaussian white noise and a reverse process that learns a score function to generate samples by denoising. Despite their tremendous success, they are mostly formulated on finite-dimensional spaces, e.g., Euclidean, limiting their applications to many domains where the data has a functional form, such as in scientific computing and 3D geometric data analysis. This work introduces a mathematically rigorous framework called Denoising Diffusion Operators (DDOs) for training diffusion models in function space. In DDOs, the forward process perturbs input functions gradually using a Gaussian process. The generative process is formulated by a function-valued annealed Langevin dynamic. Our approach requires an appropriate notion of the score for the perturbed data distribution, which we obtain by generalizing denoising score matching to function spaces that can be infinite-dimensional. We show that the corresponding discretized algorithm generates accurate samples at a fixed cost independent of the data resolution. We theoretically and numerically verify the applicability of our approach on a set of function-valued problems, including generating solutions to the Navier-Stokes equation viewed as the push-forward distribution of forcings from a Gaussian Random Field (GRF), as well as volcano InSAR and MNIST-SDF.},
  archive      = {J_JMLR},
  author       = {Jae Hyun Lim and Nikola B. Kovachki and Ricardo Baptista and Christopher Beckham and Kamyar Azizzadenesheli and Jean Kossaifi and Vikram Voleti and Jiaming Song and Karsten Kreis and Jan Kautz and Christopher Pal and Arash Vahdat and Anima Anandkumar},
  journal      = {Journal of Machine Learning Research},
  number       = {158},
  pages        = {1-62},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Score-based diffusion models in function space},
  url          = {https://jmlr.org/papers/v26/23-1472.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Regularized rényi divergence minimization through bregman proximal gradient algorithms. <em>JMLR</em>, <em>26</em>(157), 1-56. (<a href='https://jmlr.org/papers/v26/23-0573.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the variational inference problem of minimizing a regularized Rényi divergence over an exponential family. We propose to solve this problem with a Bregman proximal gradient algorithm. We propose a sampling-based algorithm to cover the black-box setting, corresponding to a stochastic Bregman proximal gradient algorithm with biased gradient estimator. We show that the resulting algorithms can be seen as relaxed moment-matching algorithms with an additional proximal step. Using Bregman updates instead of Euclidean ones allows us to exploit the geometry of our approximate model. We prove strong convergence guarantees for both our deterministic and stochastic algorithms using this viewpoint, including monotonic decrease of the objective, convergence to a stationary point or to the minimizer, and geometric convergence rates. These new theoretical insights lead to a versatile, robust, and competitive method, as illustrated by numerical experiments},
  archive      = {J_JMLR},
  author       = {Thomas Guilmeau and Emilie Chouzenoux and Víctor Elvira},
  journal      = {Journal of Machine Learning Research},
  number       = {157},
  pages        = {1-56},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Regularized rényi divergence minimization through bregman proximal gradient algorithms},
  url          = {https://jmlr.org/papers/v26/23-0573.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WEFE: A python library for measuring and mitigating bias in word embeddings. <em>JMLR</em>, <em>26</em>(156), 1-6. (<a href='https://jmlr.org/papers/v26/22-1133.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Word embeddings, which are a mapping of words into continuous vectors, are widely used in modern Natural Language Processing (NLP) systems. However, they are prone to inherit stereotypical social biases from the corpus on which they are built. The research community has focused on two main tasks to address this problem: 1) how to measure these biases, and 2) how to mitigate them. Word Embedding Fairness Evaluation (WEFE) is an open source library that implements many fairness metrics and mitigation methods in a unified framework. It also provides a standard interface for designing new ones. The software follows the object-oriented paradigm with a strong focus on extensibility. Each of its methods is appropriately documented, verified and tested. WEFE is not limited to just a library: it also contains several replications of previous studies as well as tutorials that serve as educational material for newcomers to the field. It is licensed under BSD-3 and can be easily installed through pip and conda package managers.},
  archive      = {J_JMLR},
  author       = {Pablo Badilla and Felipe Bravo-Marquez and María José Zambrano and Jorge Pérez},
  journal      = {Journal of Machine Learning Research},
  number       = {156},
  pages        = {1-6},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {WEFE: A python library for measuring and mitigating bias in word embeddings},
  url          = {https://jmlr.org/papers/v26/22-1133.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frontiers to the learning of nonparametric hidden markov models. <em>JMLR</em>, <em>26</em>(155), 1-75. (<a href='https://jmlr.org/papers/v26/24-2230.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hidden Markov models (HMMs) are flexible tools for clustering dependent data coming from unknown populations, allowing nonparametric modelling of the population densities. Identifiability fails when the data is in fact independent and identically distributed (i.i.d.), and we study the frontier between learnable and unlearnable two-state nonparametric HMMs. Learning the parameters of the HMM requires solving a nonlinear inverse problem whose difficulty depends not only on the smoothnesses of the populations but also on the distance to the i.i.d. boundary of the parameter set. The latter difficulty is mostly ignored in the literature in favour of assumptions precluding nearly independent data. This is the first work conducting a precise nonasymptotic, nonparametric analysis of the minimax risk taking into account all aspects of the hardness of the problem, in the case of two populations. Our analysis reveals an unexpected interplay between the distance to the i.i.d. boundary and the relative smoothnesses of the two populations: a surprising and intriguing transition occurs in the rate when the two densities have differing smoothnesses. We obtain upper and lower bounds revealing that, close to the i.i.d. boundary, it is possible to "borrow strength" from the estimator of the smoother density to improve the risk of the other.},
  archive      = {J_JMLR},
  author       = {Kweku Abraham and Elisabeth Gassiat and Zacharie Naulet},
  journal      = {Journal of Machine Learning Research},
  number       = {155},
  pages        = {1-75},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Frontiers to the learning of nonparametric hidden markov models},
  url          = {https://jmlr.org/papers/v26/24-2230.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On non-asymptotic theory of recurrent neural networks in temporal point processes. <em>JMLR</em>, <em>26</em>(154), 1-67. (<a href='https://jmlr.org/papers/v26/24-1953.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal point process (TPP) is an important tool for modeling and predicting irregularly timed events across various domains. Recently, the recurrent neural network (RNN)-based TPPs have shown practical advantages over traditional parametric TPP models. However, in the current literature, it remains nascent in understanding neural TPPs from theoretical viewpoints. In this paper, we establish the excess risk bounds of RNN-TPPs under many well-known TPP settings. We especially show that an RNN-TPP with no more than four layers can achieve vanishing generalization errors. Our technical contributions include the characterization of the complexity of the multi-layer RNN class, the construction of $\tanh$ neural networks for approximating dynamic event intensity functions, and the truncation technique for alleviating the issue of unbounded event sequences. Our results bridge the gap between TPP's application and neural network theory.},
  archive      = {J_JMLR},
  author       = {Zhiheng Chen and Guanhua Fang and Wen Yu},
  journal      = {Journal of Machine Learning Research},
  number       = {154},
  pages        = {1-67},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On non-asymptotic theory of recurrent neural networks in temporal point processes},
  url          = {https://jmlr.org/papers/v26/24-1953.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Classification in the high dimensional anisotropic mixture framework: A new take on robust interpolation. <em>JMLR</em>, <em>26</em>(153), 1-39. (<a href='https://jmlr.org/papers/v26/24-1366.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the classification problem under the two-component anisotropic sub-Gaussian mixture model in high dimensions and in the non-asymptotic setting. First, we derive lower bounds and matching upper bounds for the minimax risk of classification in this framework. We also show that in the high-dimensional regime, the linear discriminant analysis classifier turns out to be sub-optimal in the minimax sense. Next, we give precise characterization of the risk of classifiers based on solutions of $\ell_2$-regularized least squares problem. We deduce that the interpolating solutions may outperform the regularized classifiers under mild assumptions on the covariance structure of the noise, and present concrete examples of this phenomenon. Our analysis also demonstrates robustness of interpolation to certain models of corruption. To the best of our knowledge, this peculiar fact has not yet been investigated in the rapidly growing literature related to interpolation. We conclude that interpolation is not only benign but can also be optimal, and in some cases robust.},
  archive      = {J_JMLR},
  author       = {Stanislav Minsker and Mohamed Ndaoud and Yiqiu Shen},
  journal      = {Journal of Machine Learning Research},
  number       = {153},
  pages        = {1-39},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Classification in the high dimensional anisotropic mixture framework: A new take on robust interpolation},
  url          = {https://jmlr.org/papers/v26/24-1366.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Universal online convex optimization meets second-order bounds. <em>JMLR</em>, <em>26</em>(152), 1-53. (<a href='https://jmlr.org/papers/v26/24-1131.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, several universal methods have been proposed for online convex optimization, and attain minimax rates for multiple types of convex functions simultaneously. However, they need to design and optimize one surrogate loss for each type of functions, making it difficult to exploit the structure of the problem and utilize existing algorithms. In this paper, we propose a simple strategy for universal online convex optimization, which avoids these limitations. The key idea is to construct a set of experts to process the original online functions, and deploy a meta-algorithm over the linearized losses to aggregate predictions from experts. Specifically, the meta-algorithm is required to yield a second-order bound with excess losses, so that it can leverage strong convexity and exponential concavity to control the meta-regret. In this way, our strategy inherits the theoretical guarantee of any expert designed for strongly convex functions and exponentially concave functions, up to a double logarithmic factor. As a result, we can plug in off-the-shelf online solvers as black-box experts to deliver problem-dependent regret bounds. For general convex functions, it maintains the minimax optimality and also achieves a small-loss bound. Furthermore, we extend our universal strategy to online composite optimization, where the loss function comprises a time-varying function and a fixed regularizer. To deal with the composite loss functions, we employ a meta-algorithm based on the optimistic online learning framework, which not only enjoys a second-order bound, but also can utilize estimations for upcoming loss functions. With suitable configurations, we show that the additional regularizer does not contribute to the meta-regret, thus ensuring the universality in the composite setting.},
  archive      = {J_JMLR},
  author       = {Lijun Zhang and Yibo Wang and Guanghui Wang and Jinfeng Yi and Tianbao Yang},
  journal      = {Journal of Machine Learning Research},
  number       = {152},
  pages        = {1-53},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Universal online convex optimization meets second-order bounds},
  url          = {https://jmlr.org/papers/v26/24-1131.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sample complexity of the linear quadratic regulator: A reinforcement learning lens. <em>JMLR</em>, <em>26</em>(151), 1-50. (<a href='https://jmlr.org/papers/v26/24-0636.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide the first known algorithm that provably achieves $\varepsilon$-optimality within $\widetilde{O}(1/\varepsilon)$ function evaluations for the discounted discrete-time linear quadratic regulator problem with unknown parameters, without relying on two-point gradient estimates. These estimates are known to be unrealistic in many settings, as they depend on using the exact same initialization, which is to be selected randomly, for two different policies. Our results substantially improve upon the existing literature outside the realm of two-point gradient estimates, which either leads to $\widetilde{O}(1/\varepsilon^2)$ rates or heavily relies on stability assumptions.},
  archive      = {J_JMLR},
  author       = {Amirreza Neshaei Moghaddam and Alex Olshevsky and Bahman Gharesifard},
  journal      = {Journal of Machine Learning Research},
  number       = {151},
  pages        = {1-50},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Sample complexity of the linear quadratic regulator: A reinforcement learning lens},
  url          = {https://jmlr.org/papers/v26/24-0636.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Randomization can reduce both bias and variance: A case study in random forests. <em>JMLR</em>, <em>26</em>(150), 1-49. (<a href='https://jmlr.org/papers/v26/24-0255.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the often overlooked phenomenon, first noted in Breiman (2001), that random forests appear to reduce bias compared to bagging. Motivated by an interesting paper by Mentch and Zhou (2020), where the authors explain the success of random forests in low signal-to-noise ratio (SNR) settings through regularization, we explore how random forests can capture patterns in the data that bagging ensembles fail to capture. We empirically demonstrate that in the presence of such patterns, random forests reduce bias along with variance and can increasingly outperform bagging ensembles when SNR is high. Our observations offer insights into the real-world success of random forests across a range of SNRs and enhance our understanding of the difference between random forests and bagging ensembles. Our investigations also yield practical insights into the importance of tuning $mtry$ in random forests.},
  archive      = {J_JMLR},
  author       = {Brian Liu and Rahul Mazumder},
  journal      = {Journal of Machine Learning Research},
  number       = {150},
  pages        = {1-49},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Randomization can reduce both bias and variance: A case study in random forests},
  url          = {https://jmlr.org/papers/v26/24-0255.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Skglm: Improving scikit-learn for regularized generalized linear models. <em>JMLR</em>, <em>26</em>(149), 1-6. (<a href='https://jmlr.org/papers/v26/24-0008.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce skglm, an open-source Python package for regularized Generalized Linear Models. Thanks to its composable nature, it supports combining datafits, penalties, and solvers to fit a wide range of models, many of them not included in scikit-learn (e.g. Group Lasso and variants). It uses state-of-the-art algorithms to solve problems involving high-dimensional datasets, providing large speed-ups compared to existing implementations. It is fully compliant with the scikit-learn API and acts as a drop-in replacement for its estimators. Finally, it abides by the standards of open source development and is integrated in the scikit-learn-contrib GitHub organization.},
  archive      = {J_JMLR},
  author       = {Badr Moufad and Pierre-Antoine Bannier and Quentin Bertrand and Quentin Klopfenstein and Mathurin Massias},
  journal      = {Journal of Machine Learning Research},
  number       = {149},
  pages        = {1-6},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Skglm: Improving scikit-learn for regularized generalized linear models},
  url          = {https://jmlr.org/papers/v26/24-0008.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Losing momentum in continuous-time stochastic optimisation. <em>JMLR</em>, <em>26</em>(148), 1-55. (<a href='https://jmlr.org/papers/v26/23-1396.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The training of modern machine learning models often consists in solving high-dimensional non-convex optimisation problems that are subject to large-scale data. In this context, momentum-based stochastic optimisation algorithms have become particularly widespread. The stochasticity arises from data subsampling which reduces computational cost. Both, momentum and stochasticity help the algorithm to converge globally. In this work, we propose and analyse a continuous-time model for stochastic gradient descent with momentum. This model is a piecewise-deterministic Markov process that represents the optimiser by an underdamped dynamical system and the data subsampling through a stochastic switching. We investigate longtime limits, the subsampling-to-no-subsampling limit, and the momentum-to-no-momentum limit. We are particularly interested in the case of reducing the momentum over time. Under convexity assumptions, we show convergence of our dynamical system to the global minimiser when reducing momentum over time and letting the subsampling rate go to infinity. We then propose a stable, symplectic discretisation scheme to construct an algorithm from our continuous-time dynamical system. In experiments, we study our scheme in convex and non-convex test problems. Additionally, we train a convolutional neural network in an image classification problem. Our algorithm attains competitive results compared to stochastic gradient descent with momentum.},
  archive      = {J_JMLR},
  author       = {Kexin Jin and Jonas Latz and Chenguang Liu and Alessandro Scagliotti},
  journal      = {Journal of Machine Learning Research},
  number       = {148},
  pages        = {1-55},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Losing momentum in continuous-time stochastic optimisation},
  url          = {https://jmlr.org/papers/v26/23-1396.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent process models for functional network data. <em>JMLR</em>, <em>26</em>(147), 1-69. (<a href='https://jmlr.org/papers/v26/23-0444.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network data are often sampled with auxiliary information or collected through the observation of a complex system over time, leading to multiple network snapshots indexed by a continuous variable. Many methods in statistical network analysis are traditionally designed for a single network, and can be applied to an aggregated network in this setting, but that approach can miss important functional structure. Here we develop an approach to estimating the expected network explicitly as a function of a continuous index, be it time or another indexing variable. We parameterize the network expectation through low dimensional latent processes, whose components we represent with a fixed, finite-dimensional functional basis. We derive a gradient descent estimation algorithm, establish theoretical guarantees for recovery of the low dimensional structure, compare our method to competitors, and apply it to a data set of international political interactions over time, showing our proposed method to adapt well to data, outperform competitors, and provide interpretable and meaningful results.},
  archive      = {J_JMLR},
  author       = {Peter W. MacDonald and Elizaveta Levina and Ji Zhu},
  journal      = {Journal of Machine Learning Research},
  number       = {147},
  pages        = {1-69},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Latent process models for functional network data},
  url          = {https://jmlr.org/papers/v26/23-0444.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic bayesian learning for spatiotemporal mechanistic models. <em>JMLR</em>, <em>26</em>(146), 1-43. (<a href='https://jmlr.org/papers/v26/22-0896.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop an approach for Bayesian learning of spatiotemporal dynamical mechanistic models. Such learning consists of statistical emulation of the mechanistic system that can efficiently interpolate the output of the system from arbitrary inputs. The emulated learner can then be used to train the system from noisy data achieved by melding information from observed data with the emulated mechanistic system. This joint melding of mechanistic systems employ hierarchical state-space models with Gaussian process regression. Assuming the dynamical system is controlled by a finite collection of inputs, Gaussian process regression learns the effect of these parameters through a number of training runs, driving the stochastic innovations of the spatiotemporal state-space component. This enables efficient modeling of the dynamics over space and time. This article details exact inference with analytically accessible posterior distributions in hierarchical matrix-variate Normal and Wishart models in designing the emulator. This step obviates expensive iterative algorithms such as Markov chain Monte Carlo or variational approximations. We also show how emulation is applicable to large-scale emulation by designing a dynamic Bayesian transfer learning framework. Inference on mechanistic model parameters proceeds using Markov chain Monte Carlo as a post-emulation step using the emulator as a regression component. We demonstrate this framework through solving inverse problems arising in the analysis of ordinary and partial nonlinear differential equations and, in addition, to a black-box computer model generating spatiotemporal dynamics across a graphical model.},
  archive      = {J_JMLR},
  author       = {Sudipto Banerjee and Xiang Chen and Ian Frankenburg and Daniel Zhou},
  journal      = {Journal of Machine Learning Research},
  number       = {146},
  pages        = {1-43},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Dynamic bayesian learning for spatiotemporal mechanistic models},
  url          = {https://jmlr.org/papers/v26/22-0896.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the ability of deep networks to learn symmetries from data: A neural kernel theory. <em>JMLR</em>, <em>26</em>(145), 1-70. (<a href='https://jmlr.org/papers/v26/24-2175.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symmetries (transformations by group actions) are present in many datasets, and leveraging them holds considerable promise for improving predictions in machine learning. In this work, we aim to understand when and how deep networks---with standard architectures trained in a standard, supervised way---learn symmetries from data. Inspired by real-world scenarios, we study a classification paradigm where data symmetries are only partially observed during training: some classes include all transformations of a cyclic group, while others---only a subset. We ask: under which conditions will deep networks correctly classify the partially sampled classes? In the infinite-width limit, where neural networks behave like kernel machines, we derive a neural kernel theory of symmetry learning. The group-cyclic nature of the dataset allows us to analyze the Gram matrix of neural kernels in the Fourier domain; here we find a simple characterization of the generalization error as a function of class separation (signal) and class-orbit density (noise). This characterization reveals that generalization can only be successful when the local structure of the data prevails over its non-local, symmetry-induced structure, in the kernel space defined by the architecture. This occurs when (1) classes are sufficiently distinct and (2) class orbits are sufficiently dense. We extend our theoretical treatment to any finite group, including non-abelian groups. Our framework also applies to equivariant architectures (e.g., CNNs), and recovers their success in the special case where the architecture matches the inherent symmetry of the data. Empirically, our theory reproduces the generalization failure of finite-width networks (MLP, CNN, ViT) trained on partially observed versions of rotated-MNIST. We conclude that conventional deep networks lack a mechanism to learn symmetries that have not been explicitly embedded in their architecture a priori. In the future, our framework could be extended to guide the design of architectures and training procedures able to learn symmetries from data.},
  archive      = {J_JMLR},
  author       = {Andrea Perin and Stephane Deny},
  journal      = {Journal of Machine Learning Research},
  number       = {145},
  pages        = {1-70},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On the ability of deep networks to learn symmetries from data: A neural kernel theory},
  url          = {https://jmlr.org/papers/v26/24-2175.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained analysis and faster algorithms for iteratively solving linear systems. <em>JMLR</em>, <em>26</em>(144), 1-49. (<a href='https://jmlr.org/papers/v26/24-1906.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite being a key bottleneck in many machine learning tasks, the cost of solving large linear systems has proven challenging to quantify due to problem-dependent quantities such as condition numbers. To tackle this, we consider a fine-grained notion of complexity for solving linear systems, which is motivated by applications where the data exhibits low-dimensional structure, including spiked covariance models and kernel machines, and when the linear system is explicitly regularized, such as ridge regression. Concretely, let $\kappa_\ell$ be the ratio between the $\ell$th largest and the smallest singular value of $n\times n$ matrix $A$. We give a stochastic algorithm based on the Sketch-and-Project paradigm, that solves the linear system $Ax=b$ in time $\tilde O(\kappa_\ell\cdot n^2\log1/\epsilon)$ for any $\ell = O(n^{0.729})$. This is a direct improvement over preconditioned conjugate gradient, and it provides a stronger separation between stochastic linear solvers and algorithms accessing $A$ only through matrix-vector products. Our main technical contribution is the new analysis of the first and second moments of the random projection matrix that arises in Sketch-and-Project.},
  archive      = {J_JMLR},
  author       = {Michal Dereziński and Daniel LeJeune and Deanna Needell and Elizaveta Rebrova},
  journal      = {Journal of Machine Learning Research},
  number       = {144},
  pages        = {1-49},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Fine-grained analysis and faster algorithms for iteratively solving linear systems},
  url          = {https://jmlr.org/papers/v26/24-1906.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep generative models: Complexity, dimensionality, and approximation. <em>JMLR</em>, <em>26</em>(143), 1-37. (<a href='https://jmlr.org/papers/v26/24-1335.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative networks have shown remarkable success in learning complex data distributions, particularly in generating high-dimensional data from lower-dimensional inputs. While this capability is well-documented empirically, its theoretical underpinning remains unclear. One common theoretical explanation appeals to the widely accepted manifold hypothesis, which suggests that many real-world datasets, such as images and signals, often possess intrinsic low-dimensional geometric structures. Under this manifold hypothesis, it is widely believed that to approximate a distribution on a $d$-dimensional Riemannian manifold, the latent dimension needs to be at least $d$ or $d+1$. In this work, we show that this requirement on the latent dimension is not necessary by demonstrating that generative networks can approximate distributions on $d$-dimensional Riemannian manifolds from inputs of any arbitrary dimension, even lower than $d$, taking inspiration from the concept of space-filling curves. This approach, in turn, leads to a super-exponential complexity bound of the deep neural networks through expanded neurons. Our findings thus challenge the conventional belief on the relationship between input dimensionality and the ability of generative networks to model data distributions. This novel insight not only corroborates the practical effectiveness of generative networks in handling complex data structures, but also underscores a critical trade-off between approximation error, dimensionality, and model complexity.},
  archive      = {J_JMLR},
  author       = {Kevin Wang and Hongqian Niu and Yixin Wang and Didong Li},
  journal      = {Journal of Machine Learning Research},
  number       = {143},
  pages        = {1-37},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Deep generative models: Complexity, dimensionality, and approximation},
  url          = {https://jmlr.org/papers/v26/24-1335.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ClimSim-online: A large multi-scale dataset and framework for hybrid physics-ML climate emulation. <em>JMLR</em>, <em>26</em>(142), 1-85. (<a href='https://jmlr.org/papers/v26/24-1014.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern climate projections lack adequate spatial and temporal resolution due to computational constraints, leading to inaccuracies in representing critical processes like thunderstorms that occur on the sub-resolution scale. Hybrid methods combining physics with machine learning (ML) offer faster, higher fidelity climate simulations by outsourcing compute-hungry, high-resolution simulations to ML emulators. However, these hybrid physics-ML simulations require domain-specific data and workflows that have been inaccessible to many ML experts. This paper is an extended version of our NeurIPS award-winning ClimSim dataset paper. The ClimSim dataset includes 5.7 billion pairs of multivariate input/output vectors spanning ten years at high temporal resolution, capturing the influence of high-resolution, high-fidelity physics on a host climate simulator's macro-scale state. In this extended version, we introduce a significant new contribution in Section 5, which provides a cross-platform, containerized pipeline to integrate ML models into operational climate simulators for hybrid testing. We also implement various baselines of ML models and hybrid simulators to highlight the ML challenges of building stable, skillful emulators. The data (https://huggingface.co/datasets/LEAP/ClimSim_high-res, also in a low-resolution version at https://huggingface.co/datasets/LEAP/ClimSim_low-res and an aquaplanet version at https://huggingface.co/datasets/LEAP/ClimSim_low-res_aqua-planet) and code (https://leap-stc.github.io/ClimSim and https://github.com/leap-stc/climsim-online) are publicly released to support the development of hybrid physics-ML and high-fidelity climate simulations.},
  archive      = {J_JMLR},
  author       = {Sungduk Yu and Zeyuan Hu and Akshay Subramaniam and Walter Hannah and Liran Peng and Jerry Lin and Mohamed Aziz Bhouri and Ritwik Gupta and Björn Lütjens and Justus C. Will and Gunnar Behrens and Julius J. M. Busecke and Nora Loose and Charles I Stern and Tom Beucler and Bryce Harrop and Helge Heuer and Benjamin R Hillman and Andrea Jenney and Nana Liu and Alistair White and Tian Zheng and Zhiming Kuang and Fiaz Ahmed and Elizabeth Barnes and Noah D. Brenowitz and Christopher Bretherton and Veronika Eyring and Savannah Ferretti and Nicholas Lutsko and Pierre Gentine and Stephan Mandt and J. David Neelin and Rose Yu and Laure Zanna and Nathan M. Urban and Janni Yuval and Ryan Abernathey and Pierre Baldi and Wayne Chuang and Yu Huang and Fernando Iglesias-Suarez and Sanket Jantre and Po-Lun Ma and Sara Shamekh and Guang Zhang and Michael Pritchard},
  journal      = {Journal of Machine Learning Research},
  number       = {142},
  pages        = {1-85},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {ClimSim-online: A large multi-scale dataset and framework for hybrid physics-ML climate emulation},
  url          = {https://jmlr.org/papers/v26/24-1014.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conditional wasserstein distances with applications in bayesian OT flow matching. <em>JMLR</em>, <em>26</em>(141), 1-47. (<a href='https://jmlr.org/papers/v26/24-0586.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In inverse problems, many conditional generative models approximate the posterior measure by minimizing a distance between the joint measure and its learned approximation. While this approach also controls the distance between the posterior measures in the case of the Kullback–Leibler divergence, the same in general does not hold true for the Wasserstein distance. In this paper, we introduce a conditional Wasserstein distance via a set of restricted couplings that equals the expected Wasserstein distance of the posteriors. Interestingly, the dual formulation of the conditional Wasserstein-1 distance resembles losses in the conditional Wasserstein GAN literature in a quite natural way. We derive theoretical properties of the conditional Wasserstein distance, characterize the corresponding geodesics and velocity fields as well as the flow ODEs. Subsequently, we propose to approximate the velocity fields by relaxing the conditional Wasserstein distance. Based on this, we propose an extension of OT Flow Matching for solving Bayesian inverse problems and demonstrate its numerical advantages on an inverse problem and class-conditional image generation.},
  archive      = {J_JMLR},
  author       = {Jannis Chemseddine and Paul Hagemann and Gabriele Steidl and Christian Wald},
  journal      = {Journal of Machine Learning Research},
  number       = {141},
  pages        = {1-47},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Conditional wasserstein distances with applications in bayesian OT flow matching},
  url          = {https://jmlr.org/papers/v26/24-0586.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep variational multivariate information bottleneck - A framework for variational losses. <em>JMLR</em>, <em>26</em>(140), 1-50. (<a href='https://jmlr.org/papers/v26/24-0204.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational dimensionality reduction methods are widely used for their accuracy, generative capabilities, and robustness. We introduce a unifying framework that generalizes both such as traditional and state-of-the-art methods. The framework is based on an interpretation of the multivariate information bottleneck, trading off the information preserved in an encoder graph (defining what to compress) against that in a decoder graph (defining a generative model for data). Using this approach, we rederive existing methods, including the deep variational information bottleneck, variational autoencoders, and deep multiview information bottleneck. We naturally extend the deep variational CCA (DVCCA) family to beta-DVCCA and introduce a new method, the deep variational symmetric information bottleneck (DVSIB). DSIB, the deterministic limit of DVSIB, connects to modern contrastive learning approaches such as Barlow Twins, among others. We evaluate these methods on Noisy MNIST and Noisy CIFAR-100, showing that algorithms better matched to the structure of the problem like DVSIB and beta-DVCCA produce better latent spaces as measured by classification accuracy, dimensionality of the latent variables, sample efficiency, and consistently outperform other approaches under comparable conditions. Additionally, we benchmark against state-of-the-art models, achieving superior or competitive accuracy. Our results demonstrate that this framework can seamlessly incorporate diverse multi-view representation learning algorithms, providing a foundation for designing novel, problem-specific loss functions.},
  archive      = {J_JMLR},
  author       = {Eslam Abdelaleem and Ilya Nemenman and K. Michael Martini},
  journal      = {Journal of Machine Learning Research},
  number       = {140},
  pages        = {1-50},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Deep variational multivariate information bottleneck - A framework for variational losses},
  url          = {https://jmlr.org/papers/v26/24-0204.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffeomorphism-based feature learning using poincaré inequalities on augmented input space. <em>JMLR</em>, <em>26</em>(139), 1-31. (<a href='https://jmlr.org/papers/v26/23-1707.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a gradient-enhanced algorithm for high-dimensional function approximation. The algorithm proceeds in two steps: firstly, we reduce the input dimension by learning the relevant input features from gradient evaluations, and secondly, we regress the function output against the pre-learned features. To ensure theoretical guarantees, we construct the feature map as the first components of a diffeomorphism, which we learn by minimizing an error bound obtained using Poincaré Inequality applied either in the input space or in the feature space. This leads to two different strategies, which we compare both theoretically and numerically and relate to existing methods in the literature. In addition, we propose a dimension augmentation trick to increase the approximation power of feature detection. A generalization to vector-valued functions demonstrate that our methodology directly applies to learning autoencoders. Here, we approximate the identity function over a given dataset by a composition of feature map (encoder) with the regression function (decoder). In practice, we construct the diffeomorphism using coupling flows, a particular class of invertible neural networks. Numerical experiments on various high-dimensional functions show that the proposed algorithm outperforms state-of-the-art competitors, especially with small datasets.},
  archive      = {J_JMLR},
  author       = {Romain Verdière and Clémentine Prieur and Olivier Zahm},
  journal      = {Journal of Machine Learning Research},
  number       = {139},
  pages        = {1-31},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Diffeomorphism-based feature learning using poincaré inequalities on augmented input space},
  url          = {https://jmlr.org/papers/v26/23-1707.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite expression method for solving high-dimensional partial differential equations. <em>JMLR</em>, <em>26</em>(138), 1-31. (<a href='https://jmlr.org/papers/v26/23-1290.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing efficient and accurate numerical solvers for high-dimensional partial differential equations (PDEs) remains a challenging and important topic in computational science and engineering, mainly due to the "curse of dimensionality" in designing numerical schemes that scale in dimension. This paper introduces a new methodology that seeks an approximate PDE solution in the space of functions with finitely many analytic expressions and, hence, this methodology is named the finite expression method (FEX). It is proved in approximation theory that FEX can avoid the curse of dimensionality. As a proof of concept, a deep reinforcement learning method is proposed to implement FEX for various high-dimensional PDEs in different dimensions, achieving high and even machine accuracy with a memory complexity polynomial in dimension and an amenable time complexity. An approximate solution with finite analytic expressions also provides interpretable insights into the ground truth PDE solution, which can further help to advance the understanding of physical systems and design postprocessing techniques for a refined solution.},
  archive      = {J_JMLR},
  author       = {Senwei Liang and Haizhao Yang},
  journal      = {Journal of Machine Learning Research},
  number       = {138},
  pages        = {1-31},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Finite expression method for solving high-dimensional partial differential equations},
  url          = {https://jmlr.org/papers/v26/23-1290.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Randomly projected convex clustering model: Motivation, realization, and cluster recovery guarantees. <em>JMLR</em>, <em>26</em>(137), 1-57. (<a href='https://jmlr.org/papers/v26/23-0384.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a randomly projected convex clustering model for clustering a collection of $n$ high dimensional data points in $\mathbb{R}^d$ with $K$ hidden clusters. Compared to the convex clustering model for clustering original data with dimension $d$, we prove that, under some mild conditions, the perfect recovery of the cluster membership assignments of the convex clustering model, if exists, can be preserved by the randomly projected convex clustering model with embedding dimension $m = O(\epsilon^{-2}\log(n))$, where $\epsilon > 0$ is some given parameter. We further prove that the embedding dimension can be improved to be $O(\epsilon^{-2}\log(K))$, which is independent of the number of data points. We also establish the recovery guarantees of our proposed model with uniform weights for clustering a mixture of spherical Gaussians. Extensive numerical results demonstrate the robustness and superior performance of the randomly projected convex clustering model. The numerical results will also demonstrate that the randomly projected convex clustering model can outperform other popular clustering models on the dimension-reduced data, including the randomly projected K-means model.},
  archive      = {J_JMLR},
  author       = {Ziwen Wang and Yancheng Yuan and Jiaming Ma and Tieyong Zeng and Defeng Sun},
  journal      = {Journal of Machine Learning Research},
  number       = {137},
  pages        = {1-57},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Randomly projected convex clustering model: Motivation, realization, and cluster recovery guarantees},
  url          = {https://jmlr.org/papers/v26/23-0384.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Minimax optimal deep neural network classifiers under smooth decision boundary. <em>JMLR</em>, <em>26</em>(136), 1-38. (<a href='https://jmlr.org/papers/v26/22-0758.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has gained huge empirical successes in large-scale classification problems. In contrast, there is a lack of statistical understanding about deep learning methods, particularly in the minimax optimality perspective. For instance, in the classical smooth decision boundary setting, existing deep neural network (DNN) approaches are rate-suboptimal, and it remains elusive how to construct minimax optimal DNN classifiers. Moreover, it is interesting to explore whether DNN classifiers can circumvent the "curse of dimensionality" in handling high-dimensional data. The contributions of this paper are two-fold. First, based on a localized margin framework, we discover the source of suboptimality of existing DNN approaches. Motivated by this, we propose a new deep learning classifier using a divide-and-conquer technique: DNN classifiers are constructed on each local region and then aggregated to a global one. We further propose a localized version of the classical Tsybakov’s noise condition, under which statistical optimality of our new classifier is established. Second, we show that DNN classifiers can adapt to low-dimensional data structures and circumvent the “curse of dimensionality” in the sense that the minimax rate only depends on the effective dimension, potentially much smaller than the actual data dimension. Numerical experiments are conducted on simulated data to corroborate our theoretical results.},
  archive      = {J_JMLR},
  author       = {Tianyang Hu and Ruiqi Liu and Zuofeng Shang and Guang Cheng},
  journal      = {Journal of Machine Learning Research},
  number       = {136},
  pages        = {1-38},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Minimax optimal deep neural network classifiers under smooth decision boundary},
  url          = {https://jmlr.org/papers/v26/22-0758.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal and efficient algorithms for decentralized online convex optimization. <em>JMLR</em>, <em>26</em>(135), 1-43. (<a href='https://jmlr.org/papers/v26/24-2137.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate decentralized online convex optimization (D-OCO), in which a set of local learners are required to minimize a sequence of global loss functions using only local computations and communications. Previous studies have established $O(n^{5/4}\rho^{-1/2}\sqrt{T})$ and ${O}(n^{3/2}\rho^{-1}\log T)$ regret bounds for convex and strongly convex functions respectively, where $n$ is the number of local learners, $\rho<1$ is the spectral gap of the communication matrix, and $T$ is the time horizon. However, there exist large gaps from the existing lower bounds, i.e., $\Omega(n\sqrt{T})$ for convex functions and $\Omega(n)$ for strongly convex functions. To fill these gaps, in this paper, we first develop a novel D-OCO algorithm that can respectively reduce the regret bounds for convex and strongly convex functions to $\tilde{O}(n\rho^{-1/4}\sqrt{T})$ and $\tilde{O}(n\rho^{-1/2}\log T)$. The primary technique is to design an online accelerated gossip strategy that enjoys a faster average consensus among local learners. Furthermore, by carefully exploiting spectral properties of a specific network topology, we enhance the lower bounds for convex and strongly convex functions to $\Omega(n\rho^{-1/4}\sqrt{T})$ and $\Omega(n\rho^{-1/2}\log T)$, respectively. These results suggest that the regret of our algorithm is nearly optimal in terms of $T$, $n$, and $\rho$ for both convex and strongly convex functions. Finally, we propose a projection-free variant of our algorithm to efficiently handle practical applications with complex constraints. Our analysis reveals that the projection-free variant can achieve ${O}(nT^{3/4})$ and ${O}(nT^{2/3}(\log T)^{1/3})$ regret bounds for convex and strongly convex functions with nearly optimal $\tilde{O}(\rho^{-1/2}\sqrt{T})$ and $\tilde{O}(\rho^{-1/2}T^{1/3}(\log T)^{2/3})$ communication rounds, respectively.},
  archive      = {J_JMLR},
  author       = {Yuanyu Wan and Tong Wei and Bo Xue and Mingli Song and Lijun Zhang},
  journal      = {Journal of Machine Learning Research},
  number       = {135},
  pages        = {1-43},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Optimal and efficient algorithms for decentralized online convex optimization},
  url          = {https://jmlr.org/papers/v26/24-2137.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterizing dynamical stability of stochastic gradient descent in overparameterized learning. <em>JMLR</em>, <em>26</em>(134), 1-46. (<a href='https://jmlr.org/papers/v26/24-1547.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For overparameterized optimization tasks, such as those found in modern machine learning, global minima are generally not unique. In order to understand generalization in these settings, it is vital to study to which minimum an optimization algorithm converges. The possibility of having minima that are unstable under the dynamics imposed by the optimization algorithm limits the potential minima that the algorithm can find. In this paper, we characterize the global minima that are dynamically stable/unstable for both deterministic and stochastic gradient descent (SGD). In particular, we introduce a characteristic Lyapunov exponent that depends on the local dynamics around a global minimum and rigorously prove that the sign of this Lyapunov exponent determines whether SGD can accumulate at the respective global minimum.},
  archive      = {J_JMLR},
  author       = {Dennis Chemnitz and Maximilian Engel},
  journal      = {Journal of Machine Learning Research},
  number       = {134},
  pages        = {1-46},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Characterizing dynamical stability of stochastic gradient descent in overparameterized learning},
  url          = {https://jmlr.org/papers/v26/24-1547.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PREMAP: A unifying PREiMage APproximation framework for neural networks. <em>JMLR</em>, <em>26</em>(133), 1-44. (<a href='https://jmlr.org/papers/v26/24-1297.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most methods for neural network verification focus on bounding the image, i.e., set of outputs for a given input set. This can be used to, for example, check the robustness of neural network predictions to bounded perturbations of an input. However, verifying properties concerning the preimage, i.e., the set of inputs satisfying an output property, requires abstractions in the input space. We present a general framework for preimage abstraction that produces under- and over-approximations of any polyhedral output set. Our framework employs cheap parameterised linear relaxations of the neural network, together with an anytime refinement procedure that iteratively partitions the input region by splitting on input features and neurons. The effectiveness of our approach relies on carefully designed heuristics and optimisation objectives to achieve rapid improvements in the approximation volume. We evaluate our method on a range of tasks, demonstrating significant improvement in efficiency and scalability to high-input-dimensional image classification tasks compared to state-of-the-art techniques. Further, we showcase the application to quantitative verification and robustness analysis, presenting a sound and complete algorithm for the former and providing sound quantitative results for the latter.},
  archive      = {J_JMLR},
  author       = {Xiyue Zhang and Benjie Wang and Marta Kwiatkowska and Huan Zhang},
  journal      = {Journal of Machine Learning Research},
  number       = {133},
  pages        = {1-44},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {PREMAP: A unifying PREiMage APproximation framework for neural networks},
  url          = {https://jmlr.org/papers/v26/24-1297.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Score-aware policy-gradient and performance guarantees using local lyapunov stability. <em>JMLR</em>, <em>26</em>(132), 1-74. (<a href='https://jmlr.org/papers/v26/24-1009.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a policy-gradient method for model-based reinforcement learning (RL) that exploits a type of stationary distributions commonly obtained from Markov decision processes (MDPs) in stochastic networks, queueing systems, and statistical mechanics. Specifically, when the stationary distribution of the MDP belongs to an exponential family that is parametrized by policy parameters, we can improve existing policy gradient methods for average-reward RL. Our key identification is a family of gradient estimators, called score-aware gradient estimators (SAGEs), that enable policy gradient estimation without relying on value-function estimation in the aforementioned setting. We show that SAGE-based policy-gradient locally converges, and we obtain its regret. This includes cases when the state space of the MDP is countable and unstable policies can exist. Under appropriate assumptions such as starting sufficiently close to a maximizer and the existence of a local Lyapunov function, the policy under SAGE-based stochastic gradient ascent has an overwhelming probability of converging to the associated optimal policy. Furthermore, we conduct a numerical comparison between a SAGE-based policy-gradient method and an actor-critic method on several examples inspired from stochastic networks, queueing systems, and models derived from statistical physics. Our results demonstrate that a SAGE-based method finds close-to-optimal policies faster than an actor-critic method.},
  archive      = {J_JMLR},
  author       = {Céline Comte and Matthieu Jonckheere and Jaron Sanders and Albert Senen-Cerda},
  journal      = {Journal of Machine Learning Research},
  number       = {132},
  pages        = {1-74},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Score-aware policy-gradient and performance guarantees using local lyapunov stability},
  url          = {https://jmlr.org/papers/v26/24-1009.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the O(sqrt(d)/T^(1/4)) convergence rate of RMSProp and its momentum extension measured by l_1 norm. <em>JMLR</em>, <em>26</em>(131), 1-25. (<a href='https://jmlr.org/papers/v26/24-0523.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although adaptive gradient methods have been extensively used in deep learning, their convergence rates proved in the literature are all slower than that of SGD, particularly with respect to their dependence on the dimension. This paper considers the classical RMSProp and its momentum extension and establishes the convergence rate of $\frac{1}{T}\sum_{k=1}^TE\left[||\nabla f(\mathbf{x}^k)||_1\right]\leq O(\frac{\sqrt{d}C}{T^{1/4}})$ measured by $\ell_1$ norm without the bounded gradient assumption, where $d$ is the dimension of the optimization variable, $T$ is the iteration number, and $C$ is a constant identical to that appeared in the optimal convergence rate of SGD. Our convergence rate matches the lower bound with respect to all the coefficients except the dimension $d$. Since $||\mathbf{x}||_2\ll ||\mathbf{x}||_1\leq\sqrt{d}||\mathbf{x}||_2$ for problems with extremely large $d$, our convergence rate can be considered to be analogous to the $\frac{1}{T}\sum_{k=1}^TE\left[||\nabla f(\mathbf{x}^k)||_2\right]\leq O(\frac{C}{T^{1/4}})$ rate of SGD in the ideal case of $||\nabla f(\mathbf{x})||_1=\varTheta(\sqrt{d})||\nabla f(\mathbf{x})||_2$.},
  archive      = {J_JMLR},
  author       = {Huan Li and Yiming Dong and Zhouchen Lin},
  journal      = {Journal of Machine Learning Research},
  number       = {131},
  pages        = {1-25},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On the O(sqrt(d)/T^(1/4)) convergence rate of RMSProp and its momentum extension measured by l_1 norm},
  url          = {https://jmlr.org/papers/v26/24-0523.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Categorical semantics of compositional reinforcement learning. <em>JMLR</em>, <em>26</em>(130), 1-37. (<a href='https://jmlr.org/papers/v26/24-0197.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compositional knowledge representations in reinforcement learning (RL) facilitate modular, interpretable, and safe task specifications. However, generating compositional models requires the characterization of minimal assumptions for the robustness of the compositionality feature, especially in the case of functional decompositions. Using a categorical point of view, we develop a knowledge representation framework for a compositional theory of RL. Our approach relies on the theoretical study of the category $\mathsf{MDP}$, whose objects are Markov decision processes (MDPs) acting as models of tasks. The categorical semantics models the compositionality of tasks through the application of pushout operations akin to combining puzzle pieces. As a practical application of these pushout operations, we introduce zig-zag diagrams that rely on the compositional guarantees engendered by the category $\mathsf{MDP}$. We further prove that properties of the category $\mathsf{MDP}$ unify concepts, such as enforcing safety requirements and exploiting symmetries, generalizing previous abstraction theories for RL.},
  archive      = {J_JMLR},
  author       = {Georgios Bakirtzis and Michail Savvas and Ufuk Topcu},
  journal      = {Journal of Machine Learning Research},
  number       = {130},
  pages        = {1-37},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Categorical semantics of compositional reinforcement learning},
  url          = {https://jmlr.org/papers/v26/24-0197.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformers from diffusion: A unified framework for neural message passing. <em>JMLR</em>, <em>26</em>(129), 1-47. (<a href='https://jmlr.org/papers/v26/23-1672.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning representations for structured data with certain geometries (e.g., observed or unobserved) is a fundamental challenge, wherein message passing neural networks (MPNNs) have become a de facto class of model solutions. In this paper, inspired by physical systems, we propose an energy-constrained diffusion model, which integrates the inductive bias of diffusion on manifolds with layer-wise constraints of energy minimization. We identify that the diffusion operators have a one-to-one correspondence with the energy functions implicitly descended by the diffusion process, and the finite-difference iteration for solving the energy-constrained diffusion system induces the propagation layers of various types of MPNNs operating on observed or latent structures. This leads to a unified mathematical framework for common neural architectures whose computational flows can be cast as message passing (or its special case), including MLPs, GNNs, and Transformers. Building on these insights, we devise a new class of neural message passing models, dubbed diffusion-inspired Transformers (DIFFormer), whose global attention layers are derived from the principled energy-constrained diffusion framework. Across diverse datasets ranging from real-world networks to images, texts, and physical particles, we demonstrate that the new model achieves promising performance in scenarios where the data structures are observed (as a graph), partially observed, or entirely unobserved.},
  archive      = {J_JMLR},
  author       = {Qitian Wu and David Wipf and Junchi Yan},
  journal      = {Journal of Machine Learning Research},
  number       = {129},
  pages        = {1-47},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Transformers from diffusion: A unified framework for neural message passing},
  url          = {https://jmlr.org/papers/v26/23-1672.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal sample selection through uncertainty estimation and its application in deep learning. <em>JMLR</em>, <em>26</em>(128), 1-47. (<a href='https://jmlr.org/papers/v26/23-1160.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern deep learning heavily relies on large labeled datasets, which often comse with high costs in terms of both manual labeling and computational resources. To mitigate these challenges, researchers have explored the use of informative subset selection techniques. In this study, we present a theoretically optimal solution for addressing both sampling with and without labels within the context of linear softmax regression. Our proposed method, COPS (unCertainty based OPtimal Sub-sampling), is designed to minimize the expected loss of a model trained on subsampled data. Unlike existing approaches that rely on explicit calculations of the inverse covariance matrix, which are not easily applicable to deep learning scenarios, COPS leverages the model's logits to estimate the sampling ratio. This sampling ratio is closely associated with model uncertainty and can be effectively applied to deep learning tasks. Furthermore, we address the challenge of model sensitivity to misspecification by incorporating a down-weighting approach for low-density samples, drawing inspiration from previous works. To assess the effectiveness of our proposed method, we conducted extensive empirical experiments using deep neural networks on benchmark datasets. The results consistently showcase the superior performance of COPS compared to baseline methods, reaffirming its efficacy.},
  archive      = {J_JMLR},
  author       = {Yong Lin and Chen Liu and Chenlu Ye and Qing Lian and Yuan Yao and Tong Zhang},
  journal      = {Journal of Machine Learning Research},
  number       = {128},
  pages        = {1-47},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Optimal sample selection through uncertainty estimation and its application in deep learning},
  url          = {https://jmlr.org/papers/v26/23-1160.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Actor-critic learning for mean-field control in continuous time. <em>JMLR</em>, <em>26</em>(127), 1-42. (<a href='https://jmlr.org/papers/v26/23-0345.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study policy gradient for mean-field control in continuous time in a reinforcement learning setting. By considering randomised policies with entropy regularisation, we derive a gradient expectation representation of the value function, which is amenable to actor-critic type algorithms, where the value functions and the policies are learnt alternately based on observation samples of the state and model-free estimation of the population state distribution, either by offline or online learning. In the linear-quadratic mean-field framework, we obtain an exact parametrisation of the actor and critic functions defined on the Wasserstein space. Finally, we illustrate the results of our algorithms with some numerical experiments on concrete examples.},
  archive      = {J_JMLR},
  author       = {Noufel FRIKHA and Maximilien GERMAIN and Mathieu LAURIERE and Huyen PHAM and Xuanye SONG},
  journal      = {Journal of Machine Learning Research},
  number       = {127},
  pages        = {1-42},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Actor-critic learning for mean-field control in continuous time},
  url          = {https://jmlr.org/papers/v26/23-0345.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modelling populations of interaction networks via distance metrics. <em>JMLR</em>, <em>26</em>(126), 1-112. (<a href='https://jmlr.org/papers/v26/22-0706.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network data arises through the observation of relational information between a collection of entities, for example, friendships (relations) amongst a sample of people (entities). Traditionally, statistical models of such data have been developed to analyse a single network, that is, a single collection of entities and relations. More recently, attention has shifted to analysing samples of networks. A driving force has been the analysis of connectome data, arising in neuroscience applications, where a single network is observed for each patient in a study. These models typically assume, within each network, the entities are the units of observation, that is, more data equates to including more entities. However, an alternative paradigm considers relations—such as edges or paths—as the observational units, exemplified by email exchanges or user navigations across a website. This interaction network framework has generally been applied to single networks, without extending to the case where multiple such networks are observed, for instance, analysing navigation patterns from many users. Motivated by this gap, we propose a new Bayesian modelling framework to analyse such data. Our approach is based on practitioner-specified distance metrics between networks, allowing us to parameterise models analogous to Gaussian distributions in network space, using location and scale parameters. We address the key challenge of defining meaningful distances between interaction networks, proposing two new metrics with theoretical guarantees and practical computation strategies. To enable efficient Bayesian inference, we develop specialised Markov chain Monte Carlo (MCMC) algorithms within the involutive MCMC (iMCMC) framework, tailored to the doubly-intractable and discrete nature of the induced posteriors. Through simulation studies, we demonstrate the robustness and efficiency of our approach, and we showcase its applicability with a case study on a location-based social network (LSBN) dataset.},
  archive      = {J_JMLR},
  author       = {George Bolt and Simón Lunagómez and Christopher Nemeth},
  journal      = {Journal of Machine Learning Research},
  number       = {126},
  pages        = {1-112},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Modelling populations of interaction networks via distance metrics},
  url          = {https://jmlr.org/papers/v26/22-0706.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BitNet: 1-bit pre-training for large language models. <em>JMLR</em>, <em>26</em>(125), 1-29. (<a href='https://jmlr.org/papers/v26/24-2050.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing size of large language models (LLMs) has posed challenges for deployment and raised concerns about environmental impact due to high energy consumption. Previous research typically applies quantization after pre-training. While these methods avoid the need for model retraining, they often cause notable accuracy loss at extremely low bit-widths. In this work, we explore the feasibility and scalability of 1-bit pre-training. We introduce BitNet b1 and BitNet b1.58, the scalable and stable 1-bit Transformer architecture designed for LLMs. Specifically, we introduce BitLinear as a drop-in replacement of the nn.Linear layer in order to train 1-bit weights from scratch. Experimental results show that BitNet b1 achieves competitive performance, compared to state-of-the-art 8-bit quantization methods and FP16 Transformer baselines. With the ternary weight, BitNet b1.58 matches the half-precision Transformer LLM with the same model size and training tokens in terms of both perplexity and end-task performance, while being significantly more cost-effective in terms of latency, memory, throughput, and energy consumption. More profoundly, BitNet defines a new scaling law and recipe for training new generations of LLMs that are both high-performance and cost-effective. It enables a new computation paradigm and opens the door for designing specific hardware optimized for 1-bit LLMs.},
  archive      = {J_JMLR},
  author       = {Hongyu Wang and Shuming Ma and Lingxiao Ma and Lei Wang and Wenhui Wang and Li Dong and Shaohan Huang and Huaijie Wang and Jilong Xue and Ruiping Wang and Yi Wu and Furu Wei},
  journal      = {Journal of Machine Learning Research},
  number       = {125},
  pages        = {1-29},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {BitNet: 1-bit pre-training for large language models},
  url          = {https://jmlr.org/papers/v26/24-2050.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed kernel learning. <em>JMLR</em>, <em>26</em>(124), 1-39. (<a href='https://jmlr.org/papers/v26/24-1536.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed machine learning typically integrates physical priors into the learning process by minimizing a loss function that includes both a data-driven term and a partial differential equation (PDE) regularization. Building on the formulation of the problem as a kernel regression task, we use Fourier methods to approximate the associated kernel, and propose a tractable estimator that minimizes the physics-informed risk function. We refer to this approach as physics-informed kernel learning (PIKL). This framework provides theoretical guarantees, enabling the quantification of the physical prior’s impact on convergence speed. We demonstrate the numerical performance of the PIKL estimator through simulations, both in the context of hybrid modeling and in solving PDEs. In particular, we show that PIKL can outperform physics-informed neural networks in terms of both accuracy and computation time. Additionally, we identify cases where PIKL surpasses traditional PDE solvers, particularly in scenarios with noisy boundary conditions.},
  archive      = {J_JMLR},
  author       = {Nathan Doumèche and Francis Bach and Gérard Biau and Claire Boyer},
  journal      = {Journal of Machine Learning Research},
  number       = {124},
  pages        = {1-39},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Physics-informed kernel learning},
  url          = {https://jmlr.org/papers/v26/24-1536.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Last-iterate convergence of shuffling momentum gradient method under the kurdyka-lojasiewicz inequality. <em>JMLR</em>, <em>26</em>(123), 1-51. (<a href='https://jmlr.org/papers/v26/24-1243.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shuffling gradient algorithms are extensively used to solve finite-sum optimization problems in machine learning. However, their theoretical properties still need to be further explored, especially the last-iterate convergence in the non-convex setting. In this paper, we study the last-iterate convergence behavior of shuffling momentum gradient (SMG) method, a shuffling gradient algorithm with momentum. Specifically, we focus on the non-convex scenario and provide theoretical guarantees under arbitrary shuffling strategies. For non-convex objectives, we achieve the convergence of gradient norms at the last-iterate, showing that every accumulation point of the iterative sequence is a stationary point of the non-convex problem. Our analysis also reveals that the function values of the last-iterate converge to a finite value. Additionally, we obtain the asymptotic convergence rates of gradient norms at the minimum-iterate. By employing a uniform without-replacement sampling strategy, we further achieve an improved convergence rate for the minimum-iterate output. Under the Kurdyka-Lojasiewicz (KL) inequality, we establish the challenging strong limit-point convergence results. In particular, we prove that the whole sequence of iterates exhibits convergence to a stationary point of the finite-sum problem. By choosing an appropriate stepsize, we also obtain the corresponding rate of last-iterate convergence, matching available results in the strongly convex setting. Given that the last iteration is typically preferred as the output of the algorithm in applied scenarios, this paper contributes to narrowing the gap between theory and practice.},
  archive      = {J_JMLR},
  author       = {Yuqing Liang and Dongpo Xu},
  journal      = {Journal of Machine Learning Research},
  number       = {123},
  pages        = {1-51},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Last-iterate convergence of shuffling momentum gradient method under the kurdyka-lojasiewicz inequality},
  url          = {https://jmlr.org/papers/v26/24-1243.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Posterior and variational inference for deep neural networks with heavy-tailed weights. <em>JMLR</em>, <em>26</em>(122), 1-58. (<a href='https://jmlr.org/papers/v26/24-0894.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider deep neural networks in a Bayesian framework with a prior distribution sampling the network weights at random. Following a recent idea of Agapiou and Castillo (2024), who show that heavy-tailed prior distributions achieve automatic adaptation to smoothness, we introduce a simple Bayesian deep learning prior based on heavy-tailed weights and ReLU activation. We show that the corresponding posterior distribution achieves near-optimal minimax contraction rates, simultaneously adaptive to both intrinsic dimension and smoothness of the underlying function, in a variety of contexts including nonparametric regression, geometric data and Besov spaces. While most works so far need a form of model selection built-in within the prior distribution, a key aspect of our approach is that it does not require to sample hyperparameters to learn the architecture of the network. We also provide variational Bayes counterparts of the results, that show that mean-field variational approximations still benefit from near-optimal theoretical support.},
  archive      = {J_JMLR},
  author       = {Paul Egels and Ismaël Castillo},
  journal      = {Journal of Machine Learning Research},
  number       = {122},
  pages        = {1-58},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Posterior and variational inference for deep neural networks with heavy-tailed weights},
  url          = {https://jmlr.org/papers/v26/24-0894.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximum causal entropy IRL in mean-field games and GNEP framework for forward RL. <em>JMLR</em>, <em>26</em>(121), 1-40. (<a href='https://jmlr.org/papers/v26/24-0458.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the use of Maximum Causal Entropy Inverse Reinforcement Learning (IRL) within the context of discrete-time stationary Mean-Field Games (MFGs) characterized by finite state spaces and an infinite-horizon, discounted-reward setting. Although the resulting optimization problem is non-convex with respect to policies, we reformulate it as a convex optimization problem in terms of state-action occupation measures by leveraging the linear programming framework of Markov Decision Processes. Based on this convex reformulation, we introduce a gradient descent algorithm with a guaranteed convergence rate to efficiently compute the optimal solution. Moreover, we develop a new method that conceptualizes the MFG problem as a Generalized Nash Equilibrium Problem (GNEP), enabling effective computation of the mean-field equilibrium for forward reinforcement learning (RL) problems and marking an advancement in MFG solution techniques. We further illustrate the practical applicability of our GNEP approach by employing this algorithm to generate data for numerical MFG examples.},
  archive      = {J_JMLR},
  author       = {Berkay Anahtarci and Can Deha Kariksiz and Naci Saldi},
  journal      = {Journal of Machine Learning Research},
  number       = {121},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Maximum causal entropy IRL in mean-field games and GNEP framework for forward RL},
  url          = {https://jmlr.org/papers/v26/24-0458.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Degree of interference: A general framework for causal inference under interference. <em>JMLR</em>, <em>26</em>(120), 1-37. (<a href='https://jmlr.org/papers/v26/24-0119.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One core assumption typically adopted for valid causal inference is that of no interference between experimental units, i.e., the outcome of an experimental unit is unaffected by the treatments assigned to other experimental units. This assumption can be violated in real-life experiments, which significantly complicates the task of causal inference. As the number of potential outcomes increases, it becomes challenging to disentangle direct treatment effects from “spillover” effects. Current methodologies are lacking, as they cannot handle arbitrary, unknown interference structures to permit inference on causal estimands. We present a general framework to address the limitations of existing approaches. Our framework is based on the new concept of the “degree of interference” (DoI). The DoI is a unit-level latent variable that captures the latent structure of interference. We also develop a data augmentation algorithm that adopts a blocked Gibbs sampler and Bayesian nonparametric methodology to perform inferences on the estimands under our framework. We illustrate the DoI concept and properties of our Bayesian methodology via extensive simulation studies and an analysis of a randomized experiment investigating the impact of a cash transfer program for which interference is a critical concern. Ultimately, our framework enables us to infer causal effects without strong structural assumptions on interference.},
  archive      = {J_JMLR},
  author       = {Yuki Ohnishi and Bikram Karmakar and Arman Sabbaghi},
  journal      = {Journal of Machine Learning Research},
  number       = {120},
  pages        = {1-37},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Degree of interference: A general framework for causal inference under interference},
  url          = {https://jmlr.org/papers/v26/24-0119.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantifying the effectiveness of linear preconditioning in markov chain monte carlo. <em>JMLR</em>, <em>26</em>(119), 1-51. (<a href='https://jmlr.org/papers/v26/23-1633.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study linear preconditioning in Markov chain Monte Carlo. We consider the class of well-conditioned distributions, for which several mixing time bounds depend on the condition number $\kappa$. First we show that well-conditioned distributions exist for which $\kappa$ can be arbitrarily large and yet no linear preconditioner can reduce it. We then impose two sets of extra assumptions under which a linear preconditioner can significantly reduce $\kappa$. For the random walk Metropolis we further provide upper and lower bounds on the spectral gap with tight $1/\kappa$ dependence. This allows us to give conditions under which linear preconditioning can provably increase the gap. We then study popular preconditioners such as the covariance, its diagonal approximation, the Hessian at the mode, and the QR decomposition. We show conditions under which each of these reduce $\kappa$ to near its minimum. We also show that the diagonal approach can in fact increase the condition number. This is of interest as diagonal preconditioning is the default choice in well-known software packages. We conclude with a numerical study comparing preconditioners in different models, and we show how proper preconditioning can greatly reduce compute time in Hamiltonian Monte Carlo.},
  archive      = {J_JMLR},
  author       = {Max Hird and Samuel Livingstone},
  journal      = {Journal of Machine Learning Research},
  number       = {119},
  pages        = {1-51},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Quantifying the effectiveness of linear preconditioning in markov chain monte carlo},
  url          = {https://jmlr.org/papers/v26/23-1633.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse SVM with hard-margin loss: A newton-augmented lagrangian method in reduced dimensions. <em>JMLR</em>, <em>26</em>(118), 1-55. (<a href='https://jmlr.org/papers/v26/23-0953.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hard-margin loss function has been at the core of the support vector machine research from the very beginning due to its generalization capability. On the other hand, the cardinality constraint has been widely used for feature selection, leading to sparse solutions. This paper studies the sparse SVM with the hard-margin loss that integrates the virtues of both worlds, resulting in one of the most challenging models to solve. We cast the problem as a composite optimization with the cardinality constraint. We characterize its local minimizers in terms of pseudo KKT point that well captures the combinatorial structure of the problem, and investigate a sharper P-stationary point with a concise representation for algorithm design. We further develop an inexact proximal augmented Lagrangian method (iPAL). The different parts of the inexactness measurements from the {\rm P}-stationarity are controlled at different scales in a way that the generated sequence converges both globally and at a linear rate. To make iPAL practically efficient, we propose a gradient-Newton method in a subspace for the iPAL subproblem. This is accomplished by detecting active samples and features with the help of the proximal operator of the hard margin loss and the projection of the cardinality constraint. Extensive numerical results on both simulated and real data sets demonstrate that the proposed method is fast, produces sparse solution of high accuracy, and can lead to effective reduction on active samples and features when compared with several leading solvers.},
  archive      = {J_JMLR},
  author       = {Penghe Zhang and Naihua Xiu and Hou-Duo Qi},
  journal      = {Journal of Machine Learning Research},
  number       = {118},
  pages        = {1-55},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Sparse SVM with hard-margin loss: A newton-augmented lagrangian method in reduced dimensions},
  url          = {https://jmlr.org/papers/v26/23-0953.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On model identification and out-of-sample prediction of PCR with applications to synthetic controls. <em>JMLR</em>, <em>26</em>(117), 1-58. (<a href='https://jmlr.org/papers/v26/23-0102.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze principal component regression (PCR) in a high-dimensional error-in-variables setting with fixed design. Under suitable conditions, we show that PCR consistently identifies the unique model with minimum $\ell_2$-norm. These results enable us to establish non-asymptotic out-of-sample prediction guarantees that improve upon the best known rates. In the course of our analysis, we introduce a natural linear algebraic condition between the in- and out-of-sample covariates, which allows us to avoid distributional assumptions for out-of-sample predictions. Our simulations illustrate the importance of this condition for generalization, even under covariate shifts. Accordingly, we construct a hypothesis test to check when this condition holds in practice. As a byproduct, our results also lead to novel results for the synthetic controls literature, a leading approach for policy evaluation. To the best of our knowledge, our prediction guarantees for the fixed design setting have been elusive in both the high-dimensional error-in-variables and synthetic controls literatures.},
  archive      = {J_JMLR},
  author       = {Anish Agarwal and Devavrat Shah and Dennis Shen},
  journal      = {Journal of Machine Learning Research},
  number       = {117},
  pages        = {1-58},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On model identification and out-of-sample prediction of PCR with applications to synthetic controls},
  url          = {https://jmlr.org/papers/v26/23-0102.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian scalar-on-image regression with a spatially varying single-layer neural network prior. <em>JMLR</em>, <em>26</em>(116), 1-38. (<a href='https://jmlr.org/papers/v26/22-0246.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNN) have been widely used in scalar-on-image regression to predict an outcome variable from imaging predictors. However, training DNN typically requires large sample sizes for accurate prediction, and the resulting models often lack interpretability. In this work, we propose a novel Bayesian nonlinear scalar-on-image regression framework with a spatially varying single-layer neural network (SV-NN) prior. The SV-NN is constructed using a single hidden layer neural network with its weights generated by the soft-thresholded Gaussian process. Our framework enables the selection of interpretable image regions while achieving high prediction accuracy with limited training samples. The SV-NN offers large prior support for the imaging effect function, facilitating efficient posterior inference on image region selection and automatic network structures determination. We establish the posterior consistency for model parameters and selection consistency for image regions when the number of voxels/pixels grows much faster than the sample size. To ensure computational efficiency, we develop a stochastic gradient Langevin dynamics (SGLD) algorithm for posterior inference. We evaluate our method through extensive comparisons with state-of-the-art deep learning approaches, analyzing multiple real datasets, including task fMRI data from the Adolescent Brain Cognitive Development (ABCD) study.},
  archive      = {J_JMLR},
  author       = {Ben Wu and Keru Wu and Jian Kang},
  journal      = {Journal of Machine Learning Research},
  number       = {116},
  pages        = {1-38},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Bayesian scalar-on-image regression with a spatially varying single-layer neural network prior},
  url          = {https://jmlr.org/papers/v26/22-0246.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DRM revisited: A complete error analysis. <em>JMLR</em>, <em>26</em>(115), 1-76. (<a href='https://jmlr.org/papers/v26/24-1258.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is widely known that the error analysis for deep learning involves approximation, statistical, and optimization errors. However, it is challenging to combine them together due to overparameterization. In this paper, we address this gap by providing a comprehensive error analysis of the Deep Ritz Method (DRM). Specifically, we investigate a foundational question in the theoretical analysis of DRM under the overparameterized regime: given a target precision level, how can one determine the appropriate number of training samples, the key architectural parameters of the neural networks, the step size for the projected gradient descent optimization procedure, and the requisite number of iterations, such that the output of the gradient descent process closely approximates the true solution of the underlying partial differential equation to the specified precision?},
  archive      = {J_JMLR},
  author       = {Yuling Jiao and Ruoxuan Li and Peiying Wu and Jerry Zhijian Yang and Pingwen Zhang},
  journal      = {Journal of Machine Learning Research},
  number       = {115},
  pages        = {1-76},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {DRM revisited: A complete error analysis},
  url          = {https://jmlr.org/papers/v26/24-1258.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Principled penalty-based methods for bilevel reinforcement learning and RLHF. <em>JMLR</em>, <em>26</em>(114), 1-49. (<a href='https://jmlr.org/papers/v26/24-0720.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bilevel optimization has been recently applied to many machine learning tasks. However, their applications have been restricted to the supervised learning setting, where static objective functions with benign structures are considered. But bilevel problems such as incentive design, inverse reinforcement learning (RL), and RL from human feedback (RLHF) are often modeled as dynamic objective functions that go beyond the simple static objective structures, which pose significant challenges of using existing bilevel solutions. To tackle this new class of bilevel problems, we introduce the first principled algorithmic framework for solving bilevel RL problems through the lens of penalty formulation. We provide theoretical studies of the problem landscape and its penalty-based (policy) gradient algorithms. We demonstrate the effectiveness of our algorithms via simulations in the Stackelberg Markov game, RL from human feedback and incentive design.},
  archive      = {J_JMLR},
  author       = {Han Shen and Zhuoran Yang and Tianyi Chen},
  journal      = {Journal of Machine Learning Research},
  number       = {114},
  pages        = {1-49},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Principled penalty-based methods for bilevel reinforcement learning and RLHF},
  url          = {https://jmlr.org/papers/v26/24-0720.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Precise high-dimensional asymptotics for quantifying heterogeneous transfers. <em>JMLR</em>, <em>26</em>(113), 1-88. (<a href='https://jmlr.org/papers/v26/24-0454.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of learning one task using samples from another task is central to transfer learning. In this paper, we focus on answering the following question: when does combining the samples from two related tasks perform better than learning with one target task alone? This question is motivated by an empirical phenomenon known as negative transfer often observed in transfer learning practice. While the transfer effect from one task to another depends on factors such as their sample sizes and the spectrum of their covariance matrices, precisely quantifying this dependence has remained a challenging problem. In order to compare a transfer learning estimator to single-task learning, one needs to compare the risks between the two estimators precisely. Further, the comparison depends on the distribution shifts between the two tasks. This paper applies recent developments of random matrix theory to tackle this challenge in a high-dimensional linear regression setting with two tasks. We provide precise high-dimensional asymptotics for the bias and variance of a classical hard parameter sharing (HPS) estimator in the proportional limit, when the sample sizes of both tasks increase proportionally with dimension at fixed ratios. The precise asymptotics apply to various types of distribution shifts, including covariate shifts, model shifts, and combinations of both. We illustrate these results in a random-effects model to mathematically prove a phase transition from positive to negative transfer as the number of source task samples increases. One insight from the analysis is that a rebalanced HPS estimator, which downsizes the source task when the model shift is high, achieves the minimax optimal rate. The finding regarding phase transition also applies to multiple tasks when feature covariates are shared across all tasks. Simulations validate the accuracy of the high-dimensional asymptotics for finite dimensions.},
  archive      = {J_JMLR},
  author       = {Fan Yang and Hongyang R. Zhang and Sen Wu and Christopher Re and Weijie J. Su},
  journal      = {Journal of Machine Learning Research},
  number       = {113},
  pages        = {1-88},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Precise high-dimensional asymptotics for quantifying heterogeneous transfers},
  url          = {https://jmlr.org/papers/v26/24-0454.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Score-based causal representation learning: Linear and general transformations. <em>JMLR</em>, <em>26</em>(112), 1-90. (<a href='https://jmlr.org/papers/v26/24-0194.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses intervention-based causal representation learning (CRL) under a general nonparametric latent causal model and an unknown transformation that maps the latent variables to the observed variables. Linear and general transformations are investigated. The paper addresses both the identifiability and achievability aspects. Identifiability refers to determining algorithm-agnostic conditions that ensure the recovery of the true latent causal variables and the underlying latent causal graph. Achievability refers to the algorithmic aspects and addresses designing algorithms that achieve identifiability guarantees. By drawing novel connections between score functions (i.e., the gradients of the logarithm of density functions) and CRL, this paper designs a score-based class of algorithms that ensures both identifiability and achievability. First, the paper focuses on linear transformations and shows that one stochastic hard intervention per node suffices to guarantee identifiability. It also provides partial identifiability guarantees for soft interventions, including identifiability up to mixing with parents for general causal models and perfect recovery of the latent graph for sufficiently nonlinear causal models. Secondly, it focuses on general transformations and demonstrates that two stochastic hard interventions per node are sufficient for identifiability. This is achieved by defining a differentiable loss function whose global optima ensure identifiability for general CRL. Notably, one does not need to know which pair of interventional environments has the same node intervened. Finally, the theoretical results are empirically validated via experiments on structured synthetic data and image data.},
  archive      = {J_JMLR},
  author       = {Burak Var{{\i}}c{{\i}} and Emre Acartürk and Karthikeyan Shanmugam and Abhishek Kumar and Ali Tajer},
  journal      = {Journal of Machine Learning Research},
  number       = {112},
  pages        = {1-90},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Score-based causal representation learning: Linear and general transformations},
  url          = {https://jmlr.org/papers/v26/24-0194.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the statistical properties of generative adversarial models for low intrinsic data dimension. <em>JMLR</em>, <em>26</em>(111), 1-57. (<a href='https://jmlr.org/papers/v26/24-0054.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the remarkable empirical successes of Generative Adversarial Networks (GANs), the theoretical guarantees for their statistical accuracy remain rather pessimistic. In particular, the data distributions on which GANs are applied, such as natural images, are often hypothesized to have an intrinsic low-dimensional structure in a typically high-dimensional feature space, but this is often not reflected in the derived rates in the state-of-the-art analyses. In this paper, we attempt to bridge the gap between the theory and practice of GANs and their bidirectional variant, Bi-directional GANs (BiGANs), by deriving statistical guarantees on the estimated densities in terms of the intrinsic dimension of the data and the latent space. We analytically show that if one has access to $n$ samples from the unknown target distribution and the network architectures are properly chosen, the expected Wasserstein-1 distance of the estimates from the target scales as $O\left( n^{-1/d_\mu } \right)$ for GANs and $\tilde{O}\left( n^{-1/(d_\mu+\ell)} \right)$ for BiGANs, where $d_\mu$ and $\ell$ are the upper Wasserstein-1 dimension of the data-distribution and latent-space dimension, respectively. The theoretical analyses not only suggest that these methods successfully avoid the curse of dimensionality, in the sense that the exponent of $n$ in the error rates does not depend on the data dimension but also serve to bridge the gap between the theoretical analyses of GANs and the known sharp rates from optimal transport literature. Additionally, we demonstrate that GANs can effectively achieve the minimax optimal rate even for non-smooth underlying distributions, with the use of interpolating generator networks.},
  archive      = {J_JMLR},
  author       = {Saptarshi Chakraborty and Peter L. Bartlett},
  journal      = {Journal of Machine Learning Research},
  number       = {111},
  pages        = {1-57},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On the statistical properties of generative adversarial models for low intrinsic data dimension},
  url          = {https://jmlr.org/papers/v26/24-0054.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prominent roles of conditionally invariant components in domain adaptation: Theory and algorithms. <em>JMLR</em>, <em>26</em>(110), 1-92. (<a href='https://jmlr.org/papers/v26/23-1234.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation (DA) is a statistical learning problem that arises when the distribution of the source data used to train a model differs from that of the target data used to evaluate the model. While many DA algorithms have demonstrated considerable empirical success, blindly applying these algorithms can often lead to worse performance on new datasets. To address this, it is crucial to clarify the assumptions under which a DA algorithm has good target performance. In this work, we focus on the assumption of the presence of conditionally invariant components (CICs), which are relevant for prediction and remain conditionally invariant across the source and target data. We demonstrate that CICs, which can be estimated through conditional invariant penalty (CIP), play three prominent roles in providing target risk guarantees in DA. First, we propose a new algorithm based on CICs, importance-weighted conditional invariant penalty (IW-CIP), which has target risk guarantees beyond simple settings such as covariate shift and label shift. Second, we show that CICs help identify large discrepancies between source and target risks of other DA algorithms. Finally, we demonstrate that incorporating CICs into the domain invariant projection (DIP) algorithm can address its failure scenario caused by label-flipping features. We support our new algorithms and theoretical findings via numerical experiments on synthetic data, MNIST, CelebA, Camelyon17, and DomainNet datasets.},
  archive      = {J_JMLR},
  author       = {Keru Wu and Yuansi Chen and Wooseok Ha and Bin Yu},
  journal      = {Journal of Machine Learning Research},
  number       = {110},
  pages        = {1-92},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Prominent roles of conditionally invariant components in domain adaptation: Theory and algorithms},
  url          = {https://jmlr.org/papers/v26/23-1234.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Near-optimal nonconvex-strongly-convex bilevel optimization with fully first-order oracles. <em>JMLR</em>, <em>26</em>(109), 1-56. (<a href='https://jmlr.org/papers/v26/23-1104.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider bilevel optimization when the lower-level problem is strongly convex. Recent works show that with a Hessian-vector product (HVP) oracle, one can provably find an $\epsilon$-stationary point within ${O}(\epsilon^{-2})$ oracle calls. However, the HVP oracle may be inaccessible or expensive in practice. Kwon et al. (ICML 2023) addressed this issue by proposing a first-order method that can achieve the same goal at a slower rate of $\tilde{O}(\epsilon^{-3})$. In this paper, we incorporate a two-time-scale update to improve their method to achieve the near-optimal $\tilde{O}(\epsilon^{-2})$ first-order oracle complexity. Our analysis is highly extensible. In the stochastic setting, our algorithm can achieve the stochastic first-order oracle complexity of $\tilde {O}(\epsilon^{-4})$ and $\tilde {O}(\epsilon^{-6})$ when the stochastic noises are only in the upper-level objective and in both level objectives, respectively. When the objectives have higher-order smoothness conditions, our deterministic method can escape saddle points by injecting noise, and can be accelerated to achieve a faster rate of $\tilde {O}(\epsilon^{-1.75})$ using Nesterov's momentum.},
  archive      = {J_JMLR},
  author       = {Lesi Chen and Yaohua Ma and Jingzhao Zhang},
  journal      = {Journal of Machine Learning Research},
  number       = {109},
  pages        = {1-56},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Near-optimal nonconvex-strongly-convex bilevel optimization with fully first-order oracles},
  url          = {https://jmlr.org/papers/v26/23-1104.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive distributed kernel ridge regression: A feasible distributed learning scheme for data silos. <em>JMLR</em>, <em>26</em>(108), 1-54. (<a href='https://jmlr.org/papers/v26/23-0806.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data silos, mainly caused by privacy and interoperability, significantly constrain collaborations among different organizations with similar data for the same purpose. Distributed learning based on divide-and-conquer provides a promising way to settle the data silos, but it suffers from several challenges, including autonomy, privacy guarantees, and the necessity of collaborations. This paper focuses on developing an adaptive distributed kernel ridge regression (AdaDKRR) by taking autonomy in parameter selection, privacy in communicating non-sensitive information, and the necessity of collaborations for performance improvement into account. We provide both solid theoretical verifications and comprehensive experiments for AdaDKRR to demonstrate its feasibility and effectiveness. Theoretically, we prove that under some mild conditions, AdaDKRR performs similarly to running the optimal learning algorithms on the whole data, verifying the necessity of collaborations and showing that no other distributed learning scheme can essentially beat AdaDKRR under the same conditions. Numerically, we test AdaDKRR on both toy simulations and two real-world applications to show that AdaDKRR is superior to other existing distributed learning schemes. All these results show that AdaDKRR is a feasible scheme to overcome data silos, which are highly desired in numerous application regions such as intelligent decision-making, pricing forecasting, and performance prediction for products.},
  archive      = {J_JMLR},
  author       = {Shao-Bo Lin and Xiaotong Liu and Di Wang and Hai Zhang and Ding-Xuan Zhou},
  journal      = {Journal of Machine Learning Research},
  number       = {108},
  pages        = {1-54},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Adaptive distributed kernel ridge regression: A feasible distributed learning scheme for data silos},
  url          = {https://jmlr.org/papers/v26/23-0806.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On global and local convergence of iterative linear quadratic optimization algorithms for discrete time nonlinear control. <em>JMLR</em>, <em>26</em>(107), 1-85. (<a href='https://jmlr.org/papers/v26/22-1271.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A classical approach for solving discrete time nonlinear control on a finite horizon consists in repeatedly minimizing linear quadratic approximations of the original problem around current candidate solutions. While widely popular in many domains, such an approach has mainly been analyzed locally. We provide detailed convergence guarantees to stationary points as well as local linear convergence rates for the Iterative Linear Quadratic Regulator (ILQR) algorithm and its Differential Dynamic Programming (DDP) variant. For problems without costs on control variables, we observe that global convergence to minima can be ensured provided that the linearized discrete time dynamics are surjective, costs on the state variables are gradient dominated. We further detail quadratic local convergence when the costs are self-concordant. We show that surjectivity of the linearized dynamics hold for appropriate discretization schemes given the existence of a feedback linearization scheme. We present complexity bounds of algorithms based on linear quadratic approximations through the lens of generalized Gauss-Newton methods. Our analysis uncovers several convergence phases for regularized generalized Gauss-Newton algorithms.},
  archive      = {J_JMLR},
  author       = {Vincent Roulet and Siddhartha Srinivasa and Maryam Fazel and Zaid Harchaoui},
  journal      = {Journal of Machine Learning Research},
  number       = {107},
  pages        = {1-85},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On global and local convergence of iterative linear quadratic optimization algorithms for discrete time nonlinear control},
  url          = {https://jmlr.org/papers/v26/22-1271.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decentralized proximal gradient tracking algorithm for composite optimization on riemannian manifolds. <em>JMLR</em>, <em>26</em>(106), 1-37. (<a href='https://jmlr.org/papers/v26/24-1989.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on minimizing a smooth function combined with a nonsmooth regularization term on a compact Riemannian submanifold embedded in the Euclidean space under a decentralized setting. Typically, there are two types of approaches at present for tackling such composite optimization problems. The first, subgradient-based approaches, rely on subgradient information of the objective function to update variables, achieving an iteration complexity of $O(\epsilon^{-4}\log^2(\epsilon^{-2}))$. The second, smoothing approaches, involve constructing a smooth approximation of the nonsmooth regularization term, resulting in an iteration complexity of $O(\epsilon^{-4})$. This paper proposes a proximal gradient type algorithm that fully exploits the composite structure. The global convergence to a stationary point is established with a significantly improved iteration complexity of $O(\epsilon^{-2})$. To validate the effectiveness and efficiency of our proposed method, we present numerical results from real-world applications, showcasing its superior performance compared to existing approaches.},
  archive      = {J_JMLR},
  author       = {Lei Wang and Le Bao and Xin Liu},
  journal      = {Journal of Machine Learning Research},
  number       = {106},
  pages        = {1-37},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A decentralized proximal gradient tracking algorithm for composite optimization on riemannian manifolds},
  url          = {https://jmlr.org/papers/v26/24-1989.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning conditional distributions on continuous spaces. <em>JMLR</em>, <em>26</em>(105), 1-64. (<a href='https://jmlr.org/papers/v26/24-0924.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate sample-based learning of conditional distributions on multi-dimensional unit boxes, allowing for different dimensions of the feature and target spaces. Our approach involves clustering data near varying query points in the feature space to create empirical measures in the target space. We employ two distinct clustering schemes: one based on a fixed-radius ball and the other on nearest neighbors. We establish upper bounds for the convergence rates of both methods and, from these bounds, deduce optimal configurations for the radius and the number of neighbors. We propose to incorporate the nearest neighbors method into neural network training, as our empirical analysis indicates it has better performance in practice. For efficiency, our training process utilizes approximate nearest neighbors search with random binary space partitioning. Additionally, we employ the Sinkhorn algorithm and a sparsity-enforced transport plan. Our empirical findings demonstrate that, with a suitably designed structure, the neural network has the ability to adapt to a suitable level of Lipschitz continuity locally.},
  archive      = {J_JMLR},
  author       = {Cyril Benezet and Ziteng Cheng and Sebastian Jaimungal},
  journal      = {Journal of Machine Learning Research},
  number       = {105},
  pages        = {1-64},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Learning conditional distributions on continuous spaces},
  url          = {https://jmlr.org/papers/v26/24-0924.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified analysis of nonstochastic delayed feedback for combinatorial semi-bandits, linear bandits, and MDPs. <em>JMLR</em>, <em>26</em>(104), 1-60. (<a href='https://jmlr.org/papers/v26/24-0496.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We derive a new analysis of Follow The Regularized Leader (FTRL) for online learning with delayed bandit feedback. By separating the cost of delayed feedback from that of bandit feedback, our analysis allows us to obtain new results in four important settings. We derive the first optimal (up to logarithmic factors) regret bounds for combinatorial semi-bandits with delay and adversarial Markov Decision Processes with delay (both known and unknown transition functions). Furthermore, we use our analysis to develop an efficient algorithm for linear bandits with delay achieving near-optimal regret bounds. In order to derive these results we show that FTRL remains stable across multiple rounds under mild assumptions on the regularizer.},
  archive      = {J_JMLR},
  author       = {Lukas Zierahn and Dirk van der Hoeven and Tal Lancewicki and Aviv Rosenberg and Nicolò Cesa-Bianchi},
  journal      = {Journal of Machine Learning Research},
  number       = {104},
  pages        = {1-60},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A unified analysis of nonstochastic delayed feedback for combinatorial semi-bandits, linear bandits, and MDPs},
  url          = {https://jmlr.org/papers/v26/24-0496.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Error bounds for particle gradient descent, and extensions of the log-sobolev and talagrand inequalities. <em>JMLR</em>, <em>26</em>(103), 1-38. (<a href='https://jmlr.org/papers/v26/24-0437.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We derive non-asymptotic error bounds for particle gradient descent (PGD, Kuntz et al. (2023)), a recently introduced algorithm for maximum likelihood estimation of large latent variable models obtained by discretizing a gradient flow of the free energy. We begin by showing that the flow converges exponentially fast to the free energy's minimizers for models satisfying a condition that generalizes both the log-Sobolev and the Polyak--Łojasiewicz inequalities (LSI and PŁI, respectively). We achieve this by extending a result well-known in the optimal transport literature (that the LSI implies the Talagrand inequality) and its counterpart in the optimization literature (that the PŁI implies the so-called quadratic growth condition), and applying the extension to our new setting. We also generalize the Bakry--Émery Theorem and show that the LSI/PŁI extension holds for models with strongly concave log-likelihoods. For such models, we further control PGD's discretization error and obtain the non-asymptotic error bounds. While we are motivated by the study of PGD, we believe that the inequalities and results we extend may be of independent interest.},
  archive      = {J_JMLR},
  author       = {Rocco Caprio and Juan Kuntz and Samuel Power and Adam M. Johansen},
  journal      = {Journal of Machine Learning Research},
  number       = {103},
  pages        = {1-38},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Error bounds for particle gradient descent, and extensions of the log-sobolev and talagrand inequalities},
  url          = {https://jmlr.org/papers/v26/24-0437.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linear hypothesis testing in high-dimensional expected shortfall regression with heavy-tailed errors. <em>JMLR</em>, <em>26</em>(102), 1-54. (<a href='https://jmlr.org/papers/v26/24-0061.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expected shortfall (ES) is widely used for characterizing the tail of a distribution across various fields, particularly in financial risk management. In this paper, we explore a two-step procedure that leverages an orthogonality property to reduce sensitivity to nuisance parameters when estimating within a joint quantile and expected shortfall regression framework. For high-dimensional sparse models, we propose a robust $\ell_1$-penalized two-step approach capable of handling heavy-tailed data distributions. We establish non-asymptotic estimation error bounds and propose an appropriate growth rate for the diverging robustification parameter. To facilitate statistical inference for certain linear combinations of the ES regression coefficients, we construct debiased estimators and develop their asymptotic distributions, which form the basis for constructing valid confidence intervals. We validate the proposed method through simulation studies, demonstrating its effectiveness in high-dimensional linear models with heavy-tailed errors.},
  archive      = {J_JMLR},
  author       = {Gaoyu Wu and Jelena Bradic and Kean Ming Tan and Wen-Xin Zhou},
  journal      = {Journal of Machine Learning Research},
  number       = {102},
  pages        = {1-54},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Linear hypothesis testing in high-dimensional expected shortfall regression with heavy-tailed errors},
  url          = {https://jmlr.org/papers/v26/24-0061.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient numerical integration in reproducing kernel hilbert spaces via leverage scores sampling. <em>JMLR</em>, <em>26</em>(101), 1-55. (<a href='https://jmlr.org/papers/v26/23-1551.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we consider the problem of numerical integration, i.e., approximating integrals with respect to a target probability measure using only pointwise evaluations of the integrand. We focus on the setting in which the target distribution is only accessible through a set of $n$ i.i.d. observations, and the integrand belongs to a reproducing kernel Hilbert space. We propose an efficient procedure which exploits a small i.i.d. random subset of $m [abs] [ pdf ][ bib ] [ code ] &copy JMLR 2025. ( edit , beta )},
  archive      = {J_JMLR},
  author       = {Antoine Chatalic and Nicolas Schreuder and Ernesto De Vito and Lorenzo Rosasco},
  journal      = {Journal of Machine Learning Research},
  number       = {101},
  pages        = {1-55},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Efficient numerical integration in reproducing kernel hilbert spaces via leverage scores sampling},
  url          = {https://jmlr.org/papers/v26/23-1551.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distribution free tests for model selection based on maximum mean discrepancy with estimated parameters. <em>JMLR</em>, <em>26</em>(100), 1-52. (<a href='https://jmlr.org/papers/v26/23-1199.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There exist several testing procedures based on the maximum mean discrepancy (MMD) to address the challenge of model specification. However, these testing procedures ignore the presence of estimated parameters in the case of composite null hypotheses. In this paper, we first illustrate the effect of parameter estimation in model specification tests based on the MMD. Second, we propose simple model specification and model selection tests in the case of models with estimated parameters. All our tests are asymptotically standard normal under the null, even when the true underlying distribution belongs to the competing parametric families. A simulation study and a real data analysis illustrate the performance of our tests in terms of power and level.},
  archive      = {J_JMLR},
  author       = {Florian Brück and Jean-David Fermanian and Aleksey Min},
  journal      = {Journal of Machine Learning Research},
  number       = {100},
  pages        = {1-52},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Distribution free tests for model selection based on maximum mean discrepancy with estimated parameters},
  url          = {https://jmlr.org/papers/v26/23-1199.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Statistical field theory for markov decision processes under uncertainty. <em>JMLR</em>, <em>26</em>(99), 1-24. (<a href='https://jmlr.org/papers/v26/23-0905.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A statistical field theory is introduced for finite state and action Markov decision processes with unknown parameters, in a Bayesian setting. The Bellman equation, for policy evaluation and the optimal value function in finite and discounted infinite horizon problems, is studied as a disordered interacting dynamical system. The Markov decision process transition probabilities and mean-rewards are interpreted as quenched random variables and the value functions, or the iterates of the Bellman equation, are deterministic variables that evolve dynamically. The posterior over value functions is then equivalent to the quenched average of Fourier inverse of the Martin-Siggia-Rose-De Dominicis-Janssen generating function. The formalism enables the use of methods from field theory to compute posterior moments of value functions. The paper presents two such methods, corresponding to two distinct asymptotic limits. First, the classical approximation is applied, corresponding to the asymptotic data limit. This approximation recovers so-called plug-in estimators for the mean of the value functions. Second, a dynamic mean field theory is derived, showing that under certain assumptions the state-action values are statistically independent across state-action pairs in the asymptotic state space limit. The state-action value statistics can be computed from a set of self-consistent mean field equations, which we call dynamic mean field programming (DMFP). Collectively, the results provide analytic insight into the structure of model uncertainty in Markov decision processes, and pave the way toward more advanced field theoretic techniques and applications to planning and reinforcement learning problems.},
  archive      = {J_JMLR},
  author       = {George Stamatescu},
  journal      = {Journal of Machine Learning Research},
  number       = {99},
  pages        = {1-24},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Statistical field theory for markov decision processes under uncertainty},
  url          = {https://jmlr.org/papers/v26/23-0905.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian data sketching for varying coefficient regression models. <em>JMLR</em>, <em>26</em>(98), 1-29. (<a href='https://jmlr.org/papers/v26/23-0505.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Varying coefficient models are popular for estimating nonlinear regression functions in functional data models. Their Bayesian variants have received limited attention in large data applications, primarily due to prohibitively slow posterior computations using Markov chain Monte Carlo (MCMC) algorithms. We introduce Bayesian data sketching for varying coefficient models to obviate computational challenges presented by large sample sizes. To address the challenges of analyzing large data, we compress the functional response vector and predictor matrix by a random linear transformation to achieve dimension reduction and conduct inference on the compressed data. Our approach distinguishes itself from several existing methods for analyzing large functional data in that it requires neither the development of new models or algorithms nor any specialized computational hardware while delivering fully model-based Bayesian inference. Well-established methods and algorithms for varying-coefficient regression models can be applied to the compressed data. We establish posterior contraction rates for estimating the varying coefficients and predicting the outcome at new locations with the randomly compressed data model. We use simulation experiments and analyze remote sensed vegetation data to empirically illustrate the inferential and computational efficiency of our approach.},
  archive      = {J_JMLR},
  author       = {Rajarshi Guhaniyogi and Laura Baracaldo and Sudipto Banerjee},
  journal      = {Journal of Machine Learning Research},
  number       = {98},
  pages        = {1-29},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Bayesian data sketching for varying coefficient regression models},
  url          = {https://jmlr.org/papers/v26/23-0505.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bagged k-distance for mode-based clustering using the probability of localized level sets. <em>JMLR</em>, <em>26</em>(97), 1-62. (<a href='https://jmlr.org/papers/v26/22-1179.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an ensemble learning algorithm named bagged $k$-distance for mode-based clustering (BDMBC) by putting forward a new measure called the probability of localized level sets (PLLS), which enables us to find all clusters for varying densities with a global threshold. On the theoretical side, we show that with a properly chosen number of nearest neighbors $k_D$ in the bagged $k$-distance, the sub-sample size $s$, the bagging rounds $B$, and the number of nearest neighbors $k_L$ for the localized level sets, BDMBC can achieve optimal convergence rates for mode estimation. It turns out that with a relatively small $B$, the sub-sample size $s$ can be much smaller than the number of training data $n$ at each bagging round, and the number of nearest neighbors $k_D$ can be reduced simultaneously. Moreover, we establish fast convergence rates for the level set estimation of the PLLS in terms of Hausdorff distance, which reveals that BDMBC can find localized level sets for varying densities and thus enjoys local adaptivity. On the practical side, we conduct numerical experiments to empirically verify the effectiveness of BDMBC for mode estimation and level set estimation, which demonstrates the promising accuracy and efficiency of our proposed algorithm.},
  archive      = {J_JMLR},
  author       = {Hanyuan Hang},
  journal      = {Journal of Machine Learning Research},
  number       = {97},
  pages        = {1-62},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Bagged k-distance for mode-based clustering using the probability of localized level sets},
  url          = {https://jmlr.org/papers/v26/22-1179.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linear cost and exponentially convergent approximation of gaussian matérn processes on intervals. <em>JMLR</em>, <em>26</em>(96), 1-34. (<a href='https://jmlr.org/papers/v26/24-1779.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computational cost for inference and prediction of statistical models based on Gaussian processes with Matérn covariance functions scales cubically with the number of observations, limiting their applicability to large data sets. The cost can be reduced in certain special cases, but there are no generally applicable exact methods with linear cost. Several approximate methods have been introduced to reduce the cost, but most lack theoretical guarantees for accuracy. We consider Gaussian processes on bounded intervals with Matérn covariance functions and, for the first time, develop a generally applicable method with linear cost and a covariance error that decreases exponentially fast in the order $m$ of the proposed approximation. The method is based on an optimal rational approximation of the spectral density and results in an approximation that can be represented as a sum of $m$ independent Gaussian Markov processes, facilitating usage in general software for statistical inference. Besides theoretical justifications, we demonstrate accuracy empirically through carefully designed simulation studies, which show that the method outperforms state-of-the-art alternatives in accuracy for fixed computational cost in tasks like Gaussian process regression.},
  archive      = {J_JMLR},
  author       = {David Bolin and Vaibhav Mehandiratta and Alexandre B. Simas},
  journal      = {Journal of Machine Learning Research},
  number       = {96},
  pages        = {1-34},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Linear cost and exponentially convergent approximation of gaussian matérn processes on intervals},
  url          = {https://jmlr.org/papers/v26/24-1779.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Invariant subspace decomposition. <em>JMLR</em>, <em>26</em>(95), 1-56. (<a href='https://jmlr.org/papers/v26/24-0699.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the task of predicting a response $Y$ from a set of covariates $X$ in settings where the conditional distribution of $Y$ given $X$ changes over time. For this to be feasible, assumptions on how the conditional distribution changes over time are required. Existing approaches assume, for example, that changes occur smoothly over time so that short-term prediction using only the recent past becomes feasible. To additionally exploit observations further in the past, we propose a novel invariance-based framework for linear conditionals, called Invariant Subspace Decomposition (ISD), that splits the conditional distribution into a time-invariant and a residual time-dependent component. As we show, this decomposition can be employed both for zero-shot and time-adaptation prediction tasks, that is, settings where either no or a small amount of training data is available at the time points we want to predict $Y$ at, respectively. We propose a practical estimation procedure, which automatically infers the decomposition using tools from approximate joint matrix diagonalization. Furthermore, we provide finite sample guarantees for the proposed estimator and demonstrate empirically that it indeed improves on approaches that do not use the additional invariant structure.},
  archive      = {J_JMLR},
  author       = {Margherita Lazzaretto and Jonas Peters and Niklas Pfister},
  journal      = {Journal of Machine Learning Research},
  number       = {95},
  pages        = {1-56},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Invariant subspace decomposition},
  url          = {https://jmlr.org/papers/v26/24-0699.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Posterior concentrations of fully-connected bayesian neural networks with general priors on the weights. <em>JMLR</em>, <em>26</em>(94), 1-60. (<a href='https://jmlr.org/papers/v26/24-0425.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian approaches for training deep neural networks (BNNs) have received significant interest and have been effectively utilized in a wide range of applications. Several studies have examined the properties of posterior concentrations in BNNs. However, most of these studies focus solely on BNN models with sparse or heavy-tailed priors. Surprisingly, there are currently no theoretical results for BNNs using Gaussian priors, which are the most commonly used in practice. The lack of theory arises from the absence of approximation results of Deep Neural Networks (DNNs) that are non-sparse and have bounded parameters. In this paper, we present a new approximation theory for non-sparse DNNs with bounded parameters. Additionally, based on the approximation theory, we show that BNNs with non-sparse general priors can achieve near-minimax optimal posterior concentration rates around the true model.},
  archive      = {J_JMLR},
  author       = {Insung Kong and Yongdai Kim},
  journal      = {Journal of Machine Learning Research},
  number       = {94},
  pages        = {1-60},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Posterior concentrations of fully-connected bayesian neural networks with general priors on the weights},
  url          = {https://jmlr.org/papers/v26/24-0425.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Outlier robust and sparse estimation of linear regression coefficients. <em>JMLR</em>, <em>26</em>(93), 1-79. (<a href='https://jmlr.org/papers/v26/23-1583.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider outlier-robust and sparse estimation of linear regression coefficients, when the covariates and the noises are contaminated by adversarial outliers and noises are sampled from a heavy-tailed distribution. Our results present sharper error bounds under weaker assumptions than prior studies that share similar interests with this study. Our analysis relies on some sharp concentration inequalities resulting from generic chaining.},
  archive      = {J_JMLR},
  author       = {Takeyuki Sasai and Hironori Fujisawa},
  journal      = {Journal of Machine Learning Research},
  number       = {93},
  pages        = {1-79},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Outlier robust and sparse estimation of linear regression coefficients},
  url          = {https://jmlr.org/papers/v26/23-1583.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Affine rank minimization via asymptotic log-det iteratively reweighted least squares. <em>JMLR</em>, <em>26</em>(92), 1-44. (<a href='https://jmlr.org/papers/v26/23-0943.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The affine rank minimization problem is a well-known approach to matrix recovery. While there are various surrogates to this NP-hard problem, we prove that the asymptotic minimization of log-det objective functions indeed always reveals the desired, lowest-rank matrices---whereas such may or may not recover a sought-after ground truth. Concerning commonly applied methods such as iteratively reweighted least squares, one thus remains with two difficult to distinguish concerns: how problematic are local minima inherent to the approach truly; and opposingly, how influential instead is the numerical realization. We first show that comparable solution statements do not hold true for Schatten-$p$ functions, including the nuclear norm, and discuss the role of divergent minimizers. Subsequently, we outline corresponding implications for general optimization approaches as well as the more specific IRLS-$0$ algorithm, emphasizing through examples that the transition of the involved smoothing parameter to zero is frequently a more substantial issue than non-convexity. Lastly, we analyze several presented aspects empirically in a series of numerical experiments. In particular, allowing for instance sufficiently many iterations, one may even observe a phase transition for generic recoverability at the absolute theoretical minimum.},
  archive      = {J_JMLR},
  author       = {Sebastian Krämer},
  journal      = {Journal of Machine Learning Research},
  number       = {92},
  pages        = {1-44},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Affine rank minimization via asymptotic log-det iteratively reweighted least squares},
  url          = {https://jmlr.org/papers/v26/23-0943.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal effect of functional treatment. <em>JMLR</em>, <em>26</em>(91), 1-39. (<a href='https://jmlr.org/papers/v26/23-0381.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the causal effect with a functional treatment variable, where practical applications often arise in neuroscience, biomedical sciences, etc. Previous research concerning the effect of a functional variable on an outcome is typically restricted to exploring correlation rather than causality. The generalized propensity score, which is often used to calibrate the selection bias, is not directly applicable to a functional treatment variable due to a lack of definition of probability density function for functional data. We propose three estimators for the average dose-response functional based on the functional linear model, namely, the functional stabilized weight estimator, the outcome regression estimator and the doubly robust estimator, each of which has its own merits. We study their theoretical properties, which are corroborated through extensive numerical experiments. A real data application on electroencephalography data and disease severity demonstrates the practical value of our methods.},
  archive      = {J_JMLR},
  author       = {Ruoxu Tan and Wei Huang and Zheng Zhang and Guosheng Yin},
  journal      = {Journal of Machine Learning Research},
  number       = {91},
  pages        = {1-39},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Causal effect of functional treatment},
  url          = {https://jmlr.org/papers/v26/23-0381.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uplift model evaluation with ordinal dominance graphs. <em>JMLR</em>, <em>26</em>(90), 1-56. (<a href='https://jmlr.org/papers/v26/22-1455.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uplift modelling is a subfield of causal learning that focuses on ranking entities by individual treatment effects. Uplift models are typically evaluated using Qini curves or Qini scores. While intuitive, the theoretical grounding for Qini in the literature is limited, and the mathematical connection to the well-understood Receiver Operating Characteristic (ROC) curve is unclear. In this paper, we introduce pROCini, a novel uplift evaluation metric that improves upon Qini in two important ways. First, it explicitly incorporates more information by taking into account negative outcomes. Second, it leverages this additional information within the Ordinal Dominance Graph framework, which is the basis behind the well known ROC curve, resulting in a mathematically well-behaved metric that facilitates theoretical analysis. We derive confidence bounds for pROCini, exploiting its theoretical properties. Finally, we empirically validate the improved discriminative power of ROCini and pROCini in a simulation study as well as via experiments on real data.},
  archive      = {J_JMLR},
  author       = {Brecht Verbeken and Marie-Anne Guerry and Wouter Verbeke and Sam Verboven},
  journal      = {Journal of Machine Learning Research},
  number       = {90},
  pages        = {1-56},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Uplift model evaluation with ordinal dominance graphs},
  url          = {https://jmlr.org/papers/v26/22-1455.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-dimensional l2-boosting: Rate of convergence. <em>JMLR</em>, <em>26</em>(89), 1-54. (<a href='https://jmlr.org/papers/v26/21-0725.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Boosting is one of the most significant developments in machine learning. This paper studies the rate of convergence of L2-Boosting in a high-dimensional setting under early stopping. We close a gap in the literature and provide the rate of convergence of L2-Boosting in a high-dimensional setting under approximate sparsity and without beta-min condition. We also show that the rate of convergence of the classical L2-Boosting depends on the design matrix described by a sparse eigenvalue condition. To show the latter results, we derive new, improved approximation results for the pure greedy algorithm, based on analyzing the revisiting behavior of L2-Boosting. These results might be of independent interest. Moreover, we introduce so-called "restricted" L2-Boosting. The restricted L2-Boosting algorithm sticks to the set of the previously chosen variables, exploits the information contained in these variables first and then only occasionally allows to add new variables to this set. We derive the rate of convergence for restricted L2-Boosting under early stopping which is close to the convergence rate of Lasso in an approximate sparse, high-dimensional setting without beta-min condition. We also introduce feasible rules for early stopping, which can be easily implemented and used in applied work. Finally, we present simulation studies to illustrate the relevance of our theoretical results and to provide insights into the practical aspects of boosting. In these simulation studies, L2-Boosting clearly outperforms Lasso. An empirical illustration and the proofs are contained in the Appendix.},
  archive      = {J_JMLR},
  author       = {Ye Luo and Martin Spindler and Jannis Kueck},
  journal      = {Journal of Machine Learning Research},
  number       = {89},
  pages        = {1-54},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {High-dimensional l2-boosting: Rate of convergence},
  url          = {https://jmlr.org/papers/v26/21-0725.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature learning in finite-width bayesian deep linear networks with multiple outputs and convolutional layers. <em>JMLR</em>, <em>26</em>(88), 1-35. (<a href='https://jmlr.org/papers/v26/24-1158.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep linear networks have been extensively studied, as they provide simplified models of deep learning. However, little is known in the case of finite-width architectures with multiple outputs and convolutional layers. In this manuscript, we provide rigorous results for the statistics of functions implemented by the aforementioned class of networks, thus moving closer to a complete characterization of feature learning in the Bayesian setting. Our results include: (i) an exact and elementary non-asymptotic integral representation for the joint prior distribution over the outputs, given in terms of a mixture of Gaussians; (ii) an analytical formula for the posterior distribution in the case of squared error loss function (Gaussian likelihood); (iii) a quantitative description of the feature learning infinite-width regime, using large deviation theory. From a physical perspective, deep architectures with multiple outputs or convolutional layers represent different manifestations of kernel shape renormalization, and our work provides a dictionary that translates this physics intuition and terminology into rigorous Bayesian statistics.},
  archive      = {J_JMLR},
  author       = {Federico Bassetti and Marco Gherardi and Alessandro Ingrosso and Mauro Pastore and Pietro Rotondo},
  journal      = {Journal of Machine Learning Research},
  number       = {88},
  pages        = {1-35},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Feature learning in finite-width bayesian deep linear networks with multiple outputs and convolutional layers},
  url          = {https://jmlr.org/papers/v26/24-1158.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How good is your laplace approximation of the bayesian posterior? finite-sample computable error bounds for a variety of useful divergences. <em>JMLR</em>, <em>26</em>(87), 1-81. (<a href='https://jmlr.org/papers/v26/24-0619.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Laplace approximation is a popular method for constructing a Gaussian approximation to the Bayesian posterior and thereby approximating the posterior mean and variance. But approximation quality is a concern. One might consider using rate-of-convergence bounds from certain versions of the Bayesian Central Limit Theorem (BCLT) to provide quality guarantees. But existing bounds require assumptions that are unrealistic even for relatively simple real-life Bayesian analyses; more specifically, existing bounds either (1) require knowing the true data-generating parameter, (2) are asymptotic in the number of samples, (3) do not control the Bayesian posterior mean, or (4) require strongly log concave models to compute. In this work, we provide the first computable bounds on quality that simultaneously (1) do not require knowing the true parameter, (2) apply to finite samples, (3) control posterior means and variances, and (4) apply generally to models that satisfy the conditions of the asymptotic BCLT. Moreover, we substantially improve the dimension dependence of existing bounds; in fact, we achieve the lowest-order dimension dependence possible in the general case. We compute exact constants in our bounds for a variety of standard models, including logistic regression, and numerically demonstrate their utility. We provide a framework for analysis of more complex models.},
  archive      = {J_JMLR},
  author       = {Mikołaj J. Kasprzak and Ryan Giordano and Tamara Broderick},
  journal      = {Journal of Machine Learning Research},
  number       = {87},
  pages        = {1-81},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {How good is your laplace approximation of the bayesian posterior? finite-sample computable error bounds for a variety of useful divergences},
  url          = {https://jmlr.org/papers/v26/24-0619.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integral probability metrics meet neural networks: The radon-kolmogorov-smirnov test. <em>JMLR</em>, <em>26</em>(86), 1-57. (<a href='https://jmlr.org/papers/v26/24-0245.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integral probability metrics (IPMs) constitute a general class of nonparametric two-sample tests that are based on maximizing the mean difference between samples from one distribution $P$ versus another $Q$, over all choices of data transformations $f$ living in some function space $\mathcal{F}$. Inspired by recent work that connects what are known as functions of Radon bounded variation (RBV) and neural networks (Parhi and Nowak, 2021, 2023), we study the IPM defined by taking $\mathcal{F}$ to be the unit ball in the RBV space of a given smoothness degree $k \geq 0$. This test, which we refer to as the Radon-Kolmogorov-Smirnov (RKS) test, can be viewed as a generalization of the well-known and classical Kolmogorov-Smirnov (KS) test to multiple dimensions and higher orders of smoothness. It is also intimately connected to neural networks: we prove that the witness in the RKS test—the function $f$ achieving the maximum mean difference—is always a ridge spline of degree $k$, i.e., a single neuron in a neural network. We can thus leverage the power of modern neural network optimization toolkits to (approximately) maximize the criterion that underlies the RKS test. We prove that the RKS test has asymptotically full power at distinguishing any distinct pair $P \not= Q$ of distributions, derive its asymptotic null distribution, and carry out experiments to elucidate the strengths and weaknesses of the RKS test versus the more traditional kernel MMD test.},
  archive      = {J_JMLR},
  author       = {Seunghoon Paik and Michael Celentano and Alden Green and Ryan J. Tibshirani},
  journal      = {Journal of Machine Learning Research},
  number       = {86},
  pages        = {1-57},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Integral probability metrics meet neural networks: The radon-kolmogorov-smirnov test},
  url          = {https://jmlr.org/papers/v26/24-0245.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On inference for the support vector machine. <em>JMLR</em>, <em>26</em>(85), 1-54. (<a href='https://jmlr.org/papers/v26/23-1581.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The linear support vector machine has a parametrised decision boundary. The paper considers inference for the corresponding parameters, which indicate the effects of individual variables on the decision boundary. The proposed inference is via a convolution-smoothed version of the SVM loss function, this having several inferential advantages over the original SVM, whose associated loss function is not everywhere differentiable. Notably, convolution-smoothing comes with non-asymptotic theoretical guarantees, including a distributional approximation to the parameter estimator that scales more favourably with the dimension of the feature vector. The differentiability of the loss function produces other advantages in some settings; for instance, by facilitating the inclusion of penalties or the synthesis of information from a large number of small samples. The paper closes by relating the linear SVM parameters to those of some probability models for binary outcomes.},
  archive      = {J_JMLR},
  author       = {Jakub Rybak and Heather Battey and Wen-Xin Zhou},
  journal      = {Journal of Machine Learning Research},
  number       = {85},
  pages        = {1-54},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On inference for the support vector machine},
  url          = {https://jmlr.org/papers/v26/23-1581.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Random pruning over-parameterized neural networks can improve generalization: A training dynamics analysis. <em>JMLR</em>, <em>26</em>(84), 1-51. (<a href='https://jmlr.org/papers/v26/23-0832.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been observed that applying pruning-at-initialization methods and training the sparse networks can sometimes yield slightly better test performance than training the original dense network. Such experimental observations are yet to be understood theoretically. This work makes the first attempt to study this phenomenon. Specifically, we identify a theoretical minimal setting and study a classification task with a one-hidden-layer neural network, which is randomly pruned according to different rates at the initialization. We show that as long as the pruning rate is below a certain threshold, the network provably exhibits good generalization performance after training.More surprisingly, the generalization bound gets better as the pruning rate mildly gets larger. To complement this positive result, we also show a negative result: there exists a large pruning rate such that while gradient descent is still able to drive the training loss toward zero, the generalization performance is no better than random guessing. This further suggests that pruning can change the feature learning process, which leads to the performance drop of the pruned neural network. To our knowledge, this is the first theory work studying how different pruning rates affect neural networks' performance, suggesting that an appropriate pruning rate might improve the neural network's generalization.},
  archive      = {J_JMLR},
  author       = {Hongru Yang and Yingbin Liang and Xiaojie Guo and Lingfei Wu and Zhangyang Wang},
  journal      = {Journal of Machine Learning Research},
  number       = {84},
  pages        = {1-51},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Random pruning over-parameterized neural networks can improve generalization: A training dynamics analysis},
  url          = {https://jmlr.org/papers/v26/23-0832.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal abstraction: A theoretical foundation for mechanistic interpretability. <em>JMLR</em>, <em>26</em>(83), 1-64. (<a href='https://jmlr.org/papers/v26/23-0058.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal abstraction provides a theoretical foundation for mechanistic interpretability, the field concerned with providing intelligible algorithms that are faithful simplifications of the known, but opaque low-level details of black box AI models. Our contributions are (1) generalizing the theory of causal abstraction from mechanism replacement (i.e., hard and soft interventions) to arbitrary mechanism transformation (i.e., functionals from old mechanisms to new mechanisms), (2) providing a flexible, yet precise formalization for the core concepts of polysemantic neurons, the linear representation hypothesis, modular features, and graded faithfulness, and (3) unifying a variety of mechanistic interpretability methods in the common language of causal abstraction, namely, activation and path patching, causal mediation analysis, causal scrubbing, causal tracing, circuit analysis, concept erasure, sparse autoencoders, differential binary masking, distributed alignment search, and steering.},
  archive      = {J_JMLR},
  author       = {Atticus Geiger and Duligur Ibeling and Amir Zur and Maheep Chaudhary and Sonakshi Chauhan and Jing Huang and Aryaman Arora and Zhengxuan Wu and Noah Goodman and Christopher Potts and Thomas Icard},
  journal      = {Journal of Machine Learning Research},
  number       = {83},
  pages        = {1-64},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Causal abstraction: A theoretical foundation for mechanistic interpretability},
  url          = {https://jmlr.org/papers/v26/23-0058.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Implicit vs unfolded graph neural networks. <em>JMLR</em>, <em>26</em>(82), 1-46. (<a href='https://jmlr.org/papers/v26/22-0459.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been observed that message-passing graph neural networks (GNN) sometimes struggle to maintain a healthy balance between the efficient / scalable modeling of long-range dependencies across nodes while avoiding unintended consequences such oversmoothed node representations, sensitivity to spurious edges, or inadequate model interpretability. To address these and other issues, two separate strategies have recently been proposed, namely implicit and unfolded GNNs (that we abbreviate to IGNN and UGNN respectively). The former treats node representations as the fixed points of a deep equilibrium model that can efficiently facilitate arbitrary implicit propagation across the graph with a fixed memory footprint. In contrast, the latter involves treating graph propagation as unfolded descent iterations as applied to some graph-regularized energy function. While motivated differently, in this paper we carefully quantify explicit situations where the solutions they produce are equivalent and others where their properties sharply diverge. This includes the analysis of convergence, representational capacity, and interpretability. In support of this analysis, we also provide empirical head-to-head comparisons across multiple synthetic and public real-world node classification benchmarks. These results indicate that while IGNN is substantially more memory-efficient, UGNN models support unique, integrated graph attention mechanisms and propagation rules that can achieve strong node classification accuracy across disparate regimes such as adversarially-perturbed graphs, graphs with heterophily, and graphs involving long-range dependencies.},
  archive      = {J_JMLR},
  author       = {Yongyi Yang and Tang Liu and Yangkun Wang and Zengfeng Huang and David Wipf},
  journal      = {Journal of Machine Learning Research},
  number       = {82},
  pages        = {1-46},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Implicit vs unfolded graph neural networks},
  url          = {https://jmlr.org/papers/v26/22-0459.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards optimal branching of linear and semidefinite relaxations for neural network robustness certification. <em>JMLR</em>, <em>26</em>(81), 1-59. (<a href='https://jmlr.org/papers/v26/21-0068.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study certifying the robustness of ReLU neural networks against adversarial input perturbations. To diminish the relaxation error suffered by the popular linear programming (LP) and semidefinite programming (SDP) certification methods, we take a branch-and-bound approach to propose partitioning the input uncertainty set and solving the relaxations on each part separately. We show that this approach reduces relaxation error, and that the error is eliminated entirely upon performing an LP relaxation with a partition intelligently designed to exploit the nature of the ReLU activations. To scale this approach to large networks, we consider using a coarser partition whereby the number of parts in the partition is reduced. We prove that computing such a coarse partition that directly minimizes the LP relaxation error is NP-hard. By instead minimizing the worst-case LP relaxation error, we develop a closed-form branching scheme in the single-hidden layer case. We extend the analysis to the SDP, where the feasible set geometry is exploited to design a branching scheme that minimizes the worst-case SDP relaxation error. Experiments on MNIST, CIFAR-10, and Wisconsin breast cancer diagnosis classifiers demonstrate significant increases in the percentages of test samples certified. By independently increasing the input size and the number of layers, we empirically illustrate under which regimes the branched LP and branched SDP are best applied. Finally, we extend our LP branching method into a multi-layer branching heuristic, which attains comparable performance to prior state-of-the-art heuristics on large-scale, deep neural network certification benchmarks.},
  archive      = {J_JMLR},
  author       = {Brendon G. Anderson and Ziye Ma and Jingqi Li and Somayeh Sojoudi},
  journal      = {Journal of Machine Learning Research},
  number       = {81},
  pages        = {1-59},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Towards optimal branching of linear and semidefinite relaxations for neural network robustness certification},
  url          = {https://jmlr.org/papers/v26/21-0068.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GraphNeuralNetworks.jl: Deep learning on graphs with julia. <em>JMLR</em>, <em>26</em>(80), 1-6. (<a href='https://jmlr.org/papers/v26/24-2130.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {GraphNeuralNetworks.jl is an open-source framework for deep learning on graphs, written in the Julia programming language. It supports multiple GPU backends, generic sparse or dense graph representations, and offers convenient interfaces for manipulating standard, heterogeneous, and temporal graphs with attributes at the node, edge, and graph levels. The framework allows users to define custom graph convolutional layers using gather/scatter message-passing primitives or optimized fused operations. It also includes several popular layers, enabling efficient experimentation with complex deep architectures. The package is available on GitHub: https://github.com/JuliaGraphs/GraphNeuralNetworks.jl.},
  archive      = {J_JMLR},
  author       = {Carlo Lucibello and Aurora Rossi},
  journal      = {Journal of Machine Learning Research},
  number       = {80},
  pages        = {1-6},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {GraphNeuralNetworks.jl: Deep learning on graphs with julia},
  url          = {https://jmlr.org/papers/v26/24-2130.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic angular synchronization under smoothness constraints. <em>JMLR</em>, <em>26</em>(79), 1-45. (<a href='https://jmlr.org/papers/v26/24-0925.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an undirected measurement graph $\mathcal{H} = ([n], \mathcal{E})$, the classical angular synchronization problem consists of recovering unknown angles $\theta_1^*,\dots,\theta_n^*$ from a collection of noisy pairwise measurements of the form $(\theta_i^* - \theta_j^*) \mod 2\pi$, for all $\{i,j\} \in \mathcal{E}$. This problem arises in a variety of applications, including computer vision, time synchronization of distributed networks, and ranking from pairwise comparisons. In this paper, we consider a dynamic version of this problem where the angles, and also the measurement graphs evolve over $T$ time points. Assuming a smoothness condition on the evolution of the latent angles, we derive three algorithms for joint estimation of the angles over all time points. Moreover, for one of the algorithms, we establish non-asymptotic recovery guarantees for the mean-squared error (MSE) under different statistical models. In particular, we show that the MSE converges to zero as $T$ increases under milder conditions than in the static setting. This includes the setting where the measurement graphs are highly sparse and disconnected, and also when the measurement noise is large and can potentially increase with $T$. We complement our theoretical results with experiments on synthetic data.},
  archive      = {J_JMLR},
  author       = {Ernesto Araya and Mihai Cucuringu and Hemant Tyagi},
  journal      = {Journal of Machine Learning Research},
  number       = {79},
  pages        = {1-45},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Dynamic angular synchronization under smoothness constraints},
  url          = {https://jmlr.org/papers/v26/24-0925.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Derivative-informed neural operator acceleration of geometric MCMC for infinite-dimensional bayesian inverse problems. <em>JMLR</em>, <em>26</em>(78), 1-68. (<a href='https://jmlr.org/papers/v26/24-0745.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an operator learning approach to accelerate geometric Markov chain Monte Carlo (MCMC) for solving infinite-dimensional Bayesian inverse problems (BIPs). While geometric MCMC employs high-quality proposals that adapt to posterior local geometry, it requires repeated computations of gradients and Hessians of the log-likelihood, which becomes prohibitive when the parameter-to-observable (PtO) map is defined through expensive-to-solve parametric partial differential equations (PDEs). We consider a delayed-acceptance geometric MCMC method driven by a neural operator surrogate of the PtO map, where the proposal exploits fast surrogate predictions of the log-likelihood and, simultaneously, its gradient and Hessian. To achieve a substantial speedup, the surrogate must accurately approximate the PtO map and its Jacobian, which often demands a prohibitively large number of PtO map samples via conventional operator learning methods. In this work, we present an extension of derivative-informed operator learning [O'Leary-Roseberry et al., J. Comput. Phys., 496 (2024)] that uses joint samples of the PtO map and its Jacobian. This leads to derivative-informed neural operator (DINO) surrogates that accurately predict the observables and posterior local geometry at a significantly lower training cost than conventional methods. Cost and error analysis for reduced basis DINO surrogates are provided. Numerical studies demonstrate that DINO-driven MCMC generates effective posterior samples 3--9 times faster than geometric MCMC and 60--97 times faster than prior geometry-based MCMC. Furthermore, the training cost of DINO surrogates breaks even compared to geometric MCMC after just 10--25 effective posterior samples.},
  archive      = {J_JMLR},
  author       = {Lianghao Cao and Thomas O'Leary-Roseberry and Omar Ghattas},
  journal      = {Journal of Machine Learning Research},
  number       = {78},
  pages        = {1-68},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Derivative-informed neural operator acceleration of geometric MCMC for infinite-dimensional bayesian inverse problems},
  url          = {https://jmlr.org/papers/v26/24-0745.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wasserstein F-tests for frechet regression on bures-wasserstein manifolds. <em>JMLR</em>, <em>26</em>(77), 1-123. (<a href='https://jmlr.org/papers/v26/24-0493.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses regression analysis for covariance matrix-valued outcomes with Euclidean covariates, motivated by applications in single-cell genomics and neuroscience where covariance matrices are observed across many samples. Our analysis leverages Fr\'echet regression on the Bures-Wasserstein manifold to estimate the conditional Fr\'echet mean given covariates $x$. We establish a non-asymptotic uniform $\sqrt{n}$-rate of convergence (up to logarithmic factors) over covariates with $\|x\| \lesssim \sqrt{\log n}$ and derive a pointwise central limit theorem to enable statistical inference. For testing covariate effects, we devise a novel test whose null distribution converges to a weighted sum of independent chi-square distributions, with power guarantees against a sequence of contiguous alternatives. Simulations validate the accuracy of the asymptotic theory. Finally, we apply our methods to a single-cell gene expression dataset, revealing age-related changes in gene co-expression networks.},
  archive      = {J_JMLR},
  author       = {Haoshu Xu and Hongzhe Li},
  journal      = {Journal of Machine Learning Research},
  number       = {77},
  pages        = {1-123},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Wasserstein F-tests for frechet regression on bures-wasserstein manifolds},
  url          = {https://jmlr.org/papers/v26/24-0493.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed stochastic bilevel optimization: Improved complexity and heterogeneity analysis. <em>JMLR</em>, <em>26</em>(76), 1-58. (<a href='https://jmlr.org/papers/v26/24-0187.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers solving a class of nonconvex-strongly-convex distributed stochastic bilevel optimization (DSBO) problems with personalized inner-level objectives. Most existing algorithms require computational loops for hypergradient estimation, leading to computational inefficiency. Moreover, the impact of data heterogeneity on convergence in bilevel problems is not explicitly characterized yet. To address these issues, we propose LoPA, a loopless personalized distributed algorithm that leverages a tracking mechanism for iterative approximation of inner-level solutions and Hessian-inverse matrices without relying on extra computation loops. Our theoretical analysis explicitly characterizes the heterogeneity across nodes (denoted by $b$), and establishes a sublinear rate of $\mathcal{O}( {\frac{1}{{{{\left( {1 - \rho } \right)}}K}}\!+ \!\frac{{(\frac{b}{\sqrt{m}})^{\frac{2}{3}} }}{{\left( {1 - \rho } \right)^{\frac{2}{3}} K^{\frac{2}{3}} }} \!+ \!\frac{1}{\sqrt{ K }}( {\sigma _{\operatorname{p} }} + \frac{1}{\sqrt{m}}{\sigma _{\operatorname{c} }} ) } )$ without the boundedness of local hypergradients, where ${\sigma _{\operatorname{p} }}$ and ${\sigma _{\operatorname{c} }}$ represent the gradient sampling variances associated with the inner- and outer-level variables, respectively. We also integrate LoPA with a gradient tracking scheme to eliminate the impact of data heterogeneity, yielding an improved rate of ${{\mathcal{O}}}(\frac{{1}}{{ (1-\rho)^2K }} \!+\! \frac{1}{{\sqrt{K}}}( \sigma_{\rm{p}} \!+\! \frac{1}{\sqrt{m}}\sigma_{\rm{c}} ) )$. The computational complexity of LoPA is of ${{\mathcal{O}}}({\epsilon^{-2}})$ to an $\epsilon$-stationary point, matching the communication complexity due to the loopless structure, which outperforms existing counterparts for DSBO. Numerical experiments validate the effectiveness of the proposed algorithm.},
  archive      = {J_JMLR},
  author       = {Youcheng Niu and Jinming Xu and Ying Sun and Yan Huang and Li Chai},
  journal      = {Journal of Machine Learning Research},
  number       = {76},
  pages        = {1-58},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Distributed stochastic bilevel optimization: Improved complexity and heterogeneity analysis},
  url          = {https://jmlr.org/papers/v26/24-0187.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning causal graphs via nonlinear sufficient dimension reduction. <em>JMLR</em>, <em>26</em>(75), 1-46. (<a href='https://jmlr.org/papers/v26/24-0048.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new nonparametric methodology for estimating a directed acyclic graph (DAG) from observational data. Our method is nonparametric in nature: it does not impose any specific form on the joint distribution of the underlying DAG. Instead, it relies on a linear operator on reproducing kernel Hilbert spaces to evaluate conditional independence. However, a fully nonparametric approach would involve conditioning on a large number of random variables, subjecting it to the curse of dimensionality. To solve this problem, we apply nonlinear sufficient dimension reduction to reduce the number of variables before evaluating the conditional independence. We develop an estimator for the DAG, based on a linear operator that characterizes conditional independence, and establish the consistency and convergence rates of this estimator, as well as the uniform consistency of the estimated Markov equivalence class. We introduce a modified PC-algorithm to implement the estimating procedure efficiently such that the complexity depends on the sparseness of the underlying true DAG. We demonstrate the effectiveness of our methodology through simulations and a real data analysis.},
  archive      = {J_JMLR},
  author       = {Eftychia Solea and Bing Li and Kyongwon Kim},
  journal      = {Journal of Machine Learning Research},
  number       = {75},
  pages        = {1-46},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Learning causal graphs via nonlinear sufficient dimension reduction},
  url          = {https://jmlr.org/papers/v26/24-0048.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On consistent bayesian inference from synthetic data. <em>JMLR</em>, <em>26</em>(74), 1-65. (<a href='https://jmlr.org/papers/v26/23-1428.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating synthetic data, with or without differential privacy, has attracted significant attention as a potential solution to the dilemma between making data easily available, and the privacy of data subjects. Several works have shown that consistency of downstream analyses from synthetic data, including accurate uncertainty estimation, requires accounting for the synthetic data generation. There are very few methods of doing so, most of them for frequentist analysis. In this paper, we study how to perform consistent Bayesian inference from synthetic data. We prove that mixing posterior samples obtained separately from multiple large synthetic data sets, that are sampled from a posterior predictive, converges to the posterior of the downstream analysis under standard regularity conditions when the analyst's model is compatible with the data provider's model. We also present several examples showing how the theory works in practice, and showing how Bayesian inference can fail when the compatibility assumption is not met, or the synthetic data set is not significantly larger than the original.},
  archive      = {J_JMLR},
  author       = {Ossi Räisä and Joonas Jälkö and Antti Honkela},
  journal      = {Journal of Machine Learning Research},
  number       = {74},
  pages        = {1-65},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On consistent bayesian inference from synthetic data},
  url          = {https://jmlr.org/papers/v26/23-1428.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization over a probability simplex. <em>JMLR</em>, <em>26</em>(73), 1-35. (<a href='https://jmlr.org/papers/v26/23-1166.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new iteration scheme, the Cauchy-Simplex, to optimize convex problems over the probability simplex $\{w\in\mathbb{R}^n\ |\ \sum_i w_i=1\ \textrm{and}\ w_i\geq0\}$. Specifically, we map the simplex to the positive quadrant of a unit sphere, envisage gradient descent in latent variables, and map the result back in a way that only depends on the simplex variable. Moreover, proving rigorous convergence results in this formulation leads inherently to tools from information theory (e.g., cross-entropy and KL divergence). Each iteration of the Cauchy-Simplex consists of simple operations, making it well-suited for high-dimensional problems. In continuous time, we prove that $f(x_T)-f(x^*) = O(1/T)$ for differentiable real-valued convex functions, where $T$ is the number of time steps and $w^*$ is the optimal solution. Numerical experiments of projection onto convex hulls show faster convergence than similar algorithms. Finally, we apply our algorithm to online learning problems and prove the convergence of the average regret for (1) Prediction with expert advice and (2) Universal Portfolios.},
  archive      = {J_JMLR},
  author       = {James Chok and Geoffrey M. Vasil},
  journal      = {Journal of Machine Learning Research},
  number       = {73},
  pages        = {1-35},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Optimization over a probability simplex},
  url          = {https://jmlr.org/papers/v26/23-1166.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Laplace meets moreau: Smooth approximation to infimal convolutions using laplace's method. <em>JMLR</em>, <em>26</em>(72), 1-36. (<a href='https://jmlr.org/papers/v26/24-0944.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study approximations to the Moreau envelope---and infimal convolutions more broadly---based on Laplace's method, a classical tool in analysis which ties certain integrals to suprema of their integrands. We believe the connection between Laplace's method and infimal convolutions is generally deserving of more attention in the study of optimization and partial differential equations, since it bears numerous potentially important applications, from proximal-type algorithms to Hamilton-Jacobi equations.},
  archive      = {J_JMLR},
  author       = {Ryan J. Tibshirani and Samy Wu Fung and Howard Heaton and Stanley Osher},
  journal      = {Journal of Machine Learning Research},
  number       = {72},
  pages        = {1-36},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Laplace meets moreau: Smooth approximation to infimal convolutions using laplace's method},
  url          = {https://jmlr.org/papers/v26/24-0944.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sampling and estimation on manifolds using the langevin diffusion. <em>JMLR</em>, <em>26</em>(71), 1-50. (<a href='https://jmlr.org/papers/v26/24-0829.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Error bounds are derived for sampling and estimation using a discretization of an intrinsically defined Langevin diffusion with invariant measure $\text{d}\mu_\phi \propto e^{-\phi} \mathrm{dvol}_g $ on a compact Riemannian manifold. Two estimators of linear functionals of $\mu_\phi $ based on the discretized Markov process are considered: a time-averaging estimator based on a single trajectory and an ensemble-averaging estimator based on multiple independent trajectories. Imposing no restrictions beyond a nominal level of smoothness on $\phi$, first-order error bounds, in discretization step size, on the bias and variance/mean-square error of both estimators are derived. The order of error matches the optimal rate in Euclidean and flat spaces, and leads to a first-order bound on distance between the invariant measure $\mu_\phi$ and a stationary measure of the discretized Markov process. This order is preserved even upon using retractions when exponential maps are unavailable in closed form, thus enhancing practicality of the proposed algorithms. Generality of the proof techniques, which exploit links between two partial differential equations and the semigroup of operators corresponding to the Langevin diffusion, renders them amenable for the study of a more general class of sampling algorithms related to the Langevin diffusion. Conditions for extending analysis to the case of non-compact manifolds are discussed. Numerical illustrations with distributions, log-concave and otherwise, on the manifolds of positive and negative curvature elucidate on the derived bounds and demonstrate practical utility of the sampling algorithm.},
  archive      = {J_JMLR},
  author       = {Karthik Bharath and Alexander Lewis and Akash Sharma and Michael V. Tretyakov},
  journal      = {Journal of Machine Learning Research},
  number       = {71},
  pages        = {1-50},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Sampling and estimation on manifolds using the langevin diffusion},
  url          = {https://jmlr.org/papers/v26/24-0829.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sharp bounds for sequential federated learning on heterogeneous data. <em>JMLR</em>, <em>26</em>(70), 1-55. (<a href='https://jmlr.org/papers/v26/24-0668.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are two paradigms in Federated Learning (FL): parallel FL (PFL), where models are trained in a parallel manner across clients, and sequential FL (SFL), where models are trained in a sequential manner across clients. Specifically, in PFL, clients perform local updates independently and send the updated model parameters to a global server for aggregation; in SFL, one client starts its local updates only after receiving the model parameters from the previous client in the sequence. In contrast to that of PFL, the convergence theory of SFL on heterogeneous data is still lacking. To resolve the theoretical dilemma of SFL, we establish sharp convergence guarantees for SFL on heterogeneous data with both upper and lower bounds. Specifically, we derive the upper bounds for the strongly convex, general convex and non-convex objective functions, and construct the matching lower bounds for the strongly convex and general convex objective functions. Then, we compare the upper bounds of SFL with those of PFL, showing that SFL outperforms PFL on heterogeneous data (at least, when the level of heterogeneity is relatively high). Experimental results validate the counterintuitive theoretical finding.},
  archive      = {J_JMLR},
  author       = {Yipeng Li and Xinchen Lyu},
  journal      = {Journal of Machine Learning Research},
  number       = {70},
  pages        = {1-55},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Sharp bounds for sequential federated learning on heterogeneous data},
  url          = {https://jmlr.org/papers/v26/24-0668.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local linear recovery guarantee of deep neural networks at overparameterization. <em>JMLR</em>, <em>26</em>(69), 1-30. (<a href='https://jmlr.org/papers/v26/24-0192.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining whether deep neural network (DNN) models can reliably recover target functions at overparameterization is a critical yet complex issue in the theory of deep learning. To advance understanding in this area, we introduce a concept we term “local linear recovery” (LLR), a weaker form of target function recovery that renders the problem more amenable to theoretical analysis. In the sense of LLR, we prove that functions expressible by narrower DNNs are guaranteed to be recoverable from fewer samples than model parameters. Specifically, we establish upper limits on the optimistic sample sizes, defined as the smallest sample size necessary to guarantee LLR, for functions in the space of a given DNN. Furthermore, we prove that these upper bounds are achieved in the case of two-layer tanh neural networks. Our research lays a solid groundwork for future investigations into the recovery capabilities of DNNs in overparameterized scenarios.},
  archive      = {J_JMLR},
  author       = {Yaoyu Zhang and Leyang Zhang and Zhongwang Zhang and Zhiwei Bai},
  journal      = {Journal of Machine Learning Research},
  number       = {69},
  pages        = {1-30},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Local linear recovery guarantee of deep neural networks at overparameterization},
  url          = {https://jmlr.org/papers/v26/24-0192.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stabilizing sharpness-aware minimization through a simple renormalization strategy. <em>JMLR</em>, <em>26</em>(68), 1-35. (<a href='https://jmlr.org/papers/v26/24-0065.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, sharpness-aware minimization (SAM) has attracted much attention because of its surprising effectiveness in improving generalization performance. However, compared to stochastic gradient descent (SGD), it is more prone to getting stuck at the saddle points, which as a result may lead to performance degradation. To address this issue, we propose a simple renormalization strategy, dubbed Stable SAM (SSAM), so that the gradient norm of the descent step maintains the same as that of the ascent step. Our strategy is easy to implement and flexible enough to integrate with SAM and its variants, almost at no computational cost. With elementary tools from convex optimization and learning theory, we also conduct a theoretical analysis of sharpness-aware training, revealing that compared to SGD, the effectiveness of SAM is only assured in a limited regime of learning rate. In contrast, we show how SSAM extends this regime of learning rate and then it can consistently perform better than SAM with the minor modification. Finally, we demonstrate the improved performance of SSAM on several representative data sets and tasks.},
  archive      = {J_JMLR},
  author       = {Chengli Tan and Jiangshe Zhang and Junmin Liu and Yicheng Wang and Yunda Hao},
  journal      = {Journal of Machine Learning Research},
  number       = {68},
  pages        = {1-35},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Stabilizing sharpness-aware minimization through a simple renormalization strategy},
  url          = {https://jmlr.org/papers/v26/24-0065.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained change point detection for topic modeling with pitman-yor process. <em>JMLR</em>, <em>26</em>(67), 1-53. (<a href='https://jmlr.org/papers/v26/23-1576.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying change points in dynamic text data is crucial for understanding the evolving nature of topics across various sources, such as news articles, scientific papers, and social media posts. While topic modeling has become a widely used technique for this purpose, capturing fine-grained shifts in individual topics over time remains a significant challenge. Traditional approaches typically use a two-stage process, separating topic modeling and change point detection. However, this separation can lead to information loss and inconsistency in capturing subtle changes in topic evolution. To address this issue, we propose TOPIC-PYP, a change point detection model specifically designed for fine-grained topic-level analysis, i.e., detecting change points for each individual topic. By leveraging the Pitman-Yor process, TOPIC-PYP effectively captures the dynamic evolution of topic meanings over time. Unlike traditional methods, TOPIC-PYP integrates topic modeling and change point detection into a unified framework, facilitating a more comprehensive understanding of the relationship between topic evolution and change points. Experimental evaluations on both synthetic and real-world datasets demonstrate the effectiveness of TOPIC-PYP in accurately detecting change points and generating high-quality topics.},
  archive      = {J_JMLR},
  author       = {Feifei Wang and Zimeng Zhao and Ruimin Ye and Xiaoge Gu and Xiaoling Lu},
  journal      = {Journal of Machine Learning Research},
  number       = {67},
  pages        = {1-53},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Fine-grained change point detection for topic modeling with pitman-yor process},
  url          = {https://jmlr.org/papers/v26/23-1576.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deletion robust non-monotone submodular maximization over matroids. <em>JMLR</em>, <em>26</em>(66), 1-28. (<a href='https://jmlr.org/papers/v26/23-1219.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the deletion robust version of submodular maximization under matroid constraints. The goal is to extract a small-size summary of the data set that contains a high-value independent set even after an adversary deletes some elements. We present constant-factor approximation algorithms, whose space complexity depends on the rank $k$ of the matroid, the number $d$ of deleted elements, and the input precision $\varepsilon$. In the centralized setting we present a $(4.494+O(\varepsilon))$-approximation algorithm with summary size $O( \frac{k+d}{\varepsilon^2}\log \frac{k}{\varepsilon})$ that improves to a $(3.582+O(\varepsilon))$-approximation with $O(k + \frac{d}{\varepsilon^2}\log \frac{k}{\varepsilon})$ summary size when the objective is monotone. In the streaming setting we provide a $(9.294 + O(\varepsilon))$-approximation algorithm with summary size and memory $O(k + \frac{d}{\varepsilon^2}\log \frac{k}{\varepsilon})$; the approximation factor is then improved to $(5.582+O(\varepsilon))$ in the monotone case.},
  archive      = {J_JMLR},
  author       = {Paul Dütting and Federico Fusco and Silvio Lattanzi and Ashkan Norouzi-Fard and Morteza Zadimoghaddam},
  journal      = {Journal of Machine Learning Research},
  number       = {66},
  pages        = {1-28},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Deletion robust non-monotone submodular maximization over matroids},
  url          = {https://jmlr.org/papers/v26/23-1219.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Instability, computational efficiency and statistical accuracy. <em>JMLR</em>, <em>26</em>(65), 1-68. (<a href='https://jmlr.org/papers/v26/22-0300.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many statistical estimators are defined as the fixed point of a data-dependent operator, with estimators based on minimizing a cost function being an important special case. The limiting performance of such estimators depends on the properties of the population-level operator in the idealized limit of infinitely many samples. We develop a general framework that yields bounds on statistical accuracy based on the interplay between the deterministic convergence rate of the algorithm at the population level, and its degree of (in)stability when applied to an empirical object based on $n$ samples. Using this framework, we analyze both stable forms of gradient descent and some higher-order and unstable algorithms, including Newton's method and its cubic-regularized variant, as well as the EM algorithm. We provide applications of our general results to several concrete classes of models, including Gaussian mixture estimation, non-linear regression models, and informative non-response models. We exhibit cases in which an unstable algorithm can achieve the same statistical accuracy as a stable algorithm in exponentially fewer steps---namely, with the number of iterations being reduced from polynomial to logarithmic in sample size $n$.},
  archive      = {J_JMLR},
  author       = {Nhat Ho and Koulik Khamaru and Raaz Dwivedi and Martin J. Wainwright and Michael I. Jordan and Bin Yu},
  journal      = {Journal of Machine Learning Research},
  number       = {65},
  pages        = {1-68},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Instability, computational efficiency and statistical accuracy},
  url          = {https://jmlr.org/papers/v26/22-0300.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimation of local geometric structure on manifolds from noisy data. <em>JMLR</em>, <em>26</em>(64), 1-89. (<a href='https://jmlr.org/papers/v26/25-0183.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common observation in data-driven applications is that high-dimensional data have a low intrinsic dimension, at least locally. In this work, we consider the problem of point estimation for manifold-valued data. Namely, given a finite set of noisy samples of $\mathcal{M}$, a $d$ dimensional submanifold of $\mathbb{R}^D$, and a point $r$ near the manifold we aim to project $r$ onto the manifold. Assuming that the data was sampled uniformly from a tubular neighborhood of a $k$-times smooth boundaryless and compact manifold, we present an algorithm that takes $r$ from this neighborhood and outputs $\hat p_n\in \mathbb{R}^D$, and $\widehat{T_{\hat p_n}\mathcal{M}}$ an element in the Grassmannian $Gr(d, D)$. We prove that as the number of samples $n\to\infty$, the point $\hat p_n$ converges to $\mathbf{p}\in \mathcal{M}$, the projection of $r$ onto $\mathcal{M}$, and $\widehat{T_{\hat p_n}\mathcal{M}}$ converges to $T_{\mathbf{p}}\mathcal{M}$ (the tangent space at that point) with high probability. Furthermore, we show that $\hat p_n$ approaches the manifold with an asymptotic rate of $n^{-\frac{k}{2k + d}}$, and that $\hat p_n, \widehat{T_{\hat p_n}\mathcal{M}}$ approach $\mathbf{p}$ and $T_{\mathbf{p}}\mathcal{M}$ correspondingly with asymptotic rates of $n^{-\frac{k-1}{2k + d}}$. %While we These rates coincide with the optimal rates for the estimation of function derivatives.},
  archive      = {J_JMLR},
  author       = {Yariv Aizenbud and Barak Sober},
  journal      = {Journal of Machine Learning Research},
  number       = {64},
  pages        = {1-89},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Estimation of local geometric structure on manifolds from noisy data},
  url          = {https://jmlr.org/papers/v26/25-0183.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ontolearn---A framework for large-scale OWL class expression learning in python. <em>JMLR</em>, <em>26</em>(63), 1-6. (<a href='https://jmlr.org/papers/v26/24-1113.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present Ontolearn---a framework for learning OWL class expressions over large knowledge graphs. Ontolearn contains efficient implementations of recent state-of-the-art symbolic and neuro-symbolic class expression learners including EvoLearner and DRILL. A learned OWL class expression can be used to classify instances in the knowledge graph. Furthermore, Ontolearn integrates a verbalization module based on an LLM to translate complex OWL class expressions into natural language sentences. By mapping OWL class expressions into respective SPARQL queries, Ontolearn can be easily used to operate over a remote triplestore. The source code of Ontolearn is available at https://github.com/dice-group/Ontolearn.},
  archive      = {J_JMLR},
  author       = {Caglar Demir and Alkid Baci and N'Dah Jean Kouagou and Leonie Nora Sieger and Stefan Heindorf and Simon Bin and Lukas Blübaum and Alexander Bigerl and Axel-Cyrille Ngonga Ngomo},
  journal      = {Journal of Machine Learning Research},
  number       = {63},
  pages        = {1-6},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Ontolearn---A framework for large-scale OWL class expression learning in python},
  url          = {https://jmlr.org/papers/v26/24-1113.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continuously evolving rewards in an open-ended environment. <em>JMLR</em>, <em>26</em>(62), 1-51. (<a href='https://jmlr.org/papers/v26/24-0847.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unambiguous identification of the rewards driving behaviours of entities operating in complex open-ended real-world environments is difficult, in part because goals and associated behaviours emerge endogenously and are dynamically updated as environments change. Reproducing such dynamics in models would be useful in many domains, particularly where fixed reward functions limit the adaptive capabilities of agents. Simulation experiments described here assess a candidate algorithm for the dynamic updating of the reward function, RULE: Reward Updating through Learning and Expectation. The approach is tested in a simplified ecosystem-like setting where experiments challenge entities' survival, calling for significant behavioural change. The population of entities successfully demonstrate the abandonment of an initially rewarded but ultimately detrimental behaviour, amplification of beneficial behaviour, and appropriate responses to novel items added to their environment. These adjustments happen through endogenous modification of the entities' reward function, during continuous learning, without external intervention.},
  archive      = {J_JMLR},
  author       = {Richard M. Bailey},
  journal      = {Journal of Machine Learning Research},
  number       = {62},
  pages        = {1-51},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Continuously evolving rewards in an open-ended environment},
  url          = {https://jmlr.org/papers/v26/24-0847.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recursive causal discovery. <em>JMLR</em>, <em>26</em>(61), 1-65. (<a href='https://jmlr.org/papers/v26/24-0384.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal discovery from observational data, i.e., learning the causal graph from a finite set of samples from the joint distribution of the variables, is often the first step toward the identification and estimation of causal effects, a key requirement in numerous scientific domains. Causal discovery is hampered by two main challenges: limited data results in errors in statistical testing and the computational complexity of the learning task is daunting. This paper builds upon and extends four of our prior publications (Mokhtarian et al., 2021; Akbari et al., 2021; Mokhtarian et al., 2022, 2023a). These works introduced the concept of removable variables, which are the only variables that can be removed recursively for the purpose of causal discovery. Presence and identification of removable variables allow recursive approaches for causal discovery, a promising solution that helps to address the aforementioned challenges by reducing the problem size successively. This reduction not only minimizes conditioning sets in each conditional independence (CI) test, leading to fewer errors but also significantly decreases the number of required CI tests. The worst-case performances of these methods nearly match the lower bound. In this paper, we present a unified framework for the proposed algorithms, refined with additional details and enhancements for a coherent presentation. A comprehensive literature review is also included, comparing the computational complexity of our methods with existing approaches, showcasing their state-of-the-art efficiency. Another contribution of this paper is the release of RCD, a Python package that efficiently implements these algorithms. This package is designed for practitioners and researchers interested in applying these methods in practical scenarios. The package is available at github.com/ban-epfl/rcd, with comprehensive documentation provided at rcdpackage.com.},
  archive      = {J_JMLR},
  author       = {Ehsan Mokhtarian and Sepehr Elahi and Sina Akbari and Negar Kiyavash},
  journal      = {Journal of Machine Learning Research},
  number       = {61},
  pages        = {1-65},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Recursive causal discovery},
  url          = {https://jmlr.org/papers/v26/24-0384.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of active feature acquisition methods for time-varying feature settings. <em>JMLR</em>, <em>26</em>(60), 1-84. (<a href='https://jmlr.org/papers/v26/23-1635.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning methods often assume that input features are available at no cost. However, in domains like healthcare, where acquiring features could be expensive or harmful, it is necessary to balance a feature's acquisition cost against its predictive value. The task of training an AI agent to decide which features to acquire is called active feature acquisition (AFA). By deploying an AFA agent, we effectively alter the acquisition strategy and trigger a distribution shift. To safely deploy AFA agents under this distribution shift, we present the problem of active feature acquisition performance evaluation (AFAPE). We examine AFAPE under i) a no direct effect (NDE) assumption, stating that acquisitions do not affect the underlying feature values; and ii) a no unobserved confounding (NUC) assumption, stating that retrospective feature acquisition decisions were only based on observed features. We show that one can apply missing data methods under the NDE assumption and offline reinforcement learning under the NUC assumption. When NUC and NDE hold, we propose a novel semi-offline reinforcement learning framework. This framework requires a weaker positivity assumption and introduces three new estimators: A direct method (DM), an inverse probability weighting (IPW), and a double reinforcement learning (DRL) estimator.},
  archive      = {J_JMLR},
  author       = {Henrik von Kleist and Alireza Zamanian and Ilya Shpitser and Narges Ahmidi},
  journal      = {Journal of Machine Learning Research},
  number       = {60},
  pages        = {1-84},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Evaluation of active feature acquisition methods for time-varying feature settings},
  url          = {https://jmlr.org/papers/v26/23-1635.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On adaptive stochastic optimization for streaming data: A newton's method with O(dN) operations. <em>JMLR</em>, <em>26</em>(59), 1-49. (<a href='https://jmlr.org/papers/v26/23-1565.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic optimization methods face new challenges in the realm of streaming data, characterized by a continuous flow of large, high-dimensional data. While first-order methods, like stochastic gradient descent, are the natural choice for such data, they often struggle with ill-conditioned problems. In contrast, second-order methods, such as Newton's method, offer a potential solution but are computationally impractical for large-scale streaming applications. This paper introduces adaptive stochastic optimization methods that effectively address ill-conditioned problems while functioning in a streaming context. Specifically, we present adaptive inversion-free stochastic quasi-Newton methods with computational complexity matching that of first-order methods, $\mathcal{O}(dN)$, where $d$ represents the number of dimensions/features and $N$ the number of data points. Theoretical analysis establishes their asymptotic efficiency, and empirical studies demonstrate their effectiveness in scenarios with complex covariance structures and poor initializations. In particular, we demonstrate that our adaptive quasi-Newton methods can outperform or match existing first- and second-order methods.},
  archive      = {J_JMLR},
  author       = {Antoine Godichon-Baggioni and Nicklas Werge},
  journal      = {Journal of Machine Learning Research},
  number       = {59},
  pages        = {1-49},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On adaptive stochastic optimization for streaming data: A newton's method with O(dN) operations},
  url          = {https://jmlr.org/papers/v26/23-1565.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Determine the number of states in hidden markov models via marginal likelihood. <em>JMLR</em>, <em>26</em>(58), 1-59. (<a href='https://jmlr.org/papers/v26/23-0343.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hidden Markov models (HMM) have been widely used by scientists to model stochastic systems: the underlying process is a discrete Markov chain, and the observations are noisy realizations of the underlying process. Determining the number of hidden states for an HMM is a model selection problem which is yet to be satisfactorily solved, especially for the popular Gaussian HMM with heterogeneous covariance. In this paper, we propose a consistent method for determining the number of hidden states of HMM based on the marginal likelihood, which is obtained by integrating out both the parameters and hidden states. Moreover, we show that the model selection problem of HMM includes the order selection problem of finite mixture models as a special case. We give rigorous proof of the consistency of the proposed marginal likelihood method and provide an efficient computation method for practical implementation. We numerically compare the proposed method with the Bayesian information criterion (BIC), demonstrating the effectiveness of the proposed marginal likelihood method.},
  archive      = {J_JMLR},
  author       = {Yang Chen and Cheng-Der Fuh and Chu-Lan Michael Kao},
  journal      = {Journal of Machine Learning Research},
  number       = {58},
  pages        = {1-59},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Determine the number of states in hidden markov models via marginal likelihood},
  url          = {https://jmlr.org/papers/v26/23-0343.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variance-aware estimation of kernel mean embedding. <em>JMLR</em>, <em>26</em>(57), 1-48. (<a href='https://jmlr.org/papers/v26/23-0161.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important feature of kernel mean embeddings (KME) is that the rate of convergence of the empirical KME to the true distribution KME can be bounded independently of the dimension of the space, properties of the distribution and smoothness features of the kernel. We show how to speed-up convergence by leveraging variance information in the reproducing kernel Hilbert space. Furthermore, we show that even when such information is a priori unknown, we can efficiently estimate it from the data, recovering the desiderata of a distribution agnostic bound that enjoys acceleration in fortuitous settings. We further extend our results from independent data to stationary mixing sequences and illustrate our methods in the context of hypothesis testing and robust parametric estimation.},
  archive      = {J_JMLR},
  author       = {Geoffrey Wolfer and Pierre Alquier},
  journal      = {Journal of Machine Learning Research},
  number       = {57},
  pages        = {1-48},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Variance-aware estimation of kernel mean embedding},
  url          = {https://jmlr.org/papers/v26/23-0161.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scaling ResNets in the large-depth regime. <em>JMLR</em>, <em>26</em>(56), 1-48. (<a href='https://jmlr.org/papers/v26/22-0664.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep ResNets are recognized for achieving state-of-the-art results in complex machine learning tasks. However, the remarkable performance of these architectures relies on a training procedure that needs to be carefully crafted to avoid vanishing or exploding gradients, particularly as the depth $L$ increases. No consensus has been reached on how to mitigate this issue, although a widely discussed strategy consists in scaling the output of each layer by a factor $\alpha_L$. We show in a probabilistic setting that with standard i.i.d. initializations, the only non-trivial dynamics is for $\alpha_L = \frac{1}{\sqrt{L}}$---other choices lead either to explosion or to identity mapping. This scaling factor corresponds in the continuous-time limit to a neural stochastic differential equation, contrarily to a widespread interpretation that deep ResNets are discretizations of neural ordinary differential equations. By contrast, in the latter regime, stability is obtained with specific correlated initializations and $\alpha_L = \frac{1}{L}$. Our analysis suggests a strong interplay between scaling and regularity of the weights as a function of the layer index. Finally, in a series of experiments, we exhibit a continuous range of regimes driven by these two parameters, which jointly impact performance before and after training.},
  archive      = {J_JMLR},
  author       = {Pierre Marion and Adeline Fermanian and Gérard Biau and Jean-Philippe Vert},
  journal      = {Journal of Machine Learning Research},
  number       = {56},
  pages        = {1-48},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Scaling ResNets in the large-depth regime},
  url          = {https://jmlr.org/papers/v26/22-0664.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparative evaluation of quantification methods. <em>JMLR</em>, <em>26</em>(55), 1-54. (<a href='https://jmlr.org/papers/v26/21-0241.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantification represents the problem of estimating the distribution of class labels on unseen data. It also represents a growing research field in supervised machine learning, for which a large variety of different algorithms has been proposed in recent years. However, a comprehensive empirical comparison of quantification methods that supports algorithm selection is not available yet. In this work, we close this research gap by conducting a thorough empirical performance comparison of 24 different quantification methods on in total more than 40 datasets, considering binary as well as multiclass quantification settings. We observe that no single algorithm generally outperforms all competitors, but identify a group of methods that perform best in the binary setting, including the threshold selection-based median sweep and TSMax methods, the DyS framework including the HDy method, Forman's mixture model, and Friedman's method. For the multiclass setting, we observe that a different, broad group of algorithms yields good performance, including the HDx method, the generalized probabilistic adjusted count, the readme method, the energy distance minimization method, the EM algorithm for quantification, and Friedman's method. We also find that tuning the underlying classifiers has in most cases only a limited impact on the quantification performance. More generally, we find that the performance on multiclass quantification is inferior to the results obtained in the binary setting. Our results can guide practitioners who intend to apply quantification algorithms and help researchers identify opportunities for future research.},
  archive      = {J_JMLR},
  author       = {Tobias Schumacher and Markus Strohmaier and Florian Lemmerich},
  journal      = {Journal of Machine Learning Research},
  number       = {55},
  pages        = {1-54},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A comparative evaluation of quantification methods},
  url          = {https://jmlr.org/papers/v26/21-0241.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightning UQ box: Uncertainty quantification for neural networks. <em>JMLR</em>, <em>26</em>(54), 1-7. (<a href='https://jmlr.org/papers/v26/24-2110.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although neural networks have shown impressive results in a multitude of application domains, the "black box" nature of deep learning and lack of confidence estimates have led to scepticism, especially in domains like medicine and physics where such estimates are critical. Research on uncertainty quantification (UQ) has helped elucidate the reliability of these models, but existing implementations of these UQ methods are sparse and difficult to reuse. To this end, we introduce Lightning UQ Box, a PyTorch-based Python library for deep learning-based UQ methods powered by PyTorch Lightning. Lightning UQ Box supports classification, regression, semantic segmentation, and pixelwise regression applications, and UQ methods from a variety of theoretical motivations. With this library, we provide an entry point for practitioners new to UQ, as well as easy-to-use components and tools for scalable deep learning applications.},
  archive      = {J_JMLR},
  author       = {Nils Lehmann and Nina Maria Gottschling and Jakob Gawlikowski and Adam J. Stewart and Stefan Depeweg and Eric Nalisnick},
  journal      = {Journal of Machine Learning Research},
  number       = {54},
  pages        = {1-7},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Lightning UQ box: Uncertainty quantification for neural networks},
  url          = {https://jmlr.org/papers/v26/24-2110.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scaling data-constrained language models. <em>JMLR</em>, <em>26</em>(53), 1-66. (<a href='https://jmlr.org/papers/v26/24-1000.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current trend of scaling language models involves increasing both parameter count and training data set size. Extrapolating this trend suggests that training data set size may soon be limited by the amount of text data available on the internet. Motivated by this limit, we investigate scaling language models in data-constrained regimes. Specifically, we run a large set of experiments varying the extent of data repetition and compute budget, ranging up to 900 billion training tokens and 9 billion parameter models. We find that with constrained data for a fixed compute budget, training with up to 4 epochs of repeated data yields negligible changes to loss compared to having unique data. However, with more repetition, the value of adding compute eventually decays to zero. We propose and empirically validate a scaling law for compute optimality that accounts for the decreasing value of repeated tokens and excess parameters. Finally, we experiment with approaches mitigating data scarcity, including augmenting the training data set with code data or removing commonly used filters. Models and data sets from our 400 training runs are freely available at https://github.com/huggingface/datablations.},
  archive      = {J_JMLR},
  author       = {Niklas Muennighoff and Alexander M. Rush and Boaz Barak and Teven Le Scao and Aleksandra Piktus and Nouamane Tazi and Sampo Pyysalo and Thomas Wolf and Colin Raffel},
  journal      = {Journal of Machine Learning Research},
  number       = {53},
  pages        = {1-66},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Scaling data-constrained language models},
  url          = {https://jmlr.org/papers/v26/24-1000.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Curvature-based clustering on graphs. <em>JMLR</em>, <em>26</em>(52), 1-67. (<a href='https://jmlr.org/papers/v26/24-0781.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised node clustering (or community detection) is a classical graph learning task. In this paper, we study algorithms that exploit the geometry of the graph to identify densely connected substructures, which form clusters or communities. Our method implements discrete Ricci curvatures and their associated geometric flows, under which the edge weights of the graph evolve to reveal its community structure. We consider several discrete curvature notions and analyze the utility of the resulting algorithms. In contrast to prior literature, we study not only single-membership community detection, where each node belongs to exactly one community, but also mixed-membership community detection, where communities may overlap. For the latter, we argue that it is beneficial to perform community detection on the line graph, i.e., the graph's dual. We provide both theoretical and empirical evidence for the utility of our curvature-based clustering algorithms. In addition, we give several results on the relationship between the curvature of a graph and that of its dual, which enable the efficient implementation of our proposed mixed-membership community detection approach and which may be of independent interest for curvature-based network analysis.},
  archive      = {J_JMLR},
  author       = {Yu Tian and Zachary Lubberts and Melanie Weber},
  journal      = {Journal of Machine Learning Research},
  number       = {52},
  pages        = {1-67},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Curvature-based clustering on graphs},
  url          = {https://jmlr.org/papers/v26/24-0781.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Composite goodness-of-fit tests with kernels. <em>JMLR</em>, <em>26</em>(51), 1-60. (<a href='https://jmlr.org/papers/v26/24-0276.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose kernel-based hypothesis tests for the challenging composite testing problem, where we are interested in whether the data comes from any distribution in some parametric family. Our tests make use of minimum distance estimators based on kernel-based distances such as the maximum mean discrepancy. As our main result, we show that we are able to estimate the parameter and conduct our test on the same data (without data splitting), while maintaining a correct test level. We also prove that the popular wild bootstrap will lead to an overly conservative test, and show that the parametric bootstrap is consistent and can lead to significantly improved performance in practice. Our approach is illustrated on a range of problems, including testing for goodness-of-fit of a non-parametric density model, and an intractable generative model of a biological cellular network.},
  archive      = {J_JMLR},
  author       = {Oscar Key and Arthur Gretton and François-Xavier Briol and Tamara Fernandez},
  journal      = {Journal of Machine Learning Research},
  number       = {51},
  pages        = {1-60},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Composite goodness-of-fit tests with kernels},
  url          = {https://jmlr.org/papers/v26/24-0276.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PFLlib: A beginner-friendly and comprehensive personalized federated learning library and benchmark. <em>JMLR</em>, <em>26</em>(50), 1-10. (<a href='https://jmlr.org/papers/v26/23-1634.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Amid the ongoing advancements in Federated Learning (FL), a machine learning paradigm that allows collaborative learning with data privacy protection, personalized FL (pFL) has gained significant prominence as a research direction within the FL domain. Whereas traditional FL (tFL) focuses on jointly learning a global model, pFL aims to balance each client's global and personalized goals in FL settings. To foster the pFL research community, we started and built PFLlib, a comprehensive pFL library with an integrated benchmark platform. In PFLlib, we implemented 37 state-of-the-art FL algorithms (8 tFL algorithms and 29 pFL algorithms) and provided various evaluation environments with three statistically heterogeneous scenarios and 24 datasets. At present, PFLlib has gained more than 1600 stars and 300 forks on GitHub.},
  archive      = {J_JMLR},
  author       = {Jianqing Zhang and Yang Liu and Yang Hua and Hao Wang and Tao Song and Zhengui Xue and Ruhui Ma and Jian Cao},
  journal      = {Journal of Machine Learning Research},
  number       = {50},
  pages        = {1-10},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {PFLlib: A beginner-friendly and comprehensive personalized federated learning library and benchmark},
  url          = {https://jmlr.org/papers/v26/23-1634.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The effect of SGD batch size on autoencoder learning: Sparsity, sharpness, and feature learning. <em>JMLR</em>, <em>26</em>(49), 1-61. (<a href='https://jmlr.org/papers/v26/23-1022.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we investigate the dynamics of stochastic gradient descent (SGD) when training a single-neuron autoencoder with linear or ReLU activation on orthogonal data. We show that for this non-convex problem, randomly initialized SGD with a constant step size successfully finds a global minimum for any batch size choice. However, the particular global minimum found depends upon the batch size. In the full-batch setting, we show that the solution is dense (i.e., not sparse) and is highly aligned with its initialized direction, showing that relatively little feature learning occurs. On the other hand, for any batch size strictly smaller than the number of samples, SGD finds a global minimum that is sparse and nearly orthogonal to its initialization, showing that the randomness of stochastic gradients induces a qualitatively different type of "feature selection" in this setting. Moreover, if we measure the sharpness of the minimum by the trace of the Hessian, the minima found with full-batch gradient descent are flatter than those found with strictly smaller batch sizes, in contrast to previous works which suggest that large batches lead to sharper minima. To prove convergence of SGD with a constant step size, we introduce a powerful tool from the theory of non-homogeneous random walks which may be of independent interest.},
  archive      = {J_JMLR},
  author       = {Nikhil Ghosh and Spencer Frei and Wooseok Ha and Bin Yu},
  journal      = {Journal of Machine Learning Research},
  number       = {49},
  pages        = {1-61},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {The effect of SGD batch size on autoencoder learning: Sparsity, sharpness, and feature learning},
  url          = {https://jmlr.org/papers/v26/23-1022.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient and robust transfer learning of optimal individualized treatment regimes with right-censored survival data. <em>JMLR</em>, <em>26</em>(48), 1-54. (<a href='https://jmlr.org/papers/v26/23-0335.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An individualized treatment regime (ITR) is a decision rule that assigns treatments based on patients' characteristics. The value function of an ITR is the expected outcome in a counterfactual world had this ITR been implemented. Recently, there has been increasing interest in combining heterogeneous data sources, such as leveraging the complementary features of randomized controlled trial (RCT) data and a large observational study (OS). Usually, a covariate shift exists between the source and target population, rendering the source-optimal ITR not optimal for the target population. We present an efficient and robust transfer learning framework for estimating the optimal ITR with right-censored survival data that generalizes well to the target population. The value function accommodates a broad class of functionals of survival distributions, including survival probabilities and restrictive mean survival times (RMSTs). We propose a doubly robust estimator of the value function, and the optimal ITR is learned by maximizing the value function within a pre-specified class of ITRs. We establish the cubic rate of convergence for the estimated parameter indexing the optimal ITR, and show that the proposed optimal value estimator is consistent and asymptotically normal even with flexible machine learning methods for nuisance parameter estimation. We evaluate the empirical performance of the proposed method by simulation studies and a real data application of sodium bicarbonate therapy for patients with severe metabolic acidaemia in the intensive care unit (ICU), combining a RCT and an observational study with heterogeneity.},
  archive      = {J_JMLR},
  author       = {Pan Zhao and Julie Josse and Shu Yang},
  journal      = {Journal of Machine Learning Research},
  number       = {48},
  pages        = {1-54},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Efficient and robust transfer learning of optimal individualized treatment regimes with right-censored survival data},
  url          = {https://jmlr.org/papers/v26/23-0335.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAGs as minimal I-maps for the induced models of causal bayesian networks under conditioning. <em>JMLR</em>, <em>26</em>(47), 1-62. (<a href='https://jmlr.org/papers/v26/23-0002.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian networks (BNs) are a powerful tool for knowledge representation and reasoning, especially for complex systems. A critical task in the applications of BNs is conditional inference or inference in the presence of selection bias. However, post-conditioning, the conditional distribution family of a BN can become complex for analysis, and the corresponding induced subgraph may not accurately encode the conditional independencies for the remaining variables. In this work, we first investigate the conditions under which a BN remains closed under conditioning, meaning that the induced subgraph is consistent with the structural information of conditional distributions. Conversely, when a BN is not closed, we aim to construct a new directed acyclic graph (DAG) as a minimal $\mathcal{I}$-map for the conditional model by incorporating directed edges into the original induced graph. We present an equivalent characterization of this minimal $\mathcal{I}$-map and develop an efficient algorithm for its identification. The proposed framework improves the efficiency of conditional inference of a BN. Additionally, the DAG minimal $\mathcal{I}$-map offers graphical criteria for the safe integration of knowledge from diverse sources (subpopulations/conditional distributions), facilitating correct parameter estimation. Both theoretical analysis and simulation studies demonstrate that using a DAG minimal $\mathcal{I}$-map for conditional inference is more effective than traditional methods based on the joint distribution of the original BN.},
  archive      = {J_JMLR},
  author       = {Xiangdong Xie and Jiahua Guo and Yi Sun},
  journal      = {Journal of Machine Learning Research},
  number       = {47},
  pages        = {1-62},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {DAGs as minimal I-maps for the induced models of causal bayesian networks under conditioning},
  url          = {https://jmlr.org/papers/v26/23-0002.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adjusted expected improvement for cumulative regret minimization in noisy bayesian optimization. <em>JMLR</em>, <em>26</em>(46), 1-33. (<a href='https://jmlr.org/papers/v26/22-0523.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expected improvement (EI) is one of the most popular acquisition functions for Bayesian optimization (BO) and has demonstrated good empirical performances in many applications for the minimization of simple regret. However, under the evaluation metric of cumulative regret, the performance of EI may not be competitive, and its existing theoretical regret upper bound still has room for improvement. To adapt the EI for better performance under cumulative regret, we introduce a novel quantity called the evaluation cost which is compared against the acquisition function, and with this, develop the expected improvement-cost (EIC) algorithm. In each iteration of EIC, a new point with the largest acquisition function value is sampled, only if that value exceeds its evaluation cost. If none meets this criteria, the current best point is resampled. This evaluation cost quantifies the potential downside of sampling a point, which is important under the cumulative regret metric as the objective function value in every iteration affects the performance measure. We establish in theory a high-probability regret upper bound of EIC based on the maximum information gain, which is tighter than the bound of existing EI-based algorithms. It is also comparable to the regret bound of other popular BO algorithms such as Thompson sampling (GP-TS) and upper confidence bound (GP-UCB). We further perform experiments to illustrate the improvement of EIC over several popular BO algorithms.},
  archive      = {J_JMLR},
  author       = {Shouri Hu and Haowei Wang and Zhongxiang Dai and Bryan Kian Hsiang Low and Szu Hui Ng},
  journal      = {Journal of Machine Learning Research},
  number       = {46},
  pages        = {1-33},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Adjusted expected improvement for cumulative regret minimization in noisy bayesian optimization},
  url          = {https://jmlr.org/papers/v26/22-0523.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Manifold fitting under unbounded noise. <em>JMLR</em>, <em>26</em>(45), 1-55. (<a href='https://jmlr.org/papers/v26/21-0039.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of non-Euclidean statistical analysis, a trend has emerged in recent times, of attempts to recover a low dimensional structure, namely a manifold, underlying the high dimensional data. Recovering the manifold requires the noise to be of a certain concentration and prevailing methods address this requirement by constructing an approximated manifold that is based on the tangent space estimation at each sample point. Although theoretical convergence for these methods is guaranteed, the samples are either noiseless or the noise is bounded. However, if the noise is unbounded, as is commonplace, the tangent space estimation at the noisy samples will be blurred – an undesirable outcome since fitting a manifold from the blurred tangent space might be more greatly compromised in terms of its accuracy. In this paper, we introduce a new manifold-fitting method, whereby the output manifold is constructed by directly estimating the tangent spaces at the projected points on the latent manifold, rather than at the sample points, thus reducing the error caused by the noise. Assuming the noise is unbounded, our new method has a high probability of achieving theoretical convergence, in terms of the upper bound of the distance between the estimated and latent manifold. The smoothness of the estimated manifold is also evaluated by bounding the supremum of twice difference above. Numerical simulations are conducted as part of this new method to help validate our theoretical findings and demonstrate the advantages of our method over other relevant manifold fitting methods. Finally, our method is applied to real data examples.},
  archive      = {J_JMLR},
  author       = {Zhigang Yao and Yuqing Xia},
  journal      = {Journal of Machine Learning Research},
  number       = {45},
  pages        = {1-55},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Manifold fitting under unbounded noise},
  url          = {https://jmlr.org/papers/v26/21-0039.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning global nash equilibrium in team competitive games with generalized fictitious cross-play. <em>JMLR</em>, <em>26</em>(44), 1-30. (<a href='https://jmlr.org/papers/v26/24-1503.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-play (SP) is a popular multi-agent reinforcement learning framework for competitive games. Despite the empirical success, the theoretical properties of SP are limited to two-player settings. For team competitive games where two teams of cooperative agents compete with each other, we show a counter-example where SP cannot converge to a global Nash equilibrium (NE) with high probability. Policy-Space Response Oracles (PSRO) is an alternative framework that finds NEs by iteratively learning the best response (BR) to previous policies. PSRO can be directly extended to team competitive games with unchanged convergence properties by learning team BRs, but its repeated training from scratch makes it hard to scale to complex games. In this work, we propose Generalized Fictitious Cross-Play (GFXP), a novel algorithm that inherits benefits from both frameworks. GFXP simultaneously trains an SP-based main policy and a counter population. The main policy is trained by fictitious self-play and cross-play against the counter population, while the counter policies are trained as the BRs to the main policy's checkpoints. We evaluate GFXP in matrix games and gridworld domains where GFXP achieves the lowest exploitabilities. We further conduct experiments in a challenging football game where GFXP defeats SOTA models with over 94% win rate.},
  archive      = {J_JMLR},
  author       = {Zelai Xu and Chao Yu and Yancheng Liang and Yi Wu and Yu Wang},
  journal      = {Journal of Machine Learning Research},
  number       = {44},
  pages        = {1-30},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Learning global nash equilibrium in team competitive games with generalized fictitious cross-play},
  url          = {https://jmlr.org/papers/v26/24-1503.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wasserstein convergence guarantees for a general class of score-based generative models. <em>JMLR</em>, <em>26</em>(43), 1-54. (<a href='https://jmlr.org/papers/v26/24-0902.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Score-based generative models are a recent class of deep generative models with state-of-the-art performance in many applications. In this paper, we establish convergence guarantees for a general class of score-based generative models in the 2-Wasserstein distance, assuming accurate score estimates and smooth log-concave data distribution. We specialize our results to several concrete score-based generative models with specific choices of forward processes modeled by stochastic differential equations, and obtain an upper bound on the iteration complexity for each model, which demonstrates the impacts of different choices of the forward processes. We also provide a lower bound when the data distribution is Gaussian. Numerically, we experiment with score-based generative models with different forward processes for unconditional image generation on CIFAR-10. We find that the experimental results are in good agreement with our theoretical predictions on the iteration complexity.},
  archive      = {J_JMLR},
  author       = {Xuefeng Gao and Hoang M. Nguyen and Lingjiong Zhu},
  journal      = {Journal of Machine Learning Research},
  number       = {43},
  pages        = {1-54},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Wasserstein convergence guarantees for a general class of score-based generative models},
  url          = {https://jmlr.org/papers/v26/24-0902.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extremal graphical modeling with latent variables via convex optimization. <em>JMLR</em>, <em>26</em>(42), 1-68. (<a href='https://jmlr.org/papers/v26/24-0472.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extremal graphical models encode the conditional independence structure of multivariate extremes and provide a powerful tool for quantifying the risk of rare events. Prior work on learning these graphs from data has focused on the setting where all relevant variables are observed. For the popular class of Husler-Reiss models, we propose the eglatent method, a tractable convex program for learning extremal graphical models in the presence of latent variables. Our approach decomposes the Husler-Reiss precision matrix into a sparse component encoding the graphical structure among the observed variables after conditioning on the latent variables, and a low-rank component encoding the effect of a few latent variables on the observed variables. We provide finite-sample guarantees of eglatent and show that it consistently recovers the conditional graph as well as the number of latent variables. We highlight the improved performances of our approach on synthetic and real data.},
  archive      = {J_JMLR},
  author       = {Sebastian Engelke and Armeen Taeb},
  journal      = {Journal of Machine Learning Research},
  number       = {42},
  pages        = {1-68},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Extremal graphical modeling with latent variables via convex optimization},
  url          = {https://jmlr.org/papers/v26/24-0472.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the approximation of kernel functions. <em>JMLR</em>, <em>26</em>(41), 1-30. (<a href='https://jmlr.org/papers/v26/24-0270.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various methods in statistical learning build on kernels considered in reproducing kernel Hilbert spaces. In applications, the kernel is often selected based on characteristics of the problem and the data. This kernel is then employed to infer response variables at points, where no explanatory data were observed. The data considered here are located in compact sets in higher dimensions and the paper addresses approximations of the kernel itself. The new approach considers Taylor series approximations of radial kernel functions. For the Gauss kernel on the unit cube, the paper establishes an upper bound of the associated eigenfunctions, which grows only polynomially with respect to the index. The novel approach substantiates smaller regularization parameters than considered in the literature, overall leading to better approximations. This improvement confirms low rank approximation methods such as the Nyström method.},
  archive      = {J_JMLR},
  author       = {Paul Dommel and Alois Pichler},
  journal      = {Journal of Machine Learning Research},
  number       = {41},
  pages        = {1-30},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On the approximation of kernel functions},
  url          = {https://jmlr.org/papers/v26/24-0270.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient and robust semi-supervised estimation of average treatment effect with partially annotated treatment and response. <em>JMLR</em>, <em>26</em>(40), 1-77. (<a href='https://jmlr.org/papers/v26/23-1587.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A notable challenge of leveraging Electronic Health Records (EHR) for treatment effect assessment is the lack of precise information on important clinical variables, including the treatment received and the response. Both treatment information and response cannot be accurately captured by readily available EHR features in many studies and require labor-intensive manual chart review to precisely annotate, which limits the number of available gold standard labels on these key variables. We considered average treatment effect (ATE) estimation when 1) exact treatment and outcome variables are only observed together in a small labeled subset and 2) noisy surrogates of treatment and outcome, such as relevant prescription and diagnosis codes, along with potential confounders are observed for all subjects. We derived the efficient influence function for ATE and used it to construct a semi-supervised multiple machine learning (SMMAL) estimator. We justified that our SMMAL ATE estimator is semi-parametric efficient with B-spline regression under low-dimensional smooth models. We developed the adaptive sparsity/model doubly robust estimation under high-dimensional logistic propensity score and outcome regression models. Results from simulation studies demonstrated the validity of our SMMAL method and its superiority over supervised and unsupervised benchmarks. We applied SMMAL to the assessment of targeted therapies for metastatic colorectal cancer in comparison to chemotherapy.},
  archive      = {J_JMLR},
  author       = {Jue Hou and Rajarshi Mukherjee and Tianxi Cai},
  journal      = {Journal of Machine Learning Research},
  number       = {40},
  pages        = {1-77},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Efficient and robust semi-supervised estimation of average treatment effect with partially annotated treatment and response},
  url          = {https://jmlr.org/papers/v26/23-1587.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonconvex stochastic bregman proximal gradient method with application to deep learning. <em>JMLR</em>, <em>26</em>(39), 1-44. (<a href='https://jmlr.org/papers/v26/23-0657.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic gradient methods for minimizing nonconvex composite objective functions typically rely on the Lipschitz smoothness of the differentiable part, but this assumption fails in many important problem classes like quadratic inverse problems and neural network training, leading to instability of the algorithms in both theory and practice. To address this, we propose a family of stochastic Bregman proximal gradient (SBPG) methods that only require smooth adaptivity. SBPG replaces the quadratic approximation in SGD with a Bregman proximity measure, offering a better approximation model that handles non-Lipschitz gradients in nonconvex objectives. We establish the convergence properties of vanilla SBPG and show it achieves optimal sample complexity in the nonconvex setting. Experimental results on quadratic inverse problems demonstrate SBPG's robustness in terms of stepsize selection and sensitivity to the initial point. Furthermore, we introduce a momentum-based variant, MSBPG, which enhances convergence by relaxing the mini-batch size requirement while preserving the optimal oracle complexity. We apply MSBPG to the training of deep neural networks, utilizing a polynomial kernel function to ensure smooth adaptivity of the loss function. Experimental results on benchmark datasets confirm the effectiveness and robustness of MSBPG in training neural networks. Given its negligible additional computational cost compared to SGD in large-scale optimization, MSBPG shows promise as a universal open-source optimizer for future applications.},
  archive      = {J_JMLR},
  author       = {Kuangyu Ding and Jingyang Li and Kim-Chuan Toh},
  journal      = {Journal of Machine Learning Research},
  number       = {39},
  pages        = {1-44},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Nonconvex stochastic bregman proximal gradient method with application to deep learning},
  url          = {https://jmlr.org/papers/v26/23-0657.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing data collection for machine learning. <em>JMLR</em>, <em>26</em>(38), 1-52. (<a href='https://jmlr.org/papers/v26/23-0292.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern deep learning systems require huge data sets to achieve impressive performance, but there is little guidance on how much or what kind of data to collect. Over-collecting data incurs unnecessary present costs, while under-collecting may incur future costs and delay workflows. We propose a new paradigm to model the data collection workflow as a formal optimal data collection problem that allows designers to specify performance targets, collection costs, a time horizon, and penalties for failing to meet the targets. This formulation generalizes to tasks with multiple data sources, such as labeled and unlabeled data used in semi-supervised learning, and can be easily modified to customized analyses such as how to introduce data from new classes to an existing model. To solve our problem, we develop Learn-Optimize-Collect (LOC), which minimizes expected future collection costs. Finally, we numerically compare our framework to the conventional baseline of estimating data requirements by extrapolating from neural scaling laws. We significantly reduce the risks of failing to meet desired performance targets on several classification, segmentation, and detection tasks, while maintaining low total collection costs.},
  archive      = {J_JMLR},
  author       = {Rafid Mahmood and James Lucas and Jose M. Alvarez and Sanja Fidler and Marc T. Law},
  journal      = {Journal of Machine Learning Research},
  number       = {38},
  pages        = {1-52},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Optimizing data collection for machine learning},
  url          = {https://jmlr.org/papers/v26/23-0292.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unbalanced kantorovich-rubinstein distance, plan, and barycenter on nite spaces: A statistical perspective. <em>JMLR</em>, <em>26</em>(37), 1-70. (<a href='https://jmlr.org/papers/v26/22-1262.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze statistical properties of plug-in estimators for unbalanced optimal transport quantities between finitely supported measures in different prototypical sampling models. Specifically, our main results provide non-asymptotic bounds on the expected error of empirical Kantorovich-Rubinstein (KR) distance, plans, and barycenters for mass penalty parameter $C>0$. The impact of the mass penalty parameter $C$ is studied in detail. Based on this analysis, we mathematically justify randomized computational schemes for KR quantities which can be used for fast approximate computations in combination with any exact solver. Using synthetic and real datasets, we empirically analyze the behavior of the expected errors in simulation studies and illustrate the validity of our theoretical bounds.},
  archive      = {J_JMLR},
  author       = {Shayan Hundrieser and Florian Heinemann and Marcel Klatt and Marina Struleva and Axel Munk},
  journal      = {Journal of Machine Learning Research},
  number       = {37},
  pages        = {1-70},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Unbalanced kantorovich-rubinstein distance, plan, and barycenter on nite spaces: A statistical perspective},
  url          = {https://jmlr.org/papers/v26/22-1262.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Copula-based sensitivity analysis for multi-treatment causal inference with unobserved confounding. <em>JMLR</em>, <em>26</em>(36), 1-60. (<a href='https://jmlr.org/papers/v26/22-0372.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent work has focused on the potential and pitfalls of causal identification in observational studies with multiple simultaneous treatments. Building on previous work, we show that even if the conditional distribution of unmeasured confounders given treatments were known exactly, the causal effects would not in general be identifiable, although they may be partially identified. Given these results, we propose a sensitivity analysis method for characterizing the effects of potential unmeasured confounding, tailored to the multiple treatment setting, that can be used to characterize a range of causal effects that are compatible with the observed data. Our method is based on a copula factorization of the joint distribution of outcomes, treatments, and confounders, and can be layered on top of arbitrary observed data models. We propose a practical implementation of this approach making use of the Gaussian copula, and establish conditions under which causal effects can be bounded. We also describe approaches for reasoning about effects, including calibrating sensitivity parameters, quantifying robustness of effect estimates, and selecting models that are most consistent with prior hypotheses.},
  archive      = {J_JMLR},
  author       = {Jiajing Zheng and Alexander D'Amour and Alexander Franks},
  journal      = {Journal of Machine Learning Research},
  number       = {36},
  pages        = {1-60},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Copula-based sensitivity analysis for multi-treatment causal inference with unobserved confounding},
  url          = {https://jmlr.org/papers/v26/22-0372.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rank-one convexification for sparse regression. <em>JMLR</em>, <em>26</em>(35), 1-50. (<a href='https://jmlr.org/papers/v26/19-159.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse regression models are increasingly prevalent due to their ease of interpretability and superior out-of-sample performance. However, the exact model of sparse regression with an $\ell_0$-constraint restricting the support of the estimators is a challenging (\NP-hard) non-convex optimization problem. In this paper, we derive new strong convex relaxations for sparse regression. These relaxations are based on the convex-hull formulations for rank-one quadratic terms with indicator variables. The new relaxations can be formulated as semidefinite optimization problems in an extended space and are stronger and more general than the state-of-the-art formulations, including the perspective reformulation and formulations with the reverse Huber penalty and the minimax concave penalty functions. Furthermore, the proposed rank-one strengthening can be interpreted as a non-separable, non-convex, unbiased sparsity-inducing regularizer, which dynamically adjusts its penalty according to the shape of the error function without inducing bias for the sparse solutions. In our computational experiments with benchmark datasets, the proposed conic formulations are solved within seconds and result in near-optimal solutions (with 0.4\% optimality gap on average) for non-convex $\ell_0$-problems. Moreover, the resulting estimators also outperform alternative convex approaches, such as lasso and elastic net regression, from a statistical perspective, achieving high prediction accuracy and good interpretability.},
  archive      = {J_JMLR},
  author       = {Alper Atamturk and Andres Gomez},
  journal      = {Journal of Machine Learning Research},
  number       = {35},
  pages        = {1-50},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Rank-one convexification for sparse regression},
  url          = {https://jmlr.org/papers/v26/19-159.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gsplat: An open-source library for gaussian splatting. <em>JMLR</em>, <em>26</em>(34), 1-17. (<a href='https://jmlr.org/papers/v26/24-1476.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {gsplat is an open-source library designed for training and developing Gaussian Splatting methods. It features a front-end with Python bindings compatible with the PyTorch library and a back-end with highly optimized CUDA kernels. gsplat offers numerous features that enhance the optimization of Gaussian Splatting models, which include optimization improvements for speed, memory, and convergence times. Experimental results demonstrate that gsplat achieves up to 10% less training time and 4x less memory than the original implementation. Utilized in several research projects, gsplat is actively maintained on GitHub. Source code is available at https://github.com/nerfstudio-project/gsplat under Apache License 2.0. We welcome contributions from the open-source community.},
  archive      = {J_JMLR},
  author       = {Vickie Ye and Ruilong Li and Justin Kerr and Matias Turkulainen and Brent Yi and Zhuoyang Pan and Otto Seiskari and Jianbo Ye and Jeffrey Hu and Matthew Tancik and Angjoo Kanazawa},
  journal      = {Journal of Machine Learning Research},
  number       = {34},
  pages        = {1-17},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Gsplat: An open-source library for gaussian splatting},
  url          = {https://jmlr.org/papers/v26/24-1476.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Statistical inference of constrained stochastic optimization via sketched sequential quadratic programming. <em>JMLR</em>, <em>26</em>(33), 1-75. (<a href='https://jmlr.org/papers/v26/24-0530.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider online statistical inference of constrained stochastic nonlinear optimization problems. We apply the Stochastic Sequential Quadratic Programming (StoSQP) method to solve these problems, which can be regarded as applying second-order Newton's method to the Karush-Kuhn-Tucker (KKT) conditions. In each iteration, the StoSQP method computes the Newton direction by solving a quadratic program, and then selects a proper adaptive stepsize $\bar{\alpha}_t$ to update the primal-dual iterate. To reduce dominant computational cost of the method, we inexactly solve the quadratic program in each iteration by employing an iterative sketching solver. Notably, the approximation error of the sketching solver need not vanish as iterations proceed, meaning that the per-iteration computational cost does not blow up. For the above StoSQP method, we show that under mild assumptions, the rescaled primal-dual sequence $1/\sqrt{\bar{\alpha}_t}\cdot (x_t -x^\star, \lambda_t - \lambda^\star)$ converges to a mean-zero Gaussian distribution with a nontrivial covariance matrix depending on the underlying sketching distribution. To perform inference in practice, we also analyze a plug-in covariance matrix estimator. We illustrate the asymptotic normality result of the method both on benchmark nonlinear problems in CUTEst test set and on linearly/nonlinearly constrained regression problems.},
  archive      = {J_JMLR},
  author       = {Sen Na and Michael Mahoney},
  journal      = {Journal of Machine Learning Research},
  number       = {33},
  pages        = {1-75},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Statistical inference of constrained stochastic optimization via sketched sequential quadratic programming},
  url          = {https://jmlr.org/papers/v26/24-0530.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sliced-wasserstein distances and flows on cartan-hadamard manifolds. <em>JMLR</em>, <em>26</em>(32), 1-76. (<a href='https://jmlr.org/papers/v26/24-0359.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While many Machine Learning methods have been developed or transposed on Riemannian manifolds to tackle data with known non-Euclidean geometry, Optimal Transport (OT) methods on such spaces have not received much attention. The main OT tool on these spaces is the Wasserstein distance, which suffers from a heavy computational burden. On Euclidean spaces, a popular alternative is the Sliced-Wasserstein distance, which leverages a closed-form solution of the Wasserstein distance in one dimension, but which is not readily available on manifolds. In this work, we derive general constructions of Sliced-Wasserstein distances on Cartan-Hadamard manifolds, Riemannian manifolds with non-positive curvature, which include among others Hyperbolic spaces or the space of Symmetric Positive Definite matrices. Then, we propose different applications such as classification of documents with a suitably learned ground cost on a manifold, and data set comparison on a product manifold. Additionally, we derive non-parametric schemes to minimize these new distances by approximating their Wasserstein gradient flows.},
  archive      = {J_JMLR},
  author       = {Clément Bonet and Lucas Drumetz and Nicolas Courty},
  journal      = {Journal of Machine Learning Research},
  number       = {32},
  pages        = {1-76},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Sliced-wasserstein distances and flows on cartan-hadamard manifolds},
  url          = {https://jmlr.org/papers/v26/24-0359.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerating optimization over the space of probability measures. <em>JMLR</em>, <em>26</em>(31), 1-40. (<a href='https://jmlr.org/papers/v26/23-1288.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The acceleration of gradient-based optimization methods is a subject of significant practical and theoretical importance, particularly within machine learning applications. While much attention has been directed towards optimizing within Euclidean space, the need to optimize over spaces of probability measures in machine learning motivates the exploration of accelerated gradient methods in this context, too. To this end, we introduce a Hamiltonian-flow approach analogous to momentum-based approaches in Euclidean space. We demonstrate that, in the continuous-time setting, algorithms based on this approach can achieve convergence rates of arbitrarily high order. We complement our findings with numerical examples.},
  archive      = {J_JMLR},
  author       = {Shi Chen and Qin Li and Oliver Tse and Stephen J. Wright},
  journal      = {Journal of Machine Learning Research},
  number       = {31},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Accelerating optimization over the space of probability measures},
  url          = {https://jmlr.org/papers/v26/23-1288.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian multi-group gaussian process models for heterogeneous group-structured data. <em>JMLR</em>, <em>26</em>(30), 1-34. (<a href='https://jmlr.org/papers/v26/23-0291.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian processes are pervasive in functional data analysis, machine learning, and spatial statistics for modeling complex dependencies. Scientific data are often heterogeneous in their inputs and contain multiple known discrete groups of samples; thus, it is desirable to leverage the similarity among groups while accounting for heterogeneity across groups. We propose multi-group Gaussian processes (MGGPs) defined over $\mathbb{R}^p\times \mathscr{C}$, where $\mathscr{C}$ is a finite set representing the group label, by developing general classes of valid (positive definite) covariance functions on such domains. MGGPs are able to accurately recover relationships between the groups and efficiently share strength across samples from all groups during inference, while capturing distinct group-specific behaviors in the conditional posterior distributions. We demonstrate inference in MGGPs through simulation experiments, and we apply our proposed MGGP regression framework to gene expression data to illustrate the behavior and enhanced inferential capabilities of multi-group Gaussian processes by jointly modeling continuous and categorical variables.},
  archive      = {J_JMLR},
  author       = {Didong Li and Andrew Jones and Sudipto Banerjee and Barbara E. Engelhardt},
  journal      = {Journal of Machine Learning Research},
  number       = {30},
  pages        = {1-34},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Bayesian multi-group gaussian process models for heterogeneous group-structured data},
  url          = {https://jmlr.org/papers/v26/23-0291.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Orthogonal bases for equivariant graph learning with provable k-WL expressive power. <em>JMLR</em>, <em>26</em>(29), 1-35. (<a href='https://jmlr.org/papers/v26/23-0178.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural network (GNN) models have been widely used for learning graph-structured data. Due to the permutation-invariant requirement of graph learning tasks, a basic element in graph neural networks is the invariant and equivariant linear layers. Previous work (Maron et al., 2019b) provided a maximal collection of invariant and equivariant linear layers and a simple deep neural network model, called k-IGN, for graph data defined on k-tuples of nodes. It is shown that the expressive power of k-IGN is at least as good as the k-Weisfeiler-Leman (WL) algorithm in graph isomorphism tests. However, the dimension of the invariant layer and equivariant layer is the k-th and 2k-th bell numbers, respectively. Such high complexity makes it computationally infeasible for k-IGNs with k >= 3. In this paper, we show that a much smaller dimension for the linear layers is sufficient to achieve the same expressive power. We provide two sets of orthogonal bases for the linear layers, each with only 3(2^k-1)-k basis elements. Based on these linear layers, we develop neural network models GNN-a and GNN-b and show that for the graph data defined on k-tuples of data, GNN-a and GNN-b achieve the expressive power of the k-WL algorithm and the (k+1)-WL algorithm in graph isomorphism tests, respectively. In molecular prediction tasks on benchmark datasets, we demonstrate that low-order neural network models consisting of the proposed linear layers achieve better performance than other neural network models. In particular, order-2 GNN-b and order-3 GNN-a both have 3-WL expressive power, but use a much smaller basis and hence much less computation time than known neural network models.},
  archive      = {J_JMLR},
  author       = {Jia He and Maggie Cheng},
  journal      = {Journal of Machine Learning Research},
  number       = {29},
  pages        = {1-35},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Orthogonal bases for equivariant graph learning with provable k-WL expressive power},
  url          = {https://jmlr.org/papers/v26/23-0178.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal experiment design for causal effect identification. <em>JMLR</em>, <em>26</em>(28), 1-56. (<a href='https://jmlr.org/papers/v26/22-1516.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pearl’s do calculus is a complete axiomatic approach to learn the identifiable causal effects from observational data. When such an effect is not identifiable, it is necessary to perform a collection of often costly interventions in the system to learn the causal effect. In this work, we consider the problem of designing a collection of interventions with the minimum cost to identify the desired effect. First, we prove that this problem is NP-complete and subsequently propose an algorithm that can either find the optimal solution or a logarithmic-factor approximation of it. This is done by establishing a connection between our problem and the minimum hitting set problem. Additionally, we propose several polynomial time heuristic algorithms to tackle the computational complexity of the problem. Although these algorithms could potentially stumble on sub-optimal solutions, our simulations show that they achieve small regrets on random graphs.},
  archive      = {J_JMLR},
  author       = {Sina Akbari and Jalal Etesami and Negar Kiyavash},
  journal      = {Journal of Machine Learning Research},
  number       = {28},
  pages        = {1-56},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Optimal experiment design for causal effect identification},
  url          = {https://jmlr.org/papers/v26/22-1516.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mean aggregator is more robust than robust aggregators under label poisoning attacks on distributed heterogeneous data. <em>JMLR</em>, <em>26</em>(27), 1-51. (<a href='https://jmlr.org/papers/v26/24-1307.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robustness to malicious attacks is of paramount importance for distributed learning. Existing works usually consider the classical Byzantine attacks model, which assumes that some workers can send arbitrarily malicious messages to the server and disturb the aggregation steps of the distributed learning process. To defend against such worst-case Byzantine attacks, various robust aggregators have been proposed. They are proven to be effective and much superior to the often-used mean aggregator. In this paper, however, we demonstrate that the robust aggregators are too conservative for a class of weak but practical malicious attacks, known as label poisoning attacks, where the sample labels of some workers are poisoned. Surprisingly, we are able to show that the mean aggregator is more robust than the state-of-the-art robust aggregators in theory, given that the distributed data are sufficiently heterogeneous. In fact, the learning error of the mean aggregator is proven to be order-optimal in this case. Experimental results corroborate our theoretical findings, showing the superiority of the mean aggregator under label poisoning attacks.},
  archive      = {J_JMLR},
  author       = {Jie Peng and Weiyu Li and Stefan Vlaski and Qing Ling},
  journal      = {Journal of Machine Learning Research},
  number       = {27},
  pages        = {1-51},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Mean aggregator is more robust than robust aggregators under label poisoning attacks on distributed heterogeneous data},
  url          = {https://jmlr.org/papers/v26/24-1307.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The blessing of heterogeneity in federated Q-learning: Linear speedup and beyond. <em>JMLR</em>, <em>26</em>(26), 1-85. (<a href='https://jmlr.org/papers/v26/24-0579.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider federated Q-learning, which aims to learn an optimal Q-function by periodically aggregating local Q-estimates trained on local data alone. Focusing on infinite-horizon tabular Markov decision processes, we provide sample complexity guarantees for both the synchronous and asynchronous variants of federated Q-learning, which exhibit a linear speedup with respect to the number of agents and near-optimal dependencies on other salient problem parameters. In the asynchronous setting, existing analyses of federated Q-learning, which adopt an equally weighted averaging of local Q-estimates, require that every agent covers the entire state-action space. In contrast, our improved sample complexity scales inverse proportionally to the minimum entry of the average stationary state-action occupancy distribution of all agents, thus only requiring the agents to collectively cover the entire state-action space, unveiling the blessing of heterogeneity. However, its sample complexity still suffers when the local trajectories are highly heterogeneous. In response, we propose a novel federated Q-learning algorithm with importance averaging, giving larger weights to more frequently visited state-action pairs, which achieves a robust linear speedup as if all trajectories are centrally processed, regardless of the heterogeneity of local behavior policies.},
  archive      = {J_JMLR},
  author       = {Jiin Woo and Gauri Joshi and Yuejie Chi},
  journal      = {Journal of Machine Learning Research},
  number       = {26},
  pages        = {1-85},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {The blessing of heterogeneity in federated Q-learning: Linear speedup and beyond},
  url          = {https://jmlr.org/papers/v26/24-0579.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Depyf: Open the opaque box of PyTorch compiler for machine learning researchers. <em>JMLR</em>, <em>26</em>(25), 1-18. (<a href='https://jmlr.org/papers/v26/24-0383.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PyTorch 2.x introduces a compiler designed to accelerate deep learning programs. However, for machine learning researchers, fully leveraging the PyTorch compiler can be challenging due to its operation at the Python bytecode level, making it appear as an opaque box. To address this, we introduce depyf, a tool designed to demystify the inner workings of the PyTorch compiler. depyf decompiles the bytecode generated by PyTorch back into equivalent source code and establishes connections between the code objects in the memory and their counterparts in source code format on the disk. This feature enables users to step through the source code line by line using debuggers, thus enhancing their understanding of the underlying processes. Notably, depyf is non-intrusive and user-friendly, primarily relying on two convenient context managers for its core functionality. The project is openly available at https://github.com/thuml/depyf and is recognized as a PyTorch ecosystem project at https://pytorch.org/blog/introducing-depyf.},
  archive      = {J_JMLR},
  author       = {Kaichao You and Runsheng Bai and Meng Cao and Jianmin Wang and Ion Stoica and Mingsheng Long},
  journal      = {Journal of Machine Learning Research},
  number       = {25},
  pages        = {1-18},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Depyf: Open the opaque box of PyTorch compiler for machine learning researchers},
  url          = {https://jmlr.org/papers/v26/24-0383.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The ODE method for stochastic approximation and reinforcement learning with markovian noise. <em>JMLR</em>, <em>26</em>(24), 1-76. (<a href='https://jmlr.org/papers/v26/24-0100.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic approximation is a class of algorithms that update a vector iteratively, incrementally, and stochastically, including, e.g., stochastic gradient descent and temporal difference learning. One fundamental challenge in analyzing a stochastic approximation algorithm is to establish its stability, i.e., to show that the stochastic vector iterates are bounded almost surely. In this paper, we extend the celebrated Borkar-Meyn theorem for stability from the Martingale difference noise setting to the Markovian noise setting, which greatly improves its applicability in reinforcement learning, especially in those off-policy reinforcement learning algorithms with linear function approximation and eligibility traces. Central to our analysis is the diminishing asymptotic rate of change of a few functions, which is implied by both a form of the strong law of large numbers and a form of the law of the iterated logarithm.},
  archive      = {J_JMLR},
  author       = {Shuze Daniel Liu and Shuhang Chen and Shangtong Zhang},
  journal      = {Journal of Machine Learning Research},
  number       = {24},
  pages        = {1-76},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {The ODE method for stochastic approximation and reinforcement learning with markovian noise},
  url          = {https://jmlr.org/papers/v26/24-0100.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving graph neural networks on multi-node tasks with the labeling trick. <em>JMLR</em>, <em>26</em>(23), 1-44. (<a href='https://jmlr.org/papers/v26/23-0560.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study using graph neural networks (GNNs) for multi-node representation learning, where a representation for a set of more than one node (such as a link) is to be learned. Existing GNNs are mainly designed to learn single-node representations. When used for multi-node representation learning, a common practice is to directly aggregate the single-node representations obtained by a GNN. In this paper, we show a fundamental limitation of such an approach, namely the inability to capture the dependence among multiple nodes in the node set. A straightforward solution is to distinguish target nodes from others. Formalizing this idea, we propose \text{labeling trick}, which first labels nodes in the graph according to their relationships with the target node set before applying a GNN and then aggregates node representations obtained in the labeled graph for multi-node representations. Besides node sets in graphs, we also extend labeling tricks to posets, subsets and hypergraphs. Experiments verify that the labeling trick technique can boost GNNs on various tasks, including undirected link prediction, directed link prediction, hyperedge prediction, and subgraph prediction. Our work explains the superior performance of previous node-labeling-based methods and establishes a theoretical foundation for using GNNs for multi-node representation learning.},
  archive      = {J_JMLR},
  author       = {Xiyuan Wang and Pan Li and Muhan Zhang},
  journal      = {Journal of Machine Learning Research},
  number       = {23},
  pages        = {1-44},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Improving graph neural networks on multi-node tasks with the labeling trick},
  url          = {https://jmlr.org/papers/v26/23-0560.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Directed cyclic graphs for simultaneous discovery of time-lagged and instantaneous causality from longitudinal data using instrumental variables. <em>JMLR</em>, <em>26</em>(22), 1-62. (<a href='https://jmlr.org/papers/v26/23-0272.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of causal discovery from longitudinal observational data. We develop a novel framework that simultaneously discovers the time-lagged causality and the possibly cyclic instantaneous causality. Under common causal discovery assumptions, combined with additional instrumental information typically available in longitudinal data, we prove the proposed model is generally identifiable. To the best of our knowledge, this is the first causal identification theory for directed graphs with general cyclic patterns that achieves unique causal identifiability. Structural learning is carried out in a fully Bayesian fashion. Through extensive simulations and an application to the Women's Interagency HIV Study, we demonstrate the identifiability, utility, and superiority of the proposed model against state-of-the-art alternative methods.},
  archive      = {J_JMLR},
  author       = {Wei Jin and Yang Ni and Amanda B. Spence and Leah H. Rubin and Yanxun Xu},
  journal      = {Journal of Machine Learning Research},
  number       = {22},
  pages        = {1-62},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Directed cyclic graphs for simultaneous discovery of time-lagged and instantaneous causality from longitudinal data using instrumental variables},
  url          = {https://jmlr.org/papers/v26/23-0272.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian sparse gaussian mixture model for clustering in high dimensions. <em>JMLR</em>, <em>26</em>(21), 1-50. (<a href='https://jmlr.org/papers/v26/23-0142.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the sparse high-dimensional Gaussian mixture model when the number of clusters is allowed to grow with the sample size. A minimax lower bound for parameter estimation is established, and we show that a constrained maximum likelihood estimator achieves the minimax lower bound. However, this optimization-based estimator is computationally intractable because the objective function is highly nonconvex and the feasible set involves discrete structures. To address the computational challenge, we propose a computationally tractable Bayesian approach to estimate high-dimensional Gaussian mixtures whose cluster centers exhibit sparsity using a continuous spike-and-slab prior. We further prove that the posterior contraction rate of the proposed Bayesian method is minimax optimal. The mis- clustering rate is obtained as a by-product using tools from matrix perturbation theory. The proposed Bayesian sparse Gaussian mixture model does not require pre-specifying the number of clusters, which can be adaptively estimated. The validity and usefulness of the proposed method is demonstrated through simulation studies and the analysis of a real-world single-cell RNA sequencing data set.},
  archive      = {J_JMLR},
  author       = {Dapeng Yao and Fangzheng Xie and Yanxun Xu},
  journal      = {Journal of Machine Learning Research},
  number       = {21},
  pages        = {1-50},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Bayesian sparse gaussian mixture model for clustering in high dimensions},
  url          = {https://jmlr.org/papers/v26/23-0142.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Regularizing hard examples improves adversarial robustness. <em>JMLR</em>, <em>26</em>(20), 1-48. (<a href='https://jmlr.org/papers/v26/22-1428.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have validated that pruning hard-to-learn examples from training improves the generalization performance of neural networks (NNs). In this study, we investigate this intriguing phenomenon---the negative effect of hard examples on generalization---in adversarial training. Particularly, we theoretically demonstrate that the increase in the difficulty of hard examples in adversarial training is significantly greater than the increase in the difficulty of easy examples. Furthermore, we verify that hard examples are only fitted through memorization of the label in adversarial training. We conduct both theoretical and empirical analyses of this memorization phenomenon, showing that pruning hard examples in adversarial training can enhance the model's robustness. However, the challenge remains in finding the optimal threshold for removing hard examples that degrade robustness performance. Based upon these observations, we propose a new approach, difficulty proportional label smoothing (DPLS), to adaptively mitigate the negative effect of hard examples, thereby improving the adversarial robustness of NNs. Notably, our experimental result indicates that our method can successfully leverage hard examples while circumventing the negative effect.},
  archive      = {J_JMLR},
  author       = {Hyungyu Lee and Saehyung Lee and Ho Bae and Sungroh Yoon},
  journal      = {Journal of Machine Learning Research},
  number       = {20},
  pages        = {1-48},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Regularizing hard examples improves adversarial robustness},
  url          = {https://jmlr.org/papers/v26/22-1428.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Random ReLU neural networks as non-gaussian processes. <em>JMLR</em>, <em>26</em>(19), 1-31. (<a href='https://jmlr.org/papers/v26/24-0737.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a large class of shallow neural networks with randomly initialized parameters and rectified linear unit activation functions. We prove that these random neural networks are well-defined non-Gaussian processes. As a by-product, we demonstrate that these networks are solutions to stochastic differential equations driven by impulsive white noise (combinations of random Dirac measures). These processes are parameterized by the law of the weights and biases as well as the density of activation thresholds in each bounded region of the input domain. We prove that these processes are isotropic and wide-sense self-similar with Hurst exponent 3/2. We also derive a remarkably simple closed-form expression for their autocovariance function. Our results are fundamentally different from prior work in that we consider a non-asymptotic viewpoint: The number of neurons in each bounded region of the input domain (i.e., the width) is itself a random variable with a Poisson law with mean proportional to the density parameter. Finally, we show that, under suitable hypotheses, as the expected width tends to infinity, these processes can converge in law not only to Gaussian processes, but also to non-Gaussian processes depending on the law of the weights. Our asymptotic results provide a new take on several classical results (wide networks converge to Gaussian processes) as well as some new ones (wide networks can converge to non-Gaussian processes).},
  archive      = {J_JMLR},
  author       = {Rahul Parhi and Pakshal Bohra and Ayoub El Biari and Mehrsa Pourya and Michael Unser},
  journal      = {Journal of Machine Learning Research},
  number       = {19},
  pages        = {1-31},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Random ReLU neural networks as non-gaussian processes},
  url          = {https://jmlr.org/papers/v26/24-0737.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Riemannian bilevel optimization. <em>JMLR</em>, <em>26</em>(18), 1-44. (<a href='https://jmlr.org/papers/v26/24-0397.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider the bilevel optimization problem on Riemannian manifolds. We inspect the calculation of the hypergradient of such problems on general manifolds and thus enable the utilization of gradient-based algorithms to solve such problems. The calculation of the hypergradient requires utilizing the notion of Riemannian cross-derivative and we inspect the properties and the numerical calculations of Riemannian cross-derivatives. Algorithms in both deterministic and stochastic settings, named respectively RieBO and RieSBO, are proposed that include the existing Euclidean bilevel optimization algorithms as special cases. Numerical experiments on robust optimization on Riemannian manifolds are presented to show the applicability and efficiency of the proposed methods.},
  archive      = {J_JMLR},
  author       = {Jiaxiang Li and Shiqian Ma},
  journal      = {Journal of Machine Learning Research},
  number       = {18},
  pages        = {1-44},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Riemannian bilevel optimization},
  url          = {https://jmlr.org/papers/v26/24-0397.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Supervised learning with evolving tasks and performance guarantees. <em>JMLR</em>, <em>26</em>(17), 1-59. (<a href='https://jmlr.org/papers/v26/24-0343.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple supervised learning scenarios are composed by a sequence of classification tasks. For instance, multi-task learning and continual learning aim to learn a sequence of tasks that is either fixed or grows over time. Existing techniques for learning tasks that are in a sequence are tailored to specific scenarios, lacking adaptability to others. In addition, most of existing techniques consider situations in which the order of the tasks in the sequence is not relevant. However, it is common that tasks in a sequence are evolving in the sense that consecutive tasks often have a higher similarity. This paper presents a learning methodology that is applicable to multiple supervised learning scenarios and adapts to evolving tasks. Differently from existing techniques, we provide computable tight performance guarantees and analytically characterize the increase in the effective sample size. Experiments on benchmark datasets show the performance improvement of the proposed methodology in multiple scenarios and the reliability of the presented performance guarantees.},
  archive      = {J_JMLR},
  author       = {Verónica Álvarez and Santiago Mazuelas and Jose A. Lozano},
  journal      = {Journal of Machine Learning Research},
  number       = {17},
  pages        = {1-59},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Supervised learning with evolving tasks and performance guarantees},
  url          = {https://jmlr.org/papers/v26/24-0343.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Error estimation and adaptive tuning for unregularized robust M-estimator. <em>JMLR</em>, <em>26</em>(16), 1-40. (<a href='https://jmlr.org/papers/v26/24-0060.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider unregularized robust M-estimators for linear models under Gaussian design and heavy-tailed noise, in the proportional asymptotics regime where the sample size n and the number of features p are both increasing such that $p/n \to \gamma\in (0,1)$. An estimator of the out-of-sample error of a robust M-estimator is analyzed and proved to be consistent for a large family of loss functions that includes the Huber loss. As an application of this result, we propose an adaptive tuning procedure of the scale parameter $\lambda>0$ of a given loss function $\rho$: choosing $\hat \lambda$ in a given interval $I$ that minimizes the out-of-sample error estimate of the M-estimator constructed with loss $\rho_\lambda(\cdot) = \lambda^2 \rho(\cdot/\lambda)$ leads to the optimal out-of-sample error over $I$. The proof relies on a smoothing argument: the unregularized M-estimation objective function is perturbed, or smoothed, with a Ridge penalty that vanishes as $n\to+\infty$, and shows that the unregularized M-estimator of interest inherits properties of its smoothed version.},
  archive      = {J_JMLR},
  author       = {Pierre C. Bellec and Takuya Koriyama},
  journal      = {Journal of Machine Learning Research},
  number       = {16},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Error estimation and adaptive tuning for unregularized robust M-estimator},
  url          = {https://jmlr.org/papers/v26/24-0060.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From sparse to dense functional data in high dimensions: Revisiting phase transitions from a non-asymptotic perspective. <em>JMLR</em>, <em>26</em>(15), 1-40. (<a href='https://jmlr.org/papers/v26/23-1578.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonparametric estimation of the mean and covariance functions is ubiquitous in functional data analysis and local linear smoothing techniques are most frequently used. Zhang and Wang (2016) explored different types of asymptotic properties of the estimation, which reveal interesting phase transition phenomena based on the relative order of the average sampling frequency per subject $T$ to the number of subjects $n$, partitioning the data into three categories: “sparse”, “semi-dense”, and “ultra-dense”. In an increasingly available high-dimensional scenario, where the number of functional variables $p$ is large in relation to $n$, we revisit this open problem from a non-asymptotic perspective by deriving comprehensive concentration inequalities for the local linear smoothers. Besides being of interest by themselves, our non-asymptotic results lead to elementwise maximum rates of $L_2$ convergence and uniform convergence serving as a fundamentally important tool for further convergence analysis when $p$ grows exponentially with $n$ and possibly $T$. With the presence of extra $\log p$ terms to account for the high-dimensional effect, we then investigate the scaled phase transitions and the corresponding elementwise maximum rates from sparse to semi-dense to ultra-dense functional data in high dimensions. We also discuss a couple of applications of our theoretical results. Finally, numerical studies are carried out to confirm the established theoretical properties.},
  archive      = {J_JMLR},
  author       = {Shaojun Guo and Dong Li and Xinghao Qiao and Yizhu Wang},
  journal      = {Journal of Machine Learning Research},
  number       = {15},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {From sparse to dense functional data in high dimensions: Revisiting phase transitions from a non-asymptotic perspective},
  url          = {https://jmlr.org/papers/v26/23-1578.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Locally private causal inference for randomized experiments. <em>JMLR</em>, <em>26</em>(14), 1-40. (<a href='https://jmlr.org/papers/v26/23-1401.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local differential privacy is a differential privacy paradigm in which individuals first apply a privacy mechanism to their data (often by adding noise) before transmitting the result to a curator. The noise for privacy results in additional bias and variance in their analyses. Thus it is of great importance for analysts to incorporate the privacy noise into valid inference. In this article, we develop methodologies to infer causal effects from locally privatized data under randomized experiments. First, we present frequentist estimators under various privacy scenarios with their variance estimators and plug-in confidence intervals. We show a na\"ive debiased estimator results in inferior mean-squared error (MSE) compared to minimax lower bounds. In contrast, we show that using a customized privacy mechanism, we can match the lower bound, giving minimax optimal inference. We also develop a Bayesian nonparametric methodology along with a blocked Gibbs sampling algorithm, which can be applied to any of our proposed privacy mechanisms, and which performs especially well in terms of MSE for tight privacy budgets. Finally, we present simulation studies to evaluate the performance of our proposed frequentist and Bayesian methodologies for various privacy budgets, resulting in useful suggestions for performing causal inference for privatized data.},
  archive      = {J_JMLR},
  author       = {Yuki Ohnishi and Jordan Awan},
  journal      = {Journal of Machine Learning Research},
  number       = {14},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Locally private causal inference for randomized experiments},
  url          = {https://jmlr.org/papers/v26/23-1401.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimating network-mediated causal effects via principal components network regression. <em>JMLR</em>, <em>26</em>(13), 1-99. (<a href='https://jmlr.org/papers/v26/23-1317.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a method to decompose causal effects on a social network into an indirect effect mediated by the network, and a direct effect independent of the social network. To handle the complexity of network structures, we assume that latent social groups act as causal mediators. We develop principal components network regression models to differentiate the social effect from the non-social effect. Fitting the regression models is as simple as principal components analysis followed by ordinary least squares estimation. We prove asymptotic theory for regression coefficients from this procedure and show that it is widely applicable, allowing for a variety of distributions on the regression errors and network edges. We carefully characterize the counterfactual assumptions necessary to use the regression models for causal inference, and show that current approaches to causal network regression may result in over-control bias. The method is very general, so that it is applicable to many types of structured data beyond social networks, such as text, areal data, psychometrics, images and omics.},
  archive      = {J_JMLR},
  author       = {Alex Hayes and Mark M. Fredrickson and Keith Levin},
  journal      = {Journal of Machine Learning Research},
  number       = {13},
  pages        = {1-99},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Estimating network-mediated causal effects via principal components network regression},
  url          = {https://jmlr.org/papers/v26/23-1317.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selective inference with distributed data. <em>JMLR</em>, <em>26</em>(12), 1-44. (<a href='https://jmlr.org/papers/v26/23-0309.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When data are distributed across multiple sites or machines rather than centralized in one location, researchers face the challenge of extracting meaningful information without directly sharing individual data points. While there are many distributed methods for point estimation using sparse regression, few options are available for estimating uncertainties or conducting hypothesis tests based on the estimated sparsity. In this paper, we introduce a procedure for performing selective inference with distributed data. We consider a scenario where each local machine solves a lasso problem and communicates the selected predictors to a central machine. The central machine then aggregates these selected predictors to form a generalized linear model (GLM). Our goal is to provide valid inference for the selected GLM while reusing data that have been used in the model selection process. Our proposed procedure only requires low-dimensional summary statistics from local machines, thus keeping communication costs low and preserving the privacy of individual data sets. Furthermore, this procedure can be applied in scenarios where model selection is repeatedly conducted on randomly subsampled data sets, addressing the p-value lottery problem linked with model selection. We demonstrate the effectiveness of our approach through simulations and an analysis of a medical data set on ICU admissions.},
  archive      = {J_JMLR},
  author       = {Sifan Liu and Snigdha Panigrahi},
  journal      = {Journal of Machine Learning Research},
  number       = {12},
  pages        = {1-44},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Selective inference with distributed data},
  url          = {https://jmlr.org/papers/v26/23-0309.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-timescale gradient descent ascent algorithms for nonconvex minimax optimization. <em>JMLR</em>, <em>26</em>(11), 1-45. (<a href='https://jmlr.org/papers/v26/22-0863.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a unified analysis of two-timescale gradient descent ascent (TTGDA) for solving structured nonconvex minimax optimization problems in the form of $\min_x \max_{y \in Y} f(x, y)$, where the objective function $f(x, y)$ is nonconvex in $x$ and concave in $y$, and the constraint set $Y \subseteq \mathbb{R}^n$ is convex and bounded. In the convex-concave setting, the single-timescale gradient descent ascent (GDA) algorithm is widely used in applications and has been shown to have strong convergence guarantees. In more general settings, however, it can fail to converge. Our contribution is to design TTGDA algorithms that are effective beyond the convex-concave setting, efficiently finding a stationary point of the function $\Phi(\cdot) := \max_{y \in Y} f(\cdot, y)$. We also establish theoretical bounds on the complexity of solving both smooth and nonsmooth nonconvex-concave minimax optimization problems. To the best of our knowledge, this is the first systematic analysis of TTGDA for nonconvex minimax optimization, shedding light on its superior performance in training generative adversarial networks (GANs) and in other real-world application problems.},
  archive      = {J_JMLR},
  author       = {Tianyi Lin and Chi Jin and Michael I. Jordan},
  journal      = {Journal of Machine Learning Research},
  number       = {11},
  pages        = {1-45},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Two-timescale gradient descent ascent algorithms for nonconvex minimax optimization},
  url          = {https://jmlr.org/papers/v26/22-0863.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An axiomatic definition of hierarchical clustering. <em>JMLR</em>, <em>26</em>(10), 1-26. (<a href='https://jmlr.org/papers/v26/24-1052.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we take an axiomatic approach to defining a population hierarchical clustering for piecewise constant densities, and in a similar manner to Lebesgue integration, extend this definition to more general densities. When the density satisfies some mild conditions, e.g., when it has connected support, is continuous, and vanishes only at infinity, or when the connected components of the density satisfy these conditions, our axiomatic definition results in Hartigan's definition of cluster tree.},
  archive      = {J_JMLR},
  author       = {Ery Arias-Castro and Elizabeth Coda},
  journal      = {Journal of Machine Learning Research},
  number       = {10},
  pages        = {1-26},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {An axiomatic definition of hierarchical clustering},
  url          = {https://jmlr.org/papers/v26/24-1052.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Test-time training on video streams. <em>JMLR</em>, <em>26</em>(9), 1-29. (<a href='https://jmlr.org/papers/v26/24-0439.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prior work has established Test-Time Training (TTT) as a general framework to further improve a trained model at test time. Before making a prediction on each test instance, the model is first trained on the same instance using a self-supervised task such as reconstruction. We extend TTT to the streaming setting, where multiple test instances - video frames in our case - arrive in temporal order. Our extension is online TTT: The current model is initialized from the previous model, then trained on the current frame and a small window of frames immediately before. Online TTT significantly outperforms the fixed-model baseline for four tasks, on three real-world datasets. The improvements are more than 2.2x and 1.5x for instance and panoptic segmentation. Surprisingly, online TTT also outperforms its offline variant that accesses strictly more information, training on all frames from the entire test video regardless of temporal order. This finding challenges those in prior work using synthetic videos. We formalize a notion of locality as the advantage of online over offline TTT, and analyze its role with ablations and a theory based on bias-variance trade-off.},
  archive      = {J_JMLR},
  author       = {Renhao Wang and Yu Sun and Arnuv Tandon and Yossi Gandelsman and Xinlei Chen and Alexei A. Efros and Xiaolong Wang},
  journal      = {Journal of Machine Learning Research},
  number       = {9},
  pages        = {1-29},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Test-time training on video streams},
  url          = {https://jmlr.org/papers/v26/24-0439.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive client sampling in federated learning via online learning with bandit feedback. <em>JMLR</em>, <em>26</em>(8), 1-67. (<a href='https://jmlr.org/papers/v26/24-0385.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the high cost of communication, federated learning (FL) systems need to sample a subset of clients that are involved in each round of training. As a result, client sampling plays an important role in FL systems as it affects the convergence rate of optimization algorithms used to train machine learning models. Despite its importance, there is limited work on how to sample clients effectively. In this paper, we cast client sampling as an online learning task with bandit feedback, which we solve with an online stochastic mirror descent (OSMD) algorithm designed to minimize the sampling variance. We then theoretically show how our sampling method can improve the convergence speed of federated optimization algorithms over the widely used uniform sampling. Through both simulated and real data experiments, we empirically illustrate the advantages of the proposed client sampling algorithm over uniform sampling and existing online learning-based sampling strategies. The proposed adaptive sampling procedure is applicable beyond the FL problem studied here and can be used to improve the performance of stochastic optimization procedures such as stochastic gradient descent and stochastic coordinate descent.},
  archive      = {J_JMLR},
  author       = {Boxin Zhao and Lingxiao Wang and Ziqi Liu and Zhiqiang Zhang and Jun Zhou and Chaochao Chen and Mladen Kolar},
  journal      = {Journal of Machine Learning Research},
  number       = {8},
  pages        = {1-67},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Adaptive client sampling in federated learning via online learning with bandit feedback},
  url          = {https://jmlr.org/papers/v26/24-0385.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A random matrix approach to low-multilinear-rank tensor approximation. <em>JMLR</em>, <em>26</em>(7), 1-64. (<a href='https://jmlr.org/papers/v26/24-0193.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a comprehensive understanding of the estimation of a planted low-rank signal from a general spiked tensor model near the computational threshold. Relying on standard tools from the theory of large random matrices, we characterize the large-dimensional spectral behavior of the unfoldings of the data tensor and exhibit relevant signal-to-noise ratios governing the detectability of the principal directions of the signal. These results allow to accurately predict the reconstruction performance of truncated multilinear SVD (MLSVD) in the non-trivial regime. This is particularly important since it serves as an initialization of the higher-order orthogonal iteration (HOOI) scheme, whose convergence to the best low-multilinear-rank approximation depends entirely on its initialization. We give a sufficient condition for the convergence of HOOI and show that the number of iterations before convergence tends to $1$ in the large-dimensional limit.},
  archive      = {J_JMLR},
  author       = {Hugo Lebeau and Florent Chatelain and Romain Couillet},
  journal      = {Journal of Machine Learning Research},
  number       = {7},
  pages        = {1-64},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A random matrix approach to low-multilinear-rank tensor approximation},
  url          = {https://jmlr.org/papers/v26/24-0193.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memory gym: Towards endless tasks to benchmark memory capabilities of agents. <em>JMLR</em>, <em>26</em>(6), 1-40. (<a href='https://jmlr.org/papers/v26/24-0043.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memory Gym presents a suite of 2D partially observable environments, namely Mortar Mayhem, Mystery Path, and Searing Spotlights, designed to benchmark memory capabilities in decision-making agents. These environments, originally with finite tasks, are expanded into innovative, endless formats, mirroring the escalating challenges of cumulative memory games such as “I packed my bag”. This progression in task design shifts the focus from merely assessing sample efficiency to also probing the levels of memory effectiveness in dynamic, prolonged scenarios. To address the gap in available memory-based Deep Reinforcement Learning baselines, we introduce an implementation within the open-source CleanRL library that integrates Transformer-XL (TrXL) with Proximal Policy Optimization. This approach utilizes TrXL as a form of episodic memory, employing a sliding window technique. Our comparative study between the Gated Recurrent Unit (GRU) and TrXL reveals varied performances across our finite and endless tasks. TrXL, on the finite environments, demonstrates superior effectiveness over GRU, but only when utilizing an auxiliary loss to reconstruct observations. Notably, GRU makes a remarkable resurgence in all endless tasks, consistently outperforming TrXL by significant margins. Website and Source Code: https://marcometer.github.io/jmlr_2024.github.io/},
  archive      = {J_JMLR},
  author       = {Marco Pleines and Matthias Pallasch and Frank Zimmer and Mike Preuss},
  journal      = {Journal of Machine Learning Research},
  number       = {6},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Memory gym: Towards endless tasks to benchmark memory capabilities of agents},
  url          = {https://jmlr.org/papers/v26/24-0043.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing graph representation learning with localized topological features. <em>JMLR</em>, <em>26</em>(5), 1-36. (<a href='https://jmlr.org/papers/v26/23-1424.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning on graphs is a fundamental problem that can be crucial in various tasks. Graph neural networks, the dominant approach for graph representation learning, are limited in their representation power. Therefore, it can be beneficial to explicitly extract and incorporate high-order topological and geometric information into these models. In this paper, we propose a principled approach to extract the rich connectivity information of graphs based on the theory of persistent homology. Our method utilizes the topological features to enhance the representation learning of graph neural networks and achieve state-of-the-art performance on various node classification and link prediction benchmarks. We also explore the option of end-to-end learning of the topological features, i.e., treating topological computation as a differentiable operator during learning. Our theoretical analysis and empirical study provide insights and potential guidelines for employing topological features in graph learning tasks.},
  archive      = {J_JMLR},
  author       = {Zuoyu Yan and Qi Zhao and Ze Ye and Tengfei Ma and Liangcai Gao and Zhi Tang and Yusu Wang and Chao Chen},
  journal      = {Journal of Machine Learning Research},
  number       = {5},
  pages        = {1-36},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Enhancing graph representation learning with localized topological features},
  url          = {https://jmlr.org/papers/v26/23-1424.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep out-of-distribution uncertainty quantification via weight entropy maximization. <em>JMLR</em>, <em>26</em>(4), 1-68. (<a href='https://jmlr.org/papers/v26/23-1359.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with uncertainty quantification and out-of-distribution detection in deep learning using Bayesian and ensemble methods. It proposes a practical solution to the lack of prediction diversity observed recently for standard approaches when used out-of-distribution (Ovadia et al., 2019; Liu et al., 2021). Considering that this issue is mainly related to a lack of weight diversity, we claim that standard methods sample in "over-restricted" regions of the weight space due to the use of "over-regularization" processes, such as weight decay and zero-mean centered Gaussian priors. We propose to solve the problem by adopting the maximum entropy principle for the weight distribution, with the underlying idea to maximize the weight diversity. Under this paradigm, the epistemic uncertainty is described by the weight distribution of maximal entropy that produces neural networks "consistent" with the training observations. Considering stochastic neural networks, a practical optimization is derived to build such a distribution, defined as a trade-off between the average empirical risk and the weight distribution entropy. We provide both theoretical and numerical results to assess the efficiency of the approach. In particular, the proposed algorithm appears in the top three best methods in all configurations of an extensive out-of-distribution detection benchmark including more than thirty competitors.},
  archive      = {J_JMLR},
  author       = {Antoine de Mathelin and François Deheeger and Mathilde Mougeot and Nicolas Vayatis},
  journal      = {Journal of Machine Learning Research},
  number       = {4},
  pages        = {1-68},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Deep out-of-distribution uncertainty quantification via weight entropy maximization},
  url          = {https://jmlr.org/papers/v26/23-1359.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DisC2o-HD: Distributed causal inference with covariates shift for analyzing real-world high-dimensional data. <em>JMLR</em>, <em>26</em>(3), 1-50. (<a href='https://jmlr.org/papers/v26/23-1254.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional healthcare data, such as electronic health records (EHR) data and claims data, present two primary challenges due to the large number of variables and the need to consolidate data from multiple clinical sites. The third key challenge is the potential existence of heterogeneity in terms of covariate shift. In this paper, we propose a distributed learning algorithm accounting for covariate shift to estimate the average treatment effect (ATE) for high-dimensional data, named DisC2o-HD. Leveraging the surrogate likelihood method, our method calibrates the estimates of the propensity score and outcome models to approximately attain the desired covariate balancing property, while accounting for the covariate shift across multiple clinical sites. We show that our distributed covariate balancing propensity score estimator can approximate the pooled estimator, which is obtained by pooling the data from multiple sites together. The proposed estimator remains consistent if either the propensity score model or the outcome regression model is correctly specified. The semiparametric efficiency bound is achieved when both the propensity score and the outcome models are correctly specified. We conduct simulation studies to demonstrate the performance of the proposed algorithm; additionally, we conduct an empirical study to present the readiness of implementation and validity.},
  archive      = {J_JMLR},
  author       = {Jiayi Tong and Jie Hu and George Hripcsak and Yang Ning and Yong Chen},
  journal      = {Journal of Machine Learning Research},
  number       = {3},
  pages        = {1-50},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {DisC2o-HD: Distributed causal inference with covariates shift for analyzing real-world high-dimensional data},
  url          = {https://jmlr.org/papers/v26/23-1254.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayes meets bernstein at the meta level: An analysis of fast rates in meta-learning with PAC-bayes. <em>JMLR</em>, <em>26</em>(2), 1-60. (<a href='https://jmlr.org/papers/v26/23-025.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bernstein's condition is a key assumption that guarantees fast rates in machine learning. For example, under this condition, the Gibbs posterior with prior $\pi$ has an excess risk in $O(d_{\pi}/n)$, as opposed to $O(\sqrt{d_{\pi}/n})$ in the general case, where $n$ denotes the number of observations and $d_{\pi}$ is a complexity parameter which depends on the prior $\pi$. In this paper, we examine the Gibbs posterior in the context of meta-learning, i.e., when learning the prior $\pi$ from $T$ previous tasks. Our main result is that Bernstein's condition always holds at the meta level, regardless of its validity at the observation level. This implies that the additional cost to learn the Gibbs prior $\pi$, which will reduce the term $d_\pi$ across tasks, is in $O(1/T)$, instead of the expected $O(1/\sqrt{T})$. We further illustrate how this result improves on the standard rates in three different settings: discrete priors, Gaussian priors and mixture of Gaussian priors.},
  archive      = {J_JMLR},
  author       = {Charles Riou and Pierre Alquier and Badr-Eddine Chérief-Abdellatif},
  journal      = {Journal of Machine Learning Research},
  number       = {2},
  pages        = {1-60},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Bayes meets bernstein at the meta level: An analysis of fast rates in meta-learning with PAC-bayes},
  url          = {https://jmlr.org/papers/v26/23-025.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficiently escaping saddle points in bilevel optimization. <em>JMLR</em>, <em>26</em>(1), 1-61. (<a href='https://jmlr.org/papers/v26/22-0136.html'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bilevel optimization is one of the fundamental problems in machine learning and optimization. Recent theoretical developments in bilevel optimization focus on finding the first-order stationary points for nonconvex-strongly-convex cases. In this paper, we analyze algorithms that can escape saddle points in nonconvex-strongly-convex bilevel optimization. Specifically, we show that the perturbed approximate implicit differentiation (AID) with a warm start strategy finds an $\epsilon$-approximate local minimum of bilevel optimization in $\tilde{O}(\epsilon^{-2})$ iterations with high probability. Moreover, we propose an inexact NEgative-curvature-Originated-from-Noise Algorithm (iNEON), an algorithm that can escape saddle point and find local minimum of stochastic bilevel optimization. As a by-product, we provide the first nonasymptotic analysis of perturbed multi-step gradient descent ascent (GDmax) algorithm that converges to local minimax point for minimax problems.},
  archive      = {J_JMLR},
  author       = {Minhui Huang and Xuxing Chen and Kaiyi Ji and Shiqian Ma and Lifeng Lai},
  journal      = {Journal of Machine Learning Research},
  number       = {1},
  pages        = {1-61},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Efficiently escaping saddle points in bilevel optimization},
  url          = {https://jmlr.org/papers/v26/22-0136.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
