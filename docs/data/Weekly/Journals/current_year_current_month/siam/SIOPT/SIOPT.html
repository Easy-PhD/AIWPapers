<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SIOPT</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="siopt">SIOPT - 29</h2>
<ul>
<li><details>
<summary>
(2025). Exact convergence rate of the last iterate in subgradient methods. <em>SIOPT</em>, <em>35</em>(3), 2182-2201. (<a href='https://doi.org/10.1137/24M1717762'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study the convergence of the last iterate in subgradient methods applied to the minimization of a nonsmooth convex function with bounded subgradients. Using a novel proof technique that tracks distances to varying reference points, we derive tight worst-case convergence rates for the (projected) subgradient method with constant step sizes or step lengths. We identify the optimal constant step size for a given number of iterations , yielding a last-iterate accuracy smaller than , where bounds subgradient norms and bounds the initial distance to a minimizer. We also propose a new optimal subgradient method based on a linearly decaying sequence of step sizes that achieves a rate for the last iterate equal to , matching the theoretical lower bound. Finally, we show that no universal step size sequence can attain this rate across all iterations, highlighting that the dependence of the step size sequence in is unavoidable.},
  archive      = {J_SIOPT},
  author       = {Moslem Zamani and François Glineur},
  doi          = {10.1137/24M1717762},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2182-2201},
  shortjournal = {SIAM J. Optim.},
  title        = {Exact convergence rate of the last iterate in subgradient methods},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TS-RSR: A provably efficient approach for batch bayesian optimization. <em>SIOPT</em>, <em>35</em>(3), 2155-2181. (<a href='https://doi.org/10.1137/24M1675102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper presents a new approach for batch Bayesian optimization (BO) called Thompson Sampling-Regret to Sigma Ratio directed sampling (TS-RSR), where we sample a new batch of actions by minimizing a TS approximation of a regret to uncertainty ratio. Our sampling objective is to coordinate the actions chosen in each batch in a way that minimizes redundancy between points while focusing on points with high predictive means or high uncertainty. Theoretically, we provide rigorous convergence guarantees on our algorithm’s regret, and numerically we demonstrate that our method attains state-of-the-art performance on a range of challenging synthetic and realistic test functions, where it outperforms several competitive benchmark batch BO algorithms.},
  archive      = {J_SIOPT},
  author       = {Zhaolin Ren and Na Li},
  doi          = {10.1137/24M1675102},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2155-2181},
  shortjournal = {SIAM J. Optim.},
  title        = {TS-RSR: A provably efficient approach for batch bayesian optimization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sharp global guarantees for nonconvex low-rank recovery in the noisy overparameterized regime. <em>SIOPT</em>, <em>35</em>(3), 2128-2154. (<a href='https://doi.org/10.1137/24M1697980'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Recent work established that rank overparameterization eliminates spurious local minima in nonconvex low-rank matrix recovery under the restricted isometry property (RIP). But this does not fully explain the practical success of overparameterization, because real algorithms can still become trapped at nonstrict saddle points (approximate second-order points with arbitrarily small negative curvature) even when all local minima are global. Moreover, the result does not accommodate for noisy measurements, but it is unclear whether such an extension is even possible, in view of the many discontinuous and unintuitive behaviors already known for the overparameterized regime. In this paper, we introduce a novel proof technique that unifies, simplifies, and strengthens two previously competing approaches—one based on escape directions and the other based on the inexistence of counterexample—to provide sharp global guarantees in the noisy overparameterized regime. We show, once local minima have been converted into global minima through slight overparameterization, that near-second-order points achieve the same minimax-optimal recovery bounds (up to small constant factors) as significantly more expensive convex approaches. Our results are sharp with respect to the noise level and the solution accuracy, and hold for both the symmetric parameterization and the asymmetric parameterization under a balancing regularizer; we demonstrate that the balancing regularizer is indeed necessary.},
  archive      = {J_SIOPT},
  author       = {Richard Y. Zhang},
  doi          = {10.1137/24M1697980},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2128-2154},
  shortjournal = {SIAM J. Optim.},
  title        = {Sharp global guarantees for nonconvex low-rank recovery in the noisy overparameterized regime},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complexity of zeroth- and first-order stochastic trust-region algorithms. <em>SIOPT</em>, <em>35</em>(3), 2098-2127. (<a href='https://doi.org/10.1137/24M1664484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Model update (MU) and candidate evaluation (CE) are classical steps incorporated inside many stochastic trust-region (TR) algorithms. The sampling effort exerted within these steps, often decided with the aim of controlling model error, largely determines a stochastic TR algorithm’s sample complexity. Given that MU and CE are amenable to variance reduction, we investigate the effect of incorporating common random numbers (CRN) within MU and CE on complexity. Using ASTRO and ASTRO-DF as prototype first-order and zeroth-order families of algorithms, we demonstrate that CRN’s effectiveness leads to a range of complexities depending on sample-path regularity and the oracle order. For instance, we find that in first-order oracle settings with smooth sample paths, CRN’s effect is pronounced—ASTRO with CRN achieves a.s. sample complexity compared to a.s. in the generic no-CRN setting. By contrast, CRN’s effect is muted when the sample paths are not Lipschitz, with the sample complexity improving from a.s. to and a.s. in the zeroth- and first-order settings, respectively. Since our results imply that improvements in complexity are largely inherited from generic aspects of variance reduction, e.g., finite-differencing for zeroth-order settings and sample-path smoothness for first-order settings within MU, we anticipate similar trends in other contexts.},
  archive      = {J_SIOPT},
  author       = {Yunsoo Ha and Sara Shashaani and Raghu Pasupathy},
  doi          = {10.1137/24M1664484},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2098-2127},
  shortjournal = {SIAM J. Optim.},
  title        = {Complexity of zeroth- and first-order stochastic trust-region algorithms},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized optimistic methods for convex-concave saddle point problems. <em>SIOPT</em>, <em>35</em>(3), 2066-2097. (<a href='https://doi.org/10.1137/24M1630475'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The optimistic gradient method has seen increasing popularity as an efficient first-order method for solving convex-concave saddle point problems. To analyze its iteration complexity, a recent work [A. Mokhtari, A. E. Ozdaglar, and S. Pattathil, SIAM J. Optim., 30 (2020), pp. 3230–3251] proposed an interesting perspective that interprets the optimistic gradient method as an approximation to the proximal point method. In this paper, we follow this approach and distill the underlying idea of optimism to propose a generalized optimistic method, which encompasses the optimistic gradient method as a special case. Our general framework can handle constrained saddle point problems with composite objective functions. Moreover, we also develop a backtracking line search scheme to select the step sizes without knowledge of the smoothness coefficients. By instantiating our general framework with a second-order oracle, we propose a second-order optimistic method and prove a complexity bound of in terms of the primal-dual gap in the convex-concave setting and a complexity bound of in terms of the distance to the optimal solution in the strongly-convex-strongly-concave setting, where is the Lipschitz constant of the Jacobian, is the strong convexity parameter, and is the initial Euclidean distance to the saddle point. We also establish convergence rates in terms of the tangent residual, which generalizes the operator norm as a metric in the unconstrained setting. Moreover, our line search scheme provably only requires a constant number of calls to a subproblem solver per iteration on average.},
  archive      = {J_SIOPT},
  author       = {Ruichen Jiang and Aryan Mokhtari},
  doi          = {10.1137/24M1630475},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2066-2097},
  shortjournal = {SIAM J. Optim.},
  title        = {Generalized optimistic methods for convex-concave saddle point problems},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A symmetric Gauss–Seidel based majorized augmented lagrangian method for generalized nash equilibrium problems in hilbert spaces. <em>SIOPT</em>, <em>35</em>(3), 2040-2065. (<a href='https://doi.org/10.1137/24M1678143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a new numerical method for solving a generalized Nash equilibrium problem (GNEP) involving players, incorporating general constraints formulated in Hilbert spaces. These constraints may include linear equality, linear inequality, or conic constraints. Instead of handling joint constraints and nonlinear objectives directly, we reformulate the problem as an equality-constrained GNEP with separable structure and then construct a quadratic majorization augmented Lagrangian function for the resulting GNEP. A majorized augmented Lagrangian method (ALM) is then designed to solve the equivalent GNEP. Each iteration requires solving a coupled Nash equilibrium problem (NEP). To address this, we introduce a symmetric Gauss–Seidel (sGS) decomposition method to decouple the NEP into a sequence of single-objective unconstrained quadratic programs. We establish the convergence of this ALM under mild assumptions in a weak topology and prove the strong convergence of the primal sequence under additional regularity assumptions. Finally, numerical experiments demonstrate the effectiveness and efficiency of our algorithm.},
  archive      = {J_SIOPT},
  author       = {Hailing Wang and Di Wu and Song Wang and Kok Lay Teo and Changjun Yu},
  doi          = {10.1137/24M1678143},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2040-2065},
  shortjournal = {SIAM J. Optim.},
  title        = {A symmetric Gauss–Seidel based majorized augmented lagrangian method for generalized nash equilibrium problems in hilbert spaces},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Subdifferentials and penalty approximations of the obstacle problem. <em>SIOPT</em>, <em>35</em>(3), 2017-2039. (<a href='https://doi.org/10.1137/24M172202X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a framework for approximating the obstacle problem through a penalty approach by nonlinear PDEs. By using tools from capacity theory, we show that derivatives of the solution maps of the penalized problems converge in the weak operator topology to an element of the strong-weak Bouligand subdifferential. We are able to treat smooth penalty terms as well as nonsmooth ones involving, for example, the positive part function . Our abstract framework applies to several specific choices of penalty functions which are omnipresent in the literature. We conclude with consequences to the theory of optimal control of the obstacle problem.},
  archive      = {J_SIOPT},
  author       = {Amal Alphonse and Gerd Wachsmuth},
  doi          = {10.1137/24M172202X},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2017-2039},
  shortjournal = {SIAM J. Optim.},
  title        = {Subdifferentials and penalty approximations of the obstacle problem},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convex optimization problems inspired by geotechnical stability analysis. <em>SIOPT</em>, <em>35</em>(3), 1993-2016. (<a href='https://doi.org/10.1137/25M1723177'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper is motivated by the limit load, limit analysis, and shear strength reduction methods, which are commonly employed in geotechnical stability analysis or similar applications. The aim is to make these methods more approachable by introducing a unified framework based on abstract convex optimization and its parametric studies. We establish suitable assumptions on the abstract problems that capture the selected features of these methods and facilitate rigorous theoretical investigation. Further, we propose continuation techniques tailored to the resulting parametric problem formulations and show that the developed abstract framework could also be useful outside the domain of geotechnical stability analysis. The main results are illustrated with analytical and numerical examples. The numerical example deals with a 3D slope stability problem.},
  archive      = {J_SIOPT},
  author       = {Stanislav Sysala and Michal Béreš and Simona Bérešová and Jaroslav Haslinger and Jakub Kružík and Tomáš Luber},
  doi          = {10.1137/25M1723177},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1993-2016},
  shortjournal = {SIAM J. Optim.},
  title        = {Convex optimization problems inspired by geotechnical stability analysis},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the Bredies–Chenchene–Lorenz–Naldi algorithm: Linear relations and strong convergence. <em>SIOPT</em>, <em>35</em>(3), 1963-1992. (<a href='https://doi.org/10.1137/23M1587919'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Monotone inclusion problems occur in many areas of optimization and variational analysis. Splitting methods, which utilize resolvents or proximal mappings of the underlying operators, are often applied to solve these problems. Bredies et al. [SIAM J. Optim., 32 (2022), pp. 2376–2401] introduced a new elegant algorithmic framework that encompasses various well-known algorithms, including Douglas–Rachford and Chambolle–Pock. They obtained powerful weak and strong convergence results, where the latter type relies on additional strong monotonicity assumptions. In this paper, we complement the analysis by Bredies et al. by relating the projections of the fixed point sets of the underlying operators that generate the (reduced and original) preconditioned proximal point sequences. We obtain a new strong convergence result when the underlying operator is a linear relation. We note that without assumptions such as linearity or strong monotonicity, one may encounter weak convergence without strong convergence. In the case of the Chambolle–Pock algorithm, we obtain a new result that yields strong convergence to the projection onto the intersection of a linear subspace and the preimage of a linear subspace. Splitting algorithms by Ryu and by Malitsky and Tam are also considered. Various examples are provided to illustrate the applicability of our results.},
  archive      = {J_SIOPT},
  author       = {Heinz H. Bauschke and Walaa M. Moursi and Shambhavi Singh and Xianfu Wang},
  doi          = {10.1137/23M1587919},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1963-1992},
  shortjournal = {SIAM J. Optim.},
  title        = {On the Bredies–Chenchene–Lorenz–Naldi algorithm: Linear relations and strong convergence},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grassmannian optimization is NP-hard. <em>SIOPT</em>, <em>35</em>(3), 1939-1962. (<a href='https://doi.org/10.1137/24M1672596'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We show that unconstrained quadratic optimization over a Grassmannian is NP-hard. Our results cover all scenarios: (i) when and are both allowed to grow, (ii) when is arbitrary but fixed, and (iii) when is fixed at its lowest possible value 1. We then deduce the NP-hardness of unconstrained cubic optimization over the Stiefel manifold and the orthogonal group . As an addendum we demonstrate the NP-hardness of unconstrained quadratic optimization over the Cartan manifold, i.e., the positive definite cone regarded as a Riemannian manifold, another popular example in manifold optimization. We will also establish the nonexistence of in all cases.},
  archive      = {J_SIOPT},
  author       = {Zehua Lai and Lek-Heng Lim and Ke Ye},
  doi          = {10.1137/24M1672596},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1939-1962},
  shortjournal = {SIAM J. Optim.},
  title        = {Grassmannian optimization is NP-hard},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Perturbation analysis for KKT point sets of constrained optimization problems. <em>SIOPT</em>, <em>35</em>(3), 1914-1938. (<a href='https://doi.org/10.1137/24M165884X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper first uses the subdifferential and coderivative to consider KKT optimality conditions for a generalized equation-constrained optimization problem (GEOP), which can cover most constrained optimization problems. Based on the technique of variational analysis, we establish quantitative analysis for the KKT stationary point sets of (GEOP) and a conic optimization problem when both the objective function and the constrained multifunctions undergo small Lipschitz perturbations. Without any constraint qualification, we prove that the KKT stationary point set of a piecewise linearity constrained optimization problem with the objective function being quasi-quadratic is always stable when the objective function undergoes small Lipschitz (not necessarily quasi-quadratic) perturbations. As an application, we provide some stability results on KKT stationary point sets for quasi-quadratic programs with piecewise linear complementary constraint or sparsity constraint.},
  archive      = {J_SIOPT},
  author       = {Xi Yin Zheng},
  doi          = {10.1137/24M165884X},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1914-1938},
  shortjournal = {SIAM J. Optim.},
  title        = {Perturbation analysis for KKT point sets of constrained optimization problems},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convex ternary quartics are SOS-convex. <em>SIOPT</em>, <em>35</em>(3), 1899-1913. (<a href='https://doi.org/10.1137/24M1655834'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We show that if a ternary quartic form is convex, then it must be sos-convex; i.e., if the Hessian of a ternary quartic form is positive semidefinite for all , then the biquadratic form in the variables and must be a sum of squares. This result is in a meaningful sense the convex analog of Hilbert’s celebrated theorem on ternary quartics. We show that exploiting the structure of the Hessian matrix is crucial in any possible proof of this result by presenting an explicit example of a biquadratic form that is symmetric in and , nonnegative, but not a sum of squares.},
  archive      = {J_SIOPT},
  author       = {Amir Ali Ahmadi and Grigoriy Blekherman and Pablo A. Parrilo},
  doi          = {10.1137/24M1655834},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1899-1913},
  shortjournal = {SIAM J. Optim.},
  title        = {Convex ternary quartics are SOS-convex},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The lovász theta function for recovering planted clique covers and graph colorings. <em>SIOPT</em>, <em>35</em>(3), 1873-1898. (<a href='https://doi.org/10.1137/23M1609622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The problems of computing graph colorings and clique covers are central challenges in combinatorial optimization. Both of these are known to be NP-hard and thus computationally intractable in the worst-case instance. A prominent approach for computing approximate solutions to these problems is the celebrated Lovász theta function , which is specified as the solution of a semidefinite program (SDP) and hence is tractable to compute. In this work, we move beyond the worst-case analysis and set out to understand whether the Lovász theta function recovers clique covers for random instances that have a latent clique cover structure, possibly obscured by noise. We answer this question in the affirmative and show that for graphs generated from the planted clique model we introduce in this work, the SDP formulation of has a unique solution that reveals the underlying clique cover structure with high probability. The main technical step is an intermediate result where we prove a deterministic condition of recovery based on an appropriate notion of sparsity.},
  archive      = {J_SIOPT},
  author       = {Jiaxin Hou and Yong Sheng Soh and Antonios Varvitsiotis},
  doi          = {10.1137/23M1609622},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1873-1898},
  shortjournal = {SIAM J. Optim.},
  title        = {The lovász theta function for recovering planted clique covers and graph colorings},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A four-operator splitting algorithm for nonconvex and nonsmooth optimization. <em>SIOPT</em>, <em>35</em>(3), 1846-1872. (<a href='https://doi.org/10.1137/24M1672067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work, we address a class of nonconvex nonsmooth optimization problems where the objective function is the sum of two smooth functions (one of which is proximable) and two nonsmooth functions (one proper, closed, and proximable, and the other continuous and weakly concave). We introduce a new splitting algorithm that extends the Davis–Yin splitting (DYS) algorithm to handle such four-term nonconvex nonsmooth problems. We prove that with appropriately chosen stepsizes, our algorithm exhibits global subsequential convergence to stationary points with a stationarity measure converging at a global rate of , where is the number of iterations. When specialized to the setting of the DYS algorithm, our results allow for larger stepsizes compared to existing bounds in the literature. Experimental results demonstrate the practical applicability and effectiveness of our proposed algorithm.},
  archive      = {J_SIOPT},
  author       = {Jan Harold Alcantara and Ching-pei Lee and Akiko Takeda},
  doi          = {10.1137/24M1672067},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1846-1872},
  shortjournal = {SIAM J. Optim.},
  title        = {A four-operator splitting algorithm for nonconvex and nonsmooth optimization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convex quadratic sets and the complexity of mixed integer convex quadratic programming. <em>SIOPT</em>, <em>35</em>(3), 1822-1845. (<a href='https://doi.org/10.1137/24M1636782'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In pure integer linear programming it is often desirable to work with polyhedra that are full-dimensional, and it is well known that it is possible to reduce any polyhedron to a full-dimensional one in polynomial time. More precisely, using the Hermite normal form, it is possible to map a non-full-dimensional polyhedron to a full-dimensional isomorphic one in a lower-dimensional space, while preserving integer vectors. In this paper, we extend the above result simultaneously in two directions. First, we consider mixed integer vectors instead of integer vectors, by leveraging on the concept of “integer reflexive generalized inverse.” Second, we replace polyhedra with convex quadratic sets, which are sets obtained from polyhedra by enforcing one additional convex quadratic inequality. We study structural properties of convex quadratic sets, and utilize them to obtain polynomial time algorithms to recognize full-dimensional convex quadratic sets, and to find an affine function that maps a non-full-dimensional convex quadratic set to a full-dimensional isomorphic one in a lower-dimensional space, while preserving mixed integer vectors. We showcase the applicability and the potential impact of these results by demonstrating that they can be used to prove that mixed integer convex quadratic programming is fixed parameter tractable with parameter the number of integer variables. Our algorithm unifies and extends the known polynomial time solvability of mixed integer convex quadratic programming in fixed dimension and of convex quadratic programming.},
  archive      = {J_SIOPT},
  author       = {Alberto Del Pia},
  doi          = {10.1137/24M1636782},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1822-1845},
  shortjournal = {SIAM J. Optim.},
  title        = {Convex quadratic sets and the complexity of mixed integer convex quadratic programming},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TRFD: A derivative-free trust-region method based on finite differences for composite nonsmooth optimization. <em>SIOPT</em>, <em>35</em>(3), 1792-1821. (<a href='https://doi.org/10.1137/24M1701587'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work we present TRFD, a derivative-free trust-region method based on finite differences for minimizing composite functions of the form , where is a black-box function assumed to have a Lipschitz continuous Jacobian, and is a known convex Lipschitz function, possibly nonsmooth, with a known Lipschitz constant. The method approximates the Jacobian of via forward finite differences. We establish an upper bound for the number of evaluations of that TRFD requires to find an -approximate stationary point. For L1 and Minimax problems, we show that our complexity bound reduces to for specific instances of TRFD, where is the number of variables of the problem. Assuming that is monotone and that the components of are convex, we also establish a worst-case complexity bound, which reduces to for Minimax problems. Numerical results are provided to illustrate the relative efficiency of TRFD in comparison with existing derivative-free solvers for composite nonsmooth optimization.},
  archive      = {J_SIOPT},
  author       = {D. Davar and G. N. Grapiglia},
  doi          = {10.1137/24M1701587},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1792-1821},
  shortjournal = {SIAM J. Optim.},
  title        = {TRFD: A derivative-free trust-region method based on finite differences for composite nonsmooth optimization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A jacobi-type newton method for nash equilibrium problems with descent guarantees. <em>SIOPT</em>, <em>35</em>(3), 1761-1791. (<a href='https://doi.org/10.1137/23M1575639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A common strategy for solving an unconstrained two-player Nash equilibrium problem with continuous variables is applying Newton’s method to the system obtained by the corresponding first-order necessary optimality conditions. However, when taking into account the game dynamics, it is not clear what is the goal of each player when considering they are taking their current decision following Newton’s iterates. In this paper we provide an interpretation for Newton’s iterate as follows: instead of minimizing the quadratic approximation of the objective functions parameterized by the other player current decision (the Jacobi-type strategy), we show that the Newton iterate follows this approach but with the objective function parameterized by a prediction of the other player action. This interpretation allows us to present a new Newtonian algorithm where a backtracking procedure is introduced in order to guarantee that the computed Newtonian directions, for each player, are descent directions for the corresponding parameterized functions. Thus, besides favoring global convergence, our algorithm also favors true minimizers instead of maximizers or saddle points, unlike the standard Newton method, which does not consider the minimization structure of the problem in the nonconvex case. Thus, our method is more robust compared to other Jacobi-type strategies or the pure Newtonian approach, which is corroborated by our numerical experiments. We also present a proof of the well-definiteness of the algorithm under some standard assumptions, together with a preliminary analysis of its convergence properties taking into account the game dynamics.},
  archive      = {J_SIOPT},
  author       = {L. F. Bueno and G. Haeser and O. Kolossoski},
  doi          = {10.1137/23M1575639},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1761-1791},
  shortjournal = {SIAM J. Optim.},
  title        = {A jacobi-type newton method for nash equilibrium problems with descent guarantees},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Randomized iterative methods for generalized absolute value equations: Solvability and error bounds. <em>SIOPT</em>, <em>35</em>(3), 1731-1760. (<a href='https://doi.org/10.1137/24M1679306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Randomized iterative methods, such as the Kaczmarz method and its variants, have gained growing attention due to their simplicity and efficiency in solving large-scale linear systems. Meanwhile, absolute value equations (AVE) have attracted increasing interest due to their connection with the linear complementarity problem. In this paper, we investigate the application of randomized iterative methods to generalized AVE (GAVE). Our approach differs from most existing works in that we tackle GAVE with nonsquare coefficient matrices. We establish more comprehensive sufficient and necessary conditions for characterizing the solvability of GAVE and propose precise error bound conditions. Furthermore, we introduce a flexible and efficient randomized iterative algorithmic framework for solving GAVE, which employs randomized sketching matrices drawn from user-specified distributions. This framework is capable of encompassing many well-known methods, including the Picard iteration method and the randomized Kaczmarz method. Leveraging our findings on solvability and error bounds, we establish both almost sure convergence and linear convergence rates for this versatile algorithmic framework. Finally, we present numerical examples to illustrate the advantages of the new algorithms.},
  archive      = {J_SIOPT},
  author       = {Jiaxin Xie and Hou-Duo Qi and Deren Han},
  doi          = {10.1137/24M1679306},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1731-1760},
  shortjournal = {SIAM J. Optim.},
  title        = {Randomized iterative methods for generalized absolute value equations: Solvability and error bounds},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convex approximations of random constrained markov decision processes. <em>SIOPT</em>, <em>35</em>(3), 1703-1730. (<a href='https://doi.org/10.1137/24M1660711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Constrained Markov decision processes (CMDPs) are used as a decision-making framework to study the long-run performance of a stochastic system. It is well known that a stationary optimal policy of a CMDP problem under discounted cost criterion can be obtained by solving a linear programming problem when running costs and transition probabilities are exactly known. In this paper, we consider a discounted cost CMDP problem where the running costs and transition probabilities are defined using random variables. Consequently, both the objective function and constraints become random. We use chance constraints to model these uncertainties and formulate the uncertain CMDP problem as a joint chance-constrained Markov decision process (JCCMDP). Under random running costs, we assume that the dependency among random constraint vectors is driven by a Gumbel–Hougaard copula. Using standard probability inequalities, we construct convex upper bound approximations of the JCCMDP problem under certain conditions on random running costs. In addition, we propose a linear programming problem whose optimal value gives a lower bound to the optimal value of the JCCMDP problem. When both running costs and transition probabilities are random, we define the latter variables as a sum of their means and random perturbations. Under mild conditions on the random perturbations and random running costs, we construct convex upper and lower bound approximations of the JCCMDP problem. We analyze the quality of the derived bounds through numerical experiments on a queueing control problem for random running costs. For the case when both running costs and transition probabilities are random, we choose randomly generated Markov decision problems called Garnets for numerical experiments.},
  archive      = {J_SIOPT},
  author       = {V Varagapriya and Vikas Vikram Singh and Abdel Lisser},
  doi          = {10.1137/24M1660711},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1703-1730},
  shortjournal = {SIAM J. Optim.},
  title        = {Convex approximations of random constrained markov decision processes},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the convergence analysis of the decentralized projected gradient descent method. <em>SIOPT</em>, <em>35</em>(3), 1673-1702. (<a href='https://doi.org/10.1137/23M1562032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work, we are concerned with the decentralized optimization problem: where is a convex domain and each is a local cost function only known to agent . A fundamental algorithm for this problem is the decentralized projected gradient method (DPG) given by where is the projection operator to and are communication weight among the agents. While this method has been widely used in the literature, its convergence property has not been established so far, except for the special case . This work establishes new convergence estimates of DPG when the aggregate cost is strongly convex and each function is smooth. If the stepsize is suitably small, we prove that each converges linearly to an -neighborhood of the minimizer. In addition, we further improve the convergence result by showing that the point converges linearly to an -neighborhood of the minimizer if the domain is given by the half-space for any dimension . Numerical experiments are provided to support the convergence results.},
  archive      = {J_SIOPT},
  author       = {Woocheol Choi and Jimyeong Kim},
  doi          = {10.1137/23M1562032},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1673-1702},
  shortjournal = {SIAM J. Optim.},
  title        = {On the convergence analysis of the decentralized projected gradient descent method},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finding optimal weight vectors for ridge function approximation in \(\boldsymbol{L}^{\boldsymbol{2}}\boldsymbol{(D)}\). <em>SIOPT</em>, <em>35</em>(3), 1655-1672. (<a href='https://doi.org/10.1137/24M166632X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Ridge functions on a set are mappings of the form for given and function . We assume that is compact with nonempty interior and Lipschitz boundary. Given , let be the set of all functions of the form where , the set of continuous functions . Clearly is a subspace of . The task in this paper is, given , to characterize and find a set of weight vectors that minimizes . The maximizing is shown to exist and can be interpreted as the function “hardest to approximate” by . The value of is given in terms of the maximum eigenvalue of a self-adjoint compact operator . Computational methods are given for both computing , given , and finding that approximately minimizes through a gradient descent procedure.},
  archive      = {J_SIOPT},
  author       = {David E. Stewart},
  doi          = {10.1137/24M166632X},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1655-1672},
  shortjournal = {SIAM J. Optim.},
  title        = {Finding optimal weight vectors for ridge function approximation in \(\boldsymbol{L}^{\boldsymbol{2}}\boldsymbol{(D)}\)},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Certifying solutions of degenerate semidefinite programs. <em>SIOPT</em>, <em>35</em>(3), 1630-1654. (<a href='https://doi.org/10.1137/24M1664691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper deals with the algorithmic aspects of solving feasibility problems of semidefinite programming (SDP), aka linear matrix inequalities (LMIs). Since in some SDP instances all feasible solutions have irrational entries, numerical solvers that work with rational numbers can only find an approximate solution. We study the following question: Is it possible to certify feasibility of a given SDP using an approximate solution that is sufficiently close to some exact solution? Existing approaches make the assumption that there exist rational feasible solutions (and use techniques such as rounding and lattice reduction algorithms). We propose an alternative approach that does not need this assumption. More specifically, we show how to construct a system of polynomial equations whose set of real solutions is guaranteed to have an isolated correct solution (assuming that the target exact solution is maximum-rank). This allows, in particular, for us to use algorithms from real algebraic geometry for solving systems of polynomial equations, yielding a hybrid (or symbolic-numerical) method for SDPs. We experimentally compare it with a pure symbolic method in [D. Henrion, S. Naldi, and M. Safey El Din, SIAM J. Optim., 26 (2016), pp. 2512–2539]; the hybrid method was able to certify feasibility of many SDP instances on which the aforementioned paper failed. Our approach may have further applications, such as refining an approximate solution using methods of numerical algebraic geometry for systems of polynomial equations.},
  archive      = {J_SIOPT},
  author       = {Vladimir Kolmogorov and Simone Naldi and Jeferson Zapata},
  doi          = {10.1137/24M1664691},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1630-1654},
  shortjournal = {SIAM J. Optim.},
  title        = {Certifying solutions of degenerate semidefinite programs},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proximal gradient \(\boldsymbol{\mathcal{VU}}\)-method with superlinear convergence for nonsmooth convex optimization. <em>SIOPT</em>, <em>35</em>(3), 1601-1629. (<a href='https://doi.org/10.1137/24M1697001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The -theory for nonsmooth functions and the associated space decomposition have been used for studying the smooth substructures and for developing algorithms with superlinear convergence in those settings, which are challenging for fast convergence. We extend the theory by defining a certain bivariate -Lagrangian function and partial -Hessian. Utilizing smoothness properties of the new -Lagrangian we develop the proximal gradient -method for continuous nonsmooth convex optimization and show its superlinear convergence under natural assumptions. The framework consists of a -step which is a prox-gradient step, followed by a -step which can be considered as a quasi-Newton step applied to the -Lagrangian. We show that partial -Hessians exist for most partly smooth functions. We exhibit the explicit process of constructing a basis of the -space and of calculating the -Hessian for -regularized problems. Numerical results illustrate the method’s performance.},
  archive      = {J_SIOPT},
  author       = {Shuai Liu and Claudia Sagastizabal and Mikhail V. Solodov},
  doi          = {10.1137/24M1697001},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1601-1629},
  shortjournal = {SIAM J. Optim.},
  title        = {Proximal gradient \(\boldsymbol{\mathcal{VU}}\)-method with superlinear convergence for nonsmooth convex optimization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding the influence of digraphs on decentralized optimization: Effective metrics, lower bound, and optimal algorithm. <em>SIOPT</em>, <em>35</em>(3), 1570-1600. (<a href='https://doi.org/10.1137/24M1657341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper investigates the influence of directed networks on decentralized stochastic nonconvex optimization associated with column-stochastic mixing matrices. Surprisingly, we find that the canonical spectral gap, a widely used metric in undirected networks, is insufficient to characterize the impact of directed topology on decentralized algorithms. To overcome this limitation, we introduce a novel metric termed equilibrium skewness. This metric, together with the spectral gap, accurately and comprehensively captures the influence of column-stochastic mixing matrices on decentralized stochastic algorithms. With these two metrics, we clarify, for the first time, how the directed network topology influences the performance of prevalent algorithms such as Push-Sum and Push-DIGing. Furthermore, we establish the first lower bound of the convergence rate for decentralized stochastic nonconvex algorithms over directed networks. Since existing algorithms cannot match our lower bound, we further propose the MG-Push-DIGing algorithm, which integrates Push-DIGing with a multiround gossip technique. MG-Push-DIGing attains our lower bound up to logarithmic factors, demonstrating its near-optimal performance and the tightness of the lower bound. Numerical experiments verify our theoretical results.},
  archive      = {J_SIOPT},
  author       = {Liyuan Liang and Xinmeng Huang and Ran Xin and Kun Yuan},
  doi          = {10.1137/24M1657341},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1570-1600},
  shortjournal = {SIAM J. Optim.},
  title        = {Understanding the influence of digraphs on decentralized optimization: Effective metrics, lower bound, and optimal algorithm},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Commutation principles for nonsmooth variational problems on euclidean jordan algebras. <em>SIOPT</em>, <em>35</em>(3), 1551-1569. (<a href='https://doi.org/10.1137/24M1646777'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The commutation principle proved by Ramírez, Seeger, and Sossa (SIAM J. Optim. 23 (2013), pp. 687–694) in the setting of Euclidean Jordan algebras says that for a Fréchet differentiable function and a spectral function , any local minimizer or maximizer of over a spectral set operator commutes with the gradient of at . In this paper, we improve this commutation principle by allowing to be nonsmooth. For example, for the case of local minimizer, we show that operator commutes with some element of the limiting (Mordukhovich) subdifferential of at provided that is subdifferentially regular at satisfying a qualification condition. For the case of local maximizer, we prove that operator commutes with each element of the (Fenchel) subdifferential of at whenever this subdifferential is nonempty. As an application, we characterize local optimizers of shifted strictly convex spectral functions and norms over automorphism invariant sets.},
  archive      = {J_SIOPT},
  author       = {Juyoung Jeong and David Sossa},
  doi          = {10.1137/24M1646777},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1551-1569},
  shortjournal = {SIAM J. Optim.},
  title        = {Commutation principles for nonsmooth variational problems on euclidean jordan algebras},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New methods for parametric optimization via differential equations. <em>SIOPT</em>, <em>35</em>(3), 1524-1550. (<a href='https://doi.org/10.1137/23M1578462'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We develop and analyze several different second-order algorithms for computing a near-optimal solution path of a convex parametric optimization problem with smooth Hessian. Our algorithms are inspired by a differential equation perspective on the parametric solution path and do not rely on the specific structure of the objective function. We present computational guarantees that bound the oracle complexity to achieve a near-optimal solution path under different sets of smoothness assumptions. Under the assumptions, the results are an improvement over the best-known results of the grid search methods. We also develop second-order conjugate gradient variants that avoid exact computations of Hessians and solving of linear equations. We present computational results that demonstrate the effectiveness of our methods over grid search methods on both real and synthetic datasets. On large-scale problems, we demonstrate significant speedups of the second-order conjugate variants as compared to the standard versions of our methods.},
  archive      = {J_SIOPT},
  author       = {Heyuan Liu and Paul Grigas},
  doi          = {10.1137/23M1578462},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1524-1550},
  shortjournal = {SIAM J. Optim.},
  title        = {New methods for parametric optimization via differential equations},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Homotopy methods for convex optimization. <em>SIOPT</em>, <em>35</em>(3), 1498-1523. (<a href='https://doi.org/10.1137/24M1693416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Convex optimization encompasses a wide range of optimization problems that contain many efficiently solvable subclasses. Interior point methods are currently the state-of-the-art approach for solving such problems, particularly effective for classes like semidefinite programming, quadratic programming, and geometric programming. However, their success hinges on the construction of self-concordant barrier functions for feasible sets. In this work, we investigate and develop a homotopy-based approach to solve convex optimization problems. While homotopy methods have been considered in optimization before, their potential for general convex programs remains underexplored. This approach gradually transforms the feasible set of a trivial optimization problem into the target one while tracking solutions by solving a differential equation, in contrast to traditional central path methods. We establish a criterion that ensures that the homotopy method correctly solves the optimization problem and prove the existence of such homotopies for several important classes, including semidefinite and hyperbolic programs. Furthermore, we demonstrate that our approach numerically outperforms state-of-the-art methods in hyperbolic programming, highlighting its practical advantages.},
  archive      = {J_SIOPT},
  author       = {Andreas Klingler and Tim Netzer},
  doi          = {10.1137/24M1693416},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1498-1523},
  shortjournal = {SIAM J. Optim.},
  title        = {Homotopy methods for convex optimization},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An approximation-based regularized extra-gradient method for monotone variational inequalities. <em>SIOPT</em>, <em>35</em>(3), 1469-1497. (<a href='https://doi.org/10.1137/23M1585258'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we propose a general extra-gradient scheme for solving monotone variational inequalities (VI), referred to here as the Approximation-based Regularized Extra-gradient method (ARE). The first step of ARE solves a VI subproblem, where the associated operator consists of an approximation operator satisfying a -order Lipschitz bound with respect to the original mapping, and the gradient of a -order regularization. The optimal global convergence is guaranteed by including an additional extra-gradient step, while a -order superlinear local convergence is shown to hold if the VI is strongly monotone. The proposed ARE is a broad scheme, in the sense that a variety of solution methods can be formulated within this framework as different manifestations of approximations, and their iteration complexities would follow through in a unified fashion. The ARE framework relates to the first-order methods, while opening up possibilities to developing higher-order methods specifically for structured problems that guarantee the optimal iteration complexity bounds.},
  archive      = {J_SIOPT},
  author       = {Kevin Huang and Shuzhong Zhang},
  doi          = {10.1137/23M1585258},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1469-1497},
  shortjournal = {SIAM J. Optim.},
  title        = {An approximation-based regularized extra-gradient method for monotone variational inequalities},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Projected newton method for large-scale bayesian linear inverse problems. <em>SIOPT</em>, <em>35</em>(3), 1439-1468. (<a href='https://doi.org/10.1137/24M1645838'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Computing the regularized solution of Bayesian linear inverse problems as well as the corresponding regularization parameter is highly desirable in many applications. This paper proposes a novel iterative method, termed the Projected Newton method (PNT), that can simultaneously update the regularization parameter and solution step by step without requiring any expensive matrix inversions or decompositions. By reformulating the Tikhonov regularization as a constrained minimization problem and leveraging its Lagrangian function, a Newton-type method coupled with a Krylov subspace method is designed for the unconstrained Lagrangian function. The resulting PNT algorithm only needs solving a small-scale linear system to get a descent direction of a merit function at each iteration, thus significantly reducing computational overhead. Rigorous convergence results are proved, showing that PNT always converges to the unique regularized solution and the corresponding Lagrangian multiplier. Experimental results on both small-scale and large-scale Bayesian inverse problems demonstrate its excellent convergence property, robustness, and efficiency. Given that the most demanding computational tasks in PNT are primarily matrix-vector products, it is particularly well-suited for large-scale problems.},
  archive      = {J_SIOPT},
  author       = {Haibo Li},
  doi          = {10.1137/24M1645838},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {1439-1468},
  shortjournal = {SIAM J. Optim.},
  title        = {Projected newton method for large-scale bayesian linear inverse problems},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
