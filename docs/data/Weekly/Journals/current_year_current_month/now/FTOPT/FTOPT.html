<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>FTOPT</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ftopt">FTOPT - 2</h2>
<ul>
<li><details>
<summary>
(2025). Riemannian online learning. <em>FTOPT</em>, <em>9</em>(3), 248-406. (<a href='https://doi.org/10.1561/2400000054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In emerging fields such as machine learning, quantum computing, biomedical imaging, and robotics, data and decisions often exist in curved, non-Euclidean spaces due to physical constraints or underlying symmetries. Riemannian online optimization provides a new framework for handling learning tasks where data arrives sequentially in geometric spaces. This monograph offers a comprehensive overview of online learning over Riemannian manifolds.},
  archive      = {J_FTOPT},
  author       = {Xi Wang and Guodong Shi},
  doi          = {10.1561/2400000054},
  journal      = {Foundations and Trends® in Optimization},
  month        = {8},
  number       = {3},
  pages        = {248-406},
  shortjournal = {Found. Trends Optim.},
  title        = {Riemannian online learning},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal machine learning: A survey and open problems. <em>FTOPT</em>, <em>9</em>(1-2), 1-247. (<a href='https://doi.org/10.1561/2400000052'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal Machine Learning (CausalML) is an umbrella term for machine learning methods that formalize the datageneration process as a causal model. This perspective enables one to reason about the effects of changes to this process (interventions) and what would have happened in hindsight (counterfactuals). We categorize work in CausalML into five groups according to the problems they address: (1) causal supervised learning, (2) causal generative modeling, (3) causal explanations, (4) causal fairness, and (5) causal reinforcement learning. We systematically compare approaches in each category and point out open problems. Further, we review field-specific applications in computer vision, natural language processing, and graph representation learning. Finally, we provide an overview of causal benchmarks and a discussion of the state of this nascent field, including recommendations for future work.},
  archive      = {J_FTOPT},
  author       = {Jean Kaddour and Aengus Lynch and Qi Liu and Matt J. Kusner and Ricardo Silva},
  doi          = {10.1561/2400000052},
  journal      = {Foundations and Trends® in Optimization},
  month        = {8},
  number       = {1-2},
  pages        = {1-247},
  shortjournal = {Found. Trends Optim.},
  title        = {Causal machine learning: A survey and open problems},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
