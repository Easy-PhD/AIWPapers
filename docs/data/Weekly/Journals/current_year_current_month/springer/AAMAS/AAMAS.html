<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AAMAS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aamas">AAMAS - 11</h2>
<ul>
<li><details>
<summary>
(2025). The cost and complexity of minimizing envy in house allocation. <em>AAMAS</em>, <em>39</em>(2), 1-54. (<a href='https://doi.org/10.1007/s10458-025-09710-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study almost envy-freeness in house allocation, where m houses are to be allocated among n agents so that every agent receives exactly one house. An envy-free allocation need not exist, and therefore we may have to settle for relaxations. We study different aggregate measures of envy as markers of fairness. In particular, we define the amount of envy experienced by an agent a w.r.t. an allocation to be the number of agents that agent a envies under that allocation. We quantify the envy generated by an allocation using three different metrics: 1) the number of agents who are envious; 2) the maximum amount of envy experienced by any agent; and 3) the total amount of envy experienced by all agents, and look for allocations that minimize one of the three metrics. We prove a host of algorithmic and hardness results. We also suggest practical approaches for these problems via integer linear program (ILP) formulations and report the findings of our experimental evaluation of ILPs. Finally, we study the price of fairness, which quantifies the loss of welfare we must suffer due to the fairness requirements, and present tight bounds as well as algorithms that simultaneously optimize both welfare and fairness.},
  archive      = {J_AAMAS},
  author       = {Madathil, Jayakrishnan and Misra, Neeldhara and Sethia, Aditi},
  doi          = {10.1007/s10458-025-09710-y},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-54},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {The cost and complexity of minimizing envy in house allocation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Behavioral QLTL. <em>AAMAS</em>, <em>39</em>(2), 1-29. (<a href='https://doi.org/10.1007/s10458-025-09712-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces Behavioral QLTL, a “behavioral” variant of Linear Temporal Logic (ltl) with second-order quantifiers. Behavioral qltl is characterized by the fact that the functions that assign the truth value of the quantified propositions along the trace can only depend on the past. In other words, such functions must be “processes” (Abadi et al., Realizable and Unrealizable Specifications of Reactive Systems, 1989) . This gives the logic a strategic flavor that we usually associate with planning. Indeed we show that temporally extended planning in nondeterministic domains and ltl synthesis are expressed in Behavioral qltl through formulas with a simple quantification alternation. As such alternation increases, we get to forms of planning/synthesis in which contingent and conformant planning aspects get mixed. We study this logic from the computational point of view and compare it to the original qltl (with non-behavioral semantics) and simpler forms of behavioral semantics.},
  archive      = {J_AAMAS},
  author       = {De Giacomo, Giuseppe and Perelli, Giuseppe},
  doi          = {10.1007/s10458-025-09712-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-29},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Behavioral QLTL},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-stage generalized deferred acceptance mechanism: Strategyproof mechanism for handling general hereditary constraints. <em>AAMAS</em>, <em>39</em>(2), 1-25. (<a href='https://doi.org/10.1007/s10458-025-09713-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of two-sided matching has been extensively developed and applied to many real-life application domains. As the theory has been applied to increasingly diverse types of environments, researchers and practitioners have encountered various forms of distributional constraints. Arguably, the most general class of distributional constraints would be hereditary constraints; if a matching is feasible, then any matching that assigns weakly fewer students at each college is also feasible. However, under general hereditary constraints, it is shown that no strategyproof mechanism exists that simultaneously satisfies fairness and weak nonwastefulness, which is an efficiency (students’ welfare) requirement weaker than nonwastefulness. We propose a new strategyproof mechanism that works for hereditary constraints called the Multi-Stage Generalized Deferred Acceptance mechanism (MS-GDA). It uses the Generalized Deferred Acceptance mechanism (GDA) as a subroutine, which works when distributional constraints belong to a well-behaved class called hereditary M $$^{\natural }$$ -convex set. We show that GDA satisfies several desirable properties, most of which are also preserved in MS-GDA. We experimentally show that MS-GDA strikes a good balance between fairness and efficiency (students’ welfare) compared to existing strategyproof mechanisms when distributional constraints are close to an M $$^{\natural }$$ -convex set*.},
  archive      = {J_AAMAS},
  author       = {Kimura, Kei and Liu, Kweiguu and Sun, Zhaohong and Yahiro, Kentaro and Yokoo, Makoto},
  doi          = {10.1007/s10458-025-09713-9},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-25},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Multi-stage generalized deferred acceptance mechanism: Strategyproof mechanism for handling general hereditary constraints},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hedonic seat arrangement problems. <em>AAMAS</em>, <em>39</em>(2), 1-31. (<a href='https://doi.org/10.1007/s10458-025-09711-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a variant of hedonic games, called Seat Arrangement. The model is defined by a bijection from agents with preferences for each other to vertices in a graph G. The utility of an agent depends on the neighbors assigned in the graph. More precisely, it is the sum over all neighbors of the preferences that the agent has towards the agent assigned to the neighbor. We first consider the price of stability and fairness for different classes of preferences. In particular, we show that there is an instance such that the price of fairness (PoF) is unbounded in general. Moreover, we show an upper bound $$\tilde{d}(G)$$ and an almost tight lower bound $$\tilde{d}(G)-1/4$$ of PoF, where $$\tilde{d}(G)$$ is the average degree of an input graph. Then we investigate the computational complexity of problems to find certain “good” seat arrangements, say Utilitarian Arrangement, Egalitarian Arrangement, Stable Arrangement, and Envy-free Arrangement. We give dichotomies of computational complexity of four Seat Arrangement problems from the perspective of the maximum order of connected components in an input graph. For the parameterized complexity, Utilitarian Arrangement can be solved in time $$n^{O(\gamma )}$$ , while it cannot be solved in time $$f(\gamma )n^{o(\gamma )}$$ under ETH, where n is the number of agents and $$\gamma$$ is the vertex cover number of an input graph. Moreover, we show that Egalitarian Arrangement and Envy-free Arrangement are weakly NP-hard even on graphs of bounded vertex cover number. Finally, we prove that determining whether a stable arrangement can be obtained from a given arrangement by k swaps is W[1]-hard when parameterized by $$k+\gamma$$ , whereas it can be solved in time $$n^{O(k)}$$ .},
  archive      = {J_AAMAS},
  author       = {Bodlaender, Hans L. and Hanaka, Tesshu and Jaffke, Lars and Ono, Hirotaka and Otachi, Yota and van der Zanden, Tom C.},
  doi          = {10.1007/s10458-025-09711-x},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-31},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Hedonic seat arrangement problems},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diversity-seeking jump games in networks. <em>AAMAS</em>, <em>39</em>(2), 1-37. (<a href='https://doi.org/10.1007/s10458-025-09714-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, strategic games inspired by Schelling’s influential model of residential segregation have been studied in the TCS and AI literature. In these games, agents of k different types occupy the nodes of a network topology aiming to maximize their utility, which is a function of the fraction of same-type agents they are adjacent to in the network. As such, the agents exhibit similarity-seeking strategic behavior. In this paper, we introduce a class of strategic jump games in which the agents are diversity-seeking: The utility of an agent is defined as the fraction of its neighbors that are of different type than itself. We show that in general it is computationally hard to determine the existence of an equilibrium in such games. However, when the network is a tree, diversity-seeking jump games always admit an equilibrium assignment. For regular graphs and spider graphs with a single empty node, we prove a stronger result: The game is potential, that is, the improving response dynamics always converge to an equilibrium from any initial placement of the agents. We also show (nearly tight) bounds on the price of anarchy and price of stability in terms of the social welfare (the total utility of the agents).},
  archive      = {J_AAMAS},
  author       = {Narayanan, Lata and Sabbagh, Yasaman and Voudouris, Alexandros A.},
  doi          = {10.1007/s10458-025-09714-8},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-37},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Diversity-seeking jump games in networks},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coordinating monetary contributions in participatory budgeting. <em>AAMAS</em>, <em>39</em>(2), 1-30. (<a href='https://doi.org/10.1007/s10458-025-09715-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We formalize a framework for coordinating funding and selecting projects, the costs of which are shared among agents with quasi-linear utility functions and individual budgets. Our model contains the discrete participatory budgeting model as a special case, while capturing other useful scenarios. We propose several important axioms and objectives and study how well they can be simultaneously satisfied. We show that whereas welfare maximization admits an FPTAS, welfare maximization subject to a natural and very weak participation requirement leads to a strong inapproximability. This result is bypassed if we consider some natural restricted valuations, namely laminar single-minded valuations and symmetric valuations. Our analysis for the former restriction leads to the discovery of a new class of tractable instances for the Set Union Knapsack problem, a classical problem in combinatorial optimization.},
  archive      = {J_AAMAS},
  author       = {Aziz, Haris and Gujar, Sujit and Padala, Manisha and Suzuki, Mashbat and Vollen, Jeremy},
  doi          = {10.1007/s10458-025-09715-7},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-30},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Coordinating monetary contributions in participatory budgeting},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). POSGGym: A library for decision-theoretic planning and learning in partially observable, multi-agent environments. <em>AAMAS</em>, <em>39</em>(2), 1-45. (<a href='https://doi.org/10.1007/s10458-025-09716-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seamless integration of Planning Under Uncertainty and Reinforcement Learning (RL) promises to bring the best of both model-driven and data-driven worlds to multi-agent decision-making, resulting in an approach with assurances on performance that scales well to more complex problems. Despite this potential, progress in developing such methods has been hindered by the lack of adequate evaluation and simulation platforms. Researchers have had to rely on creating custom environments, which reduces efficiency and makes comparing new methods difficult. In this paper, we introduce POSGGym : a library for facilitating planning and RL research in partially observable, multi-agent domains. It provides a diverse collection of discrete and continuous environments, complete with their dynamics models and a reference set of policies that can be used to evaluate generalization to novel co-players. Leveraging POSGGym, we empirically investigate existing state-of-the-art planning methods and a method that combines planning and RL in the type-based reasoning setting. Our experiments corroborate that combining planning and RL can yield superior performance compared to planning or RL alone, given the model of the environment and other agents is correct. However, our particular setup also reveals that this integrated approach could result in worse performance when the model of other agents is incorrect. Our findings indicate the benefit of integrating planning and RL in partially observable, multi-agent domains, while serving to highlight several important directions for future research. Code available at: https://github.com/RDLLab/posggym .},
  archive      = {J_AAMAS},
  author       = {Schwartz, Jonathon and Newbury, Rhys and Kulić, Dana and Kurniawati, Hanna},
  doi          = {10.1007/s10458-025-09716-6},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-45},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {POSGGym: A library for decision-theoretic planning and learning in partially observable, multi-agent environments},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing node selection in search based multi-agent path finding. <em>AAMAS</em>, <em>39</em>(2), 1-24. (<a href='https://doi.org/10.1007/s10458-025-09719-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Multi-Agent Path Finding (MAPF) problem involves the task of finding paths for multiple agents that want to reach their destinations without obstructing other agents. Although MAPF is essential for numerous real-world applications, finding an optimal solution to this problem is NP-hard. Many approaches have been proposed in the literature, offering sub-optimal solutions to improve runtime efficiency. Lazy Constraints Addition search for MAPF (LaCAM) is a state-of-the-art sub-optimal MAPF algorithm that employs tree-based lazy successor generation to minimize planning effort. However, the success of the algorithm heavily relies on the effective selection of nodes for expansion. LaCAM employs a fixed heuristic throughout the entire search process, disregarding the agents’ preferences or characteristics of the underlying environment. Nevertheless, experiments with various heuristics indicate that no single heuristic consistently outperforms others across all scenarios. Consequently, in diverse environments, as the number of agents increases, reliance on a single, general heuristic leads to diminished runtime performance. Against this backdrop, with the intent to further speed up the runtime, we propose a novel approach, called eLaCAM, that adaptively selects nodes during the search process considering the current scenario of the environment and agents preferences. We introduce two distinct variants of eLaCAM. The first, eLaCAM-stat, statistically analyses previous results of using different heuristics and selects nodes accordingly. The second variant, eLaCAM-ML, analyze the environment by extracting necessary features to guide a machine learning framework in assisting adaptive node selection during the search process. Our extensive empirical results illustrate a notable improvement in runtime and a reduction in the search space compared to state-of-the-art MAPF algorithms.},
  archive      = {J_AAMAS},
  author       = {Alam, Md. Ahasanul and Mahmud, Shekhar and Mamun-or-Rashid, Md. and Khan, Md. Mosaddek},
  doi          = {10.1007/s10458-025-09719-3},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-24},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Optimizing node selection in search based multi-agent path finding},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information elicitation mechanisms for bayesian auctions. <em>AAMAS</em>, <em>39</em>(2), 1-45. (<a href='https://doi.org/10.1007/s10458-025-09718-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we design information elicitation mechanisms for Bayesian auctions. While in Bayesian mechanism design the distributions of the players’ private types are often assumed to be common knowledge, information elicitation considers the situation where the players know the distributions better than the decision maker. To weaken the information assumption in Bayesian auctions, we consider an information structure where the knowledge about the distributions is arbitrarily scattered among the players. In such an unstructured information setting, we design mechanisms for unit-demand auctions and additive auctions that aggregate the players’ knowledge, generating revenue that are constant approximations to the optimal Bayesian mechanisms with a common prior. Our mechanisms are 2-step dominant-strategy truthful and the approximation ratios improve gracefully with the amount of knowledge the players collectively have.},
  archive      = {J_AAMAS},
  author       = {Chen, Jing and Li, Bo and Li, Yingkai},
  doi          = {10.1007/s10458-025-09718-4},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-45},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Information elicitation mechanisms for bayesian auctions},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Designing policies for transition-independent multiagent systems that are robust to communication loss. <em>AAMAS</em>, <em>39</em>(2), 1-49. (<a href='https://doi.org/10.1007/s10458-025-09721-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a cooperative multiagent system, a collection of agents executes a joint policy in order to achieve some common objective. The successful deployment of such systems hinges on the availability of reliable inter-agent communication. However, many sources of potential disruption to communication exist in practice, such as radio interference, hardware failure, and adversarial attacks. In this work, we develop joint policies for cooperative multiagent systems that are robust to potential losses in communication. More specifically, we develop joint policies for cooperative Markov games with independent transitions and joint reach-avoid objectives. First, we propose an algorithm for the decentralized execution of joint policies during periods of communication loss. This algorithm is designed to work under arbitrary communication partitions between the agents. Next, we use the total correlation of the state-action process induced by a joint policy as a measure of the intrinsic dependencies between the agents. We then use this measure to lower-bound the performance of a joint policy under randomly intermittent or adversarial communication loss scenarios. We show the existence of a multiagent decision-making environment in which this bound is tight—the highest performance under intermittent communication loss, for any policy execution mechanism, is of the same order as the bound. We then present an algorithm that maximizes a proxy to this lower bound in order to synthesize minimum-dependency joint policies that remain performant under communication loss. Through two-agent and three-agent numerical experiments, we show that the proposed minimum-dependency policies require minimal coordination between the agents while incurring little to no loss in performance; the total correlation value of the synthesized policy is significantly lower than the total correlation value of the baseline policy which does not take potential communication losses into account. As a result, the performance of the minimum-dependency policies remains consistently high regardless of whether or not communication is available. By contrast, the performance of the baseline policy decreases drastically when communication is lost.},
  archive      = {J_AAMAS},
  author       = {Karabag, Mustafa O. and Neary, Cyrus and Topcu, Ufuk},
  doi          = {10.1007/s10458-025-09721-9},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-49},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Designing policies for transition-independent multiagent systems that are robust to communication loss},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the graph theory of majority illusions: Theoretical results and computational experiments. <em>AAMAS</em>, <em>39</em>(2), 1-55. (<a href='https://doi.org/10.1007/s10458-025-09720-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The popularity of an opinion in one’s direct circles is not necessarily a good indicator of its popularity in one’s entire community. Network structures make local information about global properties of the group potentially inaccurate, and the way a social network is wired constrains what kind of information distortion can actually occur. In this paper, we discuss which classes of networks allow for a large enough proportion of the population to get a wrong enough impression about the overall distribution of opinions. We start by focusing on the ‘majority illusion’, the case where one sees a majority opinion in one’s direct circles that differs from the global majority. We show that no network structure can guarantee that most agents see the correct majority. We then perform computational experiments to study the likelihood of majority illusions in different classes of networks. Finally, we generalize to other types of illusions.},
  archive      = {J_AAMAS},
  author       = {Venema-Los, Maaike and Christoff, Zoé and Grossi, Davide},
  doi          = {10.1007/s10458-025-09720-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-55},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {On the graph theory of majority illusions: Theoretical results and computational experiments},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
