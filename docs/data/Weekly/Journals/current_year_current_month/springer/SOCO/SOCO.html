<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SOCO</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="soco">SOCO - 9</h2>
<ul>
<li><details>
<summary>
(2025). Neuro-fuzzy control of commercial vehicles braking. <em>SOCO</em>, <em>29</em>(17), 5449-5464. (<a href='https://doi.org/10.1007/s00500-025-10889-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasing dynamic performance and the general level of automation of commercial vehicles emphasize the issue of safety. Modern braking systems focus on sustaining vehicle stability, often degrading the brake performance. The major downgrades of the braking performance are nearly impossible to model using a classical mathematical approach, making them not feasible to use in real braking system controllers. In this paper, the use of combined Neural Networks and Fuzzy logic for the control of the braking system of a commercial vehicle while maximizing performance and sustaining stability is proposed. The control system comprises adhesion estimation, an inverse brake model, and a fuzzy logic controller to keep the system giving optimal control signals in various brake conditions while sustaining vehicle stability and steerability. The results based on a semi-trailer system reveal the success of the proposed AI-based braking system algorithm while braking under varying conditions.},
  archive      = {J_SOCO},
  author       = {Vučinić, Veljko and Aleksendrić, Dragan},
  doi          = {10.1007/s00500-025-10889-1},
  journal      = {Soft Computing},
  month        = {9},
  number       = {17},
  pages        = {5449-5464},
  shortjournal = {Soft Comput.},
  title        = {Neuro-fuzzy control of commercial vehicles braking},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated classification of acute lymphocytic leukemia (ALL) images using light residual cognitive attention based on human two visual streams hypothesis. <em>SOCO</em>, <em>29</em>(17), 5429-5447. (<a href='https://doi.org/10.1007/s00500-025-10911-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leukemia (blood cancer) is one of the diseases with a high mortality rate worldwide. It occurs in various kinds of blood cells but most often starts in White Blood Cells (WBCs). Acute Lymphocytic Leukemia (ALL) is one of the four main kinds of leukemia that grow from primary (immature) forms of lymphocytes and happen in all ages. ALL will lead to death within a few months if it is not detected and treated quickly. Hematologists analyze blood samples under a microscope to identify leukemia in the Manual (traditional) method. This procedure is slow, time-consuming, less accurate, and dependent on hematologists’ experts. Computer-assisted systems can help pathologists to overcome these challenges. In this article, we proposed two kinds of Ventral-Dorsal Attention Blocks (VDAB) for automated classification of ALL based on the Two Visual Streams Hypothesis (TVSH). First, the Parameterized Ventral-Dorsal Attention Block (PVDAB) is designed that composed of the Parameterized Ventral Attention Block (PVAB) and the Parameterized Dorsal Attention Block (PDAB). The extracting channels related to the shape of WBCs and focusing on their location in the selected channels are performed by the PVAB and PDAB, respectively. Then, the PVDAB is improved and the first light residual cognitive attention block, Non-parameterized Ventral-Dorsal Attention Block (NPVDAB), is introduced that doesn’t impose any learning parameters on the networks. The PVDAB and NPVDAB can be employed in the architecture of each Convolutional Neural Network (CNN). We embedded the suggested attention blocks in the architectures of the ResNet18 and MobileNetv1, and four attention-based networks were generated. Different data augmentation techniques are performed on the ALL-IDB2 dataset to avoid model overfitting and its generalization. The fine-tuned ResNet18, MobileNetv1, and attention-based networks are trained, validated, and evaluated on the dataset with similarity parameters for 40 epochs. The experiment results indicated that the network-3 (ResNet18+NPVDAB) achieved better performance metrics than others with accuracy and an F1-score of 99.33% in the test step.},
  archive      = {J_SOCO},
  author       = {Zolfaghari, Mohammad and Sajedi, Hedieh},
  doi          = {10.1007/s00500-025-10911-6},
  journal      = {Soft Computing},
  month        = {9},
  number       = {17},
  pages        = {5429-5447},
  shortjournal = {Soft Comput.},
  title        = {Automated classification of acute lymphocytic leukemia (ALL) images using light residual cognitive attention based on human two visual streams hypothesis},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new intelligent model selection approach. <em>SOCO</em>, <em>29</em>(17), 5415-5428. (<a href='https://doi.org/10.1007/s00500-025-10910-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modelling spans various scientific fields, including statistics, mathematics, machine learning, artificial intelligence, deep learning, engineering, and bioinformatics. This interdisciplinary nature necessitates the creation of simple representations for modelling results. Performance measures play a crucial role in evaluating these models, indicating their effectiveness through scalar values, ratios, vectors, diagrams, or more complex indicators. These measures serve as the identities of models, highlighting their strengths and weaknesses. Thus, selecting the most appropriate performance measure is pivotal in model identification and comparison. Performance evaluation aids in selecting the optimal model from a pool of candidates, a task fraught with challenges due to the plethora of performance criteria available. Determining the best model becomes even more daunting given the diverse analysis methods and datasets. In this study, we propose a novel intelligent model evaluation method inspired by human intelligence, offering a fresh perspective on model assessment. The Intelligent Performance Measure (IPM) utilizes Convolutional Neural Networks. Unlike widely used performance measures in the literature, IPM evaluates the performance of models from a distinct perspective by learning the actual results in the form of images with all properties, rather than merely assessing error distance. The introduction, evaluation, and comparison of IPM have been thoroughly discussed, demonstrating that the proposed method is superior and represents a breakthrough in the field by being based on artificial intelligence.},
  archive      = {J_SOCO},
  author       = {Bal, Cagatay and Aladag, Cagdas Hakan},
  doi          = {10.1007/s00500-025-10910-7},
  journal      = {Soft Computing},
  month        = {9},
  number       = {17},
  pages        = {5415-5428},
  shortjournal = {Soft Comput.},
  title        = {A new intelligent model selection approach},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of hybrid models to forecast water demand in the city of ankara. <em>SOCO</em>, <em>29</em>(17), 5401-5414. (<a href='https://doi.org/10.1007/s00500-025-10904-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Realistic water consumption projections are of vital importance for efficient use of water resources and for the prevention of water waste and scarcity. In this study, estimates of future water consumption in Ankara, Turkey were developed based on gross domestic product (GDP) and population data from the 22-year period of 2000‒2021. Artificial neural networks (ANNs) were trained with back-propagation (BP), Jaya, and grey wolf optimization (GWO) algorithms, yielding ANN-BP, ANN-Jaya, and ANN-GWO models, respectively. ANN performance evaluation based on calculation of errors for training and test datasets indicated that the ANN-Jaya model showed superior performance compared to the ANN-BP and ANN-GWO models. Therefore, the ANN-Jaya model was used to estimate Ankara’s annual water demand values ​for the 29-year period of 2025‒2054 for three different scenarios and compared with official estimates. The estimates obtained in this study for high- and low-demand scenarios are 28.95% and 42.45% higher than current official estimates, respectively. Official water demand projections should thus be re-evaluated to prevent water shortages in Ankara. Notably, if a drought similar to that which occurred between 2004 and 2009 occurs in Ankara within the coming decade, the present findings indicate that existing resources will not be sufficient to meet the city’s water needs after the year 2035.},
  archive      = {J_SOCO},
  author       = {Uzlu, Ergun and Dede, Tayfun},
  doi          = {10.1007/s00500-025-10904-5},
  journal      = {Soft Computing},
  month        = {9},
  number       = {17},
  pages        = {5401-5414},
  shortjournal = {Soft Comput.},
  title        = {Development of hybrid models to forecast water demand in the city of ankara},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YOLOv5-CE-DAFF: A polyp detection model based on CBAM-ECA attention mechanism and dropout-based adaptive feature fusion. <em>SOCO</em>, <em>29</em>(17), 5385-5400. (<a href='https://doi.org/10.1007/s00500-025-10895-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorectal cancer commonly originates from polyps. Timely detection and removal of these polyps can significantly reduce mortality rates associated with colorectal cancer. Nevertheless, conventional medical imaging methods suffer from low accuracy and slow detection speeds, rendering them inadequate for practical applications. For the above reasons, we propose a real-time polyp detection model, YOLOv5-CE-DAFF, which is based on the YOLOv5 model and incorporates the CBAM-ECA attention mechanism and dropout-based adaptive feature fusion. Firstly, to pay more attention to polyp features, we incorporate the CBAM-ECA attention module into the local cross-layer fusion structure. Secondly, we design an adaptive feature fusion of the prediction feature layer based on dropout, which increases the number of high-quality prediction boxes. Thirdly, we improve the positive and negative sample matching strategy to accelerate model convergence and improve detection accuracy. Additionally, we combine Soft-NMS and WBF to replace the original NMS algorithm, which retains as many high-quality prediction boxes as possible. The model is tested on two colonoscopy datasets. Numerical experiments show that YOLOv5-CE-DAFF has high detection accuracy and a low missed detection rate for colon polyps. Compared with the original YOLOv5 model, YOLOv5-CE-DAFF significantly improves recognition accuracy and reduces missed detection rate.},
  archive      = {J_SOCO},
  author       = {Zhang, Jiao and Zhang, Qiming and Qiao, Chen and Mei, Zhandong and Ren, Kai and Chen, Jian},
  doi          = {10.1007/s00500-025-10895-3},
  journal      = {Soft Computing},
  month        = {9},
  number       = {17},
  pages        = {5385-5400},
  shortjournal = {Soft Comput.},
  title        = {YOLOv5-CE-DAFF: A polyp detection model based on CBAM-ECA attention mechanism and dropout-based adaptive feature fusion},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A spectral-spatial attention guided multi-scale convolutional network for hyperspectral image classification. <em>SOCO</em>, <em>29</em>(17), 5357-5383. (<a href='https://doi.org/10.1007/s00500-025-10890-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image classification presents significant challenges due to the high dimensionality of the data and the intricate spatial-spectral relationships inherent within hyperspectral imagery. This proposed work builds on certain well-established techniques, its novelty lies in the integration and adaptation of these components into a unified framework designed to address specific challenges in hyperspectral image classification. Unlike traditional PCA applied globally, this research work performs PCA within graph-based segmented regions. This localized approach preserves the spatial coherence of hyperspectral data while reducing dimensionality efficiently. Next to this step, a novel self-attention mechanism within a hybrid 3D-2D CNN architecture is introduced that allows the model to dynamically prioritize critical spectral bands while extracting comprehensive spatial-spectral features. The combination of graph-based segmentation, localized PCA, and attention-guided CNNs creates a robust and cohesive framework that enhances feature extraction and classification accuracy. The proposed framework is evaluated on four publicly available hyperspectral datasets Indian Pines, Kennedy Space Center, Salinas, and Pavia University and compared against seven state-of-the-art models, including SVM, 2D-CNN, 3D-CNN, AHAN, AF2GNN, DSN, and TDS-BiGRU. The experimental results demonstrate the superiority of the proposed approach, achieving an overall accuracy of 99.28% on Indian Pines, 99.99% on Salinas, 99.97% on Pavia University, and 99.34% on KSC dataset, consistently outperforming the existing methods. This framework effectively leverages segmentation, localized dimensionality reduction, and attention mechanisms, offering a robust and efficient solution for hyperspectral image classification. These results confirm the model’s capability to address the complexities of hyperspectral data, providing a significant advancement in the field.},
  archive      = {J_SOCO},
  author       = {Sahu, Soumya Ranjan and Panda, Sucheta},
  doi          = {10.1007/s00500-025-10890-8},
  journal      = {Soft Computing},
  month        = {9},
  number       = {17},
  pages        = {5357-5383},
  shortjournal = {Soft Comput.},
  title        = {A spectral-spatial attention guided multi-scale convolutional network for hyperspectral image classification},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FAA-net: Enhancing person re-identification through local-global feature association attention. <em>SOCO</em>, <em>29</em>(17), 5341-5355. (<a href='https://doi.org/10.1007/s00500-025-10888-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (Re-ID) plays a vital role in smart security and video surveillance systems. However, it remains a challenging task due to factors such as occlusion, visual similarity among individuals, and cluttered backgrounds. Existing networks often extract relatively simple features, which limits their ability to distinguish pedestrians in complex environments due to insufficient discriminative power. To address these challenges, we propose an efficient Feature Association Attention Network (FAA-Net) that integrates both local and global features. Specifically, we design a local-global feature association (LGFA) attention mechanism, which combines spatial and channel domain attention in a complementary manner to enhance the extraction of discriminative features. By effectively associating local details with global context, FAA-Net captures key visual cues and transforms them into more distinctive feature representations. Extensive experiments are conducted on four standard benchmark datasets: Market-1501, DukeMTMC-ReID, CUHK-03, and MSMT17. The results demonstrate that FAA-Net consistently outperforms state-of-the-art methods, especially in challenging Re-ID scenarios. In addition, comprehensive ablation studies validate the effectiveness of each component in our proposed architecture.},
  archive      = {J_SOCO},
  author       = {Zheng, Yangqi and Zhang, Liang and Liang, Jun},
  doi          = {10.1007/s00500-025-10888-2},
  journal      = {Soft Computing},
  month        = {9},
  number       = {17},
  pages        = {5341-5355},
  shortjournal = {Soft Comput.},
  title        = {FAA-net: Enhancing person re-identification through local-global feature association attention},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot learning for plant disease detection using DeepBDC. <em>SOCO</em>, <em>29</em>(17), 5327-5340. (<a href='https://doi.org/10.1007/s00500-025-10884-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plant disease detection in low-data scenarios is a major challenge for computer vision applications in agriculture. Traditional deep learning needs big, labeled datasets, but these are often not available for rare or new plant diseases. To address this issue, this paper presents a few-shot learning (FSL) method for classifying plant diseases using an improved Deep Brownian Distance Covariance (DeepBDC) framework. The model uses a ResNet-12 as a backbone network which uses a Convolutional Block Attention Module (CBAM) to help the network focus on important spatial and channel-wise features. In network, dropout regularization is also applied to reduce overfitting, which is common in few-shot tasks. The DeepBDC module is improved by using L2 normalization and temperature scaling, which makes the feature representations more stable and better for classification. The model uses cosine similarity for 1-shot learning and Gaussian kernel similarity for 5-shot and 10-shot settings. The method is evaluated on two public plant disease datasets, PlantVillage and CCMT, using standard 5-way classification with 15 queries per class and 2000 episodes for each configuration. On the PlantVillage dataset, the model gets 46.53% accuracy for 1-shot, 65.86% for 5-shot, and 69.67% for 10-shot tasks. On the CCMT dataset, it reaches 40.19%, 50.19%, and 53.67% accuracy for the same settings. These results show that the proposed method is a useful way to detect plant diseases when there is less data.},
  archive      = {J_SOCO},
  author       = {Ranjan, Rakesh and Singh, Jyoti Prakash and Titoriya, Ankit Kumar},
  doi          = {10.1007/s00500-025-10884-6},
  journal      = {Soft Computing},
  month        = {9},
  number       = {17},
  pages        = {5327-5340},
  shortjournal = {Soft Comput.},
  title        = {Few-shot learning for plant disease detection using DeepBDC},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning-based novel model for masked face recognition. <em>SOCO</em>, <em>29</em>(17), 5305-5326. (<a href='https://doi.org/10.1007/s00500-025-10866-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A major challenge in facial recognition is maintaining high accuracy without requiring individuals to remove their face masks. This research focuses on recognizing faces by analyzing the upper half—specifically the eyes, forehead, and visible side features like ears. We evaluated nine masked face recognition techniques, including MobileNet, MobileNetV2, ResNet50, DenseNet121, EfficientNetB0, InceptionV3, ResNet101V2, Xception, and our proposed model, using a dataset of ten classes. Our methodology introduces a novel approach that combines a modified MobileNetV2 with a convolutional architecture for fast feature embedding (CAFFE). This design was developed after extensive study of face recognition methods for artificial intelligence applications. To support this, we created a dataset of 3,340 masked face images using artificial masking and data augmentation techniques. The dataset was used to train and test our Python-based AI model. The core objective was to improve the model’s performance by enhancing a pre-trained structure with 7 additional layers, optimized weights, and associated configuration files. Our proposed model integrates transfer learning, deep neural network (DNN) and deep learning (DL) architecture to extract image features of masked face classification (MFC) and masked face recognition (MFR) strategies to effectively extract features for masked face classification and recognition. In conclusion, our model outperformed the other eight traditional approaches, achieving 98.34% accuracy with a 1.66% error rate, while offering fast computation and reduced parameter usage. The source code used in our article are now made available on github platform https://github.com/AnilKumargithu/Masked-Face-Recognition-MFR-Classification-and-Prediction . Our created dataset of artificially masked face images utilized in this research is made available on Kaggle https://www.kaggle.com/datasets/banilkumar20phd7071/masked-face-recognition-dataset-artificial-masking .},
  archive      = {J_SOCO},
  author       = {Kumar, B. Anil and Misra, Neeraj Kumar},
  doi          = {10.1007/s00500-025-10866-8},
  journal      = {Soft Computing},
  month        = {9},
  number       = {17},
  pages        = {5305-5326},
  shortjournal = {Soft Comput.},
  title        = {A deep learning-based novel model for masked face recognition},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
