<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JRTIP</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jrtip">JRTIP - 6</h2>
<ul>
<li><details>
<summary>
(2025). YOLO-GSD: A real-time pedestrian detection algorithm based on YOLOv8 in dense environments. <em>JRTIP</em>, <em>22</em>(6), 1-15. (<a href='https://doi.org/10.1007/s11554-025-01771-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With recent advancements in vision intelligence, pedestrian detection in autonomous driving has become a critical research focus within computer vision. Dense pedestrian scenarios present significant challenges from multi-scale variations and occlusions. Traditional detection methods can be used for pedestrian detection in ordinary scenarios, but they face challenges, such as high computational complexity and overly sophisticated models, that prevent effective deployment on mobile devices like in-vehicle cameras, along with unsatisfactory detection accuracy under multi-scale pedestrian scenarios and heavy occlusion conditions. To address these challenges, this paper proposes YOLO-GSD, an improved lightweight real-time pedestrian detection algorithm based on YOLOv8. The algorithm first introduces a dedicated detection layer specifically designed for small-scale targets. It then incorporates lightweight Ghost convolution and designs a DG-C2f module by integrating Ghost convolution and Dynamic Convolution, aiming to reduce computational complexity while enhancing the algorithm’s multi-scale feature fusion capability. Additionally, it employs the ultra-lightweight DySample upsampler for efficient feature reconstruction and integrates the SEAM attention mechanism to improve occlusion-aware detection. Finally, WIoUv3 is used to replace the CIoU loss function, which improves the generalization ability and overall performance of the algorithm. Experimental results demonstrate mAP@0.5 scores of 90.7% on the WiderPerson dataset (1.4% higher than the baseline) and 86.5% on the CrowdHuman dataset (2.2% improvement). The algorithm’s parameter count is reduced to 6.24 M, its FLOPs are lowered to 22.7 G, and its FPS is increased to 106.6. In addition, a homogeneous training comparison was conducted on the small-object dataset RSOD, demonstrating the advantages of YOLO-GSD in small-object detection. Therefore, the YOLO-GSD algorithm proposed in this paper is suitable for real-time pedestrian detection in multi-scale and occlusion scenarios on mobile platforms with limited computational resources.},
  archive      = {J_JRTIP},
  author       = {Zhang, Zuhao and Li, Weiwei and Luo, Lin},
  doi          = {10.1007/s11554-025-01771-2},
  journal      = {Journal of Real-Time Image Processing},
  month        = {12},
  number       = {6},
  pages        = {1-15},
  shortjournal = {J. Real-Time Image Process.},
  title        = {YOLO-GSD: A real-time pedestrian detection algorithm based on YOLOv8 in dense environments},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TOE-YOLO: Accurate and efficient detection of tiny objects in UAV imagery. <em>JRTIP</em>, <em>22</em>(6), 1-19. (<a href='https://doi.org/10.1007/s11554-025-01770-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing models achieve high accuracy in small object detection but often overlook the rotational and dense characteristics of targets. To address this, we propose an improved YOLO11-based model specifically designed for detecting dense and rotated small objects in UAV scenarios. To better extract features from rotated targets, we design a C3k2–ARC module that enhances the model’s rotational detection capability. In addition, we introduce the CL-Concat feature fusion module, which combines traditional concatenation with channel and spatial attention, significantly improving the quality of multi-scale feature fusion. The experimental results demonstrate that the proposed method achieves notable performance improvements across multiple public benchmark data sets. Compared with the advanced YOLO11n model, our approach achieves gains of 1.6% on VISDRONE, 1.4% on UAVDT, 0.2% on CARPK, and 0.1% on UAVROD, further validating its effectiveness across diverse UAV detection scenarios.},
  archive      = {J_JRTIP},
  author       = {Yan, Haimin and Kong, Xiangbo and Shimada, Tomoyasu and Tomiyama, Hiroyuki},
  doi          = {10.1007/s11554-025-01770-3},
  journal      = {Journal of Real-Time Image Processing},
  month        = {12},
  number       = {6},
  pages        = {1-19},
  shortjournal = {J. Real-Time Image Process.},
  title        = {TOE-YOLO: Accurate and efficient detection of tiny objects in UAV imagery},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast and effective helmet detection in construction sites based on PEG-YOLOv10m. <em>JRTIP</em>, <em>22</em>(6), 1-12. (<a href='https://doi.org/10.1007/s11554-025-01774-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Helmet detection is essential in engineering measurements, ensuring compliance with safety standards and providing real-time data for project management on construction sites. This paper introduces PEG-YOLOv10m, a fast and efficient detection method designed to enhance speed while preserving accuracy. The PEG module replaces the PSA attention mechanism in the backbone network, refining region-of-interest focus, optimizing feature selection, and boosting detection precision. In the neck network, redundant feature layers are removed, simplifying the model and further accelerating detection. To boost the model's effectiveness on hard samples and achieve better training outcomes, a slide loss function is used instead of binary cross-entropy loss for classification. Experimental results show that PEG-YOLOv10m achieves a mAP50 of 93.7% with 313 FPS on the SHWD dataset. Compared to YOLOv10m, PEG-YOLOv10m reduces parameters by 12%, raises mAP50 by 0.5%, and increases detection speed by 8%.},
  archive      = {J_JRTIP},
  author       = {Liu, Peilin and Fang, Yinfeng and Zhang, Xuguang},
  doi          = {10.1007/s11554-025-01774-z},
  journal      = {Journal of Real-Time Image Processing},
  month        = {12},
  number       = {6},
  pages        = {1-12},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Fast and effective helmet detection in construction sites based on PEG-YOLOv10m},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Yolo-based power-efficient object detection on edge devices for USVs. <em>JRTIP</em>, <em>22</em>(6), 1. (<a href='https://doi.org/10.1007/s11554-025-01776-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRTIP},
  author       = {Mela, Jose Luis and Sánchez, Carlos García},
  doi          = {10.1007/s11554-025-01776-x},
  journal      = {Journal of Real-Time Image Processing},
  month        = {12},
  number       = {6},
  pages        = {1},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Correction: Yolo-based power-efficient object detection on edge devices for USVs},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved YOLOv10-based real-time helmet detection algorithm for complex scenarios. <em>JRTIP</em>, <em>22</em>(6), 1-14. (<a href='https://doi.org/10.1007/s11554-025-01775-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In complex construction environments, existing algorithms exhibit significant limitations, particularly characterized by high false positive rates, frequent missed detections, and insufficient detection accuracy. To address these issues, this paper presents YOLOv10n-WDE (YOLOv10n-Wavelet Dynamic Enhancement), an enhanced helmet detection algorithm based on YOLOv10, which incorporates three key improvements. First, we developed the WFDConv (Wavelet-Frequency Dynamic Convolution) module, which integrates discrete wavelet transforms with dynamic convolution to significantly enhance the ability to capture multi-scale features, thereby improving precision and reducing false positive rates. Second, we introduced a lightweight parallel Spatial Pyramid Pooling Network (LPSPPF) that boosts feature extraction efficiency through a parallel architecture, enhancing the detection capability for small targets and consequently improving recall while minimizing missed detections. Lastly, we implemented a joint loss function mechanism that combines Focal Loss for bounding box regression with Varifocal Loss for classification optimization, thereby improving the model’s overall accuracy in complex scenarios. Experimental results show that on the SHWD dataset, YOLOv10n-WDE achieves mAP50 improvements of 5.1% and 1.8% over YOLOv8n and YOLOv10n, respectively. Its precision and recall reach 92.9% and 87.6%, both surpassing those of YOLOv8n (91.0% and 87.5%) and YOLOv10n (89.6% and 90.4%). On the SHDD dataset, compared with YOLOv10n, YOLOv10n-WDE improves precision by 5.3%, recall by 1.9%, and mAP50 by 3.7%. These enhancements fully demonstrate their effectiveness in reducing false positives and missed detections. At the same time, YOLOv10n-WDE maintains a real-time processing speed of 384 FPS, meeting the dual demands for efficiency and real-time performance in complex construction environments.},
  archive      = {J_JRTIP},
  author       = {Dong, HanTang and Wang, Yong and Miao, Duoqian},
  doi          = {10.1007/s11554-025-01775-y},
  journal      = {Journal of Real-Time Image Processing},
  month        = {12},
  number       = {6},
  pages        = {1-14},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Improved YOLOv10-based real-time helmet detection algorithm for complex scenarios},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LCPD-DETR: A lightweight object detection model based on RT-DETR for military camouflaged personnel. <em>JRTIP</em>, <em>22</em>(6), 1-16. (<a href='https://doi.org/10.1007/s11554-025-01772-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged personnel detection models are crucial for the unmanned combat mode of modern warfare. The high integration of camouflaged personnel with the environment makes recognition difficult, and existing models struggle to balance model complexity and recognition accuracy. To address this challenge, we propose a Lightweight Camouflaged Personnel Detection model (LCPD-DETR) to improve model effectiveness with lower computational cost. In the backbone, we integrate Dual Convolution (DualConv) into residual blocks to alleviate high computational redundancy and propose a Lightweight Multi-Scale Cascaded Block (LMSCBlock) to improve multi-scale feature extraction capability for high-level semantic features. In the neck stage, we design a Local–Global Attention (LGA) module to enhance the model’s ability to focus on local details of camouflaged personnel and improve the model’s computational efficiency. We present the Partial-Diverse-Branch Block (PDBBlock) for cross-scale feature fusion, thereby strengthening the ability of multi-scale feature fusion with lower computational resources. We evaluated our method separately on the Camouflaged People Dataset and the Military Camouflaged Personnel Dataset. The experimental results show that our model meets the requirements of lightweight and accurate detection, providing an efficient solution for military camouflaged personnel detection.},
  archive      = {J_JRTIP},
  author       = {Chen, Lifang and Chen, Mingxu and Zhang, Xufeng and Xie, Zhenping},
  doi          = {10.1007/s11554-025-01772-1},
  journal      = {Journal of Real-Time Image Processing},
  month        = {12},
  number       = {6},
  pages        = {1-16},
  shortjournal = {J. Real-Time Image Process.},
  title        = {LCPD-DETR: A lightweight object detection model based on RT-DETR for military camouflaged personnel},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
