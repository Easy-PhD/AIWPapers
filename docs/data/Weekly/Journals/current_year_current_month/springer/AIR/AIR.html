<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AIR</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="air">AIR - 8</h2>
<ul>
<li><details>
<summary>
(2025). AI apology: A critical review of apology in AI systems. <em>AIR</em>, <em>58</em>(12), 1-78. (<a href='https://doi.org/10.1007/s10462-025-11305-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Apologies are a powerful tool used in human-human interactions to provide affective support, regulate social processes, and exchange information following a trust violation. The emerging field of AI apology investigates the use of apologies by artificially intelligent systems, with recent research suggesting how this tool may provide similar value in human-machine interactions. Until recently, contributions to this area were sparse, and these works have yet to be synthesised into a cohesive body of knowledge. This article provides the first synthesis and critical analysis of the state of AI apology research, focusing on studies published between 2020 and 2023. We derive a framework of attributes to describe five core elements of apology: outcome, interaction, offence, recipient, and offender. With this framework as the basis for our critique, we show how apologies can be used to recover from misalignment in human-AI interactions, and examine trends and inconsistencies within the field. Among the observations, we outline the importance of curating a human-aligned and cross-disciplinary perspective in this research, with consideration for improved system capabilities and long-term outcomes.},
  archive      = {J_AIR},
  author       = {Harland, Hadassah and Dazeley, Richard and Senaratne, Hashini and Vamplew, Peter and Cruz, Francisco and Nakisa, Bahareh},
  doi          = {10.1007/s10462-025-11305-8},
  journal      = {Artificial Intelligence Review},
  month        = {12},
  number       = {12},
  pages        = {1-78},
  shortjournal = {Artif. Intell. Rev.},
  title        = {AI apology: A critical review of apology in AI systems},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effectiveness of data resampling and ensemble learning in multiclass imbalance learning. <em>AIR</em>, <em>58</em>(12), 1-60. (<a href='https://doi.org/10.1007/s10462-025-11357-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification tasks in many real-world problems often involve multiclass datasets with imbalanced class distributions, which have more difficulty factors than binary classification. Previous studies have proposed various methods to address this multiclass imbalanced learning issue. Data resampling and ensemble learning are the most popular among the proposed methods. However, no comprehensive review or survey has provided an in-depth comparison of ad hoc methods in multiclass imbalance learning, particularly with a focus on data resampling and ensemble learning. Moreover, there is a lack of studies that analyze the effectiveness of each method in terms of the difficulty factors in multiclass imbalance learning. This paper provides a comprehensive review and comparative analysis to identify the strengths and weaknesses of each method and assess their effectiveness in improving classification performance. The analysis shows that not all methods effectively enhance classification performance on multiclass imbalanced datasets. Some methods even perform worse than the baseline performance. The review also reveals that datasets with certain difficulty factors are more challenging for most existing methods to handle. Ultimately, this paper summarizes several important lessons and identifies research gaps to guide future work in the field.},
  archive      = {J_AIR},
  author       = {Fachrie, Muhammad and Musdholifah, Aina and Pulungan, Reza},
  doi          = {10.1007/s10462-025-11357-w},
  journal      = {Artificial Intelligence Review},
  month        = {12},
  number       = {12},
  pages        = {1-60},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Effectiveness of data resampling and ensemble learning in multiclass imbalance learning},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI in motion: A systematic review of artificial intelligence-driven virtual assistants for physical activity promotion and their comparison with traditional strategies. <em>AIR</em>, <em>58</em>(12), 1-28. (<a href='https://doi.org/10.1007/s10462-025-11361-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physical inactivity remains a major public health concern globally, prompting the need for scalable, cost-effective interventions. Artificial Intelligence-driven Virtual Assistants (AIVAs) such as chatbots and virtual agents have emerged as novel methods to promote physical activity (PA), yet their effectiveness compared to traditional strategies remains unclear. This systematic review aimed at examining the characteristics, strategies, and effectiveness of AIVAs in promoting PA in adults and to compare them with traditional interventions. A systematic search of Scopus, Web of Science, PubMed, and Cochrane was conducted through May 2025. Eight interventional studies that employed AIVAs targeting PA were included. Risk of bias was assessed using ROBINS-I and RoB 2 tools. Intervention characteristics, outcomes, and behavioral strategies were extracted and synthesized. AIVAs were found to incorporate established behavior change techniques such as goal setting, feedback, and motivational support. Several studies demonstrated positive effects on PA metrics such as step counts and moderate to vigorous PA, though results were heterogeneous. Engagement and usability were generally high, particularly in interventions incorporating relational features. Compared to traditional interventions, AIVAs offered advantages in scalability and user autonomy but often lacked rigorous designs and long-term evaluation. AIVAs show promise as complementary tools for PA promotion, potentially overcoming scalability barriers associated with human-delivered programs. However, future research should prioritize methodologically robust designs, long-term assessments, and hybrid models that integrate both human and AI elements.},
  archive      = {J_AIR},
  author       = {Montelaghi, Alice and Ciorciari, Andrea and Roklicer, Roberto and Jurak, Gregor and Carraro, Attilio},
  doi          = {10.1007/s10462-025-11361-0},
  journal      = {Artificial Intelligence Review},
  month        = {12},
  number       = {12},
  pages        = {1-28},
  shortjournal = {Artif. Intell. Rev.},
  title        = {AI in motion: A systematic review of artificial intelligence-driven virtual assistants for physical activity promotion and their comparison with traditional strategies},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CTWA: A novel incremental deep learning-based intrusion detection method for the internet of things. <em>AIR</em>, <em>58</em>(12), 1-24. (<a href='https://doi.org/10.1007/s10462-025-11358-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class incremental learning aims to learn new courses in an incremental manner without forgetting the categories previously learned. A novel incremental Internet of Things (IoT) intrusion detection method CTWA based on Convolutional Autoencoder (CAE) and Temporal Convolutional Network (TCN) is proposed to address the issues of insufficient generalization ability, high computational resources, and redundant features in class incremental learning. This method first completes the training of the CAE-TCN module, extracts and concatenates local features of data samples through CAE and TCN, and then initializes the incremental learning module. Residual modules are added to the CAE to improve the training effect of the model and avoid gradient vanishing problems. The CAE-TCN module shares lower-level feature representations through task-specific layers in incremental learning module. It distinguishes between old and new tasks using Gaussian distribution, and applies Weight alignment (WA) techniques between task heads to ensure that learning the new task does not result in forgetting the knowledge of the old tasks. Ultimately, the outputs of both new and old tasks are weighted and fused to ensure the optimal classification result. Additionally, a loss function combining cross-entropy loss and label smoothing loss is used to enhance the model’s performance. We conducted experiments on two datasets. The experimental results on CICIoT2023 dataset demonstrate that the proposed model excels in terms of accuracy, precision, recall, and F1-Score, achieving 0.9643, 0.9659, 0.9643, and 0.9645, respectively. With 40 training epochs, the model’s runtime is 789.58 s, which is higher than most comparison models, but the accuracy is significantly improved. The proposed method can effectively distinguishes between different known and unknown types of attacks, highlighting its potential applications in the field of cybersecurity.},
  archive      = {J_AIR},
  author       = {Wang, Haizhen and Yang, Yutong and Tan, Pan},
  doi          = {10.1007/s10462-025-11358-9},
  journal      = {Artificial Intelligence Review},
  month        = {12},
  number       = {12},
  pages        = {1-24},
  shortjournal = {Artif. Intell. Rev.},
  title        = {CTWA: A novel incremental deep learning-based intrusion detection method for the internet of things},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Empowering scientific discovery with explainable small domain-specific and large language models. <em>AIR</em>, <em>58</em>(12), 1-39. (<a href='https://doi.org/10.1007/s10462-025-11365-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As artificial intelligence (AI) increasingly integrates into scientific research, explainability has become a cornerstone for ensuring reliability and innovation in discovery processes. This review offers a forward-looking integration of explainable AI (XAI)-based research paradigms, encompassing small domain-specific models, large language models (LLMs), and agent-based large-small model collaboration. For domain-specific models, we introduce a knowledge-oriented taxonomy categorizing methods into knowledge-agnostic, knowledge-based, knowledge-infused, and knowledge-verified approaches, emphasizing the balance between domain knowledge and innovative insights. For LLMs, we examine three strategies for integrating domain knowledge—prompt engineering, retrieval-augmented generation, and supervised fine-tuning—along with advances in explainability, including local, global, and conversation-based explanations. We also envision future agent-based model collaborations within automated laboratories, stressing the need for context-aware explanations tailored to research goals. Additionally, we discuss the unique characteristics and limitations of both explainable small domain-specific models and LLMs in the realm of scientific discovery. Finally, we highlight methodological challenges, potential pitfalls, and the necessity of rigorous validation to ensure XAI’s transformative role in accelerating scientific discovery and reshaping research paradigms.},
  archive      = {J_AIR},
  author       = {Yu, Hengjie and Wang, Yizhi and Cheng, Tao and Yan, Yan and Dawson, Kenneth A. and Li, Sam F. Y. and Zheng, Yefeng and Jin, Yaochu},
  doi          = {10.1007/s10462-025-11365-w},
  journal      = {Artificial Intelligence Review},
  month        = {12},
  number       = {12},
  pages        = {1-39},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Empowering scientific discovery with explainable small domain-specific and large language models},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning diversified representations for visual abstract reasoning. <em>AIR</em>, <em>58</em>(12), 1-29. (<a href='https://doi.org/10.1007/s10462-025-11372-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning effective representations suitable for decision making in high-level cognitive space is crucial for visual abstract reasoning tasks. The visual system of the mammalian brain is organized into parallel networks that can be roughly classified in dichotomy as the dorsal and ventral streams. How do parallel networks learn efficient representations for cognitive tasks is still an elusive question. We propose the Information Competition Learning Network (ICNet) within a mutual information-constrained framework to learn diversified representations for visual abstract reasoning tasks. ICNet comprises a representation learning module and a rule extractor module. The representation learning module learns two complementary sets of representation under different constraints. These two sets compete to prevent from learning what the other has learned, thereby minimizing mutual predictability. Subsequently, these sets are combined synergistically and relayed to the rule extractor module, where discrete abstract rules are formed to predict the correct option. Empirical experiments consistently show that ICNet achieves superior results across several visual abstract reasoning datasets. Additionally, in Out-of-Distribution relationship reasoning benchmarks, ICNet demonstrates robust generalization ability.},
  archive      = {J_AIR},
  author       = {Zhao, Kai and Zhu, Yao and Si, Bailu},
  doi          = {10.1007/s10462-025-11372-x},
  journal      = {Artificial Intelligence Review},
  month        = {12},
  number       = {12},
  pages        = {1-29},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Learning diversified representations for visual abstract reasoning},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Securing (vision-based) autonomous systems: Taxonomy, challenges, and defense mechanisms against adversarial threats. <em>AIR</em>, <em>58</em>(12), 1-59. (<a href='https://doi.org/10.1007/s10462-025-11373-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid integration of computer vision into Autonomous Systems (AS) has introduced new vulnerabilities, particularly in the form of adversarial threats capable of manipulating perception and control modules. While multiple surveys have addressed adversarial robustness in deep learning, few have systematically analyzed how these threats manifest across the full stack and life-cycle of AS. This review bridges that gap by presenting a structured synthesis that spans both, foundational vision-centric literature and recent AS-specific advances, with focus on digital and physical threat vectors. We introduce a unified framework mapping adversarial threats across the AS stack and life-cycle, supported by three novel analytical matrices: the Life-cycle–Attack Matrix (linking attacks to data, training, and inference stages), the Stack–Threat Matrix (localizing vulnerabilities throughout the autonomy stack), and the Exposure–Impact Matrix (connecting attack exposure to AI design vulnerabilities and operational consequences). Drawing on these models, we define holistic requirements for effective AS defenses and critically appraise the current landscape of adversarial robustness. Finally, we propose the AS-ADS scoring framework to enable comparative assessment of defense methods in terms of their alignment with the practical needs of AS, and outline actionable directions for advancing the robustness of vision-based autonomous systems.},
  archive      = {J_AIR},
  author       = {Lopez Pellicer, Alvaro and Angelov, Plamen and Suri, Neeraj},
  doi          = {10.1007/s10462-025-11373-w},
  journal      = {Artificial Intelligence Review},
  month        = {12},
  number       = {12},
  pages        = {1-59},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Securing (vision-based) autonomous systems: Taxonomy, challenges, and defense mechanisms against adversarial threats},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic review of bias detection methods for non-english word embeddings and language models. <em>AIR</em>, <em>58</em>(12), 1-56. (<a href='https://doi.org/10.1007/s10462-025-11375-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biases in applications of machine learning and artificial intelligence are a major limitation of these applications. Stereotypes of the society are reflected in different types of applications, including image generation, machine translation or CV ranking. This is in particular also the case for language models and word embeddings, encoding human language as mathematical vectors. Research addressing the challenging problem of detection (and mitigation) of the bias in these embeddings is often conducted for the English language. However, the stereotypes encoded can be language dependent and impacted by a cultural environment. Thus, dedicated research efforts for languages other than English are required. In this paper, we conduct a systematic literature review to identify and compare existing bias detection methods for non-English word embeddings and language models. In an interdisciplinary team we examine the technical aspects, as well as the definitions of bias used by researchers in the field. Based on our findings, we outline a research plan for making bias detection in the field of NLP more inclusive for languages other than English.},
  archive      = {J_AIR},
  author       = {Puttick, Alexandre and Ikae, Catherine and Rigotti, Carlotta and Fosch-Villaronga, Eduard and Kharas, Mark W. and Søraa, Roger A. and Kurpicz-Briki, Mascha},
  doi          = {10.1007/s10462-025-11375-8},
  journal      = {Artificial Intelligence Review},
  month        = {12},
  number       = {12},
  pages        = {1-56},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A systematic review of bias detection methods for non-english word embeddings and language models},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
