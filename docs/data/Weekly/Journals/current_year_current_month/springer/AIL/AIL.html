<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AIL</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ail">AIL - 11</h2>
<ul>
<li><details>
<summary>
(2025). Correction to: Code is law: How COMPAS affects the way the judiciary handles the risk of recidivism. <em>AIL</em>, <em>33</em>(3), 873-874. (<a href='https://doi.org/10.1007/s10506-024-09400-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIL},
  author       = {Engel, Christopher and Linhardt, Lorenz and Schubert, Marcel},
  doi          = {10.1007/s10506-024-09400-2},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {873-874},
  shortjournal = {Artif. Intell. Law},
  title        = {Correction to: Code is law: How COMPAS affects the way the judiciary handles the risk of recidivism},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The digital transformation of jurisprudence: An evaluation of ChatGPT-4’s applicability to solve cases in business law. <em>AIL</em>, <em>33</em>(3), 847-871. (<a href='https://doi.org/10.1007/s10506-024-09406-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the evolving landscape of legal information systems, ChatGPT-4 and other advanced conversational agents (CAs) offer the potential to disruptively transform the law industry. This study evaluates commercially available CAs within the German legal context, thereby assessing the generalizability of previous U.S.-based findings. Employing a unique corpus of 200 distinct legal tasks, ChatGPT-4 was benchmarked against Google Bard, Google Gemini, and its predecessor, ChatGPT-3.5. Human-expert and automated assessments of 4000 CA-generated responses reveal ChatGPT-4 to be the first CA to surpass the threshold of solving realistic legal tasks and passing a German business law exam. While ChatGPT-4 outperforms ChatGPT-3.5, Google Bard, and Google Gemini in both consistency and quality, the results demonstrate a considerable degree of variability, especially in complex cases with no predefined response options. Based on these findings, legal professionals should manually verify all texts produced by CAs before use. Novices must exercise caution with CA-generated legal advice, given the expertise needed for its assessment.},
  archive      = {J_AIL},
  author       = {Schweitzer, Sascha and Conrads, Markus},
  doi          = {10.1007/s10506-024-09406-w},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {847-871},
  shortjournal = {Artif. Intell. Law},
  title        = {The digital transformation of jurisprudence: An evaluation of ChatGPT-4’s applicability to solve cases in business law},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intermediate factors and precedential constraint. <em>AIL</em>, <em>33</em>(3), 827-846. (<a href='https://doi.org/10.1007/s10506-024-09405-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the extension of formal accounts of precedential constraint to make use of a factor hierarchy with intermediate factors. A problem arises, however, because constraints expressed in terms of intermediate factors may give different outcomes from those expressed only using base level factors. We argue that constraints that use only base level factors yield the correct outcomes, but that intermediate factors play an important role in the justification and explanation of those outcomes. The discussion is illustrated with a running example.},
  archive      = {J_AIL},
  author       = {Bench-Capon, Trevor},
  doi          = {10.1007/s10506-024-09405-x},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {827-846},
  shortjournal = {Artif. Intell. Law},
  title        = {Intermediate factors and precedential constraint},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-training improves few-shot learning in legal artificial intelligence tasks. <em>AIL</em>, <em>33</em>(3), 809-825. (<a href='https://doi.org/10.1007/s10506-024-09403-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the labeling costs in legal artificial intelligence tasks are expensive. Therefore, it becomes a challenge to utilize low cost to train a robust model. In this paper, we propose a LAIAugment approach, which aims to enhance the few-shot learning capability in legal artificial intelligence tasks. Specifically, we first use the self-training approach to label the amount of unlabelled data to enhance the feature learning capability of the model. Moreover, we also search for datasets that are similar to the training set by improving the text similarity function. We conducted experimental analyses for three legal artificial intelligence tasks, including evidence extraction, legal element extraction, and case multi-label prediction, which composed of 3500 judgement documents. The experimental results show that the proposed LAIAugment method has an average F1-score of 72.3% on the three legal AI tasks, which is 1.93% higher than the baseline model. At the same time, it shows a huge improvement in few-shot learning.},
  archive      = {J_AIL},
  author       = {Zhou, Yulin and Qin, Yongbin and Huang, Ruizhang and Chen, Yanping and Lin, Chuan and Zhou, Yuan},
  doi          = {10.1007/s10506-024-09403-z},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {809-825},
  shortjournal = {Artif. Intell. Law},
  title        = {Self-training improves few-shot learning in legal artificial intelligence tasks},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Japanese tort-case dataset for rationale-supported legal judgment prediction. <em>AIL</em>, <em>33</em>(3), 783-807. (<a href='https://doi.org/10.1007/s10506-024-09402-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the first dataset for Japanese Legal Judgment Prediction (LJP), the Japanese Tort-case Dataset (JTD), which features two tasks: tort prediction and its rationale extraction. The rationale extraction task identifies the court’s accepting arguments from alleged arguments by plaintiffs and defendants, which is a novel task in the field. JTD is constructed based on annotated 3477 Japanese Civil Code judgments by 41 legal experts, resulting in 7978 instances with 59,697 of their alleged arguments from the involved parties. Our baseline experiments show the feasibility of the proposed two tasks, and our error analysis by legal experts identifies sources of errors and suggests future directions of the LJP research.},
  archive      = {J_AIL},
  author       = {Yamada, Hiroaki and Tokunaga, Takenobu and Ohara, Ryutaro and Tokutsu, Akira and Takeshita, Keisuke and Sumida, Mihoko},
  doi          = {10.1007/s10506-024-09402-0},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {783-807},
  shortjournal = {Artif. Intell. Law},
  title        = {Japanese tort-case dataset for rationale-supported legal judgment prediction},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). InstructPatentGPT: Training patent language models to follow instructions with human feedback. <em>AIL</em>, <em>33</em>(3), 739-782. (<a href='https://doi.org/10.1007/s10506-024-09401-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, patent prosecution is conceptualized as a system of reinforcement learning from human feedback. The objective of the system is to increase the likelihood for a language model to generate patent claims that have a higher chance of being granted. To showcase the controllability of the language model, the system learns from granted patents and pre-grant applications with different rewards. The status of “granted” and “pre-grant” are perceived as labeled human feedback implicitly. In addition, specific to patent drafting, the experiments in this research demonstrate the model’s capability to learn from adjusting claim length and inclusion of limiting terms for narrowing claim scope. As proof of concept, the experiments focus on claim ones only and the training data originates from a patent dataset tailored specifically for artificial intelligence. Although the available human feedback in patent prosecution are limited and the quality of generated patent text requires improvement, the experiments following the 3-stage reinforcement learning from human feedback have demonstrated that generative language models are capable of reflecting the human feedback or intent in patent prosecution. To enhance the usability of language models, the implementation in this research utilizes modern techniques that enable execution on a single consumer-grade GPU. The demonstrated proof of concept, which reduces hardware requirements, will prove valuable in the future as more human feedback in patent prosecution become available for broader use, either within patent offices or in the public domain.},
  archive      = {J_AIL},
  author       = {Lee, Jieh-Sheng},
  doi          = {10.1007/s10506-024-09401-1},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {739-782},
  shortjournal = {Artif. Intell. Law},
  title        = {InstructPatentGPT: Training patent language models to follow instructions with human feedback},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models in cryptocurrency securities cases: Can a GPT model meaningfully assist lawyers?. <em>AIL</em>, <em>33</em>(3), 691-737. (<a href='https://doi.org/10.1007/s10506-024-09399-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) could be a useful tool for lawyers. However, empirical research on their effectiveness in conducting legal tasks is scant. We study securities cases involving cryptocurrencies as one of numerous contexts where AI could support the legal process, studying GPT-3.5’s legal reasoning and ChatGPT’s legal drafting capabilities. We examine whether a) GPT-3.5 can accurately determine which laws are potentially being violated from a fact pattern, and b) whether there is a difference in juror decision-making based on complaints written by a lawyer compared to ChatGPT. We feed fact patterns from real-life cases to GPT-3.5 and evaluate its ability to determine correct potential violations from the scenario and exclude spurious violations. Second, we had mock jurors assess complaints written by ChatGPT and lawyers. GPT-3.5’s legal reasoning skills proved weak, though we expect improvement in future models, particularly given the violations it suggested tended to be correct (it merely missed additional, correct violations). ChatGPT performed better at legal drafting, and jurors’ decisions were not statistically significantly associated with the author of the document upon which they based their decisions. Because GPT-3.5 cannot satisfactorily conduct legal reasoning tasks, it would be unlikely to be able to help lawyers in a meaningful way at this stage. However, ChatGPT’s drafting skills (though, perhaps, still inferior to lawyers) could assist lawyers in providing legal services. Our research is the first to systematically study an LLM’s legal drafting and reasoning capabilities in litigation, as well as in securities law and cryptocurrency-related misconduct.},
  archive      = {J_AIL},
  author       = {Trozze, Arianna and Davies, Toby and Kleinberg, Bennett},
  doi          = {10.1007/s10506-024-09399-6},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {691-737},
  shortjournal = {Artif. Intell. Law},
  title        = {Large language models in cryptocurrency securities cases: Can a GPT model meaningfully assist lawyers?},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unfair clause detection in terms of service across multiple languages. <em>AIL</em>, <em>33</em>(3), 641-689. (<a href='https://doi.org/10.1007/s10506-024-09398-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the existing natural language processing systems for legal texts are developed for the English language. Nevertheless, there are several application domains where multiple versions of the same documents are provided in different languages, especially inside the European Union. One notable example is given by Terms of Service (ToS). In this paper, we compare different approaches to the task of detecting potential unfair clauses in ToS across multiple languages. In particular, after developing an annotated corpus and a machine learning classifier for English, we consider and compare several strategies to extend the system to other languages: building a novel corpus and training a novel machine learning system for each language, from scratch; projecting annotations across documents in different languages, to avoid the creation of novel corpora; translating training documents while keeping the original annotations; translating queries at prediction time and relying on the English system only. An extended experimental evaluation conducted on a large, original dataset indicates that the time-consuming task of re-building a novel annotated corpus for each language can often be avoided with no significant degradation in terms of performance.},
  archive      = {J_AIL},
  author       = {Galassi, Andrea and Lagioia, Francesca and Jabłonowska, Agnieszka and Lippi, Marco},
  doi          = {10.1007/s10506-024-09398-7},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {641-689},
  shortjournal = {Artif. Intell. Law},
  title        = {Unfair clause detection in terms of service across multiple languages},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boosting court judgment prediction and explanation using legal entities. <em>AIL</em>, <em>33</em>(3), 605-640. (<a href='https://doi.org/10.1007/s10506-024-09397-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic prediction of court case judgments using Deep Learning and Natural Language Processing is challenged by the variety of norms and regulations, the inherent complexity of the forensic language, and the length of legal judgments. Although state-of-the-art transformer-based architectures and Large Language Models (LLMs) are pre-trained on large-scale datasets, the underlying model reasoning is not transparent to the legal expert. This paper jointly addresses court judgment prediction and explanation by not only predicting the judgment but also providing legal experts with sentence-based explanations. To boost the performance of both tasks we leverage a legal named entity recognition step, which automatically annotates documents with meaningful domain-specific entity tags and masks the corresponding fine-grained descriptions. In such a way, transformer-based architectures and Large Language Models can attend to in-domain entity-related information in the inference process while neglecting irrelevant details. Furthermore, the explainer can boost the relevance of entity-enriched sentences while limiting the diffusion of potentially sensitive information. We also explore the use of in-context learning and lightweight fine-tuning to tailor LLMs to the legal language style and the downstream prediction and explanation tasks. The results obtained on a benchmark dataset from the Indian judicial system show the superior performance of entity-aware approaches to both judgment prediction and explanation.},
  archive      = {J_AIL},
  author       = {Benedetto, Irene and Koudounas, Alkis and Vaiani, Lorenzo and Pastor, Eliana and Cagliero, Luca and Tarasconi, Francesco and Baralis, Elena},
  doi          = {10.1007/s10506-024-09397-8},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {605-640},
  shortjournal = {Artif. Intell. Law},
  title        = {Boosting court judgment prediction and explanation using legal entities},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Re-evaluating GPT-4’s bar exam performance. <em>AIL</em>, <em>33</em>(3), 581-604. (<a href='https://doi.org/10.1007/s10506-024-09396-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Perhaps the most widely touted of GPT-4’s at-launch, zero-shot capabilities has been its reported 90th-percentile performance on the Uniform Bar Exam. This paper begins by investigating the methodological challenges in documenting and verifying the 90th-percentile claim, presenting four sets of findings that indicate that OpenAI’s estimates of GPT-4’s UBE percentile are overinflated. First, although GPT-4’s UBE score nears the 90th percentile when examining approximate conversions from February administrations of the Illinois Bar Exam, these estimates are heavily skewed towards repeat test-takers who failed the July administration and score significantly lower than the general test-taking population. Second, data from a recent July administration of the same exam suggests GPT-4’s overall UBE percentile was below the 69th percentile, and $$\sim$$ 48th percentile on essays. Third, examining official NCBE data and using several conservative statistical assumptions, GPT-4’s performance against first-time test takers is estimated to be $$\sim$$ 62nd percentile, including $$\sim$$ 42nd percentile on essays. Fourth, when examining only those who passed the exam (i.e. licensed or license-pending attorneys), GPT-4’s performance is estimated to drop to $$\sim$$ 48th percentile overall, and $$\sim$$ 15th percentile on essays. In addition to investigating the validity of the percentile claim, the paper also investigates the validity of GPT-4’s reported scaled UBE score of 298. The paper successfully replicates the MBE score, but highlights several methodological issues in the grading of the MPT + MEE components of the exam, which call into question the validity of the reported essay score. Finally, the paper investigates the effect of different hyperparameter combinations on GPT-4’s MBE performance, finding no significant effect of adjusting temperature settings, and a significant effect of few-shot chain-of-thought prompting over basic zero-shot prompting. Taken together, these findings carry timely insights for the desirability and feasibility of outsourcing legally relevant tasks to AI models, as well as for the importance for AI developers to implement rigorous and transparent capabilities evaluations to help secure safe and trustworthy AI.},
  archive      = {J_AIL},
  author       = {Martínez, Eric},
  doi          = {10.1007/s10506-024-09396-9},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {581-604},
  shortjournal = {Artif. Intell. Law},
  title        = {Re-evaluating GPT-4’s bar exam performance},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring explainable AI in the tax domain. <em>AIL</em>, <em>33</em>(3), 551-579. (<a href='https://doi.org/10.1007/s10506-024-09395-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyses whether current explainable AI (XAI) techniques can help to address taxpayer concerns about the use of AI in taxation. As tax authorities around the world increase their use of AI-based techniques, taxpayers are increasingly at a loss about whether and how the ensuing decisions follow the procedures required by law and respect their substantive rights. The use of XAI has been proposed as a response to this issue, but it is still an open question whether current XAI techniques are enough to meet existing legal requirements. The paper approaches this question in the context of a case study: a prototype tax fraud detector trained on an anonymized dataset of real-world cases handled by the Buenos Aires (Argentina) tax authority. The decisions produced by this detector are explained through the use of various classification methods, and the outputs of these explanation models are evaluated on their explanatory power and on their compliance with the legal obligation that tax authorities provide the rationale behind their decision-making. We conclude the paper by suggesting technical and legal approaches for designing explanation mechanisms that meet the needs of legal explanation in the tax domain.},
  archive      = {J_AIL},
  author       = {Górski, Łukasz and Kuźniacki, Błażej and Almada, Marco and Tyliński, Kamil and Calvo, Madalena and Asnaghi, Pablo Matias and Almada, Luciano and Iñiguez, Hilario and Rubianes, Fernando and Pera, Octavio and Nigrelli, Juan Ignacio},
  doi          = {10.1007/s10506-024-09395-w},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {551-579},
  shortjournal = {Artif. Intell. Law},
  title        = {Exploring explainable AI in the tax domain},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
