<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NCA</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="nca">NCA - 109</h2>
<ul>
<li><details>
<summary>
(2025). Estimate remaining useful life for predictive railways maintenance based on LSTM autoencoder. <em>NCA</em>, <em>37</em>(27), 22967-22978. (<a href='https://doi.org/10.1007/s00521-021-06051-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, frequent maintenance and repair of mechanical equipment whose goal is to deter the suspension time of railway infrastructures are proven to be ineffectual. It also results in loss of reliability as well as consuming unnecessary means and costs, since at least half of the precautionary maintenance activities are considered redundant. Despite this spending, operators are struggling to adequately maintain their assets—resulting in unacceptably frequent delays and cancellations and low levels of satisfaction among rail users. Thanks to the increasing availability and sophistication of advanced analytics, operators have a significant opportunity to create solutions to long-standing maintenance challenges. The role of predictive maintenance and especially that of Design-Out Maintenance constitute the necessary procedure that can predict in time any hardware failures, while reducing the damage or wearing down of the overall operational equipment. This can increase the effectiveness of the railways, while significantly reducing the overall expenditure needed for the repair and maintenance of the industry’s infrastructure. This paper proposes a predictive railways maintenance strategy based on deep learning techniques. Specifically, and in order to achieve the exact remaining useful life of the railway equipment, a hybrid neural architecture of long short-term memory autoencoder network is used. The purpose of this suggested architecture is the automatic feature extraction of dynamic time series and their utilization on a prediction model, which can predict with high accuracy the remaining useful life of the railway’s mechanical equipment.},
  archive      = {J_NCA},
  author       = {Hu, Liqiang and Dai, Guoyong},
  doi          = {10.1007/s00521-021-06051-1},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22967-22978},
  shortjournal = {Neural Comput. Appl.},
  title        = {Estimate remaining useful life for predictive railways maintenance based on LSTM autoencoder},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). I-SAMARAH, an incremental constrained clustering applied to remote sensing images. <em>NCA</em>, <em>37</em>(27), 22941-22965. (<a href='https://doi.org/10.1007/s00521-025-11161-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatically extracting knowledge from diverse datasets is a valuable task that helps experts explore new types of data while reducing the time spent on manual annotations. This is particularly important for emerging fields such as emergency management and environmental monitoring. Traditional unsupervised methods often struggle to capture experts’ intuitions or integrate non-formalized knowledge. On the other hand, supervised methods typically require a substantial amount of prior knowledge to function effectively. Constrained clustering, a semi-supervised approach, addresses these challenges by allowing experts to incorporate their knowledge into the clustering process. However, it often yields suboptimal results because it is difficult for experts to provide constraints that are both informative and coherent. Building on the idea that it is easier to critique than to construct, this article introduces a novel method called I-Samarah, an incremental constrained clustering approach. This method alternates between a clustering phase, where expert-provided constraints are applied, and a critique phase, where experts provide feedback on the clustering results. Through an iterative process, the method refines the clusters, improving their alignment with expert knowledge. We empirically demonstrate the effectiveness of I-Samarah using remote sensing image time series, comparing it to other constrained clustering methods in terms of result quality and to supervised methods in terms of annotation efficiency.},
  archive      = {J_NCA},
  author       = {Lafabrègue, Baptiste and Gançarski, Pierre},
  doi          = {10.1007/s00521-025-11161-1},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22941-22965},
  shortjournal = {Neural Comput. Appl.},
  title        = {I-SAMARAH, an incremental constrained clustering applied to remote sensing images},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online forecasting using neighbor-based incremental learning for electricity markets. <em>NCA</em>, <em>37</em>(27), 22923-22940. (<a href='https://doi.org/10.1007/s00521-024-10876-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electricity market forecasting is very useful for the different actors involved in the energy sector to plan both the supply chain and market operation. Nowadays, energy demand data are data coming from smart meters and have to be processed in real-time for more efficient demand management. In addition, electricity prices data can present changes over time such as new patterns and new trends. Therefore, real-time forecasting algorithms for both demand and prices have to adapt and adjust to online data in order to provide timely and accurate responses. This work presents a new algorithm for electricity demand and prices forecasting in real-time. The proposed algorithm generates a prediction model based on the k-nearest neighbors algorithm, which is incrementally updated in an online scenario considering both changes to existing patterns and adding new detected patterns to the model. Both time-frequency and error threshold based model updates have been evaluated. Results using energy demand from 2007 to 2016 and prices data for different time periods from the Spanish electricity market are reported and compared with other benchmark algorithms.},
  archive      = {J_NCA},
  author       = {Melgar-García, L. and Gutiérrez-Avilés, D. and Rubio-Escudero, C. and Troncoso, A.},
  doi          = {10.1007/s00521-024-10876-x},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22923-22940},
  shortjournal = {Neural Comput. Appl.},
  title        = {Online forecasting using neighbor-based incremental learning for electricity markets},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-classification of brain tumors using proposed hybrid quantum–classical integrated neural network (HQCINN) models: Shallow and deep circuit approaches. <em>NCA</em>, <em>37</em>(27), 22891-22922. (<a href='https://doi.org/10.1007/s00521-025-11522-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early detection and accurate classification of brain tumors using MRI scans are crucial for effective diagnosis and treatment planning. However, with the growing patient population and the increasing volume of MRI data, as well as limitations like noise in image data and poor resolution, accurate and rapid diagnosis becomes challenging. To address these issues, AI systems are needed to support radiologists by offering a second opinion. Recent advancements in deep learning (DL) have significantly improved MRI-based brain tumor diagnosis. Despite these improvements, challenges such as the need for higher computational power, difficulty processing large and high-resolution datasets, and limitations of classical vector space. However, quantum computing and quantum computing-based AI methods, by leveraging properties such as superposition and entanglement, have the potential to process data in parallel, handle higher-dimensional data more efficiently, and solve certain problems that classical methods struggle with, more quickly and efficiently. In this study, we proposed four different hybrid quantum–classical integrated neural network (HQCINN) models featuring various multilayer parameterized quantum circuit architectures, which we refer to as “shallow and deep circuits,” designed based on properties such as “entanglement capability, circuit loss, and the number of trainable parameters.” These models aim to distinguish between glioma, meningioma, pituitary and non-tumor classes. The performance of these models was compared to classical DL models, revealing that quantum models provide higher accuracy and lower loss values with fewer parameters. Additionally, when the HQCINN model with the best performance was applied to a brain tumor dataset consisting of CT images, it demonstrated consistent performance across different patient data distributions and imaging modalities, thereby showing strong generalization capability. These results suggest that HQCINN approaches could provide significant advantages in medical imaging tasks, particularly in complex datasets like brain tumor classification.},
  archive      = {J_NCA},
  author       = {Akpinar, Emine and Islam, Sardar M. N. and Oduncuoglu, Murat},
  doi          = {10.1007/s00521-025-11522-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22891-22922},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-classification of brain tumors using proposed hybrid quantum–classical integrated neural network (HQCINN) models: Shallow and deep circuit approaches},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight convolutional neural network based on u shape structure and attention mechanism for anterior mediastinum segmentation. <em>NCA</em>, <em>37</em>(27), 22875-22889. (<a href='https://doi.org/10.1007/s00521-025-11515-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To automatically detect anterior mediastinum lesions (AMLs) in the anterior mediastinum (AM), an automatic segmentation model designed explicitly for AM regions in chest computed tomography (CT) scans is required. Due to the low prevalence of AML, reviewing large CT datasets retrospectively is time-consuming. Developing an artificial intelligence (AI) model to identify the AM region can help radiologists manage workloads and improve diagnostic accuracy. In this paper, we introduce a U-shaped network architecture with two attention mechanisms to maintain long-range dependencies and enhance localization. We propose a parallel multi-head self-attention (MHSA) module called wide-MHSA (W-MHSA), along with a dilated depth-wise parallel path connection (DDWPP) to support upsampling stages. Additionally, an expanding convolution block is combined with W-MHSA in the encoder to ensure a lightweight design. Our proposed model demonstrates superior segmentation performance compared to state-of-the-art networks, showing strong potential for clinical application in AM lesion detection workflows.},
  archive      = {J_NCA},
  author       = {Soleimani-Fard, Sina and Jeong, Won Gi and Ferri Ripalda, Francis and Sasani, Hasti and Choi, Younhee and Deiva, S. and Jin, Gong Yong and Ko, Seok-bum},
  doi          = {10.1007/s00521-025-11515-9},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22875-22889},
  shortjournal = {Neural Comput. Appl.},
  title        = {A lightweight convolutional neural network based on u shape structure and attention mechanism for anterior mediastinum segmentation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Demand forecasting using KAN-RNN. <em>NCA</em>, <em>37</em>(27), 22857-22874. (<a href='https://doi.org/10.1007/s00521-025-11514-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s highly competitive business environment, organizations continuously strive to maintain their competitiveness and achieve sustainable profit margins to support long-term growth and development. Accurate demand forecasting has become a critical tool for decision-makers, as it allows better resource allocation, inventory management, and strategic planning. Recurrent deep learning methods, which use gating mechanisms to maintain an internal state aligned with time series data, are among the most widely used approaches to improve forecast accuracy. Despite their success, these models still exhibit significant untapped potential that could be realized by rethinking the design of their gating mechanisms. To address this, we introduce a novel demand forecasting method inspired by Kolmogorov–Arnold networks (KANs), featuring a modified recurrent architecture with a restructured gating mechanism. This innovation leverages KAN principles to enhance the model’s capacity to capture intricate temporal dependencies and adapt to evolving demand patterns. Experimental evaluations demonstrate that the proposed method outperforms state-of-the-art approaches, highlighting its ability to provide more accurate and reliable demand forecasting results.},
  archive      = {J_NCA},
  author       = {Mejía-Muñoz, Jose-Manuel and Mederos, Boris and Avelar, Liliana and Díaz-Román, José David and Cruz-Mejia, Oliverio},
  doi          = {10.1007/s00521-025-11514-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22857-22874},
  shortjournal = {Neural Comput. Appl.},
  title        = {Demand forecasting using KAN-RNN},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient deep neural unification in symbolic processing. <em>NCA</em>, <em>37</em>(27), 22827-22855. (<a href='https://doi.org/10.1007/s00521-025-11512-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unification is indispensable for inferences in symbolic processing. The authors propose a neural network-based solution to perform efficient unification. Symbolic processing in conventional artificial intelligence has strong inference abilities but is not well suited for handling large amounts of ambiguous data. Contrastingly, neural networks can easily handle large amounts of ambiguous data but are not well suited for making complex inferences. Therefore, the authors realized the unification of the knowledge base, including ambiguous data, using a network that combines a memory network and recurrent neural network. The novelty of the proposed network is that matching, which is a unification process, is highly efficient and substitution, which is a unification process, is robust. The proposed network enables highly efficient matching by grouping multiple terms and processing them in a memory network. Furthermore, it can handle unknown words even during substitution because it uses a recurrent neural network to perform substitution. The experimental results show that the proposed network can achieve more efficient unification of ambiguous data than the baseline. This study combines symbolic processing and deep learning and suggests that it contributes to the realization of complex inferences from large amounts of ambiguous data, which has proven challenging in conventional research. Furthermore, the use of unification, which handles large amounts of ambiguous data, facilitates the development of inference systems with human-interactive interfaces. This allows humans to obtain inference results without knowing the representations of the knowledge base.},
  archive      = {J_NCA},
  author       = {Honda, Hiroshi and Hagiwara, Masafumi},
  doi          = {10.1007/s00521-025-11512-y},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22827-22855},
  shortjournal = {Neural Comput. Appl.},
  title        = {Efficient deep neural unification in symbolic processing},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MB-ViT: MBConv vision transformer with time–frequency feature fusion for bearing fault diagnosis. <em>NCA</em>, <em>37</em>(27), 22801-22825. (<a href='https://doi.org/10.1007/s00521-025-11509-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Roller bearings play a crucial role in mechanical systems, where their operational condition directly impacts system performance and lifespan. However, detecting early-stage bearing faults during routine maintenance remains a challenge due to the cost and technical limitations of current fault diagnosis methods, often resulting in reduced accuracy. To address this issue, this paper proposes a bearing fault diagnosis method based on the MBConv Vision Transformer (MB-ViT) with frequency feature fusion. Specifically, we introduce a novel approach that transforms bearing fault signals into RGB images by combining Continuous Wavelet Transform (CWT) and Gramian Angular Summation Field (GASF) images, thereby enhancing feature representation and improving fault recognition. Additionally, recognizing the limitations of the traditional Vision Transformer (ViT) in capturing local features, we introduce the MB-Multi-Head Self-Attention (MB-MSA) module to overcome this challenge. Experimental results using data from Case Western Reserve University and Xi’an Jiaotong University show that feature fusion significantly improves fault diagnosis accuracy, while the MB-MSA module enhances both diagnostic precision and robustness. MB-ViT achieves an accuracy of 99.90 $$\%$$ in bearing fault diagnosis tasks, demonstrating its superior performance. In summary, the proposed model outperforms existing ViT-based methods, providing a promising solution for bearing fault diagnosis and supporting the advancement of next-generation industrial technologies. The code and data are available at https://github.com/viivan/MB-vit .},
  archive      = {J_NCA},
  author       = {Xiao, Gang and Yao, Junbo and Zhong, Liubing and Xiao, Zhongcheng and Lu, JiaWei},
  doi          = {10.1007/s00521-025-11509-7},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22801-22825},
  shortjournal = {Neural Comput. Appl.},
  title        = {MB-ViT: MBConv vision transformer with time–frequency feature fusion for bearing fault diagnosis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dependency relationship-enhanced graph convolutional network for aspect-based sentiment analysis. <em>NCA</em>, <em>37</em>(27), 22775-22800. (<a href='https://doi.org/10.1007/s00521-025-11508-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis task aims at predicting the sentiment polarity of a specific aspect in a sentence. Recent works have shown that attention-based and syntax-based approaches have gradually become mainstream methods. However, attention-based models may erroneously utilize unrelated context words as cues for prediction in sentences with long-range word dependency information. Besides, methods based on graph neural networks have been applied to model syntactic structure information, although great outcomes have been achieved, these methods are overly dependent on the precision of the syntactical dependency tree, which may lead to suboptimal dependencies between words and thus introduce noise. Effectively incorporating semantic relevance information and syntactic structure information remains a challenging task. To address the shortcomings referred to, we propose the dependency relationship-enhanced graph convolutional network (DREGCN) model, which utilizes a dual channel to integrate semantic relevance information and syntactic structure information. Specifically, in the syntactic channel, we preserve the original dependency tree to obtain global syntactic information, while introducing an aspect-oriented reconstruction tree to capture local syntactic information. Additionally, in contrast to previous studies where context words and aspect words were modeled separately, we propose cosine networks in the semantic channel to enhance information interaction between contexts and aspects. The experimental results show that our DREGCN model has a strong advantage on the three publicly available datasets.},
  archive      = {J_NCA},
  author       = {Tian, Xiaohui and Liu, Fang’ai and Zhuang, Xuqiang and Zhang, Yuling and Gao, Xuejian},
  doi          = {10.1007/s00521-025-11508-8},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22775-22800},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dependency relationship-enhanced graph convolutional network for aspect-based sentiment analysis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UDA-student network and the role of pixel-space relationships in pseudo-label optimization. <em>NCA</em>, <em>37</em>(27), 22755-22773. (<a href='https://doi.org/10.1007/s00521-025-11507-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the expensive and time-consuming nature of obtaining pixel-level annotations for real-world images in semantic segmentation, using readily available synthetic data to train models is practical. This allows the model to adapt to real-world images without needing additional annotations. This process has been explored extensively in the context of Unsupervised Domain Adaptation (UDA). Despite numerous studies proposing novel adaptation strategies, many have largely overlooked the role of the student network and the crucial impact of spatial relationships between pixels on pseudo-label generation. To address pseudo-label noise and enhance the quality of pseudo-labels, three simple yet crucial modification modules are employed: (1) Student Network Reverse-Guiding The Teacher Network: Replace low-confidence pseudo-labels generated by the teacher network at the current position with high-confidence pseudo-labels generated by the student network. (2) Pixel-Space Self-Modification: Leverage the spatial distribution characteristics between pixels by replacing unreliable low-probability labels within a specified range with high-probability labels identified by different categories of pixels within the same range. (3) Small Connected Component Elimination: Identify small connected domains within a specified range that are below a certain threshold and replace the labels within these domains with the label having the highest number of pixels in the surrounding area. In summary, the improvements introduced by these three modules increased the mIoU from GTA to Cityscapes to 76.8 and from Synthia to Cityscapes to 67.9, demonstrating the effectiveness of the proposed modules in enhancing model segmentation performance.},
  archive      = {J_NCA},
  author       = {Zhang, Hao and He, LingMin and Huo, WanLi},
  doi          = {10.1007/s00521-025-11507-9},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22755-22773},
  shortjournal = {Neural Comput. Appl.},
  title        = {UDA-student network and the role of pixel-space relationships in pseudo-label optimization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An ontology-based adaptive tutoring system for learning business english idioms. <em>NCA</em>, <em>37</em>(27), 22725-22753. (<a href='https://doi.org/10.1007/s00521-025-11506-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research presents an intelligent tutoring system (ITS) designed for the adaptive learning of Business English idioms. It addresses the problem of limited personalization and static content delivery in traditional language learning platforms. The objective is to design a hybrid ITS that adapts to individual learner performance, knowledge level, and emotional feedback. The proposed system integrates rule-based classification, ontology-driven knowledge structuring, semantic similarity algorithms, and sentiment analysis using a BERT-based deep learning model. Learners are initially categorized using pre-assessment rules, and idioms are then recommended based on difficulty, domain relevance, and previous learning outcomes. Feedback is analyzed in real time to guide dialogue and content adaptation. The methodology was evaluated through controlled user interaction scenarios. Results indicate a 25% improvement in quiz performance and a 30% increase in learner engagement, compared to a baseline non-adaptive version. Learners received personalized recommendations, adaptive quizzes, and emotionally responsive system messages, improving motivation and retention. However, limitations include the scalability of rule-based logic, difficulties in culturally interpreting idioms, and occasional inaccuracies in sentiment detection. Future work will explore reinforcement learning for dynamic adaptation and multilingual support for broader applicability. In conclusion, the system demonstrates that combining symbolic and deep learning techniques in ITS significantly enhances the learning experience. It offers a replicable model for personalized, intelligent, and emotionally aware instruction in domain-specific language learning.},
  archive      = {J_NCA},
  author       = {Ali, Rehan S. and Abouel-Ela, Magdy and Eldakhly, Nabil M.},
  doi          = {10.1007/s00521-025-11506-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22725-22753},
  shortjournal = {Neural Comput. Appl.},
  title        = {An ontology-based adaptive tutoring system for learning business english idioms},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdversarialGait: Direction invariant gait recognition with adversarial learning. <em>NCA</em>, <em>37</em>(27), 22707-22724. (<a href='https://doi.org/10.1007/s00521-025-11505-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait recognition is an emerging biometric technology that identifies individuals based on their unique walking patterns with gait sequences and variations serving as strong biometric features. Unlike other biometric modalities, it can operate over long distances without requiring active participation from the subjects, thus having wide application in security and surveillance. The performance of gait recognition can be significantly affected by variations such as view angle, posture, clothing and occlusion. Despite the advances in deep learning, these variations still pose a challenge. Specifically, a person’s appearance differs based on walking directions, impacting the accuracy of gait recognition. Existing works primarily address appearance-level variation and do not explicitly suppress the influence of walking direction. We propose a novel approach to remove the influence of walking direction in gait recognition via an adversarial process. We introduce a three module framework—the Feature Extraction Network (FEN), Gait Recognition Network (GRN) and the Direction Estimation Network (DEN). We implement an adversarial training paradigm with walking direction as the adversarial parameter in which we simultaneously train the FEN to enhance recognition capabilities of GRN while hindering DEN’s ability to estimate the walking direction, thus learning direction irrelevant gait recognition features. We train our model on the benchmark datasets, CASIA-B and OU-MVLP. Furthermore, we provide the first experimental demonstration showing that adversarial learning actively avoids direction-related features forming more compact clusters with better inter-class separability while maintaining comparable accuracy to state-of-the-art gait recognition models.},
  archive      = {J_NCA},
  author       = {Raj, Hilton and Vishnuram, A. V. and Raman, Rahul},
  doi          = {10.1007/s00521-025-11505-x},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22707-22724},
  shortjournal = {Neural Comput. Appl.},
  title        = {AdversarialGait: Direction invariant gait recognition with adversarial learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surrogate-assisted evolutionary sampling particle swarm optimization for high-dimensional expensive optimization. <em>NCA</em>, <em>37</em>(27), 22689-22705. (<a href='https://doi.org/10.1007/s00521-023-08661-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted evolutionary algorithms have been widely employed for solving expensive optimization problems. To address high-dimensional expensive optimization problems, we propose an evolutionary sampling-assisted particle swarm optimization method, termed ESPSO. ESPSO consists of some evolutionary sampling-assisted strategies. It first improves the initialized population with some elite samples by evolutionary sampling. Secondly, during the optimization process, the method builds a local radial basis function model using the personal historical optimal data of the population to approximate the objective function landscape. Finally, surrogate-assisted local search and surrogate-assisted trust region search are designed to find promising candidate solutions for replacing individuals in the population to accelerate the search process. Behavioral research experiments of ESPSO verified these strategies have led to improvements in the search efficiency of the algorithm in various aspects, such as initialization, population update, and optimal solution promotion. We compared ESPSO with five state-of-the-art SAEAs using 18 benchmark functions, which show that ESPSO outperforms the other compared SAEAs and get the best average ranking of 2.194.},
  archive      = {J_NCA},
  author       = {Huang, Kuihua and Zhen, Huixiang and Gong, Wenyin and Wang, Rui and Bian, Weiwei},
  doi          = {10.1007/s00521-023-08661-3},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22689-22705},
  shortjournal = {Neural Comput. Appl.},
  title        = {Surrogate-assisted evolutionary sampling particle swarm optimization for high-dimensional expensive optimization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LEM-PSO: A lightweight evolutionary-state-driven multiple information learning particle swarm optimization algorithm. <em>NCA</em>, <em>37</em>(27), 22667-22688. (<a href='https://doi.org/10.1007/s00521-025-11083-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle swarm optimization (PSO) has been widely used, in which each particle selects its learning sample relying on fitness information. Intuitively, fitness-based selection strategy is beneficial to optimization. However, excessive reliance on fitness information may cause premature convergence of the whole population. To solve the defects of PSO, a lightweight evolutionary-state-driven multiple information learning particle swarm optimization algorithm (LEM-PSO) is proposed. In the new proposed LEM-PSO, firstly, a lightweight multiple information learning strategy is proposed. Then, adaptive evolutionary-state adjustment mechanism is proposed. Finally, local optimum warning operation is used to help the stagnant population to jump from local optimums. The comprehensive performance of LEM-PSO is compared with seven popular PSO variants on CEC2013, CEC2017 and two engineering problems, and the results confirm the firmness of LEM-PSO.},
  archive      = {J_NCA},
  author       = {Yang, Xu and Li, Hongru},
  doi          = {10.1007/s00521-025-11083-y},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22667-22688},
  shortjournal = {Neural Comput. Appl.},
  title        = {LEM-PSO: A lightweight evolutionary-state-driven multiple information learning particle swarm optimization algorithm},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A coevolutionary artificial bee colony for training feedforword neural networks. <em>NCA</em>, <em>37</em>(27), 22649-22666. (<a href='https://doi.org/10.1007/s00521-024-10910-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A coevolutionary artificial bee colony (CoABC) trainer based on a hybrid encoding mode is proposed to optimize the network structure and connection weights of a single-hidden layer feedforward network (SLFN). In the proposed CoABC, an integrated population (or colony) with double subpopulations, one of which is responsible for evolution of the network structure encoded as a binary vector, and the other of which is in charge of evolution of the connection weights encoded as a real-number vector, is utilized to coordinate the evolution of two subpopulations. Two types of updating formulas for binary and continuous variables in employed bees phase and onlooker bees phase are developed to enhance the search capability of CoABC. The CoABC can self-organize the structure and weights of a SLFN. In the experiments, 22 benchmark classification datasets are employed to evaluate the proposed CoABC trainer. The results show that the CoABC based on the hybrid encoding mode can train the optimal SLFNs for classification tasks with average test accuracy of 85.12%. Also, the proposed CoABC trainer outperforms original ABC-based trainers and other compared metaheuristic trainers as well as gradient-based trainers. Compared with all other algorithms, the proposed algorithm ranks top 1 in average test accuracy.},
  archive      = {J_NCA},
  author       = {Zhang, Li and Li, Hong and Gao, Weifeng},
  doi          = {10.1007/s00521-024-10910-y},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22649-22666},
  shortjournal = {Neural Comput. Appl.},
  title        = {A coevolutionary artificial bee colony for training feedforword neural networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Software defect prediction based on multi-filter wrapper feature selection and deep neural network with attention mechanism. <em>NCA</em>, <em>37</em>(27), 22621-22648. (<a href='https://doi.org/10.1007/s00521-024-10902-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software defect prediction (SDP) models rely on various software metrics and defect data to identify potential defects in new software modules. However, the performance of these predictive models can be negatively impacted by irrelevant, redundant metrics and the imbalanced nature of defect datasets. Additionally, the previous studies mainly use conventional machine learning (ML) techniques, but their predictive performance is not superior enough. Addressing these issues is crucial to improve the accuracy and effectiveness of SDP models. This study presents a novel approach to SDP using a multi-filter wrapper feature selection technique (MFWFS). To identify a subset of relevant and informative features, we leverage the combination of filter techniques—Information gain (IG), Chi-square (CS), and Relief-F (RF) method, and a wrapper technique—Opposition-Based Whale Optimization Algorithm (OBWOA). One-dimensional-Convolutional Neural Network (CNN) with an attention mechanism is employed to enhance the classification performance of the predictive model by efficiently integrating the selected characteristics into abstract deep semantic features. We undertake experiments on seventeen open-source software datasets on four performance measures—AUC, G-mean, F-measure, and MCC and compare the obtained results with existing state-of-the-art ML and hybrid algorithms. The experimental findings demonstrate the greater efficiency of our approach, highlighting the usefulness of the multi-filter wrapper feature selection technique and 1D-CNN with attention to SDP.},
  archive      = {J_NCA},
  author       = {Malhotra, Ruchika and Chawla, Sonali and Sharma, Anjali},
  doi          = {10.1007/s00521-024-10902-y},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22621-22648},
  shortjournal = {Neural Comput. Appl.},
  title        = {Software defect prediction based on multi-filter wrapper feature selection and deep neural network with attention mechanism},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differential evolution using multi-strategy for the improvement of optimization performance. <em>NCA</em>, <em>37</em>(27), 22593-22620. (<a href='https://doi.org/10.1007/s00521-024-10781-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution (DE) is an effective population-based optimization approach that has been widely used to deal with scientific and engineering problems. However, the performance of DE method is largely dependent on its trial vector produce strategy, namely, mutation strategy, crossover operation and its corresponding control parameters. As claimed by the ‘No free Lunch theorem’, each mutation or crossover strategy has its fatal flaws; hence, the DE method having a single operation strategy cannot solve all types of optimization problems. Therefore, we propose a novel multi-strategy DE (MS-DE) in this study. First, the proposed algorithm uses combined mutation strategies including two powerful mutation strategies and selects them in a probabilistic way. Second, an improved crossover operation is introduced to tackle the stagnation problem. When a stagnation occurs, DE employs the top p-best vector to conduct crossover operation. Third, the control parameters are tuned in novel adaptation schemes. Finally, a local search is utilized in the proposed method to accelerate the convergence. The proposed MS-DE method is examined on CEC2017 test suite, and experiment results confirm its outperformance over several state-of-the-art DE methods. Furthermore, the proposed MS-DE is applied to two constrained engineering problems. The comparison results on these two problems also demonstrate the efficiency of our proposed MS-DE.},
  archive      = {J_NCA},
  author       = {Liu, Nengxian and Luo, Jianbin and Chang, Jie and Pan, Jeng-Shyang},
  doi          = {10.1007/s00521-024-10781-3},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22593-22620},
  shortjournal = {Neural Comput. Appl.},
  title        = {Differential evolution using multi-strategy for the improvement of optimization performance},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lung infection detection and classification using the integration of the improved grasshopper and the remora optimization approaches with improved SVM. <em>NCA</em>, <em>37</em>(27), 22573-22591. (<a href='https://doi.org/10.1007/s00521-024-10624-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infectious lung diseases, such as pneumonia and COVID-19, pose significant threats to global health, with high mortality rates and substantial burdens on healthcare systems. Accurate and timely diagnosis is crucial for effective management and treatment. This study addresses the limitations of existing diagnostic methods by proposing advanced techniques based on computer-aided diagnosis systems and enhanced machine-learning algorithms. The methodology involves the development of novel algorithms for image enhancement, segmentation, feature selection, and classification. A kurtosis-based multi-thresholding grasshopper optimization algorithm is proposed for image segmentation, reducing complexity and enhancing the accuracy of lesion identification. An improved rider optimization algorithm is also introduced for feature selection, aiming to prioritize relevant features and reduce dimensionality effectively. Furthermore, an enhanced support vector machine (SVM) algorithm for lesion classification is presented, utilizing linear mapping to generate feature scores for regions of interest. This facilitates the evaluation of the loss function and improves classification results. The approach’s effectiveness is demonstrated using datasets comprising chest X-ray and CT scan images from the LIDC-IDRI and Montgomery datasets. The improved optimization algorithms were trained and tested over the chest X-ray and CT scan image datasets. An improved SVM classified the lesions with an accuracy of 99.9% for chest X-ray images and 99.8% for CT scan images. The results proved that the improved SVM adequately classifies lung diseases from the chest X-ray and CT scan images. The findings suggest that the proposed methodologies significantly enhance the accuracy and efficiency of diagnosing pneumonia and COVID-19 from medical images. By addressing the limitations of existing diagnostic techniques, this research contributes to improving healthcare practices and ultimately reducing the burden of infectious lung diseases on a global scale.},
  archive      = {J_NCA},
  author       = {Bhimavarapu, Usharani},
  doi          = {10.1007/s00521-024-10624-1},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22573-22591},
  shortjournal = {Neural Comput. Appl.},
  title        = {Lung infection detection and classification using the integration of the improved grasshopper and the remora optimization approaches with improved SVM},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial hummingbird algorithm with chaotic-opposition-based population initialization for solving real-world problems. <em>NCA</em>, <em>37</em>(27), 22529-22572. (<a href='https://doi.org/10.1007/s00521-024-10621-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The artificial hummingbird algorithm is a global search mechanism with many applications in engineering design, but it tends to stall in high-dimensional problems with locally optimal solutions. To address this issue, this paper enhances an artificial hummingbird algorithm by using a chaos map and opposition-based method for population initialization to combat the lack of population diversity, the imbalance between exploration and exploitation, and the algorithm’s premature convergence. The randomness of chaos maps has been leveraged to prevent solutions trapped in local optima and facilitate faster convergence. Moreover, an opposition-based population can serve as a better initial solution and accelerate convergence when compared to random initialization. Two numerical test suites are used to evaluate the efficacy of the proposed algorithm: 50 benchmark functions and the CEC 2018 benchmark test suite. The outcomes are compared to eight other cutting-edge metaheuristic algorithms. Wilcoxon rank sum test, Friedman test, and mean absolute error are used to conduct additional statistical analysis on the data. Moreover, experiments are conducted on the aforementioned 57 real-world optimization problems to demonstrate the efficacy of the proposed method. The outcomes are contrasted to the algorithms SASS, MAgES, EnMODE, and COLSHADE (which won the CEC2020 Competition on Real-World Single-Objective Constrained Optimization). All quantitative and qualitative results on benchmark functions, statistical tests, as well as real-world optimization problem results demonstrate that the proposed algorithm is competitive and preferable to the metaheuristics considered in the experiments. Hence it is concluded that the proposed algorithm balances exploration and exploitation more effectively and the population initialization technique is conducive to augmenting the search capabilities of the artificial hummingbird algorithm.},
  archive      = {J_NCA},
  author       = {Kaur, Sumandeep and Kaur, Lakhwinder and Lal, Madan},
  doi          = {10.1007/s00521-024-10621-4},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22529-22572},
  shortjournal = {Neural Comput. Appl.},
  title        = {Artificial hummingbird algorithm with chaotic-opposition-based population initialization for solving real-world problems},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning at the service of metaheuristics for solving numerical optimization problems. <em>NCA</em>, <em>37</em>(27), 22493-22528. (<a href='https://doi.org/10.1007/s00521-024-10610-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating deep learning methods into metaheuristic algorithms has gained attention for addressing design-related issues and enhancing performance. The primary objective is to improve solution quality and convergence speed within solution search spaces. This study investigates the use of deep learning methods as a generative model to learn historical content, including global best and worst solutions, solution sequences, function evaluation patterns, solution space characteristics, population modification trajectories, and movement between local and global search processes. An LSTM-based architecture is trained on dynamic optimization data collected during the metaheuristic optimization process. The trained model generates an initial solution space and is integrated into the optimization algorithms to intelligently monitor the search process during exploration and exploitation phases. The proposed deep learning-based methods are evaluated on 55 benchmark functions of varying complexities, including CEC 2017 and compared with 13 biology-based, evolution-based, and swarm-based metaheuristic algorithms. Experimental results demonstrate that all the deep learning-based optimization algorithms achieve high-quality solutions, faster convergence rates, and significant performance improvements. These findings highlight the critical role of deep learning in addressing design issues, enhancing solution quality, trajectory, and performance speed in metaheuristic algorithms.},
  archive      = {J_NCA},
  author       = {Oyelade, Olaide N. and Ezugwu, Absalom E. and Saha, Apu K. and Thieu, Nguyen V. and Gandomi, Amir H.},
  doi          = {10.1007/s00521-024-10610-7},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22493-22528},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning at the service of metaheuristics for solving numerical optimization problems},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). M2M-net: Multi-objective neural architecture search using dynamic M2M population decomposition. <em>NCA</em>, <em>37</em>(27), 22473-22491. (<a href='https://doi.org/10.1007/s00521-024-10595-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multi-objective neural architecture search (MO-NAS) is an efficient solution for automating the design of deep neural network architectures, aiming to explore a diverse range of objectives. However, the sensitivity of objectives in MO-NAS varies over generations, leading to a search imbalance, and local search plays a crucial role in this combinatorial optimization problem with a discrete search space. In this paper, we propose M2M-Net, a dynamic self-adaptive (Multi-objective to Multi-objective) M2M population decomposition-based evolutionary algorithm for NAS. M2M-Net leverages dynamic self-adaptive M2M population decomposition to overcome the search imbalance in MO-NAS. The subpopulation-based search within M2M-Net facilitates local search through crossover and mutation. Additionally, M2M-Net incorporates a proxy model to reduce computational cost in architecture evaluation and utilizes the channel attention mechanism to improve the accuracy of proxy model evaluation. Experimental studies on CIFAR-10 and CIFAR-100 datasets validate the effectiveness and efficiency of M2M-Net. Comparisons and analysis demonstrate that M2M-Net achieves comparable performance to state-of-the-art NAS methods while utilizing fewer computational resources.},
  archive      = {J_NCA},
  author       = {Tan, Zhiwen and Guo, Daqi and Chen, Junan and Chen, Lei},
  doi          = {10.1007/s00521-024-10595-3},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22473-22491},
  shortjournal = {Neural Comput. Appl.},
  title        = {M2M-net: Multi-objective neural architecture search using dynamic M2M population decomposition},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid algorithm considering continuous transportation for flexible job shop scheduling problem with finite transportation resources. <em>NCA</em>, <em>37</em>(27), 22451-22471. (<a href='https://doi.org/10.1007/s00521-024-10580-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional flexible job shop scheduling ignores transportation or considers production and transportation separately. With factory digitalization and the widespread use of automated guided vehicles (AGVs), the isolated scheduling of production and transportation is no longer sufficient to meet increased productivity demands. Thus, integrated scheduling has become an inevitable option. Previous research has not sufficiently explored the domain knowledge of flexible job shop scheduling problem with finite transportation resources (FJSP-T), and thus the optimal solution cannot be found in an acceptable time using meta-heuristic algorithms. This paper explores FJSP-T to enhance the efficiency of the entire production system, and the objective is to minimize the makespan. The transportation situations of FJSP-T are analyzed, and it has been identified that the key to solving the problem is considering continuous transportation of AGVs. Further, the active decoding method and the initialization method considering continuous transportation are designed. A hybrid algorithm (HA) is proposed, which incorporates local search into the genetic algorithm, and various neighborhood structures for local search are designed. Finally, the superiority of the active decoding method is proved experimentally, and the algorithm performance is tested on two sets of famous benchmark instances (including 67 instances). Compared with other state-of-the-art reported algorithms, the proposed method obtains the new best solutions for 6 instances, and all solutions are not lower than previous results. Meanwhile, the computational time is only a few seconds. As a result, the proposed HA has significantly improved in solving FJSP-T regardless of the solution accuracy and the computational time.},
  archive      = {J_NCA},
  author       = {Wang, Qingzheng and Gao, Liang and Yu, Yanbin and Xiang, Zhimou and Yao, Youjie and Li, Xinyu and Zhou, Wei},
  doi          = {10.1007/s00521-024-10580-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22451-22471},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid algorithm considering continuous transportation for flexible job shop scheduling problem with finite transportation resources},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Empowering white shark optimizer for dimensionality reduction with case study of apple disease prediction. <em>NCA</em>, <em>37</em>(27), 22421-22449. (<a href='https://doi.org/10.1007/s00521-024-10577-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) plays a crucial role in developing classification models by reducing the number of features used while improving their predictive power. It is a challenging problem that can be viewed as an NP-hard optimization task. To tackle this problem, powerful wrapper-based metaheuristic algorithms are employed, as they have the ability to search for nearly optimal feature subsets in the vast search space. However, these algorithms often face challenges such as getting trapped in local optima and striking a balance between exploration and exploitation. To address these challenges, this study proposes an improved version of the white shark optimizer (WSO) called the improved WSO (IWSO). The IWSO incorporates two efficient strategies, namely opposition-based learning (OBL) and Gaussian mutation (GM), to overcome the limitations of the original method. OBL enhances exploration by considering opposite solutions, while GM prevents premature convergence and improves the exploitation capabilities of the algorithm. The effectiveness of the proposed IWSO is evaluated using various benchmark datasets and assessed using standard evaluation metrics. The results of the experiments demonstrate that the IWSO is capable of discovering new optimal solutions across different test cases. Furthermore, the proposed algorithm is applied to a real-world problem involving the identification of apple diseases, further validating its effectiveness.},
  archive      = {J_NCA},
  author       = {Sami, Aya and Barakat, Sherif I. and Mostafa, Reham R.},
  doi          = {10.1007/s00521-024-10577-5},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22421-22449},
  shortjournal = {Neural Comput. Appl.},
  title        = {Empowering white shark optimizer for dimensionality reduction with case study of apple disease prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A parallel hybrid approach integrating clonal selection with artificial bee colony for logistic regression in spam email detection. <em>NCA</em>, <em>37</em>(27), 22401-22419. (<a href='https://doi.org/10.1007/s00521-024-10505-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spam emails are sent to recipients for advertisement and phishing purposes. In either case, it disturbs recipients and reduces communication quality. Addressing this issue requires classifying emails on servers as either spam or ham. Numerous methods have been proposed for this classification task. Among them, logistic regression (LR) stands out for its simplicity, speed, and ease of implementation. However, LR suffers from low detection rates caused by the gradient descent algorithm used in its training phase. To overcome this limitation, we propose a novel method based on the clonal selection algorithm (CSA), renowned for its success in optimization problems due to its local and global search capabilities. Despite CSA’s effective optimization performance, it suffers from robustness and slow training time. Therefore, the CSA and artificial bee colony (ABC) algorithms are hybridized to improve CSA’s robustness and are parallelized to reduce the training time significantly. This hybrid method is employed to optimize the weights of LR by minimizing the cost at the output of LR. The empirical results denote that the proposed method, named CSA–ABC–LR, yields better classification performance compared to state-of-the-art models reported by previous studies, demonstrating an accuracy rate of 99.13% on the Enron-1 dataset, 99.22% on the CSDMC2010 dataset, and 94.49% on the Spambase dataset.},
  archive      = {J_NCA},
  author       = {Dedeturk, Bilge Kagan and Akay, Bahriye},
  doi          = {10.1007/s00521-024-10505-7},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22401-22419},
  shortjournal = {Neural Comput. Appl.},
  title        = {A parallel hybrid approach integrating clonal selection with artificial bee colony for logistic regression in spam email detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An evolutionary swarm intelligence optimizer based on probabilistic distribution. <em>NCA</em>, <em>37</em>(27), 22387-22399. (<a href='https://doi.org/10.1007/s00521-023-09299-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a novel approach to balance exploitation and exploration. The proposed approach is the Evolutionary Swarm Intelligence (ESI) optimizer, which combines an exploration-biased strategy with an exploitation-biased operator. The algorithm is built based on the collective behavior of biological groups, imitating their intelligence behavior. The biological evolutionary process, inspired by genetic algorithms, is applied to every individual in the algorithm. Both swarm intelligence and genetic algorithms have been widely used in practical problems, and their reliability has been proven. ESI is characterized by both spatial group intelligence behavior and temporal biological evolution. To test the performance of ESI, we used a classic test set from IEEE CEC2017 and 22 practical problems from IEEE CEC2011. The popular training tests of the dendritic neuron model were also included in the control trials. We compared ESI with some typical swarm intelligence algorithms and classic algorithms to evaluate its performance and ability to solve practical problems. The experimental results show that ESI outperforms other algorithms in terms of basic performance and the ability to solve practical problems.},
  archive      = {J_NCA},
  author       = {Yang, Yifei and Yang, Haichuan and Li, Haotian and Tang, Zheng and Gao, Shangce},
  doi          = {10.1007/s00521-023-09299-x},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22387-22399},
  shortjournal = {Neural Comput. Appl.},
  title        = {An evolutionary swarm intelligence optimizer based on probabilistic distribution},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive grey wolf optimization with differential evolution operator for solving the discount {0–1} knapsack problem. <em>NCA</em>, <em>37</em>(27), 22369-22385. (<a href='https://doi.org/10.1007/s00521-023-09075-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discount {0–1} knapsack problem (D {0–1} KP) is a new variant of the knapsack problem. It is an NP-hard problem and also a binary optimization problem. As a new intelligent algorithm that imitates the leadership function of wolves, the grey wolf optimizer (GWO) can solve NP problems more effectively than accurate algorithms. At the same time, the GWO has fewer parameters, faster calculations, and easier implementation than other intelligent algorithms. This paper introduces a method of adaptively updating the prey position of wolves and a differential evolution operator with a scaling factor that adaptively changes according to the number of iterations, and selects which operator to use for iteration by the value of the search agent parameter. Finally, it combines the improved greedy repair operator based on D {0–1} KP to form the adaptive grey wolf optimization with differential evolution operator (de-AGWO). The experimental results of the standard test function prove that the algorithm in this paper has a significant improvement in function optimization performance. And the experimental results of D {0–1} KP shows that the proposed algorithm yields superior solution outcomes, except for unrelated datasets, and exhibits significant advantages when solving strongly correlated datasets. Finally, it is verified that more than 80% of the iterations utilize the grey wolf evolution operator, highlighting that the core of the algorithm remains the GWO.},
  archive      = {J_NCA},
  author       = {Wang, Zijian and Fang, Xi and Gao, Fei and Xie, Liang and Meng, Xianchen},
  doi          = {10.1007/s00521-023-09075-x},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22369-22385},
  shortjournal = {Neural Comput. Appl.},
  title        = {An adaptive grey wolf optimization with differential evolution operator for solving the discount {0–1} knapsack problem},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UAV path planning in mountain areas based on a hybrid parallel compact arithmetic optimization algorithm. <em>NCA</em>, <em>37</em>(27), 22353-22368. (<a href='https://doi.org/10.1007/s00521-023-08983-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) path planning is one of the core components of its entire autonomous control system. The main challenge lies in efficiently obtaining an optimal flight route in complex environments, especially in mountain areas. To address this, we propose a novel version of arithmetic optimization algorithm (AOA), named parallel and compact AOA (PCAOA). In PCAOA, the compact technique can save the memory of UAV and shorten the calculation time, and the parallel technique can quicken the convergence speed and improve the solution accuracy. In addition, the flight path generated by PCAOA is smoothed with cubic B-spline curves, making the path suitable for a UAV. The performance of PCAOA is demonstrated on 23 benchmark functions. Experimental results show that PCAOA achieves competitive results. Finally, the simulation studies are conducted to verify that PCAOA can successfully acquire a feasible and effective route in different mountain areas.},
  archive      = {J_NCA},
  author       = {Wang, Ruo-Bin and Wang, Wei-Feng and Geng, Fang-Dong and Pan, Jeng-Shyang and Chu, Shu-Chuan and Xu, Lin},
  doi          = {10.1007/s00521-023-08983-2},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22353-22368},
  shortjournal = {Neural Comput. Appl.},
  title        = {UAV path planning in mountain areas based on a hybrid parallel compact arithmetic optimization algorithm},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A modified whale optimization algorithm with multi-strategy mechanism for global optimization problems. <em>NCA</em>, <em>37</em>(27), 22339-22352. (<a href='https://doi.org/10.1007/s00521-023-08287-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whale Optimization Algorithm (WOA) is an outstanding nature-inspired algorithm widely used to solve many complex engineering optimization problems. However, WOA has a poor balance in exploration and exploitation, which converges to local optimum easily. This article proposes a Modified Whale Optimization Algorithm (MWOA) with multi-strategy mechanism, which introduces the elite reverse learning strategy, nonlinear convergence factor, DE/rand/1 mutation strategy and Lévy flight disturbance strategy. MWOA can improve the convergent ability and maintain the balance of exploitation and exploration to avoid local optimum. Compared with WOA, PSO, MFO, SOA, SCA and other four WOA variants on the CEC2017 benchmark suite, MWOA has strong competitiveness and can better improve the efficiency of WOA according to the experimental results and analysis.},
  archive      = {J_NCA},
  author       = {Li, Mingyuan and Yu, Xiaobing and Fu, Bingbing and Wang, Xuming},
  doi          = {10.1007/s00521-023-08287-5},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {22339-22352},
  shortjournal = {Neural Comput. Appl.},
  title        = {A modified whale optimization algorithm with multi-strategy mechanism for global optimization problems},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-shot policy explanation to improve task performance via semantic reward coaching. <em>NCA</em>, <em>37</em>(26), 22315-22337. (<a href='https://doi.org/10.1007/s00521-025-11477-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication is crucial for synchronizing expectations and knowledge within teams. For robots to effectively collaborate with or provide actionable decision-support or coaching to humans, it is critical that they be able to generate intelligible explanations to reconcile differences between their understanding of the world and that of their collaborators. In this work we present Single-shot Policy Elicitation for Augmenting Rewards (SPEAR), a novel sequential optimization algorithm that uses semantic explanations derived from combinations of planning predicates to augment human agents’ reward functions, driving their policies to exhibit more optimal behavior by modeling humans as reinforcement learning (RL) agents and reconciling disparities in their reward function. We present an experimental validation of the policy manipulation capabilities of SPEAR in a practically grounded application and a performance analysis of SPEAR across a suite of domains with increasingly complex state spaces and predicate counts. SPEAR demonstrates substantial improvements in runtime and addressable problem size, enabling an expert agent to leverage its own expertise to communicate actionable information to improve human performance. Through a series of human subjects studies, we demonstrate SPEAR’s potential to improve human policies and reduce cognitive load, all while enhancing interpretability, task awareness, and promoting active thinking patterns among users. Finally, we apply SPEAR in a robot-to-robot policy manipulation scenario, showcasing its applicability in robot-robot collaborations.},
  archive      = {J_NCA},
  author       = {Tabrez, Aaquib and Leonard, Ryan and Hayes, Bradley},
  doi          = {10.1007/s00521-025-11477-y},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {22315-22337},
  shortjournal = {Neural Comput. Appl.},
  title        = {Single-shot policy explanation to improve task performance via semantic reward coaching},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting early ASD traits of adults and toddlers using machine learning and deep learning with explainable AI and optimization. <em>NCA</em>, <em>37</em>(26), 22287-22314. (<a href='https://doi.org/10.1007/s00521-025-11064-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism spectrum disorder (ASD) is a complex neurodevelopmental condition characterized by challenges in social interaction, communication difficulties, repetitive behaviors, and a range of strengths and differences in cognitive abilities. Early ASD diagnosis using machine learning and deep learning techniques is crucial for preventing its severity and long-term effects. The articles published in this area have only applied different machine learning algorithms, and a notable gap observed is the absence of an in-depth analysis in terms of hyperparameter tuning and the type of dataset used in this context. This study investigated predictive modeling for ASD traits by leveraging two distinct datasets: (i) a raw CSV dataset with tabular data and (ii) an image dataset with facial expression. This study aims to conduct an in-depth analysis of ASD trait prediction in adults and toddlers by doing hyper optimized and interpreting the result through explainable AI. In the CSV dataset, a comprehensive exploration of machine learning and deep learning algorithms, including decision trees, Naive Bayes, random forests, support vector machines (SVM), k-nearest neighbors (KNN), logistic regression, XGBoost, and ANN, was conducted. XGBoost emerged as the most effective machine learning algorithm, achieving an accuracy of 96.13%. The deep learning ANN model outperformed the traditional machine learning algorithms with an accuracy of 99%. Additionally, an ensemble model combining a decision tree, random forest, SVM, KNN, and logistic regression demonstrated superior performance, yielding an accuracy of 96.67%. The XGBoost model, utilized in hyperparameter optimization for CSV data, exhibited a substantial accuracy increase, reaching 98%. For the image dataset, advanced deep learning models, such as ResNet50, VGG16, Boosting, and Bagging, were employed. The bagging model outperformed the others, achieving an impressive accuracy of 99%. Subsequent hyperparameter optimization was conducted on both the CSV and image datasets. Similarly, the boosting model for the image dataset achieved remarkable 100% accuracy post-tuning. As a further contribution, explainable AI has been incorporated into the study through SHAP (Shapley Additive exPlanations) analysis, providing insights into feature importance for both image and CSV data.},
  archive      = {J_NCA},
  author       = {Rahman, Md. Ashiqur and Hossain, Md. Mamun and Singh, Sondip Poul and Sharmin, Nusrat},
  doi          = {10.1007/s00521-025-11064-1},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {22287-22314},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predicting early ASD traits of adults and toddlers using machine learning and deep learning with explainable AI and optimization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Experiential explanations for reinforcement learning. <em>NCA</em>, <em>37</em>(26), 22255-22285. (<a href='https://doi.org/10.1007/s00521-024-10951-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) systems can be complex and non-interpretable, making it challenging for non-AI experts to understand or intervene in their decisions. This is due in part to the sequential nature of RL in which actions are chosen because of their likelihood of obtaining future rewards. However, RL agents discard the qualitative features of their training, making it difficult to recover user-understandable information for “why” an action is chosen. We propose a technique Experiential Explanations to generate counterfactual explanations by training influence predictors along with the RL policy. Influence predictors are models that learn how different sources of reward affect the agent in different states, thus restoring information about how the policy reflects the environment. Two human evaluation studies revealed that participants presented with Experiential Explanations were better able to correctly guess what an agent would do than those presented with other standard types of explanation. Participants also found that Experiential Explanations are more understandable, satisfying, complete, useful, and accurate. Qualitative analysis provides information on the factors of Experiential Explanations that are most useful and the desired characteristics that participants seek from the explanations.},
  archive      = {J_NCA},
  author       = {Alabdulkarim, Amal and Singh, Madhuri and Mansi, Gennie and Hall, Kaely and Ehsan, Upol and Riedl, Mark O.},
  doi          = {10.1007/s00521-024-10951-3},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {22255-22285},
  shortjournal = {Neural Comput. Appl.},
  title        = {Experiential explanations for reinforcement learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Survey on deep learning in multimodal medical imaging for cancer detection. <em>NCA</em>, <em>37</em>(26), 22239-22254. (<a href='https://doi.org/10.1007/s00521-023-09214-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of multimodal cancer detection is to determine the locations and categories of lesions by using different imaging techniques, which is one of the key research methods for cancer diagnosis. Recently, deep learning-based object detection has made significant developments due to its strength in semantic feature extraction and nonlinear function fitting. However, multimodal cancer detection remains challenging due to morphological differences in lesions, interpatient variability, difficulty in annotation, and imaging artifacts. In this survey, we mainly investigate over 150 papers in recent years with respect to multimodal cancer detection using deep learning, with a focus on datasets and solutions to various challenges such as data annotation, variance between classes, small-scale lesions, and occlusion. We also provide an overview of the advantages and drawbacks of each approach. Finally, we discuss the current scope of work and provide directions for the future development of multimodal cancer detection.},
  archive      = {J_NCA},
  author       = {Tian, Yan and Xu, Zhaocheng and Ma, Yujun and Ding, Weiping and Wang, Ruili and Gao, Zhihong and Cheng, Guohua and He, Linyang and Zhao, Xuran},
  doi          = {10.1007/s00521-023-09214-4},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {22239-22254},
  shortjournal = {Neural Comput. Appl.},
  title        = {Survey on deep learning in multimodal medical imaging for cancer detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterization of the algae growth on the RTV-coated insulator surface based on the corrosion expansion and the image segmentation algorithm. <em>NCA</em>, <em>37</em>(26), 22229-22238. (<a href='https://doi.org/10.1007/s00521-024-10728-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image recognition technology for RTV (room temperature vulcanized)-coated silicone rubber insulators with algae fouling is gradually gaining popularity due to time-consuming and laborious nature of manual inspection. However, there is still an issue with the accuracy of image recognition. In this paper, a corrosion and expansion algorithm is applied for digital image processing to accurately characterize algae growth on silicone rubber insulator surfaces. After pre-processing, two common indexes are used: EXG (excess green index) and HVI (hague vegetation index). The effect of image segmentation is studied, and then the characteristic green value is used to measure algae greenness. The method for measuring algae cell density is also described. By calculating the characteristic green value of collected insulator images, the corresponding algae cell density is determined, and the algae growth degree is characterized along with the algae coverage rate. Therefore, the erosion and dilation algorithm is an essential part of image pre-processing. Based on the above work, the relationship curve between the characteristic green value and algae cell density is accurately obtained. The research results are of great significance for characterization of algae pollution on insulator surfaces using image methods.},
  archive      = {J_NCA},
  author       = {Yang, Shifang and Zhang, Zexuan and Chen, Tianyu and Liu, Yunpeng and Jia, Zhidong and Xie, Jun},
  doi          = {10.1007/s00521-024-10728-8},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {22229-22238},
  shortjournal = {Neural Comput. Appl.},
  title        = {Characterization of the algae growth on the RTV-coated insulator surface based on the corrosion expansion and the image segmentation algorithm},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incorporating prior knowledge for domain generalization traffic flow anomaly detection. <em>NCA</em>, <em>37</em>(26), 22215-22228. (<a href='https://doi.org/10.1007/s00521-024-10632-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow anomaly detection is crucial for traffic management and reducing adverse impacts. However, due to the lack of labeled information for anomaly events and the highly complex nature of road networks, practitioners find it difficult to detect anomaly information. Currently, many anomaly detection methods perform well when there is no statistical difference between training and testing data (same road), ignoring the unique traffic patterns of different road and the dependency on prior knowledge, which are difficult to dynamically adapt to the detection model. In order to effectively integrate prior knowledge and generalize this knowledge to different road for anomaly detection, we use domain-specific prior knowledge as the initial weights of convolutional kernels, fine-tuning the convolutional kernel weights using classification loss, allowing prior knowledge to adapt to extracting anomaly features. To further increase the generalization capability of features, we perturb the extracted features with Gaussian noise specific to the direction of the abnormal class during training, enabling the anomaly detection classifier to have domain generalization performance across roads with different traffic patterns. We compare the proposed model with six baseline methods on real and synthetic datasets. The results demonstrate that the proposed model can effectively detect anomalies and outperforms the baseline methods.},
  archive      = {J_NCA},
  author       = {Chen, Bo and Fang, Min and Wei, HaoJie},
  doi          = {10.1007/s00521-024-10632-1},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {22215-22228},
  shortjournal = {Neural Comput. Appl.},
  title        = {Incorporating prior knowledge for domain generalization traffic flow anomaly detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Behaviour-based trust assessment for the internet of things systems using multi-classifier ensemble learning and Dempster–Shafer fusion. <em>NCA</em>, <em>37</em>(26), 22191-22214. (<a href='https://doi.org/10.1007/s00521-025-11273-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid proliferation of the Internet of Things (IoT), robust trust management has become imperative to ensure security in these IoT systems. Prior machine learning approaches to IoT trust management have exhibited suboptimal performance, failing to capture the dynamic behaviour and complex discriminative features of IoT devices. To address these challenges, we design an evocative trust management scheme for user’s authentication based on Dempster–Shafer’s evidence theory, which can persuade the normal activities of IoT device systems. We establish a set of discriminating features to predict the trustworthiness of a network node by assessing its observed behaviours. These behaviours being assessed encompass several characteristics such as throughput, delay, jitter and network latency. As such, nodes that demonstrate elevated data transmission rates and have anomalous traffic patterns could potentially be categorised as untrustworthy. In addition, the existence of persistently high latency will impede trust prediction algorithms, and this will consequently alter the overall behaviour of the node, ultimately affecting the trustworthiness of the entire network. We also design a framework for the fusion of evidence based on the belief degree and reputation-based evidence to avoid misclassification resulting in evidence conflicting. The resultant fusion outcomes are transformed into category labels which serve as the prediction outcome of the multi-classifier ensemble scheme. We evaluate our proposed scheme with and without the best discriminative features on performance metrics including accuracy, precision, recall, F1-score, detection rate and false alarm rate. Comprehensive experiments on a transformed UNSW-NB15 dataset demonstrate the better performance of our proposed framework, especially in the application of evidence conflicting.},
  archive      = {J_NCA},
  author       = {Aaqib, Muhammad and Ali, Aftab and Chen, Liming and Nibouche, Omar},
  doi          = {10.1007/s00521-025-11273-8},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {22191-22214},
  shortjournal = {Neural Comput. Appl.},
  title        = {Behaviour-based trust assessment for the internet of things systems using multi-classifier ensemble learning and Dempster–Shafer fusion},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WLAN: Water leakage-aware network for water leakage identification in metro tunnels. <em>NCA</em>, <em>37</em>(26), 22179-22189. (<a href='https://doi.org/10.1007/s00521-024-10564-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the environmental factors, tunnel linings often experience water leakage, which affects the structural safety and shorten the operation life of the tunnel. While some computer vision-based studies aim to replace manual inspections, they still encounter challenges such as limited segmentation accuracy. In this study, we introduce a Water Leakage-Aware Network (WLAN) for tunnel defects inspection, enhancing the accuracy of water leakage segmentation and mitigating estimation errors in the predicted area. Two novel modules, the Attention-Guided Feature Fusion (AGFF) and the Auxiliary Boundary Awareness (ABA), are devised to provide supplementary information for segmentation masks and improve network perception of water leakage boundaries, respectively. Experimental evaluations showcase that WLAN outperforms existing approaches, establishing a new state-of-the-art standard in tunnel water leakage segmentation.},
  archive      = {J_NCA},
  author       = {Wang, Yuliang and Huang, Kai and Sun, Lei and Gao, Jianwei and Guo, Zhiwei and Chen, Xiaohan},
  doi          = {10.1007/s00521-024-10564-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {22179-22189},
  shortjournal = {Neural Comput. Appl.},
  title        = {WLAN: Water leakage-aware network for water leakage identification in metro tunnels},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RSMA-assisted SHAPTINs: Secrecy performance under imperfect hardware and channel estimation errors. <em>NCA</em>, <em>37</em>(26), 22161-22178. (<a href='https://doi.org/10.1007/s00521-024-10526-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Satellite high aerial platform terrestrial integrated networks have become the hot topic these years, which have been regarded as the major part of the intelligence of things for future networks. During this work, we investigate the secrecy performance for rate-splitting multiple access-assisted satellite high aerial platform terrestrial integrated networks. Besides, imperfect hardware and channel estimation errors are considered in the secrecy networks. Moreover, to enhance the energy utilization efficiency, rate-splitting multiple access scheme is utilized into the considered network, which is prior to that of the non-orthogonal multiple access scheme. What's more, to enhance the satellite transmission, multiple high aerial platforms are used to forward the transmission along with multiple eavesdroppers. In addition, the direct transmission link is not considered in the secrecy networks due to the heavy fading and obstacles. Relied on the former considerations, the exact and asymptotic analysis for the secrecy performance is further obtained to confirm the rightness of the analysis. Finally, some representative Monte Carlo simulations are carried out to validate the obtained results.},
  archive      = {J_NCA},
  author       = {Feng, Zhou and Kefeng, Guo and Jian, Cheng and Sunder Ali, Khowaja and Kapal, Dev and Reddy, Gadekallu Thippa and Hussam Al, Hamadi},
  doi          = {10.1007/s00521-024-10526-2},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {22161-22178},
  shortjournal = {Neural Comput. Appl.},
  title        = {RSMA-assisted SHAPTINs: Secrecy performance under imperfect hardware and channel estimation errors},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient deep learning model for early disease detection in vegetable crops. <em>NCA</em>, <em>37</em>(26), 22141-22160. (<a href='https://doi.org/10.1007/s00521-025-11179-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plant diseases significantly threaten global food security and economic stability by reducing crop yields, increasing production costs, and exacerbating food shortages. Early and precise detection of plant diseases is essential for mitigating these risks. This study introduces a lightweight deep learning model for early and efficient disease detection in key vegetable crops, including eggplant, potato, tomato, and soybean. The model leverages a comprehensive dataset containing 23 classes of healthy and diseased plant images. With only 388,055 parameters and a model size of 1.48 MB, it achieves an impressive accuracy of 92.75%, outperforming 17 state-of-the-art deep learning models in terms of performance, efficiency, and size. The novelty lies in the model’s compact architecture, making it highly suitable for deployment in resource-constrained environments such as mobile and edge devices. The primary objective is to provide a scalable and cost-effective solution for early disease detection to enhance agricultural productivity. The findings underscore the model’s superiority over traditional methods and emphasize its potential for real-world applications in smart and sustainable agriculture systems.},
  archive      = {J_NCA},
  author       = {Bhola, Amit and Kumar, Prabhat},
  doi          = {10.1007/s00521-025-11179-5},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {22141-22160},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient deep learning model for early disease detection in vegetable crops},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PreSA: An intelligent blockchain-based platform for monitoring and predicting water quality for smart aquaculture. <em>NCA</em>, <em>37</em>(26), 22129-22140. (<a href='https://doi.org/10.1007/s00521-024-10877-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Water quality is an important factor for the survival of most living things, such as the production process of intensive aquaculture systems. In addition, it is crucial to protect fishes from any possible catastrophe caused by pollution. In this context, it is essential to monitor, control and predict water quality to have high-quality fish farming water. In this research, machine learning (ML) and blockchain technologies offer efficient and dependable solution for smart aquaculture providing greater control, management and security. In this paper, we proposed using ML and blockchain to develop an intelligent platform collecting and predicting water pollution using trophic index (TRIX). TRIX index is a metric for assessing the trophic state of an aquatic ecosystem and understanding ecological health. Autoregressive integrated moving average (ARIMA), random forest (RF) and K-nearest neighbor (KNN) models were used to predict TRIX and to help control centers for quick decision-making and real-time interventions. Different evaluation metrics have been used to identify the best ML model. Blockchain is used to secure data and ensure alerts traceability. The evaluation confirms that RF model provides better accuracy compared to other ML models. So, this study provides a secure water quality prediction system to early detect pollution and improve water quality in aquaculture environment.},
  archive      = {J_NCA},
  author       = {Hachicha, Marwa and Ben Halima, Riadh and Frikha, Tarek},
  doi          = {10.1007/s00521-024-10877-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {22129-22140},
  shortjournal = {Neural Comput. Appl.},
  title        = {PreSA: An intelligent blockchain-based platform for monitoring and predicting water quality for smart aquaculture},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal forecasting of plant height and canopy diameter from RGB images using a CNN-based regression model for ornamental pepper plants (Capsicum spp.) growing under high-temperature stress. <em>NCA</em>, <em>37</em>(26), 22107-22128. (<a href='https://doi.org/10.1007/s00521-024-10502-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Being capable of accurately predicting morphological parameters of the plant weeks before achieving fruit maturation is of great importance in the production and selection of suitable ornamental pepper plants. The objective of this article is evaluating the feasibility and assessing the performance of CNN-based models using RGB images as input to forecast two morphological parameters: plant height and canopy diameter. To this end, four CNN-based models are proposed to predict these morphological parameters in four different scenarios: first, using as input a single image of the plant; second, using as input several images from different viewpoints of the plant acquired on the same date; third, using as input two images from two consecutive weeks; and fourth, using as input a set of images consisting of one image from each week up to the current date. The results show that it is possible to accurately predict both plant height and canopy diameter. The RMSE for a forecast performed 6 weeks in advance to the actual measurements was below 4.5 cm and 4.2 cm, respectively. When information from previous weeks is added to the model, better results can be achieved and as the prediction date gets closer to the assessment date the accuracy improves as well.},
  archive      = {J_NCA},
  author       = {Ruiz-Gonzalez, Ruben and do Nascimento, Antonia Maiara Marques and Santos, Marcos Bruno da Costa and Porto, Rutten Kécio Soares de Brito and Medeiros, Artur Mendes and dos Santos, Fábio Sandro and Martínez-Martínez, Víctor and Barroso, Priscila Alves},
  doi          = {10.1007/s00521-024-10502-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {22107-22128},
  shortjournal = {Neural Comput. Appl.},
  title        = {Temporal forecasting of plant height and canopy diameter from RGB images using a CNN-based regression model for ornamental pepper plants (Capsicum spp.) growing under high-temperature stress},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analyzing toxicity in arabic social media: A study of regional dialects, sentiments, and toxic topics on X/Twitter. <em>NCA</em>, <em>37</em>(26), 22083-22105. (<a href='https://doi.org/10.1007/s00521-025-11503-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social networks have become the most popular medium for interpersonal communication, emotional expression, and information exchange. Leveraging artificial intelligence technologies, this study aims to analyze and address the issues of toxicity and abusiveness prevalent on X (formerly known as Twitter), specifically within Arabic-speaking communities. Data for this research was collected using the X API and meticulously annotated by native Arabic speakers to create a balanced dataset of toxic and non-toxic tweets. These tweets were categorized across various topics, including politics, sports, economics, religion, technology, and more. We employed topic analysis, dialect identification, sentiment analysis, and data frequency distribution techniques to examine the dataset. Our findings indicate that topics related to politics, religion, and pornography contain the highest levels of toxicity. Additionally, dialect identification reveals significant regional variations, with the most toxic content appearing in the Libyan, Egyptian, and Yemeni dialects. Sentiment analysis shows a predominance of negative sentiments in toxic tweets. Moreover, the data frequency distribution highlights commonly used abusive terms and phrases. This study underscores the critical need to address toxicity on social media platforms across different languages and cultures, providing valuable insights into the nature and distribution of harmful content in Arabic-speaking regions.},
  archive      = {J_NCA},
  author       = {Hatem, Loay and Omar, Ahmed and Farghaly, Heba Mamdouh and Ali, Abdelmgeid A.},
  doi          = {10.1007/s00521-025-11503-z},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {22083-22105},
  shortjournal = {Neural Comput. Appl.},
  title        = {Analyzing toxicity in arabic social media: A study of regional dialects, sentiments, and toxic topics on X/Twitter},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ESMPS: An efficient stock market prediction system based on optimized and ensemble deep learning architecture. <em>NCA</em>, <em>37</em>(26), 22057-22082. (<a href='https://doi.org/10.1007/s00521-025-11502-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancements in deep learning architectures (DLAs), different application domains, including healthcare, communication, agriculture, finance, etc., get benefits in many terms. Its inclusion in stock markets in terms of prediction of closing prices can help the investors with better planning and other potential tasks such as portfolio management and decision process. However, the dynamic, unstable, and unknown patterns of stocks pose challenging situations for DLAs and increase the computational overhead. To deal with such challenges, this research work proposes an efficient stock market prediction system (ESMTS) with an ensemble DLA architecture. The convolutional neural network (CNN) in the ensemble model extracts meaningful information, such as trends and correlations in stocks. The recurrent neural network (RNN) focuses on capturing temporal dependencies and sequential patterns of stocks. This ensemble model can enhance generalization, versatility in data handling, and resilience to data shifts. Additionally, an enhanced krill herd optimization (EKH-Opt) is proposed to improve computational efficiency. The proposed model is evaluated using a small-scale and large-scale dataset of stocks from Yahoo Finances. The historical information is extracted from January 2014 to December 2023, and different technical indicators are also computed for better trend analysis and improved predictive power of the system. Different performance indicators such as mean squared error (MSE), R-squared (R2), mean squared logarithmic error (MSLE), explained variance score (EVS), and mean absolute error (MAE) are used for performance analysis and comparison. The proposed system demonstrates its effectiveness with an overall performance based on MSE of 0.0002, R2 of 0.99, MSLE of 0.00009, EVS of 0.99, and MAE of 0.0078.},
  archive      = {J_NCA},
  author       = {Singh, Shobhita and Khanna, Divya and Bhatia, B. S.},
  doi          = {10.1007/s00521-025-11502-0},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {22057-22082},
  shortjournal = {Neural Comput. Appl.},
  title        = {ESMPS: An efficient stock market prediction system based on optimized and ensemble deep learning architecture},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Swarm intelligence for handling out-of-vocabulary in arabic dialect identification with different representations. <em>NCA</em>, <em>37</em>(26), 22029-22055. (<a href='https://doi.org/10.1007/s00521-025-11501-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise in popularity of social networks and programs that let users connect instantaneously, communication has become more dynamic. So, regularly occurring new words affect the quality of representation models and make spelling errors. As the natural language processing applications depend on vector representations of texts, out-of-vocabulary (OOV) terms are unfamiliar to the models and must be handled with degrading their quality. For this, we present an OOV handling approach based on four swarm intelligence techniques, ant colony optimization, chicken swarm optimization, gray wolf optimization, and particle swarm optimization. In this study, three word embedding models have been used to obtain the representation of words. The performance of the proposed methods is evaluated on three tasks, dialect identification, sentiment analysis, sarcasm detection, and the results show that the suggested methods are promising for handling OOV and demonstrated high performance in all experiments. GWO-OOV-SVM achieved a 53.43% F1-score for dialect identification, while CSO-OOV-SVM achieved 75.66% and 57.68% F1-scores for sentiment analysis and sarcasm detection respectively, exceeding other models.},
  archive      = {J_NCA},
  author       = {Sobhy, Mahmoud and AbuElAtta, Ahmed H. and El-Sawy, Ahmed A. and Nayel, Hamada},
  doi          = {10.1007/s00521-025-11501-1},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {22029-22055},
  shortjournal = {Neural Comput. Appl.},
  title        = {Swarm intelligence for handling out-of-vocabulary in arabic dialect identification with different representations},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel GldReLU activation function with enhanced RESNET50 for classification of X-ray images. <em>NCA</em>, <em>37</em>(26), 21997-22028. (<a href='https://doi.org/10.1007/s00521-025-11500-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {GldReLU, as a novel activation function, is proposed in this research work. The number of activation functions have been investigated for Deep Learning (DL) models to improve the performance. The Rectified Linear Unit (ReLU) is a widely used activation function. Although a number of alternatives to ReLU have been used to enhance training performance and stability and to understand the ways in which ReLU interacts with different optimization strategies, weight initialization techniques, and network architectures, we propose a novel activation function, GldReLU. By scaling the ReLU function with the Golden Ratio phi (φ). The ReLU can be replaced with GldReLU in DL models. The proposed GldReLU is investigated with Residual Network (RESNET50), Visual Geometry Group (VGG16) and a customized Artificial Neural Network (ANN) model, and the outcomes are compared with every ReLU variant. The experiment is conducted with 118 real-time Chest X-ray images and 10,166 images from Kaggle for multi-classification. Furthermore more the experiment is conducted with 225 Teeth root X-ray images for binary classification. The Caltech-101 dataset is used and the results are compared with ReLU and GldReLU. Then for the text data Pima Indian Diabetes Dataset has been utilized. The comparison is done with the benchmark dataset, Cifar10. The findings demonstrated that accuracy, GldReLU outperforms ReLU and its variants.Cifar10 dataset with RESNET50 was 83% of accuracy and with modified RESNET50, is of 87%.The accuracy for the classification of real-time Chest X-ray images in RESNET50 is 85% and in modified RESNET50 is 89%. The Caltech-101 dataset is also taken for evaluation. The test accuracy improvement was 10% in GldReLU when compared with ReLU in the network. Besides this, the accuracy of the customized Artificial Neural Network (ANN) for the Pima Indian Diabetes Dataset with four hidden layers and ReLU AF is 71%, while the accuracy with GldReLU is 82%. Thus, the proposed novel GldReLU outperforms in the model with all datasets.},
  archive      = {J_NCA},
  author       = {Lakshmi, P. Pankaja and Sivagami, M.},
  doi          = {10.1007/s00521-025-11500-2},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21997-22028},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel GldReLU activation function with enhanced RESNET50 for classification of X-ray images},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An evaluation of a pre-trained transformer-based self-distillation model (DINOv2) for cross-domain plant species identification. <em>NCA</em>, <em>37</em>(26), 21969-21995. (<a href='https://doi.org/10.1007/s00521-025-11499-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plant species identification is a fundamental process in botany and agriculture sector. In recent years, deep neural networks have become the primary approach for automating this task, providing valuable insights into biodiversity, ecological systems, and agricultural practices. Along with more discoveries in plant species, training a deep neural network becomes very challenging as the cost required to collect and annotate plant samples is expensive and impractical. Despite the lack of labelled plant samples, recent studies have explored the potential of leveraging publicly available and systematically annotated plant specimens in herbaria coupled with field images for plant species identification through cross-domain adaptation techniques. However, the accuracy of these methods remains unsatisfactory, motivating the exploration of alternative approaches. In this paper, we evaluated the feasibility of employing a pre-trained transformer-based self-distillation model (DINOv2) for cross-domain plant species identification tasks. We trained our model with the PlantCLEF2020 dataset comprised of approximately 320 k herbarium and field images representing 997 plant species. Our approach leverages the advanced feature extraction capabilities of DINOv2, which enhances cross-domain adaptation by effectively bridging the gap between herbarium and field images, achieving a 17.7% improvement over the best model proposed in previous work, that employs ensembles of Siamese network architectures with triplet loss (HFTL-ENS and OSM-ENS).},
  archive      = {J_NCA},
  author       = {Ong, Chin Ann and Tay, Fei Siang and Then, Yi Lung and McCarthy, Chris},
  doi          = {10.1007/s00521-025-11499-6},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21969-21995},
  shortjournal = {Neural Comput. Appl.},
  title        = {An evaluation of a pre-trained transformer-based self-distillation model (DINOv2) for cross-domain plant species identification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel method of heterogeneous parallel machine learning by CPU–TPU for molecular dynamics. <em>NCA</em>, <em>37</em>(26), 21949-21967. (<a href='https://doi.org/10.1007/s00521-025-11498-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a heterogeneous parallel machine learning molecular dynamics (MLMD) calculation method based on both central processing unit (CPU) and SOPHON BM1684X tensor processing unit (TPU) is proposed. The method aims to offer a new hardware deployment approach for advanced MLMD algorithms, alleviating the constraints imposed by the severe "memory wall" and "power wall" bottlenecks caused by the separation of storage units and computing units inherent in von Neumann architecture-based machines at the hardware level. By decomposing complex MD simulation tasks into subtasks that can be processed in parallel on both CPU and TPU, this method enhances computational efficiency while maintaining high precision. Specifically, the potential energy surface fitting task in MD simulation is deployed on the TPU, leveraging its parallel processing capabilities to accelerate computations. Meanwhile, load balancing between the CPU and TPU is achieved by executing other computational tasks on the CPU. Experimental results demonstrate significant improvements in computational speed, energy efficiency, and the size of computable systems compared to the non-heterogeneous CPU-only system, indicating that heterogeneous parallel computing is an effective method for accelerating MD simulations.},
  archive      = {J_NCA},
  author       = {Zhang, Yujia and Zhang, Xin and Zheng, Gang and Mo, Pinghui and Zhao, Zhuoying and Li, Chenyang and Tang, Kai and Liu, Jie},
  doi          = {10.1007/s00521-025-11498-7},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21949-21967},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel method of heterogeneous parallel machine learning by CPU–TPU for molecular dynamics},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surfing the bitcoin waves: Comprehensive trend forecasting with various trader types. <em>NCA</em>, <em>37</em>(26), 21931-21948. (<a href='https://doi.org/10.1007/s00521-025-11496-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cryptocurrency trading is becoming increasingly popular worldwide, with many individuals seeking to maximize their profits. One approach they are exploring is following the actions of successful investors, automated bots, or whale traders. The insights that can help traders make better decisions may be uncovered by analyzing their behavior and impact. This study examines the effectiveness of this strategy and aims to understand how various types of traders affect the Bitcoin market, including fundamental aspects like price fluctuations over time. Additionally, we aim to identify patterns that regular traders can follow to enhance their chances of success in cryptocurrency trading. We employed a time-series forecasting method, which involves analyzing past price movements and other critical factors to predict future trends. To ensure the robustness and reliability of our findings, we utilized various advanced techniques, such as machine learning, deep learning, and traditional time-series forecasting models. These powerful tools enable us to make more accurate predictions and provide strong evidence for our research conclusions. The study demonstrates that some models, such as linear regression and random forest regression, did not perform well with features related to "whales," "bots," and "top traders." However, models like XGBoost Regression and Transformer showed positive effects. This suggests that, for now, traders should focus more on basic features like "open," "high," and "low" prices rather than these other factors. As advanced models like XGBoost and Transformer continue to develop, these features may become more important. While it is important to consider different features, relying on traditional indicators currently seems prudent.},
  archive      = {J_NCA},
  author       = {Ateş, Can Ali and Çoban, Emre and Gurgen Erdogan, Tugba},
  doi          = {10.1007/s00521-025-11496-9},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21931-21948},
  shortjournal = {Neural Comput. Appl.},
  title        = {Surfing the bitcoin waves: Comprehensive trend forecasting with various trader types},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OVST: Online video stabilization with two-stage training transformer. <em>NCA</em>, <em>37</em>(26), 21909-21929. (<a href='https://doi.org/10.1007/s00521-025-11494-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video stabilization aims to mitigate or eliminate the shake presented within video frames. Existing online video stabilization technologies rely on information from future frames, which may introduce a lag during real-time video stabilization. To surmount this hurdle, an online video stabilization model called OVST is proposed, which leverages solely historical video frames and enhanced by an attention mechanism. To simplify the complexity of model training and enhance robustness, a two-stage training strategy is proposed to decouple the fitting of real poses and the stabilization of virtual poses, and a hybrid stabilization loss with interframe soft constraints is designed, which effectively regulates the changes in camera poses between adjacent frames through interframe displacement, angular distortion, and cropping rate, thereby suppressing the distortion effects caused by excessive pose smoothing while balancing stability and cropping rate. Experiments demonstrate the superiority of the proposed OVST method over existing state-of-the-art techniques, achieving a stability metric of 0.8878 and a distortion metric of 0.9870.},
  archive      = {J_NCA},
  author       = {Wu, Xing and Zhu, Yimin and Zhang, Han and Song, Jun and Yao, Junfeng and Zhu, Dong and Qian, Quan and Guo, Yike},
  doi          = {10.1007/s00521-025-11494-x},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21909-21929},
  shortjournal = {Neural Comput. Appl.},
  title        = {OVST: Online video stabilization with two-stage training transformer},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A generalized novel approach for plant disease detection based on SimCLR and patch-based analysis. <em>NCA</em>, <em>37</em>(26), 21867-21908. (<a href='https://doi.org/10.1007/s00521-025-11493-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting plant diseases is essential for maintaining crop health and maximizing agricultural productivity. While recent advancements in machine learning and deep learning methods for plant disease diagnosis show significant promise, they also present challenges—particularly related to data annotation and the limitations of task-specific models, which often struggle to generalize across different plant diseases. Traditional methods face additional obstacles due to their dependence on crop-specific models and the need for manual inspections, resulting in inefficiencies and limited scalability. This study proposes a generalized approach for efficiently identifying a wide range of plant diseases. By integrating patch-based analysis with the self-supervised learning technique SimCLR, the method enables farmers and researchers to detect unhealthy leaves across various crop species efficiently. To evaluate the effectiveness of our approach, we trained and tested the model using the well-regarded PlantVillage dataset, known for its extensive and diverse representation. Our approach achieved an accuracy of 97.57%. Moreover, when tested on novel datasets, the model achieved an accuracy of 99.22%, demonstrating its robustness and strong generalization capability to previously unseen data.},
  archive      = {J_NCA},
  author       = {Faheem Saidahmd, Mohamed T. and Elbasiony, Reda M. and Bastwesy, Marwa R. M. and Hagar, Asmaa A. M.},
  doi          = {10.1007/s00521-025-11493-y},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21867-21908},
  shortjournal = {Neural Comput. Appl.},
  title        = {A generalized novel approach for plant disease detection based on SimCLR and patch-based analysis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing predictive accuracy of nano-additive concrete gamma ray attenuation at high temperatures using AI-based models. <em>NCA</em>, <em>37</em>(26), 21833-21866. (<a href='https://doi.org/10.1007/s00521-025-11491-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study delves into predicting the residual gamma-ray linear attenuation coefficient (Rµ) values of concrete incorporating nano-additives, specifically nanocarbon tubes (NCTs) and nano-alumina (NAl), under elevated temperatures using various artificial intelligence (AI) models. Four AI-based prediction models of artificial neural networks (ANN), fuzzy logic models (FLM), water cycle algorithm (WCA), and genetic algorithm (GA) were trained using available literature data, which includes experimental results of 104 post-heating µ values varying by temperature degree, temperature exposure period, nanomaterial type, and nanomaterial replacement ratio. Results showed that ANN and FLM models demonstrated strong potential for predicting Rµ values, achieving coefficient of determination (R2) values of 0.989 and 0.999, respectively, for the training datasets. However, their practical application is limited by the challenge of formulating concise and direct prediction equations. Conversely, metaheuristic algorithms such as WCA and GA yield highly accurate predictions and enable the derivation of robust predictive equations. The developed equations using WCA and GA demonstrated excellent performance, achieving high R2 values of 0.959 and 0.907, respectively, for the training datasets. Moreover, these models exhibited superior validation for residual Rµ values after elevated temperatures exposure, with mean absolute errors (MAEs) of 0.0322 and 0.0501 for training, 0.049 and 0.054 for validation, and 0.0499 and 0.0575 for testing datasets, respectively. Furthermore, sensitivity analysis using Shapley Additive Explanation (SHAP) was conducted to elucidate the impact and relationship between the input variables and the outputs of Rµ values. The SHAP results indicated that temperature degree exerted the most significant influence on Rµ values, followed by %NCTs, %NAl, and finally, time of exposure. The average absolute SHAP values for these variables were 2.1, 1.7, 1.6, and 1, respectively. This study’s findings emphatically underscore the effectiveness of AI-based models in predicting concrete radiation shielding behavior. Crucially, it provides valuable insights into the intricate, nonlinear relationships among the various variables that govern this behavior.},
  archive      = {J_NCA},
  author       = {Mahmoud, Alaa A. and El-Sayed, Alaa A. and Aboraya, Ayman M. and N.Fathy, Islam and Nabil, Islam M.},
  doi          = {10.1007/s00521-025-11491-0},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21833-21866},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing predictive accuracy of nano-additive concrete gamma ray attenuation at high temperatures using AI-based models},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stage APT malware propagation model in computer networks. <em>NCA</em>, <em>37</em>(26), 21805-21832. (<a href='https://doi.org/10.1007/s00521-025-11490-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early detection and prevention of advanced persistent threats (APT) is a critical challenge in cybersecurity. This paper presents an innovative approach using dual susceptible–infected–recovered (Dual-SIR) model to predict the two-stage spread of APT malware within networks. The first SIR model addresses infections at the first stage—device and user level, serving as a precursor to server compromise. The second SIR model focuses on the second stage of propagation—server infections, where sensitive organizational data is stored. Experimental results demonstrate the effectiveness of our proposed model not only for APT malware but also for other types of malware. Our work significantly contributes to the field of cybersecurity by offering a more accurate and proactive method for predicting malware spread. Additionally, this approach has potential applications in forecasting the dissemination of malware in wireless sensor networks and the spread of malicious information on social media platforms.},
  archive      = {J_NCA},
  author       = {Do Xuan, Cho and Tran, Hai-Anh and Nguyen Thi, Lan Phuong and Nguyen, Kim-Khoa},
  doi          = {10.1007/s00521-025-11490-1},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21805-21832},
  shortjournal = {Neural Comput. Appl.},
  title        = {Two-stage APT malware propagation model in computer networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel approach using explainable prediction of default risk in peer-to-peer lending based on machine learning models. <em>NCA</em>, <em>37</em>(26), 21783-21803. (<a href='https://doi.org/10.1007/s00521-025-11489-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online peer-to-peer (P2P) lending has expanded substantially during the previous decade globally. However, this quick expansion poses several potential risks as loan default risk in P2P lending remains unavoidable. As P2P lending has grown in both size and complexity, the challenges have also multiplied, leading to several complications, including high number of features, low-performing classification models and imbalanced dataset. Furthermore, machine learning models encounter another challenging issue known as the black-box problem. To overcome these challenges, the present work introduces a novel approach that involves tackling the dataset balancing issue using synthetic minority oversampling technique (SMOTE), employing carefully selected feature selection approaches (maximum relevance minimum redundancy (MRMR), sequential forward selection (SFS) and adaptive boosting (AdaBoost)) and machine learning such as nonlinear model (K-nearest neighbour (KNN)), tree-based model (random forest (RF)) and deep learning (multi-layer perceptron (MLP)). Compared to the previous studies, the present results showed that RF exhibited outstanding performance of 0.94, 0.94 and 0.99 in accuracy, F1-score and AUC, respectively. To address the black-box issue of the prediction model, enhance its interpretability and boost user trust, local interpretable model-agnostic explanations (LIME) and Shapley additive explanations (SHAP) explainable machine learning models were applied to the RF prediction model to elucidate its results. Furthermore, LIME and SHAP explainable machine learning models were applied to the RF prediction model, both with and without SMOTE resampling, to examine the influence of SMOTE resampling on the interpretability analysis of the RF prediction outcomes.},
  archive      = {J_NCA},
  author       = {Atef, Markus and Ouf, Shimaa and Seoud, Wafaa and Gabr, Menna Ibrahim},
  doi          = {10.1007/s00521-025-11489-8},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21783-21803},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel approach using explainable prediction of default risk in peer-to-peer lending based on machine learning models},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fault diagnosis method combining dual information with sample attention mechanism under small samples. <em>NCA</em>, <em>37</em>(26), 21761-21781. (<a href='https://doi.org/10.1007/s00521-025-11487-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The implementation of deep learning in fault diagnosis is challenging due to the small sample, since the deficiency of labeled fault data constrains the model’s efficacy. To address this challenge, a new similarity filtering-based pseudo-label learning approach (SFPL) is proposed based on dual information and sample attention mechanism. SFPL utilizes unlabeled data for pre-training through data similarity calculations. It also includes a sample attention mechanism that assigns weights to the samples to improve the efficiency of the model’s learning. Additionally, a data filtering mechanism based on cosine similarity is introduced to enhance the quality of pseudo-labels. These pseudo-labels are used to fine-tune the model for high-accuracy fault diagnosis. Validation experiments on two datasets show that the suggested method can achieve high accuracy and stability with only a few labeled samples.},
  archive      = {J_NCA},
  author       = {Pang, Jiachen and Han, Tian and Li, Peng},
  doi          = {10.1007/s00521-025-11487-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21761-21781},
  shortjournal = {Neural Comput. Appl.},
  title        = {A fault diagnosis method combining dual information with sample attention mechanism under small samples},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAPrompt: Deterministic assumption prompt learning for event causality identification. <em>NCA</em>, <em>37</em>(26), 21743-21759. (<a href='https://doi.org/10.1007/s00521-025-11486-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event causality identification (ECI) aims at determining whether there is a causal relation between two event mentions. Conventional prompt learning designs a prompt template to first predict an answer word and then maps it to the final decision. Unlike conventional prompts, we argue that predicting an answer word may not be a necessary prerequisite for the ECI task. Instead, we can first make a deterministic assumption on the existence of causal relation between two events and then evaluate its rationality to either accept or reject the assumption. The design motivation is to try the most utilization of the encyclopedia-like knowledge embedded in a pre-trained language model. In light of such considerations, we propose a deterministic assumption prompt learning model, called DAPrompt, for the ECI task. In particular, we design a simple deterministic assumption template concatenating with the input event pair, which includes two masks as predicted events tokens. We use the probabilities of predicted events to evaluate the assumption rationality for the final event causality decision. Experiments on the EventStoryLine corpus validate our design objective in terms of significant performance improvements over the state-of-the-art algorithms.},
  archive      = {J_NCA},
  author       = {Xiang, Wei and Zhan, Chuanhong and Zhang, Qing and Wang, Bang},
  doi          = {10.1007/s00521-025-11486-x},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21743-21759},
  shortjournal = {Neural Comput. Appl.},
  title        = {DAPrompt: Deterministic assumption prompt learning for event causality identification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting deception: Employing deep neural networks for fraudulent review detection on amazon. <em>NCA</em>, <em>37</em>(26), 21715-21742. (<a href='https://doi.org/10.1007/s00521-025-11485-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of e-commerce dominance, an increase in fake reviews on online shopping platforms compromises the integrity of consumer feedback systems. This study focuses on Amazon, a leading e-commerce platform in the USA, where fake reviews have become a significant concern. Given the limited availability of authentic datasets for analysis, we propose a novel methodology to differentiate between genuine and fraudulent reviews across verified and non-verified purchases. Our approach utilizes the bootstrap distribution of cosine similarity values, providing a robust statistical foundation for review classification. We present a comprehensive framework integrating convolutional neural networks with word embedding and emotion-mining techniques through natural language processing, using a novel loss function. This multifaceted approach enhances detection accuracy and offers insights into the linguistic and emotional markers of fake reviews. Our method demonstrates exceptional performance, achieving an accuracy rate of over 96% in distinguishing fake reviews from user reviews. This study contributes to the growing research on online review authenticity and offers practical implications for e-commerce platforms, regulatory bodies, and consumers. This research aims to foster trust in online marketplaces and protect consumers from misleading information by providing a powerful tool for fake review detection.},
  archive      = {J_NCA},
  author       = {Thilini Jayasinghe, J. M. and Dassanayaka, Sachith},
  doi          = {10.1007/s00521-025-11485-y},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21715-21742},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detecting deception: Employing deep neural networks for fraudulent review detection on amazon},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive learning of instance representatives in dual spaces for medical image classification. <em>NCA</em>, <em>37</em>(26), 21695-21714. (<a href='https://doi.org/10.1007/s00521-025-11481-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image classification plays a vital role in AI-aided medical diagnosis and is often addressed as a multiple instance learning (MIL) issue (i.e., each sample is a bag of instances). For medical images, the disease area or the discriminative area is usually smaller than the whole tissue. In other words, most of the instances in a bag are irrelevant and could interfere with the bag label inference. To address this issue, we add an instance representative selection process before MIL and propose a novel MIL approach named dual space multiple instance representative learning (DSMIRL). DSMIRL consists of two core steps: adaptive instance representative selection (AIRS) and multiple instance representative learning (MIRL). In AIRS, we group and score instances, and then meticulously devise group-wise or instance-wise strategies to select the final collection of instance representatives. The group-wise approaches only preserve the group of instances with the highest instance score as the instance representatives, while the instance-wise ones select the top-k ranked instances in each group to yield the final instance representation collection. In MIRL, we perform aggregations on the selected instance representatives. These aggregations are carried out in both label and feature spaces, so as to further exploit the complementary information of these two spaces. It is worthwhile to point out that this MIRL step can be also flexibly replaced by other existing MIL approaches and enables further improving them. Extensive experiments on four medical image datasets demonstrate the promising performance of DSMIRL over the state-of-the-art MIL approaches and also validate the effectiveness of boosting other MIL by DSMIRL.},
  archive      = {J_NCA},
  author       = {Zhu, Xiang and Huang, Sheng and Tang, Wenhao and Zhang, Yi and Zhang, Xiaoxian and Liu, Chen and Zhang, Xiahong},
  doi          = {10.1007/s00521-025-11481-2},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21695-21714},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive learning of instance representatives in dual spaces for medical image classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LSHADE-NGS: Enhancing Q-coverage in directional sensor networks through navigated generation search. <em>NCA</em>, <em>37</em>(26), 21659-21694. (<a href='https://doi.org/10.1007/s00521-025-11479-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Directional sensors play a critical role in enabling precise data collection and effective monitoring within wireless sensor networks (WSNs). Despite their effectiveness in tasks like surveillance and environmental observation, challenges remain in prolonging network life and ensuring multi-coverage, particularly Q-coverage. Multi-coverage issues arise in over-provisioned (excess sensors) and under-provisioned (insufficient sensors) environments, leading to inefficient resource utilization or coverage gaps. Achieving effective multi-coverage necessitates strategic resource allocation to maintain comprehensive monitoring while avoiding redundancy. This paper addresses the Q-coverage optimization problem in directional sensor networks with adjustable orientations by assessing whether the environment is over-provisioned or under-provisioned and dynamically determines the operational status (active or inactive) and orientation of each sensor to achieve two main objectives: maximizing network coverage balancing in under-provisioned environments and minimizing the number of active sensors in over-provisioned settings. To meet these goals, we introduce LSHADE-navigated generation search (LSHADE-NGS), a novel enhancement of the LSHADE algorithm designed to navigate each generation toward more promising search spaces. The proposed algorithm integrates several innovative components: a refined initialization method to improve the diversity of the starting population, a heuristic adjustment JADE mutation (HA-JADE) to dynamically adjust mutation strategies, and a greedily-jumped binomial crossover mechanism on the directional array (GJ-Bi) to enhance convergence speed. The algorithm’s effectiveness is evaluated using multiple metrics, including the Q-balancing index, distance index, coverage quality, power consumption, and the count of active sensors. The experimental results reveal significant enhancements in solution quality achieved by LSHADE-NGS, underscoring the method’s superiority over existing approaches and illustrating its distinct advantages compared to the conventional LSHADE framework.},
  archive      = {J_NCA},
  author       = {Thanh, Binh Huynh Thi and Van Duc, Cuong and Van, Son Nguyen and La Van, Quan and Thi, Hanh Nguyen},
  doi          = {10.1007/s00521-025-11479-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21659-21694},
  shortjournal = {Neural Comput. Appl.},
  title        = {LSHADE-NGS: Enhancing Q-coverage in directional sensor networks through navigated generation search},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fairness scale for real-time recidivism forecasts using a national database of convicted offenders. <em>NCA</em>, <em>37</em>(26), 21607-21657. (<a href='https://doi.org/10.1007/s00521-025-11478-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This investigation explores whether machine learning can predict recidivism while addressing societal biases. To investigate this, we obtained conviction data from the UK’s Police National Computer (PNC) on 346,685 records between January 1, 2000, and February 3, 2006 (His Majesty’s Inspectorate of Constabulary in Use of the Police National Computer: An inspection of the ACRO Criminal Records Office. His Majesty’s Inspectorate of Constabulary, Birmingham, https://assets-hmicfrs.justiceinspectorates.gov.uk/uploads/police-national-computer-use-acro-criminal-records-office.pdf , 2017). We generate twelve machine learning models—six to forecast general recidivism, and six to forecast violent recidivism—over a 3-year period, evaluated via fivefold cross-validation. Our best-performing models outperform the existing state-of-the-arts, receiving an area under curve (AUC) score of 0.8660 and 0.8375 for general and violent recidivism, respectively. Next, we construct a fairness scale that communicates the semantic and technical trade-offs associated with debiasing a criminal justice forecasting model. We use this scale to debias our best-performing models. Results indicate both models can achieve all five fairness definitions because the metrics measuring these definitions—the statistical range of recall, precision, positive rate, and error balance between demographics—indicate that these scores are within a one percentage point difference of each other. Deployment recommendations and implications are discussed. These include recommended safeguards against false positives, an explication of how these models addressed societal biases, and a case study illustrating how these models can improve existing criminal justice practices. That is, these models may help police identify fewer people in a way less impacted by structural bias while still reducing crime. A randomized control trial is proposed to test this illustrated case study, and further directions explored.},
  archive      = {J_NCA},
  author       = {Verrey, Jacob and Neyroud, Peter and Sherman, Lawrence and Ariel, Barak},
  doi          = {10.1007/s00521-025-11478-x},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21607-21657},
  shortjournal = {Neural Comput. Appl.},
  title        = {A fairness scale for real-time recidivism forecasts using a national database of convicted offenders},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed optimization with faulty nodes: Robust aggregation in hyperbolic space. <em>NCA</em>, <em>37</em>(26), 21563-21605. (<a href='https://doi.org/10.1007/s00521-025-11475-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing deployment of distributed machine learning models necessitates robust optimization methods that can tolerate adversarial or faulty nodes. In this work, we propose a robust gradient aggregation method for distributed stochastic gradient descent that leverages hyperbolic geometry. Specifically, local gradients computed at individual nodes are embedded into hyperbolic space using the Poincaré ball model, and their geometric median is computed as a robust aggregate. This aggregated gradient is then mapped back to Euclidean space for the gradient update. We also show that existing robust gradient aggregation methods like Krum can be improved using hyperbolic space. Compared to existing robust aggregation methods, our hyperbolic approach offers improved separation of outlier updates. We provide theoretical convergence guarantees and validate our method on benchmark datasets as well as on a traffic forecasting task, demonstrating its efficacy in mitigating Byzantine failures in distributed federated learning environments.},
  archive      = {J_NCA},
  author       = {Ghosh, Subhas Kumar and Vittamsetti, Vijay Monic},
  doi          = {10.1007/s00521-025-11475-0},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21563-21605},
  shortjournal = {Neural Comput. Appl.},
  title        = {Distributed optimization with faulty nodes: Robust aggregation in hyperbolic space},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cancer progression inference using a finite-state model to allow recurrences and losses of mutations. <em>NCA</em>, <em>37</em>(26), 21545-21562. (<a href='https://doi.org/10.1007/s00521-025-11474-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inference of cancer evolutionary histories is a key step for the understanding and treatment of the disease; thus, many tools had been developed in the last decade to address this important problem. However, methods for inferring tumor phylogenies need to strike a balance between keeping reasonable running times and employing sophisticated evolution models. Binary characters, such as single-nucleotide variants and known mutations, which is our focus, is an example of a simple model that is able to capture most relevant cases—but not copy number variants. On binary characters, most methods are designed for simpler models where mutations can only be accumulated under the infinite sites assumption; however, those models tend to be too simplistic for real case scenarios. While the most explored direction in the context of binary characters is to allow mutation losses, in this paper, we introduce an even more general model, where each mutation can be acquired and lost more than once. We describe this model, provide a simulated annealing approach exploiting this novel evolutionary framework, and show its accuracy on different sets of experimental evaluations when compared to less general models, and demonstrate potential application to real data.},
  archive      = {J_NCA},
  author       = {Ciccolella, Simone and Patterson, Murray and Hajirasouliha, Iman and Della Vedova, Gianluca},
  doi          = {10.1007/s00521-025-11474-1},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21545-21562},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cancer progression inference using a finite-state model to allow recurrences and losses of mutations},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Experimental validation of optimized performance of microbial fuel cell-based horned lizard algorithm and artificial intelligence. <em>NCA</em>, <em>37</em>(26), 21519-21544. (<a href='https://doi.org/10.1007/s00521-025-11473-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microbial fuel cell (MFC) has shown promise for simultaneous wastewater treatment and electrical power production. Improving the performance of MFC is the objective of this study. Firstly, three input parameters including Ni (mg/m2), COD (mg/L) and aeration (mL/min) are investigated experimentally to measure the performance index of the MFC. The performance index of MFC includes the power density (PD), COD removal (CODr) and coulombic efficiency (CE). Secondly, using the experimental data, an adaptive neuro-fuzzy inference system (ANFIS) model was created to simulate the MFC in terms of Ni, COD and aeration. To assess the modelling stage, the results are compared with ANOVA. For the PD model, the predicted R2 increased from 0.902 to 0.93 by around 3.1% compared to ANOVA, whereas for the ANFIS model for the CODr, the predicted R2 increased from 0.58 to 0.81 by around 39.6% compared to ANOVA. For the ANFIS model of the CE, the predicted R2 value increased from 0.81 to 0.91 by around 12.3% compared to ANOVA. This demonstrated the robustness of ANFIS model of the MFC. Thirdly, the optimal values of Ni, COD and aeration are identified based on integration between ANFIS model of the MFC and the horned lizard algorithm.},
  archive      = {J_NCA},
  author       = {Rezk, Hegazy and Ghasemi, Mostafa},
  doi          = {10.1007/s00521-025-11473-2},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21519-21544},
  shortjournal = {Neural Comput. Appl.},
  title        = {Experimental validation of optimized performance of microbial fuel cell-based horned lizard algorithm and artificial intelligence},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blind image super-resolution using swin transformer with unsupervised degradation and sparse attention. <em>NCA</em>, <em>37</em>(26), 21493-21517. (<a href='https://doi.org/10.1007/s00521-025-11471-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past few years, significant advancements in convolutional neural networks (CNNs) have significantly propelled the field of image super-resolution (SR) research. Nonetheless, many current SR techniques are limited in effectively addressing real-world data degradation, particularly in blind scenarios characterized by multi-modal, spatially variant, and unknown distributions. Based on this issue, we propose a degradation-aware Swin Transformer with sparse attention for blind SR. In this model, we proposed a degradation-aware residual Swin Transformer sparse attention block that is based on the Swin transformer layer, the non-local sparse attention (NLSA), and the degradation-aware convolutional (DA Cov). The Swin Transformer solves CNN’s problems because it has the ability to process images of large size and extract long-range dependency, which works as a local attention mechanism. Moreover, the NLSA is utilized to solve problems combined with non-local attention, which works as a global attention mechanism. Also, it prevents the model from attending to noisy and less informative locations by partitioning the deep feature pixels into different groups. The DA Cov is used to integrate the degraded kernel with extracted features. Moreover, our model shows superior visual quality and reconstruction accuracy with an efficient number of parameters and Mult-Adds. For example, on the Set5 dataset with a kernel size of 0.06 and a scaling factor of $$\times$$ 4, our model achieved a 0.1 dB improvement in PSNR compared to DRAN.},
  archive      = {J_NCA},
  author       = {Gendy, Garas and Sabor, Nabil},
  doi          = {10.1007/s00521-025-11471-4},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21493-21517},
  shortjournal = {Neural Comput. Appl.},
  title        = {Blind image super-resolution using swin transformer with unsupervised degradation and sparse attention},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UniBERT: Adversarial training for language-universal representations. <em>NCA</em>, <em>37</em>(26), 21473-21492. (<a href='https://doi.org/10.1007/s00521-025-11470-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents UniBERT, a compact multilingual language model that uses an innovative training framework that integrates three components: masked language modeling, adversarial training, and knowledge distillation. Pre-trained on a meticulously curated Wikipedia corpus spanning 107 languages, UniBERT is designed to reduce the computational demands of large-scale models while maintaining competitive performance across various natural language processing tasks. Comprehensive evaluations on four tasks, named entity recognition, natural language inference, question answering, and semantic textual similarity, demonstrate that our multilingual training strategy, enhanced by an adversarial objective, significantly improves cross-lingual generalization. Specifically, UniBERT models show an average relative improvement of 7.72% over traditional baselines, which achieved an average relative improvement of only 1.12%, and statistical analysis confirms the significance of these gains (p value = 0.0184). This work highlights the benefits of combining adversarial training and knowledge distillation to build robust and scalable language models, thus advancing the field of multilingual and cross-lingual natural language processing.},
  archive      = {J_NCA},
  author       = {Avram, Andrei-Marius and Lupaşcu, Marian and Cercel, Dumitru-Clementin and Mironică, Ionuţ and Trăuşan-Matu, Ştefan},
  doi          = {10.1007/s00521-025-11470-5},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21473-21492},
  shortjournal = {Neural Comput. Appl.},
  title        = {UniBERT: Adversarial training for language-universal representations},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweighted densely connected network for insect-pest identification in cotton crop. <em>NCA</em>, <em>37</em>(26), 21459-21472. (<a href='https://doi.org/10.1007/s00521-025-11469-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cotton, popularly known as “White-Gold” in India, accounts for about 23% of global production and significantly contributes to the Indian economy. However, it is highly susceptible to the infestation of various harmful insect-pests, which can cause substantial crop damage and yield reductions of up to 40–50%. In this context, we developed a lightweighted densely connected deep learning model for identifying insect-pests of cotton crop using RGB images. We collected 5,559 images of insect-pest infested cotton crops under natural field conditions across Indian agricultural farms. However, for enhancing the training images and to minimize the risk of overfitting the model, we applied a variety of image augmentation methods, including flipping, rotation, zooming, etc. The proposed model, with 83 layers, including four dense blocks and three transition layers, achieved around 99.24% of classification accuracy having 15 s/epoch of training time, outperforming the other pretrained models. Furthermore, Grad-CAM visualization technique was used for demonstrating the model’s effectiveness and efficiency in multiclass classification of cotton insect-pest images. This model offers a practical tool for farmers to manage pest infestations and improve cotton crop yield.},
  archive      = {J_NCA},
  author       = {Kumari, Shalini and Marwaha, Sudeep and Haque, Md. Ashraful and Sachan, Harsh and Deb, Chandan Kumar and Dahiya, Shashi and Arora, Alka and Shashank, P. R.},
  doi          = {10.1007/s00521-025-11469-y},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21459-21472},
  shortjournal = {Neural Comput. Appl.},
  title        = {A lightweighted densely connected network for insect-pest identification in cotton crop},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A GARCH-temporal fusion transformer model for the volatility prediction of exchange traded funds. <em>NCA</em>, <em>37</em>(26), 21435-21458. (<a href='https://doi.org/10.1007/s00521-025-11468-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting the volatility of financial assets—defined as the degree of their price variation over time—is a trending topic in financial research. Enhancing prediction accuracy is crucial in this field, as an asset’s volatility is widely used to assess the risk associated with its returns. In this context, we introduce a novel hybrid model that integrates traditional econometric techniques, specifically GARCH models, with the Temporal Fusion Transformer (TFT), a cutting-edge deep learning architecture. We designed such a model for analyzing Exchange Traded Funds (ETFs) composed of assets from the S&P 500, a benchmark index tracking 500 large US companies therefore reflecting the overall health and trends of the stock market, across various sectors. Utilizing volatility proxies such as historical volatility (HV) and the Garman–Klass (GK) method, our study demonstrates that the hybrid GARCH-TFT model significantly outperforms alternative models in forecasting the GK proxy and achieves performance comparable to the stand-alone TFT model for HV, underscoring the potential of merging machine learning approaches with traditional econometric methods to enhance predictive precision in volatile financial markets.},
  archive      = {J_NCA},
  author       = {Petrosino, Lorenzo and Bacco, Luca and Salvati, Giuliano and Merone, Mario and Papi, Marco},
  doi          = {10.1007/s00521-025-11468-z},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21435-21458},
  shortjournal = {Neural Comput. Appl.},
  title        = {A GARCH-temporal fusion transformer model for the volatility prediction of exchange traded funds},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A simple contrastive embedding framework for low-resource fake news detection. <em>NCA</em>, <em>37</em>(26), 21407-21433. (<a href='https://doi.org/10.1007/s00521-025-11467-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-resource fake news detection aims at discerning between true and false claims from low-resource languages with scarce benchmark datasets. In this resource-constrained scenario, fake news data collected from online hoax reporting system is inherently skewed because human fact checkers mainly sample claims that are more likely to be fake or false. Instead of training end-to-end classifier on the extremely imbalanced dataset, our study investigates a simple framework based on contrastive learning and stacking-based ensemble learning as an alternate fake news classification pipeline for Indonesian language. Our empirical result shows that by combining contrastive-based embedding model—Contrast-BERT and ensemble of multilayer perceptrons (MLPs) in inference stage, we improve the precision score in fake news classification up to 26.64%, while maintaining accuracy and recall scores of above 75%, given extreme class imbalance ratio 1:24. Contrast-BERT is also superior to its counterparts in unsupervised topic clustering and evidence retrieval by nearly twofold. Furthermore, we observe that contrastive-based model follows a similar performance trend in Indonesian clickbait benchmark dataset. Contrast-BERT is more accurate and precise at predicting samples than end-to-end BERT classifier by up to 47%, given training subset with extreme imbalance ratio $$\ge$$ 1:19.},
  archive      = {J_NCA},
  author       = {Ni’mah, Iftitahu and Wijayanti, Rini and Santosa, Agung and Jarin, Asril and Sampurno, Tri and Teduh Uliniansyah, Mohammad and Fang, Meng and Menkovski, Vlado and Pechenizkiy, Mykola},
  doi          = {10.1007/s00521-025-11467-0},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21407-21433},
  shortjournal = {Neural Comput. Appl.},
  title        = {A simple contrastive embedding framework for low-resource fake news detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stacked ensemble deep learning framework for alzheimer’s severity ranking and classification using MRI scans. <em>NCA</em>, <em>37</em>(26), 21381-21405. (<a href='https://doi.org/10.1007/s00521-025-11465-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is a progressive neurodegenerative disorder that significantly impacts cognitive function and quality of life. The early diagnosis and an accurate severity assessment of AD are always the point of target to the medical fraternity. To fulfill the dual objective this study presents a stacked ensemble deep learning framework for the automated classification and severity ranking of Alzheimer’s disease using MRI scans. The framework integrates multiple deep learning models including EfficientNet-B7, Xception, and Inception-ResNet-V2 to extract rich spatial features from MRI scans and is subsequently integrated using a rank-based fusion approach. The proposed method is evaluated on large-scale MRI OASIS and ADNI datasets of Alzheimer’s patients. According to experimental results, the suggested ensemble performs well on the OASIS dataset, achieving 97.8% accuracy, 96.5% sensitivity, and 98.2% specificity. The model outperforms the current single-model baselines with an accuracy of 98.1%, sensitivity of 97.3%, and specificity of 98.5% on the ADNI dataset. Additionally, the framework is excellent at assessing the severity of Alzheimer’s disease, making it a trustworthy tool for clinical decision support.},
  archive      = {J_NCA},
  author       = {Pandey, Nidhi and Sharma, Oshin},
  doi          = {10.1007/s00521-025-11465-2},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21381-21405},
  shortjournal = {Neural Comput. Appl.},
  title        = {A stacked ensemble deep learning framework for alzheimer’s severity ranking and classification using MRI scans},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new approach to hiding sensitive itemsets based on gray wolf optimization algorithm. <em>NCA</em>, <em>37</em>(26), 21363-21379. (<a href='https://doi.org/10.1007/s00521-025-11460-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protecting privacy in data mining has become a critical issue due to the increasing capabilities of data storage and analysis, particularly in domains involving personal data such as healthcare, banking, and commerce. Many techniques are used to protect sensitive data in data mining. However, these techniques often result in substantial information loss and reduced data utility. Therefore, a key challenge in privacy-preserving data mining (PPDM) is to develop techniques that can hide sensitive information with minimal impact on the original data. This paper introduces a new approach for protecting sensitive itemsets in association rule mining with transactions modifications rather transaction deletion. The proposed approach minimizes the impact on the original dataset while selectively hiding sensitive itemsets depending on the strategies of the gray wolf optimization (GWO) algorithm. The proposed approach introduces a novel algorithm termed GWOHSI (GWO for hiding sensitive itemset) to identify and hide sensitive itemsets with minimal side effects. The goal of this algorithm is to determine the optimal number of transactions should be modified for each item that contributes to sensitive itemsets, thus reducing their support to below the minimum support threshold. Comprehensive experiments are conducted to evaluate the performance of the proposed approach in terms of hiding failure, number of non-sensitive itemsets affected, data dissimilarity and execution time. Four datasets were used for evaluation, the results showed that the proposed approach effectively hides all sensitive itemsets (achieved a 100% hiding ratio), while minimizing the affected non-sensitive itemsets. The execution time of GWOHSI algorithm is considered satisfactory, and it is consistent across almost all datasets.},
  archive      = {J_NCA},
  author       = {Jumaa, Alaa Khalil},
  doi          = {10.1007/s00521-025-11460-7},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {21363-21379},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new approach to hiding sensitive itemsets based on gray wolf optimization algorithm},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Improved hybrid feature extractor in lightweight convolutional neural network for postharvesting technology: Automated oil palm fruit grading. <em>NCA</em>, <em>37</em>(25), 21361. (<a href='https://doi.org/10.1007/s00521-025-11303-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Junos, Mohamad Haniff and Mohd Khairuddin, Anis Salwa and Abu Talip, Mohamad Sofian and Kairi, Muhammad Izhar and Siran, Yosri Mohd},
  doi          = {10.1007/s00521-025-11303-5},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {21361},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: Improved hybrid feature extractor in lightweight convolutional neural network for postharvesting technology: Automated oil palm fruit grading},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: The FCM-guided deep learning model for low-frequency oscillation damping for electric power networks. <em>NCA</em>, <em>37</em>(25), 21359-21360. (<a href='https://doi.org/10.1007/s00521-025-11301-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Shafiullah, Md},
  doi          = {10.1007/s00521-025-11301-7},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {21359-21360},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: The FCM-guided deep learning model for low-frequency oscillation damping for electric power networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: DNACoder: A CNN-LSTM attention-based network for genomic sequence data compression. <em>NCA</em>, <em>37</em>(25), 21357-21358. (<a href='https://doi.org/10.1007/s00521-025-11271-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Sheena, K. S. and Nair, Madhu S.},
  doi          = {10.1007/s00521-025-11271-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {21357-21358},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: DNACoder: A CNN-LSTM attention-based network for genomic sequence data compression},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Performance analysis of machine learning algorithms for hybrid power generation prediction. <em>NCA</em>, <em>37</em>(25), 21353-21356. (<a href='https://doi.org/10.1007/s00521-025-11233-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Sarıışık, Gencay and Öğütlü, Ahmet Sabri},
  doi          = {10.1007/s00521-025-11233-2},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {21353-21356},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: Performance analysis of machine learning algorithms for hybrid power generation prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Object search by a concept-conditioned object detector. <em>NCA</em>, <em>37</em>(25), 21351-21352. (<a href='https://doi.org/10.1007/s00521-025-11232-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Rigoni, Davide and Serafini, Luciano and Sperduti, Alessandro},
  doi          = {10.1007/s00521-025-11232-3},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {21351-21352},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: Object search by a concept-conditioned object detector},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: Improving paraphrase generation using supervised neural-based statistical machine translation framework. <em>NCA</em>, <em>37</em>(25), 21349. (<a href='https://doi.org/10.1007/s00521-024-09650-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Razaq, Abdur and Shah, Babar and Khan, Gohar and Alfandi, Omar and Ullah, Abrar and Halim, Zahid and Ur Rahman, Atta},
  doi          = {10.1007/s00521-024-09650-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {21349},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Improving paraphrase generation using supervised neural-based statistical machine translation framework},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Knowledge distillation vulnerability of DeiT through CNN adversarial attack. <em>NCA</em>, <em>37</em>(25), 21347. (<a href='https://doi.org/10.1007/s00521-023-09412-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Hong, Inpyo and Choi, Chang},
  doi          = {10.1007/s00521-023-09412-0},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {21347},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: Knowledge distillation vulnerability of DeiT through CNN adversarial attack},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fortifying EV charging stations: AI-powered detection and mitigation of DDoS attacks using personalized federated learning. <em>NCA</em>, <em>37</em>(25), 21311-21346. (<a href='https://doi.org/10.1007/s00521-025-11452-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric vehicle charging stations (EVCS) are becoming more and more common, so it is imperative to protect these systems from cyberattacks, especially Distributed Denial-of-Service (DDoS) assaults. The objective of this study is to enhance the model interpretability and detection accuracy of DDoS attacks in EVCS using the Personalized Federated Learning (PFL) technique. The research makes use of an IoT attack dataset with 33 attacks that were carried out over 105 devices in a topology that was divided into seven different categories. Using the Firefly Algorithm, the suggested PFL method selects a subset of features wisely to maximize the performance of the classification model. Promising outcomes are seen in the evaluation of several machine learning models, such as Random Forest, Gradient Boosting Machine (GBM), K-Nearest Neighbors, and Multilayer Perceptron. GBM and Random Forest demonstrate their promise for efficient DDoS detection in EVCS by achieving high accuracy rates of 99% and 98%, respectively, in detecting DDoS attacks. The overall detection performance is further improved by the feature selection model, which also increases the efficiency and interpretability of the classification model. These results imply that machine learning models can improve the security and resilience of EVCS against DDoS attacks when combined with the PFL technique.},
  archive      = {J_NCA},
  author       = {Talaat, Fatma M. and Khoudier, Mohamed Mohsen Elsaid and Moawad, Ibrahim F. and El-Ghamry, Amir},
  doi          = {10.1007/s00521-025-11452-7},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {21311-21346},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fortifying EV charging stations: AI-powered detection and mitigation of DDoS attacks using personalized federated learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving arabic sentiment analysis with negation and speculation auxiliary tasks. <em>NCA</em>, <em>37</em>(25), 21297-21309. (<a href='https://doi.org/10.1007/s00521-025-11451-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today's era of big data, there is a growing need for computational techniques that can streamline people’s lives by generating, processing, and efficiently understanding textual data. Natural Language Processing (NLP), a branch of Artificial Intelligence, is continuously advancing in the development of deep learning models for these purposes. One crucial aspect of NLP is the detection of negation and speculation in text, particularly in a morphologically rich language like Arabic, as these phenomena can significantly alter the polarity and factuality of the text’s meaning. Addressing negation and speculation is crucial for improving the effectiveness of various NLP applications, including sentiment analysis, machine translation, and biomedical information retrieval. While many research studies have explored these challenges in English, Spanish, and Chinese, Arabic remains unexplored due to its complexity and lack of annotated corpora. This paper proposes a Multi-Task Learning (MTL) model that classifies sentiment analysis as the main task while using negation and speculation detection as auxiliary tasks to enhance contextual understanding of the main task. We trained, validated, and tested the proposed model using the Negation Speculation Arabic Review (NSAR) corpus, a pre-annotated corpus for negation and speculation. The experimental results demonstrate that our model achieves an enhancement of 5% and 3% in F1 over the baseline (F1 = 72%) for negation and speculation, respectively, when evaluated on a well-known benchmarked Arabic sentiment analysis dataset.},
  archive      = {J_NCA},
  author       = {Mahany, Ahmed and Ghoniemy, Said and Khaled, Heba},
  doi          = {10.1007/s00521-025-11451-8},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {21297-21309},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving arabic sentiment analysis with negation and speculation auxiliary tasks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel NLP-driven approach for enriching artefact descriptions, provenance, and entities in cultural heritage. <em>NCA</em>, <em>37</em>(25), 21275-21296. (<a href='https://doi.org/10.1007/s00521-025-11449-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the availability of numerous open datasets on cultural heritage, limited research has focussed on structuring and normalising this type of data, particularly through the extraction of entities from unstructured texts. This step is crucial for enriching, analysing, and understanding these complex datasets. This study presents a procedure designed to streamline the creation of domain-specific datasets for training natural language processing models and evaluates their performance across three distinct datasets generated using this procedure. A zero-shot learning model, the Generalist and Lightweight Model for Named Entity Recognition, was assessed alongside pre-trained spaCy models on three datasets created in the framework of the European Union-funded Research Intelligence Technology for Heritage and Market Security project: one containing provenance information on artefacts from North American museums, another detailing stolen cultural goods in Romania, and a third with structured yet unclassified data on WWII-looted Polish art. Further training of spaCy models on these newly defined datasets revealed that fine-tuned models significantly outperform their non-fine-tuned counterparts, with the best results from the Transformer model fine-tuned on provenance data. This success can be largely attributed to the standardised conventions in provenance research. In contrast, the model fine-tuned on descriptive information performed poorly, likely due to extensive descriptions containing non-essential data that increased model uncertainty. This work highlights the potential of automating entity extraction to build knowledge graphs for cultural object databases, enabling advanced analytical approaches such as Network Analysis.},
  archive      = {J_NCA},
  author       = {Ferro, Sara and Giovanelli, Riccardo and Leeson, Madison and De Bernardin, Michela and Traviglia, Arianna},
  doi          = {10.1007/s00521-025-11449-2},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {21275-21296},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel NLP-driven approach for enriching artefact descriptions, provenance, and entities in cultural heritage},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DEPP: Dictionary embedded probabilistic priors for scene text image super-resolution. <em>NCA</em>, <em>37</em>(25), 21259-21273. (<a href='https://doi.org/10.1007/s00521-025-11441-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene text image super-resolution (STISR), often considered a preliminary step for scene text recognition, refers to the task of enhancing the resolution of text embedded in natural scene images and plays a vital role in various applications. Most of the existing STISR methods either leverage deep convolutional neural networks by regarding text images as natural scene images or use a text recognizer’s feedback as guidance to the STISR process. However, since the text recognition is initially done on low-resolution images, it is mostly inaccurate, more so as the length of the words increases, thus degrading the super-resolution process. In this paper, we introduce DEPP which utilizes dictionary embedding (DE) based probabilistic priors calculated from a large English text corpus consisting of both alphabets and digits. The initial state and the bigram probabilities obtained are fused with the probability obtained from the recognizer, before passing it onto a single image super-resolution (SISR) block. By integrating DE as a prior and implementing a modified perceptual loss, the method effectively captures the contextual information of text, enabling more accurate super-resolution and visually pleasing results. Experimental results on the benchmark TextZoom dataset demonstrate that our DEPP framework achieves superior performance compared to most existing approaches, particularly for medium and long-length words, as measured by text recognition accuracy. Since DEPP uses the text recognition attributes to rectify or guide the super-resolution process, it makes our method more domain-inspired and task-aware, compared to usual black box deep learners.},
  archive      = {J_NCA},
  author       = {Bhattacharya, Avigyan and Basu, Subhadip and Chakraborti, Tapabrata},
  doi          = {10.1007/s00521-025-11441-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {21259-21273},
  shortjournal = {Neural Comput. Appl.},
  title        = {DEPP: Dictionary embedded probabilistic priors for scene text image super-resolution},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable deep learning techniques for wind speed forecasting in coastal areas: Integrating model configuration, regularization, early stopping, and SHAP analysis. <em>NCA</em>, <em>37</em>(25), 21219-21257. (<a href='https://doi.org/10.1007/s00521-025-11433-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate wind prediction is critical across engineering disciplines. For coastal infrastructure, it determines wave loads and storm surge resilience, directly impacting millions in vulnerable low-lying regions. The energy sector relies on precise forecasts to optimize wind farm output and stabilize power grids, while agriculture uses wind data to time pesticide applications and protect crops. Aviation and shipping industries leverage predictions for fuel-efficient routing and hazard avoidance, and urban engineers integrate wind models for skyscraper design and air pollution management. As climate change amplifies wind extremes, advancing predictive capabilities has become an urgent cross-sector priority for adaptive planning and risk mitigation. In coastal applications, empirical wave models (e.g., SWAN and WAVEWATCH III) heavily depend on accurate wind inputs, where errors can lead to underestimation of extreme events and compromise structural safety. This study introduces a novel deep learning framework, integrating advanced data preprocessing, structured neural networks, and explainable AI techniques, to enhance short-term (hourly) wind speed forecasting for coastal engineering applications, addressing the gap in region-specific deep learning frameworks for operational forecasting. The proposed method in this study addresses critical gaps in traditional methods by combining physical constraints with data-driven learning. It presents an innovative framework for wind speed data processing and prediction, integrating deep learning architectures with comprehensive meteorological analysis. Our research implements a sophisticated neural network model that processes high-frequency wind data from Bowen, incorporating multiple environmental parameters through a systematic data pipeline. The methodology encompasses three key components: (1) advanced data preprocessing, including time series standardization and cyclical feature encoding; (2) a deep learning architecture featuring three hidden layers (128-64-32 nodes) with ReLU activation and dropout regularization; and (3) comprehensive performance evaluation using five-fold cross-validation. The model achieved remarkable accuracy metrics: R2 = 0.957, RMSE = 0.449 m/s, demonstrating robust performance across varying weather conditions. Analysis revealed distinct performance patterns across wind speed ranges (low-speed MAE: 0.295 m/s; high-speed MAE: 0.433 m/s). The SHAP (SHapley Additive exPlanations) analysis provided deeper insights into feature importance and model interpretability, revealing Wind Direction (0.713 SHAP value) as the most influential predictor, followed by Relative Humidity (0.609) and Barometric Pressure (0.563). Temporal features (month, hour, and day) exhibited lower but consistent influence (SHAP values < 0.239). This research advances the field of environmental data science by providing: (1) a reproducible framework for wind speed prediction, (2) insights into feature significance and model behavior, and (3) practical applications for renewable energy planning and meteorological forecasting. The demonstrated methodology offers a foundation for future research in environmental modeling and time series prediction.},
  archive      = {J_NCA},
  author       = {Durap, Ahmet},
  doi          = {10.1007/s00521-025-11433-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {21219-21257},
  shortjournal = {Neural Comput. Appl.},
  title        = {Explainable deep learning techniques for wind speed forecasting in coastal areas: Integrating model configuration, regularization, early stopping, and SHAP analysis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel approach for crowd counting combining VGG16 and efficientnetb7 for optimal performance in harsh weather. <em>NCA</em>, <em>37</em>(25), 21193-21217. (<a href='https://doi.org/10.1007/s00521-025-11426-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate crowd counting in highly congested scenes is essential for public safety and effective resource management. The proposed method utilizes the VGG16 architecture enhanced with pretrained weights from EfficientNetB7 and compares its performance against the VGG16, ResNET50, MCNN, and VGG19 models. These models are trained and tested on the ShanghaiTech Part A and Part B datasets, representing densely and sparsely populated scenes under fog and rain, and bad weather conditions. The philosophy of this paper is based on achieving an optimal balance between enhancing image details and reducing noise to ensure high-quality feature extraction. Introducing a novel approach that uses various preprocessing techniques, including cubic interpolation and sharpening filters, to improve the quality and detail of images. After applying bad, harsh weather environments, such as rain and fog, the study analyzed the effect of preprocessing on five algorithms. The optimum results were achieved when concatenating EfficientNetB7 with VGG16 and using standalone VGG16. In contrast, VGG19 showed the poorest performance. This highlights the effectiveness of certain architectures under preprocessing enhancements. Combining the feature extraction power of EfficientNetB7 with VGG16 helps the model handle different crowd densities better. This makes the system more effective at analyzing crowds with varying numbers of people. Experiments show that the VGG16 model with EfficientNetB7 pretrained weights performs much better than the other five models in calculating error loss and the counting process. On the ShanghaiTech Part A and Part B datasets, it achieved a mean absolute error (MAE) of 102.83 compared to an MAE of 142.26 for VGG16 and an MAE of 173.06 for VGG19. This shows that EfficientNetB7 helps VGG16 handle different crowd scales and densities in complex environments more effectively. This highlights the importance of VGG16 in extracting features and achieving strong performance in the crowd counting process, which can be used as a concatenated with a strong architecture. In addition, Mall datasets scored the best metrics with a mean absolute error (MAE) of 0.78 and a mean square error (MSE) of 1.00549. Additionally, two datasets were used in testing, JHU-CROWD + + + and UCF-QNRF. The models were tested under different weather conditions, including rainy and foggy environments. Overall, the testing results were quite satisfactory.},
  archive      = {J_NCA},
  author       = {Elsepae, Heba F. and El-Rabaie, El-Sayed M. and Hamad, Ehab K. I. and El-Hoseny, Heba M.},
  doi          = {10.1007/s00521-025-11426-9},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {21193-21217},
  shortjournal = {Neural Comput. Appl.},
  title        = {Novel approach for crowd counting combining VGG16 and efficientnetb7 for optimal performance in harsh weather},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geometric multimodal learning to support prostate cancer diagnosis on limited and multicentric bi-parametric MRI data. <em>NCA</em>, <em>37</em>(25), 21173-21192. (<a href='https://doi.org/10.1007/s00521-025-11413-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of clinically significant prostate cancer (csPCa) lesions remains one of the most important challenges in prostate cancer diagnosis. For this, multimodal convolutional neural networks (CNNs) have achieved outstanding results. Nevertheless, the data used in these studies may only partially represent the total burden of csPCa cases. Hence, it is necessary to design reliable models that perform well in limited data scenarios and involving information from different centers (multicentric). A deep Riemannian geometric learning architecture was introduced to capture the intermediate relationships between bi-parametric MRI (bp-MRI) deep representations coded from a 3D multimodal convolutional backbone and considering their geometry. For this, several multimodal bp-MRI fusion strategies were explored to assess their ability to classify csPCa lesions in scenarios where the percentage of available training data was progressively reduced and multicentric data were involved. The proposed method outperformed baseline CNN techniques with an AUC-ROC of 0.96. More remarkably, the method remained stable even only using 10% of the available training data. Additionally, considering multicentric information, this approach also demonstrates generalization ability by losing only 5.4% of the AUC testing data from different acquisition centers, compared to the 10.4% loss of the baseline method. A new deep learning-based method that improves generalization under scenarios with limited data translates to better support for clinicians in accurately classifying csPCa lesions on unseen data.},
  archive      = {J_NCA},
  author       = {Olmos, Juan A. and Manzanera, Antoine and Martínez, Fabio},
  doi          = {10.1007/s00521-025-11413-0},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {21173-21192},
  shortjournal = {Neural Comput. Appl.},
  title        = {Geometric multimodal learning to support prostate cancer diagnosis on limited and multicentric bi-parametric MRI data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hardware implementation of a quantized CNN model for early detection of skin cancer cells using hls4ml tool. <em>NCA</em>, <em>37</em>(25), 21147-21171. (<a href='https://doi.org/10.1007/s00521-025-11411-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Like many other cancers, early diagnosis of skin cancer plays an essential role in a patient's survival. The survival rate for different types of skin cancer varies significantly. Early diagnosis of malignant lesions, however, could be expensive and challenging. CNNs (convolutional neural networks) have been utilized in many works in recent researches for medical applications, including cancer detection. Research has shown that skin cancer diagnosis based on CNN classifiers can be as accurate as a dermatologists’ diagnosis. In this paper, several different CNN models, all with similar parameters except different filters for each convolution layer, and different neurons for the first fully connected layer, have been implemented on FPGA. The HAM10000 is utilized as the training dataset, and the SMOTE data augmentation method is applied to it. Models have been implemented using the hls4ml tool, which is an open-source software mainly designed to deploy machine learning models on FPGA. The presented models in this study all have been trained in two different floating-point and quantized format pairs, using Keras and Qkeras frameworks, respectively. Afterward, both versions are fed as input to the hls4ml library and synthesized for FPGA implementations. All the models have been compared thoroughly for accuracy and hardware resource consumption. In the end, considering resource consumption and accuracy simultaneously, a quantized model with a software validation accuracy of 95.50% and hardware-emulated accuracy of 94.90% is proposed to be implemented in the stated conditions.},
  archive      = {J_NCA},
  author       = {Arefi, Ehsan and Mousazadeh, Morteza},
  doi          = {10.1007/s00521-025-11411-2},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {21147-21171},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hardware implementation of a quantized CNN model for early detection of skin cancer cells using hls4ml tool},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extended dissipativity-based finite-time contractive boundedness for delayed discrete-time neural networks via event-triggered approach. <em>NCA</em>, <em>37</em>(25), 21121-21146. (<a href='https://doi.org/10.1007/s00521-025-11399-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a new performance index that examines the extended dissipative criteria in a finite-time contractive boundedness framework for the delayed discrete-time neural networks (DT-NNs). Initially, to avoid unnecessary resource consumption and to govern the information broadcast, the network-induced delay-dependent event-triggered state estimation approach is employed for the considered DT-NNs. In addition, a new discrete inequality for the single summable term is derived based on the generalized free-weighting-matrix inequality and parameter-dependent reciprocally convex inequality. Novel delay-square dependent Lyapunov-based sufficient conditions are employed to obtain the enhanced finite-time extended dissipative performance based on derived summation inequality. Furthermore, an example is provided in both numerical and simulation domains to exemplify the effectiveness of the proposed theoretical approach.},
  archive      = {J_NCA},
  author       = {Adhira, B. and Nagamani, G.},
  doi          = {10.1007/s00521-025-11399-9},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {21121-21146},
  shortjournal = {Neural Comput. Appl.},
  title        = {Extended dissipativity-based finite-time contractive boundedness for delayed discrete-time neural networks via event-triggered approach},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized intrusion detection with deep learning classification models. <em>NCA</em>, <em>37</em>(25), 21091-21119. (<a href='https://doi.org/10.1007/s00521-025-11383-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing sophistication of cyber threats necessitates advanced intrusion detection systems (IDS) capable of adaptive and precise threat mitigation. This study presents an optimized deep learning (DL)-based IDS leveraging a deep neural network (DNN) with rectified linear unit (ReLU) activations and a tabular model utilizing the fastai framework. Both models were trained and evaluated on the NSL-KDD dataset following extensive preprocessing, including feature scaling, outlier handling, and class balancing. The fastai model achieved an accuracy of 84.19%, precision of 85.37%, recall of 83.92%, and F1-score of 84.64%, outperforming the DNN, which attained 79.14% accuracy, 81.25% precision, 78.60% recall, and 79.90% F1-score. Automated feature engineering and tenfold cross-validation were applied to enhance generalization and stability. The results demonstrate that deep learning provides a scalable, high-accuracy IDS framework capable of addressing the dynamic and evolving nature of cyber threats.},
  archive      = {J_NCA},
  author       = {Eldakhly, Nabil M.},
  doi          = {10.1007/s00521-025-11383-3},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {21091-21119},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimized intrusion detection with deep learning classification models},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A generalized leaf disease recognition of various crops and vegetables through computer vision and machine learning. <em>NCA</em>, <em>37</em>(25), 21069-21089. (<a href='https://doi.org/10.1007/s00521-025-11382-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agricultural production is crucial for global economies, yet crop diseases significantly threaten productivity and food security. Traditional manual diagnosis methods are labor-intensive and subjective, leading to inaccurate pesticide applications. Leveraging deep learning, recent advancements have improved disease identification accuracy. However, existing models lack generalization across multiple crops and vegetable diseases. To address this gap, a comprehensive dataset comprising 11 common leaf diseases, such as Anthracnose, Bacterial Blight, Bacterial Spot, Bacterial Wilt, Blast, Downy Mildew, Early Blight, Late Blight, Mosaic, Powdery Mildew, and Rust, affecting 20 widely consumable crops and vegetables, such as rice, wheat, corn, tea, coffee, soybean, potato, tomato, carrot, black gram, pea, cassava, sugarcane, bottle gourd, pepper bell, brinjal, lettuce, cabbage, cauliflower, and cucumber, was curated. Data augmentation techniques expanded the dataset to 16,800 images to enhance the robustness by reducing the overfitting of the deep learning disease recognition model. The dataset is publicly available on GitHub for research purposes. In addition to dataset preparation, this paper introduces a generalized deep learning model for efficient recognition of the leaf diseases of crops and vegetables. Emphasis is placed on optimizing hyperparameters for well-known pre-trained deep learning models, including DenseNet-121, ResNet-50, VGG-16, VGG-19, and Inception-V4. Experimental results using the dataset demonstrate that DenseNet-121 achieved a classification accuracy of 97.58%, surpassing the other models.},
  archive      = {J_NCA},
  author       = {Sultana, Nusrat and Sharmin, Sabrina and Uddin, Mohammad Shorif},
  doi          = {10.1007/s00521-025-11382-4},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {21069-21089},
  shortjournal = {Neural Comput. Appl.},
  title        = {A generalized leaf disease recognition of various crops and vegetables through computer vision and machine learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cultural history optimization algorithm: A new human-inspired metaheuristic algorithm for engineering optimization problems. <em>NCA</em>, <em>37</em>(25), 21009-21068. (<a href='https://doi.org/10.1007/s00521-025-11379-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta-heuristic optimization methods are popular today, but they still face many problems, such as early convergence, weak scalability, and high computing cost. As engineering problems grow larger and more complex, the need for an optimizer that can search broadly, converge quickly, and keep the computation affordable becomes even more urgent. To address these issues, this paper introduces a novel human inspired metaheuristic algorithm, the cultural history optimization algorithm (CHOA), based on cultural history principles. CHOA’s performance is evaluated against 47 benchmark functions and the CEC06−2019 test suite, encompassing large-scale unimodal, multimodal, and fixed-dimension functions. Results demonstrate CHOA’s strong exploration and exploitation capabilities, achieving global optima with rapid convergence and manageable computational cost. Performance metrics, including mean cost, standard deviation, convergence acceleration, and computational burden, are compared with established metaheuristics, highlighting effectiveness. Moreover, Wilcoxon rank-sum tests confirm CHOA’s statistical superiority. As a large-scale design optimization problem, CHOA and state-of-the-art algorithms are applied to optimize a permanent magnet synchronous motor, showcasing CHOA’s local optima avoidance and scalability. Finally, the paper describes a graphical user interface (GUI) developed for CHOA to facilitate its practical application.},
  archive      = {J_NCA},
  author       = {Sharifi, Tohid and Mirsalim, Mojtaba and Soleimanian Gharehchopogh, Farhad and Mirjalili, Seyedali},
  doi          = {10.1007/s00521-025-11379-z},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {21009-21068},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cultural history optimization algorithm: A new human-inspired metaheuristic algorithm for engineering optimization problems},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning-based decision support system for an agile humanitarian relief chain. <em>NCA</em>, <em>37</em>(25), 20983-21007. (<a href='https://doi.org/10.1007/s00521-025-11352-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid item distribution to applicants, increasing decision-making speed, improving decision-making quality, and aiding in planning and prioritizing central distribution point establishment. During severe crises like earthquakes, decisions on locating, allocating, and distributing vital items are crucial for humanitarian relief managers. Items are dispatched to demand areas via central distribution points. Due to limited resources during crises, all central distribution points cannot be set up simultaneously. Hence, prioritizing their establishment is essential. Setting up these points significantly enhances response time and service quality. Agile relief systems are pivotal in improving service quality. Without decision-making tools, comprehensive planning for such issues is challenging. Hence, this study aims to provide a reinforcement learning-based hybrid decision support system for humanitarian relief chains during the crisis to support us in decision-making based on environmental conditions. In this instance, there will be a boost in the velocity and efficiency of the decision-making process. The Q-learning method is the core of processing and computations. The Q-learning method was compared with a random walk, ε -greedy, and simulated annealing algorithms for a simulated problem with high iterations. The comparison results indicate that the algorithm under analysis provides proper efficiency in the routing process. This algorithm was used as the major core of the study to design a hybrid decision support system for earthquake crises.},
  archive      = {J_NCA},
  author       = {Javadi, Babak and Noori, Hossein and Aghaabdollahian, Behnaz},
  doi          = {10.1007/s00521-025-11352-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20983-21007},
  shortjournal = {Neural Comput. Appl.},
  title        = {Reinforcement learning-based decision support system for an agile humanitarian relief chain},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aftina: Enhancing stability and preventing hallucination in AI-based islamic fatwa generation using LLMs and RAG. <em>NCA</em>, <em>37</em>(25), 20957-20982. (<a href='https://doi.org/10.1007/s00521-025-11229-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question–answering (QA) systems face considerable challenges when involved in Islamic fatwas due to the complexity and sensitivity of the data. Such problems involve providing accurate and reliable responses, managing hallucinations and inaccurate responses, and maintaining the stability of the generated responses. Prior studies have concentrated mainly on collecting and preprocessing Islamic datasets or developing retrieval-based QA systems, overlooking the precision and reliability required for fatwa issuance. To address this issue, we propose a QA approach utilizing advanced retrieval-augmented generation (RAG), which is enhanced by a re-ranker to increase response stability, eliminate hallucinations, and prioritize the most appropriate and exact answer. This enhancement significantly improves response stability and reduces hallucinations by improving the data used for answer generation. We conducted experiments across three setups: (1) base LLM, (2) LLM with RAG, and (3) LLM with RAG and re-ranker. The third method of LLM with RAG includes a re-ranker for knowledge retrieval, which improves the process and ensures relevant and trustworthy data. This differentiates it from the second method, which uses a retrieval model. The Flash re-ranker retrieves the most relevant data, which increases the response stability and trustworthiness. Evaluations using BERTScore, hallucination, completeness, and irrelevance metrics demonstrated that the third experiment LLM with RAG and re-ranker outperformed other setups, providing precise, stable, and dependable answers. This research contributes a robust methodology to improve AI-driven fatwa systems, guaranteeing higher precision and trustworthiness in Islamic QA systems.},
  archive      = {J_NCA},
  author       = {Mohammed, Marryam Yahya and Ali, Sama Ayman and Ali, Salma Khaled and Majeed, Ayad Abdul and Mohamed, Ensaf Hussein},
  doi          = {10.1007/s00521-025-11229-y},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20957-20982},
  shortjournal = {Neural Comput. Appl.},
  title        = {Aftina: Enhancing stability and preventing hallucination in AI-based islamic fatwa generation using LLMs and RAG},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A panorama of text summarization research: Bibliometric trends and developments (2000–2024). <em>NCA</em>, <em>37</em>(25), 20917-20956. (<a href='https://doi.org/10.1007/s00521-025-11562-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A detailed bibliometric analysis of text summarization research from 2000 to 2024 is performed in this study. It tracks the growth of the field, identifies key contributors, and examines collaborative networks that have shaped the development of text summarization technologies. The analysis shows a significant rise in publication volume, particularly in the last decade, driven by advancements in natural language processing and AI. China, India, and the USA emerge as major contributors, with notable institutions and researchers leading the field. Research themes have evolved from foundational topics to advanced AI-driven approaches like deep learning and abstractive summarization. The study also highlights the global and collaborative nature of research, with extensive partnerships across institutions and countries. The findings offer valuable insights into the current state and future directions of text summarization research, providing a solid foundation for further exploration and development. Data are gathered from major academic databases like Scopus, ACM, and IEEE Xplore and filtered through a rigorous selection process to create a comprehensive dataset. Bibliometric methods analyzed publication trends, key sources, and geographical contributions. The structural topic model identified principal research themes, while the Mann–Kendall test examined trends in these themes over time. Social network analysis visualized collaborations among scholars and institutions. Key research themes include multihead attention mechanisms, graph-based semantic analysis, and topic modeling techniques, with emerging trends highlighting interest in self-supervised learning, zero-shot learning, and transformer models. This study offers valuable insights and serves as a useful resource for researchers and practitioners, enhancing the understanding of current and future directions in text summarization.},
  archive      = {J_NCA},
  author       = {Kumari, Namrata and Singh, Pardeep},
  doi          = {10.1007/s00521-025-11562-2},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20917-20956},
  shortjournal = {Neural Comput. Appl.},
  title        = {A panorama of text summarization research: Bibliometric trends and developments (2000–2024)},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Auto language identifier and text aligner using neural network. <em>NCA</em>, <em>37</em>(25), 20897-20916. (<a href='https://doi.org/10.1007/s00521-025-11390-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural Language Processing aims to facilitate computers to comprehend and refine human languages for some real-world as well as valuable objectives. While thousands of languages are spoken worldwide, language translation has been an utmost demanding and thought-provoking area of research. Researchers have been fruitful not only in representing these languages using machines but also in examining the elementary structure of these languages as reported by Niraj Aswani (in: Aligning sentences and words using English–Hindi bilingual parallel corpora). This research aims to develop a bilingual automatic AI-based text aligner using neural networks. The system inputs a text file from the user which comprises bilingual miscellaneous sentences. The bilingual text is processed based on the text sentences. The.csv file downloaded as the output consists of sentences placed adjacent to their equivalent sentences. In this, we will be working primarily with two languages English and Hindi. In this paper, we present a method for aligning English sentences with their corresponding Hindi translations at the sentence level, utilizing natural language processing and AI techniques. This approach aims to address a significant challenge in developing language models for various Indian languages, primarily due to the scarcity of aligned parallel bilingual data. In the results section, we will demonstrate the accuracy and efficiency of these models for English and Hindi, with potential applications for other Indian languages as well. The methodologies described above are typically based on either sentence length or word correspondences. Sentence-length-based approaches are generally faster and offer reasonable accuracy, while word correspondence methods tend to be more precise but are significantly slower, often relying on cognates or a bilingual lexicon. Our technique synthesizes and enhances these approaches, creating a system designed to align sentences in an English–Hindi corpus. This method achieves high accuracy at a relatively low computational cost, aiming to produce large-scale, high-quality aligned sentences between English and Hindi.},
  archive      = {J_NCA},
  author       = {Singh, Shashi Pal and Tiwari, Ritu and Sharma, Sanjeev},
  doi          = {10.1007/s00521-025-11390-4},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20897-20916},
  shortjournal = {Neural Comput. Appl.},
  title        = {Auto language identifier and text aligner using neural network},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HFCANet: Heterogeneous feature driven cascade association network for multiple object tracking. <em>NCA</em>, <em>37</em>(25), 20879-20895. (<a href='https://doi.org/10.1007/s00521-025-11518-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing multi-object tracking (MOT) methods integrate object motion and appearance features to improve tracking performance. However, these methods often exhibit sub-optimal tracking performance when facing objects with diverse poses, similar appearances, or nonlinear motions. Especially in crowded scenarios, the frequent occlusion between objects leads to an increase in the discontinuity of the trajectories, thus lagging the tracking performance. Motivated by this, we propose a heterogeneous feature driven cascade association network (HFCANet). Specifically, we design a triple heterogeneous feature extraction (THFE) module to capture more discriminative features of objects, which can realize accurate object representation even in the presence of drastic changes in scale, pose, and background. In addition, to retrieve the fragmented trajectory of the occluded object for more complete tracking, we introduce an easy-to-hard cascade association policy that analyzes heterogeneous cues to determine whether the detected object can be re-corrected into the trajectory. HFCANet comprehensively considers the heterogeneous cues of objects, encompassing the nonlinear motion and the richness of limb movements. This characteristic makes it especially well-suited for fulfilling tracking requirements in scenes with dense pedestrians and frequent occlusions. Extensive experiments and ablation studies conducted on MOT17, MOT20, and DanceTrack demonstrate the effectiveness of our proposed HFCANet, where ours has achieved better performance compared to existing state-of-the-art (SOTA) methods.},
  archive      = {J_NCA},
  author       = {Li, Hui and Guo, Ying and Qin, Su and Li, Rui and Gao, Ying},
  doi          = {10.1007/s00521-025-11518-6},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20879-20895},
  shortjournal = {Neural Comput. Appl.},
  title        = {HFCANet: Heterogeneous feature driven cascade association network for multiple object tracking},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on 1-bit quantized large language models. <em>NCA</em>, <em>37</em>(25), 20823-20878. (<a href='https://doi.org/10.1007/s00521-025-11529-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have gained significant popularity, with various models demonstrating different domains and intelligence. Deep learning methods, especially neural networks, are used to build LLMs, and their training requires enormous volumes of data. They have significantly advanced natural language processing (NLP), enabling applications like chatbots, virtual assistants, language translation, and content generation. However, training LLMs is computationally intensive due to large model sizes, extensive datasets, iterative processes, specialized hardware, and high energy consumption. To address these challenges, quantization has been introduced. This process reduces the precision of numerical values, such as weights and activations, thereby decreasing memory and computational requirements. But this technique can affect model performance negatively, therefore, recent research focuses on minimizing accuracy loss. Techniques like mixed precision training and adaptive quantization have been developed to balance efficiency and performance. This paper surveys the existing 1-bit quantization approaches, providing insights and recommendations for future work. The goal is to enable the efficient and cost-effective deployment of LLMs without compromising their performance, broadening their accessibility and applicability.},
  archive      = {J_NCA},
  author       = {Tripathi, Kritika and Malik, Devanshi and Akshat, Abhi and Lata, Kusum},
  doi          = {10.1007/s00521-025-11529-3},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20823-20878},
  shortjournal = {Neural Comput. Appl.},
  title        = {A survey on 1-bit quantized large language models},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Best practices for responsible machine learning in credit scoring. <em>NCA</em>, <em>37</em>(25), 20781-20821. (<a href='https://doi.org/10.1007/s00521-025-11520-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread use of machine learning in credit scoring has brought significant advancements in risk assessment and decision-making. However, it has also raised concerns about potential biases, discrimination, and lack of transparency in these automated systems. This tutorial paper performed a non-systematic literature review to guide best practices for developing responsible machine learning models in credit scoring, focusing on fairness, reject inference, and explainability. We discuss definitions, metrics, and techniques for mitigating biases and ensuring equitable outcomes across different groups. Additionally, we address the issue of limited data representativeness by exploring reject inference methods that incorporate information from rejected loan applications. Finally, we emphasize the importance of transparency and explainability in credit models, discussing techniques that provide insights into the decision-making process and enable individuals to understand and potentially improve their creditworthiness. By adopting these best practices, financial institutions can harness the power of machine learning while upholding ethical and responsible lending practices.},
  archive      = {J_NCA},
  author       = {Valdrighi, Giovani and M. Ribeiro, Athyrson and S. B. Pereira, Jansen and Guardieiro, Vitoria and Hendricks, Arthur and Miranda Filho, Décio and Nieto Garcia, Juan David and F. Bocca, Felipe and B. Veronese, Thalita and Wanner, Lucas and Medeiros Raimundo, Marcos},
  doi          = {10.1007/s00521-025-11520-y},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20781-20821},
  shortjournal = {Neural Comput. Appl.},
  title        = {Best practices for responsible machine learning in credit scoring},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced deep-style interpreter for automatic synthesis of annotated medical images. <em>NCA</em>, <em>37</em>(25), 20755-20780. (<a href='https://doi.org/10.1007/s00521-025-11516-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Creating an annotated medical image dataset is challenging and traditionally reliant on labor-intensive manual annotations. Additionally, these datasets often present substantial imbalances regarding sensing devices, class of medical disorders, and patient ethnicity and phenotype. Recently, there has been a research interest in mitigating these issues by employing data augmentation with generative models. However, the quality of images and semantics in medical image datasets are critical for computer vision tasks such as image segmentation. This paper presents DatasetGAN2-ADA, which aims to mitigate these difficulties by presenting an innovative deep-style interpreter robust against anomalous synthesis and designed to automate annotated image generation entirely. By leveraging the capabilities of StyleGAN2-ADA with an improved architecture of DatasetGAN and an enhanced execution framework integrated with an anomaly detector based on custom features, we propose a combined strategy for eliminating flawed synthetic images and masks. Furthermore, we propose exploiting image projections and preexisting semantics, eliminating the need for manual annotations to train our deep-style interpreter. The experimental results obtained with a magnetic resonance image (MRI) dataset demonstrate that DatasetGAN2-ADA is strongly effective in improving the efficiency and quality of synthetic generation, rejecting the synthesis of a substantial amount of low-quality images and masks. Then, an extension of this method is evaluated for detecting anomalous latent vectors a priori of the image synthesis, achieving up to 95.24% precision and illustrating its compelling potential for practical applications in medical imaging.},
  archive      = {J_NCA},
  author       = {Pacheco dos Santos Lima Junior, Marcos Sergio and Ortiz-de-Lazcano-Lobato, Juan Miguel and Fernández-Rodríguez, José David and López-Rubio, Ezequiel},
  doi          = {10.1007/s00521-025-11516-8},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20755-20780},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhanced deep-style interpreter for automatic synthesis of annotated medical images},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic literature review on the application of artificial intelligence techniques for rock strength estimation. <em>NCA</em>, <em>37</em>(25), 20721-20753. (<a href='https://doi.org/10.1007/s00521-025-11517-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a systematic literature review on the prediction of unconfined compressive strength (UCS) and elastic modulus (E) with artificial intelligence (AI) models. The study categorises three essential parts: (1) a combination of physical and mechanical properties, (2) mechanical properties, and (3) physical properties as input parameters for AI models in estimating UCS and E. The review selection was based on search keywords using title-abstract, full-text, and keywords from Scopus and Web of Science online database libraries. A total of 131 peer-reviewed research articles published from 2014 to 2024 were critically reviewed to provide answers to research-related questions related to current advancements in the prediction of UCS and E with AI models. Among the AI technologies analysed, artificial neural networks (ANN) and ANN-based models stand out as the most used AI algorithms; other algorithms, including ANFIS, RF, SVM, and XGBoost model, have been used at significant levels in predicting UCS and E with high prediction accuracy of R2 greater 0.90 with minimum mean error margins. The ANN (24.7%), ANFIS (11.7%), and RF (7.6%) have been essentially employed in many research studies to predict rock strength. The study combined mechanical and physical properties with AI models at approximately 59%, and after that, mechanical properties at 23.6%. The efficiency of AI algorithms and their application is associated with the usage of data and input parameters. This review recommends future study gaps and places emphasis on integrating rock mechanics, physical laws (Mohr–Coulomb and Hoek–Brown failure criteria) and adaptive AI techniques to advance the adaptability and reliability in predicting rock strength and deformation characteristics.},
  archive      = {J_NCA},
  author       = {Akosah, Stephen and Gratchev, Ivan and Gidigasu, Solomon S. R.},
  doi          = {10.1007/s00521-025-11517-7},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20721-20753},
  shortjournal = {Neural Comput. Appl.},
  title        = {A systematic literature review on the application of artificial intelligence techniques for rock strength estimation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effective non-random extreme learning machine. <em>NCA</em>, <em>37</em>(25), 20691-20719. (<a href='https://doi.org/10.1007/s00521-025-11519-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extreme learning machine (ELM) is a growing statistical technique widely applied to regression problems. In essence, ELMs are single-layer neural networks where the hidden layer weights are randomly sampled from a specific distribution, while the output layer weights are learned from the data. Two of the key challenges with this approach are the architecture design, specifically determining the optimal number of neurons in the hidden layer, and the method’s sensitivity to the random initialization of hidden layer weights. This paper introduces a new and enhanced learning algorithm for regression tasks, the Effective Non-Random ELM (ENR-ELM), which simplifies the architecture design and eliminates the need for random hidden layer weight selection. The proposed method incorporates concepts from signal processing, such as basis functions and projections, into the ELM framework. We introduce two versions of the ENR-ELM: the approximated ENR-ELM and the incremental ENR-ELM. Experimental results on both synthetic and real datasets demonstrate that our method overcomes the problems of traditional ELM while maintaining comparable predictive performance.},
  archive      = {J_NCA},
  author       = {De Canditiis, Daniela and Veglianti, Fabiano},
  doi          = {10.1007/s00521-025-11519-5},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20691-20719},
  shortjournal = {Neural Comput. Appl.},
  title        = {Effective non-random extreme learning machine},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel medical image security and compression based on multiple-order fractional quaternion hahn moments and 2D-chaotic map. <em>NCA</em>, <em>37</em>(25), 20663-20690. (<a href='https://doi.org/10.1007/s00521-025-11523-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objectives: Medical image analysis is essential for quick and accurate diagnosis and treatment. Nowadays, the uses of medical images for the treatment of patients and diagnosis purposes are sent over the internet. So, they should be protected from cyber attackers. These medical images are sensitive to any minor changes, and the data volume is rapidly increasing. Thus, security and storage costs must be considered in medical images. Traditional encryption and compression methods are ineffective for encrypting medical images due to their high execution time and algorithm complexity. Methods: This paper proposes a novel 2D chaotic map and generates the GS sequence in the multiple-order fractional quaternion Hahn moments matrix for generating encryption keys and improving security. The proposed algorithm uses the 2D chaotic map to generate the private key and diffusion process. The pixel values of the original images in the proposed schemes are shuffled using Mersenne Twister (MT) to improve the security of medical images. In this proposed scheme, the Differential Huffman Compression (DHC) method is used for lossless compression while performing XOR-based encryption. Findings: The proposed model has been tested on different color medical images, namely the Computed Tomography (CT) dataset, and Magnetic Resonance Imaging (MRI) dataset. It has been evaluated using performance metrics, such as entropy, key space, histogram analysis, key sensitivity, robustness analysis, correlation, and similarity analysis. The outcomes demonstrate that the proposed scheme is more effective than the other comparable schemes. Novelty: This research pioneers the study of innovative medical image security and compression techniques, married with methods development based on multiple-order fractional quaternion Hahn moments, 2D-Chaotic Map, and DHC for handling the storage cost of medical images. Our findings highlight a crucial aspect of healthcare namely the secure and efficient transfer of medical data, specifically between the radiology department and radiologists. This is vital for patient care, diagnostic accuracy, and maintaining data privacy.},
  archive      = {J_NCA},
  author       = {El Ogri, Omar and EL-Mekkaoui, Jaouad and Benslimane, Mohamed},
  doi          = {10.1007/s00521-025-11523-9},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20663-20690},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel medical image security and compression based on multiple-order fractional quaternion hahn moments and 2D-chaotic map},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An explainable deep learning-based panoptic segmentation for brain tumor diagnosis. <em>NCA</em>, <em>37</em>(25), 20639-20662. (<a href='https://doi.org/10.1007/s00521-025-11459-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor segmentation (BTS) is a critical task for the accurate diagnosis and treatment of brain tumors. Manual detection poses significant challenges due to the complex anatomy and the variations in tumor types, sizes, shapes, and locations. Computer-aided diagnostic techniques have gained popularity for assisting healthcare providers in diagnosing diseases and improving the consistency and accuracy of their findings. This study introduces a novel hybrid PA-ResNet50 deep learning approach for explainable panoptic brain tumor segmentation (PBTS), integrating both instance and semantic segmentation to achieve detailed tumor boundary delineation while addressing uncertainties in brain imaging. Unlike conventional segmentation methods, our approach leverages panoptic segmentation with uncertainty modeling, enhancing both interpretability and robustness. The primary objective is to reduce the uncertainties in brain imaging, thereby increasing tumor identification accuracy and boosting the confidence of medical professionals. Evaluation results demonstrate that the proposed framework enhances both the interpretability of the results and the precision of brain tumor segmentation. Our model achieved an accuracy of 99.3 and 98.7%, Dice scores of 99.29 and 98.85% and computational times of 13 and 27 s for the BraTS 2019 and BraTS 2021 datasets, respectively. This method not only improves segmentation precision but also enhances the interpretability and reliability of tumor diagnoses, providing a trustworthy, explainable AI-driven solution for clinical decision-making.},
  archive      = {J_NCA},
  author       = {Shaheema, Berlin and Muppalaneni, Naresh Babu and Devi, K. Suganya},
  doi          = {10.1007/s00521-025-11459-0},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20639-20662},
  shortjournal = {Neural Comput. Appl.},
  title        = {An explainable deep learning-based panoptic segmentation for brain tumor diagnosis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An integrated biomedical images security approach to secure healthcare system. <em>NCA</em>, <em>37</em>(25), 20617-20637. (<a href='https://doi.org/10.1007/s00521-025-11389-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart healthcare holds immense potential to revolutionize the healthcare industry, promoting patient-centric care, preventive medicine, and improved health outcomes. By harnessing the power of advanced technologies and data-driven solutions, healthcare providers can deliver more efficient, accessible, and personalized healthcare services, ultimately transforming the approach and experience of healthcare. Biomedical images have now become the new support for better diagnosis in the medical field. In the area of image security, perceptual hashing provides a powerful approach to enhancing the security of medical images by creating compact and unique representations of their visual content. This paper proposes a framework for smart healthcare where biomedical images are secured with perceptual hashing. In this framework, an authentication module is also deployed to verify the identity of smart users allowed to access the biomedical images over the edge or cloud layers. The performance analysis of the hashing module is evaluated using the structural similarity index measure (SSIM), peak signal-to-noise ratio (PSNR), bit error rate (BER), and Hausdorff distance. Additionally, the performance analysis of the authentication module is evaluated in terms of a system accuracy of 89% and a probability of identification of 0.45 to establish authentication.},
  archive      = {J_NCA},
  author       = {Shreya, Shashi and Chatterjee, Kakali and Singh, Ashish},
  doi          = {10.1007/s00521-025-11389-x},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20617-20637},
  shortjournal = {Neural Comput. Appl.},
  title        = {An integrated biomedical images security approach to secure healthcare system},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TLBEMSE: Design of a transfer learning-based bioinspired ensemble model for preemptive detection of stress and emotional disorders. <em>NCA</em>, <em>37</em>(25), 20591-20616. (<a href='https://doi.org/10.1007/s00521-025-11160-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalogram signals are used to depict emotional and stress disorders. To overcome issues of existing models, novel transfer learning-based bioinspired ensemble model for preemptive detection of stress and emotional disorders is discussed. The proposed model includes features of mel-frequency cepstral coefficient, iVector, cosine, Fourier and wavelet components. A combination of these features is processed via gray wolf optimization which aims at variance maximization across. The selected features are converted into 2D representation and processed via a transfer learning-based convolutional neural network model combining ResNet 101, MobileVNet, and YoLo models. The classified results from these models are further cross-validated via use of ensemble classification that combines Naïve Bayes, support vector machine, random forest, logistic regression, and multilayer perceptron models. These classifiers perform several post-processing tasks involving identification of disease spread probability, estimation of future diseases, etc. The proposed model was trained on DEAP and interface datasets, compared w.r.t. various state-of-the-art methods, in relation to accuracy, recall, precision, area under the curve, and delay performance. Based on this performance, proposed model’s effectiveness was noticed, showcasing 8.5% higher accuracy, 8.3% higher precision, 5.9% better recall, 4.5% better AUC, and 14.9% faster classification performance, which makes it highly useful for clinical deployments.},
  archive      = {J_NCA},
  author       = {Hole, Komal Rajendra and Anand, Divya and Mohanty, Sachi Nandan and Rathore, Rajkumar Singh and lvarez, Roberto Marcelo},
  doi          = {10.1007/s00521-025-11160-2},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20591-20616},
  shortjournal = {Neural Comput. Appl.},
  title        = {TLBEMSE: Design of a transfer learning-based bioinspired ensemble model for preemptive detection of stress and emotional disorders},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing patient-independent detection of freezing of gait in parkinson’s disease with deep adversarial network. <em>NCA</em>, <em>37</em>(25), 20569-20589. (<a href='https://doi.org/10.1007/s00521-025-11068-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Freezing of gait (FoG) refers to sudden, relatively brief episodes of gait arrest in Parkinson’s disease, known to manifest in the advanced stages of the condition. Events of freezing are associated with tumbles, traumas, and psychological repercussions, significantly impacting the patient’s quality of life. The use of accelerometer data derived from sensors put on a patient’s body to detect FoG has previously been proposed using convolutional neural network (CNN)-based deep learning algorithms. Here, we combine a CNN + Long short-term Memory (LSTM)-attention model to detect FoG episodes—a first for the detection of FoG using the accelerometer data. CNN facilitates automatic feature extraction from the accelerometer data itself. The output from the CNN is fed to the LSTM network, which is known for capturing sequential information. Further, the attention mechanism introduces relative focus on individual sub-sequences during the training of the LSTM network. The proposed model is made patient independent using adversarial training. The proposed model achieved improvements of +7.60% (without adversarial training) and + 8.36% (with adversarial training) in the sensitivity values over state of the art. This is obtained with little or no compromise in specificity values. The corresponding improvements in accuracy values are +3.81 and +2.23%, respectively. These findings imply that the proposed method can detect FoG gaits satisfactorily and can be effective in achieving accurate monitoring and gait assistance for Parkinson’s disease patients during daily life and rehabilitation therapy.},
  archive      = {J_NCA},
  author       = {Fahad, Md Shah and Ranjan, Ashish and Kumar, Gautam},
  doi          = {10.1007/s00521-025-11068-x},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20569-20589},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing patient-independent detection of freezing of gait in parkinson’s disease with deep adversarial network},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MFI3D: Masked face identification with 3D face reconstruction and deep learning. <em>NCA</em>, <em>37</em>(25), 20551-20567. (<a href='https://doi.org/10.1007/s00521-024-10582-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Masked face identification (MFI) aims to identify human faces that are obscured by masks or occluding objects. Today’s common practice of wearing masks imposes significant barriers to facial recognition systems that rely on an unobstructed view of the face. To address this challenge, this paper introduces MFI 3D-based deep learning model (MFI3D) to identify occluded faces. Three main architectural components provide a set of discriminant features to decide the face identity, which are synthetic face masking, face unmasking with generator and discriminator, and 3D face reconstruction. The MFI3D pipeline begins by creating a syntactic mask for the face image, simulating real-world situations where the face is partially covered by the mask. Then, effective face detection is applied using a generator that learns to generate unmasked images that are indistinguishable from true unmasked images, and a discriminator that learns to distinguish real images from fake images. As a result, the MFI model can learn to reconstruct facial features from partially masked faces. The use of 3D face reconstruction techniques to generate a detailed model of faces leverages 3D geometry to extract facial features that are not visible in 2D image, providing a superior visual facial representation. Finally, the reconstructed face is matched against a collection of known people to determine their identity. Extensive experiments were conducted on facial datasets reconstructed orderly to build a diverse collection of 3D reconstructed facial images with a benchmarking ground truth. The experimental results show the superiority of the proposed MFI3D model in identifying people with occluded faces, achieving a precision of 83.50%.},
  archive      = {J_NCA},
  author       = {Alzu’bi, Ahmad and Albalas, Firas and Al-Hadhrami, Tawfik and Albashayreh, Amjad and Younis, Lojin Bani},
  doi          = {10.1007/s00521-024-10582-8},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20551-20567},
  shortjournal = {Neural Comput. Appl.},
  title        = {MFI3D: Masked face identification with 3D face reconstruction and deep learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatiotemporal context feedback bidirectional attention network for breast cancer segmentation based on DCE-MRI. <em>NCA</em>, <em>37</em>(25), 20535-20549. (<a href='https://doi.org/10.1007/s00521-024-10528-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is a highly heterogeneous, both between patients (inter-tumor) and within individual tumors (intra-tumor), leads to indistinct boundaries and varying sizes, shapes, appearances and densities of tumors. Current 3D structural imaging-based methods face challenges to segment breast cancer. The key ingredient to the problem is how to exploit the temporal correlations of 4D functional imaging that depict the heterogeneity of vascular permeability in cancer for accurate tumor segmentation. In this paper, we propose a unique spatiotemporal context feedback bidirectional attention network, which segments breast cancer by modeling dynamic contrast-enhanced dependency to exploit pharmacokinetics feature representations. Specifically, we design a temporal context feedback encoder to learn pharmacokinetics feature representations, which embeds bidirectional temporal attention for bidirectionally propagating contextual semantics across time sequences. Additionally, learned representations are fed into a temporal context feedback decoder to obtain a voxel-level classification of breast tumors. Experimental results demonstrated that the proposed method outperforms recent tumor segmentation methods. Furthermore, our approach achieves competitive results on a small training data and avoids the over-fitting phenomenon due to the model-driven skill to capture dynamic contrast-enhanced temporal correlations.},
  archive      = {J_NCA},
  author       = {Pan, Xiang and Lv, Tianxu and Liu, Yuan and Li, Ningjun and Li, Lihua and Zhang, Yan and Ni, Jianming and Jiang, Chunjuan},
  doi          = {10.1007/s00521-024-10528-0},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20535-20549},
  shortjournal = {Neural Comput. Appl.},
  title        = {Spatiotemporal context feedback bidirectional attention network for breast cancer segmentation based on DCE-MRI},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lung disease classification using deep learning and genetic algorithm. <em>NCA</em>, <em>37</em>(25), 20519-20534. (<a href='https://doi.org/10.1007/s00521-024-10527-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung disorders are medical conditions that disrupt the lungs and their capacity to function normally. One fatal lung disease is a collapsed lung where the lung collapses partially or fully due to diseases like pneumothorax and atelectasis. The conventional approach to detecting such diseases is time-consuming, often requiring extensive manual analysis by trained experts, leading to delays in diagnosis and treatment. Computer-aided diagnostics have the potential to aid doctors in enhancing the consistency of diagnoses while also optimizing time efficiency. In this study, we enhance each lung X-ray image with three image enhancement techniques (i) contrast-limited adaptive histogram equalization (CLAHE), (ii) discrete wavelet transform (DWT), and (iii) gamma correction (GC) in parallel. A 3-channel convolutional neural network (CNN) then uses those enhanced images to extract features. The extracted features are further optimized using a genetic algorithm to improve the efficiency of the classification models. Our proposed model is validated with a dataset containing 9391 X-ray images to achieve an average precision, recall, and F1-score of 98, 97, and 98% and best accuracy of 99.33% which shows an improvement of 2.03% in terms of accuracy over the existing state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Chutia, Upasana and Tewari, Anand Shanker and Singh, Jyoti Prakash},
  doi          = {10.1007/s00521-024-10527-1},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20519-20534},
  shortjournal = {Neural Comput. Appl.},
  title        = {Lung disease classification using deep learning and genetic algorithm},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retinal fundus image enhancement using an ensemble framework for accurate glaucoma detection. <em>NCA</em>, <em>37</em>(25), 20499-20517. (<a href='https://doi.org/10.1007/s00521-024-10500-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal fundus imaging plays a crucial role in the diagnosis of ophthalmic diseases such as glaucoma, a significant cause of vision loss worldwide. Accurate detection of glaucoma using image processing, machine learning, and deep learning approaches depends on the effectiveness with which the retinal fundus images are captured. Poor-quality images with artifacts, including uneven illumination, blur, and color distortion, can lead to incorrect diagnoses. In this work, we propose an end-to-end glaucoma detection model based on the ensemble of image enhancement networks, segmentation networks, and image classification networks. The proposed approach consists of an improved version of generative adversarial network (GAN) called the cycle consistency GAN (cycle-GAN) for image quality enhancement, U-Net for optic cup and optic disc segmentation, and support vector machine for image classification. The cycle-GAN model uses autoencoders as generators and a deep convolutional neural network (CNN) as discriminators to generate high-quality fundus images. The cup-to-disc ratio, a popular feature, is utilized to categorize fundus images as either glaucomatous or non-glaucomatous. We use six imbalanced datasets for experimental analysis of the proposed ensemble model, including ORIGA, ACRIMA, DRISTI-GS, REFUGE, Messidor, and Mendeley. The experimental findings demonstrate that the proposed ensemble model works better than individual models such as GAN, Autoencoder, deep CNN, and also from existing methods. The proposed method not only reduces the artifacts from fundus images but also solves the problem of imbalanced datasets for accurate glaucoma detection. The experimental results show maximum accuracy, precision, recall, and F-measure values of 0.968, 0.821, 0.974, and 0.891, respectively.},
  archive      = {J_NCA},
  author       = {Lenka, Satyabrata and Mayaluri, Zefree Lazarus and Panda, Ganapati},
  doi          = {10.1007/s00521-024-10500-y},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20499-20517},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retinal fundus image enhancement using an ensemble framework for accurate glaucoma detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attaining an IoMT-based health monitoring and prediction: A hybrid hierarchical deep learning model and metaheuristic algorithm. <em>NCA</em>, <em>37</em>(25), 20481-20498. (<a href='https://doi.org/10.1007/s00521-023-09293-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Medical Things (IoMT) visualizes a network of medical devices and society adopting wireless communications to enable interchange of healthcare data. IoMT is utilized to gather real-time data from medical equipment and sensors. This enables possibility for continuous health monitoring and prediction. There is concern related to potential privacy and safety hazards connected with the group and transmission of sensitive health data over the network. This study proposes a hybrid hierarchical deep learning (DL) model enhanced with features and a metaheuristic algorithm to achieve health monitoring and prediction based on IoMT. The information gained from the analysis helps to identify important features for prediction. The feature selection phase applies Self-regularized Quantum Coronavirus Optimization Algorithm (SQCOA) to prioritize important features for prediction. The prediction phase includes Optimized Long Short-Term Memory (OLSTM) and Hierarchical Convolutional Spiking Neural Network (HCSNN) for feature learning and performance prediction, respectively. The proposed model is simulated by adopting MATLAB. The model attains the highest accuracy of 98%.},
  archive      = {J_NCA},
  author       = {Shukla, Prashant Kumar and Alqahtani, Ali and Dwivedi, Ashish and Alqahtani, Nayef and Shukla, Piyush Kumar and Alsulami, Abdulaziz A. and Pamucar, Dragan and Simic, Vladimir},
  doi          = {10.1007/s00521-023-09293-3},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20481-20498},
  shortjournal = {Neural Comput. Appl.},
  title        = {Attaining an IoMT-based health monitoring and prediction: A hybrid hierarchical deep learning model and metaheuristic algorithm},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AMIAC: Adaptive medical image analyzes and classification, a robust self-learning framework. <em>NCA</em>, <em>37</em>(25), 20451-20479. (<a href='https://doi.org/10.1007/s00521-023-09209-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive self-learning is a promising technique in medical image analysis that enables deep learning models to adapt to changes in image distribution over time. As medical image data can vary due to factors like imaging equipment and patient demographics, adaptive self-learning becomes valuable for maintaining the accuracy and robustness of deep learning frameworks. Initially trained on a large dataset, the framework can adapt to new modalities using transfer learning, adaptive learning, and incremental learning, incorporating both manual and auto (CNN-based) features. Adaptive self-learning offers various benefits, including improved model accuracy and efficiency, reducing the need for manual retraining. However, challenges such as the risk of overfitting, acquiring relevant manual features, and careful monitoring need to be addressed. Combining manual features and pretrained CNN models can enhance performance in medical image analysis tasks such as tumor classification, lesion detection, and cancer segmentation. Manual features capture specific image characteristics, while pretrained CNN models automatically learn abstract features from extensive datasets. Combining these approaches provides additional information that neither approach alone can capture. In this study, we present a unique framework for adaptive self-learning in medical image analysis and classification. The proposed framework analyzes image modality, applies preprocessing techniques, and acquires both manual and CNN-based pertinent features. However, careful tuning and experimentation are essential to determine the optimal combination of manual features with the appropriate CNN model architecture. The recommended adaptive self-learning framework achieves a high averaged F1-score $$97.35\pm 0.39$$ and precision of $$97.19 \pm 0.51$$ , as well as its fantabulous abstraction and accuracy of $$97.81 \pm 0.35$$ , implying that it might be used to build a pathologist’s aid tool.},
  archive      = {J_NCA},
  author       = {Iqbal, Saeed and Qureshi, Adnan N. and Aurangzeb, Khursheed and Alhussein, Musaed and Haider, Syed Irtaza and Rida, Imad},
  doi          = {10.1007/s00521-023-09209-1},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20451-20479},
  shortjournal = {Neural Comput. Appl.},
  title        = {AMIAC: Adaptive medical image analyzes and classification, a robust self-learning framework},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved content-based brain tumor retrieval for magnetic resonance images using weight initialization framework with densely connected deep neural network. <em>NCA</em>, <em>37</em>(25), 20437-20450. (<a href='https://doi.org/10.1007/s00521-023-09149-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Content-based medical image retrieval (CBMIR) systems can assist and help doctors and radiologists in reliable diagnosis by retrieving relevant medical cases from past cases that share similarities with the current case. Therefore, there is a need for improved retrieval accuracy in CBMIR systems. Retrieving similar Brain Tumor magnetic resonance imaging (MRI) slices from the same class as the query is inherently challenging. For different types of tumors, there is no class-specific structure, size or shape. Further, MRIs being present in multiple views increase discrepancy in interview retrieval. This leads to high inter-class similarity but at the same time high intra-class variations. Skewed data quantities for Brain Tumor types like Meningioma further add to another challenge. It is necessary to formulate rich and generic MRI representations to address these issues. Toward the same, it is essential to model spatial contexts on a multi-scale across the tumor-affected regions and enhances the feature representational learning by extracting generic features. Hence, we propose a Weight Initialization Framework with Densely Connected Networks to improve generalization for Brain Tumor MRI retrieval. The proposed framework uplifts DenseNet-based models for feature extraction as they incorporate feature reuse and feature learning in a multi-scale manner. Further, a weight Initialization Framework (WIF) is used for improvising the representational learning. Specifically, WIF initializes weights of the DenseNet model by transfer learning-based adaptation, which then involves freezing the initial few layers. The freezing step ensures rich low-level features, even for long-tailed classes like Meningioma, while the remaining trainable layers are fine-tuned to incorporate domain-inherent feature learning. The proposed approach outperforms state-of-the-art by a margin of 1.70% and 1.69% on standard mAP and p@10, respectively. Concretely, when DenseNet and WIF are jointly employed, a stark increment in performance for the Meningioma class is observed, suggesting the generalizability of the framework.},
  archive      = {J_NCA},
  author       = {Singh, Vibhav Prakash and Verma, Aman and Singh, Dushyant Kumar and Maurya, Ritesh},
  doi          = {10.1007/s00521-023-09149-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {20437-20450},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improved content-based brain tumor retrieval for magnetic resonance images using weight initialization framework with densely connected deep neural network},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
