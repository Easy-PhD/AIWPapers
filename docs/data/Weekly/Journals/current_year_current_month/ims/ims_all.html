<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ims</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aoap">AOAP - 17</h2>
<ul>
<li><details>
<summary>
(2025). The effective strength of selection in random environment. <em>AOAP</em>, <em>35</em>(1), 701-748. (<a href='https://doi.org/10.1214/24-AAP2127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyse a family of two-types Wright–Fisher models with selection in a random environment and skewed offspring distribution. We provide a calculable criterion to quantify the impact of different shapes of selection on the fate of the weakest allele, and thus compare them. The main mathematical tool is duality, which we prove to hold, also in presence of random environment (quenched and in some cases annealed), between the population’s allele frequencies and genealogy, both in the case of finite population size and in the scaling limit for large size. Duality also yields new insight on properties of branching-coalescing processes in random environment, such as their long-term behaviour.},
  archive      = {J_AOAP},
  author       = {Adrián González Casanova and Dario Spanò and Maite Wilke-Berenguer},
  doi          = {10.1214/24-AAP2127},
  journal      = {The Annals of Applied Probability},
  month        = {2},
  number       = {1},
  pages        = {701-748},
  shortjournal = {Ann. Appl. Probab.},
  title        = {The effective strength of selection in random environment},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The stochastic primitive equations with nonisothermal turbulent pressure. <em>AOAP</em>, <em>35</em>(1), 635-700. (<a href='https://doi.org/10.1214/24-AAP2124'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce and study the primitive equations with non-isothermal turbulent pressure and transport noise. They are derived from the Navier–Stokes equations by employing stochastic versions of the Boussinesq and the hydrostatic approximations. The temperature dependence of the turbulent pressure can be seen as a consequence of an additive noise acting on the small vertical dynamics. For such a model we prove global well-posedness in H1 where the noise is considered in both the Itô and Stratonovich formulations. Compared to previous variants of the primitive equations, the one considered here presents a more intricate coupling between the velocity field and the temperature. The corresponding analysis is seriously more involved than in the deterministic setting. Finally, the continuous dependence on the initial data and the energy estimates proven here are new, even in the case of isothermal turbulent pressure.},
  archive      = {J_AOAP},
  author       = {Antonio Agresti and Matthias Hieber and Amru Hussein and Martin Saal},
  doi          = {10.1214/24-AAP2124},
  journal      = {The Annals of Applied Probability},
  month        = {2},
  number       = {1},
  pages        = {635-700},
  shortjournal = {Ann. Appl. Probab.},
  title        = {The stochastic primitive equations with nonisothermal turbulent pressure},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wilson lines in the lattice higgs model at strong coupling. <em>AOAP</em>, <em>35</em>(1), 590-634. (<a href='https://doi.org/10.1214/24-AAP2122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the 4D fixed length lattice Higgs model with Wilson action for the gauge field and structure group Zn. We study Wilson line observables in the strong coupling regime and compute their asymptotic behavior with error estimates. Our analysis is based on a high-temperature representation of the lattice Higgs measure combined with Poisson approximation. We also give a short proof of the folklore result that Wilson line (and loop) expectations exhibit perimeter law decay whenever the Higgs field coupling constant is positive.},
  archive      = {J_AOAP},
  author       = {Malin P. Forsström and Jonatan Lenells and Fredrik Viklund},
  doi          = {10.1214/24-AAP2122},
  journal      = {The Annals of Applied Probability},
  month        = {2},
  number       = {1},
  pages        = {590-634},
  shortjournal = {Ann. Appl. Probab.},
  title        = {Wilson lines in the lattice higgs model at strong coupling},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rates in the central limit theorem for random projections of martingales. <em>AOAP</em>, <em>35</em>(1), 564-589. (<a href='https://doi.org/10.1214/24-AAP2121'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider partial sums of martingale differences weighted by random variables drawn uniformly on the sphere, and globally independent of the martingale differences. Combining Lindeberg’s method and a series of arguments due to Bobkov, Chistyakov and Götze, we show that the Kolmogorov distance between the distribution of these weighted sums and the limiting Gaussian is “super-fast” of order (logn)2/n, under conditions allowing us to control the higher-order conditional moments of the martingale differences. We also show that the same rate is achieved if we consider a quantity very close to these weighted sums, and give an application of this result to the least squares estimator of the slope in the linear model with Gaussian design.},
  archive      = {J_AOAP},
  author       = {Jérôme Dedecker and Florence Merlevède and Magda Peligrad},
  doi          = {10.1214/24-AAP2121},
  journal      = {The Annals of Applied Probability},
  month        = {2},
  number       = {1},
  pages        = {564-589},
  shortjournal = {Ann. Appl. Probab.},
  title        = {Rates in the central limit theorem for random projections of martingales},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sharp thresholds in inference of planted subgraphs. <em>AOAP</em>, <em>35</em>(1), 523-563. (<a href='https://doi.org/10.1214/24-AAP2120'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We connect the study of phase transitions in high-dimensional statistical inference to the study of threshold phenomena in random graphs. A major question in the study of the Erdős–Rényi random graph G(n,p) is to understand the probability, as a function of p, that G(n,p) contains a given subgraph H=Hn. This was studied for many specific examples of H, starting with classical work of Erdős and Rényi (1960). More recent work studies this question for general H, both in building a general theory of sharp versus coarse transitions (Friedgut and Bourgain (1999); Hatami (2012)) and in results on the location of the transition (Kahn and Kalai (2007); Talagrand (2010); Frankston, Kahn, Narayanan, Park (2019); Park and Pham (2022)). In inference problems, one often studies the optimal accuracy of inference as a function of the amount of noise. In a variety of sparse recovery problems, an “all-or-nothing (AoN) phenomenon” has been observed: Informally, as the amount of noise is gradually increased, at some critical threshold the inference problem undergoes a sharp jump from near-perfect recovery to near-zero accuracy (Gamarnik and Zadik (2017); Reeves, Xu, Zadik (2021)). We can regard AoN as the natural inference analogue of the sharp threshold phenomenon in random graphs. In contrast with the general theory developed for sharp thresholds of random graph properties, the AoN phenomenon has only been studied so far in specific inference settings, and a general theory behind its appearance remains elusive. In this paper we study the general problem of inferring a graph H=Hn planted in an Erdős–Rényi random graph, thus naturally connecting the two lines of research mentioned above. We show that questions of AoN are closely connected to first moment thresholds, and to a generalization of the so-called Kahn–Kalai expectation threshold that scans over subgraphs of H of edge density at least q. In a variety of settings we characterize AoN, by showing that AoN occurs if and only if this “generalized expectation threshold” is roughly constant in q. Our proofs combine techniques from random graph theory and Bayesian inference.},
  archive      = {J_AOAP},
  author       = {Elchanan Mossel and Jonathan Niles-Weed and Youngtak Sohn and Nike Sun and Ilias Zadik},
  doi          = {10.1214/24-AAP2120},
  journal      = {The Annals of Applied Probability},
  month        = {2},
  number       = {1},
  pages        = {523-563},
  shortjournal = {Ann. Appl. Probab.},
  title        = {Sharp thresholds in inference of planted subgraphs},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic partial differential equations arising in self-organized criticality. <em>AOAP</em>, <em>35</em>(1), 481-522. (<a href='https://doi.org/10.1214/24-AAP2119'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study scaling limits of the weakly driven Zhang and the Bak–Tang–Wiesenfeld (BTW) model for self-organized criticality. We show that the weakly driven Zhang model converges to a stochastic partial differential equation (PDE) with singular-degenerate diffusion. In addition, the deterministic BTW model is shown to converge to a singular-degenerate PDE. Alternatively, the proof of the scaling limit can be understood as a convergence proof of a finite-difference discretization for singular-degenerate stochastic PDEs. This extends recent work on finite difference approximation of (deterministic) quasilinear diffusion equations to discontinuous diffusion coefficients and stochastic PDEs. In addition, we perform numerical simulations illustrating key features of the considered models and the convergence to stochastic PDEs in spatial dimension d=1,2.},
  archive      = {J_AOAP},
  author       = {Ľubomír Baňas and Benjamin Gess and Marius Neuß},
  doi          = {10.1214/24-AAP2119},
  journal      = {The Annals of Applied Probability},
  month        = {2},
  number       = {1},
  pages        = {481-522},
  shortjournal = {Ann. Appl. Probab.},
  title        = {Stochastic partial differential equations arising in self-organized criticality},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Independence property of the busemann function in exactly solvable KPZ models. <em>AOAP</em>, <em>35</em>(1), 458-480. (<a href='https://doi.org/10.1214/24-AAP2118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of Kadar–Parsi–Zhang (KPZ) universality class has been a subject of great interest among mathematicians and physicists over the past three decades. A notably successful approach for analyzing KPZ models is the coupling method, which hinges on understanding random growth from stationary initial conditions defined by Busemann functions. To advance in this direction, we investigate the independence property of the Busemann function across multiple directions in various exactly solvable KPZ models. These models encompass the corner growth model, the inverse-gamma polymer, Brownian last-passage percolation, the O’Connell–Yor polymer, the KPZ equation, and the directed landscape. In the context of the corner growth model, our result states that disjoint Busemann increments in different directions along a down-right path are independent, as long as their associated semi-infinite geodesics have nonempty intersections almost surely. The proof for the independence utilizes the queueing representation of the Busemann process developed by Seppäläinen et al. As an application, our independence result yields a near-optimal probability upper bound (missing by a logarithmic factor) for the rare event where the endpoint of a point-to-line inverse-gamma polymer is close to the diagonal.},
  archive      = {J_AOAP},
  author       = {Xiao Shen},
  doi          = {10.1214/24-AAP2118},
  journal      = {The Annals of Applied Probability},
  month        = {2},
  number       = {1},
  pages        = {458-480},
  shortjournal = {Ann. Appl. Probab.},
  title        = {Independence property of the busemann function in exactly solvable KPZ models},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Λ-Wright–Fisher processes with general selection and opposing environmental effects: Fixation and coexistence. <em>AOAP</em>, <em>35</em>(1), 393-457. (<a href='https://doi.org/10.1214/24-AAP2117'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our results characterize the long-term behavior for a broad class of Λ-Wright–Fisher processes (on [0,1]) with frequency-dependent and environmental selection. In particular, we reveal a rich variety of parameter-dependent behaviors and provide explicit criteria to discriminate between them. That includes the situation in which both boundary points, 0 and 1, are repelling—a new phenomenon in this context. This has significant biological implications, because it means that selection alone can maintain genetic variation, that is, coexistence. If a boundary point is attractive, we derive polynomial/exponential decay rates for the probability of not being polynomially/exponentially close to that boundary, depending on some weak/strong integrability conditions. Moreover, we provide a handy representation of the fixation probability. In our proofs we make use of Siegmund duality. The dual process can be sandwiched near the boundaries in-between transformed Lévy processes. In this way we relate the boundary behavior of the dual process to fluctuation properties of these Lévy processes and shed new light on previously established conditions for attractive/repelling boundary points. Our method allows us to treat models that so far could not be analyzed by means of moment or Bernstein duality. This closes an existing gap in the literature.},
  archive      = {J_AOAP},
  author       = {Fernando Cordero and Sebastian Hummel and Grégoire Véchambre},
  doi          = {10.1214/24-AAP2117},
  journal      = {The Annals of Applied Probability},
  month        = {2},
  number       = {1},
  pages        = {393-457},
  shortjournal = {Ann. Appl. Probab.},
  title        = {Λ-Wright–Fisher processes with general selection and opposing environmental effects: Fixation and coexistence},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unadjusted hamiltonian MCMC with stratified monte carlo time integration. <em>AOAP</em>, <em>35</em>(1), 360-392. (<a href='https://doi.org/10.1214/24-AAP2116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A randomized time integrator is suggested for unadjusted Hamiltonian Monte Carlo (uHMC) which involves a very minor modification to the usual Verlet time integrator, and hence, is easy to implement. For target distributions of the form μ(dx)∝e−U(x)dx where U:Rd→R≥0 is K-strongly convex but only L-gradient Lipschitz, and initial distributions ν with finite second moment, coupling proofs reveal that an ε-accurate approximation of the target distribution in L2-Wasserstein distance W2 can be achieved by the uHMC algorithm with randomized time integration using O((d/K)1/3(L/K)5/3ε−2/3log(W2(μ,ν)/ε)+) gradient evaluations; whereas for such rough target densities the corresponding complexity of the uHMC algorithm with Verlet time integration is in general O((d/K)1/2(L/K)2ε−1log(W2(μ,ν)/ε)+). Metropolis-adjustable randomized time integrators are also provided.},
  archive      = {J_AOAP},
  author       = {Nawaf Bou-Rabee and Milo Marsden},
  doi          = {10.1214/24-AAP2116},
  journal      = {The Annals of Applied Probability},
  month        = {2},
  number       = {1},
  pages        = {360-392},
  shortjournal = {Ann. Appl. Probab.},
  title        = {Unadjusted hamiltonian MCMC with stratified monte carlo time integration},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sample-path large deviation principle for a 2-D stochastic interacting vortex dynamics with singular kernel. <em>AOAP</em>, <em>35</em>(1), 309-359. (<a href='https://doi.org/10.1214/24-AAP2115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a stochastic interacting vortex system of N particles, approximating the vorticity formulation of the 2-D Navier–Stokes equation on a torus. The singular interaction kernel is given by the Biot–Savart law. Assuming only that the initial state has finite energy, we derive a sample-path large deviation principle for the empirical measure as the number of vortices tends to infinity. This contrasts with previous studies that require the initial state to have finite entropy. The rate function is characterized by an explicit formula that takes finite values only on sample paths with finite energy and finite integrals of L2 norms over time. The proof employs a symmetrization technique for the representation of the singular kernel, originating from Delort (J. Amer. Math. Soc. 4 (1991) 553–586), and a carefully modified energy dissipation structure to establish a sharp prior estimate for an auxiliary functional as a modification of the rate function. The key step is to prove that the singular term after symmetrization can be bounded by the integral of L2 norms along sample paths.},
  archive      = {J_AOAP},
  author       = {Chenyang Chen and Hao Ge},
  doi          = {10.1214/24-AAP2115},
  journal      = {The Annals of Applied Probability},
  month        = {2},
  number       = {1},
  pages        = {309-359},
  shortjournal = {Ann. Appl. Probab.},
  title        = {Sample-path large deviation principle for a 2-D stochastic interacting vortex dynamics with singular kernel},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximately optimal distributed stochastic controls beyond the mean field setting. <em>AOAP</em>, <em>35</em>(1), 251-308. (<a href='https://doi.org/10.1214/24-AAP2114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study high-dimensional stochastic optimal control problems in which many agents cooperate to minimize a convex cost functional. We consider both the full-information problem, in which each agent observes the states of all other agents, and the distributed problem, in which each agent observes only its own state. Our main results are sharp nonasymptotic bounds on the gap between these two problems, measured both in terms of their value functions and optimal states. Along the way, we develop theory for distributed optimal stochastic control in parallel with the classical setting, by characterizing optimizers in terms of an associated stochastic maximum principle and a Hamilton–Jacobi-type equation. By specializing these results to the setting of mean field control, in which costs are (symmetric) functions of the empirical distribution of states, we derive the optimal rate for the convergence problem in the displacement convex regime.},
  archive      = {J_AOAP},
  author       = {Joe Jackson and Daniel Lacker},
  doi          = {10.1214/24-AAP2114},
  journal      = {The Annals of Applied Probability},
  month        = {2},
  number       = {1},
  pages        = {251-308},
  shortjournal = {Ann. Appl. Probab.},
  title        = {Approximately optimal distributed stochastic controls beyond the mean field setting},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contractive coupling rates and curvature lower bounds for markov chains. <em>AOAP</em>, <em>35</em>(1), 196-250. (<a href='https://doi.org/10.1214/24-AAP2113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contractive coupling rates have been recently introduced by Conforti as a tool to establish convex Sobolev inequalities (including modified log-Sobolev and Poincaré inequality) for some classes of Markov chains. In this work, for most of the examples discussed by Conforti, we use contractive coupling rates to prove stronger inequalities, in the form of curvature lower bounds (in entropic and discrete Bakry–Émery sense) and geodesic convexity of some entropic functionals. In addition, we recall and give straightforward generalizations of some notions of coarse Ricci curvature, and we discuss some of their properties and relations with the concepts of couplings and coupling rates: as an application, we show exponential contraction of the p-Wasserstein distance for the heat flow in the aforementioned examples.},
  archive      = {J_AOAP},
  author       = {Francesco Pedrotti},
  doi          = {10.1214/24-AAP2113},
  journal      = {The Annals of Applied Probability},
  month        = {2},
  number       = {1},
  pages        = {196-250},
  shortjournal = {Ann. Appl. Probab.},
  title        = {Contractive coupling rates and curvature lower bounds for markov chains},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The critical beta-splitting random tree i: Heights and related results. <em>AOAP</em>, <em>35</em>(1), 158-195. (<a href='https://doi.org/10.1214/24-AAP2112'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the critical beta-splitting model of a random n-leaf binary tree, leaf-sets are recursively split into subsets, and a set of m leaves is split into subsets containing i and m−i leaves with probabilities proportional to 1/i(m−i). We study the continuous-time model in which the holding time before that split is exponential with rate hm−1, the harmonic number. We (sharply) evaluate the first two moments of the time-height Dn and of the edge-height Ln of a uniform random leaf (i.e., the length of the path from the root to the leaf), and prove the corresponding CLTs. We study the correlation between the heights of two random leaves of the same tree realization, and analyze the expected number of splits necessary for a set of t leaves to partially or completely break away from each other. We give tail bounds for the time-height and the edge-height of the tree, that is, the maximal leaf heights. We show that there is a limit distribution for the size of a uniform random subtree, and derive the asymptotics of the mean size. Our proofs are based on asymptotic analysis of the attendant (sum-type) recurrences. The essential idea is to replace such a recursive equality by a pair of recursive inequalities for which matching asymptotic solutions can be found, allowing one to bound, both ways, the elusive explicit solution of the recursive equality. This reliance on recursive inequalities necessitates usage of Laplace transforms rather than Fourier characteristic functions.},
  archive      = {J_AOAP},
  author       = {David Aldous and Boris Pittel},
  doi          = {10.1214/24-AAP2112},
  journal      = {The Annals of Applied Probability},
  month        = {2},
  number       = {1},
  pages        = {158-195},
  shortjournal = {Ann. Appl. Probab.},
  title        = {The critical beta-splitting random tree i: Heights and related results},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solidarity of gibbs samplers: The spectral gap. <em>AOAP</em>, <em>35</em>(1), 142-157. (<a href='https://doi.org/10.1214/24-AAP2111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gibbs samplers are preeminent Markov chain Monte Carlo algorithms used in computational physics and statistical computing. Yet, their most fundamental properties, such as relations between convergence characteristics of their various versions, are not well understood. In this paper we prove the solidarity principle of the spectral gap for the Gibbs sampler: if any of the random scan or d! deterministic scans has a spectral gap then all of them have. Our methods rely on geometric interpretation of the Gibbs samplers as alternating projection algorithms and analysis of the rate of convergence in the von Neumann–Halperin method of cyclic alternating projections. As a byproduct of our analysis, we also establish that deterministic scan Gibbs, despite being nonreversible, share many robustness properties with reversible chains, including exponential inequalities and central limit theorems under the same conditions. In addition, we provide a quantitative result: if the spectral gap of the random scan Gibbs sampler decays with dimension at a polynomial rate β, then the rate is no worse than 2β+2 for any deterministic scan.},
  archive      = {J_AOAP},
  author       = {Iwona Chlebicka and Krzysztof Łatuszyński and Błażej Miasojedow},
  doi          = {10.1214/24-AAP2111},
  journal      = {The Annals of Applied Probability},
  month        = {2},
  number       = {1},
  pages        = {142-157},
  shortjournal = {Ann. Appl. Probab.},
  title        = {Solidarity of gibbs samplers: The spectral gap},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Asymptotics for the site frequency spectrum associated with the genealogy of a birth and death process. <em>AOAP</em>, <em>35</em>(1), 99-141. (<a href='https://doi.org/10.1214/24-AAP2110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider a birth and death process started from one individual in which each individual gives birth at rate λ and dies at rate μ, so that the population size grows at rate r=λ−μ. Lambert (Theor. Popul. Biol. 122 (2018) 30–35) and Harris, Johnston, and Roberts (Ann. Appl. Probab. 30 (2020) 1368–1414) came up with methods for constructing the exact genealogy of a sample of size n taken from this population at time T. We use the construction of Lambert, which is based on the coalescent point process, to obtain asymptotic results for the site frequency spectrum associated with this sample. In the supercritical case r>0, our results extend results of Durrett (Ann. Appl. Probab. 23 (2013) 230–250) for exponentially growing populations. In the critical case r=0, our results parallel those that Dahmer and Kersting (Ann. Appl. Probab. 25 (2015) 1325–1348) obtained for Kingman’s coalescent.},
  archive      = {J_AOAP},
  author       = {Jason Schweinsberg and Yubo Shuai},
  doi          = {10.1214/24-AAP2110},
  journal      = {The Annals of Applied Probability},
  month        = {2},
  number       = {1},
  pages        = {99-141},
  shortjournal = {Ann. Appl. Probab.},
  title        = {Asymptotics for the site frequency spectrum associated with the genealogy of a birth and death process},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weak error estimates for rough volatility models. <em>AOAP</em>, <em>35</em>(1), 64-98. (<a href='https://doi.org/10.1214/24-AAP2109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a class of stochastic processes with rough stochastic volatility, examples of which include the rough Bergomi and rough Stein–Stein model, that have gained considerable importance in quantitative finance. A basic question for such (non-Markovian) models concerns efficient numerical schemes. While strong rates are well understood (order H), we tackle here the intricate question of weak rates. Our main result asserts that the weak rate, for a reasonably large class of test function, is essentially of order min{3H+12,1} where H∈(0,1/2] is the Hurst parameter of the fractional Brownian motion that underlies the rough volatility process. Interestingly, the phase transition at H=1/6 is related to the correlation between the two driving factors, and thus gives additional meaning to a quantity already of central importance in stochastic volatility modelling. Our results are complemented by a lower bound which show that the obtained weak rate is indeed optimal.},
  archive      = {J_AOAP},
  author       = {Peter K. Friz and William Salkeld and Thomas Wagenhofer},
  doi          = {10.1214/24-AAP2109},
  journal      = {The Annals of Applied Probability},
  month        = {2},
  number       = {1},
  pages        = {64-98},
  shortjournal = {Ann. Appl. Probab.},
  title        = {Weak error estimates for rough volatility models},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence of population processes with small and frequent mutations to the canonical equation of adaptive dynamics. <em>AOAP</em>, <em>35</em>(1), 1-63. (<a href='https://doi.org/10.1214/24-AAP2103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a stochastic individual-based model describing Darwinian evolution of asexual, phenotypic trait-structured population, is studied. We consider a large population with constant population size characterised by a resampling rate modeling competition pressure driving selection and a mutation rate where mutations occur during life. In this model, the population state at fixed time is given as a measure on the space of phenotypes and the evolution of the population is described by a continuous time, measure-valued Markov process. We investigate the asymptotic behaviour of the system, where mutations are frequent, in the double simultaneous limit of large population (K→+∞) and small mutational effects (σK→0) proving convergence to an ODE known as the canonical equation of adaptive dynamics. This result holds only for a certain range of σK parameters (as a function of K) which must be small enough but not too small either. The canonical equation describes the evolution in time of the dominant trait in the population driven by a fitness gradient. This result is based on an slow-fast asymptotic analysis. We use an averaging method, inspired by Kurtz (In Applied Stochastic Analysis (1992) 186–209, Springer), which exploits a martingale approach and compactness-uniqueness arguments. The contribution of the fast component, which converges to the centered Fleming–Viot process, is obtained by averaging according to its invariant measure, recently characterised in Champagnat and Hass (Stochastic Process. Appl. 166 (2023) 104219).},
  archive      = {J_AOAP},
  author       = {Nicolas Champagnat and Vincent Hass},
  doi          = {10.1214/24-AAP2103},
  journal      = {The Annals of Applied Probability},
  month        = {2},
  number       = {1},
  pages        = {1-63},
  shortjournal = {Ann. Appl. Probab.},
  title        = {Convergence of population processes with small and frequent mutations to the canonical equation of adaptive dynamics},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="aoas">AOAS - 11</h2>
<ul>
<li><details>
<summary>
(2025). Estimating product cannibalisation in wholesale using multivariate hawkes processes with inhibition. <em>AOAS</em>, <em>19</em>(1), 235-260. (<a href='https://doi.org/10.1214/24-AOAS1957'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Product cannibalisation in the marketplace refers to the decrease in the sales of one product due to competition from another product. We examine this phenomenon in a wholesale data set provided by a major international company. We use a multivariate Hawkes process where each product is represented by a dimension, with cross-inhibition effects that model product cannibalisation. To implement the Hawkes process with inhibition, we resolve challenges regarding the integration of the intensity function and introduce a new, less restrictive condition for stability, as existing conditions are unnecessarily strict under inhibition. We conduct our analysis in a Bayesian framework for which we design a dimension-independent prior on the cross-inhibition based on a reparametrisation.},
  archive      = {J_AOAS},
  author       = {Isabella Deutsch and Gordon J. Ross},
  doi          = {10.1214/24-AOAS1957},
  journal      = {The Annals of Applied Statistics},
  month        = {3},
  number       = {1},
  pages        = {235-260},
  shortjournal = {Ann. Appl. Stat.},
  title        = {Estimating product cannibalisation in wholesale using multivariate hawkes processes with inhibition},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Has the covid-19 outbreak capsized the predictive performance of bayesian VAR models with cointegration and time-varying volatility?. <em>AOAS</em>, <em>19</em>(1), 212-234. (<a href='https://doi.org/10.1214/24-AOAS1956'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We check whether taking into account long-term relationships in heteroscedastic VAR models affects their predictive performance before and during the Covid-19 pandemic. Also, we examine whether the predictions can benefit from suspending posterior updates at some point. Empirical analysis covers five different economies and uses Bayesian VAR/VEC models with volatility specifications combining stochastic volatility and GARCH processes. It emerges that, while accounting for cointegration relationships in the models enhances their predictive performance prior to the pandemic, it may be counterproductive for times of economic crisis. Additionally, refraining from keeping the posterior updated does improve the predictions, but only rarely.},
  archive      = {J_AOAS},
  author       = {Anna Pajor and Łukasz Kwiatkowski and Justyna Wróblewska},
  doi          = {10.1214/24-AOAS1956},
  journal      = {The Annals of Applied Statistics},
  month        = {3},
  number       = {1},
  pages        = {212-234},
  shortjournal = {Ann. Appl. Stat.},
  title        = {Has the covid-19 outbreak capsized the predictive performance of bayesian VAR models with cointegration and time-varying volatility?},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contour location for reliability in airfoil simulation experiments using deep gaussian processes. <em>AOAS</em>, <em>19</em>(1), 191-211. (<a href='https://doi.org/10.1214/24-AOAS1951'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian deep Gaussian processes (DGPs) outperform ordinary GPs as surrogate models of complex computer experiments when response surface dynamics are nonstationary, which is especially prevalent in aerospace simulations. Yet DGP surrogates have not been deployed for the canonical downstream task in that setting: reliability analysis through contour location (CL). In that context we are motivated by a simulation of an RAE-2822 transonic airfoil which demarcates efficient and inefficient flight conditions. Level sets separating passable vs. failable operating conditions are best learned through strategic sequential designs. There are two limitations to modern CL methodology which hinder DGP integration in this setting. First, derivative-based optimization underlying acquisition functions is thwarted by sampling-based Bayesian (i.e., MCMC) inference, which is essential for DGP posterior integration. Second, canonical acquisition criteria, such as entropy, are famously myopic to the extent that optimization may even be undesirable. Here we tackle both of these limitations at once, proposing a hybrid criterion that explores along the Pareto front of entropy and (predictive) uncertainty, requiring evaluation only at strategically located “triangulation” candidates. We showcase DGP CL performance in several synthetic benchmark exercises and on the RAE-2822 airfoil.},
  archive      = {J_AOAS},
  author       = {Annie S. Booth and S. Ashwin Renganathan and Robert B. Gramacy},
  doi          = {10.1214/24-AOAS1951},
  journal      = {The Annals of Applied Statistics},
  month        = {3},
  number       = {1},
  pages        = {191-211},
  shortjournal = {Ann. Appl. Stat.},
  title        = {Contour location for reliability in airfoil simulation experiments using deep gaussian processes},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inferring synergistic and antagonistic interactions in mixtures of exposures. <em>AOAS</em>, <em>19</em>(1), 169-190. (<a href='https://doi.org/10.1214/24-AOAS1948'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is abundant interest in assessing the joint effects of multiple exposures on human health. This is often referred to as the mixtures problem in environmental epidemiology and toxicology. Classically, studies have examined the adverse health effects of different chemicals one at a time, but there is concern that certain chemicals may act together to amplify each other’s effects. Such amplification is referred to as synergistic interaction, while chemicals that inhibit each other’s effects have antagonistic interactions. Current approaches for assessing the health effects of chemical mixtures do not explicitly consider synergy or antagonism in the modeling, instead focusing on either parametric or unconstrained nonparametric dose response surface modeling. The parametric case can be too inflexible, while nonparametric methods face a curse of dimensionality that leads to overly wiggly and uninterpretable surface estimates. We propose a Bayesian approach that decomposes the response surface into additive main effects and pairwise interaction effects and then detects synergistic and antagonistic interactions. Variable selection decisions for each interaction component are also provided. This Synergistic Antagonistic Interaction Detection (SAID) framework is evaluated relative to existing approaches using simulation experiments and an application to data from NHANES.},
  archive      = {J_AOAS},
  author       = {Shounak Chattopadhyay and Stephanie M. Engel and David Dunson},
  doi          = {10.1214/24-AOAS1948},
  journal      = {The Annals of Applied Statistics},
  month        = {3},
  number       = {1},
  pages        = {169-190},
  shortjournal = {Ann. Appl. Stat.},
  title        = {Inferring synergistic and antagonistic interactions in mixtures of exposures},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PoD-BIN: A probability of decision bayesian interval design for time-to-event dose-finding trials with multiple toxicity grades. <em>AOAS</em>, <em>19</em>(1), 147-168. (<a href='https://doi.org/10.1214/24-AOAS1946'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a Bayesian framework centered on the “probability of decision” for designing dose-finding trials. The proposed PoD-BIN design evaluates the posterior predictive probabilities of up-and-down decisions. In PoD-BIN, multiple grades of toxicity, categorized as mild toxicity (MT) and dose-limiting toxicity (DLT), are simultaneously modeled, with the primary outcome being time-to-toxicity for both MT and DLT. This approach allows the enrollment of new patients while previously enrolled patients are still being monitored for toxicity, potentially reducing the trial duration. The Bayesian decision rules in PoD-BIN employ the probability of decisions to balance the trade-off between accelerating the trial and the risk of exposing patients to excessively toxic doses. Through numerical examples, we illustrate the trade-off between speed and safety of PoD-BIN and compare it with existing designs. PoD-BIN demonstrates the ability to control the frequency of risky decisions while simultaneously shortening trial duration in simulations.},
  archive      = {J_AOAS},
  author       = {Meizi Liu and Ji Lin and Gu Mi and Christelle Lorenzato and Xun Chen and Yuan Ji},
  doi          = {10.1214/24-AOAS1946},
  journal      = {The Annals of Applied Statistics},
  month        = {3},
  number       = {1},
  pages        = {147-168},
  shortjournal = {Ann. Appl. Stat.},
  title        = {PoD-BIN: A probability of decision bayesian interval design for time-to-event dose-finding trials with multiple toxicity grades},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ultra-sparse small area estimation with super heavy-tailed priors for internal migration flows. <em>AOAS</em>, <em>19</em>(1), 121-146. (<a href='https://doi.org/10.1214/24-AOAS1932'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Migration flows represent an important component of global sustainable development and demographic trends. However, the dynamic nature of the migration phenomenon, known issues of undercoverage of administrative records and long intercensal periods make estimation of internal migration a very challenging task. In this work we focus on the estimation of internal migration in Colombia, which is the subject of an ongoing armed conflict that has triggered forced and voluntary population movements from rural areas. Motivated by the high variability of migration flows across small areas in Colombia, we propose the use of super heavy-tailed (SHT) priors for sparse and ultra-sparse small area effects under a Fay–Herriot model. We establish theoretical properties of a family of log-Cauchy priors and a new SHT prior obtained by considering a four parameter beta (FPB) density. We provide especially suited Markov chain Monte Carlo (MCMC) algorithms that can also be applied to other global-local families of priors in small area contexts. In addition, we consider a simulation study to illustrate how our proposal improves the precision of posterior estimates in sparse and ultra-sparse settings compared to other existing priors in the literature. Finally, we apply our proposed methodology to the estimation of internal migration in Colombia and obtain results with improved precision that are consistent with the population dynamics in the country. Moreover, we provide practical suggestions for official statisticians and other practitioners who desire to use our proposed framework in their own SAE problems.},
  archive      = {J_AOAS},
  author       = {Jairo Fúquene-Patiño and Brenda Betancourt},
  doi          = {10.1214/24-AOAS1932},
  journal      = {The Annals of Applied Statistics},
  month        = {3},
  number       = {1},
  pages        = {121-146},
  shortjournal = {Ann. Appl. Stat.},
  title        = {Ultra-sparse small area estimation with super heavy-tailed priors for internal migration flows},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting census survey response rates with parsimonious additive models and structured interactions. <em>AOAS</em>, <em>19</em>(1), 94-120. (<a href='https://doi.org/10.1214/24-AOAS1929'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider the problem of predicting survey response rates using a family of flexible and interpretable nonparametric models. The study is motivated by the U.S. Census Bureau’s well-known ROAM application, which uses a linear regression model trained on the U.S. Census Planning Database data to identify hard-to-survey areas. A crowdsourcing competition (Public Opin. Q. 81 (2016) 144–156) organized more than 10 years ago revealed that machine learning methods, based on ensembles of regression trees, led to the best performance in predicting survey response rates; however, the corresponding models could not be adopted for the intended application due to their black-box nature. We consider nonparametric additive models with a small number of main and pairwise interaction effects using ℓ0-based penalization. From a methodological viewpoint, we study our estimator’s computational and statistical aspects and discuss variants incorporating strong hierarchical interactions. Our algorithms (open-sourced on GitHub) extend the computational frontiers of existing algorithms for sparse additive models to be able to handle datasets relevant to the application we consider. We discuss and interpret findings from our model on the U.S. Census Planning Database. In addition to being useful from an interpretability standpoint, our models lead to predictions comparable to popular black-box machine learning methods based on gradient boosting and feedforward neural networks—suggesting that it is possible to have models that have the best of both worlds, good model accuracy and interpretability.},
  archive      = {J_AOAS},
  author       = {Shibal Ibrahim and Peter Radchenko and Emanuel Ben-David and Rahul Mazumder},
  doi          = {10.1214/24-AOAS1929},
  journal      = {The Annals of Applied Statistics},
  month        = {3},
  number       = {1},
  pages        = {94-120},
  shortjournal = {Ann. Appl. Stat.},
  title        = {Predicting census survey response rates with parsimonious additive models and structured interactions},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Risk set matched difference-in-differences for the analysis of effect modification in an observational study on the impact of gun violence on health outcomes. <em>AOAS</em>, <em>19</em>(1), 75-93. (<a href='https://doi.org/10.1214/24-AOAS1918'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gun violence is a major source of injury and death in the United States. However, relatively little is known about the effects of firearm injuries on survivors and their family members and how these effects vary. To study these questions and, more generally, to address a gap in the methodological causal inference literature, we present a framework for the study of effect modification or heterogeneous treatment effects in difference-in-differences designs. We implement a new matching technique, combining profile matching and risk set matching to: (i) preserve the time alignment of covariates, exposure, and outcomes, avoiding pitfalls of other common approaches for difference-in-differences, and (ii) explicitly control biases due to imbalances in observed covariates in subgroups discovered from the data. Our case study shows significant and persistent effects of nonfatal firearm injuries on several health outcomes for those injured and on the mental health of their family members. Sensitivity analyses reveal that these results are moderately robust to unmeasured confounding bias. Finally, while the effects for those injured vary largely by the severity of the injury and its documented intent, for families, effects are strongest for those whose relative’s injury is documented as resulting from an assault, self-harm, or law enforcement intervention.},
  archive      = {J_AOAS},
  author       = {Eric R. Cohn and Zirui Song and José R. Zubizarreta},
  doi          = {10.1214/24-AOAS1918},
  journal      = {The Annals of Applied Statistics},
  month        = {3},
  number       = {1},
  pages        = {75-93},
  shortjournal = {Ann. Appl. Stat.},
  title        = {Risk set matched difference-in-differences for the analysis of effect modification in an observational study on the impact of gun violence on health outcomes},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging cellphone-derived mobility networks to assess covid-19 travel risk. <em>AOAS</em>, <em>19</em>(1), 56-74. (<a href='https://doi.org/10.1214/24-AOAS1914'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the beginning of the Covid-19 pandemic, public health authorities across the globe have implemented policies, such as lockdowns, in an attempt to reduce population mobility and, consequently, person-to-person contacts. It is well known that lockdowns reduce mobility, but to what extent does this reduction in mobility lead to lower infection rates? In this paper we extend the endemic-epidemic modeling framework in a principled manner, incorporating temporally changing mobility network data and quantifying the risk associated with travelling throughout the first year of the pandemic in two Spanish communities.},
  archive      = {J_AOAS},
  author       = {Justin J. Slater and Patrick E. Brown and Jeffrey S. Rosenthal and Jorge Mateu},
  doi          = {10.1214/24-AOAS1914},
  journal      = {The Annals of Applied Statistics},
  month        = {3},
  number       = {1},
  pages        = {56-74},
  shortjournal = {Ann. Appl. Stat.},
  title        = {Leveraging cellphone-derived mobility networks to assess covid-19 travel risk},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous treatment and spillover effects under clustered network interference. <em>AOAS</em>, <em>19</em>(1), 28-55. (<a href='https://doi.org/10.1214/24-AOAS1913'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bulk of causal inference studies rule out the presence of interference between units. However, in many real-world scenarios, units are interconnected by social, physical, or virtual ties, and the effect of the treatment can spill from one unit to other connected individuals in the network. In this paper, we develop a machine learning method that uses tree-based algorithms and a Horvitz–Thompson estimator to assess the heterogeneity of treatment and spillover effects with respect to individual, neighborhood, and network characteristics in the context of clustered networks and interference within clusters. The proposed network causal tree (NCT) algorithm has several advantages. First, it allows the investigation of the heterogeneity of the treatment effect, avoiding potential bias due to the presence of interference. Second, understanding the heterogeneity of both treatment and spillover effects can guide policymakers in scaling up interventions, designing targeting strategies, and increasing cost-effectiveness. We investigate the performance of our NCT method using a Monte Carlo simulation study and illustrate its application to assess the heterogeneous effects of information sessions on the uptake of a new weather insurance policy in rural China.},
  archive      = {J_AOAS},
  author       = {Falco J. Bargagli-Stoffi and Costanza Tortú and Laura Forastiere},
  doi          = {10.1214/24-AOAS1913},
  journal      = {The Annals of Applied Statistics},
  month        = {3},
  number       = {1},
  pages        = {28-55},
  shortjournal = {Ann. Appl. Stat.},
  title        = {Heterogeneous treatment and spillover effects under clustered network interference},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Periodogram regression: A two-stage mixed effects approach for modelling multiple integer-valued time series of tropical cyclone frequency. <em>AOAS</em>, <em>19</em>(1), 3-27. (<a href='https://doi.org/10.1214/24-AOAS1895'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tropical cyclones (TC) are significant indicators of evolving climate dynamics. Two primary responses of interest are the cyclone frequency and intensity. In this paper we propose a novel integrated modelling framework for simultaneous modelling of TC frequency across several meteorological regions within Australasia. The key methodological insight is to model the second-order properties of multiple integer-valued time series in frequency domain, instead of parametric time domain models. We take a two-stage semiparametric approach, where large scale environmental variation is modelled using generalized linear models while the stochastic variation, including spatial heterogeneity, is estimated using spectral analysis of time series under a hierarchical generating model. Using longitudinal data analysis, we are able to jointly model periodicities in TC frequencies and their correlation with El Niño–Southern Oscillation (ENSO) cycles as well as the spatial variation between regions. We project the fitted model to obtain one-step-ahead forecasts under the principle of best linear unbiased estimation. This semiparametric approach allows us to obliterate the uniqueness matter of parametric integer-valued time series modelling. Additional methodological advantages include tests for spatial heterogeneity and temporal second-order stationarity. The data analysis corroborates previous findings on declining trend of tropical cyclone frequencies, in the short-term.},
  archive      = {J_AOAS},
  author       = {Lyuyuan Zhang and Guoqi Qian and Sourav Das},
  doi          = {10.1214/24-AOAS1895},
  journal      = {The Annals of Applied Statistics},
  month        = {3},
  number       = {1},
  pages        = {3-27},
  shortjournal = {Ann. Appl. Stat.},
  title        = {Periodogram regression: A two-stage mixed effects approach for modelling multiple integer-valued time series of tropical cyclone frequency},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
