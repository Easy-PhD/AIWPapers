<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TAP</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tap">TAP - 3</h2>
<ul>
<li><details>
<summary>
(2025). Visual experience of space: Relating textual descriptions of perceived atmosphere to luminance contrast metrics. <em>TAP</em>, <em>22</em>(3), 1-18. (<a href='https://doi.org/10.1145/3727981'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This exploratory study investigates the quantifiable relationship between image properties and the aesthetic perception of indoor environments, focusing on luminance contrast, light, form, and material variations. A diverse image set of everyday spaces was curated, and a comprehensive list of atmosphere descriptors was developed from lighting literature. Using pixel value distribution analysis, images were classified by luminance contrast, and 24 participants evaluated 15 images using 54 Turkish atmosphere adjectives on a 5-point semantic differential scale. Principal Component Analysis (PCA) of the responses revealed three components based on 43 adjectives related to perceived atmosphere. Notably, the second component was significantly correlated with luminance contrast, indicating that variations in light, color, and materials—and the resulting changes in luminance contrast—can influence atmospheric perception. The first and third components captured atmospheric qualities beyond luminance contrast. These findings provide valuable insights into how image attributes, particularly luminance contrast, impact aesthetic evaluations of indoor environments, contributing to the broader understanding of atmospheric perception in built spaces.},
  archive      = {J_TAP},
  author       = {İpek Yalçın and Nilgün Olguntürk},
  doi          = {10.1145/3727981},
  journal      = {ACM Transactions on Applied Perception},
  month        = {7},
  number       = {3},
  pages        = {1-18},
  shortjournal = {ACM Trans. Appl. Perc.},
  title        = {Visual experience of space: Relating textual descriptions of perceived atmosphere to luminance contrast metrics},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An extensible open source software designed for virtual reality-based testing and treatment of vision disorders. <em>TAP</em>, <em>22</em>(3), 1-22. (<a href='https://doi.org/10.1145/3733833'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale screening programs for vision impairments can incur substantial costs. Computer-based screening methods, which combine different measurements within a single system, can facilitate and reduce the costs of such programs. Here, we present a virtual reality (VR) software, which includes tests for the assessment of visual acuity, stereoacuity, eye misalignments, and interocular suppression as well as games targeting different visual functions that may serve as treatment methods. The software can be easily extended to incorporate new tests and games. We present a proof of concept demonstrating the functionality of the software and its applicability in individuals with impaired binocularity. We evaluate a stereoacuity test in VR based on disparity detection using contoured objects by comparing its results to those obtained by standard clinical tests, i.e., TNO, Randot, and Titmus, for 7 amblyopes and 6 healthy controls. We evaluate the applicability of a new VR-based suppression test in 10 amblyopes and 6 healthy individuals. For the latter, we exploit the effects of short-term monocular deprivation, which induce a change of ocular dominance. Finally, we outline technical limitations and discuss potential applications.},
  archive      = {J_TAP},
  author       = {Johann Schneider and Yu Yi Yang and Maria Fronius and Juliane Tittes and Jochen Triesch},
  doi          = {10.1145/3733833},
  journal      = {ACM Transactions on Applied Perception},
  month        = {7},
  number       = {3},
  pages        = {1-22},
  shortjournal = {ACM Trans. Appl. Perc.},
  title        = {An extensible open source software designed for virtual reality-based testing and treatment of vision disorders},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The pulfrich effect in virtual reality. <em>TAP</em>, <em>22</em>(3), 1-22. (<a href='https://doi.org/10.1145/3746064'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Pulfrich effect, a visual phenomenon where a neural delay in one eye produces a depth misperception, has been directly studied on flat-panel displays but not in virtual reality (VR) environments. Through a series of three experiments, we investigated the relationship between luminance and contrast on the Pulfrich effect in VR and on the perception of motion. In two of our experiments, we found that low-reflectance stimuli produce a stronger Pulfrich effect than high-reflectance stimuli in VR, a result further accentuated by background luminance. Furthermore, the primary experiment showed that nullifying helix rotation motion is a powerful way to study the magnitude of the Pulfrich effect. With data from the first experiment, we developed a compelling VR illusion in which changing the color of a helix reverses the direction of perceived motion. Our second experiment extends the first with a discrimination task and a larger number of observers, confirming that low-contrast low-luminance conditions produce distinct perceptual effects. Experiment 3 elaborated that low-reflectance stimuli only produce a stronger Pulfrich effect than high-reflectance stimuli when the stimulus is moving away from the delayed eye. Data from the first and third experiments were successfully captured by power law function fits and linearized by plotting Pulfrich effect strength against logit-Michelson contrast. We use the power law as a basis for a fifth section discussing a potential model that may explain computationally how luminance and contrast contribute to the magnitude of the Pulfrich effect. All three experiments and the modeling section in tandem show that investigating well-known visual illusions such as the Pulfrich effect in VR has the potential to reveal insights into visual perception as well as inform us about the effects of contrast and asymmetric lighting in spatial computing.},
  archive      = {J_TAP},
  author       = {Anthony LoPrete and Alexander Gokan and Arthur G. Shapiro},
  doi          = {10.1145/3746064},
  journal      = {ACM Transactions on Applied Perception},
  month        = {7},
  number       = {3},
  pages        = {1-22},
  shortjournal = {ACM Trans. Appl. Perc.},
  title        = {The pulfrich effect in virtual reality},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
