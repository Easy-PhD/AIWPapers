<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TIIS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tiis">TIIS - 4</h2>
<ul>
<li><details>
<summary>
(2025). Using emotion diversification based on movie reviews to improve the user experience of movie recommender systems. <em>TIIS</em>, <em>15</em>(3), 1-27. (<a href='https://doi.org/10.1145/3743147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diversifying movie recommendations is an effective way to address choice overload, a phenomenon where recommenders generate lists with highly similar recommendations that are difficult to choose from. However, existing diversification algorithms often rely on latent features, which limits their interpretability and makes it less clear why a particular set of movies is recommended. Given that movies are designed to elicit emotional responses, researchers have suggested leveraging these responses to enhance recommender system performance. This study introduces a novel “emotion diversification” approach, which diversifies movie recommendations based on emotional signals extracted from audience reviews. We evaluate this method against latent and non-diversified baselines in a controlled user study (N = 115), finding that it significantly improves perceived taste coverage and system satisfaction without compromising recommendation quality. Going beyond the traditional rating- and/or interaction data used by traditional recommender systems, our work demonstrates the user experience benefits of extracting emotional data from rich, qualitative user feedback and using it to give users a more emotionally diverse set of recommendations.},
  archive      = {J_TIIS},
  author       = {Lior Lansman and Osnat Mokryn and Lijie Guo and Mehtab Iqbal and Bart P. Knijnenburg},
  doi          = {10.1145/3743147},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {9},
  number       = {3},
  pages        = {1-27},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {Using emotion diversification based on movie reviews to improve the user experience of movie recommender systems},
  volume       = {15},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MV-crafter: An intelligent system for music-guided video generation. <em>TIIS</em>, <em>15</em>(3), 1-27. (<a href='https://doi.org/10.1145/3748515'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Music videos, as a prevalent form of multimedia entertainment, deliver engaging audio-visual experiences to audiences and have gained immense popularity among singers and fans. Creators can express their interpretations of music naturally through visual elements. However, the creation process of music video demands proficiency in script design, video shooting, and music-video synchronization, posing significant challenges for non-professionals. Previous work has designed automated music video generation frameworks. However, they suffer from complexity in input and poor output quality. In response, we present MV-Crafter, a system capable of producing high-quality music videos with synchronized music-video rhythm and style. Our approach involves three technical modules that simulate the human creation process: the script generation module, video generation module, and music-video synchronization module. MV-Crafter leverages a large language model to generate scripts considering the musical semantics. To address the challenge of synchronizing short video clips with music of varying lengths, we propose a dynamic beat-matching algorithm and visual envelope-induced warping method to ensure precise, monotonic music-video synchronization. Besides, we design a user-friendly interface to simplify the creation process with intuitive editing features. Extensive experiments have demonstrated that MV-Crafter provides an effective solution for improving the quality of generated music videos.},
  archive      = {J_TIIS},
  author       = {Chuer Chen and Shengqi Dang and Yuqi Liu and Nanxuan Zhao and Yang Shi and Nan Cao},
  doi          = {10.1145/3748515},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {9},
  number       = {3},
  pages        = {1-27},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {MV-crafter: An intelligent system for music-guided video generation},
  volume       = {15},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 2024 TiiS best paper announcement. <em>TIIS</em>, <em>15</em>(3), 1. (<a href='https://doi.org/10.1145/3749645'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TIIS},
  author       = {Shlomo Berkovsky},
  doi          = {10.1145/3749645},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {9},
  number       = {3},
  pages        = {1},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {2024 TiiS best paper announcement},
  volume       = {15},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Imperfections of XAI: Phenomena influencing AI-assisted decision-making. <em>TIIS</em>, <em>15</em>(3), 1-40. (<a href='https://doi.org/10.1145/3750052'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing use of AI, recent research in human–computer interaction explores Explainable AI (XAI) to make AI advice more interpretable. While research addresses the effects of incorrect AI advice on AI-assisted decision-making, the impact of incorrect explanations is neglected so far. Additionally, recent work shows that not only different explanation modalities impact decision-makers, but also human factors play a critical role. To analyze relevant phenomena influencing AI-assisted decision-making, this work explores the impacting factors by conceptualizing theories of appropriate reliance and taking the first steps toward empirical evidence. We show that humans’ reliance on AI and the human–AI team performance are impacted by imperfect XAI in a study with 136 participants. Additionally, we find that cognitive styles affect decision-making in different explanation modalities. Hence, we shed light on diverse factors that impact human–AI collaboration and provide guidelines for designers to tailor such human–AI collaboration systems to individuals’ needs.},
  archive      = {J_TIIS},
  author       = {Philipp Spitzer and Katelyn Morrison and Violet Turri and Michelle Feng and Adam Perer and Niklas Kühl},
  doi          = {10.1145/3750052},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {9},
  number       = {3},
  pages        = {1-40},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {Imperfections of XAI: Phenomena influencing AI-assisted decision-making},
  volume       = {15},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
