<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>acm</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="cacm">CACM - 23</h2>
<ul>
<li><details>
<summary>
(2025). Embracing her critics to refine VoIP. <em>CACM</em>, <em>68</em>(9), 112-ff. (<a href='https://doi.org/10.1145/3743157'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CACM},
  author       = {Leah Hoffmann},
  doi          = {10.1145/3743157},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {112-ff},
  shortjournal = {Commun. ACM},
  title        = {Embracing her critics to refine VoIP},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TMO: Transparent memory offloading in datacenters. <em>CACM</em>, <em>68</em>(9), 102-110. (<a href='https://doi.org/10.1145/3746651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unrelenting growth in the memory demands of datacenter applications, combined with DRAM’s volatile prices and ever-increasing costs, has made DRAM a major infrastructure expense. Alternative technologies, such as NVMe SSDs and emerging NVM devices, offer higher capacity than DRAM at a fraction of the cost and power. A promising approach is to transparently offload colder memory to cheaper memory technologies via kernel or hypervisor techniques. The key challenge, however, is to develop a datacenter-scale solution that is robust in dealing with diverse workloads and large performance variance of different offload devices, such as compressed memory, SSD, and NVM. This paper presents TMO, Meta’s transparent memory offloading solution for heterogeneous datacenter environments. TMO introduces a new Linux kernel mechanism that directly measures, in realtime, process stalls due to resource shortages across CPU, memory, and I/O. Guided by this information and without any prior application knowledge, TMO automatically adjusts how much memory to offload to heterogeneous devices (e.g., compressed memory or SSD) according to the device’s performance characteristics and the application’s sensitivity to memory-access slowdown. To maximize memory savings, TMO targets both anonymous memory and file cache, balancing the swap-in rate of anonymous memory and the reload rate of file pages that were recently evicted from the file cache. Moreover, it identifies offloading opportunities not only from the application containers but also from the sidecar containers that provide infrastructure-level functions. TMO has been in production since 2021, saving 20–32% of total memory across millions of servers in our hyperscale datacenter fleet. We have successfully upstreamed TMO into the Linux kernel.},
  archive      = {J_CACM},
  author       = {Johannes Weiner and Niket Agarwal and Dan Schatzberg and Leon Yang and Hao Wang and Blaise Sanouillet and Bikash Sharma and Tejun Heo and Mayank Jain and Chunqiang Tang and Dimitrios Skarlatos},
  doi          = {10.1145/3746651},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {102-110},
  shortjournal = {Commun. ACM},
  title        = {TMO: Transparent memory offloading in datacenters},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memory efficiency via offloading in warehouse-scale datacenters. <em>CACM</em>, <em>68</em>(9), 101. (<a href='https://doi.org/10.1145/3746650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CACM},
  author       = {Parthasarathy Ranganathan},
  doi          = {10.1145/3746650},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {101},
  shortjournal = {Commun. ACM},
  title        = {Memory efficiency via offloading in warehouse-scale datacenters},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NeuroRadar: A neuromorphic radar sensor for low-power IoT systems. <em>CACM</em>, <em>68</em>(9), 91-100. (<a href='https://doi.org/10.1145/3745033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CACM},
  author       = {Kai Zheng and Kun Qian and Timothy Woodford and Xinyu Zhang},
  doi          = {10.1145/3745033},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {91-100},
  shortjournal = {Commun. ACM},
  title        = {NeuroRadar: A neuromorphic radar sensor for low-power IoT systems},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NeuroRadar: Can radar systems be reimagined using computational principles?. <em>CACM</em>, <em>68</em>(9), 90. (<a href='https://doi.org/10.1145/3745757'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CACM},
  author       = {Deepak Ganesan},
  doi          = {10.1145/3745757},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {90},
  shortjournal = {Commun. ACM},
  title        = {NeuroRadar: Can radar systems be reimagined using computational principles?},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differentiable economics: Strategic behavior, mechanisms, and machine learning. <em>CACM</em>, <em>68</em>(9), 80-88. (<a href='https://doi.org/10.1145/3725809'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Economics studies the behavior of individuals and firms in making decisions regarding the allocation of scarce resources and the interactions among these agents. Game theory had a substantial impact on economic modeling because it allows us to model the outcome of such economic interaction while taking the incentives of individual agents into account. Mechanism design does the same when designing the rules of economic institutions. Unfortunately, these economic models have turned out to be computationally hard to solve. For example, finding equilibrium in some incomplete-information models of markets with continuous valuation and action spaces are hard in PP, and designing a revenue-maximizing multi-item auction is # P -hard. This computational complexity poses a fundamental barrier in modeling economic systems but is worst-case and considers non-generic instances. Differentiable economics describes a new approach to solving these central problems in the economic sciences. It uses learning algorithms to find or approximate solutions to equilibrium computation or economic design problems. In particular, neural networks and learning algorithms such as Stochastic Gradient Descent have been shown to be very effective. Machine learning has led to breakthroughs in many sciences, and it also holds the potential to fundamentally alter how we analyze and design economic systems.},
  archive      = {J_CACM},
  author       = {Martin Bichler and David C. Parkes},
  doi          = {10.1145/3725809},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {80-88},
  shortjournal = {Commun. ACM},
  title        = {Differentiable economics: Strategic behavior, mechanisms, and machine learning},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Socioeconomic threats of deepfakes and the role of cyber-wellness education in defense. <em>CACM</em>, <em>68</em>(9), 70-79. (<a href='https://doi.org/10.1145/3715317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, society has witnessed accelerated advancement in generative artificial intelligence (GenAI) technologies, which may be viewed as a double-edged sword. On one hand, GenAI tools can be used to create synthetic content legitimately. For example, advertising agencies may, with permission, generate celebrities’ images or videos using GenAI tools without putting them in front of cameras and thus reducing the overall cost of media construction. On the other hand, scammers may utilize GenAI tools to craft or edit artificial content (for example, texts, images, videos, or audio), so-called deepfakes, to mislead or deceive netizens with robocalls or voice cloning phishing, potentially causing detrimental consequences for society. This article briefly debates emerging socioeconomic threats of deepfakes in today’s society and how cyber-wellness (or digital media literacy) education can help netizens mitigate their risks.},
  archive      = {J_CACM},
  author       = {Milad Taleby Ahvanooey and Wojciech Mazurczyk and Dongwon Lee},
  doi          = {10.1145/3715317},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {70-79},
  shortjournal = {Commun. ACM},
  title        = {Socioeconomic threats of deepfakes and the role of cyber-wellness education in defense},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An analysis of the impact of gold open access publications in computer science. <em>CACM</em>, <em>68</em>(9), 62-69. (<a href='https://doi.org/10.1145/3721975'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been some concern about the impact of predatory publishers on scientific research for some time. Recently, publishers previously viewed as ‘predatory’ have established their bona fides , at least to the extent that they are included in impact scores such as the field-weighted citation impact (FWCI). These are sometimes called grey publishers (MDPI, Frontiers, Hindawi). We show that the citation landscape for these grey publications is significantly different from the mainstream landscape and that affording grey publications the same status as mainstream journals may significantly distort metrics such as the FWCI.},
  archive      = {J_CACM},
  author       = {Pádraig Cunningham and Barry Smyth},
  doi          = {10.1145/3721975},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {62-69},
  shortjournal = {Commun. ACM},
  title        = {An analysis of the impact of gold open access publications in computer science},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grand challenges in trustworthy computing at 20: A retrospective look at the second CRA grand challenges conference. <em>CACM</em>, <em>68</em>(9), 54-61. (<a href='https://doi.org/10.1145/3720534'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To commemorate the 20th anniversary of the 2003 Computing Research Association (CRA) Gordon-style Conference on Grand Challenges in Trustworthy Computing, the original attendees were invited to a virtual retrospective. This landmark conference, held November 16–19, 2003, at Airlie House in Northern Virginia, brought together 50 technology and policy experts in security, privacy, and networking to identify transformative research challenges. The resulting report became a cornerstone for researchers and funding agencies at a pivotal moment in the evolution of cybersecurity. In 2023, participants met online for a six-week period to review the progress made on these challenges, assessing successes, failures, and lessons learned. This article distills those discussions, offering insight for a new generation of cybersecurity professionals who face many of the same threats today in an ever-evolving landscape. As many of the original participants remain active in the field, this retrospective not only provides a historical perspective but also serves as an inspiration to tackle new challenges and secure the future of computing infrastructure.},
  archive      = {J_CACM},
  author       = {Richard A. DeMillo and Eugene H. Spafford},
  doi          = {10.1145/3720534},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {54-61},
  shortjournal = {Commun. ACM},
  title        = {Grand challenges in trustworthy computing at 20: A retrospective look at the second CRA grand challenges conference},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The price of intelligence. <em>CACM</em>, <em>68</em>(9), 46-53. (<a href='https://doi.org/10.1145/3749447'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CACM},
  author       = {Mark Russinovich and Ahmed Salem and Santiago Zanella-Béguelin and Yonatan Zunger},
  doi          = {10.1145/3749447},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {46-53},
  shortjournal = {Commun. ACM},
  title        = {The price of intelligence},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Concerning the responsible use of AI in the U.S. criminal justice system. <em>CACM</em>, <em>68</em>(9), 41-44. (<a href='https://doi.org/10.1145/3722548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CACM},
  author       = {Cristopher Moore and Catherine Gill and Nadya Bliss and Kevin Butler and Stephanie Forrest and Dan Lopresti and Mary Lou Maher and Helena Mentis and Shashi Shekhar and Amanda Stent and Matthew Turk},
  doi          = {10.1145/3722548},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {41-44},
  shortjournal = {Commun. ACM},
  title        = {Concerning the responsible use of AI in the U.S. criminal justice system},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global AI cultures. <em>CACM</em>, <em>68</em>(9), 37-40. (<a href='https://doi.org/10.1145/3722547'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CACM},
  author       = {Simone Natale and Federico Biggio and Payal Arora and John Downey and Riccardo Fassone and Rafael Grohmann and Andrea Guzman and Emily Keightley and Deqiang Ji and Vincent Obia and Aleksandra Przegalinska and Usha Raman and Paola Ricaurte and Eduardo Villanueva-Mansilla},
  doi          = {10.1145/3722547},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {37-40},
  shortjournal = {Commun. ACM},
  title        = {Global AI cultures},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stop using vulnerability counts to measure software security. <em>CACM</em>, <em>68</em>(9), 34-36. (<a href='https://doi.org/10.1145/3718081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CACM},
  author       = {Andy Meneely and Brandon Keller},
  doi          = {10.1145/3718081},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {34-36},
  shortjournal = {Commun. ACM},
  title        = {Stop using vulnerability counts to measure software security},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three AI futures. <em>CACM</em>, <em>68</em>(9), 31-33. (<a href='https://doi.org/10.1145/3747200'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CACM},
  author       = {Peter J. Denning},
  doi          = {10.1145/3747200},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {31-33},
  shortjournal = {Commun. ACM},
  title        = {Three AI futures},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deconstructing the take it down act. <em>CACM</em>, <em>68</em>(9), 28-30. (<a href='https://doi.org/10.1145/3747203'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CACM},
  author       = {James Grimmelmann},
  doi          = {10.1145/3747203},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {28-30},
  shortjournal = {Commun. ACM},
  title        = {Deconstructing the take it down act},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ACM publications finances for 2023 and 2024. <em>CACM</em>, <em>68</em>(9), 21-25. (<a href='https://doi.org/10.1145/3749885'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CACM},
  author       = {Scott Delman and Wendy Hall and Divesh Srivastava},
  doi          = {10.1145/3749885},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {21-25},
  shortjournal = {Commun. ACM},
  title        = {ACM publications finances for 2023 and 2024},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI teams contend with synthetic data’s Jekyll/Hyde roles. <em>CACM</em>, <em>68</em>(9), 17-19. (<a href='https://doi.org/10.1145/3743156'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CACM},
  author       = {Chris Edwards},
  doi          = {10.1145/3743156},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {17-19},
  shortjournal = {Commun. ACM},
  title        = {AI teams contend with synthetic data’s Jekyll/Hyde roles},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI for senior citizens. <em>CACM</em>, <em>68</em>(9), 14-16. (<a href='https://doi.org/10.1145/3743657'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CACM},
  author       = {Sandrine Ceurstemont},
  doi          = {10.1145/3743657},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {14-16},
  shortjournal = {Commun. ACM},
  title        = {AI for senior citizens},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An algorithm for a better bookshelf. <em>CACM</em>, <em>68</em>(9), 11-13. (<a href='https://doi.org/10.1145/3743656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CACM},
  author       = {Erica Klarreich},
  doi          = {10.1145/3743656},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {11-13},
  shortjournal = {Commun. ACM},
  title        = {An algorithm for a better bookshelf},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deleting x: Why SIGDOC left the platform. <em>CACM</em>, <em>68</em>(9), 9-10. (<a href='https://doi.org/10.1145/3743155'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CACM},
  author       = {Morgan C. Banville},
  doi          = {10.1145/3743155},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {9-10},
  shortjournal = {Commun. ACM},
  title        = {Deleting x: Why SIGDOC left the platform},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A generative AI-powered digital twin for adaptive NASH care. <em>CACM</em>, <em>68</em>(9), 8-9. (<a href='https://doi.org/10.1145/3743154'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CACM},
  author       = {Santosh Kumar},
  doi          = {10.1145/3743154},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {8-9},
  shortjournal = {Commun. ACM},
  title        = {A generative AI-powered digital twin for adaptive NASH care},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The case for compact AI. <em>CACM</em>, <em>68</em>(9), 6-7. (<a href='https://doi.org/10.1145/3746057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CACM},
  author       = {Tim Menzies},
  doi          = {10.1145/3746057},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {6-7},
  shortjournal = {Commun. ACM},
  title        = {The case for compact AI},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Will AI destroy the world wide web?. <em>CACM</em>, <em>68</em>(9), 5. (<a href='https://doi.org/10.1145/3749981'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CACM},
  author       = {Moshe Y. Vardi},
  doi          = {10.1145/3749981},
  journal      = {Communications of the ACM},
  month        = {8},
  number       = {9},
  pages        = {5},
  shortjournal = {Commun. ACM},
  title        = {Will AI destroy the world wide web?},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="csur">CSUR - 28</h2>
<ul>
<li><details>
<summary>
(2025). A survey of recent advances and challenges in deep audio-visual correlation learning. <em>CSUR</em>, <em>57</em>(12), 1-46. (<a href='https://doi.org/10.1145/3696445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audio-visual correlation learning aims at capturing and understanding natural phenomena between audio and visual data. The rapid growth of dl propelled the development of proposals that process audio-visual data and can be observed in the number of proposals in the past years. Thus encouraging the development of a comprehensive survey. Besides analyzing the models used in this context, we also discuss some tasks of definition and paradigm applied in AI multimedia. In addition, we investigate objective functions frequently used and discuss how audio-visual data is exploited in the optimization process, i.e., the different methodologies for representing knowledge in the audio-visual domain. In fact, we focus on how human-understandable mechanisms, i.e., structured knowledge that reflects comprehensible knowledge, can guide the learning process. Most importantly, we provide a summarization of the recent progress of ()avcl and discuss the future research directions.},
  archive      = {J_CSUR},
  author       = {Luís Vilaça and Yi Yu and Paula Viana},
  doi          = {10.1145/3696445},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-46},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of recent advances and challenges in deep audio-visual correlation learning},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative AI for intelligent transportation systems: Road transportation perspective. <em>CSUR</em>, <em>57</em>(12), 1-45. (<a href='https://doi.org/10.1145/3719290'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent transportation systems are vital for modern traffic management and optimization, greatly improving traffic efficiency and safety. With the rapid development of generative artificial intelligence (Generative AI) technologies in areas like image generation and natural language processing, generative AI has also played a crucial role in addressing key issues in intelligent transportation systems (ITS), such as data sparsity, difficulty in observing abnormal scenarios, and in modeling data uncertainty. In this review, we systematically investigate the relevant literature on generative AI techniques in addressing key issues in different types of tasks in ITS tailored specifically for road transportation. First, we introduce the principles of different generative AI techniques. Then, we classify tasks in ITS into four types: traffic perception, traffic prediction, traffic simulation, and traffic decision-making. We systematically illustrate how generative AI techniques addresses key issues in these four different types of tasks. Finally, we summarize the challenges faced in applying generative AI to ITS, and discuss future research directions based on different application scenarios.},
  archive      = {J_CSUR},
  author       = {Huan Yan and Yong Li},
  doi          = {10.1145/3719290},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-45},
  shortjournal = {ACM Comput. Surv.},
  title        = {Generative AI for intelligent transportation systems: Road transportation perspective},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Benchmarking relaxed differential privacy in private learning: A comparative survey. <em>CSUR</em>, <em>57</em>(12), 1-34. (<a href='https://doi.org/10.1145/3729216'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential privacy (DP), a rigorously quantifiable privacy preservation technique, has found widespread application within the domain of machine learning. As DP techniques are implemented in machine learning algorithms, a significant and intricate tradeoff between privacy and utility emerges, garnering extensive attention from researchers. In the pursuit of striking a delicate equilibrium between safeguarding sensitive data and optimizing its utility, researchers have introduced various variants of Relaxed Differential Privacy (RDP) definitions. These nuanced formulations, however, exhibit substantial diversity in their underlying principles and interpretations of the core concept of DP, thereby engendering a current void in the comprehensive synthesis of these related works. The principal objective of this article is twofold. Firstly, it aims to provide a comprehensive summary of pertinent research endeavors pertaining to RDP within the realm of machine learning. Secondly, it endeavors to empirically assess the impact on both privacy and utility stemming from machine learning algorithms founded upon these RDP definitions. Additionally, this article undertakes a systematic analysis of the foundational principles underpinning distinct variants of relaxed definitions, culminating in the development of a taxonomy that categorizes these RDP definitions.},
  archive      = {J_CSUR},
  author       = {Zhaolong Zheng and Lin Yao and Haibo Hu and Guowei Wu},
  doi          = {10.1145/3729216},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Benchmarking relaxed differential privacy in private learning: A comparative survey},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unravelling digital forgeries: A systematic survey on image manipulation detection and localization. <em>CSUR</em>, <em>57</em>(12), 1-36. (<a href='https://doi.org/10.1145/3731243'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning has made significant strides, especially in computer vision applications and, more specifically, in information forensics. On the other hand, data-driven approaches have shown much promise in identifying manipulations in images and videos. However, most forensic tools ignore deep learning in favour of more traditional methodologies. This article thoroughly analyses the current state-of-the-art methods for detecting and localizing image alteration using classical and deep learning-based algorithms. In addition, this review includes the latest developments in the digital image forensics field, including Convolutional Neural Networks (CNNs), while incorporating insights from classical approaches and machine learning models. Furthermore, the most significant data-driven techniques to address the issue of image manipulation detection and localization are presented and segregated into four subtopics: copy-move, splicing, object removal, and contrast enhancement. This study provides an exhaustive and up-to-date survey of the field for researchers and practitioners working in this domain. In addition, it covers the current challenges and future directions in deep learning for image manipulation detection and localization. Finally, this review’s discussion of relevant approaches and experiments will aid future exploration and development in this field.},
  archive      = {J_CSUR},
  author       = {VijayaKumar Kadha and Sambit Bakshi and Santos Kumar Das},
  doi          = {10.1145/3731243},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Unravelling digital forgeries: A systematic survey on image manipulation detection and localization},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intrusion detection based on federated learning: A systematic review. <em>CSUR</em>, <em>57</em>(12), 1-65. (<a href='https://doi.org/10.1145/3731596'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolution of cybersecurity is closely linked to the development and improvement of artificial intelligence (AI). As a key tool for realizing more cybersecure ecosystems, Intrusion Detection Systems (IDSs) have evolved tremendously in recent years by integrating machine learning (ML) techniques to detect increasingly sophisticated cybersecurity attacks hidden in big data. However, traditional approaches rely on centralized learning, in which data from end nodes are shared with data centers for analysis. Recently, the application of federated learning (FL) in this context has attracted great interest to come up with collaborative intrusion detection approaches where data does not need to be shared. Due to the recent rise of this field, this work presents a complete, contemporary taxonomy for FL-enabled IDS approaches that stems from a comprehensive survey of the literature from 2018 to 2022. Precisely, our discussion includes an analysis of the main ML models, datasets, aggregation functions, as well as implementation libraries employed by the proposed FL-enabled IDS approaches. On top of everything else, we provide a critical view of the current state of the research around this topic, and describe the main challenges and future directions based on the analysis of the literature and our own experience in this area.},
  archive      = {J_CSUR},
  author       = {Jose Luis Hernandez-Ramos and Georgios Karopoulos and Efstratios Chatzoglou and Vasileios Kouliaridis and Enrique Marmol and Aurora Gonzalez-Vidal and Georgios Kambourakis},
  doi          = {10.1145/3731596},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-65},
  shortjournal = {ACM Comput. Surv.},
  title        = {Intrusion detection based on federated learning: A systematic review},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on off-chain networks: Frameworks, technologies, solutions and challenges. <em>CSUR</em>, <em>57</em>(12), 1-35. (<a href='https://doi.org/10.1145/3735124'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Off-chain networks that support transactions outside of the blockchain can handle large numbers of transactions and relieve the pressure on on-chain storage, showing great potential in mitigating scalability challenges of blockchain. However, since off-chain networks are still in the early stage of development, how to ensure off-chain data security, off-chain trust, off-chain transaction privacy and efficiency has become an important challenge. Against this background, this article provides a comprehensive review on off-chain networks. We first introduce the background, including design motivations, overview, and application scenarios. We then propose key issues related to off-chain networks. After that, we introduce off-chain technologies, including security and privacy based technologies, intelligent off-chain networking and routing technologies, off-chain edge computing technologies, and off-chain transaction scheduling technologies. Subsequently, we summarize mainstream solutions for corresponding key issues and provide learned lessons. Finally, we discuss some research challenges and open issues.},
  archive      = {J_CSUR},
  author       = {Xiaojie Wang and Hanxue Li and Ling Yi and Zhaolong Ning and Xiaoming Tao and Song Guo and Yan Zhang},
  doi          = {10.1145/3735124},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on off-chain networks: Frameworks, technologies, solutions and challenges},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic literature review on neonatal fingerprint recognition. <em>CSUR</em>, <em>57</em>(12), 1-34. (<a href='https://doi.org/10.1145/3735551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neonatal biometrics, especially those based on fingerprint traits, can potentially improve early childhood identification with decisive applications in healthcare, identity management, and other critical social domains. Although many biometric approaches to human recognition exist, most of them cannot be directly applied to neonates. The main barrier is the reduced size of children’s biometric traits, which affects image quality as these traits are still developing. Another issue is the lack of child biometric databases, as a periodic recollection of images is a fundamental part of neonatal identification regarding the feasibility evaluation of temporal recognition. Several works can be found in the literature addressing some of these issues. However, there is still no systematic review allowing a general understanding of these solutions, discussing their links, gaps, comparisons, and open challenges. In this sense, this article presents a systematic literature review on neonatal biometrics. In total, 1,878 papers were screened and classified, resulting in 45 being selected to be analyzed in this study. We detail and compare the results of datasets, scanners, methods, and techniques to achieve and improve neonatal recognition. Finally, research trends are identified and discussed based on the main gaps in the literature.},
  archive      = {J_CSUR},
  author       = {Luiz Fernando Puttow Southier and Gustavo Alexandre Tuchlinowicz Nunes and João Henrique Pereira Machado and Matheus Buratti and Pedro Henrique de Viveiros Trentin and Wesley Augusto Catuzzo de Bona and Barbara de Oliveira Koop and Elioenai Markson Ferreira Diniz and João Victor Costa Mazzochin and João Leonardo Harres Dall Agnol and Lucas Caldeira de Oliveira and Marcelo Filipak and Luiz Antonio Zanlorensi and Marcos Belançon and Jefferson Oliva and Marcelo Teixeira and Dalcimar Casanova},
  doi          = {10.1145/3735551},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic literature review on neonatal fingerprint recognition},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting misuse of security APIs: A systematic review. <em>CSUR</em>, <em>57</em>(12), 1-39. (<a href='https://doi.org/10.1145/3735968'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Security Application Programming Interfaces (APIs) are crucial for ensuring software security. However, their misuse introduces vulnerabilities, potentially leading to severe data breaches and substantial financial loss. Complex API design, inadequate documentation, and insufficient security training often lead to unintentional misuse by developers. The software security community has devised and evaluated several approaches to detecting security API misuse to help developers and organizations. This study rigorously reviews the literature on detecting misuse of security APIs to gain a comprehensive understanding of this critical domain. Our goal is to identify and analyze security API misuses, the detection approaches developed, and the evaluation methodologies employed along with the open research avenues to advance the state-of-the-art in this area. Employing the systematic literature review (SLR) methodology, we analyzed 69 research articles. Our review has yielded (a) identification of 6 security API types; (b) classification of 30 distinct misuses; (c) categorization of detection techniques into heuristic-based and ML-based approaches; and (d) identification of 10 performance measures and 9 evaluation benchmarks. The review reveals a lack of coverage of detection approaches in several areas. We recommend that future efforts focus on aligning security API development with developers’ needs and advancing standardized evaluation methods for detection technologies.},
  archive      = {J_CSUR},
  author       = {Zahra Mousavi and Chadni Islam and Muhammad Ali Babar and Alsharif Abuadbba and Kristen Moore},
  doi          = {10.1145/3735968},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Detecting misuse of security APIs: A systematic review},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A taxonomy and systematic review of gaze interactions for 2D displays: Promising techniques and opportunities. <em>CSUR</em>, <em>57</em>(12), 1-37. (<a href='https://doi.org/10.1145/3736250'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaze input offers strong potential for creating intuitive and engaging user interfaces, but remains constrained by inherent limitations in accuracy and precision. Although extensive research has explored gaze-based interaction over the past three decades, a systematic framework that fully captures the diversity of gaze interaction techniques is still lacking. To address this gap, we present a novel two-dimensional taxonomy that classifies gaze interactions by (1) the type of input , distinguishing between gaze-only and gaze-assisted modalities, and (2) the type of target , differentiating between those requiring absolute gaze coordinates and thus higher accuracy, and those using relative coordinates, which tolerate lower accuracy. Our taxonomy explicitly captures the required input accuracy and interface constraints of each technique, providing clearer guidance for designers of gaze-based interfaces. We apply this taxonomy to review and classify 125 studies of active gaze interactions on 2D displays. The findings highlight promising techniques and identify research opportunities to advance gaze interaction design.},
  archive      = {J_CSUR},
  author       = {Asma Shakil and Christof Lutteroth and Gerald Weber},
  doi          = {10.1145/3736250},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A taxonomy and systematic review of gaze interactions for 2D displays: Promising techniques and opportunities},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised learning for electroencephalogram: A systematic survey. <em>CSUR</em>, <em>57</em>(12), 1-38. (<a href='https://doi.org/10.1145/3736574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) is a non-invasive technique to record bioelectrical signals. Integrating supervised deep learning techniques with EEG signals has recently facilitated automatic analysis across diverse EEG-based tasks. However, the label issues of EEG signals have constrained the development of EEG-based deep models. Obtaining EEG annotations is difficult and requires domain experts to guide collection and labeling, and the variability of EEG signals among different subjects causes significant label shifts. To solve the above challenges, self-supervised learning (SSL) has been proposed to extract representations from unlabeled samples through well-designed pretext tasks. This article concentrates on integrating SSL frameworks with temporal EEG signals to achieve efficient representations and proposes a systematic survey of the SSL for EEG signals. In this article, (1) We introduce the concept and theory of self-supervised learning and typical SSL frameworks. (2) We provide a comprehensive survey of SSL for EEG analysis, including taxonomy, methodology, and technical details of the existing EEG-based SSL frameworks, and discuss the differences between these methods. (3) We investigate the adaptation of the SSL approach to various downstream tasks, including the task description and related benchmark datasets, and further explore its application in large-scale pre-trained foundation models for EEG signals. (4) Finally, we discuss the potential directions for future SSL-EEG research.},
  archive      = {J_CSUR},
  author       = {Weining Weng and Yang Gu and Shuai Guo and Yuan Ma and Zhaohua Yang and Yuchen Liu and Yiqiang Chen},
  doi          = {10.1145/3736574},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Self-supervised learning for electroencephalogram: A systematic survey},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sentiment diffusion in online social networks: A survey from the computational perspective. <em>CSUR</em>, <em>57</em>(12), 1-35. (<a href='https://doi.org/10.1145/3736750'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of mobile technologies, users can easily access Online social networks (OSNs), consequently, massive contents including personal experiences, observations, or opinions are generated online. These contents are being shared and exchanged in OSNs, which have a significant influence on the minds of people toward politics, societies, economics, and so on. In this case, sentiment diffusion which focuses on how the process of information diffusion in OSNs is affected by sentiments has become an important issue. In this survey, we conduct a comprehensive review of the problem. Specifically, we first present the definition and classification of sentiment, introduce the most advanced computational sentiment analysis techniques, list their applications, and disclose available sentiment analysis resources. Then the main OSN components, functionalities, and structural features applied in modeling social networks are analyzed and summarized. Next, a thorough overview of the information diffusion technologies in OSNs, including graph and non-graph models is made. At last, a systematic and in-depth overview of the current state and issues of research on sentiment diffusion in OSNs is provided. This survey provides the necessary knowledge and new insights for relevant researchers to better understand the research state, remaining challenges, and future directions in this field.},
  archive      = {J_CSUR},
  author       = {Han Xu and Minghua Xu and Xianjun Deng and Bang Wang},
  doi          = {10.1145/3736750},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Sentiment diffusion in online social networks: A survey from the computational perspective},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maintainability and scalability in machine learning: Challenges and solutions. <em>CSUR</em>, <em>57</em>(12), 1-36. (<a href='https://doi.org/10.1145/3736751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid advancements in Machine Learning (ML) introduce unique maintainability and scalability challenges. Our research addresses the evolving challenges and identifies ML maintainability and scalability solutions by conducting a thorough literature review of over 17,000 papers, ultimately refining our focus to 124 relevant sources that meet our stringent selection criteria. We present a catalogue of 41 Maintainability and 13 Scalability challenges and solutions across Data, Model Engineering and the overall development of ML applications and systems. This study equips practitioners with insights on building robust ML applications, laying the groundwork for future research on improving ML system robustness at different workflow stages.},
  archive      = {J_CSUR},
  author       = {Karthik Shivashankar and Ghadi Al Hajj and Antonio Martini},
  doi          = {10.1145/3736751},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Maintainability and scalability in machine learning: Challenges and solutions},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive review of causal inference in banking, finance, and insurance. <em>CSUR</em>, <em>57</em>(12), 1-36. (<a href='https://doi.org/10.1145/3736752'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This is a comprehensive survey of the applications of causal inference in the Banking, Financial Services and Insurance (BFSI) domain based on 45 papers published from 1992 to 2023. It categorizes papers into (i) Banking and risk management (ii) Finance (covering investment, asset and portfolio management; behavioral finance and time series), (iii) Financial markets and (iv) Insurance. Exploring methods such as Bayesian Causal Network, Granger Causality, and counterfactuals, the article emphasizes significance of causal inference in explaining predictions of AI/ML models. This survey also recommends promising future research directions in the intersection of causal inference and these domains making it helpful for the professionals working therein.},
  archive      = {J_CSUR},
  author       = {Satyam Kumar and Yelleti Vivek and Vadlamani Ravi and Indranil Bose},
  doi          = {10.1145/3736752},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive review of causal inference in banking, finance, and insurance},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent root cause localization in MicroService systems: A survey and new perspectives. <em>CSUR</em>, <em>57</em>(12), 1-37. (<a href='https://doi.org/10.1145/3736755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Root cause localization is the process of monitoring system behavior and analyzing fault patterns from behavioral data. It is applicable in software development, network operations, and cloud computing. However, with the advent of microservice architectures and cloud-native technologies, root cause localization becomes an arduous task. Frequent updates in systems result in large-scale data and complex dependencies. Traditional analysis methods relying on manual experience and predefined rules have limited data processing and cannot learn new fault patterns from historical knowledge. Artificial Intelligence techniques have emerged as powerful tools to leverage historical knowledge and are now widely used in root cause localization. In this article, we provide a structured overview and a qualitative analysis of root cause localization in microservice systems. To begin with, we review the literature in this area and abstract a workflow of root cause localization, including multimodal data collection, intelligent root cause analysis, and performance evaluation. In particular, we highlight the role played by Artificial Intelligence techniques. Finally, we discuss some open challenges and research directions and propose an end-to-end framework from a new perspective, providing insights for future works.},
  archive      = {J_CSUR},
  author       = {Nan Fu and Guang Cheng and Yue Teng and Guangye Dai and Shui Yu and Zihan Chen},
  doi          = {10.1145/3736755},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Intelligent root cause localization in MicroService systems: A survey and new perspectives},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Supervised learning from data streams: An overview and update. <em>CSUR</em>, <em>57</em>(12), 1-31. (<a href='https://doi.org/10.1145/3737279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The literature on machine learning in the context of data streams is vast and growing. This indicates not only an ongoing interest, but also an ongoing need for a synthesis of new developments in this area. Here, we reformulate the definitions of supervised data-stream learning, alongside consideration of contemporary concept drift and temporal dependence. Equipped with this, carry out a fresh discussion of what constitutes a supervised data-stream learning task; including continual and reinforcement learning; highlighting major assumptions and constraints. We carry out a fresh reconsideration of approaches and methods, with regard to their suitability to modern settings. But more than a categorization of state-of-the-art streaming methods, we provide a re-introduction to what is supervised stream learning, and our emphasis here is a survey of settings, and algorithmic settings. Our main goal is to pull theory and practice of supervised learning over data streams closer together. We conclude that practical stream learning does not mandate an online-learning regime. In the modern context, learning regimes should be selected and developed according to the factual data arrival mode, resource constraints, and maximum robustness and trustworthiness. We finish with a set of recommendations to this effect.},
  archive      = {J_CSUR},
  author       = {Jesse Read and Indre Zliobaite},
  doi          = {10.1145/3737279},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-31},
  shortjournal = {ACM Comput. Surv.},
  title        = {Supervised learning from data streams: An overview and update},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A functionally-grounded benchmark framework for XAI methods: Insights and foundations from a systematic literature review. <em>CSUR</em>, <em>57</em>(12), 1-40. (<a href='https://doi.org/10.1145/3737445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) is transforming industries, offering new opportunities to manage and enhance innovation. However, these advancements bring significant challenges for scientists and businesses, with one of the most critical being the ‘trustworthiness” of AI systems. A key requirement of trustworthiness is transparency , closely linked to explicability . Consequently, the exponential growth of eXplainable AI (XAI) has led to the development of numerous methods and metrics for explainability. Nevertheless, this has resulted in a lack of standardized and formal definitions for fundamental XAI properties (e.g., what do soundness, completeness, and faithfulness of an explanation entail? How is the stability of an XAI method defined?). This lack of consensus makes it difficult for XAI practitioners to establish a shared foundation, thereby impeding the effective benchmarking of XAI methods. This survey article addresses these challenges with two primary objectives. First, it systematically reviews and categorizes XAI properties, distinguishing them between human-centered (relying on empirical studies involving explainees) or functionally-grounded (quantitative metrics independent of explainees). Second, it expands this analysis by introducing a hierarchically structured, functionally grounded benchmark framework for XAI methods, providing formal definitions of XAI properties. The framework’s practicality is demonstrated by applying it to two widely used methods: LIME and SHAP.},
  archive      = {J_CSUR},
  author       = {Dulce Canha and Sylvain Kubler and Kary Främling and Guy Fagherazzi},
  doi          = {10.1145/3737445},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {A functionally-grounded benchmark framework for XAI methods: Insights and foundations from a systematic literature review},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of subgraph optimization for expert team formation. <em>CSUR</em>, <em>57</em>(12), 1-40. (<a href='https://doi.org/10.1145/3737455'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expert Team Formation is the search for gathering a team of experts who are expected to collaboratively work toward accomplishing a given project, a problem that has historically been solved in a variety of ways, including manually in a time-consuming and bias-filled manner, and algorithmically within disciplines like social sciences and management. In the present effort, while providing a taxonomy to distinguish between search-based versus learning-based approaches, we survey graph-based studies from the search-based category, motivated as they comprise the mainstream. We present a unifying and vetted overview of the various definitions in this realm, scrutinize assumptions, and identify shortfalls. We start by reviewing initial approaches to the Expert Team Formation problem to lay the conceptual foundations and set forth the necessary notions for a more grounded view of this realm. Next, we provide a detailed view of graph-based Expert Team Formation approaches based on the objective functions they optimize. We lay out who builds on whom and how algorithms have evolved to solve the drawbacks of previous works. Furthermore, we categorize evaluation schemas and elaborate on metrics and insights that can be drawn from each. Referring to the evaluation schemas and metrics, we compare works and propose future directions.},
  archive      = {J_CSUR},
  author       = {Mahdis Saeedi and Hawre Hosseini and Christine Wong and Hossein Fani},
  doi          = {10.1145/3737455},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of subgraph optimization for expert team formation},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Myoelectric prosthetic hands: A review of muscle synergy, machine learning and edge computing. <em>CSUR</em>, <em>57</em>(12), 1-33. (<a href='https://doi.org/10.1145/3742471'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, the integration of electromyography (EMG) techniques with machine learning has significantly advanced prosthetic device control. Researchers have developed sophisticated deep learning classifiers for gesture recognition and created EMG controllers capable of simultaneous proportional control across multiple degrees of freedom. However, the increasing complexity of these machine learning models demands greater computational power, creating challenges for real-time deployment on embedded prosthetic controllers. Various optimization techniques - including hyperdimensional computing, pruning, and quantization - have demonstrated effectiveness in reducing computational requirements while preserving system performance. Concurrently, biomedical research has explored muscle and task synergies as methods to simplify inputs for machine learning models. This review examines synergy extraction in upper limb prosthetics research and identifies the need for standardized hardware specifications to facilitate proper validation and comparison of research outcomes. Furthermore, it explores how optimization techniques from Internet of Things (IoT) applications could enhance EMG controllers in biomedical settings. The analysis identifies sensor fusion and high-density EMG as particularly promising approaches for achieving robust, generalized control of upper limb prosthetics.},
  archive      = {J_CSUR},
  author       = {Hamdy O. Farag and Mohamed Medhat Gaber and Mohammed Ibrahim Awad and Nancy E. Elhady},
  doi          = {10.1145/3742471},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Myoelectric prosthetic hands: A review of muscle synergy, machine learning and edge computing},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An end-to-end pipeline perspective on video streaming in best-effort networks: A survey and tutorial. <em>CSUR</em>, <em>57</em>(12), 1-47. (<a href='https://doi.org/10.1145/3742472'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remaining a dominant force in Internet traffic, video streaming captivates end users, service providers, and researchers. This article takes a pragmatic approach to reviewing recent advances in the field by focusing on the prevalent streaming paradigm that involves delivering long-form two-dimensional videos over the best-effort Internet with client-side adaptive bitrate (ABR) algorithms and assistance from content delivery networks (CDNs). To enhance accessibility, we supplement the survey with tutorial material. Unlike existing surveys that offer fragmented views, our work provides a holistic perspective on the entire end-to-end streaming pipeline, from video capture by a camera-equipped device to playback by the end user. Our novel perspective covers the ingestion, processing, and distribution stages of the pipeline and addresses key challenges such as video compression, upload, transcoding, ABR algorithms, CDN support, and quality of experience. We review over 200 papers and classify streaming designs by problem-solving methodology, whether based on intuition, theory, or machine learning. The survey further refines these methodology-based categories and characterizes each design by additional traits such as compatible codecs. We connect the reviewed research to real-world applications by discussing the practices of commercial streaming platforms. Finally, the survey highlights prominent current trends and outlines future directions in video streaming.},
  archive      = {J_CSUR},
  author       = {Leonardo Peroni and Sergey Gorinsky},
  doi          = {10.1145/3742472},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-47},
  shortjournal = {ACM Comput. Surv.},
  title        = {An end-to-end pipeline perspective on video streaming in best-effort networks: A survey and tutorial},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph deep learning for time series forecasting. <em>CSUR</em>, <em>57</em>(12), 1-34. (<a href='https://doi.org/10.1145/3742784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph deep learning methods have become popular tools to process collections of correlated time series. Unlike traditional multivariate forecasting methods, graph-based predictors leverage pairwise relationships by conditioning forecasts on graphs spanning the time series collection. The conditioning takes the form of architectural inductive biases on the forecasting architecture, resulting in a family of models called spatiotemporal graph neural networks. These biases allow for training global forecasting models on large collections of time series while localizing predictions w.r.t. each element in the set (nodes) by accounting for correlations among them (edges). Recent advances in graph neural networks and deep learning for time series forecasting make the adoption of such processing framework appealing and timely. However, most studies focus on refining existing architectures by exploiting modern deep-learning practices. Conversely, foundational and methodological aspects have not been subject to systematic investigation. To fill this void, this tutorial paper aims to introduce a comprehensive methodological framework formalizing the forecasting problem and providing design principles for graph-based predictors, as well as methods to assess their performance. In addition, together with an overview of the field, we provide design guidelines and best practices, as well as an in-depth discussion of open challenges and future directions.},
  archive      = {J_CSUR},
  author       = {Andrea Cini and Ivan Marisca and Daniele Zambon and Cesare Alippi},
  doi          = {10.1145/3742784},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Graph deep learning for time series forecasting},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating EEG microstate analysis in cognitive software engineering tasks: A systematic mapping study and taxonomy. <em>CSUR</em>, <em>57</em>(12), 1-36. (<a href='https://doi.org/10.1145/3742899'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performing software engineering (SE) tasks requires the activation of software developers’ brain neural networks. Electroencephalography (EEG) microstate analysis emerges as a promising neurophysiological method to investigate the spatiotemporal dynamics of brain networks at high temporal resolution. An EEG microstate represents a unique topography of electric potentials over the multichannel EEG records. However, academia has neglected classifying published studies on EEG microstate analysis related to SE. Hence, a careful understanding of state-of-the-art studies remains limited and inconclusive. This article aims at classifying studies on the EEG microstate analysis in cognitive SE tasks. We conducted a systematic mapping study following well-established guidelines to answer ten research questions. After careful filtering, 54 primary studies (out of 1.545) were selected from 8 electronic databases. The main results are that most primary studies focus on revealing brain dynamics, exploring a wide range of EEG microstate application contexts and experimental tasks, running empirical studies in a controlled environment, using K -means as a clustering method, applying ICA-based strategy to filter artifacts, such as muscle activity and eye blinks. However, No study has applied EEG microstate analysis to SE, highlighting a significant gap and the need for further research. Finally, this article presents a classification taxonomy and identifies critical challenges and future research directions.},
  archive      = {J_CSUR},
  author       = {Willian Bolzan and Kleinner Farias},
  doi          = {10.1145/3742899},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Investigating EEG microstate analysis in cognitive software engineering tasks: A systematic mapping study and taxonomy},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of program analysis for distributed software systems. <em>CSUR</em>, <em>57</em>(12), 1-45. (<a href='https://doi.org/10.1145/3742900'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed software systems are pervasive today and they are increasingly developed/deployed to meet the growing needs for scalable computing. Given their critical roles in modern information infrastructures, assuring the quality of distributed software is crucial. As a fundamental methodology for software quality assurance in general, program analysis underlies a range of techniques and tools for constructing and assuring distributed systems. Yet to this date, there remains a lack of systematical understanding of what have been done and how far we are in the field of program analysis for distributed systems. To gain a comprehensive and coherent view of this area hence inform relevant future research, this article provides a systematic literature review of the (1) technical approaches , including analysis methodology, modality, underlying representation, algorithmic design, data utilized, and scope, (2) applications , with respect to the quality aspects served, and (3) evaluation , including the datasets and metrics considered, of various program analyses in the domain of distributed software in the past 30 years (1995–2024). In addition to knowledge systematization, we also extend our insights into the limitations of and challenges faced by current technique and evaluation designs, which shed light on potentially promising future research directions .},
  archive      = {J_CSUR},
  author       = {Haipeng Cai},
  doi          = {10.1145/3742900},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-45},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of program analysis for distributed software systems},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on event prediction methods from a systems perspective: Bringing together disparate research areas. <em>CSUR</em>, <em>57</em>(12), 1-37. (<a href='https://doi.org/10.1145/3743672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event prediction is the ability of anticipating future events, i.e., future real-world occurrences, and aims to support the user in deciding on actions that change future events towards a desired state. An event prediction method learns the relation between features of past events and future events. It is applied to newly observed events to predict corresponding future events that are evaluated with respect to the user’s desired future state. If the predicted future events do not comply with this state, actions are taken towards achieving desirable future states. Evidently, event prediction is valuable in many application domains such as business and natural disasters. The diversity of application domains results in a diverse range of methods that are scattered across various research areas which, in turn, use different terminology for event prediction methods. Consequently, sharing methods and knowledge for developing future event prediction methods is restricted. To facilitate knowledge sharing on account of a comprehensive integration and assessment of event prediction methods, we take a systems perspective to integrate event prediction methods into a single system, elicit requirements, and assess existing work with respect to the requirements. Based on the assessment, we identify open challenges and discuss future research directions.},
  archive      = {J_CSUR},
  author       = {Janik-Vasily Benzin and Stefanie Rinderle-Ma},
  doi          = {10.1145/3743672},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on event prediction methods from a systems perspective: Bringing together disparate research areas},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-augmented graph machine learning for drug discovery: A survey. <em>CSUR</em>, <em>57</em>(12), 1-38. (<a href='https://doi.org/10.1145/3744237'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence has become integral to intelligent drug discovery, with Graph Machine Learning (GML) emerging as a powerful structure-based method for modelling graph-structured biomedical data and investigating their properties. However, GML faces challenges such as limited interpretability and heavy dependency on abundant high-quality training data. On the other hand, knowledge-based methods leverage biomedical knowledge databases, e.g., Knowledge Graphs (KGs), to explore unknown knowledge. Nevertheless, KG construction is resource-intensive and often neglects crucial structural information in biomedical data. In response, recent studies have proposed integrating external biomedical knowledge into the GML pipeline to realise more precise and interpretable drug discovery with scarce training data. Nevertheless, a systematic definition for this burgeoning research direction is yet to be established. This survey formally summarises Knowledge-augmented Graph Machine Learning (KaGML) for drug discovery and organises collected KaGML works into four categories following a novel-defined taxonomy. We also present a comprehensive overview of long-standing drug discovery principles and provide the foundational concepts and cutting-edge techniques for graph-structured data and knowledge databases. To facilitate research in this promptly emerging field, we share collected practical resources that are valuable for intelligent drug discovery and provide an in-depth discussion of the potential avenues for future advancements.},
  archive      = {J_CSUR},
  author       = {Zhiqiang Zhong and Anastasia Barkova and Davide Mottin},
  doi          = {10.1145/3744237},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Knowledge-augmented graph machine learning for drug discovery: A survey},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Smart water-IoT: Harnessing IoT and AI for efficient water management. <em>CSUR</em>, <em>57</em>(12), 1-36. (<a href='https://doi.org/10.1145/3744338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The treatment, monitoring, and distribution of drinking water is an integral component of critical national infrastructure and therefore places continually increasing demands on Water Distribution Networks (WDNs). This domain and its sub-sectors face several major problems, namely climate change and drought-induced rises in water consumption from surface and underground reservoirs, in addition to the existence of significant water leaks during transmission to end users. These problems can be addressed by deploying Internet of Things (IoT) systems and smart distribution grids to improve the efficiency and safety of water distribution and to easily detect leaks or unauthorized consumption. This type of smart grid is referred to as Smart Water-IoT (SW-IoT), a novel, comprehensive water management concept. This review article discusses the application of IoT components and artificial intelligence (AI) in five basic categories (agriculture, water treatment, security, WDNs, and wastewater). Relevant legislation in the EU, USA, Canada, Australia, China, Japan, and India is also reviewed. In this context, the mandatory implementation of smart remote data reading solutions into the critical infrastructure of EU member states is outlined to highlight the importance of responsible water handling. The article provides a detailed analysis of the current research in SW-IoT and defines the main research challenges for future investigation.},
  archive      = {J_CSUR},
  author       = {Vlastimil Slany and Eva Krcalova and Jiri Balej and Martin Zach and Tereza Kucova and Michal Prauzek and Radek Martinek},
  doi          = {10.1145/3744338},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Smart water-IoT: Harnessing IoT and AI for efficient water management},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing the effectiveness of ChatGPT in secure code development: A systematic literature review. <em>CSUR</em>, <em>57</em>(12), 1-32. (<a href='https://doi.org/10.1145/3744553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ChatGPT, a Large Language Model (LLM) maintained by OpenAI, has demonstrated a remarkable ability to seemingly comprehend and contextually generate text. Among its myriad applications, its capability to autonomously generate and analyze computer code stands out as particularly promising. This functionality has piqued substantial interest due to its potential to streamline the software development process. However, this technological advancement also brings to the forefront significant apprehensions concerning the security of code produced by LLMs. In this article, we survey recent research that examines the use of ChatGPT to generate secure code, detect vulnerabilities in code, or perform other tasks related to secure code development. Beyond categorizing and synthesizing these studies, we identify important insights into ChatGPT’s potential impact on secure programming. Key findings indicate that while ChatGPT shows great promise as an aid in writing secure code, challenges remain. Its effectiveness varies across security tasks, depending on the context of experimentation (programming language, CWE, code length, etc.) and the benchmark used for comparison–whether against other LLMs, traditional analysis tools, or its own versions. The overall trend indicates that GPT-4 consistently surpasses its predecessor in most tasks.},
  archive      = {J_CSUR},
  author       = {Rezika Bouzid and Raphaël Khoury},
  doi          = {10.1145/3744553},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-32},
  shortjournal = {ACM Comput. Surv.},
  title        = {Assessing the effectiveness of ChatGPT in secure code development: A systematic literature review},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resource provisioning in fog computing - A survey. <em>CSUR</em>, <em>57</em>(12), 1-26. (<a href='https://doi.org/10.1145/3744662'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The internet world has created an era where any device can interconnect with each other. Gathering intelligence from streaming data is challenging and can create wonders and valuable innovations for humanity. The shortcomings of connectivity due to the remote location of the cloud induce latency and performance issues in real-time. Thus, a traditional cloud may not be suitable for all applications. A secure, low latent bandwidth infrastructure under research led to Fog Computing . The fog nodes have limited resources, and effective utilization can boost the application’s performance. Ensuring effective routing of the tasks and load balancing among the nodes is essential and tedious in any network. Resource management becomes challenging due to heterogeneity, dynamic workload, unpredictability of the computing environment, and so on. In such cases, using Artificial Intelligence (AI) can be promising, provided the complexity and the computing are handled. Proactive load handling based on the changes in network traffic has a huge scope for research. This article gives a detailed survey of the various fog network architectures and the intelligent methodologies in resource allocation in a fog network using machine learning algorithms. Furthermore, the article shows the directions of research in intelligent resource allocation and handling.},
  archive      = {J_CSUR},
  author       = {Divya Vetriveeran and Leena Sri R},
  doi          = {10.1145/3744662},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-26},
  shortjournal = {ACM Comput. Surv.},
  title        = {Resource provisioning in fog computing - A survey},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causality in bandits: A survey. <em>CSUR</em>, <em>57</em>(12), 1-30. (<a href='https://doi.org/10.1145/3744917'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The literature on bandits has developed largely independently of advances in causal inference. Work in the last few years has started investigating the close connections between these two areas and that has led to fruitful ideas that have produced advances in bandit algorithms. We present the first survey focusing specifically on the intersection of these two areas. We first provide a taxonomy for categorizing research in this area, and then place important works within this structure. We also describe various algorithms and methods, and provide the highlights. Finally, we point out promising directions for future research in this area.},
  archive      = {J_CSUR},
  author       = {Chandrasekar Subramanian and Balaraman Ravindran},
  doi          = {10.1145/3744917},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-30},
  shortjournal = {ACM Comput. Surv.},
  title        = {Causality in bandits: A survey},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jacm">JACM - 1</h2>
<ul>
<li><details>
<summary>
(2025). Expected constant round byzantine broadcast under dishonest majority. <em>JACM</em>, <em>72</em>(4), 1-39. (<a href='https://doi.org/10.1145/3748254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Byzantine Broadcast (BB) is a central question in distributed systems, and an important challenge is to understand its round complexity. Under the honest majority setting, it is long known that there exist randomized protocols that can achieve BB in expected constant rounds, regardless of the number of nodes n . However, whether we can match the expected constant round complexity in the corrupt majority setting —or more precisely, when \(f \ge n/2 + \omega (1)\) —remains unknown, where f denotes the number of corrupt nodes. In this article, we are the first to resolve this long-standing question. We show how to achieve BB in expected \(O((n/(n-f))^2)\) rounds. Our results hold under a weakly adaptive adversary who cannot perform “after-the-fact removal” of messages already sent by a node before it becomes corrupt. We also assume trusted setup and the Decision Linear (DLIN) assumption in bilinear groups.},
  archive      = {J_JACM},
  author       = {Jun Wan and Hanshen Xiao and Elaine Shi and Srinivas Devadas},
  doi          = {10.1145/3748254},
  journal      = {Journal of the ACM},
  month        = {8},
  number       = {4},
  pages        = {1-39},
  shortjournal = {J. ACM},
  title        = {Expected constant round byzantine broadcast under dishonest majority},
  volume       = {72},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="taas">TAAS - 10</h2>
<ul>
<li><details>
<summary>
(2025). Adaptive scheduling of high-availability drone swarms for congestion alleviation in connected automated vehicles. <em>TAAS</em>, <em>20</em>(3), 1-19. (<a href='https://doi.org/10.1145/3673905'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Intelligent Transportation System (ITS) serves as a pivotal element within urban networks, offering decision support to users and connected automated vehicles through comprehensive information gathering, sensing, device control, and data processing. Presently, ITS predominantly relies on sensors embedded in fixed infrastructure, notably Roadside Units (RSUs). However, RSUs are confined by coverage limitations and may encounter challenges in prompt emergency responses. On-demand resources, such as drones, present a viable option to supplement these deficiencies effectively. This article introduces an approach where Software-Defined Networking and Mobile Edge Computing technologies are integrated to formulate a high-availability drone swarm control and communication infrastructure framework comprising the cloud layer, edge layer, and device layer. Drones confront limitations in flight duration attributed to battery limitations, posing a challenge in sustaining continuous monitoring of road conditions over extended periods. Effective drone scheduling stands as a promising solution to overcome these constraints. To tackle this issue, we initially utilized Graph WaveNet, a specialized graph neural network structure tailored for spatial-temporal graph modeling, for training a congestion prediction model using real-world dataset inputs. Building upon this, we further propose an algorithm for drone scheduling based on congestion prediction. Our simulation experiments using real-world data demonstrate that, compared to the baseline method, the proposed scheduling algorithm not only yielded superior scheduling gains but also mitigated drone idle rates.},
  archive      = {J_TAAS},
  author       = {Shengye Pang and Yi Li and Zhen Qin and Xinkui Zhao and Jintao Chen and Fan Wang and Jianwei Yin},
  doi          = {10.1145/3673905},
  journal      = {ACM Transactions on Autonomous and Adaptive Systems},
  month        = {9},
  number       = {3},
  pages        = {1-19},
  shortjournal = {ACM Trans. Auton. Adapt. Syst.},
  title        = {Adaptive scheduling of high-availability drone swarms for congestion alleviation in connected automated vehicles},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Secure collaborative learning for self-adaptive systems on connected autonomous vehicles. <em>TAAS</em>, <em>20</em>(3), 1-30. (<a href='https://doi.org/10.1145/3690768'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an advanced carrier of on-board sensors, connected autonomous vehicle (CAV) can be viewed as an aggregation of self-adaptive systems with monitor-analyze-plan-execute (MAPE) for vehicle-related services. Meanwhile, machine learning (ML) has been applied to enhance analysis and plan functions of MAPE so that self-adaptive systems have optimal adaption to changing conditions. However, most of ML-based approaches don’t utilize CAVs’ connectivity to collaboratively generate an optimal learner for MAPE, because of sensor data threatened by gradient leakage attack (GLA). In this article, we first design an intelligent architecture for MAPE-based self-adaptive systems on web 3.0-based CAVs, in which a collaborative machine learner supports the capabilities of managing systems. Then, we observe by practical experiments that importance sampling of sparse vector technique (SVT) approaches cannot defend GLA well. Next, we propose a fine-grained SVT approach to secure the learner in MAPE-based self-adaptive systems that uses layer and gradient sampling to select uniform and important gradients. At last, extensive experiments show that our private learner spends a slight utility cost for MAPE (e.g., \(0.77\%\) decrease in accuracy) defending GLA and outperforms the typical SVT approaches in terms of defense (increased by \(10\) – \(14\%\) attack success rate) and utility (decreased by \(1.29\%\) accuracy loss).},
  archive      = {J_TAAS},
  author       = {Xiaotong Wu and Yuwen Liu and Xiaoxiao Chi and Rong Jiang and Xiaokang Zhou and Wajid Rafique and Maqbool Khan},
  doi          = {10.1145/3690768},
  journal      = {ACM Transactions on Autonomous and Adaptive Systems},
  month        = {9},
  number       = {3},
  pages        = {1-30},
  shortjournal = {ACM Trans. Auton. Adapt. Syst.},
  title        = {Secure collaborative learning for self-adaptive systems on connected autonomous vehicles},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A consortium blockchain-based edge task offloading method for connected autonomous vehicles. <em>TAAS</em>, <em>20</em>(3), 1-27. (<a href='https://doi.org/10.1145/3696004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the proliferation of Connected Autonomous Vehicles (CAV) has revolutionized the transportation industry. However, these vehicles often face limitations in terms of local computing resources, leading to the need for offloading interactive-intensive application tasks to servers for processing. Traditional paradigm has its limitations in meeting the demands of massive task processing. The combination of Web3.0 and edge computing offers users high-reliable, low-latency, and highly flexible services. Nevertheless, the new paradigm also presents its own challenges such as ensuring privacy data protection, and reducing the time and energy costs associated with task offloading. To tackle these challenges, an edge task offloading framework based on consortium blockchain for CAVs has been developed. Within this framework, a consortium blockchain-based interaction-intensive task offloading method, called CBIToMe, has been designed. CBIToMe specifically addresses the multi-stage nature of interactive-intensive CAV tasks and aims to minimize task completion time and offloading costs, particularly when the waiting time for interaction is uncertain. Additionally, CBIToMe effectively utilizes consortium blockchain technology to safeguard the CAV privacy data. Results from experiments conducted in various scenarios demonstrate that CBIToMe outperforms three representative methods, showcasing its superior performance.},
  archive      = {J_TAAS},
  author       = {Bowen Liu and Hao Tian and Zhijie Shen and Yueyue Xu and Wanchun Dou},
  doi          = {10.1145/3696004},
  journal      = {ACM Transactions on Autonomous and Adaptive Systems},
  month        = {9},
  number       = {3},
  pages        = {1-27},
  shortjournal = {ACM Trans. Auton. Adapt. Syst.},
  title        = {A consortium blockchain-based edge task offloading method for connected autonomous vehicles},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent reinforcement learning based edge content caching for connected autonomous vehicles in IoV. <em>TAAS</em>, <em>20</em>(3), 1-26. (<a href='https://doi.org/10.1145/3699431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Connected Autonomous Vehicle (CAV) Driving, as a data-driven intelligent driving technology within the Internet of Vehicles (IoV), presents significant challenges to the efficiency and security of real-time data management. The combination of Web3.0 and edge content caching holds promise in providing low-latency data access for CAVs’ real-time applications. Web3.0 enables the reliable pre-migration of frequently requested content from content providers to edge nodes. However, identifying optimal edge node peers for joint content caching and replacement remains challenging due to the dynamic nature of traffic flow in IoV. Addressing these challenges, this article introduces GAMA-Cache, an innovative edge content caching methodology leveraging Graph Attention Networks (GAT) and Multi-Agent Reinforcement Learning (MARL). GAMA-Cache conceptualizes the cooperative edge content caching issue as a constrained Markov decision process. It employs a MARL technique predicated on cooperation effectiveness to discern optimal caching decisions, with GAT augmenting information extracted from adjacent nodes. A distinct collaborator selection mechanism is also developed to streamline communication between agents, filtering out those with minimal correlations in the vector input to the policy network. Experimental results demonstrate that, in terms of service latency and delivery failure, the GAMA-Cache outperforms other state-of-the-art MARL solutions for edge content caching in IoV.},
  archive      = {J_TAAS},
  author       = {Xiaolong Xu and Linjie Gu and Muhammad Bilal and Maqbool Khan and Yiping Wen and Guoqiang Liu and Yuan Yuan},
  doi          = {10.1145/3699431},
  journal      = {ACM Transactions on Autonomous and Adaptive Systems},
  month        = {9},
  number       = {3},
  pages        = {1-26},
  shortjournal = {ACM Trans. Auton. Adapt. Syst.},
  title        = {Multi-agent reinforcement learning based edge content caching for connected autonomous vehicles in IoV},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining personalized federated hypernetworks and shared residual learning for distributed QoS prediction. <em>TAAS</em>, <em>20</em>(3), 1-25. (<a href='https://doi.org/10.1145/3709141'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Connected vehicles due to the high mobility and dynamic network topologies of connected vehicles require accurate QoS that includes high throughput and low latency to assess satisfactory QoE. Existing methods mainly focus on centralized QoS prediction while paying little attention to distributed mobile QoS prediction, making it challenging to protect user privacy information when invoking Web services. Moreover, even though some advanced centralized methods can be transformed into federated architectures, they often face difficulty in capturing latent feature representations of users and services and learning personalized prediction layers between them due to the heterogeneity of the QoS dataset. To address the above issues, we propose a novel framework for distributed QoS prediction, called Combining Personalized Federated Hypernetworks and Shared Residual Learning for Distributed QoS Prediction (FHR-DQP) . FHR-DQP adopts the federated averaging (FedAvg) to aggregate location-aware residual shared feature information across all clients. Additionally, a hypernetwork is leveraged to generate personalized networks for user-service QoS prediction in each client. These components are integrated as a hybrid framework that performs training using a federated approach and makes personalized QoS predictions within each client. Extensive experiments are conducted on a real-world benchmark QoS dataset called WS-DREAM, containing nearly 2,000,000 historical QoS invocation records. Compared with both centralized and federated competing baselines, the results demonstrate that FHR-DQP achieves the highest performance for distributed QoS prediction, when it provides privacy-preserving of users’ QoS invocations.},
  archive      = {J_TAAS},
  author       = {Guobing Zou and Shiyi Lin and Shaogang Wu and Shengxiang Hu and Song Yang and Yanglan Gan and Bofeng Zhang and Yixin Chen},
  doi          = {10.1145/3709141},
  journal      = {ACM Transactions on Autonomous and Adaptive Systems},
  month        = {9},
  number       = {3},
  pages        = {1-25},
  shortjournal = {ACM Trans. Auton. Adapt. Syst.},
  title        = {Combining personalized federated hypernetworks and shared residual learning for distributed QoS prediction},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LyDRL: Lyapunov-guided deep reinforcement learning for stable task offloading in connected autonomous vehicles. <em>TAAS</em>, <em>20</em>(3), 1-29. (<a href='https://doi.org/10.1145/3715333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task offloading is recognized as a promising approach to enhance the computational performance of Connected Autonomous Vehicles (CAVs). Some applications of CAVs, such as metaverse applications, require substantial resources, posing significant challenges to CAVs with limited computing and storage capacities. CAVs can offload resource-intensive applications to the Vehicular Edge Computing (VEC) server, which has strong computing capabilities. To fully utilize the resources in the CAV system, partial offloading is employed. However, the local computing resources are limited for continuously generated partial offloading tasks. This results in many partially locally executed tasks experiencing long processing times or being discarded, which is detrimental to delay-sensitive tasks on CAVs. This article proposes Lyapunov function-guided reinforcement learning for the CAVs task offloading computational framework, LyDRL. Specifically, LyDRL first uses the Lyapunov function to transform the long-term objective optimization problem into subproblems determined at each time slot. In each time slot, deep reinforcement learning is used to obtain the optimal task offloading decision while satisfying the constraints. Simulation results show that compared with the existing algorithms, the proposed strategy can ensure the stability of the CAVs system and achieve the lowest system overhead.},
  archive      = {J_TAAS},
  author       = {Yanming Chen and Ziyang Huang and Yiwen Zhang and Weiwei Fang and Neal N. Xiong},
  doi          = {10.1145/3715333},
  journal      = {ACM Transactions on Autonomous and Adaptive Systems},
  month        = {9},
  number       = {3},
  pages        = {1-29},
  shortjournal = {ACM Trans. Auton. Adapt. Syst.},
  title        = {LyDRL: Lyapunov-guided deep reinforcement learning for stable task offloading in connected autonomous vehicles},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Web 3.0-enabled microservice re-scheduling for heterogenous resources co-optimization in metaverse-integrated edge networks. <em>TAAS</em>, <em>20</em>(3), 1-26. (<a href='https://doi.org/10.1145/3715700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Web 3.0 and metaverse can empower intelligent application of Connected Autonomous Vehicles (CAVs). The adoption of edge computing can contribute to the low latency interaction between CAVs and the metaverse. Microservices are widely deployed on edge networks and the cloud nowadays. User’s requests from CAVs are typically fulfilled through the composition of microservices, which may be hosted by contiguous edge nodes. Requests may differ on their required resources at runtime. Consequently, when requests are continuously injected into edge networks, the usage of heterogenous resources, including CPU, memory, and network bandwidth, may not be the same, or differ significantly, on certain edge nodes. This happens especially when burst requests are injected into the network to be satisfied concurrently. Therefore, the usage of heterogenous resources provided by edge nodes should be co-optimized through re-scheduling microservices. To address this challenge, this article proposes a Web 3.0-enabled M icroservice R e- S cheduling approach (called MRS ), which is a migration-based mechanism integrating a placement strategy. Specifically, we formulate the MRS task as a multi-objective and multi-constraint optimization problem, which can be solved through a penalty signal-integrated framework and an improved pointer network. Extensive experiments are conducted on two real-world datasets. Evaluation results show that our MRS performs better than the counterparts with improvements of at least 7.7%, 2.4%, and 2.2% in terms of network throughput, latency, and energy consumption, respectively.},
  archive      = {J_TAAS},
  author       = {Yihong Yang and Zhangbing Zhou and Lei Shu and Feng Zhou and Walid Gaaloul and Arif Ali Khan},
  doi          = {10.1145/3715700},
  journal      = {ACM Transactions on Autonomous and Adaptive Systems},
  month        = {9},
  number       = {3},
  pages        = {1-26},
  shortjournal = {ACM Trans. Auton. Adapt. Syst.},
  title        = {Web 3.0-enabled microservice re-scheduling for heterogenous resources co-optimization in metaverse-integrated edge networks},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QSTMF: Quantum-secured trust management framework for VANETs in web 3.0 and metaverse. <em>TAAS</em>, <em>20</em>(3), 1-29. (<a href='https://doi.org/10.1145/3735672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Connected Autonomous Vehicles (CAVs) need a reliable communication structure which enables the complete evolution of transportation systems. Our proposed trust management strategy implements Quantum Key Distribution (QKD) and blockchain technology for solving CAV network security and coherence problems. The system applies QKD to produce unbreakable quantum keys which defend vehicle communication networks and blockchain systems strengthen governing networks by decentralizing operations and ensuring transparency and credibility. This framework employs QKD together with blockchain technology through a structure that demonstrates adaptability to changing networking conditions and cyber dangers within CAV environments. The independent operational mindset allows for automatic security rule updates that result in steady improvements to the encryption standards and system protocols. The framework demonstrates its functionality through simulations performed on multiple traffic conditions featuring different speeds together with density levels. The analysis included evaluation of energy efficiency together with overhead ratio performance as well as QKD success rates and blockchain verification duration. The testing results demonstrate that this system performs effectively under different operational scenarios while demonstrating strong defense capabilities against Sybil and Wormhole security attacks. Under dense traffic scenarios, Quantum-Secured Trust Management Framework (QSTMF) delivered improved network throughput reaching 15% above current models while high-speed traffic circumstances led to 20% diminished blockchain verification times. Attack detection rate performance of the framework exceeded 90% throughout multiple attack simulations indicating its robust capabilities for vehicle communication protection.},
  archive      = {J_TAAS},
  author       = {Kamran Ahmad Awan and Ikram Ud Din and Ahmad Almogren and Joel J. P. C. Rodrigues},
  doi          = {10.1145/3735672},
  journal      = {ACM Transactions on Autonomous and Adaptive Systems},
  month        = {9},
  number       = {3},
  pages        = {1-29},
  shortjournal = {ACM Trans. Auton. Adapt. Syst.},
  title        = {QSTMF: Quantum-secured trust management framework for VANETs in web 3.0 and metaverse},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). INSYTE: A classification framework for traditional to agentic AI systems. <em>TAAS</em>, <em>20</em>(3), 1-39. (<a href='https://doi.org/10.1145/3760424'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing classification frameworks for AI and autonomous systems are being outpaced by recent advancements in AI technologies. This limits their applicability to modern intelligent systems, particularly agentic AI systems (autonomous systems that leverage foundation models to achieve wide-ranging, multi-layered goals). To address this deficiency, we introduce INSYTE, a multi-faceted framework that supports the classification of AI systems ranging from traditional rule-based systems to cutting-edge embodied AI and agentic systems. To that end, INSYTE considers the essential characteristics of an AI system across eight key dimensions grouped into four categories: system design ( underspecification and adaptiveness ); functionality ( breadth and depth ); operating environment ( diversity and dynamism ); and independence from human operational control ( intervention and oversight ). Different AI systems (or versions of systems) yield different ‘patterns’ on an eight-axis radar chart that INSYTE uses to provide an immediate visual summary of an AI system’s overall capability and a detailed representation of its individual characteristics. The INSYTE framework aligns with OECD’s definition of deployed AI systems, which is becoming the standard definition used by legislators and developers worldwide.},
  archive      = {J_TAAS},
  author       = {Zoe Porter and Radu Calinescu and Ernest Lim and Victoria Hodge and Philippa Ryan and Simon Burton and Ibrahim Habli and Tom Lawton and John McDermid and John Molloy and Helen Monkhouse and Phillip Morgan and Paul Noordhof and Colin Paterson and Isobel Standen and Jie Zou},
  doi          = {10.1145/3760424},
  journal      = {ACM Transactions on Autonomous and Adaptive Systems},
  month        = {9},
  number       = {3},
  pages        = {1-39},
  shortjournal = {ACM Trans. Auton. Adapt. Syst.},
  title        = {INSYTE: A classification framework for traditional to agentic AI systems},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Introduction to the special issue on intelligent applications of web 3.0 and metaverse for connected autonomous vehicles. <em>TAAS</em>, <em>20</em>(3), 1-4. (<a href='https://doi.org/10.1145/3761817'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TAAS},
  author       = {Lianyong Qi and Burak Kantarci and Houbing Song and Anna Maria Vegni},
  doi          = {10.1145/3761817},
  journal      = {ACM Transactions on Autonomous and Adaptive Systems},
  month        = {9},
  number       = {3},
  pages        = {1-4},
  shortjournal = {ACM Trans. Auton. Adapt. Syst.},
  title        = {Introduction to the special issue on intelligent applications of web 3.0 and metaverse for connected autonomous vehicles},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="taco">TACO - 37</h2>
<ul>
<li><details>
<summary>
(2025). HopScotch: A holistic approach to data layout-aware mapping on NPUs for high-performance DNN inference. <em>TACO</em>, <em>22</em>(3), 1-26. (<a href='https://doi.org/10.1145/3711821'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern deep neural networks (DNNs) are widely utilized across a broad range of domains, scaling rapidly and often comprising hundreds of diverse layers with varying types and configurations. To accelerate DNN execution, specialized hardware solutions, known as neural processing units (NPUs), have been developed. However, this heterogeneity of layers in a DNN model may cause performance degradation on NPUs. For example, while a layer’s execution or dataflow is generally associated with a specific data access order, the data layout in on-chip memory may not be well aligned with it, introducing bubble cycles for layout reordering. Given the hundreds of diverse layers in DNNs, this layout reordering overhead presents a new challenge for achieving efficient end-to-end DNN inference on NPUs. To address this problem, this article introduces HopScotch, a holistic approach to data layout-aware mapping of DNNs on NPUs. First, HopScotch adopts a routing interconnect between the on-chip memory and the systolic array utilizing three-input multiplexers, paired with an on-chip programmable vector processor to manage arbitrary data layout reordering at runtime. Additionally, it introduces a tailored data layout to accommodate a variety of convolutional configurations within the proposed microarchitecture. Second, HopScotch presents a novel layout mapping solver that employs a top-k selection strategy based on a beam search algorithm, facilitating the efficient exploration of the vast layout mapping space at compile time. Third, the proposed layout mapping solver is integrated into the HopScotch mapping framework (HMF) to explore the layout mapping space and evaluate the resulting performance. Experiments with popular DNN models show that HopScotch reduces layout reordering costs by up to 98.2% and 90.3%, resulting in speedups of 2.62× and 1.64× in end-to-end latency, compared to XLA and GCD 2 , respectively.},
  archive      = {J_TACO},
  author       = {Suhong Lee and Boyeal Kim and Yongseok Choi and Hyuk-Jae Lee},
  doi          = {10.1145/3711821},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-26},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {HopScotch: A holistic approach to data layout-aware mapping on NPUs for high-performance DNN inference},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LarQucut: A new cutting and mapping approach for large-sized quantum circuits in distributed quantum computing (DQC) environments. <em>TACO</em>, <em>22</em>(3), 1-24. (<a href='https://doi.org/10.1145/3730585'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed quantum computing (DQC) is a promising way to achieve large-scale quantum computing. However, mapping large-sized quantum circuits in DQC is a challenging job; for example, it is difficult to find an ideal cutting and mapping solution when many qubits, complicated qubit operations, and diverse QPUs are involved. In this study, we propose LarQucut, a new quantum circuit cutting and mapping approach for large-sized circuits in DQC. LarQucut has several new designs. (1) LarQucut can have cutting solutions that use fewer cuts, and it does not cut a circuit into independent sub-circuits, therefore reducing the overall cutting and computing overheads. (2) LarQucut finds isomorphic sub-circuits and reuses their execution results. So, LarQucut can reduce the number of sub-circuits that need to be executed to reconstruct the large circuit's output, reducing the time spent on sampling the sub-circuits. (3) We design an adaptive quantum circuit mapping approach, which identifies qubit interaction patterns and accordingly enables the best-fit mapping policy in DQC. The experimental results show that, for large circuits with hundreds to thousands of qubits in DQC, LarQucut can provide a better cutting and mapping solution with lower overall overheads and achieves results closer to the ground truth.},
  archive      = {J_TACO},
  author       = {Xinglei Dou and Lei Liu and Zhuohao Wang and Pengyu Li},
  doi          = {10.1145/3730585},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-24},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {LarQucut: A new cutting and mapping approach for large-sized quantum circuits in distributed quantum computing (DQC) environments},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards optimizing learned index for high performance, memory efficiency and NUMA awareness. <em>TACO</em>, <em>22</em>(3), 1-26. (<a href='https://doi.org/10.1145/3736168'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learned indexes provide significant performance advantages over classical ordered indexes. However, current learned indexes face challenges regarding tradeoffs between performance and space, as well as scalability issues in platforms with multiple NUMA nodes. These limitations hinder the practical application of learned indexes in production environments. This article presents DiffLex, a learned index with high-performance, memory-efficiency, and NUMA-awareness. The core design of DiffLex is to perform differentiated management based on the popularity of data. For optimal performance, DiffLex stores newly inserted data in sparse delta arrays and frequently accessed data in sparse hot cache arrays. However, for cold data that occupy a majority of the storage space, DiffLex stores them in dense arrays and conducts compression to reduce memory costs. DiffLex ensures NUMA-awareness by partitioning sparse deltas and replicating the hot cache arrays across multiple NUMA nodes. Additionally, we propose a persistent version of DiffLex tailored for emerging persistent memory devices. Our evaluation results demonstrate that DiffLex achieving 3.88× and 1.82× performance improvements compared to state-of-the-art learned indexes, while maintaining a compact index size.},
  archive      = {J_TACO},
  author       = {Lixiao Cui and Kedi Yang and Yusen Li and Gang Wang and Xiaoguang Liu},
  doi          = {10.1145/3736168},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-26},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {Towards optimizing learned index for high performance, memory efficiency and NUMA awareness},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Benchmarking WebAssembly for embedded systems. <em>TACO</em>, <em>22</em>(3), 1-21. (<a href='https://doi.org/10.1145/3736169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {WebAssembly is a modern, low-level virtual machine with designed for improved application performance in web browsers. Recently, WebAssembly gained interest for its use outside the web, for example as a replacement for serverless container runtimes. A number of non-web WebAssembly implementations are actively supported, some of which target microcontrollers, IoT devices, and embedded systems. Such hardware platforms have strict resource constraints which may render the usage of WebAssembly impossible or too costly, for example, due to its performance overhead and memory requirements. However, it is currently unclear what performance to expect of WebAssembly on low-resource microcontrollers compared with machine code and alternative application virtual machines. To answer this question, we evaluated the processing overhead and memory characteristics of WebAssembly application virtual machines on microcontrollers, and compared it to native execution, and the established application virtual machines: MicroPython and Lua. Furthermore, we analyzed the feature-set and architecture of the WebAssembly implementations in more detail, and measured the performance impact different runtime features have. We found that WebAssembly, despite its high extensibility and versatility in supported source languages, application paradigms, and target hardware, delivers very competitive performance. We conclude that WebAssembly can find wider industry usage for embedded systems and could replace other more costly or less flexible virtualization techniques, such as Java.},
  archive      = {J_TACO},
  author       = {Konrad Moron and Stefan Wallentowitz},
  doi          = {10.1145/3736169},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-21},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {Benchmarking WebAssembly for embedded systems},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BigLittleMCA: A spatially-optimal tiled hardware accelerator for MCMC image processing. <em>TACO</em>, <em>22</em>(3), 1-26. (<a href='https://doi.org/10.1145/3736171'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Markov-Chain Monte-Carlo (MCMC) algorithms offer a general framework for performing interpretable inference but have high overheads due to the computational complexity of the sampling process and the large number of samples required to produce an accurate result. Computer Vision is a common class of workloads that can be performed using MCMC methods. As computer vision workloads trend toward high-resolution real-time inference, it becomes challenging to perform inference in contexts such as edge computing, which operates under strict power and area budgets. Previous work explores hardware techniques for efficient sampling; however, MCMC algorithms still require many samples. We reduce the overheads of Gibbs Sampling, an MCMC algorithm, using an approach we call mixed-resolution sampling. This approach uses low-resolution inference to provide a starting point for full-resolution sampling. We evaluate this approach on three important computer vision tasks: stereo matching, optical flow, and blind source separation. Mixed-resolution sampling reduces root mean square error (RMSE) by an average of 19.6% for stereo-matching tasks, 13% for optical flow tasks, and 6.3% for blind source separation relative to traditional Gibbs Sampling. To enable real-time, explainable MCMC inference under edge power constraints, we exploit the structure of mixed-resolution sampling to architect and implement a hardware-software co-designed accelerator architecture, BigLittleMCA ( Big - Little MC MC A ccelerator). BigLittleMCA is a tiled MCMC accelerator architecture that uses a small sampler for low-resolution sampling and a large sampler for full-resolution sampling. Our results show that the architecture sustains real-time 720p inference at 30 FPS (frames per second) using 48.5% less power than prior work.},
  archive      = {J_TACO},
  author       = {Chris Kjellqvist and Lisa Wills and Alvin Lebeck},
  doi          = {10.1145/3736171},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-26},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {BigLittleMCA: A spatially-optimal tiled hardware accelerator for MCMC image processing},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attack and defense: Enhancing robustness of binary hyper-dimensional computing. <em>TACO</em>, <em>22</em>(3), 1-25. (<a href='https://doi.org/10.1145/3736172'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyper-Dimensional Computing (HDC) has emerged as a lightweight computational model, renowned for its robust and efficient learning capabilities, particularly suitable for resource-constrained hardware. As HDC often finds its application in edge devices, the associated security challenges pose a critical concern that cannot be ignored. In this work, we aim to quantitatively delve into the robustness of binary HDC, which is widely recognized for its robustness. Employing the bit-flip attack as our initial focal point, we meticulously devise both an attack mechanism and a corresponding defense mechanism. Our objective is to comprehensively explore the robustness of the binary hyper-dimensional computation model, aiming to gain a deeper understanding of its security vulnerabilities and potential defenses. Specifically, we introduce a novel attack framework for HDC, named HyperAttack, which is capable of compromising a robust binary HDC model by maliciously flipping a minimal number of bits within its memory system (specifically, the DRAM) that houses the associative memory. The bit-flip operation is executed through the well-known Row Hammer attack, and HyperAttack optimizes the accuracy degradation by pinpointing the most vulnerable bits in the hyper-dimensional vectors (represented as binary vectors within the associative memory) of the HDC model. The proposed HyperAttack framework is grounded in the principles of fuzziness, seamlessly integrating dimensional ranking and feature similarity analysis within hypervectors to precisely identify the bits to be flipped. Furthermore, we have developed a defense mechanism named HyperDefense, designed to bolster the robustness of binary hyper-dimensional computational models against bit-flip attacks. This defense scheme is tailored specifically for HDC models, providing a robust safeguard against potential threats. HyperDefense operates directly on the associative memory of HDC models, strengthening their defenses. By meticulously modifying selected bits, HyperDefense maintains a high level of accuracy close to the original model, even in the face of increased bit flip rates. This defense mechanism leverages redundant dimensions as backups for critical information. Through a thorough analysis of dimension importance, HyperDefense achieves superior robustness by gracefully sacrificing non-critical dimensions, thus ensuring the model’s robustness against potential attacks.},
  archive      = {J_TACO},
  author       = {Haomin Li and Fangxin Liu and Zongwu Wang and Ning Yang and Shiyuan Huang and Xiaoyao Liang and Haibing Guan and Li Jiang},
  doi          = {10.1145/3736172},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-25},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {Attack and defense: Enhancing robustness of binary hyper-dimensional computing},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GECC: A GPU-based high-throughput framework for elliptic curve cryptography. <em>TACO</em>, <em>22</em>(3), 1-27. (<a href='https://doi.org/10.1145/3736176'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Elliptic Curve Cryptography (ECC) is an encryption method that provides security comparable to traditional techniques like Rivest–Shamir–Adleman (RSA) but with lower computational complexity and smaller key sizes, making it a competitive option for applications such as blockchain, secure multi-party computation, and database security. However, the throughput of ECC is still hindered by the significant performance overhead associated with elliptic curve (EC) operations, which can affect their efficiency in real-world scenarios. This article presents gECC, a versatile framework for ECC optimized for GPU architectures, specifically engineered to achieve high-throughput performance in EC operations. To maximize throughput, gECC incorporates batch-based execution of EC operations and microarchitecture-level optimization of modular arithmetic. It employs Montgomery’s trick [ 40 ] to enable batch EC computation and incorporates novel computation parallelization and memory management techniques to maximize the computation parallelism and minimize the access overhead of GPU global memory. Furthermore, we analyze the primary bottleneck in modular multiplication by investigating how the user codes of modular multiplication are compiled into hardware instructions and what these instructions’ issuance rates are. We identify that the efficiency of modular multiplication is highly dependent on the number of Integer Multiply-Add (IMAD) instructions. To eliminate this bottleneck, we propose novel techniques to minimize the number of IMAD instructions by leveraging predicate registers to pass the carry information and using addition and subtraction instructions (IADD3) to replace IMAD instructions. Our experimental results show that, for ECDSA and ECDH, the two commonly used ECC algorithms, gECC can achieve performance improvements of 5.56 × and 4.94 ×, respectively, compared to the state-of-the-art GPU-based system. In a real-world blockchain application, we can achieve performance improvements of 1.56 ×, compared to the state-of-the-art CPU-based system. gECC is completely and freely available at https://github.com/CGCL-codes/gECC .},
  archive      = {J_TACO},
  author       = {Qian Xiong and Weiliang Ma and Xuanhua Shi and Yongluan Zhou and Hai Jin and Kaiyi Huang and Haozhou Wang and Zhengru Wang},
  doi          = {10.1145/3736176},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-27},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {GECC: A GPU-based high-throughput framework for elliptic curve cryptography},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging iterative applications to improve the scalability of task-based programming models on distributed systems. <em>TACO</em>, <em>22</em>(3), 1-27. (<a href='https://doi.org/10.1145/3743134'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed tasking models such as OmpSs-2@Cluster, StarPU-MPI, and PaRSEC express HPC applications as task graphs with explicit dependencies. The single task graph unifies the representation of parallelism across CPU cores, accelerators, and distributed-memory nodes, offering higher programmer productivity compared to traditional MPI + X. Most task-based models construct the task graph sequentially, which provides a clear and familiar programming model, simplifying code development, maintenance, and porting. However, this design introduces a bottleneck in task creation and dependency management, limiting performance and scalability. As a result, unless the tasks are very coarse-grained, current distributed sequential tasking models cannot match the performance of MPI + X. Many scientific applications, however, are iterative in nature, constructing the same directed acyclic task graph at each timestep. We exploit this structure to eliminate the sequential bottleneck and control message overhead in a sequentially-constructed distributed tasking model, while preserving its simplicity and productivity. Our approach builts on the recently proposed taskiter directive for OpenMP and OmpSs-2, allowing a single iteration to be expressed as a cyclic graph. The runtime partitions the cyclic graph across nodes, precomputes the MPI transfers, and then executes the loop body at low overhead. By integrating the MPI communications directly into the application’s task graph, our approach naturally overlaps computation and communication, in some cases exposing dramatically more parallelism than fork–join MPI + OpenMP. We define the programming model and describe the full runtime implementation, and integrate our proposal into OmpSs-2@Cluster. We evaluate it using five benchmarks on up to 128 nodes of the MareNostrum 5 supercomputer. For applications with fork–join parallelism, our approach has performance similar to fork–join MPI + OpenMP, making it a viable productive alternative, unlike the existing OmpSs-2@Cluster model, which is up to 7.7 times slower than MPI + OpenMP. For a 2D Gauss–Seidel stencil computation, our approach enables 3D wavefront computation, giving performance up to 22 times faster than fork–join MPI + OpenMP and on-a-par with state-of-the-art TAMPI + OmpSs-2. All software, comprising the compiler, runtime, and benchmarks, is released open source. 1},
  archive      = {J_TACO},
  author       = {Omar Shaaban Ibrahim ali and Juliette Fournis d'Albiat and Isabel Piedrahita and Vicenç Beltran and Xavier Martorell and Paul Carpenter and Eduard Ayguadé and Jesus Labarta},
  doi          = {10.1145/3743134},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-27},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {Leveraging iterative applications to improve the scalability of task-based programming models on distributed systems},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scheduling language chronology: Past, present, and future. <em>TACO</em>, <em>22</em>(3), 1-31. (<a href='https://doi.org/10.1145/3743135'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scheduling languages express to a compiler—or equivalently, a code generator—a sequence of optimizations to apply. Performance tools that support a scheduling language interface allow exploration of optimizations, i.e., exploratory compilers . While scheduling languages have become a common feature of tools for experts, the proliferation of these languages without unifying common features may be confusing to users. Moreover, we recognize a need to organize the compiler developer community around common exploratory compiler infrastructure, and future advances to address, for example, data layout and data movement. To support a broader set of users may require raising the level of abstraction. This article provides a chronology of scheduling languages, discussing their origins in iterative compilation and autotuning, noting the common features that are used in existing frameworks, and calling for changes to increase their utility and portability.},
  archive      = {J_TACO},
  author       = {Mary Hall and Cosmin E. Oancea and Anne C. Elster and Ari Rasch and Sameeran Joshi and Amir Mohammad Tavakkoli and Richard Schulze},
  doi          = {10.1145/3743135},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-31},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {Scheduling language chronology: Past, present, and future},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In-SRAM parallel data shuffle. <em>TACO</em>, <em>22</em>(3), 1-24. (<a href='https://doi.org/10.1145/3743136'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While Single Instruction Multiple Data (SIMD) units are widely employed in processors for neural networks, signal processing, and high-performance computing, they suffer from expensive shuffle operations dedicated to data alignment. In fact, shuffle operations only change the layout of data and ideally should be done entirely within memory. To this end, we propose Shuffle SRAM in this article, which can shuffle multiple data elements simultaneously across SRAM banks. The key idea is exploiting inter-bank word line wise data movement to shuffle data in parallel, where all data elements on the same word line of SRAM can be shuffled simultaneously, achieving a high level of parallelism. Through suitable data layout preparation and proper control, Shuffle SRAM efficiently supports a wide range of commonly used shuffle operations. Our evaluation results show that the Shuffle SRAM can reap performance benefits of 14.3× for data reorganization only applications and 1.97× for data reorganization + computation applications over conventional shuffle architecture on general-purpose processors. With Shuffle SRAM, the state-of-the-art vector processor can obtain 2.58× energy efficiency. Compared with traditional SRAM, Shuffle SRAM only increases 3.5% additional area overhead.},
  archive      = {J_TACO},
  author       = {Chaoyang Jia and Zhang Dunbo and Qingjie Lang and Ruoxi Wang and Li Shen},
  doi          = {10.1145/3743136},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-24},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {In-SRAM parallel data shuffle},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EDAS: Enabling fast data loading for GPU serverless computing. <em>TACO</em>, <em>22</em>(3), 1-23. (<a href='https://doi.org/10.1145/3743137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating GPUs into serverless computing platforms is crucial for improving efficiency. Many GPU functions, such as DNN inferences and scientific services, benefit from GPU usage, which requires only tens to hundreds of milliseconds for pure computation. Under these circumstances, fast data loading is imperative for function performance. However, existing GPU serverless systems face significant data stall issues, leading to extremely low GPU efficiency. Faced with the above problems, we observe opportunities to optimize data loading, such as data preloading and deduplicated data loading. However, these optimizations are impossible in existing GPU serverless systems due to the lack of insights into data information, such as data sizes and read-write attributes of function inputs. To address this, we propose a novel GPU serverless system, EDAS. EDAS first enhances user request specifications, allowing users to annotate data retrieved by GPU functions from the database with additional attributes. Based on this, EDAS takes over data loading from GPU functions and proposes two innovative data loading management schemes: a parallelized data loading scheme and a multi-stage resource exit scheme. Our experimental results show that EDAS reduces function duration by 16.2× and improves system throughput by 1.91× compared with the state-of-the-art serverless platform.},
  archive      = {J_TACO},
  author       = {Han Zhao and Weihao Cui and Quan Chen and Zijun Li and Zhenhua Han and Nan Wang and Yu Feng and Jieru Zhao and Chen Chen and Jingwen Leng and Minyi Guo},
  doi          = {10.1145/3743137},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-23},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {EDAS: Enabling fast data loading for GPU serverless computing},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CGCGraph: Efficient CPU-GPU co-execution for concurrent dynamic graph processing. <em>TACO</em>, <em>22</em>(3), 1-26. (<a href='https://doi.org/10.1145/3744904'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous growth of user scale and application data, the demand for large-scale concurrent graph processing is increasing. Typically, large-scale concurrent graph processing jobs need to process corresponding snapshots of dynamically changing graph data to obtain information at different time points. To enhance the throughput of such applications, current solutions concurrently process multiple graph snapshots on the GPU. However, when dealing with rapidly changing graph data, transferring multiple snapshots of concurrent jobs to the GPU results in high data transfer overhead between CPU and GPU. Additionally, the execution mode of existing work suffers from underutilization of GPU computational resources. In this work, we introduce CGCGraph, which can be integrated into existing GPU graph processing systems like Subway, to enable efficient concurrent graph snapshot processing jobs and enhance overall system resource utilization. The key idea is to offload unshared graph data of multiple concurrent snapshots to the CPU, reducing CPU-GPU transfer overhead. By implementing CPU-GPU co-execution, there is potential for enhanced utilization of GPU computing resources. Specifically, CGCGraph leverages kernel fusion to process shared graph data concurrently on the GPU, while executing all snapshots in parallel on the CPU, with each snapshot assigned a dedicated thread. This approach enables efficient concurrent processing within a novel CPU-GPU co-execution model, incorporating three optimization strategies targeting storage, computation, and synchronization. We integrate CGCGraph with Subway, an existing system designed for out-of-GPU-memory static graph processing. Experimental results show that the integration of CGCGraph with current GPU-based systems obtains performance improvements ranging from 1.7 to 4.5 times.},
  archive      = {J_TACO},
  author       = {Yiming Sun and Jie Zhang and Huawei Cao and Yuan Zhang and Xuejun An and Junying Huang and Xiaochun Ye},
  doi          = {10.1145/3744904},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-26},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {CGCGraph: Efficient CPU-GPU co-execution for concurrent dynamic graph processing},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MetaEC: An efficient and resilient erasure-coded KV store on disaggregated memory. <em>TACO</em>, <em>22</em>(3), 1-26. (<a href='https://doi.org/10.1145/3744905'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In-memory KV stores have recently been migrated from traditional monolithic servers to disaggregated memory (DM) for higher resource utilization and elasticity. These works use replication-based schemes for fault tolerance, which can be replaced with erasure coding (EC) for space efficiency. However, existing EC schemes designed in KV stores on traditional monolithic architectures encounter performance constraints when directly implemented in DM due to the challenges in EC metadata management and consistent parity updating. This article proposes MetaEC, an erasure-coded KV store on DM with high efficiency and resilience. First, for organizing KV pairs to stripes, MetaEC logically forms data chunks and leverages lazy coding to remove the accumulating and coding latency from the critical path. Second, for efficient EC metadata management, MetaEC designs EC metadata structures based on accessing features, and employs a hybrid redundancy schema with deterministic distribution to provide fault tolerance with high storage efficiency. Third, for consistent parity updating, we design a parity updating protocol based on parity logging and co-design EC metadata structures to handle concurrent conflicts by allowing only concurrent reads or writes. Experimental results show that compared with the state-of-the-art replication-based KV stores on DM, MetaEC achieves up to 53.33% latency reduction, up to 31.01% throughput improvement, and 58.17% memory consumption savings.},
  archive      = {J_TACO},
  author       = {Qiliang Li and Min Lyu and Tian Liu and Liangliang Xu and Wei Wang and Yinlong Xu},
  doi          = {10.1145/3744905},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-26},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {MetaEC: An efficient and resilient erasure-coded KV store on disaggregated memory},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerating parallel structures in DNNs via parallel fusion and operator co-optimization. <em>TACO</em>, <em>22</em>(3), 1-26. (<a href='https://doi.org/10.1145/3744906'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parallel structures have become a key pattern in deep neural networks (DNNs), offering improved efficiency and scalability. However, existing machine learning compilers (MLCs) face challenges in optimizing these structures due to limited parallel fusion scope and insufficient analysis of intra-operator characteristics. This article introduces Magneto, a framework designed to accelerate DNN inference by co-optimizing parallel operators. Magneto broadens the fusion scope and incorporates a specialized co-tuning algorithm to optimize operators jointly. Our approach addresses the unique challenges inherent in optimizing parallel structures, enabling significant performance improvements across various hardware platforms. Experimental results show that Magneto outperforms state-of-the-art NVIDIA TensorRT and AMD MIGraphX, achieving geometric mean speedups of 2.27× and 2.88×, respectively.},
  archive      = {J_TACO},
  author       = {Zhanyuan Di and Leping Wang and Zhaojia Ma and En Shao and Jie Zhao and Ziyi Ren and Siyuan Feng and Dingwen Tao and Guangming Tan and Ninghui Sun},
  doi          = {10.1145/3744906},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-26},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {Accelerating parallel structures in DNNs via parallel fusion and operator co-optimization},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-stage degradation-based topology reconfiguration algorithm for fault-tolerant multiprocessor arrays. <em>TACO</em>, <em>22</em>(3), 1-26. (<a href='https://doi.org/10.1145/3744907'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the integration density of multiprocessor arrays increases, the likelihood of permanent faults in processing elements (PEs) rises, requiring effective topology reconfiguration for system reliability. However, existing router-based multiprocessor arrays reconfiguration methods predominantly rely on redundancy techniques and lack effective degradation strategies for applications of varying sizes. To address this, we propose a two-stage degradation-based topology reconfiguration algorithm to construct a maximized and high-performance logical array. First, we introduce a novel fault compensation mechanism by defining a set of faulty PE candidates to identify locally optimal fault-free PEs for compensation, minimizing the compensation path. Building upon this, we develop a greedy bidirectional column reconfiguration algorithm that constructs an initial fault-free logical array with short interconnects and prove its maximality. Lastly, we propose a satisfiability-based reconfiguration algorithm, transforming the topology reconfiguration problem into a satisfiability problem via a SAT model, reducing interconnect redundancy, and further optimizing array performance. Experimental results demonstrate that the proposed algorithm consistently outperforms state-of-the-art methods in reducing communication latency and alleviating link congestion, especially under high fault density conditions. Furthermore, as array size and fault density increase, the effectiveness of the proposed method becomes more pronounced, showcasing excellent scalability and robustness.},
  archive      = {J_TACO},
  author       = {Hao Ding and Peiling Song and Yelin Li and Junyan Qian},
  doi          = {10.1145/3744907},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-26},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {A two-stage degradation-based topology reconfiguration algorithm for fault-tolerant multiprocessor arrays},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Address/Data instruction steering in clustered general purpose processors. <em>TACO</em>, <em>22</em>(3), 1-24. (<a href='https://doi.org/10.1145/3744908'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although they differentiate between integer and floating-point datum, modern Instruction Set Architectures and their implementations do not differentiate integer datum used to address memory from integer datum used in purely arithmetic and logical computations. This is a perfectly reasonable choice as addresses are, in fact, integral quantities. However, in many cases, there is already a fundamental difference between addresses and integer data: Their width. As computer systems moved from 16 to 32, then to 64-bit pointers, with a potential future where 128-bit might be used for specific systems, the data width required to compute a given output with a given algorithm has remained the same, e.g., an ASCII character is still represented on a byte. This work aims to leverage this dichotomy to revisit hardware clustering, a well-known microarchitectural technique used to mitigate the cost of scaling processor backend structures by dividing the backend into several mostly independent execution clusters. We show that by treating instructions as manipulating addresses or data and steering them to a “data” or an “address” cluster accordingly, reasonable cluster load balancing can be achieved without the need for complex steering policies that can lead to performance on par with the baseline with limited hardware overhead. Moreover, we highlight two possible optimizations stemming from this distribution. First, the registers of the “address” cluster can easily be compressed thanks to address spatial and temporal locality. Second, if a processor requires a large address space but only processes narrow data (e.g., 32-bit data with 64-bit pointers or 64-bit data with 128-bit pointers), the “data” cluster datapath can be kept narrower than the “address” cluster datapath.},
  archive      = {J_TACO},
  author       = {Chandana S. Deshpande and Arthur Perais and Frédéric Pétrot},
  doi          = {10.1145/3744908},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-24},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {Address/Data instruction steering in clustered general purpose processors},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3D GNLM: Efficient 3D non-local means kernel with nested reuse strategies for embedded GPUs. <em>TACO</em>, <em>22</em>(3), 1-22. (<a href='https://doi.org/10.1145/3744909'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 3D Non-Local Means (NLM) algorithm has become a crucial preprocessing technique for 3D image datasets due to its effectiveness in denoising while preserving fine details. This method has been proven to be highly efficient in high-demand tasks within industrial applications such as medical imaging and remote sensing. The 3D NLM algorithm computes the filtered value for each voxel by calculating the weighted average of all voxels within a 3D search window, where the weights are determined by the similarity between pairs of 3D template windows. Therefore, the computational burden becomes significant, especially in embedded GPUs with limited computational power and memory resources. To address this issue, we propose an efficient GPU parallel kernel to minimize redundant computations and memory accesses. The kernel integrates three nested reuse strategies to handle redundant computations in three dimensions: for columns, we leverage the fast data exchange mechanism to reuse column computation results via on-chip registers; for rows, we use a sliding window strategy, utilizing GPU global memory as an intermediary to store and reuse similarity values between filtered rows; and for channels, we introduce a zigzag scanning strategy that enables simultaneous computation across multiple channels and employs on-chip registers to facilitate channel computation reuse. Experimental results demonstrate that our kernel achieves an average speedup of 7.7x on the embedded Jetson AGX Xavier platform across a range of 3D image datasets compared to existing methods, showcasing exceptional performance.},
  archive      = {J_TACO},
  author       = {Xiang Li and Qiong Chang and Yun Li and Jun Miyazaki},
  doi          = {10.1145/3744909},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-22},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {3D GNLM: Efficient 3D non-local means kernel with nested reuse strategies for embedded GPUs},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ZNSFQ: An efficient and high-performance fair queue scheduling scheme for ZNS SSDs. <em>TACO</em>, <em>22</em>(3), 1-27. (<a href='https://doi.org/10.1145/3746230'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Zoned Namespace (ZNS) interface transfers most storage maintenance responsibilities from the underlying Solid-State Drives (SSDs) to the host. This shift creates new opportunities to ensure fairness and high performance in multi-tenant cloud computing environments at both hardware and software levels. However, when applications with different workloads share a single ZNS SSD hardware, traditional fair queueing schedulers fail to achieve fairness due to their limited awareness of workload characteristics. Moreover, allowing multiple outstanding requests to access the device simultaneously improves resource utilization but often leads to significant I/O interference among these requests. This interference results in over-throttling, which subsequently degrades the performance of existing fair queueing schedulers. To address the above problems, this article proposes an efficient and high-performance fair queueing scheduling scheme for ZNS SSD (ZNSFQ) on the host side. Firstly, ZNSFQ introduces a workload-aware fair scheduler that enhances fairness by accurately estimating the I/O cost for each application based on its workload characteristics. Secondly, to optimize performance while ensuring fairness, ZNSFQ designs a request dispatch parallelism adjuster. This adjuster manages the channel-level request dispatch parallelism for each application to minimize I/O interference. Finally, ZNSFQ employs a global adaptive coordinator to alleviate device-level I/O blocking, reducing tail latency and CPU consumption while satisfying fairness and performance. A comprehensive evaluation demonstrates that ZNSFQ significantly enhances fairness and performance compared to the latest fair queuing schedulers. In sequential access scenarios, ZNSFQ enhances fairness by over 38.13% and increases I/O bandwidth by more than 49.24%. Furthermore, in random access scenarios, it reduces CPU utilization by 70.22% while maintaining both fairness and high performance.},
  archive      = {J_TACO},
  author       = {Yachun Liu and Dan Feng and Jianxi Chen and Jing Hu and Zhouxuan Peng and Jinlei Hu},
  doi          = {10.1145/3746230},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-27},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {ZNSFQ: An efficient and high-performance fair queue scheduling scheme for ZNS SSDs},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance implications of pipelining the data transfer in CPU-GPU heterogeneous systems. <em>TACO</em>, <em>22</em>(3), 1-26. (<a href='https://doi.org/10.1145/3746231'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the increasing demands of machine learning, heterogeneous systems combining CPUs and GPUs have emerged as the dominant architecture for parallel computing in recent years. To optimize memory management and data transfer between CPUs and GPUs, Nvidia GPUs have introduced unified virtual memory ( UVM ) and pinned memory ( PM ) over the last decade. UVM can avoid explicit memory copies and potentially overlap GPU kernel computations with CPU-GPU data transfer. PM ensures that data with high locality remains in the main memory, preventing it from being paged out. In addition to these two techniques, asynchronous memory copy ( Async Memcpy ) was introduced recently in Nvidia GPUs to improve the CPU-GPU pipeline further. By utilizing Async Memcpy , the data transfer from GPU global memory to shared memory can be overlapped with GPU computations, adding an additional stage to the CPU-GPU data transfer pipeline. A thorough performance analysis of how Async Memcpy affects the current UVM and PM CPU-GPU data transfer scheme is desired. In this article, we provide performance implications of the combined effect of UVM , PM , and Async Memcpy , exploring which applications benefit from which combination of these features. We implement all these features on a suite of 25 workloads, including microbenchmarks and realworld applications. We observe an average performance gain of 24% when utilizing UVM and a 34% gain when employing PM on realworld applications, compared to not applying any data transfer optimization techniques. The performance benefits of Async Memcpy vary across different workloads. For workloads featuring extensive shared memory usage and high compute density (e.g., kmeans and lud ), Async Memcpy delivers around a 20% performance improvement over using UVM or PM alone. In other workloads like knn , we note a 20% performance degradation when using Async Memcpy . Furthermore, we conduct an in-depth investigation of the GPU kernel using performance counters to uncover the root causes of performance differences among various data transfer models. We also perform sensitivity analyses to examine how the number of blocks and threads, as well as the L1-cache/shared memory partitioning, impact performance. We explore future research directions aimed at enhancing the data transfer pipeline by overlapping memory allocation with data transfer and computation across GPU kernels.},
  archive      = {J_TACO},
  author       = {Ruihao Li and Bagus Hanindhito and Sanjana Yadav and Qinzhe Wu and Krishna Kavi and Gayatri Mehta and Neeraja J. Yadwadkar and Lizy K. John},
  doi          = {10.1145/3746231},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-26},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {Performance implications of pipelining the data transfer in CPU-GPU heterogeneous systems},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partitioned scheduling and analysis for a typed DAG task on heterogeneous multi-cores. <em>TACO</em>, <em>22</em>(3), 1-24. (<a href='https://doi.org/10.1145/3746232'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous multi-core architectures are gaining popularity in recent years as they combine the benefits of different processors, resulting in improved execution capacity and energy efficiency. However, analyzing response times and allocating resources for the typed directed acyclic graph (DAG) task, which has complex execution logic, on heterogeneous multi-core systems poses significant challenges. Major approaches may yield overly pessimistic worst-case response time (WCRT) estimates in certain scenarios while failing to adequately address critical structural characteristics inherent to typed DAG tasks. To address these limitations, this article explores the WCRT analysis and core allocations for the typed DAG task under partitioned scheduling. In this work, we first delve into the characteristics of the topology structure of the typed DAG task and propose a novel WCRT upper bound to enhance the accuracy of WCRT analysis. Then, a subtask allocation strategy is presented, which enables an effectively utilization of the resources of multi-cores. Finally, the performance of the proposed analysis algorithm and allocation strategy are tested by implementing a verification system on a real heterogeneous multi-core platform. Experimental results demonstrate that our proposed WCRT analysis algorithm exhibits substantial improvements of 38.7% and 37.43% in the theoretical analysis performance and actual analysis accuracy, respectively. Similarly, our proposed core allocation strategy improves the theoretical and the actual execution efficiency of the system by 10.6% and 7.41%, respectively. These results substantiate the practical value of our enhanced WCRT derivation methodology and allocation scheme in improving system resource utilization efficiency.},
  archive      = {J_TACO},
  author       = {Yulong Wu and Yehan Ma and Mingdong Xie and Weizhe Zhang},
  doi          = {10.1145/3746232},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-24},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {Partitioned scheduling and analysis for a typed DAG task on heterogeneous multi-cores},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DCSolver: Accelerating sparse iterative solvers via divide-and-conquer on GPUs. <em>TACO</em>, <em>22</em>(3), 1-25. (<a href='https://doi.org/10.1145/3746233'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse iterative solvers are commonly used in various fields. However, certain essential kernels of these solvers, such as sparse triangular solves (SpTRSV), present significant challenges for efficient parallelization due to data dependencies . Previous methods, like level-scheduling or multi-coloring, typically involve creating a Task Dependency Graph (TDG) to represent data dependencies and identify independent sets from the TDG for parallel execution. However, these approaches often result in limited parallelism with substantial synchronization overheads or negatively impact the solver convergence rate. This article introduces DCSolver , a Divide-and-Conquer (DC) framework designed to efficiently parallelize sparse solvers with data dependencies on GPUs. To achieve this, we break down the solver TDG into independent subgraphs, allowing us to exploit both coarse-grained and fine-grained parallelism. To efficiently allocate GPU threads for subgraphs with varying degrees of parallelism, we have developed an adaptive in-warp scheduling strategy. Additionally, we propose a hybrid parallelization scheme in DCSolver, which involves employing different parallel approaches for different DC recursions to achieve a more optimal balance between parallelism and convergence for solvers. To evaluate the effectiveness of DCSolver, we apply it to two preconditioned Krylov subspace solvers and an unstructured mesh Computational Fluid Dynamics (CFD) solver. Our results show that when compared with the state-of-the-art methods, DCSolver accelerates the time-to-solution of solvers by an average speedup of up to 26.19X.},
  archive      = {J_TACO},
  author       = {Haozhong Qiu and Chuanfu Xu and Jianbin Fang and Jian Zhang and Liang Deng and Zhe Dai and Yue Ding and Yue Wang and Zhimeng Han and Yonggang Che and Jie Liu},
  doi          = {10.1145/3746233},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-25},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {DCSolver: Accelerating sparse iterative solvers via divide-and-conquer on GPUs},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cppless: Single-source and high-performance serverless programming in c++. <em>TACO</em>, <em>22</em>(3), 1-27. (<a href='https://doi.org/10.1145/3747841'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of serverless computing introduced a new class of scalable, elastic, and widely available parallel workers in the cloud. Many systems and applications benefit from offloading computations and parallel tasks to dynamically allocated resources. However, the developers of C++ applications find it difficult to integrate functions due to complex deployment, lack of compatibility between client and cloud environments, and loosely typed input and output data. To enable single-source and efficient serverless acceleration in C++, we introduce Cppless , an end-to-end framework for implementing remote functions which handles the creation, deployment, and invocation of serverless functions. Cppless is built on top of LLVM and requires only two compiler extensions to automatically extract C++ function objects and deploy them to the cloud. We demonstrate that offloading parallel computations, such as from a C++ application to serverless workers, can provide up to 59x speedup with minimal cost increase while requiring only minor code modifications.},
  archive      = {J_TACO},
  author       = {Marcin Copik and Lukas Möller and Alexandru Calotoiu and Torsten Hoefler},
  doi          = {10.1145/3747841},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-27},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {Cppless: Single-source and high-performance serverless programming in c++},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mobile-3DCNN: An acceleration framework for ultra-real-time execution of large 3D CNNs on mobile devices. <em>TACO</em>, <em>22</em>(3), 1-22. (<a href='https://doi.org/10.1145/3747842'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is challenging to deploy 3D Convolutional Neural Networks (3D CNNs) on mobile devices, specifically if both real-time execution and high inference accuracy are in demand, because the increasingly large model size and complex model structure of 3D CNNs usually require tremendous computation and memory resources. Weight pruning is proposed to mitigate this challenge. However, existing pruning is either not compatible with modern parallel architectures, resulting in long inference latency or subject to significant accuracy degradation. This article proposes an end-to-end 3D CNN acceleration framework based on pruning/compilation co-design called Mobile-3DCNN that consists of two parts: a novel, fine-grained structured pruning enhanced by a prune/Winograd adaptive selection (that is mobile-hardware-friendly and can achieve high pruning accuracy), and a set of compiler optimization and code generation techniques enabled by our pruning (to fully transform the pruning benefit to real performance gains). The evaluation demonstrates that Mobile-3DCNN outperforms state-of-the-art end-to-end DNN acceleration frameworks that support 3D CNN execution on mobile devices, Alibaba Mobile Neural Networks and Pytorch-Mobile with speedup up to 34× with minor accuracy degradation, proving it is possible to execute high-accuracy large 3D CNNs on mobile devices in real-time (or even ultra-real-time).},
  archive      = {J_TACO},
  author       = {Wei Niu and Mengshu Sun and Zhengang Li and Jou-An Chen and Jiexiong Guan and Xipeng Shen and Jun Liu and Mei Zhang and Yanzhi Wang and Xue Lin and Bin Ren},
  doi          = {10.1145/3747842},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-22},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {Mobile-3DCNN: An acceleration framework for ultra-real-time execution of large 3D CNNs on mobile devices},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TRACED: A temporal graph neural networks-based model for data prefetching. <em>TACO</em>, <em>22</em>(3), 1-25. (<a href='https://doi.org/10.1145/3747843'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern microarchitectures, machine-learning-based prefetchers use past memory requests to learn access patterns and predict memory addresses, thereby prefetching data into the cache to mitigate the processor-memory speed gap. However, they face two key challenges in capturing irregular access patterns generated by complex data structures and algorithms. One is data dispersion: the disorderliness of memory addresses makes it difficult for prefetchers to extract meaningful data features. The other is temporal and spatial complexity: existing prefetchers fail to effectively learn temporal and spatial characteristics, and thus are unable to explore more complex access patterns. To resolve these challenges, we propose TRACED, a novel temporal graph neural network-based prefetcher aimed at learning access patterns of memory addresses. TRACED consists of two key components: a dynamic clustering component and a temporal graph neural network component. In the dynamic clustering component, we introduce a similarity function to quantify the similarity of memory addresses. Based on the quantified similarity, we dynamically group unordered memory addresses into different clusters. This ensures that the memory addresses in each cluster are ordered and change smoothly, thus resolving the first challenge. The temporal graph neural network component constructs a spatiotemporal graph to represent relationships among memory addresses. This helps capture temporal and spatial characteristics both across and within clusters, thus resolving the second challenge. This article demonstrates the effectiveness of the proposed prefetcher through experiments. Specifically, in terms of accuracy, TRACED outperforms BO, SPP, DOMINO, Delta-LSTM, and VOYAGER by 2.29%–40.83% on average. Furthermore, TRACED attains remarkable coverage of 55.67% and IPC of 43.75%, outperforming all competing approaches in both metrics.},
  archive      = {J_TACO},
  author       = {He Jiang and Liuwei Fu and Dong Liu and Zhilei Ren and Yuting Chen and Lei Qiao},
  doi          = {10.1145/3747843},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-25},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {TRACED: A temporal graph neural networks-based model for data prefetching},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GenCNN: A partition-aware multi-objective mapping framework for CNN accelerators based on genetic algorithm. <em>TACO</em>, <em>22</em>(3), 1-26. (<a href='https://doi.org/10.1145/3747844'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Networks (CNNs) require partitioning to efficiently run on CNN accelerators, which offer multiple parallel processing dimensions, such as Processing Element (PE) array topologies and Single Instruction Multiple Data (SIMD) execution. The choice of parallelization strategy directly impacts accelerator performance. However, the vast search space for CNN partitioning and parallelization makes manual optimization costly and complex, especially when addressing both aspects simultaneously. This highlights the need for an automated framework to efficiently map CNNs onto accelerators. Our key insight is that existing approaches suffer from inadequate accelerator performance modeling and a lack of multi-objective optimization strategies that jointly consider task partitioning and convolution parallelization. To address this, we propose GenCNN, a multi-objective genetic algorithm-based mapping framework for CNN accelerators. GenCNN first constructs a fine-grained performance model that captures both off-chip data access and on-chip data processing. It then applies the Non-dominated Sorting Genetic Algorithm II improved by Multi-Objective Bayesian Optimization to derive a Pareto-optimal partitioning and parallelization strategy that balances off-chip latency and PE utilization. Finally, GenCNN optimizes scheduling and routing to minimize data transfers. Experimental results show that GenCNN achieves up to 17.66× speedup in compilation and 6.47× in execution compared with state-of-the-art mapping frameworks.},
  archive      = {J_TACO},
  author       = {Yudong Mu and Zhihua Fan and Wenming Li and Zhiyuan Zhang and Xuejun An and Dongrui Fan and Xiaochun Ye},
  doi          = {10.1145/3747844},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-26},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {GenCNN: A partition-aware multi-objective mapping framework for CNN accelerators based on genetic algorithm},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Supports of data cache division for computational solid-state drives. <em>TACO</em>, <em>22</em>(3), 1-20. (<a href='https://doi.org/10.1145/3747845'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computational SSD ( CompSSD ), with high computing capabilities, can function not only as a storage device but also as a computing node. The data cache of the CompSSD device stores both the output data from host-side tasks and the input data for tasks executed on the CompSSD . However, current cache management strategies are optimized for traditional SSDs and are incompatible with the unique requirements of CompSSD . To address the issue of cache management for CompSSD , this article proposes a novel cache division scheme, to dynamically divide the cache into two parts, for separately buffering output data from host-side tasks and input data used by CompSSD -side tasks. To this end, we construct a mathematical model that periodically estimate an optimal cache division ratio, by considering the factors of the ratios of read/write data amount, the cache hits, and the overhead of data transfer between the storage device and the host. Besides, we propose a scheme of proactive data flushing to write the output data to the underlying flash arrays, without impacts on I/O responsiveness. The trace-driven experiments show that our scheme can improve the overall I/O latency by 35.4% on average, in contrast to existing cache management schemes for CompSSD devices.},
  archive      = {J_TACO},
  author       = {Zhibing Sha and Shuaiwen Yu and Chengyong Tang and Zhigang Cai and Peng Tang and Ming Huang and Jun Li and Jianwei Liao},
  doi          = {10.1145/3747845},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-20},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {Supports of data cache division for computational solid-state drives},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ephemera: Accelerating I/O-intensive serverless workloads with a harvested in-memory file system. <em>TACO</em>, <em>22</em>(3), 1-24. (<a href='https://doi.org/10.1145/3747846'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Serverless computing has gained popularity for its ability to shift the burden of server management from developers to cloud providers, which allows providers to exercise greater control over resource management, optimizing configurations to enhance efficiency and performance. The diversity of serverless computing tasks, from short-lived, event-driven tasks to more complex workloads, highlights the growing importance of efficient file I/O performance for I/O-intensive workloads, yet effectively handling ephemeral storage for I/O-intensive tasks remains a challenge. Traditional file system approaches often introduce substantial latency and fail to fully leverage available memory resources within the execution environment, limiting performance and efficiency. Our work stems from the observation of the under-utilization of memory resources in serverless computing platforms and the potential efficiency improvement of I/O operations using an in-memory file system. Based on this observation, we propose Ephemera , a system designed to enhance ephemeral storage efficiency and memory utilization. Ephemera satisfies three design goals: transparent memory I/O integration , heterogeneous tasks resource synergy , and harmonized cluster workload orchestration . Ephemera integrates three components: the Runtime Daemon, responsible for managing a container’s in-memory file system; the Tenant Manager, facilitating memory configuration sharing across containers; and the Cluster Controller, optimizing workload balancing. Our experiments demonstrate that Ephemera significantly improves performance for I/O-intensive tasks compared to traditional file systems. Specifically, Ephemera decreases I/O processing time by 50% on average and reduces latency by up to 95.73% in certain scenarios with negligible overhead.},
  archive      = {J_TACO},
  author       = {Lingxiao Jin and Zinuo Cai and Haoxin Wang and Zongpu Zhang and Ruhui Ma and Haibing Guan and Yuan Liu and Buyya Rajkumar},
  doi          = {10.1145/3747846},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-24},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {Ephemera: Accelerating I/O-intensive serverless workloads with a harvested in-memory file system},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SpMARD: A sparse-sparse matrix multiplication accelerator with reconfigurable dataflow for DNN workloads. <em>TACO</em>, <em>22</em>(3), 1-23. (<a href='https://doi.org/10.1145/3747847'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning becomes increasingly popular, and its main workload is Sparse-Sparse Matrix Multiplication (SpMSpM). Most SpMSpM accelerators usually only support a single dataflow. Different dataflows have different performance in different computing environments. Therefore, the single-dataflow accelerator cannot maintain the highest performance in all environments. Compared with single-dataflow accelerators, multi-dataflow accelerators provide flexible options for different workloads and improve the overall performance. Flexagon, Sparm, and SPADA are state-of-the-art multi-dataflow accelerators. However, the computation process of Flexagon and Sparm is not fully pipelined, and SPADA cannot support inner product dataflow. Additionally, Flexagon, Sparm, and SPADA cannot switch dataflows quickly and accurately. Inspired by these observations, we present SpMARD, a SpMSpM accelerator with reconfigurable dataflow. The computation process of SpMARD is fully pipelined, and SpMARD can support six dataflow variants simultaneously. Through the design of a Two-stage Pipeline Adder Network (TPAN) and a Position-based Psum Array (PPA), SpMARD can execute element-level merging, which can hide the merging overhead. Through the quantitative analysis of dataflows, we implement a Dataflow Switcher (DSwitcher), which can switch dataflows more efficiently. For the SpMSpM workload, the performance (GOPS) of the SpMARD we proposed is 1.27 times that of Flexagon, 1.18 times that of Sparm, and 1.22 times that of SPADA.},
  archive      = {J_TACO},
  author       = {Bo Wang and Sheng Ma and Yunping Zhao and Shengbai Luo and Lizhou Wu and Jianmin Zhang and Dongsheng Li and Tiejun Li and Zhuojun Chen},
  doi          = {10.1145/3747847},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-23},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {SpMARD: A sparse-sparse matrix multiplication accelerator with reconfigurable dataflow for DNN workloads},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HAKV: A hotness-aware zone management approach to optimizing performance of LSM-tree-based key-value stores. <em>TACO</em>, <em>22</em>(3), 1-26. (<a href='https://doi.org/10.1145/3747848'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Log-Structured Merge tree-based key-value (KV) stores, like LevelDB and RocksDB, are extensively applied in large-scale data storage systems. This design excels in write-intensive environments by converting random writes into sequential append operations. Despite its advantages, KV stores struggle with real-world workloads where most updates in KV pairs are infrequent. The compaction process and hierarchical data organization result in high write and read amplification. To mitigate these issues, we propose HAKV – a hotness-aware zone management approach to optimizing performance of KV stores. HAKV first separates hot KV pairs from cold KV pairs, storing hot KV pairs in dedicated zones within persistent memory (PM), enabling centralized and lightweight compaction. Second, we propose a storage zone structure in PM to achieve space optimization for cold KV pairs. Third, to bolster cache hit ratio in PM, we provide a hierarchical data framework for hot KV pairs – and a recycling strategy for invalid hot KV pairs in a zone to enhance the space utilization of PM for hot KV pairs. Finally, we design a dynamic window-based adaptive adjustment mechanism for zone pool in PM to optimize the space utilization. Thus, HAKV significantly reduces write amplification while boosting overall read and write performance. The experimental results demonstrate that HAKV achieves write amplification reduction by up to 92.3%, 79.2%, 90.2%, 41.1%, 80.6%, and 62.4% compared with LevelDB, RocksDB, NoveLSM, LightKV, Wisckey, and UniKV, respectively, with average reduction rates of 89.6%, 74.4%, 84.9% 32.3%, 63.7%, and 42.5%. Furthermore, HAKV boosts random write performance by up to 54.2×, 51.5×, 44.2×, 4.3×, 3.1×, and 4.3×, respectively—and the average improvement reaches 25.8×, 20.9×, 23.9×, 2.7×, 2.5×, and 3.4×.},
  archive      = {J_TACO},
  author       = {Hui Sun and Qianli Yue and Guanzhong Chen and Yi Zou and Yinliang Yue and Xiao Qin},
  doi          = {10.1145/3747848},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-26},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {HAKV: A hotness-aware zone management approach to optimizing performance of LSM-tree-based key-value stores},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Matrix: Multi-cipher structures dataflow for parallel and pipelined TFHE accelerator. <em>TACO</em>, <em>22</em>(3), 1-23. (<a href='https://doi.org/10.1145/3750446'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fully homomorphic encryption over torus (TFHE) enables the execution of arbitrary functions on encrypted data through programmable bootstrapping (PBS). However, performing all operations on ciphertext during PBS results in high computational and memory requirements, limiting the deployment of PBS in real-world scenarios. Previous TFHE accelerator designs have attempted to improve performance by employing specific dataflow and functional units, but these techniques may require large off-chip bandwidth or on-chip storage when scaling up computation capacity. Additionally, the design of specialized functional units may limit the utilization of computation units when facing dynamic secure parameter settings. To address these challenges and further improve PBS throughput in TFHE, we propose Matrix , an ASIC-based architecture that balances off-chip bandwidth and on-chip storage according to the execution flow of PBS. In Matrix , we utilize a unified special-prime-based processing element (PE) that achieves high utilization with minimal resource overhead. Furthermore, we propose a hybrid PBS dataflow that can efficiently reduce computation complexity and memory requirements. Compared to state-of-the-art TFHE accelerators, Matrix achieves 1.43 × -5.66 × throughput improvement for PBS. For ZAMA Deep-NN benchmark, we achieve 525.60× and 68.06× speedup compared to CPU and GPU, respectively. 1},
  archive      = {J_TACO},
  author       = {Ling Liang and Zhen Gu and Fahong Zhang and Zhaohui Chen and Zhirui Li and Xin Fan and Dimin Niu and Meng Li and Zhiyong Li and Zongwei Wang and Hongzhong Zheng and Yimao Cai and Yuan Xie},
  doi          = {10.1145/3750446},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-23},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {Matrix: Multi-cipher structures dataflow for parallel and pipelined TFHE accelerator},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SampDedup: Sampling prediction for efficient inline data deduplication on non-volatile memory. <em>TACO</em>, <em>22</em>(3), 1-25. (<a href='https://doi.org/10.1145/3750447'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data deduplication is an effective technique for reducing redundant data storage space in various storage systems. Generally, deduplication consists of four steps: chunking, fingerprinting, fingerprint lookup, and data management. Recently, Non-volatile Memory (NVM) as an emerging storage device has received widespread attention. Directly applying the deduplication technique on NVM for storage cost savings faces many challenges: (a) deduplication on NVM devices suffers from computation bottleneck instead of the I/O bottleneck faced by deduplication on traditional storage devices (such as HDD and SSD); (b) new fingerprint indexes and metadata are required to be re-designed to adapt to NVM characteristics; (c) inline deduplication on NVM is more sensitive to the latency. To solve these challenges, we propose a novel Samp ling prediction-based inline data Dedup lication method ( SampDedup ) on NVM devices. It aims to ensure high deduplication ratios while reducing computation costs and latency by optimizing data chunking , fingerprinting , and fingerprint lookup . (a) For data chunking , a sampling prediction-based chunking method ( SampChunk ) is proposed to leverage chunk similarity to distinguish duplicate chunks and skip them for chunking. This method can be easily integrated into most sliding-window based and non-window based CDC chunking algorithms. (b) For fingerprinting , the commonly used SHA-1 algorithm is further optimized to reduce the extra computational overhead introduced by SampChunk, and an asynchronous fingerprinting method is proposed to reduce the fingerprinting latency of unique chunks. (c) For fingerprint lookup , we design a header fingerprint index and metadata table for each data chunk constructed by SampChunk on NVM, and we use a fast-read buffer to replace the traditional slow LRU cache to improve search efficiency. Experiments on four real-world datasets demonstrate that SampDedup consistently presents high inline data deduplication ratios on NVM with different workloads and data partitioning algorithms while saving more than 90% chunking time compared with state-of-the-art deduplication baselines.},
  archive      = {J_TACO},
  author       = {Ziyue Xu and Yichen Li and Ranzhe Deng and Liping Yi and Yusen Li and Gang Wang and Xiaoguang Liu},
  doi          = {10.1145/3750447},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-25},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {SampDedup: Sampling prediction for efficient inline data deduplication on non-volatile memory},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RACER: Avoiding end-to-end slowdowns in accelerated chip multi-processors. <em>TACO</em>, <em>22</em>(3), 1-22. (<a href='https://doi.org/10.1145/3750448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent chip multiprocessors incorporate several on-chip accelerators, marking the beginning of the Accelerated Chip Multi-Processor (XMP) era in datacenters. Despite the close proximity of accelerators and general-purpose cores, offloading functions to accelerators may not always be beneficial. Offloading to hardware accelerators can introduce several end-to-end overheads that can negate the speedup of the accelerable function. In this article, we design RACER, a hardware architecture and runtime system that evades the danger of end-to-end slowdowns when using hardware acceleration. RACER leverages a low-overhead interface between general-purpose cores and on-chip accelerators, fine-grained context switching, accelerator-initiated preemption, and seamless data motion between general-purpose cores and accelerators to improve the performance of workloads that use on-chip accelerators. We evaluate RACER on five representative request processing workloads featuring diverse memory access patterns, accelerable functions, and compute intensities. RACER improves the performance of hardware acceleration on a real XMP by an average of 1.31× on a range of diverse workloads and guarantees that accelerator offloads never cause slowdowns.},
  archive      = {J_TACO},
  author       = {Neel Patel and Ren Wang and Mohammad Alian},
  doi          = {10.1145/3750448},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-22},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {RACER: Avoiding end-to-end slowdowns in accelerated chip multi-processors},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A sparsity-aware autonomous path planning accelerator with HW/SW co-design and multi-level dataflow optimization. <em>TACO</em>, <em>22</em>(3), 1-25. (<a href='https://doi.org/10.1145/3750449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning is a critical task for autonomous driving, aiming to generate smooth, collision-free, and feasible paths based on input perception and localization information. The planning task is both highly time-sensitive and computationally intensive, posing significant challenges to resource-constrained autonomous driving hardware. In this article, we propose an end-to-end framework for accelerating path planning on FPGA platforms. This framework focuses on accelerating quadratic programming (QP) solving, which is the core of optimization-based path planning and has the most computationally-intensive workloads. Our method leverages a hardware-friendly alternating direction method of multipliers (ADMM) to solve QP problems while employing a highly parallelizable preconditioned conjugate gradient (PCG) method for solving the associated linear systems. We analyze the sparse patterns of matrix operations in QP and design customized storage schemes along with efficient sparse matrix multiplication and sparse matrix-vector multiplication units. Our customized design significantly reduces resource consumption for data storage and computation while dramatically speeding up matrix operations. Additionally, we propose a multi-level dataflow optimization strategy. Within individual operators, we achieve acceleration through parallelization and pipelining. For different operators in an algorithm, we analyze inter-operator data dependencies to enable fine-grained pipelining. At the system level, we map different steps of the planning process to the CPU and FPGA and pipeline these steps to enhance end-to-end throughput. We implement and validate our design on the AMD ZCU102 platform. Our implementation achieves state-of-the-art performance in both latency and energy efficiency compared with existing works, including an average 1.48× speedup over the best FPGA-based design, a 2.89× speedup compared with the state-of-the-art QP solver on an Intel i7-11800H CPU, a 5.62× speedup over an ARM Cortex-A57 embedded CPU, and a 1.56× speedup over state-of-the-art GPU-based work. Furthermore, our design delivers a 2.05× improvement in throughput compared with the state-of-the-art FPGA-based design.},
  archive      = {J_TACO},
  author       = {Yifan Zhang and Xiaoyu Niu and Hongzheng Tian and Yanjun Zhang and Bo Yu and Shaoshan Liu and Sitao Huang},
  doi          = {10.1145/3750449},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-25},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {A sparsity-aware autonomous path planning accelerator with HW/SW co-design and multi-level dataflow optimization},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TianheGraph: Topology-aware graph processing. <em>TACO</em>, <em>22</em>(3), 1-24. (<a href='https://doi.org/10.1145/3750450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world graph data can have billions to trillions of edges. Processing graphs at such scales requires the efficient use of parallel computing systems. However, current graph processing engines and methods struggle to scale beyond a few dozen computing nodes because they (i) cannot efficiently store and process graph data on this scale due to the huge memory footprint incurred and (ii) do not account for the variations in communication costs across different levels of the interconnection hierarchy. We introduce TianheGraph, a software approach to reduce the memory footprint of graphs and optimize graph processing on large-scale parallel systems with complex hardware interconnection components. TianheGraph integrates a new space-time-efficient graph compression technique to reduce the memory footprint of large-scale graphs. It provides a novel graph partitioning method to improve load balancing and minimize communication overhead across various levels of the interconnection hierarchy. We evaluate TianheGraph by applying it to fundamental graph operations on synthetic and real-world graphs, using up to 79,024 computing nodes and over 1.2 million processor cores. Our extensive experiments show that TianheGraph outperforms state-of-the-art parallel graph processing engines in throughput and scalability. Moreover, TianheGraph outperformed the top-ranked systems on the Graph 500 list at the time of submission.},
  archive      = {J_TACO},
  author       = {Xinbiao Gan},
  doi          = {10.1145/3750450},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-24},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {TianheGraph: Topology-aware graph processing},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A low-latency on-chip cache hierarchy for load-to-use stall reduction in GPUs. <em>TACO</em>, <em>22</em>(3), 1-27. (<a href='https://doi.org/10.1145/3760782'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memory hierarchy in Graphics Processing Units (GPUs) is conventionally designed to provide high bandwidth rather than low latency. In particular, because of the high tolerance to load-to-use latency (i.e., the time that warps wait for data fetched by memory loads), GPU L1D caches are optimized for density, capacity, and low power with latencies that are often orders of magnitude longer than conventional CPU caches. However, there are many important classes of data-parallel applications (e.g., graph, tree, priority queue processing, and sparse deep learning applications) that benefit from lower load-to-use latency than that offered by modern GPUs due to their inherent divergence and low effective Thread-Level Parallelism (TLP). This article introduces an innovative on-chip cache hierarchy that incorporates a decoupled L1D cache with reduced latency (LoTUS) and its management scheme. LoTUS is a minimally sized fully associative cache placed in each GPU subcore that captures the primary working set of data-parallel applications. It exploits conventional high-performance low-density SRAM cells and dramatically reduces load-to-use latency. We also propose an intelligent extension of LoTUS, called LoTUSage, which employs a lightweight learning-based model to predict the utility of caching requests in LoTUS. Evaluation results show that LoTUS and LoTUSage improve the average performance by 23.9% and 35.4% and reduce the average energy consumption by 27.8% and 38.5%, respectively, for the applications suffering from high load-to-use stalls with negligible area and power overheads.},
  archive      = {J_TACO},
  author       = {Negin (Sadat) (Nematollahi zadeh) Mahani and Hajar Falahati and Sina Darabi and Ahmad Javadi-Nezhad and Yunho Oh and Mohammad Sadrosadati and Hamid Sarbazi-Azad and Babak Falsafi},
  doi          = {10.1145/3760782},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-27},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {A low-latency on-chip cache hierarchy for load-to-use stall reduction in GPUs},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ecmas+: Efficient circuit mapping and scheduling for surface code encoded circuit on quantum cloud platform. <em>TACO</em>, <em>22</em>(3), 1-25. (<a href='https://doi.org/10.1145/3760783'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the leading candidate for quantum error correction, the surface code faces substantial overhead, such as redundant physical qubits and prolonged execution time. Reducing the space-time cost of circuit execution can significantly improve the throughput of modern quantum cloud platforms. While utilizing more physical qubits can reduce execution time, different quantum circuits vary in their ability to leverage chip resources. Therefore, optimizing the compilation of surface code circuits on quantum chips becomes critical. In this work, we address the mapping and scheduling problem in compiling surface code to reduce the cost. First, we introduce a novel metric Circuit Parallelism Degree to characterize circuit properties in detail and select the most suitable chip from a list of available options. Next, we will quantitatively assess the resources to determine if they are sufficient for the circuit. We then propose a resource-adaptive mapping and scheduling method called Ecmas+ , which customizes the initialization of chip resources for each circuit. Ecmas+ significantly reduces execution time in the double defect and lattice surgery models. Extensive numerical tests on practical datasets demonstrate that Ecmas+ outperforms state-of-the-art methods, reducing execution time by an average of 46% for the double defect model and 29.7% for the lattice surgery model.},
  archive      = {J_TACO},
  author       = {Mingzheng Zhu and Hao Fu and Haishan Song and Jun Wu and Chi Zhang and Wei Xie and Xiangyang Li},
  doi          = {10.1145/3760783},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-25},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {Ecmas+: Efficient circuit mapping and scheduling for surface code encoded circuit on quantum cloud platform},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Augur: Semantics-aware temporal prefetching for linked data structure. <em>TACO</em>, <em>22</em>(3), 1-27. (<a href='https://doi.org/10.1145/3762997'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linked data structures (LDS), such as lists and trees, are widely used in modern applications. Traversing LDS typically involves a significant amount of pointer chasing. Due to the serial nature of memory access in pointer chasing, the incurred long memory latency of traversing LDS has become a critical performance bottleneck. Furthermore, the poor spatial locality in LDS makes it difficult for spatial prefetchers to predict access addresses. Although temporal prefetchers can handle irregular memory access patterns, hindered by the challenges of collecting semantic information, current state-of-the-art temporal prefetchers suffer from significant metadata redundancy and frequent metadata conflicts. Consequently, there remain substantial opportunities to enhance the LDS prefetching. To solve this problem, we propose Augur, a semantics-aware temporal prefetcher to enhance LDS performance. Augur utilizes a novel pruning method to obtain semantic information and effectively extracts node address correlations from the perspective of nodes in LDS, thereby diminishing the metadata redundancy and conflicts. Additionally, Augur employs efficient metadata management strategies that guarantee a minimal storage overhead. Evaluated on LDS workloads, Augur achieves an average performance speedup of 17.8% and 11.7% over the baseline stride prefetcher and state-of-the-art spatial prefetcher Berti, respectively. Furthermore, Augur outperforms the state-of-the-art temporal prefetcher MISB, Triage, and Triangel, by 17.4%, 12.8%, and 6.3%, respectively, with a significantly lower storage overhead of only 1.26 KB.},
  archive      = {J_TACO},
  author       = {Feng Xue and Junliang Wu and Chenji Han and Xinyu Li and Tingting Zhang and Tianyi Liu and Fuxin Zhang},
  doi          = {10.1145/3762997},
  journal      = {ACM Transactions on Architecture and Code Optimization},
  month        = {9},
  number       = {3},
  pages        = {1-27},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  title        = {Augur: Semantics-aware temporal prefetching for linked data structure},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="tap">TAP - 3</h2>
<ul>
<li><details>
<summary>
(2025). Visual experience of space: Relating textual descriptions of perceived atmosphere to luminance contrast metrics. <em>TAP</em>, <em>22</em>(3), 1-18. (<a href='https://doi.org/10.1145/3727981'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This exploratory study investigates the quantifiable relationship between image properties and the aesthetic perception of indoor environments, focusing on luminance contrast, light, form, and material variations. A diverse image set of everyday spaces was curated, and a comprehensive list of atmosphere descriptors was developed from lighting literature. Using pixel value distribution analysis, images were classified by luminance contrast, and 24 participants evaluated 15 images using 54 Turkish atmosphere adjectives on a 5-point semantic differential scale. Principal Component Analysis (PCA) of the responses revealed three components based on 43 adjectives related to perceived atmosphere. Notably, the second component was significantly correlated with luminance contrast, indicating that variations in light, color, and materials—and the resulting changes in luminance contrast—can influence atmospheric perception. The first and third components captured atmospheric qualities beyond luminance contrast. These findings provide valuable insights into how image attributes, particularly luminance contrast, impact aesthetic evaluations of indoor environments, contributing to the broader understanding of atmospheric perception in built spaces.},
  archive      = {J_TAP},
  author       = {İpek Yalçın and Nilgün Olguntürk},
  doi          = {10.1145/3727981},
  journal      = {ACM Transactions on Applied Perception},
  month        = {7},
  number       = {3},
  pages        = {1-18},
  shortjournal = {ACM Trans. Appl. Perc.},
  title        = {Visual experience of space: Relating textual descriptions of perceived atmosphere to luminance contrast metrics},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An extensible open source software designed for virtual reality-based testing and treatment of vision disorders. <em>TAP</em>, <em>22</em>(3), 1-22. (<a href='https://doi.org/10.1145/3733833'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale screening programs for vision impairments can incur substantial costs. Computer-based screening methods, which combine different measurements within a single system, can facilitate and reduce the costs of such programs. Here, we present a virtual reality (VR) software, which includes tests for the assessment of visual acuity, stereoacuity, eye misalignments, and interocular suppression as well as games targeting different visual functions that may serve as treatment methods. The software can be easily extended to incorporate new tests and games. We present a proof of concept demonstrating the functionality of the software and its applicability in individuals with impaired binocularity. We evaluate a stereoacuity test in VR based on disparity detection using contoured objects by comparing its results to those obtained by standard clinical tests, i.e., TNO, Randot, and Titmus, for 7 amblyopes and 6 healthy controls. We evaluate the applicability of a new VR-based suppression test in 10 amblyopes and 6 healthy individuals. For the latter, we exploit the effects of short-term monocular deprivation, which induce a change of ocular dominance. Finally, we outline technical limitations and discuss potential applications.},
  archive      = {J_TAP},
  author       = {Johann Schneider and Yu Yi Yang and Maria Fronius and Juliane Tittes and Jochen Triesch},
  doi          = {10.1145/3733833},
  journal      = {ACM Transactions on Applied Perception},
  month        = {7},
  number       = {3},
  pages        = {1-22},
  shortjournal = {ACM Trans. Appl. Perc.},
  title        = {An extensible open source software designed for virtual reality-based testing and treatment of vision disorders},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The pulfrich effect in virtual reality. <em>TAP</em>, <em>22</em>(3), 1-22. (<a href='https://doi.org/10.1145/3746064'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Pulfrich effect, a visual phenomenon where a neural delay in one eye produces a depth misperception, has been directly studied on flat-panel displays but not in virtual reality (VR) environments. Through a series of three experiments, we investigated the relationship between luminance and contrast on the Pulfrich effect in VR and on the perception of motion. In two of our experiments, we found that low-reflectance stimuli produce a stronger Pulfrich effect than high-reflectance stimuli in VR, a result further accentuated by background luminance. Furthermore, the primary experiment showed that nullifying helix rotation motion is a powerful way to study the magnitude of the Pulfrich effect. With data from the first experiment, we developed a compelling VR illusion in which changing the color of a helix reverses the direction of perceived motion. Our second experiment extends the first with a discrimination task and a larger number of observers, confirming that low-contrast low-luminance conditions produce distinct perceptual effects. Experiment 3 elaborated that low-reflectance stimuli only produce a stronger Pulfrich effect than high-reflectance stimuli when the stimulus is moving away from the delayed eye. Data from the first and third experiments were successfully captured by power law function fits and linearized by plotting Pulfrich effect strength against logit-Michelson contrast. We use the power law as a basis for a fifth section discussing a potential model that may explain computationally how luminance and contrast contribute to the magnitude of the Pulfrich effect. All three experiments and the modeling section in tandem show that investigating well-known visual illusions such as the Pulfrich effect in VR has the potential to reveal insights into visual perception as well as inform us about the effects of contrast and asymmetric lighting in spatial computing.},
  archive      = {J_TAP},
  author       = {Anthony LoPrete and Alexander Gokan and Arthur G. Shapiro},
  doi          = {10.1145/3746064},
  journal      = {ACM Transactions on Applied Perception},
  month        = {7},
  number       = {3},
  pages        = {1-22},
  shortjournal = {ACM Trans. Appl. Perc.},
  title        = {The pulfrich effect in virtual reality},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="telo">TELO - 7</h2>
<ul>
<li><details>
<summary>
(2025). First steps toward a runtime analysis when starting with a good solution. <em>TELO</em>, <em>5</em>(2), 1-41. (<a href='https://doi.org/10.1145/3675783'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The mathematical runtime analysis of evolutionary algorithms traditionally regards the time an algorithm needs to find a solution of a certain quality when initialized with a random population. In practical applications it may be possible to guess solutions that are better than random ones. We start a mathematical runtime analysis for such situations. We observe that different algorithms profit to a very different degree from a better initialization. We also show that the optimal parameterization of an algorithm can depend strongly on the quality of the initial solutions. To overcome this difficulty, self-adjusting and randomized heavy-tailed parameter choices can be profitable. Finally, we observe a larger gap between the performance of the best evolutionary algorithm we found and the corresponding black-box complexity. This could suggest that evolutionary algorithms better exploiting good initial solutions are still to be found. These first findings stem from analyzing the performance of the \((1+1)\) evolutionary algorithm and the static, self-adjusting, and heavy-tailed \((1+(\lambda,\lambda))\) genetic algorithms on the OneMax benchmark. We are optimistic that the question of how to profit from good initial solutions is interesting beyond these first examples.},
  archive  = {J},
  author   = {Denis Antipov and Maxim Buzdalov and Benjamin Doerr},
  doi      = {10.1145/3675783},
  journal  = {ACM Transactions on Evolutionary Learning},
  month    = {5},
  number   = {2},
  pages    = {1-41},
  title    = {First steps toward a runtime analysis when starting with a good solution},
  volume   = {5},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable optimisation through online and offline hyper-heuristics. <em>TELO</em>, <em>5</em>(2), 1-29. (<a href='https://doi.org/10.1145/3701236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Research in the explainability of optimisation techniques has largely focused on metaheuristics and their movement of solutions around the search landscape. Hyper-heuristics create a different challenge for explainability as they make use of many more operators, or low-level heuristics and learning algorithms which modify their probability of selection online. This article describes a set of methods for explaining hyper-heuristics decisions in both online and offline scenarios using selection hyper-heuristics as an example. These methods help to explain various aspects of the function of hyper-heuristics both at a particular juncture in the optimisation process and through time. Visualisations of each method acting on sequences provide an understanding of which operators are being utilised and when, and in which combinations to produce a greater understanding of the algorithm-problem nexus in hyper-heuristic search. These methods are demonstrated on a range of problems including those in operational research and water distribution network optimisation. They demonstrate the insight that can be generated from optimisation using selection hyper-heuristics, including building an understanding of heuristic usage, useful combinations of heuristics and heuristic parameterisations. Furthermore the dynamics of heuristic utility are explored throughout an optimisation run and we show that it is possible to cluster problem instances according to heuristic selection alone, providing insight into the perception of problems from a hyper-heuristic perspective.},
  archive  = {J},
  author   = {William B. Yates and Edward C. Keedwell and Ahmed Kheiri},
  doi      = {10.1145/3701236},
  journal  = {ACM Transactions on Evolutionary Learning},
  month    = {5},
  number   = {2},
  pages    = {1-29},
  title    = {Explainable optimisation through online and offline hyper-heuristics},
  volume   = {5},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EVOTER: Evolution of transparent explainable rule-sets. <em>TELO</em>, <em>5</em>(2), 1-30. (<a href='https://doi.org/10.1145/3702651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Most AI systems are black boxes generating reasonable outputs for given inputs. Some domains, however, have explainability and trustworthiness requirements that cannot be directly met by these approaches. Various methods have therefore been developed to interpret black-box models after training. This article advocates an alternative approach where the models are transparent and explainable to begin with. This approach, EVOTER, evolves rule-sets based on extended propositional logic expressions. The approach is evaluated in several prediction/classification and prescription/policy search domains with and without a surrogate. It is shown to discover meaningful rule-sets that perform similarly to black-box models. The rules can provide insight into the domain and make hidden biases explicit. It may also be possible to edit the rules directly to remove biases and add constraints. EVOTER thus forms a promising foundation for building trustworthy AI systems for real-world applications in the future.},
  archive  = {J},
  author   = {Hormoz Shahrzad and Babak Hodjat and Risto Miikkulainen},
  doi      = {10.1145/3702651},
  journal  = {ACM Transactions on Evolutionary Learning},
  month    = {5},
  number   = {2},
  pages    = {1-30},
  title    = {EVOTER: Evolution of transparent explainable rule-sets},
  volume   = {5},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objectivising acquisition functions in bayesian optimisation. <em>TELO</em>, <em>5</em>(2), 1-33. (<a href='https://doi.org/10.1145/3716504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian optimisation (BO) is an efficient approach for solving expensive optimisation problems, where acquisition functions play a major role in achieving the tradeoff between exploitation and exploration. The exploitation–exploration tradeoff is challenging; excessive focus on exploitation can stagnate the search, while too much exploration can slow convergence. Multi-objectivisation has been explored as an effective approach to mitigate the exploitation–exploration tradeoff problem. Along this line, in this article, we propose a Multi-Objectivisation-Based Adaptive Exploitation–Exploration Tradeoff Framework (MOEE) to balance exploitation and exploration in BO. MOEE considers the nondominated front formed by the exploitation and exploration objectives and adaptively switches the focus on exploration and exploitation on the basis of the search status. We verify our method on the 19 synthetic and practical problem instances with 1–20 dimensions, and the results show that our proposed multi-objectivisation framework can achieve a good balance between exploitation and exploration.},
  archive      = {J_TELO},
  author       = {Chao Jiang and Miqing Li},
  doi          = {10.1145/3716504},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  month        = {5},
  number       = {2},
  pages        = {1-33},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Multi-objectivising acquisition functions in bayesian optimisation},
  volume       = {5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable benchmarking for iterative optimization heuristics. <em>TELO</em>, <em>5</em>(2), 1-30. (<a href='https://doi.org/10.1145/3716638'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Benchmarking heuristic algorithms is vital to understand under which conditions and on what kind of problems certain algorithms perform well. In most current research into heuristic optimization algorithms, only a very limited number of scenarios, algorithm configurations and hyper-parameter settings are explored, leading to incomplete and often biased insights and results. This article presents a novel approach that we call explainable benchmarking. We introduce the IOHxplainer software library, for systematic analysing the performance of various optimization algorithms and the impact of their different components and hyperparameters. We showcase the methodology in the context of two modular optimization implementations. Through this library, we examine the impact of different algorithmic components and configurations, offering insights into their performance across diverse scenarios. We provide a systematic method for evaluating and interpreting the behaviour and efficiency of iterative optimization heuristics in a more transparent and comprehensible manner, aiming to improve future benchmarking and algorithm design practices.},
  archive  = {J},
  author   = {Niki van Stein and Diederick Vermetten and Anna V. Kononova and Thomas Bäck},
  doi      = {10.1145/3716638},
  journal  = {ACM Transactions on Evolutionary Learning},
  month    = {5},
  number   = {2},
  pages    = {1-30},
  title    = {Explainable benchmarking for iterative optimization heuristics},
  volume   = {5},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards explainable metaheuristics: Feature mining of search trajectories through principal component projection. <em>TELO</em>, <em>5</em>(2), 1-30. (<a href='https://doi.org/10.1145/3731456'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {While population-based metaheuristics have proven useful for refining and improving explainable AI systems, they are seldom the focus of explanatory approaches themselves. This stems from their inherently stochastic, population-driven searches, which complicate the use of standard explainability techniques. In this article, we present a method to identify which decision variables have the greatest impact during an algorithm’s trajectory from random initialsation to convergence. We apply Principal Component Analysis to project each population onto a lower-dimensional space, then introduce two metrics—Mean Variable Contribution and Proportion of Aligned Variables—to identify the variables most responsible for guiding the search. Using four different population-based methods (Particle Swarm Optimisation, Genetic Algorithm, Differential Evolution, and Covariance Matrix Adaptation Evolution Strategy) on 24 BBOB benchmark functions in 10 dimensions, we find that these metrics highlight meaningful variable relationships and provide a window into each method’s search dynamics. By comparing the features extracted across algorithms and problems, we illustrate how certain variable subsets consistently drive major improvements in solution quality. In doing so, new evolutionary algorithm variants can be designed to take advantage of these influential variables, while also identifying underutilised variables that may benefit alternative search strategies.},
  archive  = {J},
  author   = {Martin Fyvie and John A. W. McCall and Lee A. Christie},
  doi      = {10.1145/3731456},
  journal  = {ACM Transactions on Evolutionary Learning},
  month    = {5},
  number   = {2},
  pages    = {1-30},
  title    = {Towards explainable metaheuristics: Feature mining of search trajectories through principal component projection},
  volume   = {5},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Introduction to the special issue on explainable AI in evolutionary Computation—Part 2. <em>TELO</em>, <em>5</em>(2), 1-2. (<a href='https://doi.org/10.1145/3733611'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Jaume Bacardit and Alexander Brownlee and Stefano Cagnoni and Giovanni Iacca and John McCall and David Walker},
  doi     = {10.1145/3733611},
  journal = {ACM Transactions on Evolutionary Learning},
  month   = {5},
  number  = {2},
  pages   = {1-2},
  title   = {Introduction to the special issue on explainable AI in evolutionary Computation—Part 2},
  volume  = {5},
  year    = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="tiis">TIIS - 1</h2>
<ul>
<li><details>
<summary>
(2025). Practitioners and bias in machine learning: A study. <em>TIIS</em>, <em>15</em>(2), 1-28. (<a href='https://doi.org/10.1145/3733838'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing adoption of machine learning (ML) raises ethical concerns, particularly regarding bias. This study explores how ML practitioners with limited experience in bias understand and apply bias definitions, detection measures, and mitigation methods. Through a take-home task, exercises, and interviews with 22 participants, we identified five key themes: sources of bias, selecting bias metrics, detecting bias, mitigating bias, and ethical considerations. Participants faced unresolved conflicts, such as applying fairness definitions in practice, selecting context-dependent bias metrics, addressing real-world biases, balancing model performance with bias mitigation, and relying on personal perspectives over data-driven metrics. While bias mitigation techniques helped identify biases in two datasets, participants could not fully eliminate bias, citing the oversimplification of complex processes into models with limited variables. We propose designing bias detection tools that encourage practitioners to focus on the underlying assumptions and integrating bias concepts into ML practices, such as using a harmonic mean-based approach, akin to the F1 score, to balance bias and accuracy.},
  archive      = {J_TIIS},
  author       = {Robert Cinca and Enrico Costanza and Mirco Musolesi},
  doi          = {10.1145/3733838},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {6},
  number       = {2},
  pages        = {1-28},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {Practitioners and bias in machine learning: A study},
  volume       = {15},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="tist">TIST - 8</h2>
<ul>
<li><details>
<summary>
(2025). Integrating AI planning with natural language processing: A combination of explicit and tacit knowledge. <em>TIST</em>, <em>16</em>(4), 1-37. (<a href='https://doi.org/10.1145/3729236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural language processing (NLP) aims at investigating the interactions between agents and humans, which processes and analyzes large amounts of natural language data. Large-scale language models play an important role in current NLP. However, the challenges of explainability and complexity come along with the development of language models. One way is to introduce logical relations and rules into NLP models, such as making use of Automated Planning. Automated planning (AI planning) focuses on building symbolic domain models and synthesizing plans to transit initial states to goals based on domain models. Recently, there have been plenty of works related to those two fields, which have the abilities to generate explicit knowledge, e.g., preconditions and effects of action models, and learn from tacit knowledge, e.g., neural models, respectively. Integrating AI planning and NLP effectively improves the communication between human and intelligent agents. This article outlines the commons and relations between AI planning and NLP, and it argues that each of them can effectively impact the other one in six areas: (1) planning-based text understanding, (2) planning-based NLP, (3) text-based human–robot interaction, (4) planning-based explainability, (5) evaluation metrics, and (6) applications. We also explore some potential future issues between AI planning and NLP. To the best of our knowledge, this survey is the first that addresses the deep connections between AI planning and NLP.},
  archive      = {J_TIST},
  author       = {Kebing Jin and Hankz Hankui Zhuo},
  doi          = {10.1145/3729236},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {8},
  number       = {4},
  pages        = {1-37},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Integrating AI planning with natural language processing: A combination of explicit and tacit knowledge},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PREUS: Proactive and robust edge-UAV systems for autonomous monitoring in dynamic environments. <em>TIST</em>, <em>16</em>(4), 1-20. (<a href='https://doi.org/10.1145/3733836'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing and AI can potentially empower Unmanned Aerial Vehicle (UAV) systems with automated decision-making and resource support for monitoring in future science tasks such as emergency response, search and rescue, inspections, and wildfires. However, it is challenging to achieve autonomous and robust monitoring in such systems, given the dynamic environmental situations, the limited capabilities, and the unbalanced load of the UAVs. For instance, the monitoring activity levels at different locations might vary, which leads to an unbalanced monitoring load for the corresponding UAVs. Moreover, the UAVs require regular recharging/maintenance and can have malfunctions that will disrupt the monitoring task. In this article, we develop a novel proactive and robust Edge-UAV framework named PREUS to enable autonomous and efficient monitoring of dynamic environments when faced with dynamic environment situations and various UAV workload stresses that can jeopardize the monitoring performance. PREUS features a unique design to handle the varying UAV workload stress of the monitored area. It incorporates novel spatial, temporal, and proactive exploration vs. exploitation planning to balance the UAVs’ workloads in various locations with fluctuating activities. In addition, PREUS includes novel Deep Reinforcement Learning (DRL) design specialized to maximize coverage in the complex environments and provides faster and stabler decision-making capabilities than the existing methods. The positive impact brought by PREUS is demonstrated in terms of the achieved monitoring performance, including coverage and balanced UAV load.},
  archive      = {J_TIST},
  author       = {Ismail Alqerm and Nuo Cheng and Jianli Pan},
  doi          = {10.1145/3733836},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {8},
  number       = {4},
  pages        = {1-20},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {PREUS: Proactive and robust edge-UAV systems for autonomous monitoring in dynamic environments},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grounding foundation models through federated transfer learning: A general framework. <em>TIST</em>, <em>16</em>(4), 1-54. (<a href='https://doi.org/10.1145/3742788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foundation Models (FMs) such as GPT-4 encoded with vast knowledge and powerful emergent abilities have achieved remarkable success in various natural language processing and computer vision tasks. Grounding FMs by adapting them to domain-specific tasks or augmenting them with domain-specific knowledge enables us to exploit the full potential of FMs. However, grounding FMs faces several challenges, stemming primarily from constrained computing resources, data privacy, model heterogeneity, and model ownership. Federated Transfer Learning (FTL), the combination of federated learning and transfer learning, provides promising solutions to address these challenges. Recently, the need for grounding FMs leveraging FTL, coined FTL-FM, has arisen strongly in both academia and industry. Motivated by the strong growth in FTL-FM research and the potential impact of FTL-FM on industrial applications, we propose an FTL-FM framework that formulates problems of grounding FMs in the federated learning setting, construct a detailed taxonomy based on the FTL-FM framework to categorize state-of-the-art FTL-FM works, and comprehensively overview FTL-FM works based on the proposed taxonomy. We also establish correspondence between FTL-FM and conventional phases of adapting FM so that FM practitioners can align their research works with FTL-FM. In addition, we overview advanced efficiency-improving and privacy-preserving techniques because efficiency and privacy are critical concerns in FTL-FM. Last, we discuss opportunities and future research directions of FTL-FM.},
  archive      = {J_TIST},
  author       = {Yan Kang and Tao Fan and Hanlin Gu and Xiaojin Zhang and Lixin Fan and Qiang Yang},
  doi          = {10.1145/3742788},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {8},
  number       = {4},
  pages        = {1-54},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Grounding foundation models through federated transfer learning: A general framework},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling multi-seasonal multi-behavior dependency for temporal recommendation. <em>TIST</em>, <em>16</em>(4), 1-23. (<a href='https://doi.org/10.1145/3742793'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mining temporal patterns from user behaviors has long been investigated, but most of the existing work centers on single-type user–item interactions, such as purchase or click, which fails to take advantage of the user’s diversified interests revealed by various types of behavior. However, capturing patterns from different behavior sequences and modeling the complex inter-correlation between them are non-trivial tasks, as the high sparsity of type-related interactions, multi-seasonality of individual behaviors, and time-variant dependency of multi-type activities make it really challenging. To address these challenges, we propose a novel framework that aims to model the M ulti-Seasonal M ulti-Behavior Dep endencies (MMDep) both within and across the multi-type behavior sequences. In the proposed model, an item co-occurrence matrix factorization strategy is introduced to alleviate the sparsity issue in type-related behavior sequences. And a temporal dependency module that incorporates multi-scale EMA mechanism is utilized to capture the multi-seasonal dependencies within individual sequences. Moreover, a cross-behavior dependency module is employed to learn the time-variant dependency among different behaviors. Extensive experiments on three real-world datasets demonstrate that the proposed MMDep performs significantly better than the state-of-the-art baselines. And it may provide some new insights and tools on how to leverage multi-behavior data for better temporal recommendation.},
  archive      = {J_TIST},
  author       = {Shichao Liang and Wen Wen and Yali Feng and Ruichu Cai and Zhifeng Hao},
  doi          = {10.1145/3742793},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {8},
  number       = {4},
  pages        = {1-23},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Modeling multi-seasonal multi-behavior dependency for temporal recommendation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Smart imputation, better recommendations: Improving traditional point-of-interest recommendation through data augmentation. <em>TIST</em>, <em>16</em>(4), 1-35. (<a href='https://doi.org/10.1145/3744347'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data sparsity is a persistent challenge in recommender systems, especially in specific domains like Point-of-Interest (POI) recommendation, where it significantly impacts model performance. While classical recommender systems have used various imputation and data augmentation mechanisms to address data sparsity, these methods have not been extensively explored in the POI recommendation domain. In this work, we propose a generic imputation framework to study the use of data augmentation techniques to generate synthetic check-ins and analyze their effects on the POI recommendation scenario. Our main goal is to enhance the performance of various traditional recommenders by increasing the training set interactions, considering specific characteristics of the domain, such as geographical information. We apply these techniques in six different cities from a global Foursquare check-in dataset, as well as in two additional cities from the Gowalla dataset, and a separate dataset from Yelp, ensuring a comprehensive evaluation across multiple data sources. Our imputation approach evidences improvements for most models. In several cases, these improvements exceeded 100% for ranking accuracy, measured in terms of nDCG, without considerably compromising novelty or diversity. Data and code are released at https://github.com/pablosanchezp/ImputationForPOIRecsys .},
  archive      = {J_TIST},
  author       = {Pablo Sánchez and Alejandro Bellogín},
  doi          = {10.1145/3744347},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {8},
  number       = {4},
  pages        = {1-35},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Smart imputation, better recommendations: Improving traditional point-of-interest recommendation through data augmentation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrated hybrid transformer and multi-receptive feature extraction mechanism for electrocardiogram denoising using score-based diffusion model. <em>TIST</em>, <em>16</em>(4), 1-24. (<a href='https://doi.org/10.1145/3744654'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrocardiogram (ECG) is the foundation of the analysis of cardiac disease. In the hospital clinical ECG diagnostic scenarios, when doctors analyze ECG signals or when an ECG intelligent diagnostic system is used, there might be strong noises like baseline wander or muscle artifact in the ECG signals due to the unstable state of the subjects, and such interferences are usually difficult to be filtered out by traditional filters, which can lead to serious errors in the subsequent signal analysis. To solve this problem, we propose a novel network which integrates hybrid transformer and multi-receptive feature extraction mechanism into score-based diffusion model. We used score-based diffusion model to reconstruct the clean ECG signals from noisy ones. The experiment was conducted on the QT Database and the MIT-BIH Noise Stress Test Database to verify the feasibility of our method. Baseline methods are used for comparison. The evaluation results show that our method can achieve an outstanding performance on four distance-based evaluation metrics by at least 26% overall improvement in the comparison with the best baseline method. The study demonstrates that the signal denoising and reconstruction method based on the self-designed score-based diffusion model can effectively remove the interferences in the ECG signals, thereby facilitating the subsequent diagnosis in real-world situation. It also has huge potential for establishing the ECG intelligent analysis system.},
  archive      = {J_TIST},
  author       = {Baofeng Zhu and Wanjun Cheng and Xia Zhang and Jiren Liu},
  doi          = {10.1145/3744654},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {8},
  number       = {4},
  pages        = {1-24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Integrated hybrid transformer and multi-receptive feature extraction mechanism for electrocardiogram denoising using score-based diffusion model},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Counter-samples: A stateless strategy to neutralize black-box adversarial attacks. <em>TIST</em>, <em>16</em>(4), 1-23. (<a href='https://doi.org/10.1145/3744657'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our article introduces a novel defense mechanism against black-box attacks, where attackers exploit the victim model as an oracle to craft adversarial examples. Unlike traditional pre-processing defenses that rely on sanitizing input samples, our stateless strategy directly counters the attack process itself. For each query, we evaluate a counter-sample, an optimized version of the original sample, designed to thwart the attacker’s objective. By responding to every black-box query with a targeted white-box optimization, our strategy introduces a strategic asymmetry that significantly advantages the defender. Our approach proves to be highly effective against state-of-the-art black-box attacks, outperforming existing defenses on both CIFAR-10 and ImageNet datasets. Specifically, our method achieves an average Attack Failure Rate (AFR) of 74.7% (up from 13%) on ImageNet and 67.7% (up from 3.5%) on CIFAR-10 when tested against 10 state-of-the-art query-based black-box attacks. Moreover, it maintains the model’s performance on legitimate inputs, with accuracy (ACC) reduced by only 0.7% on ImageNet and 0.9% on CIFAR-10. This is in stark contrast to other defenses tested, which can cause accuracy drops of up to 50%. Such a modest decrease ensures negligible performance degradation on legitimate tasks. Furthermore, we demonstrate that our defense exhibits superior robustness across datasets and attack scenarios, including adaptive attacks specifically designed to try to bypass our method. This robustness highlights the strength and adaptability of our approach in countering adversarial threats.},
  archive      = {J_TIST},
  author       = {Roey Bokobza and Yisroel Mirsky},
  doi          = {10.1145/3744657},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {8},
  number       = {4},
  pages        = {1-23},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Counter-samples: A stateless strategy to neutralize black-box adversarial attacks},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing reachability in graph-based recommender systems. <em>TIST</em>, <em>16</em>(4), 1-23. (<a href='https://doi.org/10.1145/3744658'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While accuracy has long been prioritized as the primary metric for Recommender Systems (RSs), it is increasingly accepted that the system’s overall quality is not solely determined by this factor. Reachability, the ease with which users can navigate the whole content catalog through recommendations, emerges as a pivotal yet under-explored concept: not only it ensures a smooth experience for users, but it also provides more equitable exposure for the items, avoiding that only a small fraction of popular items get the bulk of the attention. Despite its importance, the few existing studies analyze reachability without attempting a proper optimization. In this article, we study the problem of optimizing the overall reachability of a RS while maintaining high-quality recommendations. We model a user browsing session as a random walk on a recommendation graph, where the links and the transition probabilities are defined based on the relevance score of the recommendation list that the user gets at every step. In this setting, reachability is modeled as the expected length of a path to reach a given item. We introduce two optimization problems, one discrete and one continuous, and characterize their theoretical properties. We then devise two algorithms that outperform non-trivial baseline methods in enhancing reachability while maintaining a high Normalized Discounted Cumulative Gain (nDCG) score. Our experimental results show that, in some settings, our methods are able to improve the reachability metric by 80% while only compromising nDCG by 5%. Moreover, our empirical analysis shows that optimizing for reachability provides positive effects also on other prevalent “beyond-accuracy” metrics.},
  archive      = {J_TIST},
  author       = {Alex Martínez and Federico Cinus and Francesco Bonchi and Jordi Vitrià},
  doi          = {10.1145/3744658},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {8},
  number       = {4},
  pages        = {1-23},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Optimizing reachability in graph-based recommender systems},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="tkdd">TKDD - 18</h2>
<ul>
<li><details>
<summary>
(2025). Causal meta-learning with multi-view graphs for cold-start recommendation. <em>TKDD</em>, <em>19</em>(7), 1-29. (<a href='https://doi.org/10.1145/3732943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cold-start recommendation is a well-known problem in practical application scenarios. Generating reliable recommendations can be challenging when interactions are typically sparse. To mitigate the cold-start problem, some methods incorporate auxiliary information about users and items, and others adopt meta-learning to improve recommendation accuracy. However, these approaches overlook the fact that items are interdependent and likely to be related or similar. Moreover, user preference distributions in the meta-training and meta-testing phases are different in the cold-start scenario. To address these problems, we present a novel strategy called Causal Meta-learning with Multi-view Graphs (CausalMMG). Specifically, we first construct multi-view item-item graphs to explore the correlations and similarities between items from multiple perspectives. A multi-view item representer is then used to learn item representations, exploiting graph convolution neural networks to capture the structure of these different item–item graphs. We then resort to the structural causal models of causal inference and further develop a causality-enhanced bi-level adaptive meta-learner to eliminate bias caused by the different distributions of user preferences. Moreover, the meta-learner learns the user preferences for items in different orders through hierarchical and task-level adaptations. Finally, we evaluate CausalMMG on several real-world datasets, demonstrating its effectiveness in various scenarios. The results show that the proposed CausalMMG is significantly superior to competitive baseline methods for cold-start recommendation on all datasets, highlighting the importance of incorporating the multiple relationships between items and modeling different user preference distributions in recommender systems.},
  archive      = {J_TKDD},
  author       = {Huiting Liu and Wei Zhang and Peipei Li and Peng Zhao and Xindong Wu},
  doi          = {10.1145/3732943},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-29},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Causal meta-learning with multi-view graphs for cold-start recommendation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent representation learning for attributed graph anomaly detection. <em>TKDD</em>, <em>19</em>(7), 1-22. (<a href='https://doi.org/10.1145/3733604'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection in attributed graph data has been widely applied in real applications. However, the intricate topology of graph data, high-dimensional attributes, and class imbalance inherent in anomaly detection tasks render attributed graph anomaly detection a challenging task. To detect anomalies using the intricate topology information of graph data, a dual-masked autoencoders is proposed for attributed graph anomaly detection, denoted as MAGAD. Specifically, in the MAGAD, the class imbalance in attributed graph data is dealt with by randomly masking the original graph data to obtain masked graph data for the anomaly detection task. And then, a latent representation of the graph data is obtained by training dual autoencoders, where one autoencoder is developed for reconstructing the original graph data, and another for reconstructing randomly masked graph data. This assists in identifying abnormal nodes in the attributed graph data. Subsequently, to capture anomalous information from relevant features, MAGAD uses a random re-masking strategy for latent representations learned from the masked graph. Finally, the anomaly scores of the nodes are calculated using the learned latent representations from the decoders of the dual autoencoders. Experimental results on five real-world datasets demonstrate that the MAGAD algorithm outperforms state-of-the-art anomaly detection algorithms.},
  archive      = {J_TKDD},
  author       = {Shichao Zhang and Penghui Xi and Mengqi Jiang and Guixian Zhang and Debo Cheng},
  doi          = {10.1145/3733604},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Latent representation learning for attributed graph anomaly detection},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph self-attention mechanism for interpretable multi-hop knowledge graph link prediction. <em>TKDD</em>, <em>19</em>(7), 1-22. (<a href='https://doi.org/10.1145/3737702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graphs (KGs) are extensively used in recommendation systems and information retrieval but often suffer from incompleteness. A popular solution to this problem is multi-hop inference through a reinforcement learning framework, which provides an interpretable path for predicting missing links in KGs. Most previous work focuses on improving the performance of multi-hop link prediction. However, it has been observed that many multi-hop paths generated by these methods are irrational; they often fail to reasonably explain the predicted answer entities. To address this challenge, we introduce the Joint Multi-hop Link Prediction (JMLP) framework. The framework consists of a relation attention network and an entity attention network, which collaboratively generate the reasoning paths. The relation attention module utilizes an induction network to encode historical paths and employs the graph self-attention mechanism to refine the interaction of relation contextual information. The entity attention module uses the graph attention mechanism to obtain the aggregated contextual features and leverages self-attention to strengthen the correlation between local and global contextual entity features. Extensive experiments on five datasets validate the effectiveness of our approach, demonstrating significant improvements both in predictive performance and interpretability compared to state-of-the-art methods.},
  archive      = {J_TKDD},
  author       = {Hao Liu and Dong Li and Bing Zeng and Wei Liang and Dongjie Li},
  doi          = {10.1145/3737702},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Graph self-attention mechanism for interpretable multi-hop knowledge graph link prediction},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding and guiding weakly supervised entity alignment with potential isomorphism propagation. <em>TKDD</em>, <em>19</em>(7), 1-28. (<a href='https://doi.org/10.1145/3742436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly Supervised Entity Alignment (EA) is the task of identifying equivalent entities across diverse knowledge graphs (KGs) using only a limited number of seed alignments. Despite substantial advances in aggregation-based weakly supervised EA, the underlying mechanisms in this setting remain unexplored. In this article, we present a propagation perspective to analyze weakly supervised EA and explain the existing aggregation-based EA models. Our theoretical analysis reveals that these models essentially seek propagation operators for pairwise entity similarities. We further prove that, despite the structural heterogeneity across different KGs, the potentially aligned entities within aggregation-based EA models exhibit isomorphic subgraphs, a fundamental yet underexplored premise of EA. Leveraging this insight, we introduce a potential isomorphism propagation operator to enhance the propagation of neighborhood information across KGs. We develop a general EA framework, PipEA, incorporating this operator to improve the accuracy of every type of aggregation-based model without altering the learning process. Extensive experiments substantiate our theoretical findings and demonstrate PipEA’s significant performance gains over state-of-the-art weakly supervised EA methods. Our work advances the field and enhances our comprehension of aggregation-based weakly supervised EA.},
  archive      = {J_TKDD},
  author       = {Haifeng Sun and Yuanyi Wang and Han Li and Wei Tang and Zirui Zhuang and Qi Qi and Jingyu Wang},
  doi          = {10.1145/3742436},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-28},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Understanding and guiding weakly supervised entity alignment with potential isomorphism propagation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MagiNet: Mask-aware graph imputation network for incomplete traffic data. <em>TKDD</em>, <em>19</em>(7), 1-20. (<a href='https://doi.org/10.1145/3743141'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to detector malfunctions and communication failures, missing data is ubiquitous during the collection of traffic data. Therefore, it is of vital importance to impute the missing values to facilitate data analysis and decision-making for Intelligent Transportation System (ITS) . However, existing imputation methods generally perform zero pre-filling techniques to initialize missing values, introducing inevitable noise. Moreover, we observe prevalent over-smoothed interpolations, falling short in revealing the intrinsic spatio-temporal correlations of incomplete traffic data. To this end, we propose Mask-Aware Graph Imputation Network (MagiNet) . Our method designs an adaptive mask spatio-temporal encoder to learn the latent representations of incomplete data, eliminating the reliance on pre-filling missing values. Furthermore, we devise a spatio-temporal decoder that stacks multiple blocks to capture the inherent spatial and temporal dependencies within incomplete traffic data, alleviating over-smoothed imputation. Extensive experiments demonstrate that our method outperforms state-of-the-art imputation methods on five real-world traffic datasets, yielding an average improvement of 4.31% in RMSE and 3.72% in MAPE under Missing Completely at Random (MCAR) pattern. Code is available at https://github.com/JeremyChou28/MagiNet .},
  archive      = {J_TKDD},
  author       = {Jianping Zhou and Bin Lu and Zhanyu Liu and Siyu Pan and Xuejun Feng and Hua Wei and Guanjie Zheng and Xinbing Wang and Chenghu Zhou},
  doi          = {10.1145/3743141},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {MagiNet: Mask-aware graph imputation network for incomplete traffic data},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence-guaranteed federated learning through gradient trajectory smoothing with triple-objective decomposition. <em>TKDD</em>, <em>19</em>(7), 1-31. (<a href='https://doi.org/10.1145/3743142'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) has been widely adopted as a distributed machine learning paradigm aiming to derive a global model without transferring local data to the server. In the context of heterogeneous environments typical of many FL deployments, our research has identified the performance oscillation problem in existing FL methods, resulting in slow convergence and severe performance drop. In this article, we first investigate the global optimizing objective in FL and demonstrate that, due to data heterogeneity and partial client participation, the global updates in a single training epoch may diverge from the intended objectives of conventional FL methods. To address this problem, we introduce a triple-objective decomposition mechanism to decompose the overarching global objective into three distinct local objectives aimed at aligning client gradients. Subsequently, we propose a gradient trajectory smoothing technique known as FedGTS, which refines local updates by estimating a pseudo-gradient leveraging historical global update trajectories. This approach is designed to mitigate performance oscillations and enhance the stability of the learning process. We theoretically demonstrate that our approach reduces variance of local updates and achieves a guaranteed convergence rate. We experimentally show that the proposed method outperforms the baselines with faster convergence and higher accuracy. Extensive experiments validate the effectiveness of the proposed approach across various heterogeneity settings. Our codes are publicly available at GitHub ( https://github.com/ZongHR/FedGTS ).},
  archive      = {J_TKDD},
  author       = {Haoran Zong and Xiao Zhang and Ruichen Li and Jianhui Duan and Derun Zou and Wenzhong Li},
  doi          = {10.1145/3743142},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-31},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Convergence-guaranteed federated learning through gradient trajectory smoothing with triple-objective decomposition},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CAT-LLM: Style-enhanced large language models with text style definition for chinese article-style transfer. <em>TKDD</em>, <em>19</em>(7), 1-33. (<a href='https://doi.org/10.1145/3744250'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text style transfer plays a vital role in online entertainment and social media. However, existing models struggle to handle the complexity of Chinese long texts, such as rhetoric, structure, and culture, which restricts their broader application. To bridge this gap, we propose a Chinese Article-style Transfer (CAT-LLM) framework, which addresses the challenges of style transfer in complex Chinese long texts. At its core, CAT-LLM features a bespoke pluggable Text Style Definition (TSD) module that integrates machine learning algorithms to analyze and model article styles at both word and sentence levels. This module acts as a bridge, enabling large language models (LLMs) to better understand and adapt to the complexities of Chinese article styles. Furthermore, it supports the dynamic expansion of internal style trees, enabling the framework to seamlessly incorporate new and diverse style definitions, enhancing adaptability and scalability for future research and applications. Additionally, to facilitate robust evaluation, we created 10 parallel datasets using a combination of ChatGPT and various Chinese texts, each corresponding to distinct writing styles, significantly improving the accuracy of the model evaluation and establishing a novel paradigm for text style transfer research. Extensive experimental results demonstrate that CAT-LLM, combined with GPT-3.5-Turbo, achieves state-of-the-art performance, with a transfer accuracy F1 score of 79.36% and a content preservation F1 score of 96.47% on the “Fortress Besieged” dataset. These results highlight CAT-LLM’s innovative contributions to style transfer research, including its ability to preserve content integrity while achieving precise and flexible style transfer across diverse Chinese text domains. Building on these contributions, CAT-LLM presents significant potential for advancing Chinese digital media and facilitating automated content creation. Source code is available at GitHub ( https://github.com/TaoZhen1110/CAT-LLM ).},
  archive      = {J_TKDD},
  author       = {Zhen Tao and Dinghao Xi and Zhiyu Li and Liumin Tang and Wei Xu},
  doi          = {10.1145/3744250},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-33},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {CAT-LLM: Style-enhanced large language models with text style definition for chinese article-style transfer},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PRIME: Pretraining for patient condition representation with irregular multimodal electronic health records. <em>TKDD</em>, <em>19</em>(7), 1-39. (<a href='https://doi.org/10.1145/3744251'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing collection of electronic health records (EHRs), deep learning has become a crucial tool for real-time treatment analysis. However, due to patient privacy concerns, the scarcity of labeled data limits the end-to-end models that rely on large training data. Self-supervised pretraining offers a promising solution. Nevertheless, applying pretraining to EHRs faces two key issues: (1) EHRs exhibit multimodality, including monitoring data and recorded clinical note. For multimodal pretraining, designing a self-supervised task that can establish cross-modal associations while preserving all modal-unique information remains challenging. (2) Both modalities are sequential and irregular, with varying intervals between monitoring or records. Aligning monitoring times with recorded times poses a significant issue for fine-grained cross-modal pretraining. Existing pretraining models either focus on a single modality or only models regular data, failing to address them together. To fill this gap and fully utilize unlabel EHR data, we propose a p retraining model to learn patient r epresentation using unlabel i rregular m ultimodal E HRs, named PRIME. We first utilize a multi-element encoding module to extract patient condition snapshots from both modalities. Then, to construct multiple aligned cross-modal positive sample pairs that span the entire treatment process from irregular data, we employ patient condition alignment modules that integrate time-aware and feature-aware components to transfer snapshots to the aligned timestamps. Next, to preserve both shared and unique information of each modality, our decoupled representation learning strategy first uses a constraint matrix to separate shared information. We then employ contrastive-based cross-modal learning and reconstruction-based intra-modal learning to model shared and complete information, respectively. Extensive experiments on two real-world tasks demonstrate the superiority of PRIME over the state-of-the-art models, especially with limited labels.},
  archive      = {J_TKDD},
  author       = {Bohao Li and Bowen Du and Junchen Ye},
  doi          = {10.1145/3744251},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-39},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {PRIME: Pretraining for patient condition representation with irregular multimodal electronic health records},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards sequence utility maximization under utility occupancy measure. <em>TKDD</em>, <em>19</em>(7), 1-27. (<a href='https://doi.org/10.1145/3744344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discovery of utility-driven patterns is a valuable and difficult research topic. It can extract significant and interesting information from specific and varied databases, increasing the value of the services provided. In practice, the utility measure is often used to reflect the importance, profit, or risk of an object or pattern. In the database, while utility is a flexible criterion for patterns, it is also a somewhat limited criterion due to the overlook of utility sharing. This leads to the derived patterns only exploring partial and local knowledge in the database. Utility occupancy considers the problem of mining with high utility but low occupancy. However, existing studies are focused on itemsets that cannot reveal the temporal relationship of object occurrences. Therefore, this article first defines the concept of utility occupancy of sequence data and raises the problem of High-Utility Occupancy Sequential Pattern Mining (HUOSPM). Three dimensions, including frequency, utility, and occupancy, are comprehensively evaluated in HUOSPM. An algorithm called Sequence Utility Maximization with Utility occupancy measure (SUMU) is proposed. Furthermore, two data structures for storing pattern-related information, including Utility-Occupancy-List-Chain (UOL-Chain) and Utility-Occupancy-Table (UO-Table), are designed, and six upper bounds are proposed to improve efficiency. Extensive experiments are conducted to evaluate the efficiency and effectiveness of the novel algorithm. A specific case study is provided, and the effects of different upper bounds and pruning strategies are analyzed. The comprehensive results suggest that the HUOSPM task is useful and efficient.},
  archive      = {J_TKDD},
  author       = {Gengsen Huang and Wensheng Gan and Philip S. Yu},
  doi          = {10.1145/3744344},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Towards sequence utility maximization under utility occupancy measure},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical spatial decompositions under local differential privacy. <em>TKDD</em>, <em>19</em>(7), 1-37. (<a href='https://doi.org/10.1145/3744569'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The popularity of smartphones, GPS-enabled devices, social networks, and connected vehicles all contribute to the increasing volume of spatial data. Spatial decompositions assist in handling big spatial data, and they have been commonly used in the Differential Privacy (DP) literature for range query answering, spatial indexing, count-of-counts histograms, data summarization, and visualization. However, their applications under the emerging Local DP (LDP) notion are scarce. In this article, we study the problem of building hierarchical spatial decompositions under LDP, focusing on two methods: quadtrees and kd-trees. We develop two solutions for quadtrees: a baseline solution that is inspired by the centralized DP literature, and a proposed solution that utilizes a single data collection step from users, propagates density estimates to remaining nodes, and performs structural corrections to the quadtree. Since kd-trees rely on node medians which are data-dependent, we observe that it is not feasible to build kd-trees using a single data collection step. We therefore propose an iterative solution that constructs kd-trees in top-down fashion by utilizing a novel algorithm for estimating node medians at each tree depth. We experimentally evaluate our quadtree and kd-tree algorithms using four real-world spatial datasets, multiple utility metrics, varying privacy budgets, and tree parameters. Results demonstrate that our algorithms enable the building of accurate spatial decompositions that provide high utility in practice. Notably, our quadtrees and kd-trees achieve substantially lower errors in answering spatial density queries (up to 10-fold improvement) when compared with a state-of-the-art method.},
  archive      = {J_TKDD},
  author       = {Ece Alptekin and Berkay Kemal Balioglu and M. Emre Gursoy},
  doi          = {10.1145/3744569},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-37},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Hierarchical spatial decompositions under local differential privacy},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding the robustness of deep recommendation under adversarial attacks. <em>TKDD</em>, <em>19</em>(7), 1-46. (<a href='https://doi.org/10.1145/3744570'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been shown that deep recommendation models are susceptible to adversarial attacks, with this vulnerability potentially leading to significant economic losses in the e-commerce field. However, the robustness of deep recommendation models in response to adversarial attacks has not been systematically investigated. In this article, therefore, we comprehensively evaluate the adversarial robustness of various representative deep models in different settings, aiming to analyze their performance impact under adversarial attacks and compare it with traditional collaborative filtering models. Notably, we examine poisoning attacks under different proportions of fake users and various popularity conditions to understand why certain deep recommendation models perform exceptionally or sub-optimally. On this basis, we further proposed practical robustness improvement strategy for the problems found in the evaluation and fully verified it through rigorous experiments. Key findings include: (1) the sparser the training dataset, the weaker the robustness of a recommendation model’s performance under adversarial attacks; (2) deep recommendation models exhibit greater robustness in recommending popular items under adversarial attacks, while they are more vulnerable when attacked with non-popular items; (3) the robustness of deep recommendation models is not consistently weaker than that of traditional collaborative filtering models across all attack settings. These findings highlight the security concerns in deep recommendation systems and contribute to developing more reliable models.},
  archive      = {J_TKDD},
  author       = {Fulan Qian and Wenbin Chen and Hai Chen and Yan Cui and Shu Zhao and Yanping Zhang},
  doi          = {10.1145/3744570},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-46},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Understanding the robustness of deep recommendation under adversarial attacks},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interactive fusion label enhancement for multi-label learning. <em>TKDD</em>, <em>19</em>(7), 1-23. (<a href='https://doi.org/10.1145/3744571'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Label Learning (MLL) involves the task of assigning a set of relevant labels to a given instance. Recently, Label Enhancement (LE) has gained significant attention in various MLL tasks, as it allows for effective mining the implicit relative importance information of different labels. However, in existing LE-based MLL methods, the LE process is decoupled from the MLL process. Consequently, the label distribution recovered by the LE process may not be suitable for training the predictive model, thus affecting the overall learning system. In this study, we propose a novel approach named interactive Fusion Label Enhancement for Multi-Label Learning ( Flem ) that seamlessly integrates the LE process with the MLL process. Specifically, we introduce a matching and interaction mechanism comprising a novel interaction label enhancement loss and a contrastive alignment approach to prevent object mismatch. Furthermore, we present a unified label distribution loss that establishes the relationship between the recovered label distribution and the training of the predictive model. By leveraging these losses, the label distributions obtained from the LE process can be efficiently utilized for training the predictive model. Experimental results on multiple benchmark datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_TKDD},
  author       = {Xingyu Zhao and Yuexuan An and Ning Xu and Lei Qi and Xin Geng},
  doi          = {10.1145/3744571},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Interactive fusion label enhancement for multi-label learning},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Framework for variable-lag motif following relation inference in time series using matrix profile analysis. <em>TKDD</em>, <em>19</em>(7), 1-24. (<a href='https://doi.org/10.1145/3744652'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowing who follows whom and what patterns they are following are crucial steps to understand collective behaviors (e.g., a group of human, a school of fish, or a stock market). Time series is one of the resources that can be used to get insight regarding following relations. However, the concept of following patterns or motifs and the solution to find them in time series are not obvious. In this work, we formalize a concept of following motifs between two time series and present a framework to infer following patterns between two time series. The framework utilizes one of the efficient and scalable methods to retrieve motifs from time series called the Matrix Profile Inference Method. We compare our proposed framework with several baselines. The framework performs better than baselines in the simulation datasets. In the dataset of sound recording, the framework is able to retrieve the following motifs within a pair of time series in which two singers sing following each other. In the cryptocurrency dataset, the framework is capable of capturing the following motifs within a pair of time series from two digital currencies, which implies that the values of one currency follow the values of another currency patterns. Our framework can be utilized in any field of time series to get insight regarding following patterns between time series. The code and datasets can be found at https://github.com/hughnaaek/Following-Motif-Relation .},
  archive      = {J_TKDD},
  author       = {Naaek Chinpattanakarn and Chainarong Amornbunchornvej},
  doi          = {10.1145/3744652},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Framework for variable-lag motif following relation inference in time series using matrix profile analysis},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge graph fine-grained modeling network with contrastive learning for recommendation. <em>TKDD</em>, <em>19</em>(7), 1-18. (<a href='https://doi.org/10.1145/3744926'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph (KG) is often introduced into recommendation systems because of its large amount of edge information. The method based on graph neural networks (GNNs) has gradually become the mainstream of KG-aware recommendation. However, traditional KG-aware recommendation models based on GNNs fail to utilize the dependencies of items and item attributes to model user preferences at a fine-grained level, which will result in a lack of interpretability in the model’s recommendations to users. In addition, traditional KG-aware recommendation models based on GNNs fail to mine supervision signals from the perspective of user preferences and item attributes, which will result in a lack of effective supervision signals in the model. In this study, we utilize a combination of items and attributes behind the items to model user preferences at a fine-grained level, so as to achieve independence between different user preferences. Furthermore, we utilize the KG and the user–item interaction graph (UIIG) to construct the user-specific preference similarity view and the item-specific attribute correlation views, respectively, and then apply the contrastive learning framework to effectively mine the association signals between users and between items. Based on this, we propose a novel model named Knowledge Graph Fine-grained Modeling Network with Contrastive Learning (KGFM-CL). Extensive experiments conducted on two real-world datasets demonstrate that KGFM-CL significantly outperforms state-of-the-art baseline models.},
  archive      = {J_TKDD},
  author       = {Xiya Bu and Yu Liu},
  doi          = {10.1145/3744926},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-18},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Knowledge graph fine-grained modeling network with contrastive learning for recommendation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Raker: A relation-aware knowledge reasoning model for inductive relation prediction. <em>TKDD</em>, <em>19</em>(7), 1-20. (<a href='https://doi.org/10.1145/3745029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inductive relation prediction, an important task for knowledge graph completion, is to predict the relations between entities that are unseen at the training stage. The latest methods use Pre-Trained Language Models (PLMs) to encode the paths between the head entity and tail entity and achieve state-of-the-art prediction performance. However, these methods cannot handle no-path scenarios well and lack the capability to learn comprehensive relation representations for distinguishing different relations. To tackle this issue, we propose a novel R elation- a ware k nowledg e r easoning model entitled Raker, which introduces an adaptive reasoning information extraction method to identify relation-aware reasoning neighbors of entities in the target triple to handle no-path scenarios and enables the PLM to better distinguish different relations via the relation-specific soft prompting. Raker is evaluated on three public datasets and achieves SOTA performance in inductive relation prediction when compared with the baseline methods. Notably, the absolute improvement of Raker is even more than 5% on the FB15k-237 dataset in the inductive setting. Moreover, Raker also demonstrates the superiority in transductive, few-shot, and unseen relation settings. The code of Raker is available at https://github.com/ADMIS-TONGJI/Raker .},
  archive      = {J_TKDD},
  author       = {Jiaqi Wang and Wengen Li and Yulou Shu and Jihong Guan and Yichao Zhang and Shuigeng Zhou},
  doi          = {10.1145/3745029},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Raker: A relation-aware knowledge reasoning model for inductive relation prediction},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards recommendation on good quality data science solutions. <em>TKDD</em>, <em>19</em>(7), 1-19. (<a href='https://doi.org/10.1145/3746235'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data science aims to solve real-world problems with the knowledge derived from data. Successfully tackling a data science problem requires practitioners to choose an appropriate solution, which potentially comprises various components such as pre-processing techniques, learning algorithms, hyper-parameters, and so on. Therefore, a problem-driven recommendation for the promising solution is invaluable, as it facilitates efficient and convenient problem-solving. However, existing solution recommendation approaches confront notable challenges when dealing with limited and sparse prior experience in practical applications. Learning from such prior easily leads to overfitting and poor generalization in solution recommendations. To address this issue, we propose a novel solution recommendation method that can predict a good-quality data science solution, including the pre-processing, the learning algorithm, and hyper-parameters, for a given problem. The foundation of our method is a carefully designed ranking model that exploits a weight-sharing structure and a newly proposed loss. The ranking model focuses on incorporating relative ranking information into the predicted performance score of each solution. With these techniques, our method can recommend the solution with the highest score and effectively mitigate the limitations of using sparse prior experience. Our experiments demonstrate the superiority of our method in predicting solutions with higher accuracy and rank, even trained on highly sparse historical performance records. It also reduces recommendation time significantly compared to the baselines, offering remarkable efficiency and convenience for practitioners.},
  archive      = {J_TKDD},
  author       = {Jian Chen and Yile Chen and Zeyi Wen and Yawen Chen and Jin Huang},
  doi          = {10.1145/3746235},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-19},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Towards recommendation on good quality data science solutions},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weakly supervised open-domain aspect-based sentiment analysis. <em>TKDD</em>, <em>19</em>(7), 1-29. (<a href='https://doi.org/10.1145/3747849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-Based Sentiment Analysis (ABSA) comprises several subtasks: aspect term extraction (ATE), opinion term extraction (OTE), aspect term sentiment extraction (ATSE), aspect-opinion pair extraction (AOPE), and aspect sentiment triplet extraction (ASTE). Existing unified frameworks for ABSA rely heavily on large-scale annotated data, limiting scalability across domains. We propose UAOS, a double-layer unified span extraction framework that performs all five ABSA subtasks under weak supervision. Our approach first extracts aspect-opinion pairs using universal dependency-based rules from unannotated corpora. Sentiment labels for these pairs are generated via a novel zero-shot, domain-agnostic prompt-based method. The resulting weak labels train a unified span extraction architecture equipped with canonical correlation analysis for early stopping and a self-training mechanism to mitigate noise and bias in supervision. Extensive experiments on four ABSA benchmarks demonstrate that UAOS achieves competitive or superior performance compared to fully supervised baselines. It improves upon the state-of-the-art ODAO by +1.54 F1 for ATE, +0.56 for OTE, and +0.82 for AOPE. In ATSE and ASTE, where no weakly supervised baselines exist, UAOS outperforms several supervised models, setting new benchmarks. To assess domain generalizability, we evaluate UAOS on a psychology/education-domain dataset of student reflections spanning four instructional conditions. Without in-domain fine-tuning, it achieves macro F1 scores of 71.05 (ATE), 74.39 (OTE), 68.24 (AOPE), and 60.56 (ASTE). These results highlight the model’s ability to generalize to out-of-distribution, non-commercial text, underscoring its scalability for low-resource ABSA applications.},
  archive      = {J_TKDD},
  author       = {Mohna Chakraborty and Adithya Kulkarni and Qi Li},
  doi          = {10.1145/3747849},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-29},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Weakly supervised open-domain aspect-based sentiment analysis},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-temporal data mining for ocean science: Data, methodologies and opportunities. <em>TKDD</em>, <em>19</em>(7), 1-47. (<a href='https://doi.org/10.1145/3748259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid amassing of spatial-temporal (ST) ocean data, many spatial-temporal data mining (STDM) studies have been conducted to address various oceanic issues, including climate forecasting and disaster warning. Compared with typical ST data (e.g., traffic data), ST ocean data presents some unique characteristics, e.g., diverse regionality and high sparsity. These characteristics make it difficult to design and train STDM models on ST ocean data. To the best of our knowledge, a comprehensive survey of existing studies remains missing in the literature, which hinders not only computer scientists from identifying the research issues in ocean data mining but also ocean scientists to apply advanced STDM techniques. In this article, we provide a comprehensive survey of existing STDM studies for ocean science. Concretely, we first review the widely used ST ocean datasets and highlight their unique characteristics. Then, typical ST ocean data quality enhancement techniques are discussed. Next, we classify existing STDM studies for ocean science into four types of tasks, i.e., prediction, event detection, pattern mining, and anomaly detection, and elaborate the techniques for these tasks. Finally, promising research opportunities are discussed. This survey can help scientists from both computer science and ocean science better understand the fundamental concepts, key techniques, and open challenges of STDM for ocean science.},
  archive      = {J_TKDD},
  author       = {Hanchen Yang and Jiannong Cao and Wengen Li and Shuyu Wang and Hui Li and Jihong Guan and Shuigeng Zhou},
  doi          = {10.1145/3748259},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {7},
  pages        = {1-47},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Spatial-temporal data mining for ocean science: Data, methodologies and opportunities},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="tmis">TMIS - 9</h2>
<ul>
<li><details>
<summary>
(2025). Zero-shot construction of chinese medical knowledge graph with GPT-3.5-turbo and GPT-4. <em>TMIS</em>, <em>16</em>(2), 1-17. (<a href='https://doi.org/10.1145/3657305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs have revolutionized the organization and retrieval of real-world knowledge, prompting interest in automatic natural language processing approaches for extracting medical knowledge from texts. However, the availability of high-quality Chinese medical knowledge remains limited, posing challenges for constructing Chinese medical knowledge graphs. As large language models like ChatGPT show promise in zero-shot learning for many natural language processing downstream tasks, their potential on constructing Chinese medical knowledge graphs remains uncertain. In this study, we create a Chinese medical knowledge graph by manually annotating textual data and using ChatGPT to automatically generate the graph. We refine the results using filtering and mapping rules to align with our schema. The manually generated graph serves as the ground truth for evaluation, and we explore different methods to enhance its accuracy through knowledge graph completion techniques. As a result, we emphasize the potential of employing ChatGPT for automated knowledge graph construction within the Chinese medical domain. While ChatGPT successfully identifies a larger number of entities, further enhancements are required to improve its performance in extracting more qualified relations.},
  archive      = {J_TMIS},
  author       = {Ling-I Wu and Yuxin Su and Guoqiang Li},
  doi          = {10.1145/3657305},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {3},
  number       = {2},
  pages        = {1-17},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Zero-shot construction of chinese medical knowledge graph with GPT-3.5-turbo and GPT-4},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ShennongMGS: An LLM-based chinese medication guidance system. <em>TMIS</em>, <em>16</em>(2), 1-14. (<a href='https://doi.org/10.1145/3658451'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapidly evolving field of Large Language Models (LLMs) holds immense promise for healthcare, particularly in medication guidance and adverse drug reaction prediction. Despite their potential, existing LLMs face challenges in dealing with complex polypharmacy scenarios and often grapple with data lag issues. To address these limitations, we introduce an LLM-based Chinese medication guidance system, called ShennongMGS, specifically tailored for robust medication guidance and adverse drug reaction predictions. Our system transforms multi-source heterogeneous medication information into a knowledge graph and employs a two-stage training strategy to construct a specialized LLM (ShennongGPT). This method enables the simulation of professional pharmacists’ decision-making processes and incorporates the capability for knowledge self-updating, thereby significantly enhancing drug safety and the overall quality of medical services. Rigorously evaluated by medical professionals and artificial intelligence experts, our method demonstrates superiority, outperforming existing general and specialized LLMs in performance.},
  archive      = {J_TMIS},
  author       = {Yutao Dou and Yuwei Huang and Xiongjun Zhao and Haitao Zou and Jiandong Shang and Ying Lu and Xiaolin Yang and Jian Xiao and Shaoliang Peng},
  doi          = {10.1145/3658451},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {3},
  number       = {2},
  pages        = {1-14},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {ShennongMGS: An LLM-based chinese medication guidance system},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Language models for online depression detection: A review and benchmark analysis on remote interviews. <em>TMIS</em>, <em>16</em>(2), 1-35. (<a href='https://doi.org/10.1145/3673906'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of machine learning (ML) to detect depression in online settings has emerged as an important health and wellness use case. In particular, the use of deep learning methods for depression detection from textual content posted on social media has garnered considerable attention. Conversely, there has been relatively limited evaluation of depression detection in clinical environments involving text generated from remote interviews. In this research, we review state-of-the-art feature-based ML, deep learning, and large language models for depression detection. We use a multidimensional analysis framework to benchmark various language models on a novel testbed comprising speech-to-text transcriptions of remote interviews. Our framework considers the impact of different transcription types and interview segments on depression detection performance. Finally, we summarize the key trends and takeaways from the review and benchmark evaluation and provide suggestions to guide the design of future detection methods.},
  archive      = {J_TMIS},
  author       = {Ruiyang Qin and Kai Yang and Ahmed Abbasi and David Dobolyi and Salman Seyedi and Emily Griner and Hyeokhyen Kwon and Robert Cotes and Zifan Jiang and Gari Clifford and Ryan A. Cook},
  doi          = {10.1145/3673906},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {3},
  number       = {2},
  pages        = {1-35},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Language models for online depression detection: A review and benchmark analysis on remote interviews},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differentially private low-rank adaptation of large language model using federated learning. <em>TMIS</em>, <em>16</em>(2), 1-24. (<a href='https://doi.org/10.1145/3682068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The surge in interest and application of large language models (LLMs) has sparked a drive to fine-tune these models to suit specific applications, such as finance and medical science. However, concerns regarding data privacy have emerged, especially when multiple stakeholders aim to collaboratively enhance LLMs using sensitive data. In this scenario, federated learning becomes a natural choice, allowing decentralized fine-tuning without exposing raw data to central servers. Motivated by this, we investigate how data privacy can be ensured in LLM fine-tuning through practical federated learning approaches, enabling secure contributions from multiple parties to enhance LLMs. Yet, challenges arise: (1) despite avoiding raw data exposure, there is a risk of inferring sensitive information from model outputs, and (2) federated learning for LLMs incurs notable communication overhead. To address these challenges, this article introduces DP-LoRA, a novel federated learning algorithm tailored for LLMs. DP-LoRA preserves data privacy by employing a Gaussian mechanism that adds noise in weight updates, maintaining individual data privacy while facilitating collaborative model training. Moreover, DP-LoRA optimizes communication efficiency via low-rank adaptation, minimizing the transmission of updated weights during distributed training. The experimental results across medical, financial, and general datasets using various LLMs demonstrate that DP-LoRA effectively ensures strict privacy constraints while minimizing communication overhead.},
  archive      = {J_TMIS},
  author       = {Xiao-Yang Liu and Rongyi Zhu and Daochen Zha and Jiechao Gao and Shan Zhong and Matt White and Meikang Qiu},
  doi          = {10.1145/3682068},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {3},
  number       = {2},
  pages        = {1-24},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Differentially private low-rank adaptation of large language model using federated learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MOSS-MED: A family of multimodal models serving medical image analysis. <em>TMIS</em>, <em>16</em>(2), 1-14. (<a href='https://doi.org/10.1145/3688005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remarkable advancements in large language models (LLMs) and large-scale visual encoders have laid a solid foundation for enhancing the capabilities of artificial intelligence (AI) in various application scenarios. In this study, we introduce MOSS-MED, a suite of models designed for biomedical vision-language understandings. MOSS-MED includes two models currently: MOSS-MED-2.5B and MOSS-MED-LLaMA, with different scale of their underlying LLMs. We employ a two-stage training pipeline that involves visual-text alignment and visual-involved instruction fine-tuning from both general domains and the medical domain. We evaluate the performance of MOSS-MED family on medical visual question answering (VQA) benchmarks. The results and cases demonstrate the impressive proficiency in medical expertise that MOSS-MED embodies.},
  archive      = {J_TMIS},
  author       = {Junqi Dai and Qin Zhu and Jun Zhan and Bo Wang and Xipeng Qiu},
  doi          = {10.1145/3688005},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {3},
  number       = {2},
  pages        = {1-14},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {MOSS-MED: A family of multimodal models serving medical image analysis},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLMs and their applications in medical artificial intelligence. <em>TMIS</em>, <em>16</em>(2), 1-7. (<a href='https://doi.org/10.1145/3711837'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical artificial intelligence (AI) is a cross-disciplinary field focused on developing advanced computing and AI technologies to benefit medicine and healthcare. Globally, medical AI has tremendous potential to support the United Nations’ sustainable development goals pertaining to health and well-being. In particular, large language models (LLMs) afford opportunities for positively disrupting medical AI-related research and practice. We present a research framework for LLMs in medical AI. Our framework considers the interplay between health and well-being goals, disease lifecycle stages, and the important emerging role of LLMs in medical AI processes related to various lifecycle stages. As part of our framework, we describe the LLM multiplex—important multimodal, multi-model, multicultural, and multi-responsibility considerations for LLMs in medical AI. We discuss how the five articles in the special issue relate to this framework and are helping us learn about the opportunities and challenges for LLMs in medical AI.},
  archive      = {J_TMIS},
  author       = {Wenji Mao and Xipeng Qiu and Ahmed Abbasi},
  doi          = {10.1145/3711837},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {3},
  number       = {2},
  pages        = {1-7},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {LLMs and their applications in medical artificial intelligence},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). COTR: Efficient job task recognition for occupational information systems with class-incremental learning. <em>TMIS</em>, <em>16</em>(2), 1-30. (<a href='https://doi.org/10.1145/3712306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Occupation-specific job tasks (OSTs) refer to the duties, responsibilities, and activities associated with a particular occupation, which define the core functions and performance expectations for those engaged in that profession. Efficient recognition and extraction of OSTs from large-scale job description data are essential for establishing a continually updated occupational information system (OIS), such as O*NET, which serves as critical tools for advancing research in work and labor markets. However, this task presents substantial challenges due to its heavy reliance on domain experts for the labor-intensive annotation of job postings, rendering the process time-consuming and difficult to scale for large-scale implementation. To this end, in this article, we present COTR , a novel data-driven framework designed for the efficient recognition of OSTs from job postings, capable of continually identifying new tasks through class-incremental learning. Specifically, we first employ large language models (LLMs) and prompt learning to develop a three-phase process–“expansion, translation, and generation”–that addresses the critical challenge of the absence of predefined OSTs in non-English labor market data, leveraging O*NET as a foundational reference. Subsequently, we introduce a BERT-based model for OST recognition, incorporating a uniquely designed pair-wise loss function that distills valuable insights from ChatGPT or other LLMs, thereby substantially enhancing recognition performance. In addition, to achieve cost-effective training data annotation, we develop an LLM-based coarse-to-fine candidate OSTs generation algorithm, integrating contrastive active learning to optimize the annotation process through human-machine collaboration. Notably, we design a supervised fine-tuning strategy with a novel encoding technique to optimize LLMs, improving the recall rate of the generated candidate OSTs and achieving up to a 343-fold increase in annotation efficiency compared to traditional manual expert annotation in our experiments. Afterward, we propose an efficient class-incremental learning method that incorporates an out-of-distribution (OOD) detection module for identifying potential novel OSTs and a fine-tuning module to extend the model’s recognition capabilities to include newly discovered tasks. Finally, we construct two real-world datasets using job posting data collected from the labor markets of China and the United States, respectively. Extensive experiments on the real-world datasets, along with two publicly available datasets, have demonstrated the effectiveness of the proposed COTR. Furthermore, several case studies showcase the significant benefits of COTR for various downstream applications in labor market analysis, including analyzing the evolving demand for OSTs, assessing the value of OSTs, and recognizing the relationships between OSTs and associated skills.},
  archive      = {J_TMIS},
  author       = {Chuan Qin and Chuyu Fang and Kaichun Yao and Xi Chen and Fuzhen Zhuang and Hengshu Zhu},
  doi          = {10.1145/3712306},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {3},
  number       = {2},
  pages        = {1-30},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {COTR: Efficient job task recognition for occupational information systems with class-incremental learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncovering IT career path patterns with job embedding-based sequence clustering. <em>TMIS</em>, <em>16</em>(2), 1-32. (<a href='https://doi.org/10.1145/3712705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting typical career paths from large-scale and unstructured talent profiles has recently attracted increasing research attention. However, various challenges arise in effectively analyzing self-reported career records. Inspired by recent advancements in neural networks and embedding models, we develop a novel career path clustering approach and apply it to uncover information technology (IT) career path patterns. Specifically, we construct employment profiles of over 60,000 IT professionals, and form their career path sequences by chaining the job records in each profile. Then we simultaneously learn cluster-wise job embeddings and construct career path clusters. The resultant cluster-wise likelihoods of career paths can quantify their soft bonding with different clusters, and the job embeddings can reveal connections among job titles within each cluster. With both real and simulated data, we conduct extensive experiments with our framework to establish the modeling performance and great improvement over the traditional optimal matching analysis methods. The empirical results from analyzing real data on career paths show that our approach can discover distinct IT career path patterns and reveal valuable insights.},
  archive      = {J_TMIS},
  author       = {Hao Zhong and Chuanren Liu and Chaojiang Wu},
  doi          = {10.1145/3712705},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {3},
  number       = {2},
  pages        = {1-32},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Uncovering IT career path patterns with job embedding-based sequence clustering},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint ability assessment for talent recruitment: A neural cognitive diagnosis approach. <em>TMIS</em>, <em>16</em>(2), 1-25. (<a href='https://doi.org/10.1145/3714414'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ability assessment is a critical task in talent recruitment that aims at identifying the most suitable job candidates by evaluating the alignment of their skills with job requirements. Indeed, traditional ability assessment involves multiple staffing processes with various forms of evaluation methods, such as written tests and face-to-face interviews, which usually result in fragmented, noisy, and inconsistent conclusions. Therefore, a long-standing challenge in talent recruitment is how to comprehensively evaluate candidates by integrating multi-source heterogeneous assessment results. To this end, in this article, we propose a holistic framework, JCD-TR ( J oint C ognitive D iagnosis for T alent R ecruitment), for enhancing the performance of ability assessment in talent recruitment by jointly modeling the multi-source heterogeneous assessment results. Specifically, we first construct a skill graph based on the co-occurrence relations of skills in multi-source recruitment data. Along this line, we can learn the skill representations that maintain both the semantic and structural information with graph embedding. Then, we design a multi-source candidate ability profiling module with the guidance of item response theory in psychometrics and the neural topic model. As a result, the candidates’ ability profiles can be explored from their resumes, written tests, and interview assessment data, respectively. Furthermore, we propose a joint cognitive diagnosis module by integrating those multi-view ability profiles and skill representations to assess the candidates’ skill proficiency state. Extensive experiments on a real-world dataset demonstrate the effectiveness of our JCD-TR.},
  archive      = {J_TMIS},
  author       = {Haiping Ma and Manwei Li and Chuan Qin and Dazhong Shen and Hengshu Zhu and Xingyi Zhang and Hui Xiong},
  doi          = {10.1145/3714414},
  journal      = {ACM Transactions on Management Information Systems},
  month        = {3},
  number       = {2},
  pages        = {1-25},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Joint ability assessment for talent recruitment: A neural cognitive diagnosis approach},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="tocs">TOCS - 3</h2>
<ul>
<li><details>
<summary>
(2025). Validating JIT compilers via compilation space exploration. <em>TOCS</em>, <em>43</em>(3), 1-37. (<a href='https://doi.org/10.1145/3715102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the concept of compilation space as a new pivot for the comprehensive validation of just-in-time (JIT) compilers in modern language virtual machines (LVMs). The compilation space of a program encompasses a wide range of equivalent JIT-compilation choices, which can be cross-validated to ensure the correctness of the program’s JIT compilations. To thoroughly explore the compilation space in a lightweight and LVM-agnostic manner, we strategically mutate test programs with JIT-relevant but semantics-preserving code constructs, aiming to provoke diverse JIT compilation optimizations. We primarily implement this approach in Artemis , a tool for validating Java Virtual Machines (JVMs). Within three months, Artemis successfully discovered 85 bugs in three widely used production JVMs—HotSpot, OpenJ9, and the Android Runtime—where 53 were already confirmed or fixed and many of which were classified as critical. It is noteworthy that all reported bugs concern JIT compilers, highlighting the effectiveness and practicality of our technique. Building on the promising results with JVMs, we experimentally applied our technique to a state-of-the-art JavaScript Engine (JSE) fuzzer called Fuzzilli, aiming to augment it to find mis-compilation bugs without significantly sacrificing its ability to detect crashes. Our experiments demonstrate that our enhanced version of Fuzzilli namely Apollo could achieve comparable code coverage with a considerably smaller number of generated programs with a similar number of crashes. Additionally, Apollo successfully uncovered four mis-compilations in JavaScriptCore and SpiderMonkey within seven days. Following Artemis ’ and Apollo ’s success, we are expecting that the generality and practicability of our approach will make it broadly applicable for understanding and validating the JIT compilers of other LVMs.},
  archive      = {J_TOCS},
  author       = {Cong Li and Yanyan Jiang and Chang Xu and Zhendong Su},
  doi          = {10.1145/3715102},
  journal      = {ACM Transactions on Computer Systems},
  month        = {7},
  number       = {3},
  pages        = {1-37},
  shortjournal = {ACM Trans. Comput. Syst.},
  title        = {Validating JIT compilers via compilation space exploration},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Whole-system persistence made efficient with tree-structured checkpointing on microkernel. <em>TOCS</em>, <em>43</em>(3), 1-29. (<a href='https://doi.org/10.1145/3742425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whole-system persistence promises simplified application deployment and near-instantaneous recovery. This can be implemented using single-level store (SLS) through periodic checkpointing of ephemeral state to persistent devices. However, traditional SLSs suffer from two main issues on checkpointing efficiency and external synchrony, which are critical for low-latency services with persistence need. In this article, we note that the decentralized state of microkernel-based systems can be exploited to simplify and optimize state checkpointing. To this end, we propose TreeSLS, a whole-system persistent microkernel that simplifies the whole-system state maintenance to a capability tree and a failure-resilient checkpoint manager. TreeSLS further exploits the emerging non-volatile memory to minimize checkpointing pause time by eliminating the distinction between ephemeral and persistent devices. With efficient state maintenance, TreeSLS further proposes delayed external visibility to provide transparent external synchrony with little overhead. Evaluation on microbenchmarks and real-world applications (e.g., Memcached, Redis, and RocksDB) show that TreeSLS can complete a whole-system persistence in around 100 μs and even take a checkpoint every 1 ms with reasonable overhead to applications.},
  archive      = {J_TOCS},
  author       = {Mingkai Dong and Fangnuo Wu and Gequan Mo and Haibo Chen},
  doi          = {10.1145/3742425},
  journal      = {ACM Transactions on Computer Systems},
  month        = {7},
  number       = {3},
  pages        = {1-29},
  shortjournal = {ACM Trans. Comput. Syst.},
  title        = {Whole-system persistence made efficient with tree-structured checkpointing on microkernel},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Introduction to the special section on SOSP 2023. <em>TOCS</em>, <em>43</em>(3), 1-2. (<a href='https://doi.org/10.1145/3744676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TOCS},
  author       = {Jason Flinn and Margo Seltzer},
  doi          = {10.1145/3744676},
  journal      = {ACM Transactions on Computer Systems},
  month        = {7},
  number       = {3},
  pages        = {1-2},
  shortjournal = {ACM Trans. Comput. Syst.},
  title        = {Introduction to the special section on SOSP 2023},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="todaes">TODAES - 10</h2>
<ul>
<li><details>
<summary>
(2025). ILOSSS - Improved logic synthesis based on several stateful logic gates. <em>TODAES</em>, <em>30</em>(4), 1-23. (<a href='https://doi.org/10.1145/3731245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memristor stateful logic is an effective way to achieve the real sense of in-memory computing in memristor-based crossbar array (MCBA). At present, the synthesis tools fall short in conducting a thorough exploration of the optimization potential pertaining to cascading stateful logic gates within MCBA, and the optimization objectives are relatively simple. In this article, a suit of stateful logic synthesis kit, named ILOSSS, improved from the previous LOSSS tool is achieved. Such kit includes two kinds of stateful logic synthesis processes for latency (corresponding to the High Time-Efficiency Synthesis Process (HTESP)) and energy (corresponding to the Low-Energy Synthesis Process (LESP)) optimization, respectively. Both of the synthesis processes are achieved by improving an existing synthesis process of MAGIC (SIMPLER-MAGIC) to support multiple stateful logic gates and inserting a post-processing stage with a well-developed automated optimization algorithm to reduce the number of the gates of the netlist with a corresponding purpose. Comparing to the standard SIMPLER-MAGIC tool, the HTESP achieves arithmetic mean improvements of over 23% in performance, and over 34% in effective lifetime under the EPFL benchmark suit which is also better than the results reported by the state-of-the-art MAGIC synthesis process (X-MAGIC). Meanwhile, the energy-delay product (EDP) of LESP has decreased by an average of over 10% and 42% compared to SIMPLER-MAGIC and HTESP, respectively.},
  archive      = {J_TODAES},
  author       = {Nuo Xu and Yihong Hu and Chaochao Feng and Wei Tong and Kang Liu and Liang Fang},
  doi          = {10.1145/3731245},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {7},
  number       = {4},
  pages        = {1-23},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {ILOSSS - Improved logic synthesis based on several stateful logic gates},
  volume       = {30},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ChatDSE: A zero-shot microarchitecture design space explorer powered by GPT4.0. <em>TODAES</em>, <em>30</em>(4), 1-24. (<a href='https://doi.org/10.1145/3735640'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Design Space Exploration (DSE) aims at identifying Pareto optimal synthesis configurations. Previous works require microarchitecture samples with key labels, including power and clock cycles, to train their models. However, as the chip design space expands rapidly, the cost of sampling the design space has significantly increased, due to the growing number of samples and time-consuming Very Large Scale Integration (VLSI) implementation flow. Recent advancements in Large Language Models (LLMs) have demonstrated their remarkable power in zero-shot learning tasks, presenting an innovative strategy for accomplishing DSE. Hence, this article presents ChatDSE, a zero-shot framework for DSE that is powered by the advanced capabilities of the LLM GPT4.0. Firstly, this framework analyzes the nature of the target microarchitecture and generates a corresponding system context to provide the prior knowledge of the microarchitecture. Secondly, a proposed sampling algorithm, PriorDC, identifies the most representative samples with pseudo labels. One of these samples is chosen as a baseline, whose power and clock cycles labels are set as 1, and the remaining sample labels are obtained by chatting with GPT4.0. Finally, ChatDSE engages in a dialogue with GPT4.0 to estimate the power and clock cycles of designs within the space, ultimately identifying the Pareto optimal design set. In the DSE for the RISC-V Berkeley Out-of-Order Machine (BOOM), experimental results show that ChatDSE is capable of identifying optimal designs and accelerates the exploration process by 574 times when compared to the state-of-the-art DSE methodologies.},
  archive      = {J_TODAES},
  author       = {Mingxin Tang and Wei Chen and Lizhou Wu and Libo Huang and Kun Zeng},
  doi          = {10.1145/3735640},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {7},
  number       = {4},
  pages        = {1-24},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {ChatDSE: A zero-shot microarchitecture design space explorer powered by GPT4.0},
  volume       = {30},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ARIANNA: An automatic design flow for fabric customization and eFPGA redaction. <em>TODAES</em>, <em>30</em>(4), 1-23. (<a href='https://doi.org/10.1145/3737287'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the modern global Integrated Circuit (IC) supply chain, protecting intellectual property (IP) is a complex challenge, and balancing IP loss risk and added cost for theft countermeasures is hard to achieve. Using embedded configurable logic allows designers to completely hide the functionality of selected design portions from parties that do not have access to the configuration string (bitstream). However, the design space of redacted solutions is huge, with tradeoffs between the portions selected for redaction and the configuration of the configurable embedded logic. We propose ARIANNA, a complete flow that aids the designer in all the stages, from selecting the logic to be hidden to tailoring the bespoke fabrics for the configurable logic used to hide it. We present a security evaluation of the considered fabrics and introduce two heuristics for the novel bespoke fabric flow. We evaluate the heuristics against an exhaustive approach. We also evaluate the complete flow using a selection of benchmarks. Results show that using ARIANNA to customize the redaction fabrics yields up to 3.3× lower overheads and 4× higher eFPGA fabric utilization than a one-fits-all fabric as proposed in prior works.},
  archive      = {J_TODAES},
  author       = {Luca Collini and Jitendra Bhandari and Chiara Muscari Tomajoli and Abdul Moosa and Benjamin Tan and Xifan Tang and Pierre-Emanuel Gaillardon and Ramesh Karri and Christian Pilato},
  doi          = {10.1145/3737287},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {7},
  number       = {4},
  pages        = {1-23},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {ARIANNA: An automatic design flow for fabric customization and eFPGA redaction},
  volume       = {30},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HAPE: Hardware-aware LLM pruning for efficient on-device inference optimization. <em>TODAES</em>, <em>30</em>(4), 1-18. (<a href='https://doi.org/10.1145/3744244'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past few years, large language models (LLMs) have demonstrated remarkable performance and versatility across a variety of complex tasks. However, their deployment has been challenged by their substantial model size and computational requirements. Pruning is a effective approach to make the model parameters sparse, thereby acquire inference acceleration. While not everyone requires training or fine-tuning large models, the diverse range of applications necessitates the deployment of LLMs on different devices. Model pruning and compression have emerged as areas of deep research interest to address these challenges. In consideration of versatility and practicality, we have designed a hardware-aware pruning process for general-purpose hardware/edge devices to enable efficient deployment and inference of LLMs. Instead of considering sparse ratio alone, we are motivated to design a pruning framework that incorporates genuine inference speed-up sensitivity from each pruning structure. Moreover, our framework breaks the layer-by-layer pruning setting and fuse several layers into one pruning stage to allow cross-layer optimization. Apart from that, we hold pragmatism by conducting compilation optimization during pruning. This step is critical because most sparsity patterns barely show distinct speed acceleration with corresponding dataflow and memory optimization. Our process operates within a post-training framework, obviating the need for additional training and thereby reducing resource requirements, while ensuring diverse inference speed and accuracy requirements on hardware.},
  archive      = {J_TODAES},
  author       = {Wenqian Zhao and Lancheng Zou and Zixiao Wang and Xufeng Yao and Bei Yu},
  doi          = {10.1145/3744244},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {7},
  number       = {4},
  pages        = {1-18},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {HAPE: Hardware-aware LLM pruning for efficient on-device inference optimization},
  volume       = {30},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interactive visual performance space exploration of operational amplifiers with differentiable neural network surrogate models. <em>TODAES</em>, <em>30</em>(4), 1-33. (<a href='https://doi.org/10.1145/3744245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To this day, the design of analog integrated circuits is a predominantly manual task, heavily reliant on the knowledge and intuition of human experts. Many current automation approaches aim to be holistic solutions, attempting to take the human out of the loop. This work, in turn, does not intend to replace human designers with algorithms, but support their qualities in the established flow. Here, the performance space of analog ICs is modeled by PVT-aware neural networks and visualized with parallel coordinate plots. Such a responsive visualization gives insights into the relations of parameters through interactive exploration where any parameter can be the cause while all others show the immediate effect. Thus, complex decision-making problems based on the experience of seasoned designers, such as circuit sizing or topology selection, are transformed into intuitive perceptual problems. Through the responsiveness and immediacy of the implementation, designers are encouraged to explore the entire performance space instead of basing all decisions on previous designs, never leaving the beaten path. A data generation and training procedure for surrogate models is outlined. Models for three operational amplifiers in three different technologies illustrate the applicability and feasibility of the presented approach. Additionally, a web-based demo, including all source code, is available for review.},
  archive      = {J_TODAES},
  author       = {Yannick Uhlmann and Till Moldenhauer and Juergen Scheible},
  doi          = {10.1145/3744245},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {7},
  number       = {4},
  pages        = {1-33},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Interactive visual performance space exploration of operational amplifiers with differentiable neural network surrogate models},
  volume       = {30},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Securing network-on-chips against trojan-induced packet duplication attacks. <em>TODAES</em>, <em>30</em>(4), 1-28. (<a href='https://doi.org/10.1145/3744645'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The third-party Intellectual Property (IP) supply chain exposes System-on-Chip designs to malicious implants like Hardware Trojans (HTs). With extremely rare trigger conditions, some HTs can evade conventional and even machine learning-based validation methods. Current detection and mitigation approaches fall short, especially against HTs capable of creating detrimental effects on cache and Network-on-Chip (NoC) performance. In this article, we present a novel intermittent and robust HT called LOKI, which primarily operates within the Network Adapter (NA) but can simultaneously impact the performance of the NoC, the shared cache, and the cores. LOKI is implanted in a malicious IP’s NA and triggers packet duplication attacks, leading to increased latency and performance degradation across the system. This action has cascading effects on the system, including increased latency in the NoC, adversely impacting communication efficiency. The duplication also leads to increased cache misses and longer miss penalties, further degrading cache performance. Additionally, LOKI affects the Instruction-Per-Cycle (IPC) of the cores, thus influencing overall processing performance. Our evaluation demonstrates that LOKI causes a 3.53× increase in packet latency, a 15% increase in miss penalty, and a 10% decrease in overall IPC. To neutralize the effects of HT-induced packet duplication, we propose a ubiquitous mitigation framework called HULK. HULK is installed in the NA and monitors all messages going in and out of the NoC, allowing it to address anomalies occurring in the NA, routers, and links. Experimental evaluation shows that HULK can effectively mitigate LOKI’s impact, achieving baseline system-like performance with negligible hardware overhead. Unlike existing HT-specific mitigation proposals, HULK serves as a generic solution to neutralize all types of packet duplication attacks. To promote reproducibility and community adoption, we have open sourced the implementation at https://github.com/itsmanju/hulk .},
  archive      = {J_TODAES},
  author       = {Manju Rajan and Abhijit Das and John Jose},
  doi          = {10.1145/3744645},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {7},
  number       = {4},
  pages        = {1-28},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Securing network-on-chips against trojan-induced packet duplication attacks},
  volume       = {30},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Layout synthesis for quantum circuits considering toffoli gate decomposition. <em>TODAES</em>, <em>30</em>(4), 1-21. (<a href='https://doi.org/10.1145/3744646'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art studies on quantum layout synthesis have proposed various approaches based on the assumption that the input circuit is only composed of single-qubit and two-qubit gates. This assumption greatly simplifies the layout synthesis problem, and thus they only require ensuring that all controlled-NOT (CNOT) gates satisfy the hardware constraints imposed by a given coupling graph. However, during the design of quantum circuits, multi-controlled Toffoli (MCT) gates are usually used to better characterize the function of the circuits. Directly decomposing them into single and two-qubit gates with a fixed routine ignores the flexibility and optimization opportunity provided by various decomposition (i.e., logic synthesis) possibilities and thus suffers from sub-optimal results. This article proposes a co-optimization approach for quantum logic and layout synthesis. The MCT gates are first decomposed into Toffoli gates, and an efficient qubit mapping checking process is proposed to optimally solve the SWAP-free layout synthesis problem by automatically determining the decomposition result of each Toffoli gate. If a SWAP-free result cannot be found, the proposed algorithm flow is then used to obtain a solution that minimizes the total cost that simultaneously counts the cost caused by the different decomposition methods for Toffoli gates and the cost induced by SWAP gates. Compared with a state-of-the-art method, the proposed approach reduces the number of additional CNOT gates by 16% with around 25X runtime speedup for the cases with SWAP-free solutions, which cannot be obtained without the co-optimization approach.},
  archive      = {J_TODAES},
  author       = {Po-Wei Chen and Sheng-Tan Huang and Shao-Yun Fang},
  doi          = {10.1145/3744646},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {7},
  number       = {4},
  pages        = {1-21},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Layout synthesis for quantum circuits considering toffoli gate decomposition},
  volume       = {30},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FV-LIDAC: Formally verified library of input data aware approximate arithmetic circuits. <em>TODAES</em>, <em>30</em>(4), 1-23. (<a href='https://doi.org/10.1145/3744710'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximate circuits have become ubiquitous in error-resilient applications. These circuits provide large reductions in area, power, and delay at the cost of erroneous computations. The error-resilient applications produce acceptable output quality, even after the introduction of erroneous computations. However, we observed that the error resilience of an application varies widely with respect to the applied inputs. Since prior works have mostly focused on using samples from a uniform distribution while designing the approximate circuits, they are unable to exploit input aware properties to design optimal circuits. Hence, in this work, we bridge this gap and propose Formally Verified Library of Input Data Aware Approximate Circuits (FV-LIDAC). FV-LIDAC is the first formally verified library of input distribution aware approximate arithmetic circuits. We use three of the most widely occurring distributions, namely uniform, normal, and exponential distributions, to show that optimal design sets are heavily dependent on the input data. FV-LIDAC chooses the best designs among millions of functional approximated adder and multiplier circuits, depending upon the inputs. Since there are no existing input-aware approximate circuit libraries, we compared FV-LIDAC against state-of-the-art input-unaware EvoApproxLib, to further highlight the need for FV-LIDAC. Additionally, we perform case studies on real-world applications to further highlight the improvement over state-of-the-art. We aim to make the Pareto-optimal designs available as open source to stimulate further research.},
  archive      = {J_TODAES},
  author       = {Sallar Ahmadi-Pour and Sajjad Parvin and Chandan Kumar Jha and Rolf Drechsler},
  doi          = {10.1145/3744710},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {7},
  number       = {4},
  pages        = {1-23},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {FV-LIDAC: Formally verified library of input data aware approximate arithmetic circuits},
  volume       = {30},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A CPU+FPGA OpenCL heterogeneous computing platform for multi-kernel pipeline. <em>TODAES</em>, <em>30</em>(4), 1-23. (<a href='https://doi.org/10.1145/3744922'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decades, Field-Programmable Gate Arrays (FPGAs) have become a choice for heterogeneous computing due to their flexibility, energy efficiency, and processing speed. OpenCL is used in FPGA heterogeneous computing for its high-level abstraction and cross-platform compatibility. Previous works have introduced optimization techniques in OpenCL for FPGAs to leverage FPGA-specific advantages. However, the multi-kernel pipeline technique, which can raise throughput and resource utilization, has not performed well. This article presents a CPU+FPGA heterogeneous platform with a novel execution model to optimize multi-kernel pipeline. Firstly, we extend OpenCL by introducing new APIs and additional functions to represent the execution model. Secondly, a hardware-software co-scheduling scheme is employed to manage execution. Thirdly, we design a holistic development flow and toolkit to facilitate the deployment of algorithms on the platform or the integration of RTL IP cores to the OpenCL environment. We validate the platform using a Range Doppler algorithm. The proposed development flow and integrated toolchain enhance the efficiency of integrating traditional RTL IP cores into the OpenCL environment. Experimental results demonstrate that, with a comparable processing speed (averaging 95%) to traditional RTL implementations, the platform successfully establishes the multi-kernel pipelines. Leveraging the multi-kernel pipeline, the platform achieves a significant improvement in multi-frame processing speed compared to traditional OpenCL.},
  archive      = {J_TODAES},
  author       = {Yuefei Wang and Wendong Mao and Lang Feng and Jin Sha and Zhongfeng Wang},
  doi          = {10.1145/3744922},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {7},
  number       = {4},
  pages        = {1-23},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {A CPU+FPGA OpenCL heterogeneous computing platform for multi-kernel pipeline},
  volume       = {30},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Concurrent prediction of timing and wire length using a multi-task graph neural network. <em>TODAES</em>, <em>30</em>(4), 1-20. (<a href='https://doi.org/10.1145/3747181'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional supervised single-task learning models are used in timing-driven placement exploration to improve both effectiveness and efficiency by predicting wire length, wire delay, and cell delay separately. However, these metrics are interdependent, with the two delays being timing-based and wire length non-timing, which makes it difficult for single-task models to capture their complex relationships. Moreover, the limited existing multi-task learning methods can only predict either multiple timing or non-timing metrics. To address these limitations, this article introduces DLGNN, a novel multi-task graph learning model that simultaneously predicts these three metrics through an embedder-predictor architecture featuring two residual connections, a combination of both soft and hard parameter sharing, and a geometric loss strategy. Cross-design experimental results on the Nangate 45nm library demonstrate that DLGNN outperforms baseline models in terms of both predictive performance and time efficiency. Additionally, ablation studies emphasize the critical roles of the residual connections, the combination of soft and hard parameter sharing, and the geometric loss strategy in improving DLGNN’s predictive performance. The generalization experiment on the ASAP 7nm library further confirms DLGNN’s advantages for more advanced technology nodes.},
  archive      = {J_TODAES},
  author       = {Yan Xing and Hongtao Hu and Weijun Li and Shuting Cai and Xiaoming Xiong},
  doi          = {10.1145/3747181},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {7},
  number       = {4},
  pages        = {1-20},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Concurrent prediction of timing and wire length using a multi-task graph neural network},
  volume       = {30},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="tog">TOG - 132</h2>
<ul>
<li><details>
<summary>
(2025). Correct your balance heuristic: Optimizing balance-style multiple importance sampling weights. <em>TOG</em>, <em>44</em>(4), 1-14. (<a href='https://doi.org/10.1145/3730819'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple importance sampling (MIS) is a vital component of most rendering algorithms. MIS computes a weighted sum of samples from many different techniques to achieve generalization, that is, to handle a wide range of scene types and lighting effects. A key factor to the performance of MIS is the choice of weighting function. The go-to default - the balance heuristic - performs well in many cases, but prior work has shown that it can yield unsatisfactory results. A number of challenges cause this suboptimal performance, including low-variance techniques, sample correlation, and unknown sampling densities. Prior work has suggested improvements for some of these problems, but a general optimal solution has yet to be found. We propose a general and practical weight correction scheme: We optimize, on-the-fly, a set of correction factors that are multiplied into any baseline MIS heuristic (e.g., balance or power). We demonstrate that this approach yields consistently better equal-time performance on two rendering applications: bidirectional algorithms and resampled importance sampling for direct illumination.},
  archive      = {J_TOG},
  author       = {Qingqin Hua and Pascal Grittmann and Philipp Slusallek},
  doi          = {10.1145/3730819},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-14},
  shortjournal = {ACM Trans. Graph.},
  title        = {Correct your balance heuristic: Optimizing balance-style multiple importance sampling weights},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sobol' sequences with guaranteed-quality 2D projections. <em>TOG</em>, <em>44</em>(4), 1-16. (<a href='https://doi.org/10.1145/3730821'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-discrepancy sequences, and more particularly Sobol' sequences are gold standard for drawing highly uniform samples for quasi-Monte Carlo applications. They produce so-called ( t,s )-sequences, that is, sequences of s -dimensional samples whose uniformity is controlled by a non-negative integer quality factor t. The Monte Carlo integral estimator has a convergence rate that improves as t decreases. Sobol' construction in base 2 also provides extremely fast sampling point generation using efficient xor-based arithmetic. Computer graphics applications, such as rendering, often require high uniformity in consecutive 2D projections and in higher-dimensional projections at the same time. However, it can be shown that, in the classical Sobol' construction, only a single 2D sequence of points (up to scrambling), constructed using irreducible polynomials x and x + 1, achieves the ideal t = 0 property. Reusing this sequence in projections necessarily loses high dimensional uniformity. We prove the existence and construct many 2D Sobol' sequences having t = 1 using irreducible polynomials p and p 2 + p + 1. They can be readily combined to produce higher-dimensional low discrepancy sequences with a high-quality t = 1, guaranteed in consecutive pairs of dimensions. We provide the initialization table that can be directly used with any existing Sobol' implementation, along with the corresponding generator matrices, for an optimized 692-dimensional Sobol' construction. In addition to guaranteeing the (1, 2)-sequence property for all consecutive pairs, we ensure that t ≤ 4 for consecutive 4D projections up to 2 15 points.},
  archive      = {J_TOG},
  author       = {Nicolas Bonneel and David Coeurjolly and Jean-Claude Iehl and Victor Ostromoukhov},
  doi          = {10.1145/3730821},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-16},
  shortjournal = {ACM Trans. Graph.},
  title        = {Sobol' sequences with guaranteed-quality 2D projections},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving global motion estimation in sparse IMU-based motion capture with physics. <em>TOG</em>, <em>44</em>(4), 1-16. (<a href='https://doi.org/10.1145/3730822'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By learning human motion priors, motion capture can be achieved by 6 inertial measurement units (IMUs) in recent years with the development of deep learning techniques, even though the sensor inputs are sparse and noisy. However, human global motions are still challenging to be reconstructed by IMUs. This paper aims to solve this problem by involving physics. It proposes a physical optimization scheme based on multiple contacts to enable physically plausible translation estimation in the full 3D space where the z-directional motion is usually challenging for previous works. It also considers gravity in local pose estimation which well constrains human global orientations and refines local pose estimation in a joint estimation manner. Experiments demonstrate that our method achieves more accurate motion capture for both local poses and global motions. Furthermore, by deeply integrating physics, we can also estimate 3D contact, contact forces, joint torques, and interacting proxy surfaces. Code is available at https://xinyu-yi.github.io/GlobalPose/.},
  archive      = {J_TOG},
  author       = {Xinyu Yi and Shaohua Pan and Feng Xu},
  doi          = {10.1145/3730822},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-16},
  shortjournal = {ACM Trans. Graph.},
  title        = {Improving global motion estimation in sparse IMU-based motion capture with physics},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to assemble with alternative plans. <em>TOG</em>, <em>44</em>(4), 1-16. (<a href='https://doi.org/10.1145/3730824'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a reinforcement learning framework for constructing assemblies composed of rigid parts, which are commonly seen in many historical masonry buildings and bridges. Traditional construction methods for such structures often depend on dense scaffolding to stabilize their intermediate assembly steps, making the process both labor-intensive and time-consuming. This work utilizes multiple robots to collaboratively assemble structures, offering temporary support by holding parts in place without additional scaffolding. Precomputing the robotic assembly process to ensure structural stability involves a time-consuming offline process due to the combinatorial nature of its search space. However, the precomputed assembly plans may get disrupted during real-world execution due to unforeseen changes, such as setup modifications or delays in part delivery. Recomputing these plans using traditional offline methods results in significant project delays. Therefore, we propose a reinforcement learning-based approach in which a neural network is trained to efficiently generate alternative assembly plans for a given structure online, enabling adaptation to external changes. To enable effective and efficient training, we introduce three key innovations: a GPU-based stability simulator for parallelizing simulations, a novel curriculum-based training scheme to address sparse rewards during training, and a new graph neural network architecture for efficiently encoding assembly geometry. We validate our approach by training reinforcement learning agents on various assemblies and evaluating their performance on unseen assembly tasks. Furthermore, we demonstrate the effectiveness of our framework in planning multi-robot assembly processes, effectively handling disruptions in both simulation and physical environments.},
  archive      = {J_TOG},
  author       = {Ziqi Wang and Wenjun Liu and Jingwen Wang and Gabriel Vallat and Fan Shi and Stefana Parascho and Maryam Kamgarpour},
  doi          = {10.1145/3730824},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-16},
  shortjournal = {ACM Trans. Graph.},
  title        = {Learning to assemble with alternative plans},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Facial appearance capture at home with patch-level reflectance prior. <em>TOG</em>, <em>44</em>(4), 1-16. (<a href='https://doi.org/10.1145/3730825'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing facial appearance capture methods can reconstruct plausible facial reflectance from smartphone-recorded videos. However, the reconstruction quality is still far behind the ones based on studio recordings. This paper fills the gap by developing a novel daily-used solution with a co-located smartphone and flashlight video capture setting in a dim room. To enhance the quality, our key observation is to solve facial reflectance maps within the data distribution of studio-scanned ones. Specifically, we first learn a diffusion prior over the Light Stage scans and then steer it to produce the reflectance map that best matches the captured images. We propose to train the diffusion prior at the patch level to improve generalization ability and training stability, as current Light Stage datasets are in ultra-high resolution but limited in data size. Tailored to this prior, we propose a patch-level posterior sampling technique to sample seamless full-resolution reflectance maps from this patch-level diffusion model. Experiments demonstrate our method closes the quality gap between low-cost and studio recordings by a large margin, opening the door for everyday users to clone themselves to the digital world.},
  archive      = {J_TOG},
  author       = {Yuxuan Han and Junfeng Lyu and Kuan Sheng and Minghao Que and Qixuan Zhang and Lan Xu and Feng Xu},
  doi          = {10.1145/3730825},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-16},
  shortjournal = {ACM Trans. Graph.},
  title        = {Facial appearance capture at home with patch-level reflectance prior},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast subspace fluid simulation with a temporally-aware basis. <em>TOG</em>, <em>44</em>(4), 1-18. (<a href='https://doi.org/10.1145/3730826'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel reduced-order fluid simulation technique leveraging Dynamic Mode Decomposition (DMD) to achieve fast, memory-efficient, and user-controllable subspace simulation. We demonstrate that our approach combines the strengths of both spatial reduced order models (ROMs) as well as spectral decompositions. By optimizing for the operator that evolves a system state from one timestep to the next, rather than the system state itself, we gain both the compressive power of spatial ROMs as well as the intuitive physical dynamics of spectral methods. The latter property is of particular interest in graphics applications, where user control of fluid phenomena is of high demand. We demonstrate this in various applications including spatial and temporal modulation tools and fluid upscaling with added turbulence. We adapt DMD for graphics applications by reducing computational overhead, incorporating user-defined force inputs, and optimizing memory usage with randomized SVD. The integration of OptDMD and DMD with Control (DMDc) facilitates noise-robust reconstruction and real-time user interaction. We demonstrate the technique's robustness across diverse simulation scenarios, including artistic editing, time-reversal, and super-resolution. Through experimental validation on challenging scenarios, such as colliding vortex rings and boundary-interacting plumes, our method also exhibits superior performance and fidelity with significantly fewer basis functions compared to existing spatial ROMs. Leveraging the inherent linearity of the DMD formulation, we demonstrate a range of diverse applications. This work establishes another avenue for developing real-time, high-quality fluid simulations, enriching the space of fluid simulation techniques in interactive graphics and animation.},
  archive      = {J_TOG},
  author       = {Siyuan Chen and Yixin Chen and Jonathan Panuelos and Otman Benchekroun and Yue Chang and Eitan Grinspun and Zhecheng Wang},
  doi          = {10.1145/3730826},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-18},
  shortjournal = {ACM Trans. Graph.},
  title        = {Fast subspace fluid simulation with a temporally-aware basis},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fully-statistical wave scattering model for heterogeneous surfaces. <em>TOG</em>, <em>44</em>(4), 1-17. (<a href='https://doi.org/10.1145/3730828'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous surfaces exhibit spatially varying geometry and material, and therefore admit diverse appearances. Existing computer graphics works can only model heterogeneity using explicit structures or statistical parameters that describe a coarser level of detail. We extend the boundary by introducing a new model that describes the heterogeneous surfaces fully statistically at the microscopic level, with rich geometry and material details that are comparable to the wavelengths of light. We treat the heterogeneous surfaces as a mixture of stochastic vector processes. We adapt the well-known generalized Harvey-Shack theory to quantify the mean scattered intensity, i.e., the BRDF of these surfaces. We further explore the covariance statistic of the scattered field and derive its rank-1 decomposition. This leads to a practical algorithm that samples the speckles (fluctuating intensities) from the statistics, enriching the appearance without explicit definition of heterogeneous surfaces. The formulations are analytic, and we validate the quantities by comprehensive numerical simulations. Our heterogeneous surface model demonstrates various applications including corrosion (natural), particle deposition (man-made), and height-correlated mixture (artistic). Code for this paper is available at https://github.com/Rendering-at-ZJU/HeteroSurface.},
  archive      = {J_TOG},
  author       = {Zhengze Liu and Yuchi Huo and Yifan Peng and Rui Wang},
  doi          = {10.1145/3730828},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-17},
  shortjournal = {ACM Trans. Graph.},
  title        = {A fully-statistical wave scattering model for heterogeneous surfaces},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid near-wall model for kinetic simulation of turbulent boundary layer flows. <em>TOG</em>, <em>44</em>(4), 1-24. (<a href='https://doi.org/10.1145/3730829'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Turbulent boundary layer represents one of the most complex but interesting phenomena in fluid flows. While the generation and alteration of sheared vortices in various interacting scales near the boundary are visually appealing, it is difficult to correctly replicate such phenomena by simulation, especially at high Reynolds numbers. Practical methodologies typically incorporate empirical wall modeling to substantially curtail the computational expenses while retaining physical consistency. Nevertheless, these are predominantly applicable to steady-state flow solvers. While complex scenarios involving dynamic fluid-solid interaction and its application to create time-dependent flow phenomena invariably necessitate unsteady flow solvers, the underlying wall modeling techniques are imprecise, leading to a different formation of near-wall vortices, especially for the highly efficient lattice Boltzmann solver operating on Cartesian grids. In this paper, we propose a novel hybrid near-wall model for the lattice Boltzmann solver, which can handle turbulent boundary layer flows in a simple and efficient manner, inspired by measuring the degree of boundary layer separation. Our model comprises both macroscopic and mesoscopic algebraic models, which collaborate to let the low dissipation lattice Boltzmann solver naturally form the turbulent boundary layer appropriately. By leveraging the multi-resolution technique, accurate simulation outcomes can be obtained. Our model is parameterized to approximate different physical attributes of the solid surface that can potentially influence the boundary layer distribution, and comparable boundary layer flow behaviors can be simulated at various grid resolutions. Rigorous benchmark tests are carried out to validate our model at different grid resolutions by comparing with experimental data and visualizations. We showcase the applications of our new model in both facilitating computational design and generating visual animations, accompanied by specific examples and comparisons with actual experimental setups and photographic images. All demonstrations affirm the physical consistency of our solver even when simulated with a relatively coarse grid resolution.},
  archive      = {J_TOG},
  author       = {Mengyun Liu and Kai Bai and Xiaopei Liu},
  doi          = {10.1145/3730829},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-24},
  shortjournal = {ACM Trans. Graph.},
  title        = {A hybrid near-wall model for kinetic simulation of turbulent boundary layer flows},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast but accurate: A real-time hyperelastic simulator with robust frictional contact. <em>TOG</em>, <em>44</em>(4), 1-19. (<a href='https://doi.org/10.1145/3730834'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a GPU-friendly framework for real-time implicit simulation of elastic material in the presence of frictional contacts. The integration of hyperelasticity, non-interpenetration contact, and friction in real-time simulations presents formidable nonlinear and non-smooth problems, which are highly challenging to solve. By incorporating nonlinear complementarity conditions within the local-global framework, we achieve rapid convergence in addressing these challenges. While the structure of local-global methods is not fully GPU-friendly, our proposal of a simple yet efficient solver with sparse presentation of the system inverse enables highly parallel computing while maintaining a fast convergence rate. Moreover, our novel splitting strategy for non-smooth indicators not only amplifies overall performance but also refines the complementarity preconditioner, enhancing the accuracy of frictional behavior modeling. Through extensive experimentation, the robustness of our framework in managing real-time contact scenarios, ranging from large-scale systems and extreme deformations to non-smooth contacts and precise friction interactions, has been validated. Compatible with a wide range of hyperelastic models, our approach maintains efficiency across both low and high stiffness materials. Despite its remarkable efficiency, robustness, and generality, our method is elegantly simple, with its core contributions grounded solely on standard matrix operations.},
  archive      = {J_TOG},
  author       = {Ziqiu Zeng and Siyuan Luo and Fan Shi and Zhongkai Zhang},
  doi          = {10.1145/3730834},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-19},
  shortjournal = {ACM Trans. Graph.},
  title        = {Fast but accurate: A real-time hyperelastic simulator with robust frictional contact},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hand-shadow poser. <em>TOG</em>, <em>44</em>(4), 1-16. (<a href='https://doi.org/10.1145/3730836'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hand shadow art is a captivating art form, creatively using hand shadows to reproduce expressive shapes on the wall. In this work, we study an inverse problem: given a target shape, find the poses of left and right hands that together best produce a shadow resembling the input. This problem is nontrivial, since the design space of 3D hand poses is huge while being restrictive due to anatomical constraints. Also, we need to attend to the input's shape and crucial features, though the input is colorless and textureless. To meet these challenges, we design Hand-Shadow Poser, a three-stage pipeline, to decouple the anatomical constraints (by hand) and semantic constraints (by shadow shape): (i) a generative hand assignment module to explore diverse but reasonable left/right-hand shape hypotheses; (ii) a generalized hand-shadow alignment module to infer coarse hand poses with a similarity-driven strategy for selecting hypotheses; and (iii) a shadow-feature-aware refinement module to optimize the hand poses for physical plausibility and shadow feature preservation. Further, we design our pipeline to be trainable on generic public hand data, thus avoiding the need for any specialized training dataset. For method validation, we build a benchmark of 210 diverse shadow shapes of varying complexity and a comprehensive set of metrics, including a novel DINOv2-based evaluation metric. Through extensive comparisons with multiple baselines and user studies, our approach is demonstrated to effectively generate bimanual hand poses for a large variety of hand shapes for over 85% of the benchmark cases.},
  archive      = {J_TOG},
  author       = {Hao Xu and Yinqiao Wang and Niloy J. Mitra and Shuaicheng Liu and Pheng-Ann Heng and Chi-Wing Fu},
  doi          = {10.1145/3730836},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-16},
  shortjournal = {ACM Trans. Graph.},
  title        = {Hand-shadow poser},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BANG: Dividing 3D assets via generative exploded dynamics. <em>TOG</em>, <em>44</em>(4), 1-21. (<a href='https://doi.org/10.1145/3730840'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D creation has always been a unique human strength, driven by our ability to deconstruct and reassemble objects using our eyes, mind and hand. However, current 3D design tools struggle to replicate this natural process, requiring considerable artistic expertise and manual labor. This paper introduces BANG, a novel generative approach that bridges 3D generation and reasoning, allowing for intuitive and flexible part-level decomposition of 3D objects. At the heart of BANG is "Generative Exploded Dynamics", which creates a smooth sequence of exploded states for an input geometry, progressively separating parts while preserving their geometric and semantic coherence. BANG utilizes a pre-trained large-scale latent diffusion model, fine-tuned for exploded dynamics with a lightweight exploded view adapter, allowing precise control over the decomposition process. It also incorporates a temporal attention module to ensure smooth transitions and consistency across time. BANG enhances control with spatial prompts, such as bounding boxes and surface regions, enabling users to specify which parts to decompose and how. This interaction can be extended with multimodal models like GPT-4, enabling 2D-to-3D manipulations for more intuitive and creative workflows. The capabilities of BANG extend to generating detailed part-level geometry, associating parts with functional descriptions, and facilitating component-aware 3D creation and manufacturing workflows. Additionally, BANG offers applications in 3D printing, where separable parts are generated for easy printing and reassembly. In essence, BANG enables seamless transformation from imaginative concepts to detailed 3D assets, offering a new perspective on creation that resonates with human intuition.},
  archive      = {J_TOG},
  author       = {Longwen Zhang and Qixuan Zhang and Haoran Jiang and Yinuo Bai and Wei Yang and Lan Xu and Jingyi Yu},
  doi          = {10.1145/3730840},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-21},
  shortjournal = {ACM Trans. Graph.},
  title        = {BANG: Dividing 3D assets via generative exploded dynamics},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CAST: Component-aligned 3D scene reconstruction from an RGB image. <em>TOG</em>, <em>44</em>(4), 1-19. (<a href='https://doi.org/10.1145/3730841'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recovering high-quality 3D scenes from a single RGB image is a challenging task in computer graphics. Current methods often struggle with domain-specific limitations or low-quality object generation. To address these, we propose CAST (Component-Aligned 3D Scene Reconstruction from a Single RGB Image), a novel method for 3D scene reconstruction. CAST starts by extracting object-level 2D segmentation and relative depth information from the input image, followed by using a GPT-based model to analyze inter-object spatial relations. This enables understanding of how objects relate to each other within the scene, ensuring more coherent reconstruction. CAST then employs an occlusion-aware large-scale 3D generation model to independently generate each object's full geometry, using Masked Auto Encoder (MAE) and point cloud conditioning to mitigate the effects of occlusions and partial object information, ensuring accurate alignment with the source image's geometry and texture. To align each object with the scene, the alignment generation model computes the necessary transformations, allowing the generated meshes to be accurately placed and integrated into the scene's point cloud. Finally, CAST applies a physics-aware correction mechanism, which leverages a fine-grained relation graph to generate a constraint graph. This graph guides the optimization of object poses, ensuring physical consistency and spatial coherence. By utilizing Signed Distance Fields (SDF), the model effectively addresses issues such as occlusions, object penetration, and floating objects, ensuring that the generated scene accurately reflects real-world physical interactions. Experimental results demonstrate that CAST significantly improves the quality of single-image 3D scene reconstruction, offering enhanced realism and accuracy in scene understanding and reconstruction tasks. CAST has practical applications in virtual content creation, such as immersive game environments and film production, where real-world setups can be seamlessly integrated into virtual landscapes. Additionally, CAST can be leveraged in robotics, enabling efficient real-to-simulation workflows and providing realistic, scalable simulation environments for robotic systems.},
  archive      = {J_TOG},
  author       = {Kaixin Yao and Longwen Zhang and Xinhao Yan and Yan Zeng and Qixuan Zhang and Lan Xu and Wei Yang and Jiayuan Gu and Jingyi Yu},
  doi          = {10.1145/3730841},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-19},
  shortjournal = {ACM Trans. Graph.},
  title        = {CAST: Component-aligned 3D scene reconstruction from an RGB image},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HoLa: B-rep generation using a holistic latent representation. <em>TOG</em>, <em>44</em>(4), 1-25. (<a href='https://doi.org/10.1145/3730842'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel representation for learning and generating Computer-Aided Design (CAD) models in the form of boundary representations (B-Reps). Our representation unifies the continuous geometric properties of B-Rep primitives in different orders (e.g., surfaces and curves) and their discrete topological relations in a holistic latent (HoLa) space. This is based on the simple observation that the topological connection between two surfaces is intrinsically tied to the geometry of their intersecting curve. Such a prior allows us to reformulate topology learning in B-Reps as a geometric reconstruction problem in Euclidean space. Specifically, we eliminate the presence of curves, vertices, and all the topological connections in the latent space by learning to distinguish and derive curve geometries from a pair of surface primitives via a neural intersection network. To this end, our holistic latent space is only defined on surfaces but encodes a full B-Rep model, including the geometry of surfaces, curves, vertices, and their topological relations. Our compact and holistic latent space facilitates the design of a first diffusion-based generator to take on a large variety of inputs including point clouds, single/multi-view images, 2D sketches, and text prompts. Our method significantly reduces ambiguities, redundancies, and incoherences among the generated B-Rep primitives, as well as training complexities inherent in prior multi-step B-Rep learning pipelines, while achieving greatly improved validity rate over current state of the art: 82% vs. ≈50%.},
  archive      = {J_TOG},
  author       = {Yilin Liu and Duoteng Xu and Xingyao Yu and Xiang Xu and Daniel Cohen-Or and Hao Zhang and Hui Huang},
  doi          = {10.1145/3730842},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-25},
  shortjournal = {ACM Trans. Graph.},
  title        = {HoLa: B-rep generation using a holistic latent representation},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TokenVerse: Versatile multi-concept personalization in token modulation space. <em>TOG</em>, <em>44</em>(4), 1-11. (<a href='https://doi.org/10.1145/3730843'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present TokenVerse - a method for multi-concept personalization, leveraging a pre-trained text-to-image diffusion model. Our framework can disentangle complex visual elements and attributes from as little as a single image, while enabling seamless plug-and-play generation of combinations of concepts extracted from multiple images. As opposed to existing works, TokenVerse can handle multiple images with multiple concepts each, and supports a wide-range of concepts, including objects, accessories, materials, pose, and lighting. Our work exploits a DiT-based text-to-image model, in which the input text affects the generation through both attention and modulation (shift and scale). We observe that the modulation space is semantic and enables localized control over complex concepts. Building on this insight, we devise an optimization-based framework that takes as input an image and a text description, and finds for each word a distinct direction in the modulation space. These directions can then be used to generate new images that combine the learned concepts in a desired configuration. We demonstrate the effectiveness of TokenVerse in challenging personalization settings, and showcase its advantages over existing methods.},
  archive      = {J_TOG},
  author       = {Daniel Garibi and Shahar Yadin and Roni Paiss and Omer Tov and Shiran Zada and Ariel Ephrat and Tomer Michaeli and Inbar Mosseri and Tali Dekel},
  doi          = {10.1145/3730843},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-11},
  shortjournal = {ACM Trans. Graph.},
  title        = {TokenVerse: Versatile multi-concept personalization in token modulation space},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sphere carving: Bounding volumes for signed distance fields. <em>TOG</em>, <em>44</em>(4), 1-13. (<a href='https://doi.org/10.1145/3730845'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce Sphere Carving , a novel method for automatically computing bounding volumes that closely bound a procedurally defined implicit surface. Starting from an initial bounding volume located far from the object, we iteratively approach the surface by leveraging the signed distance function information. Field function queries define a set of empty spheres, from which we extract intersection points that are used to compute a bounding volume. Our method is agnostic of the function representation and only requires a conservative signed distance field as input. This encompasses a large set of procedurally defined implicit surface models such as exact or Lipschitz functions, BlobTrees, or even neural representations. Sphere Carving is conceptually simple, independent of the function representation, requires a small number of function queries to create bounding volumes, and accelerates queries in Sphere Tracing and polygonization.},
  archive      = {J_TOG},
  author       = {Hugo Schott and Theo Thonat and Thibaud Lambert and Eric Guérin and Eric Galin and Axel Paris},
  doi          = {10.1145/3730845},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-13},
  shortjournal = {ACM Trans. Graph.},
  title        = {Sphere carving: Bounding volumes for signed distance fields},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Segment-based light transport simulation. <em>TOG</em>, <em>44</em>(4), 1-10. (<a href='https://doi.org/10.1145/3730847'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel segment-based light transport framework that uses segments as the basic unit of light transport. Unlike vertex-based formulations, our segment-based formulation naturally accommodates the disconnected subpaths encountered in photon density estimation and path filtering methods, and opens the door to a wide range of new rendering methods that consider segments as a sampling primitive. To facilitate the development of segment-based rendering methods, we introduce several segment sampling techniques and estimation strategies, including a highly-performant recursive estimator. One of our key contributions is a general-purpose segment sampling framework based on marginal multiple importance sampling (MMIS). To demonstrate the practicality of our sampling framework, we show how it allows us to easily implement a robust bidirectional path filtering method — challenging under a vertex-based formulation — achieving superior filtering efficiency and convergence compared to state-of-the-art approaches.},
  archive      = {J_TOG},
  author       = {Wenyou Wang and Rex West and Toshiya Hachisuka},
  doi          = {10.1145/3730847},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-10},
  shortjournal = {ACM Trans. Graph.},
  title        = {Segment-based light transport simulation},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Creating fluid-interactive virtual agents by an efficient simulator with local-domain control. <em>TOG</em>, <em>44</em>(4), 1-19. (<a href='https://doi.org/10.1145/3730848'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of digital twin systems, establishing simulation environments for creating and testing virtual agents has garnered substantial attention across various applications. The obtained control policies endow virtual agents with more realistic behaviors and interactive capabilities, finding applications in both computer animation and robotic control. While rigid-body simulators are widely used for virtual agents, achieving similar feats in fluid environments presents formidable challenges due to high complexity and exorbitant costs. One major reason is that most fluid simulators feature a fixed domain, which struggles to enable agents to freely navigate in an unbounded, obstacle-filled space, especially when computational resources are limited, thus restricting their wide utility for creating virtual agents. In this paper, we introduce a novel fluid-solid interaction simulator grounded in an efficient lattice Boltzmann solver. A key feature of this simulator is a dynamically moving local domain that encircles the agent, offering greater flexibility for obtaining control policy while maintaining efficiency in simulation. Previous methods, which anchored a square moving local domain along with the agent, suffered from severe spurious flows when the agent underwent rapid acceleration especially when the domain had to rotate, such as during a U-turn. This led to inaccurate results and instability. Conversely, we propose a novel domain-tracking method that harnesses optimal control techniques to address this issue. Our approach not only bolsters local-domain simulation stability, but also improves efficiency by employing a slender domain, which broadens the application scope of direct fluid-solid interactions for virtual agents. We validate our method by comparing simulations to physical phenomena and obtaining control policies for various virtual agents to accomplish challenging tasks. This effort culminates in a series of animations that vividly demonstrate the efficacy of the entire framework potentially used in both computer animation and robotics.},
  archive      = {J_TOG},
  author       = {Wenbin Song and Heng Zhang and Yang Wang and Xiaopei Liu},
  doi          = {10.1145/3730848},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-19},
  shortjournal = {ACM Trans. Graph.},
  title        = {Creating fluid-interactive virtual agents by an efficient simulator with local-domain control},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TetWeave: Isosurface extraction using on-the-fly delaunay tetrahedral grids for gradient-based mesh optimization. <em>TOG</em>, <em>44</em>(4), 1-19. (<a href='https://doi.org/10.1145/3730851'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce TetWeave, a novel isosurface representation for gradient-based mesh optimization that jointly optimizes the placement of a tetrahedral grid used for Marching Tetrahedra and a novel directional signed distance at each point. TetWeave constructs tetrahedral grids on-the-fly via Delaunay triangulation, enabling increased flexibility compared to predefined grids. The extracted meshes are guaranteed to be watertight, two-manifold and intersection-free. The flexibility of TetWeave enables a resampling strategy that places new points where reconstruction error is high and allows to encourage mesh fairness without compromising on reconstruction error. This leads to high-quality, adaptive meshes that require minimal memory usage and few parameters to optimize. Consequently, TetWeave exhibits near-linear memory scaling relative to the vertex count of the output mesh — a substantial improvement over predefined grids. We demonstrate the applicability of TetWeave to a broad range of challenging tasks in computer graphics and vision, such as multi-view 3D reconstruction, mesh compression and geometric texture generation. Our code is available at https://github.com/AlexandreBinninger/TetWeave.},
  archive      = {J_TOG},
  author       = {Alexandre Binninger and Ruben Wiersma and Philipp Herholz and Olga Sorkine-Hornung},
  doi          = {10.1145/3730851},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-19},
  shortjournal = {ACM Trans. Graph.},
  title        = {TetWeave: Isosurface extraction using on-the-fly delaunay tetrahedral grids for gradient-based mesh optimization},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Claycode: Stylable and deformable 2D scannable codes. <em>TOG</em>, <em>44</em>(4), 1-14. (<a href='https://doi.org/10.1145/3730853'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces Claycode, a novel 2D scannable code designed for extensive stylization and deformation. Unlike traditional matrix-based codes (e.g. , QR codes), Claycodes encode their message in a tree structure. During the encoding process, bits are mapped into a topology tree, which is then depicted as a nesting of color regions drawn within the boundaries of a target polygon shape. When decoding, Claycodes are extracted and interpreted in real-time from a camera stream. We detail the end-to-end pipeline and show that Claycodes allow for extensive stylization without compromising their functionality. We then empirically demonstrate Claycode's high tolerance to heavy deformations, outperforming traditional 2D scannable codes in scenarios where they typically fail.},
  archive      = {J_TOG},
  author       = {Marco Maida and Alberto Crescini and Marco Perronet and Elena Camuffo},
  doi          = {10.1145/3730853},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-14},
  shortjournal = {ACM Trans. Graph.},
  title        = {Claycode: Stylable and deformable 2D scannable codes},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive phase-field-FLIP for very large scale two-phase fluid simulation. <em>TOG</em>, <em>44</em>(4), 1-23. (<a href='https://doi.org/10.1145/3730854'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capturing the visually compelling features of large-scale water phenomena, such as the spray clouds of crashing waves, stormy seas, or waterfalls, involves simulating not only the water but also the motion of the air interacting with it. However, current solutions in the visual effects industry still largely rely on single-phase solvers and non-physical "white-water" heuristics. To address these limitations, we present Phase-Field-FLIP (PF-FLIP), a hybrid Eulerian/Lagrangian method for the fully physics-based simulation of very large-scale, highly turbulent multiphase flows at high Reynolds numbers and high fluid density contrasts. PF-FLIP transports mass and momentum in a consistent, non-dissipative manner and, unlike most existing multiphase approaches, does not require a surface reconstruction step. Furthermore, we employ spatial adaptivity across all critical components of the simulation algorithm, including the pressure Poisson solver. We augment PF-FLIP with a dual multiresolution scheme that couples an efficient treeless adaptive grid with adaptive particles, along with a fast adaptive Poisson solver tailored for high-density-contrast multiphase flows. Our method enables the simulation of two-phase flow scenarios with a level of physical realism and detail previously unattainable in graphics, supporting billions of particles and adaptive 3D resolutions with thousands of grid cells per dimension on a single workstation.},
  archive      = {J_TOG},
  author       = {Bernhard Braun and Jan Bender and Nils Thuerey},
  doi          = {10.1145/3730854},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-23},
  shortjournal = {ACM Trans. Graph.},
  title        = {Adaptive phase-field-FLIP for very large scale two-phase fluid simulation},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Practical inverse rendering of textured and translucent appearance. <em>TOG</em>, <em>44</em>(4), 1-16. (<a href='https://doi.org/10.1145/3730855'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse rendering has emerged as a standard tool to reconstruct the parameters of appearance models from images (e.g., textured BSDFs). In this work, we present several novel contributions motivated by the practical challenges of recovering high-resolution surface appearance textures, including spatially-varying subsurface scattering parameters. First, we propose Laplacian mipmapping , which combines differentiable mipmapping and a Laplacian pyramid representation into an effective preconditioner. This seemingly simple technique significantly improves the quality of recovered surface textures on a set of challenging inverse rendering problems. Our method automatically adapts to the render and texture resolutions, only incurs moderate computational cost and achieves better quality than prior work while using fewer hyperparameters. Second, we introduce a specialized gradient computation algorithm for textured, path-traced subsurface scattering, which facilitates faithful reconstruction of translucent materials. By using path tracing, we enable the recovery of complex appearance while avoiding the approximations of the previously used diffusion dipole methods. Third, we demonstrate the application of both these techniques to reconstructing the textured appearance of human faces from sparse captures. Our method recovers high-quality relightable appearance parameters that are compatible with current production renderers.},
  archive      = {J_TOG},
  author       = {Philippe Weier and Jérémy Riviere and Ruslan Guseinov and Stephan Garbin and Philipp Slusallek and Bernd Bickel and Thabo Beeler and Delio Vicini},
  doi          = {10.1145/3730855},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-16},
  shortjournal = {ACM Trans. Graph.},
  title        = {Practical inverse rendering of textured and translucent appearance},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Order matters: Learning element ordering for graphic design generation. <em>TOG</em>, <em>44</em>(4), 1-16. (<a href='https://doi.org/10.1145/3730858'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The past few years have witnessed an emergent interest in building generative models for the graphic design domain. For adoption of powerful deep generative models with Transformer-based neural backbones, prior approaches formulate designs as ordered sequences of elements, and simply order the elements in a random or raster manner. We argue that such naive ordering methods are sub-optimal and there is room for improving sample quality through a better choice of order between graphic design elements. In this paper, we seek to explore the space of orderings to find the ordering strategy that optimizes the performance of graphic design generation models. For this, we propose a model, namely G enerative O rder L earner (GOL), which trains an autoregressive generator on design sequences, jointly with an ordering network that sort design elements to maximize the generation quality. With unsupervised training on vector graphic design data, our model is capable of learning a content-adaptive ordering approach, called neural order. Our experiments show that the generator trained with our neural order converges faster, achieving remarkably improved generation quality compared with using alternative ordering baselines. We conduct comprehensive analysis of our learned order to have a deeper understanding of its ordering behaviors. In addition, our learned order can generalize well to diffusion-based generative models and help design generators scale up excellently.},
  archive      = {J_TOG},
  author       = {Bo Yang and Ying Cao},
  doi          = {10.1145/3730858},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-16},
  shortjournal = {ACM Trans. Graph.},
  title        = {Order matters: Learning element ordering for graphic design generation},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Digital animation of powder-snow avalanches. <em>TOG</em>, <em>44</em>(4), 1-20. (<a href='https://doi.org/10.1145/3730862'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Powder-snow avalanches are natural phenomena that result from an instability in the snow cover on a mountain relief. It begins with a dense avalanche core moving fast down the mountain. During its evolution, the snow particles in the avalanche front mix with the air, forming a suspended turbulent cloud of snow dust surrounding the dense snow avalanche. This paper introduces a physically-based framework using the Finite Volume Method to simulate powder-snow avalanches under complex terrains. Specifically, the primary goal is to simulate the turbulent snow cloud dynamics within the avalanche in a visually realistic manner. Our approach relies on a multi-layer model that splits the avalanche into two main layers: dense and powder-snow. The dense-snow layer flow is simulated by solving a type of Shallow Water Equations suited for intricate basal surfaces, known as the Savage-Hutter model. The powder-snow layer flow is modeled as a two-phase mixture of miscible fluids and simulated using Navier-Stokes equations. Moreover, we propose a novel model for the transition layer, which is responsible for coupling the avalanche main layers, including the snow mass injected into the powder-snow cloud from the snow entrainment processes and its injection velocity. In brief, our framework comprehensively simulates powder-snow avalanches, allowing us to render convincing animations of one of the most complex gravity-driven flows.},
  archive      = {J_TOG},
  author       = {Filipe Nascimento and Fabricio S. Sousa and Afonso Paiva},
  doi          = {10.1145/3730862},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-20},
  shortjournal = {ACM Trans. Graph.},
  title        = {Digital animation of powder-snow avalanches},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Piecewise ruled approximation for freeform mesh surfaces. <em>TOG</em>, <em>44</em>(4), 1-18. (<a href='https://doi.org/10.1145/3730866'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A ruled surface is a shape swept out by moving a line in 3D space. Due to their simple geometric forms, ruled surfaces have applications in various domains such as architecture and engineering. In the past, various approaches have been proposed to approximate a target shape using developable surfaces, which are special ruled surfaces with zero Gaussian curvature. However, methods for shape approximation using general ruled surfaces remain limited and often require the target shape to be either represented as parametric surfaces or have non-positive Gaussian curvature. In this paper, we propose a method to compute a piecewise ruled surface that approximates an arbitrary freeform mesh surface. We first use a group-sparsity formulation to optimize the given mesh shape into an approximately piecewise ruled form, in conjunction with a tangent vector field that indicates the ruling directions. Afterward, we utilize the optimization result to extract seams that separate smooth families of rulings, and use the seams to construct the initial rulings. Finally, we further optimize the positions and orientations of the rulings to improve the alignment with the input target shape. We apply our method to a variety of freeform shapes with different topologies and complexity, demonstrating its effectiveness in approximating arbitrary shapes.},
  archive      = {J_TOG},
  author       = {Yiling Pan and Zhixin Xu and Bin Wang and Bailin Deng},
  doi          = {10.1145/3730866},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-18},
  shortjournal = {ACM Trans. Graph.},
  title        = {Piecewise ruled approximation for freeform mesh surfaces},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In search of empty spheres: 3D apollonius diagrams on GPU. <em>TOG</em>, <em>44</em>(4), 1-15. (<a href='https://doi.org/10.1145/3730868'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel comprehensive construction algorithm of Apollonius diagrams designed for GPUs. Efficient and robust algorithms have been proposed for the computation of Voronoi diagrams or Power diagrams. In contrast, Apollonius cells are neither convex nor bounded by straight boundaries, making their computation complex, especially in more than two dimensions. Their parallel computation also represents a challenge because of the sequential nature of state-of-the-art algorithms. In this article, we tackle the computation of these diagrams from the geometry of their cells. Our strategy is based on a core cell topology update allowing the iterative insertion of new sites found through nearest neighbor queries. To benefit from the highly parallel environment of modern GPUs and fit their memory restriction, we define a lightweight data structure allowing the representation of the complex topology of Apollonius cells. Additionally, we provide several space exploration procedures for their efficient construction under both homogeneous and heterogeneous spatial distributions. Our method outperforms the fastest state-of-the-art CPU implementation while computing the complete geometry. As a possible use case, we show an application for molecular illustration.},
  archive      = {J_TOG},
  author       = {Cyprien Plateau-Holleville and Benjamin Stamm and Vincent Nivoliers and Maxime Maria and Stéphane Mérillou},
  doi          = {10.1145/3730868},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-15},
  shortjournal = {ACM Trans. Graph.},
  title        = {In search of empty spheres: 3D apollonius diagrams on GPU},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A versatile quaternion-based constrained rigid body dynamics. <em>TOG</em>, <em>44</em>(4), 1-17. (<a href='https://doi.org/10.1145/3730872'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a constrained Rigid Body Dynamics (RBD) that guarantees satisfaction of kinematic constraints, enabling direct simulation of complex mechanical systems with arbitrary kinematic structures. To ensure constraint satisfaction, we use an implicit integration scheme. For this purpose, we derive compatible dynamic equations expressed through the quaternion time derivative, adopting an additive approach to quaternion updates instead of a multiplicative one, while enforcing quaternion unit-length as a constraint. We support all joints between rigid bodies that restrict subsets of the three translational or three rotational degrees of freedom, including position- and force-based actuation. Their constraints are formulated such that Lagrange multipliers are interpretable as joint forces and torques. We discuss a unified solution strategy for systems with redundant constraints, overactuation, and passive degrees of freedom, by eliminating redundant constraints and navigating the subspaces spanned by multipliers. As our method uses a standard additive update, we can interface with unconditionally-stable implicit integrators. Moreover, the simulation can readily be made differentiable as we show with examples.},
  archive      = {J_TOG},
  author       = {Guirec Maloisel and Ruben Grandia and Christian Schumacher and Espen Knoop and Moritz Bächer},
  doi          = {10.1145/3730872},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-17},
  shortjournal = {ACM Trans. Graph.},
  title        = {A versatile quaternion-based constrained rigid body dynamics},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The mokume dataset and inverse modeling of solid wood textures. <em>TOG</em>, <em>44</em>(4), 1-18. (<a href='https://doi.org/10.1145/3730874'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the Mokume dataset for solid wood texturing consisting of 190 cube-shaped samples of various hard and softwood species documented by high-resolution exterior photographs, annual ring annotations, and volumetric computed tomography (CT) scans. A subset of samples further includes photographs along slanted cuts through the cube for validation purposes. Using this dataset, we propose a three-stage inverse modeling pipeline to infer solid wood textures using only exterior photographs. Our method begins by evaluating a neural model to localize year rings on the cube face photographs. We then extend these exterior 2D observations into a globally consistent 3D representation by optimizing a procedural growth field using a novel iso-contour loss. Finally, we synthesize a detailed volumetric color texture from the growth field. For this last step, we propose two methods with different efficiency and quality characteristics: a fast inverse procedural texture method, and a neural cellular automaton (NCA). We demonstrate the synergy between the Mokume dataset and the proposed algorithms through comprehensive comparisons with unseen captured data. We also present experiments demonstrating the efficiency of our pipeline's components against ablations and baselines. Our code, the dataset, and reconstructions are available via https://mokumeproject.github.io/.},
  archive      = {J_TOG},
  author       = {Maria Larsson and Hodaka Yamaguchi and Ehsan Pajouheshgar and I-Chao Shen and Kenji Tojo and Chia-Ming Chang and Lars Hansson and Olof Broman and Takashi Ijiri and Ariel Shamir and Wenzel Jakob and Takeo Igarashi},
  doi          = {10.1145/3730874},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-18},
  shortjournal = {ACM Trans. Graph.},
  title        = {The mokume dataset and inverse modeling of solid wood textures},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Streaming-aware neural monte carlo rendering framework with unified denoising-compression and client collaboration. <em>TOG</em>, <em>44</em>(4), 1-13. (<a href='https://doi.org/10.1145/3730879'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in cloud rendering have brought us a promising alternative for interactive photorealistic rendering on lightweight devices, which used to be only available on high-end platforms equipped with powerful graphic cards. This technique enables users to perform rendering-related creative tasks, such as 3D product visualization and lighting design, from the comfort of any location using handheld devices, rather than being confined to the front of a noisy heat-generating workstation. However, existing large-scale cloud rendering systems that stream path-traced frames from the server to the client present extremely high rendering costs and transmission bandwidth requirements, even with advanced path-tracing acceleration and video compression techniques. To alleviate these problems, we propose a novel streaming-aware rendering framework that is able to learn a joint optimal model integrating two path-tracing acceleration techniques (adaptive sampling and denoising) and video compression technique. Our joint model can fully exploit the inherent connections between these techniques and thus achieve substantially reduced rendering costs and enhanced compression quality. We also introduce the collaboration of client rendering ability to assist the frame decoding by rendering G-buffers as the shared side information. We demonstrate that appropriately incorporating the geometry and material priors from G-buffers into a neural compression pipeline can significantly reduce the streaming bandwidth in a cloud rendering system, and lighten the compression module design for computation efficiency. Our experiments show that our method delivers the best quality at various bitrates compared to existing Monte Carlo rendering streaming schemes, while remaining lightweight and efficient for cross-platform thin clients, including mobiles and tablets.},
  archive      = {J_TOG},
  author       = {Hangming Fan and Yuchi Huo and Chuankun Zheng and Chonghao Hu and Yazhen Yuan and Rui Wang},
  doi          = {10.1145/3730879},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-13},
  shortjournal = {ACM Trans. Graph.},
  title        = {Streaming-aware neural monte carlo rendering framework with unified denoising-compression and client collaboration},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Designing pin-pression gripper and learning its dexterous grasping with online in-hand adjustment. <em>TOG</em>, <em>44</em>(4), 1-17. (<a href='https://doi.org/10.1145/3730880'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel design of parallel-jaw grippers drawing inspiration from pin-pression toys. The proposed pin-pression gripper features a distinctive mechanism in which each finger integrates a 2D array of pins capable of independent extension and retraction. This unique design allows the gripper to instantaneously customize its finger's shape to conform to the object being grasped by dynamically adjusting the extension/retraction of the pins. In addition, the gripper excels in in-hand re-orientation of objects for enhanced grasping stability again via dynamically adjusting the pins. To learn the dynamic grasping skills of pin-pression grippers, we devise a dedicated reinforcement learning algorithm with careful designs of state representation and reward shaping. To achieve a more efficient grasp-while-lift grasping mode, we propose a curriculum learning scheme. Extensive evaluations demonstrate that our design, together with the learned skills, leads to highly flexible and robust grasping with much stronger generality to unseen objects than alternatives. We also highlight encouraging physical results of sim-to-real transfer on a physically manufactured pin-pression gripper, demonstrating the practical significance of our novel gripper design and grasping skill. Demonstration videos for this paper are available at https://github.com/siggraph-pin-pression-gripper/pin-pression-gripper-video.},
  archive      = {J_TOG},
  author       = {Hewen Xiao and Xiuping Liu and Hang Zhao and Jian Liu and Kai Xu},
  doi          = {10.1145/3730880},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-17},
  shortjournal = {ACM Trans. Graph.},
  title        = {Designing pin-pression gripper and learning its dexterous grasping with online in-hand adjustment},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Closed-form generalized winding numbers of rational parametric curves for robust containment queries. <em>TOG</em>, <em>44</em>(4), 1-9. (<a href='https://doi.org/10.1145/3730886'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We derive closed-form expressions for generalized winding numbers of rational parametric curves for robust containment queries. Given an oriented rational parametric curve and a query point, the generalized winding number can be reformulated to an integral of a rational polynomial. The key to computing the integral lies in using the residue theorem. Then, add up the contributions of each curve to obtain the generalized winding numbers of a set of rational parametric curves. Furthermore, the derivatives of generalized winding numbers are easily derived. Consequently, the expressions for generalized winding numbers are concise and computationally efficient, becoming faster than state-of-the-art methods. Moreover, the computational costs for various query points are almost the same.},
  archive      = {J_TOG},
  author       = {Shibo Liu and Ligang Liu and Xiao-Ming Fu},
  doi          = {10.1145/3730886},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-9},
  shortjournal = {ACM Trans. Graph.},
  title        = {Closed-form generalized winding numbers of rational parametric curves for robust containment queries},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Polynomial 2D biharmonic coordinates for high-order cages. <em>TOG</em>, <em>44</em>(4), 1-10. (<a href='https://doi.org/10.1145/3730887'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We derive closed-form expressions of biharmonic coordinates for 2D high-order cages, enabling the transformation of the input polynomial curves into polynomial curves of any order. Central to our derivation is the use of the high-order boundary element method. We demonstrate the practicality and effectiveness of our method on various 2D deformations. In practice, users can easily manipulate the Bézier control points to perform the desired intuitive deformation, as the biharmonic coordinates provide an enriched deformation space and encourage the alignment between the boundary cage and its interior geometry.},
  archive      = {J_TOG},
  author       = {Shibo Liu and Tielin Dai and Ligang Liu and Xiao-Ming Fu},
  doi          = {10.1145/3730887},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-10},
  shortjournal = {ACM Trans. Graph.},
  title        = {Polynomial 2D biharmonic coordinates for high-order cages},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Asymptotic analysis and design of linear elastic shell lattice metamaterials. <em>TOG</em>, <em>44</em>(4), 1-18. (<a href='https://doi.org/10.1145/3730888'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an asymptotic analysis of shell lattice metamaterials based on Ciarlet's shell theory, introducing a new metric— asymptotic directional stiffness (ADS)—to quantify how the geometry of the middle surface governs the effective stiffness. We prove a convergence theorem that rigorously characterizes ADS and establishes its upper bound, along with necessary and sufficient condition for achieving it. As a key result, our theory provides the first rigorous explanation for the high bulk modulus observed in Triply Periodic Minimal Surfaces (TPMS)-based shell lattices. To optimize ADS on general periodic surfaces, we propose a triangular-mesh-based discretization and shape optimization framework. Numerical experiments validate the theoretical findings and demonstrate the effectiveness of the optimization under various design objectives. Our implementation is available at https://github.com/lavenklau/minisurf.},
  archive      = {J_TOG},
  author       = {Di Zhang and Ligang Liu},
  doi          = {10.1145/3730888},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-18},
  shortjournal = {ACM Trans. Graph.},
  title        = {Asymptotic analysis and design of linear elastic shell lattice metamaterials},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Field smoothness-controlled partition for quadrangulation. <em>TOG</em>, <em>44</em>(4), 1-15. (<a href='https://doi.org/10.1145/3730889'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel partition method for reliable feature-aligned quadrangulation. The core insight of the partition is that smooth streamlines distant from singularities are more suitable as patch boundaries. This allows singularities to be enclosed within patches, resulting in straighter patch boundaries and reducing the distorting influence of singularities. Accordingly, we introduce a new patch quality control mechanism that keeps the patch boundaries inside regions with high field smoothness. Combined with other common metrics (e.g., aligning boundaries with field and feature lines), we develop a practical partition algorithm that first iteratively traces paths in field smoothness-controlled regions to form patches and then removes redundant paths to simplify the patch layout. We demonstrate the effectiveness and practicability of our partitions by using them to generate quality quad meshes on a massive test data set. Compared with state-of-the-art methods, our approach produces quad meshes with significantly enhanced quality while maintaining similar reliability, validating the core insight. Code and data for this paper are at https://github.com/AnderLiang/Field-Smoothness-Controlled-Quadrangulation.},
  archive      = {J_TOG},
  author       = {Zhongxuan Liang and Wei Du and Xiao-Ming Fu},
  doi          = {10.1145/3730889},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-15},
  shortjournal = {ACM Trans. Graph.},
  title        = {Field smoothness-controlled partition for quadrangulation},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revisiting tradition and beyond: A customized bilateral filtering framework for point cloud denoising. <em>TOG</em>, <em>44</em>(4), 1-13. (<a href='https://doi.org/10.1145/3730891'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based methods have become the dominant solution for point cloud denoising, offering strong generalization capabilities through data-driven training. However, traditional methods, despite their drawbacks of heavy parameter tuning and weak generalization, retain unique advantages in interpretability and theoretical robustness. This complementarity motivates us to explore a hybrid solution that leverages data-driven paradigms to overcome the performance constraints of traditional methods. In this paper, we revisit the classic bilateral filter (BF) as a case study and identify three key limitations hindering its performance: excessive parameter tuning, suboptimal neighborhood quality, and fixed parameters across the entire model. To address them, we propose CustomBF, a novel framework for customizing BF components at a per-point level. CustomBF employs multigraph encoders and a mutual guidance strategy to analyze local patches, enabling the customization of BF components including center point normal, neighborhood point coordinates, Gaussian function parameters, and neighborhood radius for each point. Experimental results demonstrate that this component-customized bilateral filter outperforms state-of-the-art methods and achieves robust denoising even in complex scenarios. It highlights the potential of hybrid methods to extend the applicability and effectiveness of traditional techniques.},
  archive      = {J_TOG},
  author       = {Peng Li and Zeyong Wei and Honghua Chen and Xuefeng Yan and Mingqiang Wei},
  doi          = {10.1145/3730891},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-13},
  shortjournal = {ACM Trans. Graph.},
  title        = {Revisiting tradition and beyond: A customized bilateral filtering framework for point cloud denoising},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TransparentGS: Fast inverse rendering of transparent objects with gaussians. <em>TOG</em>, <em>44</em>(4), 1-17. (<a href='https://doi.org/10.1145/3730892'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of neural and Gaussian-based radiance field methods has led to considerable advancements in novel view synthesis and 3D object reconstruction. Nonetheless, specular reflection and refraction continue to pose significant challenges due to the instability and incorrect overfitting of radiance fields to high-frequency light variations. Currently, even 3D Gaussian Splatting (3D-GS), as a powerful and efficient tool, falls short in recovering transparent objects with nearby contents due to the existence of apparent secondary ray effects. To address this issue, we propose TransparentGS, a fast inverse rendering pipeline for transparent objects based on 3D-GS. The main contributions are three-fold. Firstly, an efficient representation of transparent objects, transparent Gaussian primitives, is designed to enable specular refraction through a deferred refraction strategy. Secondly, we leverage Gaussian light field probes (GaussProbe) to encode both ambient light and nearby contents in a unified framework. Thirdly, a depth-based iterative probes query (IterQuery) algorithm is proposed to reduce the parallax errors in our probe-based framework. Experiments demonstrate the speed and accuracy of our approach in recovering transparent objects from complex environments, as well as several applications in computer graphics and vision.},
  archive      = {J_TOG},
  author       = {Letian Huang and Dongwei Ye and Jialin Dan and Chengzhi Tao and Huiwen Liu and Kun Zhou and Bo Ren and Yuanqi Li and Yanwen Guo and Jie Guo},
  doi          = {10.1145/3730892},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-17},
  shortjournal = {ACM Trans. Graph.},
  title        = {TransparentGS: Fast inverse rendering of transparent objects with gaussians},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Moment bounds are differentiable: Efficiently approximating measures in inverse rendering. <em>TOG</em>, <em>44</em>(4), 1-21. (<a href='https://doi.org/10.1145/3730899'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {All rendering methods aim at striking a balance between realism and efficiency. This is particularly relevant for differentiable rendering, where the additional aspect of differentiablity w.r.t. scene parameters causes increased computational complexity while, on the other hand, in the common application of inverse rendering, the diverse effects of real image formation must be faithfully reproduced. An important effect in rendering is the attenuation of light as it travels through different media (visibility, shadows, transmittance, transparency). This can be modeled as an integral over non-negative functions and has been successfully approximated in forward rendering by so-called moments. We show that moment-based approximations are differentiable in the parameters defining the moments, and that this leads to efficient and practical methods for inverse rendering. In particular, we demonstrate the method at the examples of shadow mapping and visibility in volume rendering, leading to approximations that are similar in efficiency to existing ad-hoc techniques while being significantly more accurate.},
  archive      = {J_TOG},
  author       = {Markus Worchel and Marc Alexa},
  doi          = {10.1145/3730899},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-21},
  shortjournal = {ACM Trans. Graph.},
  title        = {Moment bounds are differentiable: Efficiently approximating measures in inverse rendering},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differentiable geometric acoustic path tracing using time-resolved path replay backpropagation. <em>TOG</em>, <em>44</em>(4), 1-17. (<a href='https://doi.org/10.1145/3730900'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differentiable rendering has become a key ingredient in solving challenging inverse problems in computer graphics and vision. Existing systems can simulate and differentiate the spatial propagation of light. We exploit the duality of light transport simulations and geometric acoustics to apply differential rendering techniques to established acoustic simulation methods. The resulting system is capable of simulating sound according to the geometrical acoustics model and computing derivatives of the output energy spectrograms with respect to arbitrary parameters of the scene, including materials, emitters, microphones, and scene geometry. Contrary to current differentiable transient rendering, we can handle arbitrary simulation depths and achieve constant memory and linear execution times by presenting a temporal extension of Path Replay Backpropagation [Vicini et al. 2021]. We verify our model against established simulation software, and demonstrate the capabilities of optimization with gradients at examples of inverse acoustics and optimizing room parameters. This opens up a new field of research for acoustic optimization that could be as impactful for the acoustic community as differentiable rendering was for the graphics community.},
  archive      = {J_TOG},
  author       = {Ugo Finnendahl and Markus Worchel and Tobias Jüterbock and Daniel Wujecki and Fabian Brinkmann and Stefan Weinzierl and Marc Alexa},
  doi          = {10.1145/3730900},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-17},
  shortjournal = {ACM Trans. Graph.},
  title        = {Differentiable geometric acoustic path tracing using time-resolved path replay backpropagation},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boolean operation for CAD models using a hybrid representation. <em>TOG</em>, <em>44</em>(4), 1-17. (<a href='https://doi.org/10.1145/3730908'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Boolean operations for Boundary Representation (B-Rep) models are among the most commonly used functions in Computer Aided Design (CAD) systems. They are also one of the most delicate soft modules, with challenges arising from complex algorithmic flows and efficiency and accuracy issues, especially in extreme cases. Common issues encountered in processing complex models include low efficiency, missing results, and non-watertightness. In this paper, we propose a novel algorithm for efficient and accurate Boolean operations on B-Rep models. This is achieved by establishing a bijective mapping between B-Rep models and the corresponding triangle meshes with controllable approximation error, thus mapping B-Rep Boolean operations to mesh Boolean operations. By using conservative intersection detection on the mesh to locate all surface intersection curves and carefully handling degeneration and topology errors, we ensure that the results are consistently watertight and correct. We demonstrate the superior efficiency of the proposed method using the open-source geometry engine OCCT, the commercial engine ACIS, and the commercial software Rhino as benchmarks.},
  archive      = {J_TOG},
  author       = {Yingyu Yang and Xiaohong Jia and Bolun Wang and Jieyin Yang and Shiqing Xin and Dong-Ming Yan},
  doi          = {10.1145/3730908},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-17},
  shortjournal = {ACM Trans. Graph.},
  title        = {Boolean operation for CAD models using a hybrid representation},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On-the-fly reconstruction for large-scale novel view synthesis from unposed images. <em>TOG</em>, <em>44</em>(4), 1-14. (<a href='https://doi.org/10.1145/3730913'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiance field methods such as 3D Gaussian Splatting (3DGS) allow easy reconstruction from photos, enabling free-viewpoint navigation. Nonetheless, pose estimation using Structure from Motion and 3DGS optimization can still each take between minutes and hours of computation after capture is complete. SLAM methods combined with 3DGS are fast but struggle with wide camera baselines and large scenes. We present an on-the-fly method to produce camera poses and a trained 3DGS immediately after capture. Our method can handle dense and wide-baseline captures of ordered photo sequences and large-scale scenes. To do this, we first introduce fast initial pose estimation, exploiting learned features and a GPU-friendly mini bundle adjustment. We then introduce direct sampling of Gaussian primitive positions and shapes, incrementally spawning primitives where required, significantly accelerating training. These two efficient steps allow fast and robust joint optimization of poses and Gaussian primitives. Our incremental approach handles large-scale scenes by introducing scalable radiance field construction, progressively clustering 3DGS primitives, storing them in anchors, and offloading them from the GPU. Clustered primitives are progressively merged, keeping the required scale of 3DGS at any viewpoint. We evaluate our solution on a variety of datasets and show that it can provide on-the-fly processing of all the capture scenarios and scene sizes we target. At the same time our method remains competitive - in speed, image quality, or both - with other methods that only handle specific capture styles or scene sizes.},
  archive      = {J_TOG},
  author       = {Andreas Meuleman and Ishaan Shah and Alexandre Lanvin and Bernhard Kerbl and George Drettakis},
  doi          = {10.1145/3730913},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-14},
  shortjournal = {ACM Trans. Graph.},
  title        = {On-the-fly reconstruction for large-scale novel view synthesis from unposed images},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DesignManager: An agent-powered copilot for designers to integrate AI design tools into creative workflows. <em>TOG</em>, <em>44</em>(4), 1-26. (<a href='https://doi.org/10.1145/3730919'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Creative design is an inherently complex and iterative process characterized by continuous exploration, evaluation, and refinement. While recent advances in generative AI have demonstrated remarkable potential in supporting specific design tasks, there remains a critical gap in understanding how these technologies can enhance the holistic design process rather than just isolated stages. This paper introduces DesignManager, a novel AI-powered design support system that aims to transform how designers collaborate with AI throughout their creative workflow. Through a formative study examining designers' current practices with generative AI, we identified key challenges and opportunities in integrating AI into the creative design process. Based on these insights, we developed DesignManager as an interactive copilot system that provides node-based visualization of design evolution, enabling designers to track, modify, and branch their design processes while maintaining meaningful dialogue-based collaboration. The system offers two collaboration modes: DesignManager-guiding and Designer-guiding. Designers can engage in conversational interactions with the DesignManager to obtain design inspiration and tool recommendations, and proactively advance the design progress. The system employs an agent framework to manage decoupled contextual information emerged during the design process, facilitating deep understanding of designers' needs and providing context-aware assistance. Our technical evaluation validated the effectiveness of context decoupling and the use of agent framework, while the open-ended user study with experts demonstrated that DesignManager successfully supports intuitive intention expression, flexible process control, and deeper creative articulation. This work contributes to the understanding of how AI can evolve from task-specific tools to collaborative partners in creative design processes.},
  archive      = {J_TOG},
  author       = {Weitao You and Yinyu Lu and Zirui Ma and Nan Li and Mingxu Zhou and Xue Zhao and Pei Chen and Lingyun Sun},
  doi          = {10.1145/3730919},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-26},
  shortjournal = {ACM Trans. Graph.},
  title        = {DesignManager: An agent-powered copilot for designers to integrate AI design tools into creative workflows},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural co-optimization of structural topology, manufacturable layers, and path orientations for fiber-reinforced composites. <em>TOG</em>, <em>44</em>(4), 1-17. (<a href='https://doi.org/10.1145/3730922'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a neural network-based computational framework for the simultaneous optimization of structural topology, curved layers, and path orientations to achieve strong anisotropic strength in fiber-reinforced thermoplastic composites while ensuring manufacturability. Our framework employs three implicit neural fields to represent geometric shape, layer sequence, and fiber orientation. This enables the direct formulation of both design and manufacturability objectives - such as anisotropic strength, structural volume, machine motion control, layer curvature, and layer thickness - into an integrated and differentiable optimization process. By incorporating these objectives as loss functions, the framework ensures that the resultant composites exhibit optimized mechanical strength while remaining its manufacturability for filament-based multi-axis 3D printing across diverse hardware platforms. Physical experiments demonstrate that the composites generated by our co-optimization method can achieve an improvement of up to 33.1% in failure loads compared to composites with sequentially optimized structures and manufacturing sequences.},
  archive      = {J_TOG},
  author       = {Tao Liu and Tianyu Zhang and Yongxue Chen and Weiming Wang and Yu Jiang and Yuming Huang and Charlie C. L. Wang},
  doi          = {10.1145/3730922},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-17},
  shortjournal = {ACM Trans. Graph.},
  title        = {Neural co-optimization of structural topology, manufacturable layers, and path orientations for fiber-reinforced composites},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A divide-and-conquer approach for global orientation of non-watertight scene-level point clouds using 0-1 integer optimization. <em>TOG</em>, <em>44</em>(4), 1-15. (<a href='https://doi.org/10.1145/3730923'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Orienting point clouds is a fundamental problem in computer graphics and 3D vision, with applications in reconstruction, segmentation, and analysis. While significant progress has been made, existing approaches mainly focus on watertight, object-level 3D models. The orientation of large-scale, non-watertight 3D scenes remains an underexplored challenge. To address this gap, we propose DACPO (Divide-And-Conquer Point Orientation), a novel framework that leverages a divide-and-conquer strategy for scalable and robust point cloud orientation. Rather than attempting to orient an unbounded scene at once, DACPO segments the input point cloud into smaller, manageable blocks, processes each block independently, and integrates the results through a global optimization stage. For each block, we introduce a two-step process: estimating initial normal orientations by a randomized greedy method and refining them by an adapted iterative Poisson surface reconstruction. To achieve consistency across blocks, we model inter-block relationships using an an undirected graph, where nodes represent blocks and edges connect spatially adjacent blocks. To reliably evaluate orientation consistency between adjacent blocks, we introduce the concept of the visible connected region , which defines the region over which visibility-based assessments are performed. The global integration is then formulated as a 0-1 integer-constrained optimization problem, with block flip states as binary variables. Despite the combinatorial nature of the problem, DACPO remains scalable by limiting the number of blocks (typically a few hundred for 3D scenes) involved in the optimization. Experiments on benchmark datasets demonstrate DACPO's strong performance, particularly in challenging large-scale, non-watertight scenarios where existing methods often fail. The source code is available at https://github.com/zd-lee/DACPO.},
  archive      = {J_TOG},
  author       = {Zhuodong Li and Fei Hou and Wencheng Wang and Xuequan Lu and Ying He},
  doi          = {10.1145/3730923},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-15},
  shortjournal = {ACM Trans. Graph.},
  title        = {A divide-and-conquer approach for global orientation of non-watertight scene-level point clouds using 0-1 integer optimization},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When gaussian meets surfel: Ultra-fast high-fidelity radiance field rendering. <em>TOG</em>, <em>44</em>(4), 1-15. (<a href='https://doi.org/10.1145/3730925'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce Gaussian-enhanced Surfels (GESs), a bi-scale representation for radiance field rendering, wherein a set of 2D opaque surfels with view-dependent colors represent the coarse-scale geometry and appearance of scenes, and a few 3D Gaussians surrounding the surfels supplement fine-scale appearance details. The rendering with GESs consists of two passes - surfels are first rasterized through a standard graphics pipeline to produce depth and color maps, and then Gaussians are splatted with depth testing and color accumulation on each pixel order independently. The optimization of GESs from multi-view images is performed through an elaborate coarse-to-fine procedure, faithfully capturing rich scene appearance. The entirely sorting-free rendering of GESs not only achieves very fast rates, but also produces view-consistent images, successfully avoiding popping artifacts under view changes. The basic GES representation can be easily extended to achieve antialiasing in rendering (Mip-GES), boosted rendering speeds (Speedy-GES) and compact storage (Compact-GES), and reconstruct better scene geometries by replacing 3D Gaussians with 2D Gaussians (2D-GES). Experimental results show that GESs advance the state-of-the-arts as a compelling representation for ultra-fast high-fidelity radiance field rendering.},
  archive      = {J_TOG},
  author       = {Keyang Ye and Tianjia Shao and Kun Zhou},
  doi          = {10.1145/3730925},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-15},
  shortjournal = {ACM Trans. Graph.},
  title        = {When gaussian meets surfel: Ultra-fast high-fidelity radiance field rendering},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MonetGPT: Solving puzzles enhances MLLMs' image retouching skills. <em>TOG</em>, <em>44</em>(4), 1-12. (<a href='https://doi.org/10.1145/3730926'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retouching is an essential task in post-manipulation of raw photographs. Generative editing, guided by text or strokes, provides a new tool accessible to users but can easily change the identity of the original objects in unacceptable and unpredictable ways. In contrast, although traditional procedural edits, as commonly supported by photoediting tools (e.g., Gimp, Lightroom), are conservative, they are still preferred by professionals. Unfortunately, professional quality retouching involves many individual procedural editing operations that is challenging to plan for most novices. In this paper, we ask if a multimodal large language model (MLLM) can be taught to critique raw photographs, suggest suitable remedies, and finally realize them with a given set of pre-authored procedural image operations. We demonstrate that MLLMs can be first made aware of the underlying image processing operations, by training them to solve specially-designed visual puzzles. Subsequently, such an operation-aware MLLM can both plan and propose edit sequences. To facilitate training, given a set of expert-edited photos, we synthesize a reasoning dataset by procedurally manipulating the expert edits and then grounding a pretrained LLM on the visual adjustments, to synthesize reasoning for finetuning. The proposed retouching operations are, by construction, understandable by the users, preserve object details and resolution, and can be optionally overridden. We evaluate our setup on a variety of test examples and show advantages, in terms of explainability and identity preservation, over existing generative and other procedural alternatives. Code, data, models, and supplementary results can be found via our project website at https://monetgpt.github.io.},
  archive      = {J_TOG},
  author       = {Niladri Shekhar Dutt and Duygu Ceylan and Niloy J. Mitra},
  doi          = {10.1145/3730926},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-12},
  shortjournal = {ACM Trans. Graph.},
  title        = {MonetGPT: Solving puzzles enhances MLLMs' image retouching skills},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-dimensional procedural wave noise. <em>TOG</em>, <em>44</em>(4), 1-15. (<a href='https://doi.org/10.1145/3730928'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While precise spectral control can be achieved through sparse convolution, corresponding state of the art noise models are typically too expensive for solid noise. We introduce an alternative, wave-based procedural noise model, fast enough to be used in any dimension. We express the noise in the spectral domain and then apply an inverse Fourier transform (FT), requiring the computation of a multidimensional integral. Our contribution is a novel, efficient way to perform this computation, using a sum of precomputed complex-valued hyperplanar wave-functions, oriented in random directions. We show that using suitable wave profiles and combination operators, our model is able to extend to 3D a number of Gaussian and non-Gaussian noises, including Gabor, by-example and Phasor noises, as well as generate novel cellular noises. Our versatile and controllable solid noise model is very compact, a key feature for complex power spectrum and animated noises. We illustrate this through the design of 2D, 3D, and 3D+t materials using color, transparency and style transfer functions.},
  archive      = {J_TOG},
  author       = {Pascal Guehl and Rémi Allègre and Guillaume Gilet and Basile Sauvage and Marie-Paule Cani and Jean-Michel Dischler},
  doi          = {10.1145/3730928},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-15},
  shortjournal = {ACM Trans. Graph.},
  title        = {Multi-dimensional procedural wave noise},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tiny is not small enough: High quality, low-resource facial animation models through hybrid knowledge distillation. <em>TOG</em>, <em>44</em>(4), 1-18. (<a href='https://doi.org/10.1145/3730929'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The training of high-quality, robust machine learning models for speech-driven 3D facial animation requires a large, diverse dataset of high-quality audio-animation pairs. To overcome the lack of such a dataset, recent work has introduced large pre-trained speech encoders that are robust to variations in the input audio and, therefore, enable the facial animation model to generalize across speakers, audio quality, and languages. However, the resulting facial animation models are prohibitively large and lend themselves only to offline inference on a dedicated machine. In this work, we explore on-device, real-time facial animation models in the context of game development. We overcome the lack of large datasets by using hybrid knowledge distillation with pseudo-labeling. Given a large audio dataset, we employ a high-performing teacher model to train very small student models. In contrast to the pre-trained speech encoders, our student models only consist of convolutional and fully-connected layers, removing the need for attention context or recurrent updates. In our experiments, we demonstrate that we can reduce the memory footprint to up to 3.4 MB and required future audio context to up to 81 ms while maintaining high-quality animations. This paves the way for on-device inference, an important step towards realistic, model-driven digital characters.},
  archive      = {J_TOG},
  author       = {Zhen Han and Mattias Teye and Derek Yadgaroff and Judith Bütepage},
  doi          = {10.1145/3730929},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-18},
  shortjournal = {ACM Trans. Graph.},
  title        = {Tiny is not small enough: High quality, low-resource facial animation models through hybrid knowledge distillation},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). One model to rig them all: Diverse skeleton rigging with UniRig. <em>TOG</em>, <em>44</em>(4), 1-18. (<a href='https://doi.org/10.1145/3730930'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid evolution of 3D content creation, encompassing both AI-powered methods and traditional workflows, is driving an unprecedented demand for automated rigging solutions that can keep pace with the increasing complexity and diversity of 3D models. We introduce UniRig , a novel, unified framework for automatic skeletal rigging that leverages the power of large autoregressive models and a bone-point cross-attention mechanism to generate both high-quality skeletons and skinning weights. Unlike previous methods that struggle with complex or non-standard topologies, UniRig accurately predicts topologically valid skeleton structures thanks to a new Skeleton Tree Tokenization method that efficiently encodes hierarchical relationships within the skeleton. To train and evaluate UniRig, we present Rig-XL , a new large-scale dataset of over 14,000 rigged 3D models spanning a wide range of categories. UniRig significantly outperforms state-of-the-art academic and commercial methods, achieving a 215% improvement in rigging accuracy and a 194% improvement in motion accuracy on challenging datasets. Our method works seamlessly across diverse object categories, from detailed anime characters to complex organic and inorganic structures, demonstrating its versatility and robustness. By automating the tedious and time-consuming rigging process, UniRig has the potential to speed up animation pipelines with unprecedented ease and efficiency. Project Page: https://zjp-shadow.github.io/works/UniRig/},
  archive      = {J_TOG},
  author       = {Jia-Peng Zhang and Cheng-Feng Pu and Meng-Hao Guo and Yan-Pei Cao and Shi-Min Hu},
  doi          = {10.1145/3730930},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-18},
  shortjournal = {ACM Trans. Graph.},
  title        = {One model to rig them all: Diverse skeleton rigging with UniRig},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). C-tubes: Design and optimization of tubular structures composed of developable strips. <em>TOG</em>, <em>44</em>(4), 1-19. (<a href='https://doi.org/10.1145/3730933'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce C-tubes , 3D tubular structures composed of developable surface strips. C-tubes can be understood as a generalization of Monge surfaces—a special class of sweep surfaces—towards the recently introduced conenets. This observation allows formulating a constructive algorithm to create tubular structures that ensures developability of the constituent surfaces, while significantly broadening the design space. Our novel form-finding tool enables design exploration by solving for the input variables of the constructive algorithm so that the C-tube best conforms to user-specified objectives. We discuss several case studies that illustrate the versatility of our approach for the design and fabrication of complex structures, with applications in architecture, furniture, and lighting design.},
  archive      = {J_TOG},
  author       = {Michele Vidulis and Klara Mundilova and Quentin Becker and Florin Isvoranu and Mark Pauly},
  doi          = {10.1145/3730933},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-19},
  shortjournal = {ACM Trans. Graph.},
  title        = {C-tubes: Design and optimization of tubular structures composed of developable strips},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WishGI: Lightweight static global illumination baking via spherical harmonics fitting. <em>TOG</em>, <em>44</em>(4), 1-12. (<a href='https://doi.org/10.1145/3730935'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global illumination combines direct and indirect lighting to create realistic lighting effects, bringing virtual scenes closer to reality. Static global illumination is a crucial component of virtual scene rendering, leveraging precomputation and baking techniques to significantly reduce runtime computational costs. Unfortunately, many existing works prioritize visual quality by relying on extensive texture storage and massive pixel-level texture sampling, leading to large performance overhead. In this paper, we introduce an illumination reconstruction method that effectively reduces sampling in fragment shader and avoids additional render passes, making it well-suited for low-end platforms. To achieve high-quality global illumination with reduced memory usage, we adopt a spherical harmonics fitting approach for baking effective illumination information and propose an inverse probe distribution method that generates unique probe associations for each mesh. This association, which can be generated offline in the local space, ensures consistent lighting quality across all instances of the same mesh. As a consequence, our method delivers highly competitive lighting effects while using only approximately 5% of the memory required by mainstream industry techniques.},
  archive      = {J_TOG},
  author       = {Junke Zhu and Zehan Wu and Qixing Zhang and Cheng Liao and Zhangjin Huang},
  doi          = {10.1145/3730935},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-12},
  shortjournal = {ACM Trans. Graph.},
  title        = {WishGI: Lightweight static global illumination baking via spherical harmonics fitting},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer IMU calibrator: Dynamic on-body IMU calibration for inertial motion capture. <em>TOG</em>, <em>44</em>(4), 1-14. (<a href='https://doi.org/10.1145/3730937'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel dynamic calibration method for sparse inertial motion capture systems, which is the first to break the restrictive absolute static assumption in IMU calibration, i.e., the coordinate drift R G′ G and measurement offset R BS remain constant during the entire motion, thereby significantly expanding their application scenarios. Specifically, we achieve real-time estimation of R G′ G and R BS under two relaxed assumptions: i) the matrices change negligibly in a short time window; ii) the human movements/IMU readings are diverse in such a time window. Intuitively, the first assumption reduces the number of candidate matrices, and the second assumption provides diverse constraints, which greatly reduces the solution space and allows for accurate estimation of R G′ G and R BS from a short history of IMU readings in real time. To achieve this, we created synthetic datasets of paired R G′ G , R BS matrices and IMU readings, and learned their mappings using a Transformer-based model. We also designed a calibration trigger based on the diversity of IMU readings to ensure that assumption ii) is met before applying our method. To our knowledge, we are the first to achieve implicit IMU calibration (i.e., seamlessly putting IMUs into use without the need for an explicit calibration process), as well as the first to enable long-term and accurate motion capture using sparse IMUs. The code and dataset are available at https://github.com/ZuoCX1996/TIC.},
  archive      = {J_TOG},
  author       = {Chengxu Zuo and Jiawei Huang and Xiao Jiang and Yuan Yao and Xiangren Shi and Rui Cao and Xinyu Yi and Feng Xu and Shihui Guo and Yipeng Qin},
  doi          = {10.1145/3730937},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-14},
  shortjournal = {ACM Trans. Graph.},
  title        = {Transformer IMU calibrator: Dynamic on-body IMU calibration for inertial motion capture},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HexHex: Highspeed extraction of hexahedral meshes. <em>TOG</em>, <em>44</em>(4), 1-20. (<a href='https://doi.org/10.1145/3730940'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern hexahedral mesh generation relies on integer-grid maps (IGM), which map the Cartesian grid of integer iso-surfaces to a structure-aligned and conforming hexahedral cell complex discretizing the target shape. The hexahedral mesh is formed by iso-surfaces of the map such that an extraction algorithm is needed to convert the implicit map representation into an explicit mesh. State-of-the-art algorithms have been designed with two goals in mind, i.e., (i) unconditional robustness and (ii) tolerance to map defects in the form of inverted or degenerate tetrahedra. Because of significant advancements in the generation of locally injective maps, the tolerance to map defects has become irrelevant. At the same time, there is a growing demand for efficiently handling significantly larger mesh complexities, unfortunately not well served by the state-of-the-art since the tolerance to map defects induces a high runtime cost. Consequently, we present HexHex, a novel (unconditionally robust) hexahedral mesh extraction algorithm for locally injective integer-grid maps designed for maximal performance and scalability. Key contributions include a novel and highly compact mesh data structure based on so-called propellers and a conservative rasterization technique, significantly reducing the number of required exact predicate tests. HexHex not only offers lower asymptotic runtime complexities from a theoretical perspective but also lower constants, enabling in practice a 30x speedup for medium-sized examples and a larger speedup for more complex inputs, specifically when the hex-to-tet ratio is large. We provide a C++ reference implementation, supporting multi-core parallelization and the extraction of curved (piecewise-linear) hexahedral mesh edges and faces, e.g., valuable for subsequent higher-order mesh generation.},
  archive      = {J_TOG},
  author       = {Tobias Kohler and Martin Heistermann and David Bommes},
  doi          = {10.1145/3730940},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-20},
  shortjournal = {ACM Trans. Graph.},
  title        = {HexHex: Highspeed extraction of hexahedral meshes},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conformal first passage for epsilon-free walk-on-spheres. <em>TOG</em>, <em>44</em>(4), 1-11. (<a href='https://doi.org/10.1145/3730942'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, grid-free Monte Carlo methods have gained increasing popularity for solving fundamental partial differential equations. For a given point in the domain, the Walk-on-Spheres method solves a boundary integral equation by integrating recursively over the largest possible sphere. When the walks approach boundaries with Dirichlet conditions, the number of path vertices increases considerably, since the step size becomes smaller with decreasing distance to the boundary. In practice, the walks are terminated once they reach an epsilon-shell around the boundary. This, however, introduces bias, leading to a trade-off between accuracy and performance. Instead of using spheres, we propose to utilize geometric primitives that share more than one point with the boundary to increase the likelihood of immediately terminating. Along the boundary of those new geometric primitives a sampling probability is needed, which corresponds to the exit probability of a Brownian motion. This is known as a first passage problem. Utilizing that Laplace equations are invariant under conformal maps, we transform exit points from unit circles to the exit points of our geometric primitives, for which we describe a suitable placement strategy. With this, we obtain a novel approach to solve the Laplace equation in two dimensions, which does not require an epsilon-shell, significantly reduces the number of path vertices, and reduces inaccuracies near Dirichlet boundaries.},
  archive      = {J_TOG},
  author       = {Paul Himmler and Tobias Günther},
  doi          = {10.1145/3730942},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-11},
  shortjournal = {ACM Trans. Graph.},
  title        = {Conformal first passage for epsilon-free walk-on-spheres},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NAM: Neural adjoint maps for refining shape correspondences. <em>TOG</em>, <em>44</em>(4), 1-15. (<a href='https://doi.org/10.1145/3730943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel approach to refine 3D shape correspondences by leveraging multi-layer perceptions within the framework of functional maps. Central to our contribution is the concept of Neural Adjoint Maps , a novel neural representation that generalizes the traditional solution of functional maps for estimating correspondence between manifolds. Fostering our neural representation, we propose an iterative algorithm explicitly designed to enhance the precision and robustness of shape correspondence across diverse modalities such as meshes and point clouds. By harnessing the expressive power of non-linear solutions, our method captures intricate geometric details and feature correspondences that conventional linear approaches often overlook. Extensive evaluations on standard benchmarks and challenging datasets demonstrate that our approach achieves state-of-the-art accuracy for both isometric and non-isometric meshes and for point clouds where traditional methods frequently struggle. Moreover, we show the versatility of our method in tasks such as signal and neural field transfer, highlighting its broad applicability to domains including computer graphics, medical imaging, and other fields demanding precise transfer of information among 3D shapes. Our work sets a new standard for shape correspondence refinement, offering robust tools across various applications.},
  archive      = {J_TOG},
  author       = {Giulio Viganò and Maks Ovsjanikov and Simone Melzi},
  doi          = {10.1145/3730943},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-15},
  shortjournal = {ACM Trans. Graph.},
  title        = {NAM: Neural adjoint maps for refining shape correspondences},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Painless differentiable rotation dynamics. <em>TOG</em>, <em>44</em>(4), 1-13. (<a href='https://doi.org/10.1145/3730944'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose the formulation of forward and differentiable rigid-body dynamics using Lie-algebra rotation derivatives. In particular, we show how this approach can easily be applied to incremental-potential formulations of forward dymamics, and we introduce a novel definition of adjoints for differentiable dynamics. In contrast to other parameterizations of rotations (notably the popular rotation-vector parameterization), our approach leads to painlessly simple and compact derivatives, better conditioning, and higher runtime efficiency. We demonstrate our approach on fundamental rigid-body problems, but also on Cosserat rods as an example of multi-rigid-body dynamics.},
  archive      = {J_TOG},
  author       = {Magí Romanyà-Serrasolsas and Juan J. Casafranca and Miguel A. Otaduy},
  doi          = {10.1145/3730944},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-13},
  shortjournal = {ACM Trans. Graph.},
  title        = {Painless differentiable rotation dynamics},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geometric contact potential. <em>TOG</em>, <em>44</em>(4), 1-24. (<a href='https://doi.org/10.1145/3731142'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Barrier potentials gained popularity as a means for robust contact handling in physical modeling and for modeling self-avoiding shapes. The key to the success of these approaches is adherence to geometric constraints, i.e., avoiding intersections, which are the cause of most robustness problems in complex deformation simulation with contact. However, existing barrier-potential methods may lead to spurious forces and imperfect satisfaction of the geometric constraints. They may have strong resolution dependence, requiring careful adaptation of the potential parameters to the object discretizations. We present a systematic derivation of a continuum potential defined for smooth and piecewise smooth surfaces, starting from identifying a set of natural requirements for contact potentials, including the barrier property, locality, differentiable dependence on shape, and absence of forces in rest configurations. Our potential is formulated independently of surface discretization and addresses the shortcomings of existing potential-based methods while retaining their advantages. We present a discretization of our potential that is a drop-in replacement for the potential used in the incremental potential contact formulation [Li et al. 2020], and compare its behavior to other potential formulations, demonstrating that it has the expected behavior. The presented formulation connects existing barrier approaches, as all recent existing methods can be viewed as a variation of the presented potential, and lays a foundation for developing alternative (e.g., higher-order) versions.},
  archive      = {J_TOG},
  author       = {Zizhou Huang and Maxwell Paik and Zachary Ferguson and Daniele Panozzo and Denis Zorin},
  doi          = {10.1145/3731142},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-24},
  shortjournal = {ACM Trans. Graph.},
  title        = {Geometric contact potential},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single edge collapse quad-dominant mesh reduction. <em>TOG</em>, <em>44</em>(4), 1-23. (<a href='https://doi.org/10.1145/3731143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mesh reduction using quadric error metrics is the industry standard for producing level-of-detail (LOD) geometry for meshes. Although industry tools produce visually excellent LODs, mesh topology is often ruined during decimation. This is because tools focus on triangle simplification and preserving rendered appearance, whereas artists often produce quad dominant meshes with clean edge topology. Artist created manual LODs preserve both appearance and quad topology. Furthermore, most existing tools for quad decimation only accept pure quad meshes and cannot handle any triangles. The gap between quad and triangular mesh decimation is because they are built on fundamentally different operations, triangle simplification uses single edge collapses, whereas quad decimation requires that entire sets of edges be collapsed atomically. In this work, we demonstrate that single edge collapse can be used to preserve most input quads without degrading geometric quality. Single edge collapse quad preservation is made possible by introducing dihedral-angle weighted quadrics for every edge, allowing optimization to evenly space edges while preserving features. It is further enabled by explicitly ordering edge collapses with nearly equivalent quadric error in a way that preserves quad topology. In addition to quad preservation, we demonstrate that by introducing weights for quadrics on certain edges, our framework can be used to preserve symmetry and joint influences. To demonstrate our approach is suitable for skinned mesh decimation on triangle meshes, we show that QEM with attributes can preserve joint influences better than prior work. We implement and test our approach on 67 static and 19 animated meshes from Sketchfab. On both static and animated meshes, our approach consistently outperforms prior work with lower Chamfer and Hausdorff distance, while preserving more quad topology when present.},
  archive      = {J_TOG},
  author       = {Julian Knodt},
  doi          = {10.1145/3731143},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-23},
  shortjournal = {ACM Trans. Graph.},
  title        = {Single edge collapse quad-dominant mesh reduction},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple importance reweighting for path guiding. <em>TOG</em>, <em>44</em>(4), 1-11. (<a href='https://doi.org/10.1145/3731144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contemporary path guiding employs an iterative training scheme to fit radiance distributions. However, existing methods combine the estimates generated in each iteration merely within image space, overlooking differences in the convergence of distribution fitting over individual light paths. This paper formulates the estimation combination task as a path reweighting process. To compute spatio-directional varying combination weights, we propose multiple importance reweighting , leveraging the importance distributions from multiple guiding iterations. We demonstrate that our proposed path-level reweighting makes guiding algorithms less sensitive to noise and overfitting in distributions. This facilitates a finer subdivision of samples both spatially and temporally (i.e., over iterations), which leads to additional improvements in the accuracy of distributions and samples. Inspired by adaptive multiple importance sampling (AMIS), we introduce a simple yet effective mixture-based weighting scheme with theoretically guaranteed consistency, demonstrating good practical performance compared to alternative weighting schemes. To further foster usage with high sample rates, we introduce a hyperparameter that controls the size of sample storage. When this size limit is exceeded, low-valued samples are splatted during rendering and reweighted using a partial mixture of distributions. We found limiting the storage size reduces memory overhead and keeps variance reduction and bias comparable to the unlimited ones. Our method is largely agnostic to the underlying guiding method and compatible with conventional pixel reweighting techniques. Extensive evaluations underscore the feasibility of our approach in various scenes, achieving variance reduction with negligible bias over state-of-the-art solutions within equal sample rates and rendering time.},
  archive      = {J_TOG},
  author       = {Zhimin Fan and Yiming Wang and Chenxi Zhou and Ling-Qi Yan and Yanwen Guo and Jie Guo},
  doi          = {10.1145/3731144},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-11},
  shortjournal = {ACM Trans. Graph.},
  title        = {Multiple importance reweighting for path guiding},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bernstein bounds for caustics. <em>TOG</em>, <em>44</em>(4), 1-15. (<a href='https://doi.org/10.1145/3731145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Systematically simulating specular light transport requires an exhaustive search for triangle tuples containing admissible paths. Given the extreme inefficiency of enumerating all combinations, we significantly reduce the search domain by stochastically sampling such tuples. The challenge is to design proper sampling probabilities that keep the noise level controllable. Our key insight is that by bounding the irradiance contributed by each triangle tuple at a given position, we can sample a subset of triangle tuples with potentially high contributions. Although low-contribution tuples are assigned a negligible probability, the overall variance remains low. Therefore, we derive position and irradiance bounds for caustics casted by each triangle tuple, introducing a bounding property of rational functions on a Bernstein basis. When formulating position and irradiance expressions into rational functions, we handle non-rational parts through remainder variables to maintain bounding validity. Finally, we carefully design the sampling probabilities by optimizing the upper bound of the variance, expressed only using the position and irradiance bounds. The bound-driven sampling of triangle tuples is intrinsically unbiased even without defensive sampling. It can be combined with various unbiased and biased root-finding techniques within a local triangle domain. Extensive evaluations show that our method enables the fast and reliable rendering of complex caustics effects. Yet, our method is efficient for no more than two specular vertices, where complexity grows sublinearly to the number of triangles and linearly to that of emitters, and does not consider the Fresnel and visibility terms. We also rely on parameters to control subdivisions.},
  archive      = {J_TOG},
  author       = {Zhimin Fan and Chen Wang and Yiming Wang and Boxuan Li and Yuxuan Guo and Ling-Qi Yan and Yanwen Guo and Jie Guo},
  doi          = {10.1145/3731145},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-15},
  shortjournal = {ACM Trans. Graph.},
  title        = {Bernstein bounds for caustics},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quadric-based silhouette sampling for differentiable rendering. <em>TOG</em>, <em>44</em>(4), 1-20. (<a href='https://doi.org/10.1145/3731146'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physically based differentiable rendering has established itself as key to inverse rendering, in which scenes are recovered from images through gradient-based optimization. Taking the derivative of the rendering equation is made difficult by the presence of discontinuities in the integrand at object silhouettes. To obtain correct derivatives w.r.t. changing geometry, accounting e.g. for changing penumbras or silhouettes in glossy reflections, differentiable renderers must compute an integral over these silhouettes. Prior work proposed importance sampling of silhouette edges for a given shading point. The main challenge is to efficiently reject parts of the mesh without silhouettes during sampling, which has been done using top-down traversal of a tree. Inaccuracies of this existing rejection procedure result in many samples with zero contribution. Thus, variance remains high and subsequent work has focused on alternatives such as area sampling or path space differentiable rendering. We propose an improved rejection test. It reduces variance substantially, which makes edge sampling in a unidirectional path tracer competitive again. Our rejection test relies on two approximations to the triangle planes of a mesh patch: A bounding box in dual space and dual quadrics. Additionally, we improve the heuristics used for stochastic traversal of the tree. We evaluate our method in a unidirectional path tracer and achieve drastic improvements over the original edge sampling and outperform methods based on area sampling.},
  archive      = {J_TOG},
  author       = {Mariia Soroka and Christoph Peters and Steve Marschner},
  doi          = {10.1145/3731146},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-20},
  shortjournal = {ACM Trans. Graph.},
  title        = {Quadric-based silhouette sampling for differentiable rendering},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linear-time transport with rectified flows. <em>TOG</em>, <em>44</em>(4), 1-13. (<a href='https://doi.org/10.1145/3731147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matching probability distributions allows to compare or interpolate them, or model their manifold. Optimal transport is a tool that solves this matching problem. However, despite the development of numerous exact and approximate algorithms, these approaches remain too slow for large datasets due to the inherent challenge of optimizing transport plans. Taking intuitions from recent advances in rectified flows we propose an algorithm that, while not resulting in optimal transport plans, produces transport plans from uniform densities to densities stored on grids that resemble the optimal ones in practice. Our algorithm has linear-time complexity with respect to the problem size and is embarrassingly parallel. It is also trivial to implement, essentially computing three summed-area tables and advecting particles with velocities easily computed from these tables using simple arithmetic. This already allows for applications such as stippling and area-preserving mesh parameterization. Combined with linearized transport ideas, we further extend our approach to match two non-uniform distributions. This allows for wider applications such as shape interpolation or barycenters, matching the quality of more complex optimal or approximate transport solvers while resulting in orders of magnitude speedups. We illustrate our applications in 2D and 3D.},
  archive      = {J_TOG},
  author       = {Khoa Do and David Coeurjolly and Pooran Memari and Nicolas Bonneel},
  doi          = {10.1145/3731147},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-13},
  shortjournal = {ACM Trans. Graph.},
  title        = {Linear-time transport with rectified flows},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Shape space spectra. <em>TOG</em>, <em>44</em>(4), 1-16. (<a href='https://doi.org/10.1145/3731148'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eigenanalysis of differential operators, such as the Laplace operator or elastic energy Hessian, is typically restricted to a single shape and its discretization, limiting reduced order modeling (ROM). We introduce the first eigenanalysis method for continuously parameterized shape families. Given a parametric shape, our method constructs spatial neural fields that represent eigen-functions across the entire shape space. It is agnostic to the specific shape representation, requiring only an inside/outside indicator function that depends on shape parameters. Eigenfunctions are computed by minimizing a variational principle over nested spaces with orthogonality constraints. Since eigenvalues may swap dominance at points of multiplicity, we jointly train multiple eigenfunctions while dynamically reordering them based on their eigenvalues at each step. Through causal gradient filtering , this reordering is reflected in backpropagation. Our method enables applications to operate over shape space, providing a single ROM that encapsulates vibration modes for all shapes, including previously unseen ones. Since our eigenanalysis is differentiable with respect to shape parameters, it facilitates eigenfunction-aware shape optimization. We evaluate our approach on shape optimization for sound synthesis and locomotion, as well as reduced-order modeling for elastodynamic simulation.},
  archive      = {J_TOG},
  author       = {Yue Chang and Otman Benchekroun and Maurizio M. Chiaramonte and Peter Yichen Chen and Eitan Grinspun},
  doi          = {10.1145/3731148},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-16},
  shortjournal = {ACM Trans. Graph.},
  title        = {Shape space spectra},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RigAnything: Template-free autoregressive rigging for diverse 3D assets. <em>TOG</em>, <em>44</em>(4), 1-12. (<a href='https://doi.org/10.1145/3731149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present RigAnything , a novel autoregressive transformer-based model, which makes 3D assets rig-ready by probabilistically generating joints and skeleton topologies and assigning skinning weights in a template-free manner. Unlike most existing auto-rigging methods, which rely on predefined skeleton templates and are limited to specific categories like humanoid, RigAnything approaches the rigging problem in an autoregressive manner, iteratively predicting the next joint based on the global input shape and the previous prediction. While autoregressive models are typically used to generate sequential data, RigAnything extends its application to effectively learn and represent skeletons, which are inherently tree structures. To achieve this, we organize the joints in a breadth-first search (BFS) order, enabling the skeleton to be defined as a sequence of 3D locations and the parent index. Furthermore, our model improves the accuracy of position prediction by leveraging diffusion modeling, ensuring precise and consistent placement of joints within the hierarchy. This formulation allows the autoregressive model to efficiently capture both spatial and hierarchical relationships within the skeleton. Trained end-to-end on both RigNet and Objaverse datasets, RigAnything demonstrates state-of-the-art performance across diverse object types, including humanoids, quadrupeds, marine creatures, insects, and many more, surpassing prior methods in quality, robustness, generalizability, and efficiency. It achieves significantly faster performance than existing auto-rigging methods, completing rigging in under a few seconds per shape.},
  archive      = {J_TOG},
  author       = {Isabella Liu and Zhan Xu and Wang Yifan and Hao Tan and Zexiang Xu and Xiaolong Wang and Hao Su and Zifan Shi},
  doi          = {10.1145/3731149},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-12},
  shortjournal = {ACM Trans. Graph.},
  title        = {RigAnything: Template-free autoregressive rigging for diverse 3D assets},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A monte carlo rendering framework for simulating optical heterodyne detection. <em>TOG</em>, <em>44</em>(4), 1-19. (<a href='https://doi.org/10.1145/3731150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical heterodyne detection (OHD) employs coherent light and optical interference techniques (Fig. 1-(A)) to extract physical parameters, such as velocity or distance, which are encoded in the frequency modulation of the light. With its superior signal-to-noise ratio compared to incoherent detection methods, such as time-of-flight lidar, OHD has become integral to applications requiring high sensitivity, including autonomous navigation, atmospheric sensing, and biomedical velocimetry. However, current simulation tools for OHD focus narrowly on specific applications, relying on domain-specific settings like restricted reflection functions, scene configurations, or single-bounce assumptions, which limit their applicability. In this work, we introduce a flexible and general framework for spectral-domain simulation of OHD. We demonstrate that classical radiometry-based path integral formulation can be adapted and extended to simulate the OHD measurements in the spectral domain. This enables us to leverage the rich modeling and sampling capabilities of existing Monte Carlo path tracing techniques. Our formulation shares structural similarities with transient rendering but operates in the spectral domain and accounts for the Doppler effect (Fig. 1-(B)). While simulators for the Doppler effect in incoherent (intensity) detection methods exist, they are largely not suitable to simulate OHD. We use a microsurface interpretation to show that these two Doppler imaging techniques capture different physical quantities and thus need different simulation frameworks. We validate the correctness and predictive power of our simulation framework by qualitatively comparing the simulations with real-world captured data for three different OHD applications—FMCW lidar, blood flow velocimetry, and wind Doppler lidar (Fig. 1-(C)).},
  archive      = {J_TOG},
  author       = {Juhyeon Kim and Craig Benko and Magnus Wrenninge and Ryusuke Villemin and Zeb Barber and Wojciech Jarosz and Adithya Pediredla},
  doi          = {10.1145/3731150},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-19},
  shortjournal = {ACM Trans. Graph.},
  title        = {A monte carlo rendering framework for simulating optical heterodyne detection},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). C5D: Sequential continuous convex collision detection using cone casting. <em>TOG</em>, <em>44</em>(4), 1-14. (<a href='https://doi.org/10.1145/3731151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In physics-based simulation of rigid or nearly rigid objects, collisions often become the primary performance bottleneck, particularly when enforcing intersection-free constraints. Previous simulation frameworks rely on primitive-level CCD algorithms. Due to the large number of colliding surface primitives to process, those methods are computationally intensive and heavily dependent on advanced parallel computing resources such as GPUs, which are often inaccessible due to competing tasks or capped threading capacity in applications like policy training for robotics. To address these limitations, we propose a sequential CCD algorithm for convex shapes undergoing constant affine motion. This approach uses the conservative advancement method to iteratively refine a lower-bound estimate of the TOI, exploiting the linearity of affine motion and the efficiency of convex shape distance computation. Our CCD algorithm integrates seamlessly into the ABD framework, achieving a 10-fold speed-up over primitive-level CCD. Its high single-threaded efficiency further enables significant throughput improvements via scene-level parallelism, making it well-suited for resource-constrained environments.},
  archive      = {J_TOG},
  author       = {Xiaodi Yuan and Fanbo Xiang and Yin Yang and Hao Su},
  doi          = {10.1145/3731151},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-14},
  shortjournal = {ACM Trans. Graph.},
  title        = {C5D: Sequential continuous convex collision detection using cone casting},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving partial differential equations in participating media. <em>TOG</em>, <em>44</em>(4), 1-21. (<a href='https://doi.org/10.1145/3731152'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of solving partial differential equations (PDEs) in domains with complex microparticle geometry that is impractical, or intractable, to model explicitly. Drawing inspiration from volume rendering, we propose tackling this problem by treating the domain as a participating medium that models microparticle geometry stochastically , through aggregate statistical properties (e.g., particle density). We first introduce the problem setting of PDE simulation in participating media. We then specialize to exponential media and describe the properties that make them an attractive model of microparticle geometry for PDE simulation problems. We use these properties to develop two new algorithms, volumetric walk on spheres and volumetric walk on stars , that generalize previous Monte Carlo algorithms to enable efficient and discretization-free simulation of linear elliptic PDEs (e.g., Laplace) in participating media. We demonstrate experimentally that our algorithms can solve Laplace boundary value problems with complex microparticle geometry more accurately and more efficiently than previous approaches, such as ensemble averaging and homogenization.},
  archive      = {J_TOG},
  author       = {Bailey Miller and Rohan Sawhney and Keenan Crane and Ioannis Gkioulekas},
  doi          = {10.1145/3731152},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-21},
  shortjournal = {ACM Trans. Graph.},
  title        = {Solving partial differential equations in participating media},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VR-doh: Hands-on 3D modeling in virtual reality. <em>TOG</em>, <em>44</em>(4), 1-12. (<a href='https://doi.org/10.1145/3731154'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce VR-Doh, an open-source, hands-on 3D modeling system that enables intuitive creation and manipulation of elastoplastic objects in Virtual Reality (VR). By customizing the Material Point Method (MPM) for real-time simulation of hand-induced large deformations and enhancing 3D Gaussian Splatting for seamless rendering, VR-Doh provides an interactive and immersive 3D modeling experience. Users can naturally sculpt, deform, and edit objects through both contact- and gesture-based hand-object interactions. To achieve real-time performance, our system incorporates localized simulation techniques, particle-level collision handling, and the decoupling of physical and appearance representations, ensuring smooth and responsive interactions. VR-Doh supports both object creation and editing, enabling diverse modeling tasks such as designing food items, characters, and interlocking structures, all resulting in simulation-ready assets. User studies with both novice and experienced participants highlight the system's intuitive design, immersive feedback, and creative potential. Compared to existing geometric modeling tools, VR-Doh offers enhanced accessibility and natural interaction, making it a powerful tool for creative exploration in VR.},
  archive      = {J_TOG},
  author       = {Zhaofeng Luo and Zhitong Cui and Shijian Luo and Mengyu Chu and Minchen Li},
  doi          = {10.1145/3731154},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-12},
  shortjournal = {ACM Trans. Graph.},
  title        = {VR-doh: Hands-on 3D modeling in virtual reality},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CK-MPM: A compact-kernel material point method. <em>TOG</em>, <em>44</em>(4), 1-14. (<a href='https://doi.org/10.1145/3731155'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Material Point Method (MPM) has become a cornerstone of physics-based simulation, widely used in geomechanics and computer graphics for modeling phenomena such as granular flows, viscoelasticity, fracture mechanics, etc. Despite its versatility, the original MPM suffers from cell-crossing instabilities caused by discontinuities in particle-grid transfer kernels. Existing solutions mostly mitigate these issues by adopting smoother shape functions, but at the cost of increased numerical diffusion and computational overhead due to larger kernel support. In this paper, we propose a novel C 2 -continuous compact kernel for MPM that achieves a unique balance in terms of stability, accuracy, and computational efficiency. Our method integrates seamlessly with Affine Particle-In-Cell (APIC) and Moving Least Squares (MLS) MPM, while only doubling the number of grid nodes associated with each particle compared to linear kernels. At its core is an innovative dual-grid framework, which associates particles with grid nodes exclusively within the cells they occupy on two staggered grids, ensuring consistent and stable force computations. We demonstrate that our method can be conveniently implemented using a domain-specific language, Taichi, or based on open-source GPU MPM frameworks, achieving faster runtime and less numerical diffusion compared to quadratic B-spline MPM. Comprehensive validation through unit tests, comparative studies, and stress tests demonstrates the efficacy of our approach in conserving both linear and angular momentum, handling stiff materials, and scaling efficiently for large-scale simulations. Our results highlight the transformative potential of compact, high-order kernels in advancing MPM's capabilities for stable, accurate, and high-performance simulations.},
  archive      = {J_TOG},
  author       = {Michael Liu and Xinlei Wang and Minchen Li},
  doi          = {10.1145/3731155},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-14},
  shortjournal = {ACM Trans. Graph.},
  title        = {CK-MPM: A compact-kernel material point method},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topological offsets. <em>TOG</em>, <em>44</em>(4), 1-19. (<a href='https://doi.org/10.1145/3731157'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce Topological Offsets , a novel approach to generate manifold and self-intersection-free offset surfaces that are topologically equivalent to an offset infinitesimally close to the surface. Our approach, by construction, creates a manifold, watertight, and self-intersection-free offset surface strictly enclosing the input, while doing a best effort to move it to a prescribed distance from the input. Differently from existing approaches, we embed the input in a background mesh and insert a topological offset around the input with purely combinatorial operations. The topological offset is then inflated/deflated to match the user-prescribed distance while enforcing that no intersections or non-manifold configurations are introduced. We evaluate the effectiveness and robustness of our approach on the Thingi10k dataset, and show that topological offsets are beneficial in multiple graphics applications, including (1) converting non-manifold surfaces to manifold ones, (2) creating layered offsets, and (3) reliably computing finite offsets.},
  archive      = {J_TOG},
  author       = {Daniel Zint and Zhouyuan Chen and Yifei Zhu and Denis Zorin and Teseo Schneider and Daniele Panozzo},
  doi          = {10.1145/3731157},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-19},
  shortjournal = {ACM Trans. Graph.},
  title        = {Topological offsets},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AlignTex: Pixel-precise texture generation from multi-view artwork. <em>TOG</em>, <em>44</em>(4), 1-12. (<a href='https://doi.org/10.1145/3731158'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current 3D asset creation pipelines typically consist of three stages: creating multi-view concept art, producing 3D meshes based on the artwork, and painting textures for the meshes—an often labor-intensive process. Automated texture generation offers significant acceleration, but prior methods, which fine-tune 2D diffusion models with multi-view input images, often fail to preserve pixel-level details. These methods primarily emphasize semantic and subject consistency, which do not meet the requirements of artwork-guided texture workflows. To address this, we present AlignTex , a novel framework for generating high-quality textures from 3D meshes and multi-view artwork, ensuring both appearance detail and geometric consistency. AlignTex operates in two stages: aligned image generation and texture refinement. The core of our approach, AlignNet , resolves complex misalignments by extracting information from both the artwork and the mesh, generating images compatible with orthographic projection while maintaining geometric and visual fidelity. After projecting aligned images into the texture space, further refinement addresses seams and self-occlusion using an inpainting model and a geometry-aware texture dilation method. Experimental results demonstrate that AlignTex outperforms baseline methods in generation quality and efficiency, offering a practical solution to enhance 3D asset creation in gaming and film production.},
  archive      = {J_TOG},
  author       = {Yuqing Zhang and Hao Xu and Yiqian Wu and Sirui Chen and Sirui Lin and Xiang Li and Xifeng Gao and Xiaogang Jin},
  doi          = {10.1145/3731158},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-12},
  shortjournal = {ACM Trans. Graph.},
  title        = {AlignTex: Pixel-precise texture generation from multi-view artwork},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NeurCross: A neural approach to computing cross fields for quad mesh generation. <em>TOG</em>, <em>44</em>(4), 1-17. (<a href='https://doi.org/10.1145/3731159'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quadrilateral mesh generation plays a crucial role in numerical simulations within Computer-Aided Design and Engineering (CAD/E). Producing high-quality quadrangulation typically requires satisfying four key criteria. First, the quadrilateral mesh should closely align with principal curvature directions. Second, singular points should be strategically placed and effectively minimized. Third, the mesh should accurately conform to sharp feature edges. Lastly, quadrangulation results should exhibit robustness against noise and minor geometric variations. Existing methods generally involve first computing a regular cross field to represent quad element orientations across the surface, followed by extracting a quadrilateral mesh aligned closely with this cross field. A primary challenge with this approach is balancing the smoothness of the cross field with its alignment to pre-computed principal curvature directions, which are sensitive to small surface perturbations and often ill-defined in spherical or planar regions. To tackle this challenge, we propose NeurCross , a novel framework that simultaneously optimizes a cross field and a neural signed distance function (SDF), whose zero-level set serves as a proxy of the input shape. Our joint optimization is guided by three factors: faithful approximation of the optimized SDF surface to the input surface, alignment between the cross field and the principal curvature field derived from the SDF surface, and smoothness of the cross field. Acting as an intermediary, the neural SDF contributes in two essential ways. First, it provides an alternative, optimizable base surface exhibiting more regular principal curvature directions for guiding the cross field. Second, we leverage the Hessian matrix of the neural SDF to implicitly enforce cross field alignment with principal curvature directions, thus eliminating the need for explicit curvature extraction. Extensive experiments demonstrate that NeurCross outperforms the state-of-the-art methods in terms of singular point placement, robustness against surface noise and surface undulations, and alignment with principal curvature directions and sharp feature curves.},
  archive      = {J_TOG},
  author       = {Qiujie Dong and Huibiao Wen and Rui Xu and Shuangmin Chen and Jiaran Zhou and Shiqing Xin and Changhe Tu and Taku Komura and Wenping Wang},
  doi          = {10.1145/3731159},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-17},
  shortjournal = {ACM Trans. Graph.},
  title        = {NeurCross: A neural approach to computing cross fields for quad mesh generation},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generating past and future in digital painting processes. <em>TOG</em>, <em>44</em>(4), 1-13. (<a href='https://doi.org/10.1145/3731160'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a framework to generate past and future processes for drawing process videos. Given a canvas image uploaded by a user, the framework can generate both preceding and succeeding states of the drawing process, and the generated states can be reused as inputs for further state generation. We observe that the user queries typically have one-to-one or many-to-many states, and in many cases, involve non-contiguous states. This necessitates a backend that solves a set-to-set problem with arbitrary combinations of past or future states. To this end, we repurpose video diffusion models to learn the set-to-set mapping with pretrained video priors. We implement the system with strong diffusion transformer backbones ( e.g. , CogVideoX and LTXVideo) and high-quality data processing ( e.g. , sampling short shots from long videos of real drawing records). Experiments show that the generated states are diverse in drawing contexts and resemble human drawing processes. This capability may aid artists in visualizing potential outcomes, generating creative inspirations, or refining existing workflows.},
  archive      = {J_TOG},
  author       = {Lvmin Zhang and Chuan Yan and Yuwei Guo and Jinbo Xing and Maneesh Agrawala},
  doi          = {10.1145/3731160},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-13},
  shortjournal = {ACM Trans. Graph.},
  title        = {Generating past and future in digital painting processes},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic preconditioning for neural field optimization. <em>TOG</em>, <em>44</em>(4), 1-10. (<a href='https://doi.org/10.1145/3731161'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural fields are a highly effective representation across visual computing. This work observes that fitting these fields is greatly improved by incorporating spatial stochasticity during training, and that this simple technique can replace or even outperform custom-designed hierarchies and frequency-space constructions. The approach is formalized as implicitly operating on a blurred version of the field, evaluated in-expectation by sampling with Gaussian-distributed offsets. Querying the blurred field during optimization greatly improves convergence and robustness, akin to the role of preconditioners in numerical linear algebra. This implicit, sampling-based perspective fits naturally into the neural field paradigm, comes at no additional cost, and is extremely simple to implement. We describe the basic theory of this technique, including details such as handling boundary conditions, and extending to a spatially-varying blur. Experiments demonstrate this approach on representations including coordinate MLPs, neural hashgrids, triplanes, and more, across tasks including surface reconstruction and radiance fields. In settings where custom-designed hierarchies have already been developed, stochastic preconditioning nearly matches or improves their performance with a simple and unified approach; in settings without existing hierarchies it provides an immediate boost to quality and robustness.},
  archive      = {J_TOG},
  author       = {Selena Ling and Merlin Nimier-David and Alec Jacobson and Nicholas Sharp},
  doi          = {10.1145/3731161},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-10},
  shortjournal = {ACM Trans. Graph.},
  title        = {Stochastic preconditioning for neural field optimization},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic mesh processing on the GPU. <em>TOG</em>, <em>44</em>(4), 1-19. (<a href='https://doi.org/10.1145/3731162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a system for dynamic triangle mesh processing entirely on the GPU. Our system features an efficient data structure that enables rapid updates to mesh connectivity and attributes. By partitioning the mesh into small patches, we process all dynamic updates for each patch within the GPU's fast shared memory. This approach leverages speculative processing for conflict handling, minimizing rollback costs, maximizing parallelism, and reducing locking overhead. Additionally, we introduce a new programming model for dynamic mesh processing. This model provides concise semantics for dynamic updates, abstracting away concerns about conflicting updates during parallel execution. At the core of our model is the cavity operator , a general mesh update operator that facilitates any dynamic operation by removing a set of mesh elements and inserting new ones into the resulting void. We applied our system to various GPU applications, including isotropic remeshing, surface tracking, mesh decimation, and Delaunay edge flips. On large inputs, our system achieves an order-of-magnitude speedup compared to multi-threaded CPU solutions and is more than two orders of magnitude faster than state-of-the-art single-threaded CPU solutions. Furthermore, our data structure outperforms state-of-the-art GPU static data structures in terms of both speed and memory efficiency.},
  archive      = {J_TOG},
  author       = {Ahmed H. Mahmoud and Serban D. Porumbescu and John D. Owens},
  doi          = {10.1145/3731162},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-19},
  shortjournal = {ACM Trans. Graph.},
  title        = {Dynamic mesh processing on the GPU},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gaussian wave splatting for computer-generated holography. <em>TOG</em>, <em>44</em>(4), 1-13. (<a href='https://doi.org/10.1145/3731163'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art neural rendering methods optimize Gaussian scene representations from a few photographs for novel-view synthesis. Building on these representations, we develop an efficient algorithm, dubbed Gaussian Wave Splatting, to turn these Gaussians into holograms. Unlike existing computergenerated holography (CGH) algorithms, Gaussian Wave Splatting supports accurate occlusions and view-dependent effects for photorealistic scenes by leveraging recent advances in neural rendering. Specifically, we derive a closed-form solution for a 2D Gaussian-to-hologram transform that supports occlusions and alpha blending. Inspired by classic computer graphics techniques, we also derive an efficient approximation of the aforementioned process in the Fourier domain that is easily parallelizable and implement it using custom CUDA kernels. By integrating emerging neural rendering pipelines with holographic display technology, our Gaussian-based CGH framework paves the way for next-generation holographic displays.},
  archive      = {J_TOG},
  author       = {Suyeon Choi and Brian Chao and Jacqueline Yang and Manu Gopakumar and Gordon Wetzstein},
  doi          = {10.1145/3731163},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-13},
  shortjournal = {ACM Trans. Graph.},
  title        = {Gaussian wave splatting for computer-generated holography},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GenAnalysis: Joint shape analysis by learning man-made shape generators with deformation regularizations. <em>TOG</em>, <em>44</em>(4), 1-19. (<a href='https://doi.org/10.1145/3731164'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present GenAnalysis, an implicit shape generation framework that allows joint analysis of man-made shapes, including shape matching and joint shape segmentation. The key idea is to enforce an as-affine-as-possible (AAAP) deformation between synthetic shapes of the implicit generator that are close to each other in the latent space, which we achieve by designing a regularization loss. It allows us to understand the shape variation of each shape in the context of neighboring shapes and also offers structure-preserving interpolations between the input shapes. We show how to extract these shape variations by recovering piecewise affine vector fields in the tangent space of each shape. These vector fields provide single-shape segmentation cues. We then derive shape correspondences by iteratively propagating AAAP deformations across a sequence of intermediate shapes. These correspondences are then used to aggregate single-shape segmentation cues into consistent segmentations. We conduct experiments on the ShapeNet dataset to show superior performance in shape matching and joint shape segmentation over previous methods.},
  archive      = {J_TOG},
  author       = {Yuezhi Yang and Haitao Yang and Kiyohiro Nakayama and Xiangru Huang and Leonidas Guibas and Qixing Huang},
  doi          = {10.1145/3731164},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-19},
  shortjournal = {ACM Trans. Graph.},
  title        = {GenAnalysis: Joint shape analysis by learning man-made shape generators with deformation regularizations},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interspatial attention for efficient 4D human video generation. <em>TOG</em>, <em>44</em>(4), 1-16. (<a href='https://doi.org/10.1145/3731165'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating photorealistic videos of digital humans in a controllable manner is crucial for a plethora of applications. Existing approaches either build on methods that employ template-based 3D representations or emerging video generation models but suffer from poor quality or limited consistency and identity preservation when generating individual or multiple digital humans. In this paper, we introduce a new interspatial attention (ISA) mechanism as a scalable building block for modern diffusion transformer (DiT)-based video generation models. ISA is a new type of cross attention that uses relative positional encodings tailored for the generation of human videos. Leveraging a custom-developed video variation autoencoder, we train a latent ISA-based diffusion model on a large corpus of video data. Our model achieves state-of-the-art performance for 4D human video synthesis, demonstrating remarkable motion consistency and identity preservation while providing precise control of the camera and body poses. Our code and model are publicly released at https://dsaurus.github.io/isa4d/.},
  archive      = {J_TOG},
  author       = {Ruizhi Shao and Yinghao Xu and Yujun Shen and Ceyuan Yang and Yang Zheng and Changan Chen and Yebin Liu and Gordon Wetzstein},
  doi          = {10.1145/3731165},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-16},
  shortjournal = {ACM Trans. Graph.},
  title        = {Interspatial attention for efficient 4D human video generation},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DeFillet: Detection and removal of fillet regions in polygonal CAD models. <em>TOG</em>, <em>44</em>(4), 1-19. (<a href='https://doi.org/10.1145/3731166'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Filleting is a fundamental operation in CAD systems, akin to a ball rolling between two adjacent surface patches, resulting in a seamless connection. The reverse process, which we refer to as DeFillet in this paper, is crucial for CAE analysis and secondary design phases. However, it presents significant challenges, particularly when the input data originates from surface reconstruction or discretization processes. Our DeFillet algorithm is inspired by the observation that the rolling-ball center defines an osculating sphere, while the Voronoi diagram of surface samples provides sufficiently many rolling-ball center candidates. By leveraging this insight, we compute a transformation between the Voronoi vertices and the surface samples, enabling the efficient identification of fillet regions. Subsequently, we formulate the reconstruction of sharp features as a quadratic optimization problem. Our method's effectiveness has been validated through extensive testing using self-constructed models and 100 filleted models selected from the Fusion 360 Gallery dataset. The code for this paper is publicly available at https://github.com/xiaowuga/DeFillet.},
  archive      = {J_TOG},
  author       = {Jing-En Jiang and Hanxiao Wang and Mingyang Zhao and Dong-Ming Yan and Shuangmin Chen and Shiqing Xin and Changhe Tu and Wenping Wang},
  doi          = {10.1145/3731166},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-19},
  shortjournal = {ACM Trans. Graph.},
  title        = {DeFillet: Detection and removal of fillet regions in polygonal CAD models},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sketch2Anim: Towards transferring sketch storyboards into 3D animation. <em>TOG</em>, <em>44</em>(4), 1-15. (<a href='https://doi.org/10.1145/3731167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Storyboarding is widely used for creating 3D animations. Animators use the 2D sketches in storyboards as references to craft the desired 3D animations through a trial-and-error process. The traditional approach requires exceptional expertise and is both labor-intensive and time-consuming. Consequently, there is a high demand for automated methods that can directly translate 2D storyboard sketches into 3D animations. This task is under-explored to date and inspired by the significant advancements of motion diffusion models, we propose to address it from the perspective of conditional motion synthesis. We thus present Sketch2Anim , composed of two key modules for sketch constraint understanding and motion generation. Specifically, due to the large domain gap between the 2D sketch and 3D motion, instead of directly conditioning on 2D inputs, we design a 3D conditional motion generator that simultaneously leverages 3D keyposes, joint trajectories, and action words, to achieve precise and fine-grained motion control. Then, we invent a neural mapper dedicated to aligning user-provided 2D sketches with their corresponding 3D keyposes and trajectories in a shared embedding space, enabling, for the first time , direct 2D control of motion generation. Our approach successfully transfers storyboards into high-quality 3D motions and inherently supports direct 3D animation editing, thanks to the flexibility of our multi-conditional motion generator. Comprehensive experiments and evaluations, and a user perceptual study demonstrate the effectiveness of our approach. The code, data, trained models, and sketch-based motion designing interface are at https://zhongleilz.github.io/Sketch2Anim/.},
  archive      = {J_TOG},
  author       = {Lei Zhong and Chuan Guo and Yiming Xie and Jiawei Wang and Changjian Li},
  doi          = {10.1145/3731167},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-15},
  shortjournal = {ACM Trans. Graph.},
  title        = {Sketch2Anim: Towards transferring sketch storyboards into 3D animation},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transforming unstructured hair strands into procedural hair grooms. <em>TOG</em>, <em>44</em>(4), 1-20. (<a href='https://doi.org/10.1145/3731168'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, reconstruction methods have been developed that can recover strand-level hair geometry from images. However, these methods recover a vast number of individual hair strands that are difficult to edit and simulate. Many methods also rely on neural priors to infer non-visible inner hair, which can result in poor inner hair structure for complex hairstyles, such as curly hair. We propose an inverse hair grooming pipeline that transforms the imperfect 3D strands from these reconstruction methods into procedural hair grooms that consist of a small set of guide strands and hair grooming operators, inspired by pipelines used by artists in popular 3D modeling tools such as Blender and Houdini. We take a probabilistic view of these hair grooms and design various optimization strategies and loss functions to optimize for the guide strands and operator parameters. Due to the proceduralism, our resulting grooms can naturally represent challenging hairstyles, have structurally sound inner hair, and are easily editable.},
  archive      = {J_TOG},
  author       = {Wesley Chang and Andrew L. Russell and Stephane Grabli and Matt Jen-Yuan Chiang and Christophe Hery and Doug Roble and Ravi Ramamoorthi and Tzu-Mao Li and Olivier Maury},
  doi          = {10.1145/3731168},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-20},
  shortjournal = {ACM Trans. Graph.},
  title        = {Transforming unstructured hair strands into procedural hair grooms},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Controllable complex freezing dynamics simulation on thin films. <em>TOG</em>, <em>44</em>(4), 1-12. (<a href='https://doi.org/10.1145/3731170'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The freezing of thin films is a mesmerizing natural phenomenon, inspiring photographers to capture its beauty through their lenses and digital artists to recreate its allure using effects tools. In this paper, we present a novel method for physically simulating the intricate freezing dynamics on thin films. By accounting for the influence of phase and temperature changes on surface tension, our method reproduces Marangoni freezing and the "Snow-Globe Effect", characterized by swirling ice dendrites on the film. We introduce a novel Phase Map method on top of the state-of-the-art Moving Eulerian-Lagrangian Particles (MELP) meshless framework, enabling dendritic crystal simulation on mobile particles and offering precise control over freezing patterns. We demonstrate that our method is able to capture a wide range of dynamic freezing processes of soap bubbles and is stable for complex boundaries in our experiments.},
  archive      = {J_TOG},
  author       = {Yijie Liu and Taiyuan Zhang and Xiaoxiao Yan and Nuoming Liu and Bo Ren},
  doi          = {10.1145/3731170},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-12},
  shortjournal = {ACM Trans. Graph.},
  title        = {Controllable complex freezing dynamics simulation on thin films},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MyTimeMachine: Personalized facial age transformation. <em>TOG</em>, <em>44</em>(4), 1-16. (<a href='https://doi.org/10.1145/3731172'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial aging is a complex process, highly dependent on multiple factors like gender, ethnicity, lifestyle, etc., making it extremely challenging to learn a global aging prior to predict aging for any individual accurately. Existing techniques often produce realistic and plausible aging results, but the re-aged images often do not resemble the person's appearance at the target age and thus need personalization. In many practical applications of virtual aging, e.g. VFX in movies and TV shows, access to a personal photo collection of the user depicting aging in a small time interval (20~40 years) is often available. However, naive attempts to personalize global aging techniques on personal photo collections often fail. Thus, we propose MyTimeMachine (MyTM), a method that combines a global aging prior with a personalized photo collection (ranging from as few as 10 images, ideally 50) to learn individualized age transformations. We introduce a novel Adapter Network that combines personalized aging features with global aging features and generates a re-aged image with StyleGAN2. We also introduce three loss functions to personalize the Adapter Network with personalized aging loss, extrapolation regularization, and adaptive w-norm regularization. Our method demonstrates strong performance on fair-use imagery of widely recognizable individuals, producing photorealistic and identity-consistent age transformations that generalize well across diverse appearances. It also extends naturally to video, delivering high-quality, temporally consistent results that closely resemble actual appearances at target ages—outperforming state-of-the-art approaches.},
  archive      = {J_TOG},
  author       = {Luchao Qi and Jiaye Wu and Bang Gong and Annie N. Wang and David W. Jacobs and Roni Sengupta},
  doi          = {10.1145/3731172},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-16},
  shortjournal = {ACM Trans. Graph.},
  title        = {MyTimeMachine: Personalized facial age transformation},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IntrinsicEdit: Precise generative image manipulation in intrinsic space. <em>TOG</em>, <em>44</em>(4), 1-13. (<a href='https://doi.org/10.1145/3731173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative diffusion models have advanced image editing by delivering high-quality results through intuitive interfaces such as prompts, scribbles, and semantic drawing. However, these interfaces lack precise control, and associated editing methods often specialize in a single task. We introduce a versatile workflow for a range of editing tasks which operates in an intrinsic-image latent space, enabling semantic, local manipulation with pixel precision while automatically handling effects like reflections and shadows. We build on the RGB↔X diffusion framework and address its key deficiencies: the lack of identity preservation and the need to update multiple channels to achieve plausible results. We propose an edit-friendly diffusion inversion and prompt-embedding optimization to enable precise and efficient editing of only the relevant channels. Our method achieves identity preservation and resolves global illumination, without requiring task-specific model fine-tuning. We demonstrate state-of-the-art performance across a variety of tasks on complex images, including material adjustments, object insertion and removal, global relighting, and their combinations.},
  archive      = {J_TOG},
  author       = {Linjie Lyu and Valentin Deschaintre and Yannick Hold-Geoffroy and Miloš Hašan and Jae Shin Yoon and Thomas Leimkühler and Christian Theobalt and Iliyan Georgiev},
  doi          = {10.1145/3731173},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-13},
  shortjournal = {ACM Trans. Graph.},
  title        = {IntrinsicEdit: Precise generative image manipulation in intrinsic space},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unbiased differential visibility using fixed-step walk-on-spherical-caps and closest silhouettes. <em>TOG</em>, <em>44</em>(4), 1-16. (<a href='https://doi.org/10.1145/3731174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing derivatives of path integrals under evolving scene geometry is a fundamental problem in physics-based differentiable rendering, which requires differentiating discontinuities in the visibility function. Warped-area reparameterization is a powerful technique to compute differential visibility, and key is construction of a velocity field that is continuous in the domain interior and agrees with defined velocities on boundaries. Robustly and efficiently constructing such fields remains challenging. We present a novel velocity field construction for differential visibility. Inspired by recent Monte Carlo solvers for partial differential equations (PDEs), we formulate the velocity field via Laplace's equation and solve it with a walk-on-spheres (WoS) algorithm. To improve efficiency, we introduce a fixed-step WoS that terminates random walks after a fixed step count, resulting in a continuous but non-harmonic velocity field still valid for warped-area reparameterization. Furthermore, to practically apply our method to complex 3D scenes, we propose an efficient cone query to find the closest silhouettes on a boundary. Our cone query finds the closest point under the geodesic distance on a unit sphere, and is analogous to the closest point query by WoS to compute Euclidean distance. As a result, our method generalizes WoS to perform random walks on spherical caps over the unit sphere. We demonstrate that this enables a more robust and efficient unbiased estimator for differential visibility.},
  archive      = {J_TOG},
  author       = {Lifan Wu and Nathan Morrical and Sai Praveen Bangaru and Rohan Sawhney and Shuang Zhao and Chris Wyman and Ravi Ramamoorthi and Aaron Lefohn},
  doi          = {10.1145/3731174},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-16},
  shortjournal = {ACM Trans. Graph.},
  title        = {Unbiased differential visibility using fixed-step walk-on-spherical-caps and closest silhouettes},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vector-valued monte carlo integration using ratio control variates. <em>TOG</em>, <em>44</em>(4), 1-16. (<a href='https://doi.org/10.1145/3731175'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variance reduction techniques are widely used for reducing the noise of Monte Carlo integration. However, these techniques are typically designed with the assumption that the integrand is scalar-valued. Recognizing that rendering and inverse rendering broadly involve vector-valued integrands, we identify the limitations of classical variance reduction methods in this context. To address this, we introduce ratio control variates, an estimator that leverages a ratio-based approach instead of the conventional difference-based control variates. Our analysis and experiments demonstrate that ratio control variables can significantly reduce the mean squared error of vector-valued integration compared to existing methods and are broadly applicable to various rendering and inverse rendering tasks.},
  archive      = {J_TOG},
  author       = {Haolin Lu and Delio Vicini and Wesley Chang and Tzu-Mao Li},
  doi          = {10.1145/3731175},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-16},
  shortjournal = {ACM Trans. Graph.},
  title        = {Vector-valued monte carlo integration using ratio control variates},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rectangular surface parameterization. <em>TOG</em>, <em>44</em>(4), 1-21. (<a href='https://doi.org/10.1145/3731176'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes a method for computing surface parameterizations that map infinitesimal axis-aligned squares in the plane to infinitesimal rectangles on the surface. Such rectangular parameterizations are needed for a broad range of tasks, from physical simulation to geometric modeling to computational fabrication. Our main contribution is a novel strategy for constructing frame fields that are perfectly orthogonal and exactly integrable, in the limit of mesh refinement. In contrast to past strategies for achieving integrability, we obtain maps that are less distorted and better preserve target field directions. The method supports user-defined distortion measures, sharp feature alignment, prescribed or automatic cone singularities, and direct control over boundary behavior (e.g., sizing or aspect ratio). By quantizing and contouring these maps we obtain high-quality anisotropic quad meshes, even without element-based optimization. Empirically, we outperform state-of-the-art research and commercial mesh generation algorithms in terms of element quality, accuracy, and asymptotic convergence rate in end-to-end simulation tasks, are competitive with the widely-used ZBrush package for automatic retopology, and provide Chebyshev nets of superior quality to methods specifically tailored to digital fabrication.},
  archive      = {J_TOG},
  author       = {Etienne Corman and Keenan Crane},
  doi          = {10.1145/3731176},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-21},
  shortjournal = {ACM Trans. Graph.},
  title        = {Rectangular surface parameterization},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dress-1-to-3: Single image to simulation-ready 3D outfit with diffusion prior and differentiable physics. <em>TOG</em>, <em>44</em>(4), 1-16. (<a href='https://doi.org/10.1145/3731177'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in large models have significantly advanced image-to-3D reconstruction. However, the generated models are often fused into a single piece, limiting their applicability in downstream tasks. This paper focuses on 3D garment generation, a key area for applications like virtual try-on with dynamic garment animations, which require garments to be separable and simulation-ready. We introduce Dress-1-to-3, a novel pipeline that reconstructs physics-plausible, simulation-ready separated garments with sewing patterns and humans from an in-the-wild image. Starting with the image, our approach combines a pre-trained image-to-sewing pattern generation model for creating coarse sewing patterns with a pre-trained multi-view diffusion model to produce multi-view images. The sewing pattern is further refined using a differentiable garment simulator based on the generated multi-view images. Versatile experiments demonstrate that our optimization approach substantially enhances the geometric alignment of the reconstructed 3D garments and humans with the input image. Furthermore, by integrating a texture generation module and a human motion generation module, we produce customized physics-plausible and realistic dynamic garment demonstrations. Our project page is https://dress-1-to-3.github.io/.},
  archive      = {J_TOG},
  author       = {Xuan Li and Chang Yu and Wenxin Du and Ying Jiang and Tianyi Xie and Yunuo Chen and Yin Yang and Chenfanfu Jiang},
  doi          = {10.1145/3731177},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-16},
  shortjournal = {ACM Trans. Graph.},
  title        = {Dress-1-to-3: Single image to simulation-ready 3D outfit with diffusion prior and differentiable physics},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting fabric appearance through thread scattering and inversion. <em>TOG</em>, <em>44</em>(4), 1-12. (<a href='https://doi.org/10.1145/3731178'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fashion industry has a real need to preview fabric designs using the actual threads they intend to use, ensuring that the designs they envisage can be physically realized. Unfortunately, today's fabric rendering relies on either hand-tuned parameters or parameters acquired from already fabricated cloth. Furthermore, existing curve-based scattering models are not suitable for this problem: they are either not naturally differentiable due to discrete fiber count parameters, or require a more detailed geometry representation, introducing extra complexity. In this work, we bridge this gap by presenting a novel pipeline that captures and digitizes physical threads and predicts the appearance of the fabric based on the weaving pattern. We develop a practical thread scattering model based on simulations of multiple fiber scattering within a thread. Using a cost-efficient multi-view setup, we capture threads of diverse colors and materials. We apply differentiable rendering to digitize threads, demonstrating that our model significantly improves the reconstruction accuracy compared to existing models, matching both reflection and transmission. We leverage a two-scale rendering technique to efficiently render woven cloth. We validate that our digital threads, combined with simulated woven yarn geometry, can accurately predict the fabric appearance by comparing to real samples. We show how our work can aid designs using diverse thread profiles, woven patterns, and textured design patterns.},
  archive      = {J_TOG},
  author       = {Mengqi (Mandy) Xia and Zhaoyang Zhang and Sumit Chaturvedi and Yutong Yi and Rundong Wu and Holly Rushmeier and Julie Dorsey},
  doi          = {10.1145/3731178},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-12},
  shortjournal = {ACM Trans. Graph.},
  title        = {Predicting fabric appearance through thread scattering and inversion},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive algebraic reuse of reordering in cholesky factorizations with dynamic sparsity patterns. <em>TOG</em>, <em>44</em>(4), 1-17. (<a href='https://doi.org/10.1145/3731179'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce Parth, a fill-reducing ordering method for sparse Cholesky solvers with dynamic sparsity patterns (e.g., in physics simulations with contact or geometry processing with local remeshing). Parth facilitates the selective reuse of fill-reducing orderings when sparsity patterns exhibit temporal coherence, avoiding full symbolic analysis by localizing the effect of dynamic sparsity changes on the ordering vector. We evaluated Parth on over 175,000 linear systems collected from both physics simulations and geometry processing applications, and show that for some of the most challenging physics simulations, it achieves up to 14x reordering runtime speedup, resulting in a 2x speedup in Cholesky solve time—even on top of well-optimized solvers such as Apple Accelerate and Intel MKL.},
  archive      = {J_TOG},
  author       = {Behrooz Zarebavani and Danny M. Kaufman and David I. W. Levin and Maryam Mehri Dehnavi},
  doi          = {10.1145/3731179},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-17},
  shortjournal = {ACM Trans. Graph.},
  title        = {Adaptive algebraic reuse of reordering in cholesky factorizations with dynamic sparsity patterns},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leapfrog flow maps for real-time fluid simulation. <em>TOG</em>, <em>44</em>(4), 1-12. (<a href='https://doi.org/10.1145/3731180'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose Leapfrog Flow Maps (LFM) to simulate incompressible fluids with rich vortical flows in real time. Our key idea is to use a hybrid velocityimpulse scheme enhanced with leapfrog method to reduce the computational workload of impulse-based flow map methods, while possessing strong ability to preserve vortical structures and fluid details. In order to accelerate the impulse-to-velocity projection, we develop a fast matrix-free Algebraic Multigrid Preconditioned Conjugate Gradient (AMGPCG) solver with customized GPU optimization, which makes projection comparable with impulse evolution in terms of time cost. We demonstrate the performance of our method and its efficacy in a wide range of examples and experiments, such as real-time simulated burning fire ball and delta wingtip vortices.},
  archive      = {J_TOG},
  author       = {Yuchen Sun and Junlin Li and Ruicheng Wang and Sinan Wang and Zhiqi Li and Bart G. van Bloemen Waanders and Bo Zhu},
  doi          = {10.1145/3731180},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-12},
  shortjournal = {ACM Trans. Graph.},
  title        = {Leapfrog flow maps for real-time fluid simulation},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Designing 3D anisotropic frame fields with odeco tensors. <em>TOG</em>, <em>44</em>(4), 1-14. (<a href='https://doi.org/10.1145/3731181'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a method to synthesize a 3D tensor field within a constrained geometric domain represented as a tetrahedral mesh. Whereas previous techniques optimize for isotropic fields, we focus on anisotropic tensor fields that are smooth and aligned with the domain boundary or user guidance. The key ingredient of our method is a novel computational design framework, built on top of the symmetric orthogonally decomposable (odeco) tensor representation, to optimize the stretching ratios and orientations for each tensor in the domain. In contrast to past techniques designed only for isotropic tensors, we demonstrate the efficacy of our approach in generating smooth volumetric tensor fields with high anisotropy and shape conformity, especially for the domain with complex shapes. We apply these anisotropic tensor fields to various applications, such as anisotropic meshing, structural mechanics, and fabrication.},
  archive      = {J_TOG},
  author       = {Haikuan Zhu and Hongbo Li and Hsueh-Ti Derek Liu and Wenping Wang and Jing Hua and Zichun Zhong},
  doi          = {10.1145/3731181},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-14},
  shortjournal = {ACM Trans. Graph.},
  title        = {Designing 3D anisotropic frame fields with odeco tensors},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-performance CPU cloth simulation using domain-decomposed projective dynamics. <em>TOG</em>, <em>44</em>(4), 1-17. (<a href='https://doi.org/10.1145/3731182'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whenever the concept of high-performance cloth simulation is brought up, GPU acceleration is almost always the first that comes to mind. Leveraging immense parallelization, GPU algorithms have demonstrated significant success recently, whereas CPU methods are somewhat overlooked. Indeed, the need for an efficient CPU simulator is evident and pressing. In many scenarios, high-end GPUs may be unavailable or are already allocated to other tasks, such as rendering and shading. A high-performance CPU alternative can greatly boost the overall system capability and user experience. Inspired by this demand, this paper proposes a CPU algorithm for high-resolution cloth simulation. By partitioning the garment model into multiple (but not massive) sub-meshes or domains, we assign per-domain computations to individual CPU processors. Borrowing the idea of projective dynamics that breaks the computation into global and local steps, our key contribution is a new parallelization paradigm at domains for both global and local steps so that domain-level calculations are sequential and lightweight. The CPU has much fewer processing units than a GPU. Our algorithm mitigates this disadvantage by wisely balancing the scale of the parallelization and convergence. We validate our method in a wide range of simulation problems involving high-resolution garment models. Performance-wise, our method is at least one order faster than existing CPU methods, and it delivers a similar performance compared with the state-of-the-art GPU algorithms in many examples, but without using a GPU.},
  archive      = {J_TOG},
  author       = {Zixuan Lu and Ziheng Liu and Lei Lan and Huamin Wang and Yuko Ishiwaka and Chenfanfu Jiang and Kui Wu and Yin Yang},
  doi          = {10.1145/3731182},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-17},
  shortjournal = {ACM Trans. Graph.},
  title        = {High-performance CPU cloth simulation using domain-decomposed projective dynamics},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). JGS2: Near second-order converging Jacobi/Gauss-seidel for GPU elastodynamics. <em>TOG</em>, <em>44</em>(4), 1-15. (<a href='https://doi.org/10.1145/3731183'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In parallel simulation, convergence and parallelism are often seen as inherently conflicting objectives. Improved parallelism typically entails lighter local computation and weaker coupling, which unavoidably slow the global convergence. This paper presents a novel GPU algorithm that achieves convergence rates comparable to fullspace Newton's method while maintaining good parallelizability just like the Jacobi method. Our approach is built on a key insight into the phenomenon of overshoot. Overshoot occurs when a local solver aggressively minimizes its local energy without accounting for the global context, resulting in a local update that undermines global convergence. To address this, we derive a theoretically second-order optimal solution to mitigate overshoot. Furthermore, we adapt this solution into a pre-computable form. Leveraging Cubature sampling, our runtime cost is only marginally higher than the Jacobi method, yet our algorithm converges nearly quadratically as Newton's method. We also introduce a novel full-coordinate formulation for more efficient pre-computation. Our method integrates seamlessly with the incremental potential contact method and achieves second-order convergence for both stiff and soft materials. Experimental results demonstrate that our approach delivers high-quality simulations and outperforms state-of-the-art GPU methods with 50× to 100× better convergence.},
  archive      = {J_TOG},
  author       = {Lei Lan and Zixuan Lu and Chun Yuan and Weiwei Xu and Hao Su and Huamin Wang and Chenfanfu Jiang and Yin Yang},
  doi          = {10.1145/3731183},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-15},
  shortjournal = {ACM Trans. Graph.},
  title        = {JGS2: Near second-order converging Jacobi/Gauss-seidel for GPU elastodynamics},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time knit deformation and rendering. <em>TOG</em>, <em>44</em>(4), 1-12. (<a href='https://doi.org/10.1145/3731184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The knit structure consists of interlocked yarns, with each yarn comprising multiple plies comprising tens to hundreds of twisted fibers. This intricate geometry and the large number of geometric primitives present substantial challenges for achieving high-fidelity simulation and rendering in real-time applications. In this work, we introduce the first real-time framework that takes an animated stitch mesh as input and enhances it with yarn-level simulation and fiber-level rendering. Our approach relies on a knot-based representation to model interlocked yarn contacts. The knot positions are interpolated from the underlying mesh, and associated yarn control points are optimized using a physically inspired energy formulation, which is solved through a GPU-based Gauss-Newton scheme for real-time performance. The optimized control points are sent to the GPU rasterization pipeline and rendered as yarns with fiber-level details. In real-time rendering, we introduce several decomposition strategies to enable realistic lighting effects on complex knit structures, even under environmental lighting, while maintaining computational and memory efficiency. Our simulation faithfully reproduces yarn-level structures under deformations, e.g., stretching and shearing, capturing interlocked yarn behaviors. The rendering pipeline achieves near-ground-truth visual quality while being 120,000× faster than path tracing reference with fiber-level geometries. The whole system provides real-time performance and has been evaluated through various application scenarios, including knit simulation for small patches and full garments and yarn-level relaxation in the design pipeline.},
  archive      = {J_TOG},
  author       = {Tao Huang and Haoyang Shi and Mengdi Wang and Yuxing Qiu and Yin Yang and Kui Wu},
  doi          = {10.1145/3731184},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-12},
  shortjournal = {ACM Trans. Graph.},
  title        = {Real-time knit deformation and rendering},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UltraMeshRenderer: Efficient structure and management of GPU out-of-core memory for real-time rendering of gigantic 3D meshes. <em>TOG</em>, <em>44</em>(4), 1-19. (<a href='https://doi.org/10.1145/3731186'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {GPUs can encounter memory capacity constraints, which pose challenges for achieving real-time rendering performance when processing large 3D models that exceed available memory. State-of-the-art out-of-core rendering frameworks have leveraged Level of Detail (LOD) and frame-to-frame coherence data management techniques to optimize memory usage and minimize CPU-to-GPU data transfer costs. However, the size of view-dependently selected data may still exceed GPU memory capacity, and data transfer remains the most significant bottleneck in overall performance costs. To address these, we introduce a new GPU out-of-core rendering approach that includes a LOD selection method that takes into account both memory and coherence constraints and a parallel in-place GPU memory management algorithm that efficiently assembles the data of the current frame with GPU-resident data from the previous frame and transferred data. Our approach bounds memory usage and data transfer costs, prioritizes and schedules the transfer of essential data, incrementally refining the LOD over subsequent frames to converge toward the desired visual fidelity. Our parallel memory management algorithm consolidates frame-different and reusable data, dynamically reallocating GPU memory slots for efficient in-place operations. Hierarchical LOD representations remain a core component, and we emphasize their role in supporting adaptive data transfer and coherence management, characterized by a uniform depth and near-equal patch size at all levels. Our approach adapts seamlessly to scenarios with varying levels of coherence by balancing real-time performance with visual consistency. Experimental results demonstrate that our system achieves significant performance improvements, rendering scenes with billions of triangles in real-time, outperforming existing methods while maintaining consistent visual quality during dynamic interactions.},
  archive      = {J_TOG},
  author       = {Huadong Zhang and Lizhou Cao and Chao Peng},
  doi          = {10.1145/3731186},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-19},
  shortjournal = {ACM Trans. Graph.},
  title        = {UltraMeshRenderer: Efficient structure and management of GPU out-of-core memory for real-time rendering of gigantic 3D meshes},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inverse geometric locomotion. <em>TOG</em>, <em>44</em>(4), 1-17. (<a href='https://doi.org/10.1145/3731187'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous tasks in robotics and character animation involve solving combinations of inverse kinematics and motion planning problems that require the precise design of pose sequences to achieve desired motion objectives. Accounting for the complex interplay between body deformations and resulting motion, especially through interactions with the environment, poses significant challenges for the design of such pose sequences. We propose a computational framework to address these challenges in scenarios where the motion of a deformable body is entirely determined by dynamic changes of its shape. Complementing recent methods on the forward problem—mapping shape sequences to global motion trajectories based on a geometric formulation of locomotion—we address the inverse problem of optimizing shape sequences to achieve user-defined motion objectives. We demonstrate the effectiveness of our method through a diverse set of examples, producing realistic shape sequences that result in desired motion trajectories.},
  archive      = {J_TOG},
  author       = {Quentin Becker and Oliver Gross and Mark Pauly},
  doi          = {10.1145/3731187},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-17},
  shortjournal = {ACM Trans. Graph.},
  title        = {Inverse geometric locomotion},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 4D gaussian videos with motion layering. <em>TOG</em>, <em>44</em>(4), 1-14. (<a href='https://doi.org/10.1145/3731189'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online free-view navigation in volumetric videos requires high-quality rendering and real-time streaming in order to provide immersive user experiences. However, existing methods ( e.g. , dynamic NeRF and 3DGS) may not handle dynamic scenes with complex motions, and their models may not be streamable due to storage and bandwidth constraints. In this paper, we propose a novel 4D Gaussian Video (4DGV) approach that enables the creation and streaming of photorealistic, volumetric videos for dynamic scenes over the Internet. The core of our 4DGV is a novel streamable group of Gaussians (GOG) representation based on motion layering. Each GOG consists of static and dynamic points obtained via lifting 2D segmentation into 3D in motion layering, where the deformation of each dynamic point is represented as the temporal offset of its attributes. We also adaptively convert static points back to dynamic points to handle the appearance change, (e.g. , moving shadows and reflections), of static objects through optimization. To support real-time streaming of 4DGVs, we show that by applying quantization on Gaussian attributes and H.265 encoding on deformation offsets, our GOG representation can be significantly compressed (to around 6% of the original model size) without sacrificing the accuracy (PSNR loss less than 0.01dB). Extensive experiments on standard benchmarks demonstrate that our method outperforms state-of-the-art volumetric video approaches, with superior rendering quality and minimum storage overheads.},
  archive      = {J_TOG},
  author       = {Pinxuan Dai and Peiquan Zhang and Zheng Dong and Ke Xu and Yifan Peng and Dandan Ding and Yujun Shen and Yin Yang and Xinguo Liu and Rynson W. H. Lau and Weiwei Xu},
  doi          = {10.1145/3731189},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-14},
  shortjournal = {ACM Trans. Graph.},
  title        = {4D gaussian videos with motion layering},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cirrus: Adaptive hybrid particle-grid flow maps on GPU. <em>TOG</em>, <em>44</em>(4), 1-17. (<a href='https://doi.org/10.1145/3731190'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose the adaptive hybrid particle-grid flow map method, a novel flow-map approach that leverages Lagrangian particles to simultaneously transport impulse and guide grid adaptation, introducing a fully adaptive flow map-based fluid simulation framework. The core idea of our method is to maintain flow-map trajectories separately on grid nodes and particles: the grid-based representation tracks long-range flow maps at a coarse spatial resolution, while the particle-based representation tracks both long and short-range flow maps, enhanced by their gradients, at a fine resolution. This hybrid Eulerian-Lagrangian flow-map representation naturally enables adaptivity for both advection and projection steps. We implement this method in Cirrus , a GPU-based fluid simulation framework designed for octree-like adaptive grids enhanced with particle trackers. The efficacy of our system is demonstrated through numerical tests and various simulation examples, achieving up to 512 × 512 × 2048 effective resolution on an RTX 4090 GPU. We achieve a 1.5 to 2× speedup with our GPU optimization over the Particle Flow Map method on the same hardware, while the adaptive grid implementation offers efficiency gains of one to two orders of magnitude by reducing computational resource requirements. The source code has been made publicly available at: https://wang-mengdi.github.io/proj/25-cirrus/.},
  archive      = {J_TOG},
  author       = {Mengdi Wang and Fan Feng and Junlin Li and Bo Zhu},
  doi          = {10.1145/3731190},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-17},
  shortjournal = {ACM Trans. Graph.},
  title        = {Cirrus: Adaptive hybrid particle-grid flow maps on GPU},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variational surface reconstruction using natural neighbors. <em>TOG</em>, <em>44</em>(4), 1-19. (<a href='https://doi.org/10.1145/3731191'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface reconstruction from points is a fundamental problem in computer graphics. While numerous methods have been proposed, it remains challenging to reconstruct from sparse and non-uniform point distributions, particularly when normals are absent. We present a robust and scalable method for reconstructing an implicit surface from points without normals. By exploring the locality of natural neighborhoods, we propose local reformulations of a previous global method, known for its ability to surface sparse points but high computational cost, thereby significantly improving its scalability while retaining its robustness. Experiments show that our method achieves comparable speed to existing reconstruction methods on large inputs while producing fewer artifacts in under-sampled regions.},
  archive      = {J_TOG},
  author       = {Jianjun Xia and Tao Ju},
  doi          = {10.1145/3731191},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-19},
  shortjournal = {ACM Trans. Graph.},
  title        = {Variational surface reconstruction using natural neighbors},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fluid simulation on compressible flow maps. <em>TOG</em>, <em>44</em>(4), 1-17. (<a href='https://doi.org/10.1145/3731192'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a unified compressible flow map framework designed to accommodate diverse compressible flow systems, including high-Mach-number flows (e.g., shock waves and supersonic aircraft), weakly compressible systems (e.g., smoke plumes and ink diffusion), and incompressible systems evolving through compressible acoustic quantities (e.g., free-surface shallow water). At the core of our approach is a theoretical foundation for compressible flow maps based on Lagrangian path integrals, a novel advection scheme for the conservative transport of density and energy, and a unified numerical framework for solving compressible flows with varying pressure treatments. We validate our method across three representative compressible flow systems, characterized by varying fluid morphologies, governing equations, and compressibility levels, demonstrating its ability to preserve and evolve spatiotemporal features such as vortical structures and wave interactions governed by different flow physics. Our results highlight a wide range of novel phenomena, from ink torus breakup to delta wing tail vortices and vortex shedding on free surfaces, significantly expanding the range of fluid systems that flow-map methods can handle.},
  archive      = {J_TOG},
  author       = {Duowen Chen and Zhiqi Li and Taiyuan Zhang and Jinjin He and Junwei Zhou and Bart G. van Bloemen Waanders and Bo Zhu},
  doi          = {10.1145/3731192},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-17},
  shortjournal = {ACM Trans. Graph.},
  title        = {Fluid simulation on compressible flow maps},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EDGE: Epsilon-difference gradient evolution for buffer-free flow maps. <em>TOG</em>, <em>44</em>(4), 1-11. (<a href='https://doi.org/10.1145/3731193'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose the Epsilon Difference Gradient Evolution (EDGE) method for accurate flow-map calculation on grids via Hermite interpolation without using velocity buffers. Our key idea is to integrate Gradient Evolution for accurate first-order derivatives and a tetrahedron-based Epsilon Difference scheme to compute higher-order derivatives with reduced memory consumption. EDGE achieves O (1) memory usage, independent of flow map length, while maintaining vorticity preservation comparable to buffer-based methods. We validate our methods across diverse vortical flow scenarios, demonstrating up to 90% backward map memory reduction and significant computational efficiency, broadening the applicability of flow-map methods to large-scale and complex fluid simulations.},
  archive      = {J_TOG},
  author       = {Zhiqi Li and Ruicheng Wang and Junlin Li and Duowen Chen and Sinan Wang and Bo Zhu},
  doi          = {10.1145/3731193},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-11},
  shortjournal = {ACM Trans. Graph.},
  title        = {EDGE: Epsilon-difference gradient evolution for buffer-free flow maps},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clebsch gauge fluid on particle flow maps. <em>TOG</em>, <em>44</em>(4), 1-12. (<a href='https://doi.org/10.1145/3731194'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel gauge fluid solver that evolves Clebsch wave functions on particle flow maps (PFMs). The key insight underlying our work is that particle flow maps exhibit superior performance in transporting point elements—such as Clebsch components—compared to line and surface elements, which were the focus of previous methods relying on impulse and vortex gauge variables for flow maps. Our Clebsch PFM method incorporates three main contributions: a novel gauge transformation enabling accurate transport of wave functions on particle flow maps, an enhanced velocity reconstruction method for coarse grids, and a PFM-based simulation framework designed to better preserve fine-scale flow structures. We validate the Clebsch PFM method through a wide range of benchmark tests and simulation examples, ranging from leapfrogging vortex rings and vortex reconnections to Kelvin-Helmholtz instabilities, demonstrating that our method outperforms its impulse- or vortex-based counterparts on particle flow maps, particularly in preserving and evolving small-scale features.},
  archive      = {J_TOG},
  author       = {Zhiqi Li and Candong Lin and Duowen Chen and Xinyi Zhou and Shiying Xiong and Bo Zhu},
  doi          = {10.1145/3731194},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-12},
  shortjournal = {ACM Trans. Graph.},
  title        = {Clebsch gauge fluid on particle flow maps},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Augmented vertex block descent. <em>TOG</em>, <em>44</em>(4), 1-12. (<a href='https://doi.org/10.1145/3731195'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vertex Block Descent is a fast physics-based simulation method that is unconditionally stable, highly parallelizable, and capable of converging to the implicit Euler solution. We extend it using an augmented Lagrangian formulation to address some of its fundamental limitations. First, we introduce a mechanism to handle hard constraints with infinite stiffness without introducing numerical instabilities. Second, we substantially improve the convergence in the presence of high stiffness ratios. These changes we introduce allow simulating complex contact scenarios involving rigid bodies with stacking and friction, articulated bodies connected with hard constraints, including joints with limited degrees of freedom, and stiff systems interacting with soft bodies. We present evaluations using a parallel GPU implementation that can deliver real-time performance and stable simulations with low iteration counts for millions of objects interacting via collisions, various joint/attachment constraints, and springs of various stiffness. Our results show superior performance, convergence, and stability compared to the state-of-the-art alternatives.},
  archive      = {J_TOG},
  author       = {Chris Giles and Elie Diaz and Cem Yuksel},
  doi          = {10.1145/3731195},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-12},
  shortjournal = {ACM Trans. Graph.},
  title        = {Augmented vertex block descent},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightning-fast boundary element method. <em>TOG</em>, <em>44</em>(4), 1-14. (<a href='https://doi.org/10.1145/3731196'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Boundary element methods (BEM) for solving linear elliptic partial differential equations have gained traction in a wide range of graphics applications: they eliminate the need for volumetric meshing by solving for variables exclusively on the domain boundary through a linear boundary integral equation (BIE). However, BEM often generate dense and ill-conditioned linear systems that lead to poor computational scalability and substantial memory demands for large-scale problems, limiting their applicability and efficiency in practice. In this paper, we address these limitations by generalizing the Kaporin-based approach to asymmetric preconditioning: we construct a sparse approximation of the inverse-LU factorization of arbitrary BIE matrices in a massively parallel manner. Our sparse inverse-LU factorization, when employed as a preconditioner for the generalized minimal residual (GMRES) method, significantly enhances the efficiency of BIE solves, often yielding orders-of-magnitude speedups in solving times.},
  archive      = {J_TOG},
  author       = {Jiong Chen and Florian Schäfer and Mathieu Desbrun},
  doi          = {10.1145/3731196},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-14},
  shortjournal = {ACM Trans. Graph.},
  title        = {Lightning-fast boundary element method},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discrete torsion of connection forms on simplicial meshes. <em>TOG</em>, <em>44</em>(4), 1-10. (<a href='https://doi.org/10.1145/3731197'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While discrete (metric) connections have become a staple of n -vector field design and analysis on simplicial meshes, the notion of torsion of a discrete connection has remained unstudied. This is all the more surprising as torsion is a crucial component in the fundamental theorem of Riemannian geometry, which introduces the existence and uniqueness of the Levi-Civita connection induced by the metric. In this paper, we extend the existing geometry processing toolbox by providing torsion control over discrete connections. Our approach consists in first introducing a new discrete Levi-Civita connection for a metric with locally-constant curvature to replace the hinge connection of a triangle mesh whose curvature is concentrated at singularities; from this reference connection, we define the discrete torsion of a connection to be the discrete dual 1-form by which a connection deviates from our discrete Levi-Civita connection. We discuss how the curvature and torsion of a discrete connection can then be controlled and assigned in a manner consistent with the continuous case. We also illustrate our approach through theoretical analysis and practical examples arising in vector and frame design.},
  archive      = {J_TOG},
  author       = {Theo Braune and Mark Gillespie and Yiying Tong and Mathieu Desbrun},
  doi          = {10.1145/3731197},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-10},
  shortjournal = {ACM Trans. Graph.},
  title        = {Discrete torsion of connection forms on simplicial meshes},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fluid simulation on vortex particle flow maps. <em>TOG</em>, <em>44</em>(4), 1-24. (<a href='https://doi.org/10.1145/3731198'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose the V ortex P article F low M ap (VPFM) method to simulate incompressible flow with complex vortical evolution in the presence of dynamic solid boundaries. The core insight of our approach is that vorticity is an ideal quantity for evolution on particle flow maps, enabling significantly longer flow map distances compared to other fluid quantities like velocity or impulse. To achieve this goal, we developed a hybrid Eulerian-Lagrangian representation that evolves vorticity and flow map quantities on vortex particles, while reconstructing velocity on a background grid. The method integrates three key components: (1) a vorticity-based particle flow map framework, (2) an accurate Hessian evolution scheme on particles, and (3) a solid boundary treatment for no-through and no-slip conditions in VPFM. These components collectively allow a substantially longer flow map length ( 3–12 times longer) than the state-of-the-art, enhancing vorticity preservation over extended spatiotemporal domains. We validated the performance of VPFM through diverse simulations, demonstrating its effectiveness in capturing complex vortex dynamics and turbulence phenomena.},
  archive      = {J_TOG},
  author       = {Sinan Wang and Junwei Zhou and Fan Feng and Zhiqi Li and Yuchen Sun and Duowen Chen and Greg Turk and Bo Zhu},
  doi          = {10.1145/3731198},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-24},
  shortjournal = {ACM Trans. Graph.},
  title        = {Fluid simulation on vortex particle flow maps},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MaterialPicker: Multi-modal DiT-based material generation. <em>TOG</em>, <em>44</em>(4), 1-12. (<a href='https://doi.org/10.1145/3731199'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-quality material generation is key for virtual environment authoring and inverse rendering. We propose MaterialPicker, a multi-modal material generator leveraging a Diffusion Transformer (DiT) architecture, improving and simplifying the creation of high-quality materials from text prompts and/or photographs. Our method can generate a material based on an image crop of a material sample, even if the captured surface is distorted, viewed at an angle or partially occluded, as is often the case in photographs of natural scenes. We further allow the user to specify a text prompt to provide additional guidance for the generation. We finetune a pre-trained DiT-based video generator into a material generator, where each material map is treated as a frame in a video sequence. We evaluate our approach both quantitatively and qualitatively and show that it enables more diverse material generation and better distortion correction than previous work.},
  archive      = {J_TOG},
  author       = {Xiaohe Ma and Valentin Deschaintre and Miloš Hašan and Fujun Luan and Kun Zhou and Hongzhi Wu and Yiwei Hu},
  doi          = {10.1145/3731199},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-12},
  shortjournal = {ACM Trans. Graph.},
  title        = {MaterialPicker: Multi-modal DiT-based material generation},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Collaborative on-sensor array cameras. <em>TOG</em>, <em>44</em>(4), 1-18. (<a href='https://doi.org/10.1145/3731200'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern nanofabrication techniques have enabled us to manipulate the wave-front of light with sub-wavelength-scale structures, offering the potential to replace bulky refractive surfaces in conventional optics with ultrathin metasurfaces. In theory, arrays of nanoposts provide unprecedented control over manipulating the wavefront in terms of phase, polarization, and amplitude at the nanometer resolution. A line of recent work successfully investigates flat computational cameras that replace compound lenses with a single metalens or an array of metasurfaces a few millimeters from the sensor. However, due to the inherent wavelength dependence of metalenses, in practice, these cameras do not match their refractive counterparts in image quality for broadband imaging, and may even suffer from hallucinations when relying on generative reconstruction methods. In this work, we investigate a collaborative array of metasurface elements that are jointly learned to perform broadband imaging. To this end, we learn a nanophotonics array with 100-million nanoposts that is end-to-end jointly optimized over the full visible spectrum—a design task that existing inverse design methods or learning approaches cannot support due to memory and compute limitations. We introduce a distributed meta-optics learning method to tackle this challenge. This allows us to optimize a large parameter array along with a learned metaatom proxy and a non-generative reconstruction method that is parallax-aware and noise-aware. The proposed camera performs favorably in simulation and in all experimental tests irrespective of the scene illumination spectrum.},
  archive      = {J_TOG},
  author       = {Jipeng Sun and Kaixuan Wei and Thomas Eboli and Congli Wang and Cheng Zheng and Zhihao Zhou and Arka Majumdar and Wolfgang Heidrich and Felix Heide},
  doi          = {10.1145/3731200},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-18},
  shortjournal = {ACM Trans. Graph.},
  title        = {Collaborative on-sensor array cameras},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Arenite: A physics-based sandstone simulator. <em>TOG</em>, <em>44</em>(4), 1-13. (<a href='https://doi.org/10.1145/3731201'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce Arenite, a novel physics-based approach for modeling sandstone structures. The key insight of our work is that simulating a combination of stress and multi-factor erosion enables the generation of a wide variety of sandstone structures observed in nature. We isolate the key shape-forming phenomena: multi-physics fabric interlocking, wind and fluvial erosion, and particle-based deposition processes. Complex 3D structures such as arches, alcoves, hoodoos, or buttes can be achieved by creating simple 3D structures with user-painted erodable areas and vegetation and running the simulation. We demonstrate the algorithm on a wide variety of structures, and our GPU-based implementation achieves the simulation in less than 5 minutes on a desktop computer for our most complex example.},
  archive      = {J_TOG},
  author       = {Zhanyu Yang and Aryamaan Jain and Guillaume Cordonnier and Marie-Paule Cani and Zhaopeng Wang and Bedrich Benes},
  doi          = {10.1145/3731201},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-13},
  shortjournal = {ACM Trans. Graph.},
  title        = {Arenite: A physics-based sandstone simulator},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive dynamics++: A framework for stable, continuous, and consistent animation across resolution and time. <em>TOG</em>, <em>44</em>(4), 1-20. (<a href='https://doi.org/10.1145/3731202'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recently developed Progressive Dynamics framework [Zhang et al. 2024] addresses the long-standing challenge in enabling rapid iterative design for high-fidelity cloth and shell animation. In this work, we identify fundamental limitations of the original method in terms of stability and temporal continuity. For robust progressive dynamics simulation we seek methods that provide: (1) stability across all levels of detail (LOD) and timesteps, (2) temporally continuous animations without jumps or jittering, and (3) user-controlled balancing between geometric consistency and enrichment at each timestep, thereby making it a practical previewing tool with high-quality results at the finest level to be used as the final output. We propose a general framework, Progressive Dynamics++, for constructing a family of progressive dynamics integration methods that advance physical simulation states forward in both time and spatial resolution, which includes Zhang et al. [2024]'s method as one member. We analyze necessary stability conditions for Progressive Dynamics integrators and introduce a novel, stable method that significantly improves temporal continuity, supported by a new quantitative measure. Additionally, we present a quantitative analysis of the trade-off between geometric consistency and enrichment, along with strategies for balancing between these aspects in transitions across resolution and time.},
  archive      = {J_TOG},
  author       = {Jiayi Eris Zhang and Doug L. James and Danny M. Kaufman},
  doi          = {10.1145/3731202},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-20},
  shortjournal = {ACM Trans. Graph.},
  title        = {Progressive dynamics++: A framework for stable, continuous, and consistent animation across resolution and time},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Putting rigid bodies to rest. <em>TOG</em>, <em>44</em>(4), 1-16. (<a href='https://doi.org/10.1145/3731203'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the analysis and design of the resting configurations of a rigid body, without the use of physical simulation. In particular, given a rigid body in R 3 , we identify all possible stationary points, as well as the probability that the body will stop at these points, assuming a random initial orientation and negligible momentum. The forward version of our method can hence be used to automatically orient models, to provide feedback about object stability during the design process, and to furnish plausible distributions of shape orientation for natural scene modeling. Moreover, a differentiable inverse version of our method lets us design shapes with target resting behavior, such as dice with target, nonuniform probabilities. Here we find solutions that would be nearly impossible to find using classical techniques, such as dice with additional unstable faces that provide more natural overall geometry. From a technical point of view, our key observation is that rolling equilibria can be extracted from the Morse-Smale complex of the support function over the Gauss map. Our method is hence purely geometric, and does not make use of random sampling, or numerical time integration. Yet surprisingly, this purely geometric model makes extremely accurate predictions of rest behavior, which we validate both numerically, and via physical experiments. Moreover, for computing rest statistics, it is orders of magnitude faster than state of the art rigid body simulation, opening the door to inverse design—rather than just forward analysis.},
  archive      = {J_TOG},
  author       = {Hossein Baktash and Nicholas Sharp and Qingnan Zhou and Alec Jacobson and Keenan Crane},
  doi          = {10.1145/3731203},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-16},
  shortjournal = {ACM Trans. Graph.},
  title        = {Putting rigid bodies to rest},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal r-adaptive in-timestep remeshing for elastodynamics. <em>TOG</em>, <em>44</em>(4), 1-19. (<a href='https://doi.org/10.1145/3731204'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a coupled mesh-adaptation model and physical simulation algorithm to jointly generate, per timestep, optimal adaptive remeshings and implicit solutions for the simulation of frictionally contacting elastodynamics. To do so, we begin with Ferguson et al.'s [2023] recently developed in-timestep remeshing (ITR) framework, which proposes an Incremental Potential based objective for mesh refinement, and a corresponding, locally greedy remeshing algorithm to minimize it. While this initial ITR framework demonstrates significant improvements, its greedy remeshing does not generate optimal meshes, and so does not converge to improving physical solutions with increasing mesh resolution. In practice, due to lack of optimality, the original ITR framework can and will find mesh and state solutions with unnecessarily low-quality geometries and corresponding physical solution artifacts. At the same time, we also identify additional fundamental challenges to adaptive simulation in terms of both ITR's original remeshing objective and its corresponding optimization problem formulation. In this work, in order to extend the ITR framework to high-quality, optimal in-timestep remeshing, we first construct a new remeshing objective function built from simple, yet critical, updates to the Incremental Potential energy, and a corresponding constrained model problem, whose minimizers provide locally optimal remeshings for physical problems. We then propose a new in-timestep remeshing optimization that jointly solves, per-timestep, for a new locally optimal remeshing and the next physical state defined upon it. To evaluate and demonstrate our extension of the ITR framework, we apply it to the optimal r-adaptive ITR simulation of frictionally contacting elasto-dynamics and statics. To enable r-adaptivity we additionally propose a new numerical method to robustly compute derivatives of the L 2 -projection operator necessary for optimal mesh-to-mesh state mappings within solves, a constraint model to enable on-boundary node adaptivity, and an efficient Newton-type optimization method for practically solving each per-timestep r-adaptive ITR solution. We extensively evaluate our method on challenging large-deformation and frictionally contacting scenarios. Here we observe optimal r-adaptivity captures comparable and better accuracy than unadapted meshes orders-of-magnitude larger, with corresponding significant advantages in both computation speedup and decrease in memory usage.},
  archive      = {J_TOG},
  author       = {Jiahao Wen and Jernej Barbič and Danny M. Kaufman},
  doi          = {10.1145/3731204},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-19},
  shortjournal = {ACM Trans. Graph.},
  title        = {Optimal r-adaptive in-timestep remeshing for elastodynamics},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Offset geometric contact. <em>TOG</em>, <em>44</em>(4), 1-21. (<a href='https://doi.org/10.1145/3731205'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel contact model, termed Offset Geometric Contact (OGC), for guaranteed penetration-free simulation of codimensional objects with minimal computational overhead. Our method is based on constructing a volumetric shape by offsetting each face along its normal direction, ensuring orthogonal contact forces, thus allows large contact radius without artifacts. We compute vertex-specific displacement bounds to guarantee penetration-free simulation, which improves convergence and avoids the need for expensive continuous collision detection. Our method relies solely on massively parallel local operations, avoiding global synchronization and enabling efficient GPU implementation. Experiments demonstrate real-time, large-scale simulations with performance more than two orders of magnitude faster than prior methods while maintaining consistent computational budgets.},
  archive      = {J_TOG},
  author       = {Anka He Chen and Jerry Hsu and Ziheng Liu and Miles Macklin and Yin Yang and Cem Yuksel},
  doi          = {10.1145/3731205},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-21},
  shortjournal = {ACM Trans. Graph.},
  title        = {Offset geometric contact},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffuse-CLoC: Guided diffusion for physics-based character look-ahead control. <em>TOG</em>, <em>44</em>(4), 1-12. (<a href='https://doi.org/10.1145/3731206'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present Diffuse-CLoC, a guided diffusion framework for physics-based look-ahead control that enables intuitive, steerable, and physically realistic motion generation. While existing kinematics motion generation with diffusion models offer intuitive steering capabilities with inference-time conditioning, they often fail to produce physically viable motions. In contrast, recent diffusion-based control policies have shown promise in generating physically realizable motion sequences, but the lack of kinematics prediction limits their steerability. Diffuse-CLoC addresses these challenges through a key insight: modeling the joint distribution of states and actions within a single diffusion model makes action generation steerable by conditioning it on the predicted states. This approach allows us to leverage established conditioning techniques from kinematic motion generation while producing physically realistic motions. As a result, we achieve planning capabilities without the need for a high-level planner. Our method handles a diverse set of unseen long-horizon downstream tasks through a single pre-trained model, including static and dynamic obstacle avoidance, motion in-betweening, and task-space control. Experimental results show that our method significantly outperforms the traditional hierarchical framework of high-level motion diffusion and low-level tracking.},
  archive      = {J_TOG},
  author       = {Xiaoyu Huang and Takara Truong and Yunbo Zhang and Fangzhou Yu and Jean Pierre Sleiman and Jessica Hodgins and Koushil Sreenath and Farbod Farshidian},
  doi          = {10.1145/3731206},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-12},
  shortjournal = {ACM Trans. Graph.},
  title        = {Diffuse-CLoC: Guided diffusion for physics-based character look-ahead control},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MiSo: A DSL for robust and efficient solve and MInimize problems. <em>TOG</em>, <em>44</em>(4), 1-18. (<a href='https://doi.org/10.1145/3731207'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many problems in computer graphics can be formulated as finding the global minimum of a function subject to a set of non-linear constraints (Minimize), or finding all solutions of a system of non-linear constraints (Solve). We introduce MiSo, a domain-specific language and compiler for generating efficient C++ code for low-dimensional Minimize and Solve problems, that uses interval methods to guarantee conservative results while using floating point arithmetic. We demonstrate that MiSo-generated code shows competitive performance compared to hand-optimized codes for several computer graphics problems, including high-order collision detection with non-linear trajectories, surface-surface intersection, and geometrical validity checks for finite element simulation.},
  archive      = {J_TOG},
  author       = {Federico Sichetti and Enrico Puppo and Zizhou Huang and Marco Attene and Denis Zorin and Daniele Panozzo},
  doi          = {10.1145/3731207},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-18},
  shortjournal = {ACM Trans. Graph.},
  title        = {MiSo: A DSL for robust and efficient solve and MInimize problems},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ANIME-rod: Adjustable nonlinear isotropic materials for elastic rods. <em>TOG</em>, <em>44</em>(4), 1-23. (<a href='https://doi.org/10.1145/3731208'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We give a method to simulate large deformations of 3D elastic rods under arbitrary nonlinear isotropic 3D solid materials. Rod elastic energies in existing graphics literature are derived from volumetric models under the small-strain linearization assumptions. While the resulting equations can and are commonly applied to large deformations, the material modeling has been limited to a single material, namely linear Hooke law. Starting from any 3D solid nonlinear isotropic elastic energy density function ψ , we derive our rod elastic energy by subjecting the 3D solid volumetric material to the limit process whereby rod thickness is decreased to zero. This enables us to explain rod stretching, bending and twisting in a unified model. Care must be taken to adequately model cross-sectional in-plane and out-of-plane deformations. Our key insight is to compute the three cross-sectional deformation modes corresponding to bending (in the two directions) and twisting, using linear theory. Then, given any ψ , we use these modes to derive an analytical formula for a 5D "macroscopic" large-deformation rod elastic energy function of the local longitudinal stretch, radial scaling, the two bending curvatures and torsion. Our model matches linear theory for small deformations, including cross-sectional shrinkage due to Poisson's effect, and produces correct bending and torsional constants. Our experiments demonstrate that our energy closely matches volumetric FEM even under large stretches and curvatures, whereas commonly used methods in graphics deviate from it. We also compare to closely related work from mechanics literature; we give an explicit expansion of all energy terms in terms of the rod cross-section diameter, allowing independent adjustment of stretching, bending and twisting. Finally, we observe an inherent limitation in the ability of rod models to control nonlinear bendability and twistability. We propose to "relax" rod physics to more easily control nonlinear bending and twisting in computer graphics applications.},
  archive      = {J_TOG},
  author       = {Huanyu Chen and Jiahao Wen and Jernej Barbič},
  doi          = {10.1145/3731208},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-23},
  shortjournal = {ACM Trans. Graph.},
  title        = {ANIME-rod: Adjustable nonlinear isotropic materials for elastic rods},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MoVer: Motion verification for motion graphics animations. <em>TOG</em>, <em>44</em>(4), 1-17. (<a href='https://doi.org/10.1145/3731209'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While large vision-language models can generate motion graphics animations from text prompts, they regularly fail to include all spatio-temporal properties described in the prompt. We introduce MoVer, a motion verification DSL based on first-order logic that can check spatio-temporal properties of a motion graphics animation. We identify a general set of such properties that people commonly use to describe animations (e.g., the direction and timing of motions, the relative positioning of objects, etc.). We implement these properties as predicates in MoVer and provide an execution engine that can apply a MoVer program to any input SVG-based motion graphics animation. We then demonstrate how MoVer can be used in an LLM-based synthesis and verification pipeline for iteratively refining motion graphics animations. Given a text prompt, our pipeline synthesizes a motion graphics animation and a corresponding MoVer program. Executing the verification program on the animation yields a report of the predicates that failed and the report can be automatically fed back to LLM to iteratively correct the animation. To evaluate our pipeline, we build a synthetic dataset of 5600 text prompts paired with ground truth MoVer verification programs. We find that while our LLM-based pipeline is able to automatically generate a correct motion graphics animation for 58.8% of the test prompts without any iteration, this number raises to 93.6% with up to 50 correction iterations. Our code and dataset are at https://mover-dsl.github.io.},
  archive      = {J_TOG},
  author       = {Jiaju Ma and Maneesh Agrawala},
  doi          = {10.1145/3731209},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-17},
  shortjournal = {ACM Trans. Graph.},
  title        = {MoVer: Motion verification for motion graphics animations},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IMLS-splatting: Efficient mesh reconstruction from multi-view images via point representation. <em>TOG</em>, <em>44</em>(4), 1-11. (<a href='https://doi.org/10.1145/3731210'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view mesh reconstruction has long been a challenging problem in graphics and computer vision. In contrast to recent volumetric rendering methods that generate meshes through post-processing, we propose an end-to-end mesh optimization approach called IMLS-Splatting. Our method leverages the sparsity and flexibility of point clouds to efficiently represent the underlying surface. To achieve this, we introduce a splatting-based differentiable Implicit Moving-Least Squares (IMLS) algorithm that enables the fast conversion of point clouds into SDFs and texture fields, optimizing both mesh reconstruction and rasterization. Additionally, the IMLS representation ensures that the reconstructed SDF and mesh maintain continuity and smoothness without the need for extra regularization. With this efficient pipeline, our method enables the reconstruction of highly detailed meshes in approximately 11 minutes, supporting high-quality rendering and achieving state-of-the-art reconstruction performance. Our code is available at https://github.com/SilenKZYoung/IMLS-Splatting.},
  archive      = {J_TOG},
  author       = {Kaizhi Yang and Liu Dai and Isabella Liu and Xiaoshuai Zhang and Xiaoyan Sun and Xuejin Chen and Zexiang Xu and Hao Su},
  doi          = {10.1145/3731210},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-11},
  shortjournal = {ACM Trans. Graph.},
  title        = {IMLS-splatting: Efficient mesh reconstruction from multi-view images via point representation},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3DGH: 3D head generation with composable hair and face. <em>TOG</em>, <em>44</em>(4), 1-12. (<a href='https://doi.org/10.1145/3731211'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present 3DGH, an unconditional generative model for 3D human heads with composable hair and face components. Unlike previous work that entangles the modeling of hair and face, we propose to separate them using a novel data representation with template-based 3D Gaussian Splatting, in which deformable hair geometry is introduced to capture the geometric variations across different hairstyles. Based on this data representation, we design a 3D GAN-based architecture with dual generators and employ a cross-attention mechanism to model the inherent correlation between hair and face. The model is trained on synthetic renderings using carefully designed objectives to stabilize training and facilitate hair-face separation. We conduct extensive experiments to validate the design choice of 3DGH, and evaluate it both qualitatively and quantitatively by comparing with several state-of-the-art 3D GAN methods, demonstrating its effectiveness in unconditional full-head image synthesis and composable 3D hairstyle editing. More details will be available on our project page: https://c-he.github.io/projects/3dgh/.},
  archive      = {J_TOG},
  author       = {Chengan He and Junxuan Li and Tobias Kirschstein and Artem Sevastopolsky and Shunsuke Saito and Qingyang Tan and Javier Romero and Chen Cao and Holly Rushmeier and Giljoo Nam},
  doi          = {10.1145/3731211},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-12},
  shortjournal = {ACM Trans. Graph.},
  title        = {3DGH: 3D head generation with composable hair and face},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Faraday cage estimation of normals for point clouds and ribbon sketches. <em>TOG</em>, <em>44</em>(4), 1-13. (<a href='https://doi.org/10.1145/3731212'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel method (FaCE) for normal estimation of unoriented point clouds and VR ribbon sketches that leverages a modeling of the Faraday cage effect. Input points, or a sampling of the ribbons, form a conductive cage and shield the interior from external fields. The gradient of the maximum field strength over external field scenarios is used to estimate a normal at each input point or ribbon. The electrostatic effect is modeled with a simple Poisson system, accommodating intuitive user-driven sculpting via the specification of point charges and Faraday cage points. On inputs sampled from clean, watertight meshes, our method achieves comparable normal quality to existing methods tailored for this scenario. On inputs containing interior structures and artifacts, our method produces superior surfacing output when combined with Poisson Surface Reconstruction. In the case of ribbon sketches, our method accommodates sparser ribbon input while maintaining an accurate geometry, allowing for greater flexibility in the artistic process. We demonstrate superior performance to an existing approach for surfacing ribbon sketches in this sparse setting.},
  archive      = {J_TOG},
  author       = {Daniel Scrivener and Daniel Cui and Ellis Coldren and S. Mazdak Abulnaga and Mikhail Bessmeltsev and Edward Chien},
  doi          = {10.1145/3731212},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-13},
  shortjournal = {ACM Trans. Graph.},
  title        = {Faraday cage estimation of normals for point clouds and ribbon sketches},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QUASAR: Quad-based adaptive streaming and rendering. <em>TOG</em>, <em>44</em>(4), 1-18. (<a href='https://doi.org/10.1145/3731213'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As AR/VR systems evolve to demand increasingly powerful GPUs, physically separating compute from display hardware emerges as a natural approach to enable a lightweight, comfortable form factor. Unfortunately, splitting the system into a client-server architecture leads to challenges in transporting graphical data. Simply streaming rendered images over a network suffers in terms of latency and reliability, especially given variable bandwidth. Although image-based reprojection techniques can help, they often do not support full motion parallax or disocclusion events. Instead, scene geometry can be streamed to the client, allowing local rendering of novel views. Traditionally, this has required a prohibitively large amount of interconnect bandwidth, excluding the use of practical networks. This paper presents a new quad-based geometry streaming approach that is designed with compression and the ability to adjust Quality-of-Experience (QoE) in response to target network bandwidths. Our approach advances previous work by introducing a more compact data structure and a temporal compression technique that reduces data transfer overhead by up to 15×, reducing bandwidth usage to as low as 100 Mbps. We optimized our design for hardware video codec compatibility and support an adaptive data streaming strategy that prioritizes transmitting only the most relevant geometry updates. Our approach achieves image quality comparable to, and in many cases exceeds, state-of-the-art techniques while requiring only a fraction of the bandwidth, enabling real-time geometry streaming on commodity headsets over WiFi.},
  archive      = {J_TOG},
  author       = {Edward Lu and Anthony Rowe},
  doi          = {10.1145/3731213},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-18},
  shortjournal = {ACM Trans. Graph.},
  title        = {QUASAR: Quad-based adaptive streaming and rendering},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Echoes of the coliseum: Towards 3D live streaming of sports events. <em>TOG</em>, <em>44</em>(4), 1-17. (<a href='https://doi.org/10.1145/3731214'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-centered live events have always played a pivotal role in shaping culture and fostering social connections. Traditional 2D live transmissions fail to replicate the immersive quality of physical attendance. Addressing this gap, this paper proposes LiveSplats , a framework towards real-time, photo-realistic 3D reconstructions of live events using high-performance 3D Gaussian Splatting. Our solution capitalizes on strong geometric priors to optimize through distributed processing and load balancing, enabling interactive, freely explorable 3D experiences. By dividing scene reconstruction into actor-centric and environment-specific tasks, we employ hierarchical coarse-to-fine optimization to rapidly and accurately reconstruct human actors based on pose data, refining their geometry and appearance with photometric loss. For static environments, we focus on view-dependent appearance changes, streamlining rendering efficiency and maximizing GPU performance. To facilitate evaluation, we introduce (and distribute) a synthetic benchmark dataset of basketball games, offering high visual fidelity as ground truth. In both our synthetic benchmark and publicly available benchmarks, LiveSplats consistently outperforms existing approaches. The dataset is available at https://humansensinglab.github.io/basket-multiview.},
  archive      = {J_TOG},
  author       = {Junkai Huang and Saswat Subhajyoti Mallick and Alejandro Amat and Marc Ruiz Olle and Albert Mosella-Montoro and Bernhard Kerbl and Francisco Vicente Carrasco and Fernando De la Torre},
  doi          = {10.1145/3731214},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-17},
  shortjournal = {ACM Trans. Graph.},
  title        = {Echoes of the coliseum: Towards 3D live streaming of sports events},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature-aligned parametrization in penner coordinates. <em>TOG</em>, <em>44</em>(4), 1-21. (<a href='https://doi.org/10.1145/3731216'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parametrization is a key element of many geometric modeling tasks. Seamless parametrization, in particular, is needed as a starting point for many algorithms for quadrangulation and conversion to high-order patches, as well as for the construction of seamless texture maps and displacement maps. Seamless parametrizations are difficult to compute robustly, in part because, in general, it is not known if one exists for a given mesh connectivity or for a particular configuration of singularities. Recently, Penner-coordinate-based methods that allow for connectivity changes have been shown to achieve a perfect success rate on a widely used dataset (Thingi10k). However, previously proposed Penner coordinate methods do not support sharp feature alignment or soft alignment with preferred directions on the surface, both of which are important for practical applications, especially those involving models with sharp features. In this paper, we extend Penner coordinates to surfaces with sharp features to which the parametrization needs to be aligned. Our algorithm extends the holonomy signature description of seamless parametrizations to surfaces with marked feature curves. We describe sufficient conditions for obtaining feasible solutions and describe a two-phase method to efficiently enforce feature constraints or minimize residual errors when solutions are unattainable. We demonstrate that the resulting algorithm works robustly on the Thingi10k dataset with automatic feature labeling, and the resulting seamless parametrizations can be optimized, quantized, and quadrangulated, completing the quad mesh generation pipeline.},
  archive      = {J_TOG},
  author       = {Ryan Capouellez and Rodrigo Singh and Martin Heistermann and David Bommes and Denis Zorin},
  doi          = {10.1145/3731216},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-21},
  shortjournal = {ACM Trans. Graph.},
  title        = {Feature-aligned parametrization in penner coordinates},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variational green and biharmonic coordinates for 2D polynomial cages. <em>TOG</em>, <em>44</em>(4), 1-20. (<a href='https://doi.org/10.1145/3731421'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present closed-form expressions for Green and biharmonic coordinates with respect to polynomial curved 2D cages, enabling reliable cage-based image deformation both to and from a curved cage. We further provide closed-form expressions for first- and second-order derivatives of these coordinates with respect to the encoded position. This enables the use of variational solvers for interacting with the 2D shape at arbitrary points while keeping the fast decoding strength of cage-based deformation, which we illustrate for a variety of elastic deformation energies.},
  archive      = {J_TOG},
  author       = {Élie Michel and Alec Jacobson and Siddhartha Chaudhuri and Jean-Marc Thiery},
  doi          = {10.1145/3731421},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-20},
  shortjournal = {ACM Trans. Graph.},
  title        = {Variational green and biharmonic coordinates for 2D polynomial cages},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meschers: Geometry processing of impossible objects. <em>TOG</em>, <em>44</em>(4), 1-10. (<a href='https://doi.org/10.1145/3731422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Impossible objects, geometric constructions that humans can perceive but that cannot exist in real life, have been a topic of intrigue in visual arts, perception, and graphics, yet no satisfying computer representation of such objects exists. Previous work embeds impossible objects in 3D, cutting them or twisting/bending them in the depth axis. Cutting an impossible object changes its local geometry at the cut, which can hamper downstream graphics applications, such as smoothing, while bending makes it difficult to relight the object. Both of these can invalidate geometry operations, such as distance computation. As an alternative, we introduce Meschers, meshes capable of representing impossible constructions akin to those found in M.C. Escher's woodcuts. Our representation has a theoretical foundation in discrete exterior calculus and supports the use-cases above, as we demonstrate in a number of example applications. Moreover, because we can do discrete geometry processing on our representation, we can inverse-render impossible objects. We also compare our representation to cut and bend representations of impossible objects.},
  archive      = {J_TOG},
  author       = {Ana Dodik and Isabella Yu and Kartik Chandra and Jonathan Ragan-Kelley and Joshua Tenenbaum and Vincent Sitzmann and Justin Solomon},
  doi          = {10.1145/3731422},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-10},
  shortjournal = {ACM Trans. Graph.},
  title        = {Meschers: Geometry processing of impossible objects},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid tours: A clip-based system for authoring long-take touring shots. <em>TOG</em>, <em>44</em>(4), 1-13. (<a href='https://doi.org/10.1145/3731423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-take touring (LTT) shots are characterized by smooth camera motion over a long distance that seamlessly connects different views of the captured scene. These shots offer a compelling way to visualize 3D spaces. However, filming LTT shots directly is very difficult, and rendering them based on a virtual reconstruction of a scene is resource-intensive and prone to many visual artifacts. We propose Hybrid Tours , a hybrid approach to creating LTT shots that combines the capture of short clips representing potential tour segments with a custom interactive application that lets users filter and combine these segments into longer camera trajectories. We show that Hybrid Tours makes capturing LTT shots much easier than the traditional single-take approach, and that clip-based authoring and reconstruction leads to higher-fidelity results at a lower cost than common image-based rendering workflows.},
  archive      = {J_TOG},
  author       = {Xinrui Liu and Longxiulin Deng and Abe Davis},
  doi          = {10.1145/3731423},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-13},
  shortjournal = {ACM Trans. Graph.},
  title        = {Hybrid tours: A clip-based system for authoring long-take touring shots},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ViSA: Physics-based virtual stunt actors for ballistic stunts. <em>TOG</em>, <em>44</em>(4), 1-15. (<a href='https://doi.org/10.1145/3731424'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce ViSA (Virtual Stunt Actors), an interactive animation system designed to create realistic ballistic stunt actions frequently seen in filmmaking and TV production. By providing spatial constraints suitable for the desired stunt scene, our system generates physically plausible motions satisfying the given constraints. The problem is formulated as a deep reinforcement learning task, incorporating a novel state and action spaces, as well as straightforward yet effective rewards for ballistic stunt actions. Users can receive a fast response within several minutes and continue to choreograph complex stunt scenes in an interactive manner. We demonstrate ballistic stunt scenes resembling those in various films and TV dramas, such as traffic accidents, falling down stairs, and falls from buildings. The effectiveness of the technical components and design choices in our system is demonstrated through extensive comparisons, analyses, and ablation studies.},
  archive      = {J_TOG},
  author       = {Minseok Kim and Wonjeong Seo and Sung-Hee Lee and Jungdam Won},
  doi          = {10.1145/3731424},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-15},
  shortjournal = {ACM Trans. Graph.},
  title        = {ViSA: Physics-based virtual stunt actors for ballistic stunts},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PhysicsFC: Learning user-controlled skills for a physics-based football player controller. <em>TOG</em>, <em>44</em>(4), 1-21. (<a href='https://doi.org/10.1145/3731425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose PhysicsFC, a method for controlling physically simulated football player characters to perform a variety of football skills-such as dribbling, trapping, moving, and kicking-based on user input, while seamlessly transitioning between these skills. Our skill-specific policies, which generate latent variables for each football skill, are trained using an existing physics-based motion embedding model that serves as a foundation for reproducing football motions. Key features include a tailored reward design for the Dribble policy, a two-phase reward structure combined with projectile dynamics-based initialization for the Trap policy, and a Data-Embedded Goal-Conditioned Latent Guidance (DEGCL) method for the Move policy. Using the trained skill policies, the proposed football player finite state machine (PhysicsFC FSM) allows users to interactively control the character. To ensure smooth and agile transitions between skill policies, as defined in the FSM, we introduce the Skill Transition-Based Initialization (STI), which is applied during the training of each skill policy. We develop several interactive scenarios to showcase PhysicsFC's effectiveness, including competitive trapping and dribbling, give-and-go plays, and 11v11 football games, where multiple PhysicsFC agents produce natural and controllable physics-based football player behaviors. Quantitative evaluations further validate the performance of individual skill policies and the transitions between them, using the presented metrics and experimental designs.},
  archive      = {J_TOG},
  author       = {Minsu Kim and Eunho Jung and Yoonsang Lee},
  doi          = {10.1145/3731425},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-21},
  shortjournal = {ACM Trans. Graph.},
  title        = {PhysicsFC: Learning user-controlled skills for a physics-based football player controller},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning-based virtual oculoplastic surgery simulator. <em>TOG</em>, <em>44</em>(4), 1-15. (<a href='https://doi.org/10.1145/3731426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oculoplastic surgery is a critical treatment for various eye conditions, such as ptosis, which can cause both aesthetic and functional issues. Due to the anxiety about the outcome, patients are often hesitant to undergo the necessary procedures required for the surgery. Virtual oculoplastic surgery simulation technology offers a solution to alleviate these concerns by providing realistic previews of post-surgical results. In this paper, we present a novel deep learning-based virtual oculoplastic surgery simulation system that addresses the limitations of existing methods. The proposed system aims to improve the accuracy of simulations by considering the anatomical structure and characteristics of the eye. Our method utilizes a deformable parametric mesh to enhance the controllability of the image transformation process. Furthermore, the combination of a style-based generator and a neural texture has been implemented to generate high-quality results. The proposed system is expected to facilitate better communication between doctors and patients by providing anatomically inspired high-quality simulation results. The development of this advanced virtual simulation system has the potential to enhance patient experiences and improve satisfaction with outcomes in the field of oculoplastic surgery.},
  archive      = {J_TOG},
  author       = {Seonghyeon Kim and Chang Wook Seo and Kwanggyoon Seo and Seung Han Song and Junyong Noh},
  doi          = {10.1145/3731426},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-15},
  shortjournal = {ACM Trans. Graph.},
  title        = {A deep learning-based virtual oculoplastic surgery simulator},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Instant self-intersection repair for 3D meshes. <em>TOG</em>, <em>44</em>(4), 1-14. (<a href='https://doi.org/10.1145/3731427'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-intersection repair in static 3D surface meshes presents unique challenges due to the absence of temporal motion and penetration depth information—two critical elements typically leveraged in physics-based approaches. We introduce a novel framework that transforms local contact handling into a global repair strategy through a combination of local signed tangent-point energies and their gradient diffusion. At the heart of our method is a key insight: rather than computing expensive global repulsive potentials, we can effectively approximate long-range interactions by diffusing energy gradients from local contacts throughout the mesh surface. In turn, resolving complex self-intersections reduces to simply propagating local repulsive energies through standard diffusion mechanics and iteratively solving tractable local optimizations. We further accelerate convergence through our momentum-based optimizer, which adaptively regulates momentum based on gradient statistics to prevent overshooting while maintaining rapid intersection repair. The resulting algorithm handles a variety of challenging scenarios, from shallow contacts to deep penetrations, while providing computational efficiency suitable for interactive applications.},
  archive      = {J_TOG},
  author       = {Wonjong Jang and Yucheol Jung and Gyeongmin Lee and Seungyong Lee},
  doi          = {10.1145/3731427},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-14},
  shortjournal = {ACM Trans. Graph.},
  title        = {Instant self-intersection repair for 3D meshes},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variable shared template for consistent non-rigid ICP. <em>TOG</em>, <em>44</em>(4), 1-16. (<a href='https://doi.org/10.1145/3731428'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-rigid registration of 3D shape collections using a template mesh is essential for constructing 3D datasets. Traditional non-rigid Iterative Closest Point (ICP) methods rely on manually selected template meshes, which can result in inconsistent registrations when applied to diverse shape collections. This inconsistency arises particularly when the template lacks common shape features with the input instances or when landmark annotations are sparse. To overcome this limitation, we propose a novel ICP framework that jointly optimizes a shared template shape and its instance-wise deformations. Our joint optimization framework assigns distinct roles to the shared template and instance-wise deformations: the template captures common shape features, while instance-wise deformations handle residual registration errors. We use stronger smoothness regularization on the instance-wise deformations in early iterations to prioritize the accumulation of common details on the template. Additionally, a distortion alignment energy minimizes interinstance map distortions, promoting consistent instance-wise deformations. On challenging 3D datasets with large shape variations, our method achieves state-of-the-art fitting accuracy and consistent results in shape averaging and deformation transfer. By removing the need for a carefully selected preset template, our method extends the capability of extrinsic non-rigid registration frameworks, offering a more robust and flexible solution for challenging registration scenarios.},
  archive      = {J_TOG},
  author       = {Yucheol Jung and Hyomin Kim and Hyejeong Yoon and Yoonha Hwang and Seungyong Lee},
  doi          = {10.1145/3731428},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-16},
  shortjournal = {ACM Trans. Graph.},
  title        = {Variable shared template for consistent non-rigid ICP},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Light pipe holographic display: Bandwidth-preserved kaleidoscopic guiding for AR glasses. <em>TOG</em>, <em>44</em>(4), 1-12. (<a href='https://doi.org/10.1145/3731429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a holographic display using a light pipe for augmented reality, and the hologram rendering method via bandwidth-preserved kaleidoscopic guiding method. Conventional augmented reality displays typically share optical architectures where the light engine and image combiner are adjacent. Minimizing the size of both components is highly challenging, and most commercial and research prototypes of augmented reality displays are bulky, front-heavy and sight-obstructing. Here, we propose the use of light pipe to decouple and spatially reposition the light engine from the image combiner, enabling a pragmatic glasses-type design. Through total internal reflection, light pipes have an advantage in guiding the full angular bandwidth regardless of its length. By modeling such kaleidoscopic guiding of the wavefront inside the light pipe and applying it to holographic image generation, we successfully separate the light engine from the image combiner, making the front of the device clear and lightweight. We experimentally validate that the proposed light pipe system delivers virtual images with high-quality and 3D depth cues. We further present a method to simulate and compensate for light pipe misalignment, enhancing the robustness and practicality of the proposed system.},
  archive      = {J_TOG},
  author       = {Minseok Chae and Chun Chen and Seung-Woo Nam and Yoonchan Jeong},
  doi          = {10.1145/3731429},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-12},
  shortjournal = {ACM Trans. Graph.},
  title        = {Light pipe holographic display: Bandwidth-preserved kaleidoscopic guiding for AR glasses},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FLoD: Integrating flexible level of detail into 3D gaussian splatting for customizable rendering. <em>TOG</em>, <em>44</em>(4), 1-16. (<a href='https://doi.org/10.1145/3731430'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D Gaussian Splatting (3DGS) has significantly advanced computer graphics by enabling high-quality 3D reconstruction and fast rendering speeds, inspiring numerous follow-up studies. However, 3DGS and its subsequent works are restricted to specific hardware setups, either on only low-cost or on only high-end configurations. Approaches aimed at reducing 3DGS memory usage enable rendering on low-cost GPU but compromise rendering quality, which fails to leverage the hardware capabilities in the case of higher-end GPU. Conversely, methods that enhance rendering quality require high-end GPU with large VRAM, making such methods impractical for lower-end devices with limited memory capacity. Consequently, 3DGS-based works generally assume a single hardware setup and lack the flexibility to adapt to varying hardware constraints. To overcome this limitation, we propose Flexible Level of Detail (FLoD) for 3DGS. FLoD constructs a multi-level 3DGS representation through level-specific 3D scale constraints, where each level independently reconstructs the entire scene with varying detail and GPU memory usage. A level-by-level training strategy is introduced to ensure structural consistency across levels. Furthermore, the multi-level structure of FLoD allows selective rendering of image regions at different detail levels, providing additional memory-efficient rendering options. To our knowledge, among prior works which incorporate the concept of Level of Detail (LoD) with 3DGS, FLoD is the first to follow the core principle of LoD by offering adjustable options for a broad range of GPU settings. Experiments demonstrate that FLoD provides various rendering options with trade-offs between quality and memory usage, enabling real-time rendering under diverse memory constraints. Furthermore, we show that FLoD generalizes to different 3DGS frameworks, indicating its potential for integration into future state-of-the-art developments.},
  archive      = {J_TOG},
  author       = {Yunji Seo and Young Sun Choi and HyunSeung Son and Youngjung Uh},
  doi          = {10.1145/3731430},
  journal      = {ACM Transactions on Graphics},
  month        = {7},
  number       = {4},
  pages        = {1-16},
  shortjournal = {ACM Trans. Graph.},
  title        = {FLoD: Integrating flexible level of detail into 3D gaussian splatting for customizable rendering},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="toms">TOMS - 7</h2>
<ul>
<li><details>
<summary>
(2025). Algorithm 1055: HDSDP: Software for semidefinite programming. <em>TOMS</em>, <em>51</em>(2), 1-30. (<a href='https://doi.org/10.1145/3721123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {HDSDP is a numerical software solving semidefinite programming problems. The main framework of HDSDP resembles the dual-scaling interior point solver DSDP and several new features, including a dual method based on the simplified homogeneous self-dual embedding, have been implemented. The embedding technique enhances the stability of the dual method, and several new heuristics and computational techniques are designed to accelerate its convergence. HDSDP aims to show how the dual-scaling algorithm benefits from the self-dual embedding, and it is developed in parallel to DSDP 5.8. Numerical experiments over several classical benchmark datasets exhibit their robustness and efficiency, particularly their advantages on SDP instances featuring low-rank structure and sparsity. HDSDP is open sourced under an MIT license and available at https://github.com/Gwzwpxz/HDSDP .},
  archive      = {J_TOMS},
  author       = {Wenzhi Gao and Dongdong Ge and Yinyu Ye},
  doi          = {10.1145/3721123},
  journal      = {ACM Transactions on Mathematical Software},
  month        = {6},
  number       = {2},
  pages        = {1-30},
  shortjournal = {ACM Trans. Math. Softw.},
  title        = {Algorithm 1055: HDSDP: Software for semidefinite programming},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximating large-scale hessian matrices using secant equations. <em>TOMS</em>, <em>51</em>(2), 1-21. (<a href='https://doi.org/10.1145/3728460'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale optimization algorithms frequently require sparse Hessian matrices that are not readily available. Existing methods for approximating large sparse Hessian matrices either do not impose sparsity or are computationally prohibitive. To try and overcome these limitations, we propose a novel approach that seeks to satisfy as many componentwise secant equations as necessary to define each row of the Hessian matrix. A naive application of this approach is too expensive for Hessian matrices that have some relatively dense rows but, by carefully taking into account the symmetry and connectivity of the Hessian matrix, we are able devise an approximation algorithm that is fast and efficient with scope for parallelism. Example sparse Hessian matrices from the CUTEst test collection for optimization illustrate the effectiveness and robustness of our proposed method.},
  archive      = {J_TOMS},
  author       = {Jaroslav M. Fowkes and Nicholas I. M. Gould and Jennifer A. Scott},
  doi          = {10.1145/3728460},
  journal      = {ACM Transactions on Mathematical Software},
  month        = {6},
  number       = {2},
  pages        = {1-21},
  shortjournal = {ACM Trans. Math. Softw.},
  title        = {Approximating large-scale hessian matrices using secant equations},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intersection of tetrahedra. <em>TOMS</em>, <em>51</em>(2), 1-26. (<a href='https://doi.org/10.1145/3729532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When intersecting non-matching three-dimensional lattices, one needs to calculate the intersections of tetrahedra. The authors’ previously published two-dimensional triangle–triangle intersection algorithm suggests a novel approach in three dimensions based on parsimony. The algorithm presented here expands on this two-dimensional algorithm and introduces new strategies necessitated by the increase in dimension. An extensive proof is given for the consistency of the algorithm. Thus, the algorithm is shown to be robust to numerical error arising from floating-point arithmetic. Example problems demonstrate its use and effectiveness.},
  archive      = {J_TOMS},
  author       = {Conor McCoid and Martin J. Gander},
  doi          = {10.1145/3729532},
  journal      = {ACM Transactions on Mathematical Software},
  month        = {6},
  number       = {2},
  pages        = {1-26},
  shortjournal = {ACM Trans. Math. Softw.},
  title        = {Intersection of tetrahedra},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LevelSetPy: A GPU-accelerated package for hyperbolic Hamilton–Jacobi partial differential equations. <em>TOMS</em>, <em>51</em>(2), 1-14. (<a href='https://doi.org/10.1145/3730407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a software package release for geometrically reasoning about the safety desiderata of (complex) dynamical systems via level set methods. In emphasis, safety is analyzed with the Hamilton–Jacobi equations. In scope, we provide implementations of numerical algorithms for the resolution of Hamilton–Jacobi–Isaacs equations: the spatial derivatives of the associated value function via upwinding, the Hamiltonian via Lax–Friedrichs schemes, and the integration of the Hamilton–Jacobi equation altogether via total variation diminishing Runge–Kutta schemes. Since computational speed and interoperability with other modern scientific computing libraries (typically written in the Python language) are of essence, we capitalize on modern computational frameworks such as CUPY and NUMPY and move heavy computations to GPU devices to aid parallelization and improve bring-up time in safety analysis. We hope that this package can aid users to quickly iterate on ideas and evaluate all possible safety desiderata of a system via geometrical simulation in modern engineering problems.},
  archive      = {J_TOMS},
  author       = {Lekan Molu},
  doi          = {10.1145/3730407},
  journal      = {ACM Transactions on Mathematical Software},
  month        = {6},
  number       = {2},
  pages        = {1-14},
  shortjournal = {ACM Trans. Math. Softw.},
  title        = {LevelSetPy: A GPU-accelerated package for hyperbolic Hamilton–Jacobi partial differential equations},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Algorithm 1056: QPoly—A magma package for working with quaternionic polynomials. <em>TOMS</em>, <em>51</em>(2), 1-14. (<a href='https://doi.org/10.1145/3731677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article presents the package for the computer algebra system Magma . It is a collection of functions for manipulating quaternionic polynomials over number fields. It provides nearly the same functionality for quaternionic polynomials as the ones provided by Magma for polynomials over fields.},
  archive      = {J_TOMS},
  author       = {Przemysław Koprowski},
  doi          = {10.1145/3731677},
  journal      = {ACM Transactions on Mathematical Software},
  month        = {6},
  number       = {2},
  pages        = {1-14},
  shortjournal = {ACM Trans. Math. Softw.},
  title        = {Algorithm 1056: QPoly—A magma package for working with quaternionic polynomials},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Algorithm 1057: FunC: A minimally invasive c++ library for the generation and analysis of univariate lookup tables. <em>TOMS</em>, <em>51</em>(2), 1-30. (<a href='https://doi.org/10.1145/3734692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Lookup Table (LUT) is a computationally inexpensive piecewise function used to approximate computationally expensive mathematical functions. Evaluating a LUT can be as quick as using Horner’s method to evaluate a polynomial after looking up its coefficients. A common choice of LUT is a piecewise constant or piecewise linear function; however, high-degree interpolating polynomials can also be valuable. Here, we describe the functionality of FunC 2.0, a C++ library designed to streamline the process of building, comparing, and implementing univariate LUTs in practical applications. In particular, FunC 2.0 can build relatively small LUTs satisfying user-provided absolute and relative tolerances for error. Furthermore, FunC 2.0 can build nonuniform LUTs, it provides utilities to quickly determine reasonable LUT bounds and tolerances for error, and it provides a way to quickly profile a set of LUTs. We demonstrate FunC ’s utility in application by reducing the total runtime of a simulation performed by the Canadian Hydrological Model (CHM). This simulation modeled the snow mass distribution across Western Canada over 1 month. Now, the CHM can evaluate the mathematical function of interest about 28 times faster, allowing the necessary algorithm to finish two times faster, and the overall simulation is about 9% faster.},
  archive      = {J_TOMS},
  author       = {Shawn S. C. McAdam and Raymond J. Spiteri},
  doi          = {10.1145/3734692},
  journal      = {ACM Transactions on Mathematical Software},
  month        = {6},
  number       = {2},
  pages        = {1-30},
  shortjournal = {ACM Trans. Math. Softw.},
  title        = {Algorithm 1057: FunC: A minimally invasive c++ library for the generation and analysis of univariate lookup tables},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Symbolic and user-friendly geometric algebra routines (SUGAR) for computations in matlab. <em>TOMS</em>, <em>51</em>(2), 1-31. (<a href='https://doi.org/10.1145/3734693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geometric Algebra (GA) provides a unified, compact mathematical framework for geometric computing, simplifying relations typically handled with more complex tools like matrix multiplication. In fields like robotics, GA replaces conventional coordinate-based approaches with the multiplication of special elements called rotors, offering greater efficiency. Despite its advantages, GA’s complexity and the lack of symbolic tools hinder its broader adoption among applied mathematicians and engineers. To address this, this article introduces Symbolic and User-friendly Geometric Algebra Routines (SUGAR), an open source Matlab toolbox. SUGAR streamlines GA usage in Matlab through a collection of user-friendly functions that support both numeric and symbolic computations, even in high-dimensional algebras. Designed for applied mathematics and engineering, it enables intuitive manipulation of geometric elements and transformations in two- and three-dimensional projective and conformal GAs, consistent with established computational methods. Moreover, SUGAR manages multivector functions such as exponential, logarithmic, sinusoidal, and cosine operations, enhancing its applicability in domains like robotics, control systems, and power electronics. Finally, this article also presents three validation examples across these fields, showcasing SUGAR’s practical utility in solving real-world engineering and applied mathematics problems.},
  archive      = {J_TOMS},
  author       = {Manel Velasco and Isiah Zaplana and Arnau Dòria-Cerezo and Pau Martí},
  doi          = {10.1145/3734693},
  journal      = {ACM Transactions on Mathematical Software},
  month        = {6},
  number       = {2},
  pages        = {1-31},
  shortjournal = {ACM Trans. Math. Softw.},
  title        = {Symbolic and user-friendly geometric algebra routines (SUGAR) for computations in matlab},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="tosem">TOSEM - 30</h2>
<ul>
<li><details>
<summary>
(2025). JSimpo: Structural deobfuscation of JavaScript programs. <em>TOSEM</em>, <em>34</em>(7), 1-28. (<a href='https://doi.org/10.1145/3714460'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {JavaScript (JS) obfuscation is now prevalent among popular websites and introduces challenges for malware detection and code review. Given an obfuscated JS program, existing deobfuscation techniques aim to recover the original JS program. However, these techniques overlook structural obfuscation (e.g., control-flow flattening), which causes deobfuscation to have a sub-optimal success rate. To address these challenges, in this article, we propose the first approach of structural deobfuscation named JSimpo for JS programs with two novel techniques: slice symbolic execution and dynamic code execution. We implement our JSimpo approach and evaluate it on 2,000 JS programs from the top 100 JS projects on GitHub. The evaluation results show that JSimpo can effectively conduct structural deobfuscation, boosting the average structural similarity to 78.41% (from 39.33%) between obfuscated programs and their original programs, whereas the best of the state-of-the-art/practice deobfuscators can achieve only 62.64%. The results also show JSimpo's generalization ability over programs obfuscated by various obfuscators. Additionally, JSimpo preserves the semantics of deobfuscated programs by passing all test cases that obfuscated programs have passed.},
  archive      = {J_TOSEM},
  author       = {Tianyu Chen and Ding Li and Ying Zhang and Tao Xie},
  doi          = {10.1145/3714460},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-28},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {JSimpo: Structural deobfuscation of JavaScript programs},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring parameter-efficient fine-tuning techniques for code generation with large language models. <em>TOSEM</em>, <em>34</em>(7), 1-25. (<a href='https://doi.org/10.1145/3714461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) demonstrate impressive capabilities to generate accurate code snippets given natural language intents in a zero-shot manner, i.e., without the need for specific fine-tuning. While prior studies have highlighted the advantages of fine-tuning LLMs, this process incurs high computational costs, making it impractical in resource-scarce environments, particularly for models with billions of parameters. To address these challenges, previous research explored in-context learning (ICL) and retrieval-augmented generation (RAG) as strategies to guide the LLM generative process with task-specific prompt examples. However, ICL and RAG introduce inconveniences, such as the need for designing contextually relevant prompts and the absence of learning task-specific parameters, thereby limiting downstream task performance. In this context, we foresee parameter-efficient fine-tuning (PEFT) as a promising approach to efficiently specialize LLMs to task-specific data while maintaining reasonable resource consumption. In this article, we deliver a comprehensive study of PEFT techniques for LLMs in the context of automated code generation. Our comprehensive investigation of PEFT techniques for LLMs reveals their superiority and potential over ICL and RAG across a diverse set of LLMs and three representative Python code generation datasets: Conala, CodeAlpacaPy, and APPS. Furthermore, our study highlights the potential for tuning larger LLMs and significant reductions in memory usage by combining PEFT with quantization. Therefore, this study opens opportunities for broader applications of PEFT in software engineering scenarios.},
  archive      = {J_TOSEM},
  author       = {Martin Weyssow and Xin Zhou and Kisub Kim and David Lo and Houari Sahraoui},
  doi          = {10.1145/3714461},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-25},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Exploring parameter-efficient fine-tuning techniques for code generation with large language models},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Teaching code LLMs to use autocompletion tools in repository-level code generation. <em>TOSEM</em>, <em>34</em>(7), 1-27. (<a href='https://doi.org/10.1145/3714462'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent code large language models (LLMs) have shown promising performance in generating standalone functions. However, they face limitations in repository-level code generation due to their lack of awareness of repository - level dependencies (e.g., user-defined attributes), resulting in dependency errors such as undefined-variable and no-member errors. In this work, we introduce ToolGen , an approach that integrates autocompletion tools into the code LLM generation process to address these dependencies. ToolGen comprises two main phases: Trigger Insertion and Model Fine-tuning (Offline), and Tool-integrated Code Generation (Online). During the offline phase, ToolGen augments functions within a given code corpus with a special mark token, indicating positions to trigger autocompletion tools. These augmented functions, along with their corresponding descriptions, are then used to fine-tune a selected code LLM. In the online phase, ToolGen iteratively generates functions by predicting tokens step-by-step using the fine-tuned LLM. Whenever a mark token is encountered, ToolGen invokes the autocompletion tool to suggest code completions and selects the most appropriate one through constrained greedy search. We conduct comprehensive experiments to evaluate ToolGen ’s effectiveness in repository-level code generation across three distinct code LLMs: CodeGPT, CodeT5, and CodeLlama. To facilitate this evaluation, we create a benchmark comprising 671 real-world code repositories and introduce two new dependency-based metrics: Dependency Coverage and Static Validity Rate . The results demonstrate that ToolGen significantly improves Dependency Coverage by 31.4% to 39.1% and Static Validity Rate by 44.9% to 57.7% across the three LLMs, while maintaining competitive or improved performance in widely recognized similarity metrics such as BLEU-4, CodeBLEU, Edit Similarity, and Exact Match. On the CoderEval dataset, ToolGen achieves improvements of 40.0% and 25.0% in test pass rate (Pass@1) for CodeT5 and CodeLlama, respectively, while maintaining the same pass rate for CodeGPT. ToolGen also demonstrates high efficiency in repository-level code generation, with latency ranging from 0.63 to 2.34 seconds for generating each function. Furthermore, our generalizability evaluation confirms ToolGen ’s consistent performance when applied to diverse code LLMs, encompassing various model architectures and scales.},
  archive      = {J_TOSEM},
  author       = {Chong Wang and Jian Zhang and Yebo Feng and Tianlin Li and Weisong Sun and Yang Liu and Xin Peng},
  doi          = {10.1145/3714462},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-27},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Teaching code LLMs to use autocompletion tools in repository-level code generation},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TAEFuzz: Automatic fuzzing for image-based deep learning systems via transferable adversarial examples. <em>TOSEM</em>, <em>34</em>(7), 1-31. (<a href='https://doi.org/10.1145/3714463'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) components have been broadly applied in diverse applications. Similar to traditional software engineering, effective test case generation methods are needed by industry to enhance the quality and robustness of these DL components. To this end, we propose a novel automatic software testing technique, Fuzz-testing via T ransferable A dversarial E xamples ( TAEFuzz ), which aims to automatically assess and enhance the robustness of image-based DL systems based on test cases generated by transferable adversarial examples. TAEFuzz alleviates the over-fitting problem during optimized test case generation and prevents test cases from prematurely falling into local optima. In addition, TAEFuzz enhances the visual quality of test cases through constraining perturbations inserted into sensitive areas of the images. For a system with low robustness, TAEFuzz trains a low-cost denoising module to reduce the impact of perturbations in transferable adversarial examples on the system. Experimental results demonstrate that the test cases generated by TAEFuzz can discover up to 46.1% more errors in the targeted systems and ensure the visual quality of test cases. Compared to existing techniques, TAEFuzz also enhances the robustness of the target systems against transferable adversarial examples with the perturbation denoising module.},
  archive      = {J_TOSEM},
  author       = {Shunhui Ji and Changrong Huang and Bin Ren and Hai Dong and Lars Grunske and Yan Xiao and Pengcheng Zhang},
  doi          = {10.1145/3714463},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-31},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {TAEFuzz: Automatic fuzzing for image-based deep learning systems via transferable adversarial examples},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Signal feature coverage and testing for CPS dataflow models. <em>TOSEM</em>, <em>34</em>(7), 1-37. (<a href='https://doi.org/10.1145/3714467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Design of cyber-physical systems (CPS) typically involves dataflow modeling. The structure of dataflow models differs from the traditional software, making standard coverage metrics not appropriate for measuring the thoroughness of testing. To address this limitation, this article proposes signal feature coverage as a new coverage metric for systematically testing CPS dataflow models. We derive signal feature coverage by leveraging signal features. We developed a testing framework in Simulink, a popular dataflow modeling and simulation environment, that automates the generation and execution of test cases based on the defined coverage metric. We evaluated the effectiveness of our approach by carrying out experiments on five Simulink models tested against ten Signal Temporal Logic specifications. We compared our coverage-based testing approach to adaptive random testing, falsification testing, output diversity-based approaches, and testing using MathWorks’ Simulink Design Verifier. The results demonstrate that our coverage-based testing approach outperforms the conventional techniques regarding fault detection capability.},
  archive      = {J_TOSEM},
  author       = {Ezio Bartocci and Leonardo Mariani and Dejan Nickovic and Drishti Yadav},
  doi          = {10.1145/3714467},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-37},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Signal feature coverage and testing for CPS dataflow models},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Faster and better quantum software testing through specification reduction and projective measurements. <em>TOSEM</em>, <em>34</em>(7), 1-39. (<a href='https://doi.org/10.1145/3714468'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computing (QC) promises polynomial and exponential speedups in many domains, such as unstructured search and prime number factoring. However, quantum programs yield probabilistic outputs from exponentially growing distributions and are vulnerable to quantum-specific faults. Existing quantum software testing (QST) approaches treat quantum superpositions as classical distributions. This leads to two major limitations when applied to quantum programs: (1) an exponentially growing sample space distribution and (2) failing to detect quantum-specific faults such as phase flips. To overcome these limitations, we introduce a QST approach, which applies a reduction algorithm to a quantum program specification. The reduced specification alleviates the limitations (1) by enabling faster sampling through quantum parallelism and (2) by performing projective measurements in the mixed Hadamard basis. Our evaluation of 143 quantum programs across four categories demonstrates significant improvements in test runtimes and fault detection with our reduction approach. Average test runtimes improved from 169.9 s to 11.8 s, with notable enhancements in programs with large circuit depths (383.1 s to 33.4 s) and large program specifications (464.8 s to 7.7 s). Furthermore, our approach increases mutation scores from \(54.5\%\) to \(74.7\%\) , effectively detecting phase flip faults that non-reduced specifications miss. These results underline our approach's importance to improve QST efficiency and effectiveness.},
  archive      = {J_TOSEM},
  author       = {Noah H. Oldfield and Christoph Laaber and Tao Yue and Shaukat Ali},
  doi          = {10.1145/3714468},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-39},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Faster and better quantum software testing through specification reduction and projective measurements},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Introducing phylogenetics in search-based software engineering: Phylogenetics-aware SBSE. <em>TOSEM</em>, <em>34</em>(7), 1-38. (<a href='https://doi.org/10.1145/3715002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phylogenetics studies the relationships, in terms of biological history and kinship, of a set of taxa (e.g., species). We argue that in Search-based Software Engineering (SBSE), the individuals of an evolutionary computation-driven population could be considered as taxa for which the leverage of Phylogenetic Inference might be beneficial. In this work, we present our Phylogenetics-aware SBSE approach. Our approach introduces a novel Phylogenetic Operation to promote results which are sufficiently aligned (in terms of lineage) with a certain reference given by the domain expert. Our approach is evaluated in two heterogeneous industrial case studies: Procedural Content Generation from Game Software Engineering, and Feature Location from Software Maintenance. The results are analyzed using quality-of-the-solution and acceptance-by-developers measurements. We performed a statistical analysis to determine whether the impact on the results is significant compared to baselines that do not leverage Phylogenetics. The results show that our approach significantly outperforms two baselines in both case studies. Furthermore, two focus groups confirmed the acceptance of our approach and stressed that solution acceptance may make the difference in industrial environments. Our work has the potential to motivate a new breed of research work on Phylogenetics awareness to produce better results in Software Engineering.},
  archive      = {J_TOSEM},
  author       = {Daniel Blasco and Antonio Iglesias and Jorge Echeverría and Francisca Pérez and Carlos Cetina},
  doi          = {10.1145/3715002},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-38},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Introducing phylogenetics in search-based software engineering: Phylogenetics-aware SBSE},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid automated program repair by combining large language models and program analysis. <em>TOSEM</em>, <em>34</em>(7), 1-28. (<a href='https://doi.org/10.1145/3715004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated Program Repair (APR) has garnered significant attention due to its potential to streamline the bug repair process for human developers. Recently, LLM-based APR methods have shown promise in repairing real-world bugs. However, existing APR methods often utilize patches generated by LLMs without further optimization, resulting in reduced effectiveness due to the lack of program-specific knowledge. Furthermore, the evaluations of these APR methods have typically been conducted under the assumption of perfect fault localization, which may not accurately reflect their real-world effectiveness. To address these limitations, this article introduces an innovative APR approach called G iant R epair . Our approach leverages the insight that LLM-generated patches, although not necessarily correct, offer valuable guidance for the patch generation process. Based on this insight, G iant R epair first constructs patch skeletons from LLM-generated patches to confine the patch space, and then generates high-quality patches tailored to specific programs through context-aware patch generation by instantiating the skeletons. To evaluate the performance of our approach, we conduct two large-scale experiments. The results demonstrate that G iant R epair not only effectively repairs more bugs (an average of 27.78% on Defects4J v1.2 and 23.40% on Defects4J v2.0) than using LLM-generated patches directly, but also outperforms state-of-the-art APR methods by repairing at least 42 and 7 more bugs under perfect and automated fault localization scenarios, respectively.},
  archive      = {J_TOSEM},
  author       = {Fengjie Li and Jiajun Jiang and Jiajun Sun and Hongyu Zhang},
  doi          = {10.1145/3715004},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-28},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Hybrid automated program repair by combining large language models and program analysis},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The good, the bad, and the monstrous: Predicting highly change-prone source code methods at their inception. <em>TOSEM</em>, <em>34</em>(7), 1-29. (<a href='https://doi.org/10.1145/3715006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cost of software maintenance often surpasses the initial development expenses, making it a significant concern for the software industry. A key strategy for alleviating future maintenance burdens is the early prediction and identification of change-prone code components, which allows for timely optimizations. While prior research has largely concentrated on predicting change-prone files and classes—an approach less favored by practitioners—this article shifts focus to predicting highly change-prone methods, aligning with the preferences of both practitioners and researchers. We analyzed 774,051 source code methods from 49 prominent open source Java projects. Our findings reveal that approximately 80% of changes are concentrated in just 20% of the methods, demonstrating the Pareto 80/20 principle. Moreover, this subset of methods is responsible for the majority of the identified bugs in these projects. After establishing their critical role in mitigating software maintenance costs, our study shows that machine learning models can effectively identify these highly change-prone methods from their inception. Additionally, we conducted a thorough manual analysis to uncover common patterns (or concepts) among the more difficult-to-predict methods. These insights can help future research develop new features and enhance prediction accuracy.},
  archive      = {J_TOSEM},
  author       = {Shaiful Chowdhury},
  doi          = {10.1145/3715006},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-29},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {The good, the bad, and the monstrous: Predicting highly change-prone source code methods at their inception},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An empirical study on challenges for LLM application developers. <em>TOSEM</em>, <em>34</em>(7), 1-37. (<a href='https://doi.org/10.1145/3715007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, large language models (LLMs) have seen rapid advancements, significantly impacting various fields such as computer vision, natural language processing, and software engineering. These LLMs, exemplified by OpenAI's ChatGPT, have revolutionized the way we approach language understanding and generation tasks. However, in contrast to traditional software development practices, LLM development introduces new challenges for AI developers in design, implementation, and deployment. These challenges span different areas (such as prompts, APIs, and plugins), requiring developers to navigate unique methodologies and considerations specific to LLM application development. Despite the profound influence of LLMs, to the best of our knowledge, these challenges have not been thoroughly investigated in previous empirical studies. To fill this gap, we present the first comprehensive study on understanding the challenges faced by LLM developers. Specifically, we crawl and analyze 29,057 relevant questions from a popular OpenAI developer forum. We first examine their popularity and difficulty. After manually analyzing 2,364 sampled questions, we construct a taxonomy of challenges faced by LLM developers. Based on this taxonomy, we summarize a set of findings and actionable implications for LLM-related stakeholders, including developers and providers (especially the OpenAI organization).},
  archive      = {J_TOSEM},
  author       = {Xiang Chen and Chaoyang Gao and Chunyang Chen and Guangbei Zhang and Yong Liu},
  doi          = {10.1145/3715007},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-37},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {An empirical study on challenges for LLM application developers},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated detection and repair of floating-point precision problems in convolutional neural network operators. <em>TOSEM</em>, <em>34</em>(7), 1-32. (<a href='https://doi.org/10.1145/3715104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Network (CNN) operators, mostly based on mathematical linear computations, are of vital importance to developing CNN-based software. Existing studies reveal that these operators are prone to floating-point precision problems (FPPs). In a CNN-based application, such problems can be propagated and result in catastrophic consequences. Thus, it is highly desired to detect and repair the FPPs in CNN operators. Considering the FPPs in CNN operators are mainly caused by accumulated floating-point errors and diverse floating-point tensors instead of wrong codes or bad implementations, it requires much time cost and is difficult to tackle these FPPs. In this article, we propose the first method for the automated detection and repair of FPPs in CNN operators from the perspective of floating-point tensors. To generate diverse tensors with floating-point numbers, we design two levels of mutation rules, namely computation-level mutation and input-level mutation, containing a total of five mutation methods. To detect the FPPs caused by the accumulated floating-point errors, our method uses a weight matrix to guide the progressive mutation. To repair the detected FPPs, our method transforms the error-prone floating-point tensors based on the mathematical rewriting of the floating-point linear computational properties without destroying the original computation. Experimental results show that our methods can detect and repair FPPs in CNN operators effectively and efficiently and could reduce 93.32% to 100% of the FPPs in CNN operators. We conduct a case study on six different widely used CNN models and confirm that the proposed FPP method is generalizable and effective across a variety of tasks and architectures. Our detection and repair method offers an intuitive way to handle FPPs during development, allowing users to continue building and fine-tuning their models without being slowed down by numerical precision errors. We believe that our method could open up a new way to enhance the quality of CNN operators and CNN-based software.},
  archive      = {J_TOSEM},
  author       = {Jiawei Liu and Xufan Zhang and Lurong Xu and Chunrong Fang and Mingzheng Gu and Weisi Luo and Dong Chai and Jiang Wang and Zhihong Zhao and Zhenyu Chen},
  doi          = {10.1145/3715104},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-32},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Automated detection and repair of floating-point precision problems in convolutional neural network operators},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finding safety violations of AI-enabled control systems through the lens of synthesized proxy programs. <em>TOSEM</em>, <em>34</em>(7), 1-35. (<a href='https://doi.org/10.1145/3715105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the increasing adoption of modern AI-enabled control systems, ensuring their safety and reliability has become a critical task in software testing. One prevalent approach to testing control systems is falsification, which aims to find an input signal that causes the control system to violate a formal safety specification using optimization algorithms. However, applying falsification to AI-enabled control systems poses two significant challenges: (1) it requires the system to execute numerous candidate test inputs, which can be time-consuming, particularly for systems with AI models that have many parameters, and (2) multiple safety requirements are typically defined as a conjunctive specification, which is difficult for existing falsification approaches to comprehensively cover. This article introduces Synthify , a falsification framework tailored for AI-enabled control systems, i.e., control systems equipped with AI controllers. Our approach performs falsification in a two-phase process. At the start, Synthify synthesizes a program that implements one or a few linear controllers to serve as a proxy for the AI controller. This proxy program mimics the AI controller’s functionality but is computationally more efficient. Then, Synthify employs the \(\epsilon\) -greedy strategy to sample a promising sub-specification from the conjunctive safety specification. It then uses a Simulated Annealing-based falsification algorithm to find violations of the sampled sub-specification for the control system. To evaluate Synthify , we compare it to PSY-TaLiRo , a state-of-the-art and industrial-strength falsification tool, on eight publicly available control systems. On average, Synthify achieves a 83.5% higher success rate in falsification compared to PSY-TaLiRo with the same budget of falsification trials. Additionally, our method is 12.8 \(\times\) faster in finding a single safety violation than the baseline. The safety violations found by Synthify are also more diverse than those found by PSY-TaLiRo , covering 137.7% more sub-specifications.},
  archive      = {J_TOSEM},
  author       = {Jieke Shi and Zhou Yang and Junda He and Bowen Xu and Dongsun Kim and Donggyun Han and David Lo},
  doi          = {10.1145/3715105},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-35},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Finding safety violations of AI-enabled control systems through the lens of synthesized proxy programs},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing and analyzing the correctness of GitHub copilot’s code suggestions. <em>TOSEM</em>, <em>34</em>(7), 1-32. (<a href='https://doi.org/10.1145/3715108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI programming has become a popular topic in recent years. Code suggestion, with code suggestion being a key capability of AI programming. Copilot, an “AI programmer” that provides code suggestions from natural language descriptions, has been launched by GitHub and OpenAI. By far, Copilot has been widely used by millions of developers. However, little work has systematically evaluated the correctness of Copilot’s suggestions. We conducted an empirical study on all 2,033 LeetCode problems to assess Copilot’s code generation across four mainstream languages: C, Java, JavaScript, and Python. We have found that: (1) 70.0% of problems received at least one correct suggestion, with language-specific rates of 29.7% (C), 57.7% (Java), 54.1% (JavaScript), and 41.0% (Python); (2) correctness decreases as problem difficulty increases, with acceptance rates of 89.3% (easy), 72.1% (medium), and 43.4% (hard); (3) acceptance rates vary across problem domains from 49.5% to 90.1%, while Graph problems challenge C and Python most, and Prefix Sum and Heap challenge Java and JavaScript most; (4) for the incorrect suggestions, we further summarize 17 types of error reasons accounting for their incorrectness and analyzed possible causes for why these errors occur. We believe our study can provide valuable insights into Copilot’s capabilities and limitations.},
  archive      = {J_TOSEM},
  author       = {Ran Mo and Dongyu Wang and Wenjing Zhan and Yingjie Jiang and Yepeng Wang and Yuqi Zhao and Zengyang Li and Yutao Ma},
  doi          = {10.1145/3715108},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-32},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Assessing and analyzing the correctness of GitHub copilot’s code suggestions},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HumanEvalComm: Benchmarking the communication competence of code generation for LLMs and LLM agents. <em>TOSEM</em>, <em>34</em>(7), 1-42. (<a href='https://doi.org/10.1145/3715109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have significantly improved their ability to perform tasks in the field of code generation. However, there is still a gap between LLMs being capable coders and being top-tier software engineers. The most recent trend is using LLM-based agents to iterate the code generation process. Based on the observation that top-level software engineers often ask clarifying questions to reduce Ambiguity in both requirements and coding solutions, we argue that the same should be applied to LLMs for code generation tasks. For this purpose, we define the communication skills of LLMs as “being able to ask clarifying questions when the description of the code generation problem has issues.” In this study, we restrict these issues to three matters from the software requirement engineering field: inconsistent requirements, ambiguous requirements, and incomplete requirements. By asking probing questions about the requirements of problem descriptions before generating the final code, the challenges of programming with LLMs such as unclear intent specification may be alleviated, resulting to a correct code in the initial iterations. In this work, we conducted an empirical study on the benchmark and analysis of the communication skills of LLMs for code generation. We created a new benchmark, HumanEvalComm, by modifying problem descriptions according to three issues mentioned above, Inconsistency , Ambiguity , and Incompleteness . We then experimented on HumanEvalComm with different Code LLMs, and a new LLM agent approach, Code Clarification and Generation Agent (Okanagan), to identify and ask questions in ambiguous parts from code and descriptions for further refining the generated code. In the evaluation, we introduced an LLM-based evaluator and created Communication Rate and Good Question Rate as the evaluation metrics to represent the ratio of questions asked and questions with good quality in responses. We found that more than 60% of responses from Code LLMs still generate code rather than ask questions when the problem descriptions are manually modified according to different clarification categories. The Pass@1 and Test Pass Rate of most Code LLMs drop by 35% — 52% and by 17% — 35%, respectively, with statistical significance in each category for over 75% numbers. Okanagan, as an LLM agent approach that uses LLM such as ChatGPT 3.5, effectively increases the Communication Rate and Good Question Rate by an absolute 58% and 38%, respectively. Thus, Okanagan boosts Pass@1 and Test Pass Rate by an absolute 8% and 7%, respectively, when the problem descriptions are modified based on given clarification categories. This result indicates the potential for achieving more effective communication capability using LLM agent. Our benchmark and full code are publicly available at https://github.com/jie-jw-wu/human-eval-comm .},
  archive      = {J_TOSEM},
  author       = {Jie JW Wu and Fatemeh H. Fard},
  doi          = {10.1145/3715109},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-42},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {HumanEvalComm: Benchmarking the communication competence of code generation for LLMs and LLM agents},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing the robustness of test selection methods for deep neural networks. <em>TOSEM</em>, <em>34</em>(7), 1-26. (<a href='https://doi.org/10.1145/3715693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regularly testing deep learning-powered systems on newly collected data is critical to ensure their reliability, robustness, and efficacy in real-world applications. This process is demanding due to the significant time and human effort required for labeling new data. While test selection methods alleviate manual labor by labeling and evaluating only a subset of data while meeting testing criteria, we observe that such methods with reported promising results are simply evaluated, e.g., testing on original test data. The question arises: are they always reliable? In this article, we explore when and to what extent test selection methods fail. First, we identify potential pitfalls of 11 selection methods based on their construction. Second, we conduct a study to empirically confirm the existence of these pitfalls. Furthermore, we demonstrate how pitfalls can break the reliability of these methods. Concretely, methods for fault detection suffer from data that are: (1) correctly classified but uncertain or (2) misclassified but confident. Remarkably, the test relative coverage achieved by such methods drops by up to 86.85%. Besides, methods for performance estimation are sensitive to the choice of intermediate-layer output. The effectiveness of such methods can be even worse than random selection when using an inappropriate layer.},
  archive      = {J_TOSEM},
  author       = {Qiang Hu and Yuejun Guo and Xiaofei Xie and Maxime Cordy and Wei Ma and Mike Papadakis and Lei Ma and Yves Le Traon},
  doi          = {10.1145/3715693},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-26},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Assessing the robustness of test selection methods for deep neural networks},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language model-aware in-context learning for code generation. <em>TOSEM</em>, <em>34</em>(7), 1-33. (<a href='https://doi.org/10.1145/3715908'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have shown impressive In-Context Learning (ICL) ability in code generation. LLMs take a prompt context consisting of a few demonstration examples and a new requirement as input, and output new programs without any parameter update. Existing studies have found that the performance of ICL-based code generation heavily depends on the quality of demonstration examples and thus arises research on selecting demonstration examples: given a new requirement, a few demonstration examples are selected from a candidate pool, where LLMs are expected to learn the pattern hidden in these selected demonstration examples. Existing approaches are mostly based on heuristics or randomly selecting examples. However, the distribution of randomly selected examples usually varies greatly, making the performance of LLMs less robust. The heuristics retrieve examples by only considering textual similarities of requirements, leading to sub-optimal performance. To fill this gap, we propose a L arge language model- A ware selection approach for I n-context- L earning-based code generation named LAIL. LAIL uses LLMs themselves to select examples. It requires LLMs themselves to label a candidate example as a positive example or a negative example for a requirement. Positive examples are helpful for LLMs to generate correct programs, while negative examples are trivial and should be ignored. Based on the labeled positive and negative data, LAIL trains a model-aware retriever to learn the preference of LLMs and select demonstration examples that LLMs need. During the inference, given a new requirement, LAIL uses the trained retriever to select a few examples and feed them into LLMs to generate desired programs. We apply LAIL to four widely used LLMs and evaluate it on five code generation datasets. Extensive experiments demonstrate that LAIL outperforms the State-of-the-Art (SOTA) baselines by 11.58%, 3.33%, and 5.07% on CodeGen-Multi-16B, 1.32%, 2.29%, and 1.20% on CodeLlama-34B, and achieves 4.38%, 2.85%, and 2.74% improvements on Text-davinci-003 in terms of Pass@1 at MBJP, MBPP, and MBCPP, respectively. In addition to function-level code generation, LAIL improves the performance of LLMs on DevEval, a repository-level code generation dataset, which achieves 10.04%, 8.12%, and 4.63% improvements compared to the SOTA baselines at Pass@1, 3, and 5 on CodeLlama-7B. Human evaluation further verifies that the generated programs of LAIL are superior in correctness, code quality, and maintainability. Besides, LAIL has satisfactory transferability across different LLMs and datasets, where the retriever learned on one LLM (dataset) can be transferred to other LLMs (datasets).},
  archive      = {J_TOSEM},
  author       = {Jia Li and Chongyang Tao and Jia Li♂ and Ge Li and Zhi Jin and Huangzhao Zhang and Zheng Fang and Fang Liu},
  doi          = {10.1145/3715908},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-33},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Large language model-aware in-context learning for code generation},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond decision: Android malware description generation through profiling malicious behavior trajectory. <em>TOSEM</em>, <em>34</em>(7), 1-39. (<a href='https://doi.org/10.1145/3715909'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malware family labels and key features used for the decision-making of Android malware detection models fall short of precise comprehension of malicious behaviors due to their coarse granularity. To solve these problems, in this article, we first introduce the concept of the malicious behavior trajectory ( MBT ) and propose an innovative approach called ProMal . ProMal aims to automatically generate malware descriptions with fine granularity through extracted MBTs from malware for users. Specifically, a labeled dataset of MBTs is constructed through substantial human efforts to build a behavioral knowledge graph ( BxKG ). The BxKG is scalable and can be automatically updated using two strategies to ensure its completeness and timeliness: (1) taking into consideration the evolution of Android SDKs and (2) mining new MBTs by leveraging the widely-used malware datasets. We highlight that the knowledge graph is essential in ProMal , which can reason new MBTs based on existing MBTs because of its structured data representation and semantic relation modeling, and thus helps effectively extract real MBTs in Android malware. We evaluated ProMal on a recent malware dataset where researcher-crafted malware descriptions are available, and the Precision, Recall, and F1-Score of MBT identification based on BxKG reached 96.97%, 91.43%, and 0.94, respectively, outperforming the state-of-the-art approaches. Taking MBTs identified from Android malware as inputs, precise, fine-grained, and human-readable descriptions can be generated using the large language model, whose readability and usability are verified through a user study. The generated descriptions play a significant role in interpreting and comprehending malware behaviors.},
  archive      = {J_TOSEM},
  author       = {Chunlian Wu and Sen Chen and Jiaming Li and Renchao Chai and Lingling Fan and Xiaofei Xie and Ruitao Feng},
  doi          = {10.1145/3715909},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-39},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Beyond decision: Android malware description generation through profiling malicious behavior trajectory},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards reliable evaluation of neural program repair with natural robustness testing. <em>TOSEM</em>, <em>34</em>(7), 1-44. (<a href='https://doi.org/10.1145/3716167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated program repair (APR) has recently gained ground, with numerous research efforts being conducted in the area that have been adopted in the industry. One notable class of APR is neural program repair (NPR), which typically employs deep learning techniques that are trained on vast amounts of historical data to fix bugs that have not been seen in the past. To study the true effectiveness of NPR on existing limited datasets, recent work augments the evaluation data by employing semantics-preserving transformations to convert original buggy programs to semantically equivalent ones. Experiments show that NPR techniques are not robust; e.g., NPR cannot repair semantically equivalent counterparts of 20%–35% of bugs that they can repair in the original dataset. However, we found that many of these transformations are unnatural, that are unlikely to occur in real-world scenarios, leading to misleading conclusions about NPR effectiveness and misguide the improvement on unrobust behaviors, which have minimal real-world impact. In this article, we propose shifting the focus of robustness evaluation for NPR techniques towards naturally occurring data transformations. To accomplish this, we first examine the naturalness of semantic-preserving transformations through a two-stage human study. This study includes: (i) interviews with senior software developers to establish concrete criteria for evaluating the naturalness of these transformations and (ii) a survey involving 10 developers to assess the naturalness of 1,178 transformations, i.e., pairs of original and transformed programs, applied to 225 real-world bugs. Our findings show that only 60% of these transformations are considered natural, while 20% are considered unnatural, with strong agreement among the annotators. Moreover, the unnaturalness of these transformations significantly impacts both their applicability to benchmarks and the conclusions drawn from robustness testing. Next, we conduct natural robustness tests on NPR techniques to assess their true effectiveness against real-world data variations. Our experimental results reveal a substantial number of prediction changes in NPR techniques, leading to significant reductions in both plausible and correct patch rates when comparing performance on the original and transformed datasets. Furthermore, we observe notable differences in performance improvements between NPR techniques, suggesting potential biases in the evaluation of NPR introduced by limited datasets. Finally, we explore automating the assessment of transformation naturalness by developing a new naturalness metric, namely RNC, using large language models. This metric effectively evaluates naturalness with an AUC of 0.7, offering a promising direction for automating the naturalness assessment of code transformations.},
  archive      = {J_TOSEM},
  author       = {Thanh Le-Cong and Dat Nguyen and Bach Le and Toby Murray},
  doi          = {10.1145/3716167},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-44},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Towards reliable evaluation of neural program repair with natural robustness testing},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An empirical study on vulnerability disclosure management of open source software systems. <em>TOSEM</em>, <em>34</em>(7), 1-31. (<a href='https://doi.org/10.1145/3716822'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vulnerability disclosure is critical for ensuring the security and reliability of open source software (OSS). However, in practice, many vulnerabilities are reported and discussed on public platforms before being formally disclosed, posing significant risks to vulnerability management. Inadequate vulnerability disclosure can expose users to security threats and severely impact the stability and reliability of software systems. For example, prior work shows that over 21% of CVEs are publicly discussed before a patch is released. Despite its importance, we still lack clarity on the vulnerability disclosure practices adopted by open source communities and the preferences of practitioners regarding vulnerability management. To fill this gap, we analyzed the vulnerability disclosure practices of 8,073 OSS projects spanning from 2017 to 2023. We then conducted an empirical study by surveying practitioners about their preferences and recommendations in vulnerability disclosure management. Finally, we compared the survey results with the actual vulnerability practice observed within the OSS projects. Our results show that while over 80% of practitioners support Coordinated Vulnerability Disclosure (CVD), only 55% of vulnerabilities conform to CVD in practice. Although only 20% of practitioners advocate discussions before disclosure, 42% of vulnerabilities are discussed in issue reports before their disclosure. This study reveals the vulnerability management practices in OSS, provides valuable guidance to OSS owners, and highlights potential directions to improve the security of OSS platforms.},
  archive      = {J_TOSEM},
  author       = {Shuhan Liu and Jiayuan Zhou and Xing Hu and Filipe Roseiro Cogo and Xin Xia and Xiaohu Yang},
  doi          = {10.1145/3716822},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-31},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {An empirical study on vulnerability disclosure management of open source software systems},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted suspiciousness and balanced aggregation to boost spectrum-based fault localization of deep learning models. <em>TOSEM</em>, <em>34</em>(7), 1-28. (<a href='https://doi.org/10.1145/3716849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) models have proven to be highly successful and are now essential to our everyday routines. However, DL models, like traditional software, inevitably contain bugs that affect their performance in real-world scenarios. Effective software engineering techniques are necessary to ensure their dependability. In recent years, fault localization methods for DL models have gained significant attention as a valuable tool for improving the reliability of DL models. Owing to the data-driven programming paradigm, traditional fault localization techniques are challenging to apply directly to DL programs. Previous studies have shown that neuron errors within models can lead to abnormal behavior, and they fix the DL model errors from the perspective of neurons. Nonetheless, there remains a significant gap between the DL program statement and model errors. To tackle this problem, this article proposes a novel fault localization method for DL models, named weiGhted sUspIciousness anD balancEd aggRegation ( GUIDER ) that revisits the idea and challenge of spectrum-based fault localization in the context of DL models. For pre-trained DL models, GUIDER utilizes neuron coverage information and test case confidence to compute weighted neuron suspiciousness values and employs balanced aggregation methods to elevate these values from the neuron level to the layer level, which establishes a bridge between the DL model and the DL program, facilitating the developers’ debugging process. We evaluate GUIDER using 161 real model bugs collected from StackOverflow and five state-of-the-art fault localization methods for DL models as baselines. The results indicate that (a) our method successfully localizes 67% of the model bugs by ranking the buggy layer to the first place (i.e., top-1), significantly outperforming all five baselines, and (b) our method maintains an acceptable time overhead compared with all baseline methods.},
  archive      = {J_TOSEM},
  author       = {Wenjie Xu and Yanhui Li and Mingliang Ma and Lin Chen and Yuming Zhou},
  doi          = {10.1145/3716849},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-28},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Weighted suspiciousness and balanced aggregation to boost spectrum-based fault localization of deep learning models},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An empirical study of retrieval-augmented code generation: Challenges and opportunities. <em>TOSEM</em>, <em>34</em>(7), 1-28. (<a href='https://doi.org/10.1145/3717061'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code generation aims to automatically generate code snippets of specific programming language according to natural language descriptions. The continuous advancements in deep learning, particularly pre-trained models, have empowered the code generation task to achieve remarkable performance. One main challenge of pre-trained models for code generation is the semantic gap between developers’ natural language requirements and source code. To address the issue, prior studies typically adopt a retrieval-augmented framework for the task, where the similar code snippets collected by a retrieval process can be leveraged to help understand the requirements and provide guidance for the generation process. In a retrieval-augmented framework, similar data can be retrieved from the database using a retrieval algorithm, and original input data can be fused with retrieved data by different fusion strategies. However, there is a lack of systematic study on the application of this framework for code generation, including the impact of the final generated results and the specific usage of the framework. In this article, we choose three popular pre-trained code models, namely CodeGen, UniXcoder, and CodeT5, to assess the impact of the quality and utilization of retrieved code on the retrieval-augmented framework. Our analysis shows that the retrieval-augmented framework is beneficial for improving the performance of the existing pre-trained models. We also provide suggestions on the utilization of the retrieval-augmented code generation framework: BM25 and Sequential Integration Fusion are recommended due to their convenience and superior performance. Sketch Filling Fusion, which extracts a sketch of relevant code, could help the model improve its performance further. Additionally, we conduct experiments to investigate the influence of the retrieval-augmented framework on large language models for code generation, showing the effectiveness of the framework, and we discuss the tradeoff between performance improvement and computational costs in each phase within the framework.},
  archive      = {J_TOSEM},
  author       = {Zezhou Yang and Sirong Chen and Cuiyun Gao and Zhenhao Li and Xing Hu and Kui Liu and Xin Xia},
  doi          = {10.1145/3717061},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-28},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {An empirical study of retrieval-augmented code generation: Challenges and opportunities},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive study of governance issues in decentralized finance applications. <em>TOSEM</em>, <em>34</em>(7), 1-31. (<a href='https://doi.org/10.1145/3717062'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized Finance (DeFi) is a prominent application of smart contracts, representing a novel financial paradigm in contrast to centralized finance. While DeFi applications are rapidly emerging on mainstream blockchain platforms, their quality varies greatly, presenting numerous challenges, particularly in terms of their governance mechanisms. In this article, we present a comprehensive study of governance issues in DeFi applications. Initially, we collected 3,165 academic papers and numerous industry reports. After thorough screening, we selected 44 academic papers and 11 industry reports for detailed analysis. Drawing upon insights from industry reports and academic research articles, we develop a taxonomy to categorize these governance issues. We collect and build a dataset of 4,446 audit reports from 17 Web3 security companies, categorizing their governance issues according to our constructed taxonomy. We conducted a thorough analysis of governance issues and identified vulnerabilities in the governance design and implementation, e.g., voting sybil attack and proposal front-running. Our statistical analysis indicates that a significant portion (35.48%) of governance-related issues is classified as severe. Within these, ownership-related problems constitute the largest share (65.38%). Despite DeFi governance being essential for the long-term success of DeFi projects, our data shows that both auditors and development teams have not fully grasped its significance. Based on audit reports, we also analyzed common vulnerabilities and issues in the governance domain. Our research identifies two primary categories of DeFi governance issues: technology-centric and human-centric. Technology-centric issues can be addressed through technology updates and iterations, whereas human-centric issues are influenced not only by the development team’s technical skills but also by their understanding of DeFi governance. Data analysis reveals that design and implementation issues are frequently overlooked; although not directly associated with vulnerabilities, these issues can impact the equitable distribution of project benefits. Furthermore, our analysis of 104 projects’ tokenomics configurations, including 15 collected from DeFi platforms, uncovered 27 inconsistent configurations, with only two projects exhibiting no issues. This suggests that such issues are relatively common. We therefore advise project teams to ensure consistency between their tokenomics design and the actual code. Our study culminates in providing several key practical implications for various DeFi stakeholders, including developers, users, researchers, and regulators, aiming to deepen the understanding of DeFi governance issues and contribute to the robust growth of DeFi systems.},
  archive      = {J_TOSEM},
  author       = {Wei Ma and Chenguang Zhu and Ye Liu and Xiaofei Xie and Yi Li},
  doi          = {10.1145/3717062},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-31},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {A comprehensive study of governance issues in decentralized finance applications},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward understanding FPGA synthesis tool bugs. <em>TOSEM</em>, <em>34</em>(7), 1-37. (<a href='https://doi.org/10.1145/3718737'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Field Programmable Gate Array (FPGA) synthesis tools are crucial for hardware development and AI acceleration, and their bugs could compromise hardware reliability and risk downstream applications. However, it remains unknown in understanding the characteristics of these bugs. What are the root causes that trigger bugs in FPGA synthesis tools? What are the characteristics of these bugs? What are the challenges in detecting and addressing them? This article takes the first step toward answering these questions by conducting a comprehensive study of FPGA synthesis tool bugs. We analyze 551 confirmed bugs in both commercial and open-source FPGA synthesis tools, i.e., Vivado, Quartus Prime, and Yosys, covering root causes, symptoms, bug-prone components, fix characteristics, and achieve 17 valuable findings. We find that, on average, around 46.2% of bugs result from Hardware Description Language (HDL) standard non-compliance across the three tools. However, it is hard for current formal validations to fully test HDL standards compliance. Additionally, on average, over 25.8% bugs show domain-specific optimization traits due to inappropriate optimization and mapping. Meanwhile, beyond 28% of bugs trigger unexpected behavior without clear signs, making the formulation of effective test oracles challenging. These findings help addressing FPGA synthesis tool bugs and guide further research.},
  archive      = {J_TOSEM},
  author       = {Yi Zhang and He Jiang and Shikai Guo and Xiaochen Li and Hui Liu and Chongyang Shi},
  doi          = {10.1145/3718737},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-37},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Toward understanding FPGA synthesis tool bugs},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterizing smart contract evolution. <em>TOSEM</em>, <em>34</em>(7), 1-22. (<a href='https://doi.org/10.1145/3719004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart contracts are programs that permanently store and automatically execute on the blockchain system such as Ethereum. Due to the non-tamperable nature of the underlying blockchain, smart contracts are difficult to update once deployed, which requires redeploying the contracts and migrating the data. It means that the observation of smart contract evolution in the real world makes more sense. Hence, in this article, we conducted the first large-scale empirical study to characterize the evolution of smart contracts in Ethereum. For evolution identification, we presented a contract similarity-based search algorithm, digEvolution, and evaluated its effectiveness with five different search strategies. Then we applied this algorithm to 80,152 on-chain contracts we collected from Ethereum, to dig out the evolution among these contracts. We then explored three research questions. We first studied whether the evolution of smart contracts is common (RQ1), then we studied how do the Gas consumption (RQ2) and the vulnerability (RQ3) of smart contracts vary during the evolution. Our research results show that the evolution of smart contracts is not very common. There are some contract components that have vulnerability but still be called by users. The Gas consumption of most smart contracts doesn’t vary during the evolution, contract is Gas-efficient before and after the evolution. The vulnerability of most smart contracts doesn’t vary during the evolution, both are secure before and after the evolution.},
  archive      = {J_TOSEM},
  author       = {Xiangping Chen and Ziang Qian and Peiyong Liao and Yuan Huang and Changlin Yang and Zibin Zheng},
  doi          = {10.1145/3719004},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-22},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Characterizing smart contract evolution},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving deep assertion generation via fine-tuning retrieval-augmented pre-trained language models. <em>TOSEM</em>, <em>34</em>(7), 1-23. (<a href='https://doi.org/10.1145/3721128'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unit testing validates the correctness of the units of the software system under test and serves as the cornerstone in improving software quality and reliability. To reduce manual efforts in writing unit tests, some techniques have been proposed to generate test assertions automatically, including Deep Learning (DL)-based, retrieval-based, and integration-based ones. Among them, recent integration-based approaches inherit from both DL-based and retrieval-based approaches and are considered state-of-the-art. Despite being promising, such integration-based approaches suffer from inherent limitations, such as retrieving assertions with lexical matching while ignoring meaningful code semantics and generating assertions with a limited training corpus. In this article, we propose a novel Retrieval-Augmented Deep Assertion Generation (RetriGen) approach based on a hybrid assertion retriever and a Pre-Trained Language Model (PLM)-based assertion generator. Given a focal-test, RetriGen first builds a hybrid assertion retriever to search for the most relevant test–assert pair from external codebases. The retrieval process takes both lexical similarity and semantical similarity into account via a token-based and an embedding-based retriever, respectively. RetriGen then treats assertion generation as a sequence-to-sequence task and designs a PLM-based assertion generator to predict a correct assertion with historical test–assert pairs and the retrieved external assertion. Although our concept is general and can be adapted to various off-the-shelf encoder–decoder PLMs, we implement RetriGen to facilitate assertion generation based on the recent CodeT5 model. We conduct extensive experiments to evaluate RetriGen against six state-of-the-art approaches across two large-scale datasets and two metrics. The experimental results demonstrate that RetriGen achieves 57.66% and 73.24% in terms of accuracy and CodeBLEU, outperforming all baselines with an average improvement of 50.66% and 14.14%, respectively. Furthermore, RetriGen generates 1,598 and 1,818 unique correct assertions that all baselines fail to produce, 3.71X and 4.58X more than the most recent approach EditAS . We also demonstrate that adopting other PLMs can provide substantial advancement, e.g., four additionally utilized PLMs outperform EditAS by 7.91%–12.70% accuracy improvement, indicating the generalizability of RetriGen. Overall, our study highlights the promising future of fine-tuning off-the-shelf PLMs to generate accurate assertions by incorporating external knowledge sources.},
  archive      = {J_TOSEM},
  author       = {Quanjun Zhang and Chunrong Fang and Yi Zheng and Yaxin Zhang and Yuan Zhao and Rubing Huang and Jianyi Zhou and Yun Yang and Tao Zheng and Zhenyu Chen},
  doi          = {10.1145/3721128},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-23},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Improving deep assertion generation via fine-tuning retrieval-augmented pre-trained language models},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Experimental evaluation of parameter-efficient fine-tuning for software engineering tasks. <em>TOSEM</em>, <em>34</em>(7), 1-34. (<a href='https://doi.org/10.1145/3722107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-trained models (PTMs) have succeeded in various software engineering (SE) tasks following the “pre-train then fine-tune” paradigm. As fully fine-tuning all parameters of PTMs can be computationally expensive, a potential solution is parameter-efficient fine-tuning (PEFT), which freezes PTMs while introducing extra parameters. Although PEFT methods have been applied to SE tasks, researchers often focus on specific scenarios and lack a comprehensive comparison of PTMs from different aspects such as field, size, and architecture. To fill this gap, we have conducted an empirical study on six PEFT methods, eight PTMs, and four SE tasks. The experimental results reveal several noteworthy findings. For example, model architecture has little impact on PTM performance when using PEFT methods. Additionally, we provide a comprehensive discussion of PEFT methods from three perspectives. First, we analyze the effectiveness and efficiency of PEFT methods. Second, we explore the impact of the scaling factor hyperparameter. Finally, we investigate the application of PEFT methods on the latest open source large language model, Llama 3.2. These findings provide valuable insights to guide future researchers in effectively applying PEFT methods to SE tasks.},
  archive      = {J_TOSEM},
  author       = {Wentao Zou and Zongwen Shen and Qi Li and Jidong Ge and Chuanyi Li and Xiang Chen and Xiaoyu Shen and Liguo Huang and Bin Luo},
  doi          = {10.1145/3722107},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-34},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Experimental evaluation of parameter-efficient fine-tuning for software engineering tasks},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging risk models to improve productivity for effective code un-freeze at scale. <em>TOSEM</em>, <em>34</em>(7), 1-24. (<a href='https://doi.org/10.1145/3722216'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Changing software is essential to add needed functionality and to fix problems, but changes may introduce defects that lead to outages. This motivates one of the oldest software quality control techniques: a temporary prevention of non-critical changes to the codebase—code freeze. Despite its widespread use in practice, research literature is scant. Historically, code freezes were used as a way to improve software quality by preventing changes during periods before software releases, but code freezes significantly slow down development. To address this shortcoming, we develop and evaluate a family of code un-freeze (permitting changes) strategies tailored to different occasions and products at Meta. They are designed to un-freeze the maximum amount of code without compromising quality. The three primary dimensions to un-freeze involve (a) the exact timing of (and the reasoning behind it) the code freezes, (b) the parts of the organization or the codebase where the codebase freeze is applied to, and (c) the method of screening of the code diffs during the code freeze with the aim to allow low risk diffs and prevent only the most risky diffs. To operationalize the drivers of outages, we consider the entire network of interdependencies among different parts of the source code, the engineers that modify the code, code complexity, and the coordination dependencies and authors’ expertise. Since the code freeze is a balancing act between reducing outages and allowing software development to proceed unimpeded, the performance of the various approaches to code un-freeze is evaluated based on the fraction of flagged/gated changes to measure overhead and the fraction of all outage-causing changes contained within the set of flagged set of changes to measure the ability of the code un-freeze to delay (or prevent) outages. We found that taking into account the risk posed by modifying individual files and the properties of the change we could un-freeze 2 and 2.5 times more changes correspondingly. The change level model is used by Meta in production. For example, during the winter 2023 code freeze, we see that only 16% of changes are gated. Although 42% more changes landed (were integrated into the codebase) compared to the prior year, there was a 52% decrease in outages. This reduction meant less impact on users and less strain on engineers during the holiday period. The risk model has been enormously effective at allowing low-risk changes to proceed while gating high-risk changes and reducing outages.},
  archive      = {J_TOSEM},
  author       = {Audris Mockus and Rui Abreu and Peter C. Rigby and David Amsallem and Parveen Bansal and Kaavya Chinniah and Brian Ellis and Peng Fan and Jun Ge and Bingjie He and Kelly Hirano and Sahil Kumar and Ajay Lingapuram and Andrew Loe and Megh Mehta and Venus Montes and Maher Saba and Gursharan Singh and Matt Steiner and Weiyan Sun and Siri Uppalapati and Nachiappan Nagappan},
  doi          = {10.1145/3722216},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-24},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Leveraging risk models to improve productivity for effective code un-freeze at scale},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wenwang: Toward effectively generating code beyond standalone functions via generative pre-trained models. <em>TOSEM</em>, <em>34</em>(7), 1-27. (<a href='https://doi.org/10.1145/3725213'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code generation models based on the pre-training and fine-tuning paradigm have been increasingly attempted by both academia and industry, resulting in well-known industrial models such as Codex, CodeGen, and PanGu-Coder. After being pre-trained on a large-scale corpus of code, a model is further fine-tuned with datasets specifically for the target downstream task, e.g., generating code from natural language description. The target code being generated can be classified into two types: a standalone function, i.e., a function that invokes or accesses only built-in functions and standard libraries, and a non-standalone function, i.e., a function that invokes or accesses user-defined functions or third-party libraries. To effectively generate code especially non-standalone functions (largely ignored by existing work), in this article, we present Wenwang, an approach to improving the capability of a pre-trained model on generating code beyond standalone functions. Wenwang consists of two components: a fine-tuning dataset named WenwangData and a fine-tuned model named WenwangCoder. Compared with existing fine-tuning datasets, WenwangData additionally covers non-standalone functions. Besides the docstring and code snippet for a function, WenwangData also includes its contextual information collected via program analysis. Based on PanGu-Coder, we produce WenwangCoder by fine-tuning PanGu-Coder on WenwangData with our context-aware fine-tuning technique so that the contextual information can be fully leveraged during code generation. On CoderEval and HumanEval, WenwangCoder outperforms three state-of-the-art models with similar parameter sizes (at the scale of around 300 M), namely CodeGen, PanGu-Coder, and PanGu-FT. Although WenwangCoder does not outperform ChatGPT on HumanEval, WenwangCoder with smaller model parameter sizes can achieve similar effects to ChatGPT on CoderEval. Our experimental results also shed light on a number of promising optimization directions based on existing pre-trained models.},
  archive      = {J_TOSEM},
  author       = {Hao Yu and Bo Shen and Jiaxin Zhang and Shaoxin Lin and Lin Li and Guangtai Liang and Ying Li and Qianxiang Wang and Tao Xie},
  doi          = {10.1145/3725213},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-27},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Wenwang: Toward effectively generating code beyond standalone functions via generative pre-trained models},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autonomous driving system testing via diversity-oriented driving scenario exploration. <em>TOSEM</em>, <em>34</em>(7), 1-28. (<a href='https://doi.org/10.1145/3727875'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Testing Autonomous Driving Systems (ADS) is critical for validating their safety in operational environments. High-fidelity simulators enable the testing of ADS through virtual driving scenarios, especially those that are hazardous to replicate in real-world settings. However, existing testing approaches suffer from inadequate coverage of real-world traffic situations due to over-simplified modeling of vehicle movements (e.g., insufficient diversity in driving styles), resulting in undetected critical ADS failures. In this article, we propose a testing framework to discover diverse failures of ADS in driving scenarios that embody real-world traffic complexity. The framework leverages advanced traffic simulation methods to encode vehicle movements and generates realistic yet safety-critical driving scenarios for ADS by mutating vehicle movements. To efficiently explore driving scenarios that pose different challenges for ADS and expose diverse ADS failures, this framework further leverages a dynamic prioritization mechanism that prioritizes vehicle movements likely to trigger unique ADS behaviors. Specifically, we propose a method to estimate the possibility based on encoded vehicle movements. We implement this framework and evaluate it with three representative ADS from the famous CARLA Leaderboard. Empirical evaluation demonstrates that the proposed approach discovers more unique failures of ADS than existing testing frameworks.},
  archive      = {J_TOSEM},
  author       = {Xinyu Ji and Lei Xue and Zhijian He and Xiapu Luo},
  doi          = {10.1145/3727875},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-28},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Autonomous driving system testing via diversity-oriented driving scenario exploration},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy in chatbot conversation-driven development: A comprehensive review and requirements proposal. <em>TOSEM</em>, <em>34</em>(7), 1-44. (<a href='https://doi.org/10.1145/3730578'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring data privacy is a major challenge for software developers, especially in chatbots, where balancing privacy protection with response quality is key, given the need for conversation-driven development and data protection regulations. This research identifies privacy requirements and techniques for chatbot development through a literature review, privacy policy analysis, and a practitioner survey. The methodology includes a Systematic Literature Review (SLR), an adapted Gray Literature Review (GLR), privacy requirement formulation, and validation via a survey. Based on the SLR and GLR, eight privacy requirements are proposed, covering personal information protection, user authentication, access control, secure communication, database safety, user rights empowerment, decentralized storage, and reliable infrastructure. Survey results highlight foundational measures like secure communication and scalable infrastructures as priorities, while advanced measures such as decentralized storage or privacy rights implementation scored lower due to complexity and cost. Practitioners also stressed clarity and verifiability, citing gaps in definitions, examples, and validation criteria as challenges to adoption.},
  archive      = {J_TOSEM},
  author       = {Geovana Ramos Sousa Silva and Edna Dias Canedo},
  doi          = {10.1145/3730578},
  journal      = {ACM Transactions on Software Engineering and Methodology},
  month        = {8},
  number       = {7},
  pages        = {1-44},
  shortjournal = {ACM Trans. Softw. Eng. Methodol.},
  title        = {Privacy in chatbot conversation-driven development: A comprehensive review and requirements proposal},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
