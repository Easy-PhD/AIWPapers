<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TIST</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tist">TIST - 8</h2>
<ul>
<li><details>
<summary>
(2025). Integrating AI planning with natural language processing: A combination of explicit and tacit knowledge. <em>TIST</em>, <em>16</em>(4), 1-37. (<a href='https://doi.org/10.1145/3729236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural language processing (NLP) aims at investigating the interactions between agents and humans, which processes and analyzes large amounts of natural language data. Large-scale language models play an important role in current NLP. However, the challenges of explainability and complexity come along with the development of language models. One way is to introduce logical relations and rules into NLP models, such as making use of Automated Planning. Automated planning (AI planning) focuses on building symbolic domain models and synthesizing plans to transit initial states to goals based on domain models. Recently, there have been plenty of works related to those two fields, which have the abilities to generate explicit knowledge, e.g., preconditions and effects of action models, and learn from tacit knowledge, e.g., neural models, respectively. Integrating AI planning and NLP effectively improves the communication between human and intelligent agents. This article outlines the commons and relations between AI planning and NLP, and it argues that each of them can effectively impact the other one in six areas: (1) planning-based text understanding, (2) planning-based NLP, (3) text-based human–robot interaction, (4) planning-based explainability, (5) evaluation metrics, and (6) applications. We also explore some potential future issues between AI planning and NLP. To the best of our knowledge, this survey is the first that addresses the deep connections between AI planning and NLP.},
  archive      = {J_TIST},
  author       = {Kebing Jin and Hankz Hankui Zhuo},
  doi          = {10.1145/3729236},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {8},
  number       = {4},
  pages        = {1-37},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Integrating AI planning with natural language processing: A combination of explicit and tacit knowledge},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PREUS: Proactive and robust edge-UAV systems for autonomous monitoring in dynamic environments. <em>TIST</em>, <em>16</em>(4), 1-20. (<a href='https://doi.org/10.1145/3733836'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing and AI can potentially empower Unmanned Aerial Vehicle (UAV) systems with automated decision-making and resource support for monitoring in future science tasks such as emergency response, search and rescue, inspections, and wildfires. However, it is challenging to achieve autonomous and robust monitoring in such systems, given the dynamic environmental situations, the limited capabilities, and the unbalanced load of the UAVs. For instance, the monitoring activity levels at different locations might vary, which leads to an unbalanced monitoring load for the corresponding UAVs. Moreover, the UAVs require regular recharging/maintenance and can have malfunctions that will disrupt the monitoring task. In this article, we develop a novel proactive and robust Edge-UAV framework named PREUS to enable autonomous and efficient monitoring of dynamic environments when faced with dynamic environment situations and various UAV workload stresses that can jeopardize the monitoring performance. PREUS features a unique design to handle the varying UAV workload stress of the monitored area. It incorporates novel spatial, temporal, and proactive exploration vs. exploitation planning to balance the UAVs’ workloads in various locations with fluctuating activities. In addition, PREUS includes novel Deep Reinforcement Learning (DRL) design specialized to maximize coverage in the complex environments and provides faster and stabler decision-making capabilities than the existing methods. The positive impact brought by PREUS is demonstrated in terms of the achieved monitoring performance, including coverage and balanced UAV load.},
  archive      = {J_TIST},
  author       = {Ismail Alqerm and Nuo Cheng and Jianli Pan},
  doi          = {10.1145/3733836},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {8},
  number       = {4},
  pages        = {1-20},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {PREUS: Proactive and robust edge-UAV systems for autonomous monitoring in dynamic environments},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grounding foundation models through federated transfer learning: A general framework. <em>TIST</em>, <em>16</em>(4), 1-54. (<a href='https://doi.org/10.1145/3742788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foundation Models (FMs) such as GPT-4 encoded with vast knowledge and powerful emergent abilities have achieved remarkable success in various natural language processing and computer vision tasks. Grounding FMs by adapting them to domain-specific tasks or augmenting them with domain-specific knowledge enables us to exploit the full potential of FMs. However, grounding FMs faces several challenges, stemming primarily from constrained computing resources, data privacy, model heterogeneity, and model ownership. Federated Transfer Learning (FTL), the combination of federated learning and transfer learning, provides promising solutions to address these challenges. Recently, the need for grounding FMs leveraging FTL, coined FTL-FM, has arisen strongly in both academia and industry. Motivated by the strong growth in FTL-FM research and the potential impact of FTL-FM on industrial applications, we propose an FTL-FM framework that formulates problems of grounding FMs in the federated learning setting, construct a detailed taxonomy based on the FTL-FM framework to categorize state-of-the-art FTL-FM works, and comprehensively overview FTL-FM works based on the proposed taxonomy. We also establish correspondence between FTL-FM and conventional phases of adapting FM so that FM practitioners can align their research works with FTL-FM. In addition, we overview advanced efficiency-improving and privacy-preserving techniques because efficiency and privacy are critical concerns in FTL-FM. Last, we discuss opportunities and future research directions of FTL-FM.},
  archive      = {J_TIST},
  author       = {Yan Kang and Tao Fan and Hanlin Gu and Xiaojin Zhang and Lixin Fan and Qiang Yang},
  doi          = {10.1145/3742788},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {8},
  number       = {4},
  pages        = {1-54},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Grounding foundation models through federated transfer learning: A general framework},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling multi-seasonal multi-behavior dependency for temporal recommendation. <em>TIST</em>, <em>16</em>(4), 1-23. (<a href='https://doi.org/10.1145/3742793'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mining temporal patterns from user behaviors has long been investigated, but most of the existing work centers on single-type user–item interactions, such as purchase or click, which fails to take advantage of the user’s diversified interests revealed by various types of behavior. However, capturing patterns from different behavior sequences and modeling the complex inter-correlation between them are non-trivial tasks, as the high sparsity of type-related interactions, multi-seasonality of individual behaviors, and time-variant dependency of multi-type activities make it really challenging. To address these challenges, we propose a novel framework that aims to model the M ulti-Seasonal M ulti-Behavior Dep endencies (MMDep) both within and across the multi-type behavior sequences. In the proposed model, an item co-occurrence matrix factorization strategy is introduced to alleviate the sparsity issue in type-related behavior sequences. And a temporal dependency module that incorporates multi-scale EMA mechanism is utilized to capture the multi-seasonal dependencies within individual sequences. Moreover, a cross-behavior dependency module is employed to learn the time-variant dependency among different behaviors. Extensive experiments on three real-world datasets demonstrate that the proposed MMDep performs significantly better than the state-of-the-art baselines. And it may provide some new insights and tools on how to leverage multi-behavior data for better temporal recommendation.},
  archive      = {J_TIST},
  author       = {Shichao Liang and Wen Wen and Yali Feng and Ruichu Cai and Zhifeng Hao},
  doi          = {10.1145/3742793},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {8},
  number       = {4},
  pages        = {1-23},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Modeling multi-seasonal multi-behavior dependency for temporal recommendation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Smart imputation, better recommendations: Improving traditional point-of-interest recommendation through data augmentation. <em>TIST</em>, <em>16</em>(4), 1-35. (<a href='https://doi.org/10.1145/3744347'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data sparsity is a persistent challenge in recommender systems, especially in specific domains like Point-of-Interest (POI) recommendation, where it significantly impacts model performance. While classical recommender systems have used various imputation and data augmentation mechanisms to address data sparsity, these methods have not been extensively explored in the POI recommendation domain. In this work, we propose a generic imputation framework to study the use of data augmentation techniques to generate synthetic check-ins and analyze their effects on the POI recommendation scenario. Our main goal is to enhance the performance of various traditional recommenders by increasing the training set interactions, considering specific characteristics of the domain, such as geographical information. We apply these techniques in six different cities from a global Foursquare check-in dataset, as well as in two additional cities from the Gowalla dataset, and a separate dataset from Yelp, ensuring a comprehensive evaluation across multiple data sources. Our imputation approach evidences improvements for most models. In several cases, these improvements exceeded 100% for ranking accuracy, measured in terms of nDCG, without considerably compromising novelty or diversity. Data and code are released at https://github.com/pablosanchezp/ImputationForPOIRecsys .},
  archive      = {J_TIST},
  author       = {Pablo Sánchez and Alejandro Bellogín},
  doi          = {10.1145/3744347},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {8},
  number       = {4},
  pages        = {1-35},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Smart imputation, better recommendations: Improving traditional point-of-interest recommendation through data augmentation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrated hybrid transformer and multi-receptive feature extraction mechanism for electrocardiogram denoising using score-based diffusion model. <em>TIST</em>, <em>16</em>(4), 1-24. (<a href='https://doi.org/10.1145/3744654'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrocardiogram (ECG) is the foundation of the analysis of cardiac disease. In the hospital clinical ECG diagnostic scenarios, when doctors analyze ECG signals or when an ECG intelligent diagnostic system is used, there might be strong noises like baseline wander or muscle artifact in the ECG signals due to the unstable state of the subjects, and such interferences are usually difficult to be filtered out by traditional filters, which can lead to serious errors in the subsequent signal analysis. To solve this problem, we propose a novel network which integrates hybrid transformer and multi-receptive feature extraction mechanism into score-based diffusion model. We used score-based diffusion model to reconstruct the clean ECG signals from noisy ones. The experiment was conducted on the QT Database and the MIT-BIH Noise Stress Test Database to verify the feasibility of our method. Baseline methods are used for comparison. The evaluation results show that our method can achieve an outstanding performance on four distance-based evaluation metrics by at least 26% overall improvement in the comparison with the best baseline method. The study demonstrates that the signal denoising and reconstruction method based on the self-designed score-based diffusion model can effectively remove the interferences in the ECG signals, thereby facilitating the subsequent diagnosis in real-world situation. It also has huge potential for establishing the ECG intelligent analysis system.},
  archive      = {J_TIST},
  author       = {Baofeng Zhu and Wanjun Cheng and Xia Zhang and Jiren Liu},
  doi          = {10.1145/3744654},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {8},
  number       = {4},
  pages        = {1-24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Integrated hybrid transformer and multi-receptive feature extraction mechanism for electrocardiogram denoising using score-based diffusion model},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Counter-samples: A stateless strategy to neutralize black-box adversarial attacks. <em>TIST</em>, <em>16</em>(4), 1-23. (<a href='https://doi.org/10.1145/3744657'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our article introduces a novel defense mechanism against black-box attacks, where attackers exploit the victim model as an oracle to craft adversarial examples. Unlike traditional pre-processing defenses that rely on sanitizing input samples, our stateless strategy directly counters the attack process itself. For each query, we evaluate a counter-sample, an optimized version of the original sample, designed to thwart the attacker’s objective. By responding to every black-box query with a targeted white-box optimization, our strategy introduces a strategic asymmetry that significantly advantages the defender. Our approach proves to be highly effective against state-of-the-art black-box attacks, outperforming existing defenses on both CIFAR-10 and ImageNet datasets. Specifically, our method achieves an average Attack Failure Rate (AFR) of 74.7% (up from 13%) on ImageNet and 67.7% (up from 3.5%) on CIFAR-10 when tested against 10 state-of-the-art query-based black-box attacks. Moreover, it maintains the model’s performance on legitimate inputs, with accuracy (ACC) reduced by only 0.7% on ImageNet and 0.9% on CIFAR-10. This is in stark contrast to other defenses tested, which can cause accuracy drops of up to 50%. Such a modest decrease ensures negligible performance degradation on legitimate tasks. Furthermore, we demonstrate that our defense exhibits superior robustness across datasets and attack scenarios, including adaptive attacks specifically designed to try to bypass our method. This robustness highlights the strength and adaptability of our approach in countering adversarial threats.},
  archive      = {J_TIST},
  author       = {Roey Bokobza and Yisroel Mirsky},
  doi          = {10.1145/3744657},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {8},
  number       = {4},
  pages        = {1-23},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Counter-samples: A stateless strategy to neutralize black-box adversarial attacks},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing reachability in graph-based recommender systems. <em>TIST</em>, <em>16</em>(4), 1-23. (<a href='https://doi.org/10.1145/3744658'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While accuracy has long been prioritized as the primary metric for Recommender Systems (RSs), it is increasingly accepted that the system’s overall quality is not solely determined by this factor. Reachability, the ease with which users can navigate the whole content catalog through recommendations, emerges as a pivotal yet under-explored concept: not only it ensures a smooth experience for users, but it also provides more equitable exposure for the items, avoiding that only a small fraction of popular items get the bulk of the attention. Despite its importance, the few existing studies analyze reachability without attempting a proper optimization. In this article, we study the problem of optimizing the overall reachability of a RS while maintaining high-quality recommendations. We model a user browsing session as a random walk on a recommendation graph, where the links and the transition probabilities are defined based on the relevance score of the recommendation list that the user gets at every step. In this setting, reachability is modeled as the expected length of a path to reach a given item. We introduce two optimization problems, one discrete and one continuous, and characterize their theoretical properties. We then devise two algorithms that outperform non-trivial baseline methods in enhancing reachability while maintaining a high Normalized Discounted Cumulative Gain (nDCG) score. Our experimental results show that, in some settings, our methods are able to improve the reachability metric by 80% while only compromising nDCG by 5%. Moreover, our empirical analysis shows that optimizing for reachability provides positive effects also on other prevalent “beyond-accuracy” metrics.},
  archive      = {J_TIST},
  author       = {Alex Martínez and Federico Cinus and Francesco Bonchi and Jordi Vitrià},
  doi          = {10.1145/3744658},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {8},
  number       = {4},
  pages        = {1-23},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Optimizing reachability in graph-based recommender systems},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
