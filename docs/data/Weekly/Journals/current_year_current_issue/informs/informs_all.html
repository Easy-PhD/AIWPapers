<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>informs</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="deca">DECA - 4</h2>
<ul>
<li><details>
<summary>
(2025). Note: Ordinal equivalence of buying and selling prices for Information—When is constant risk attitude entailed?. <em>DECA</em>, <em>22</em>(3), 227-233. (<a href='https://doi.org/10.1287/deca.2024.0307'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hazen and Sounderpandian (1999) claim to have demonstrated that ordinal equivalence of the buying price and the selling price for information entails that the utility function must have constant risk attitude (i.e., be linear or exponential). However, there is no explicit indication of the scope of the ordinal equivalence assumed—is it within any particular decision problem , or within all decision problems sharing the same utility function ? Here we explore the difference between these two assumptions, providing counterexamples for the constant risk attitude assertion in the first case, and in the second case a proof that buy-sell ordinal equivalence within all decision problems sharing the same utility forces constant risk attitude. In the first case, the simplest counterexample arises from the assertion that more refined information sources have greater information values.},
  archive      = {J_DECA},
  doi          = {10.1287/deca.2024.0307},
  journal      = {Decision Analysis},
  month        = {9},
  number       = {3},
  pages        = {227-233},
  shortjournal = {Decis. Anal.},
  title        = {Note: Ordinal equivalence of buying and selling prices for Information—When is constant risk attitude entailed?},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization scheduling of integrated park energy systems with hydrogen energy storage based on hybrid copula. <em>DECA</em>, <em>22</em>(3), 206-226. (<a href='https://doi.org/10.1287/deca.2024.0261'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the energy utilization efficiency of the comprehensive energy park and the proportion of renewable energy grid connection, this paper first proposes to use the hybrid copula theory to construct a wind power and photovoltaics joint output model, reducing the uncertainty of wind power output and photovoltaic output. Secondly, this paper proposes the participation of hydrogen energy storage equipment in the power system scheduling of integrated energy parks. Hydrogen energy storage, as a clean, efficient, and sustainable carbon-free energy storage technology, can be used to mitigate the impact of wind power and photovoltaics output on the power grid. Finally, this paper proposes to construct an optimized scheduling model that considers economic optimization and proves the economic feasibility of the model through case analysis. The calculation results show that the comprehensive energy operating cost has been reduced by 14.15%, the proportion of thermal power output has been reduced by 32.54%, and the proportion of wind solar combined output has increased by 30.9%.},
  archive      = {J_DECA},
  doi          = {10.1287/deca.2024.0261},
  journal      = {Decision Analysis},
  month        = {9},
  number       = {3},
  pages        = {206-226},
  shortjournal = {Decis. Anal.},
  title        = {Optimization scheduling of integrated park energy systems with hydrogen energy storage based on hybrid copula},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A machine learning-assisted decision-making methodology based on simplex weight generation for non-dominated alternative selection. <em>DECA</em>, <em>22</em>(3), 189-205. (<a href='https://doi.org/10.1287/deca.2024.0188'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multiobjective decision-making problems, it is common to encounter nondominated alternatives. In these situations, the decision-making process becomes complex, as each alternative offers better outcomes for some objectives and worse outcomes for others simultaneously. However, DMs still must choose a single alternative that provides an acceptable balance between the conflicting objectives, which can become exceedingly challenging. To address this scenario, our work introduces a decision-making framework aimed at supporting such decisions. Our proposed framework draws upon concepts from the field of Multi-Criteria Decision Making, and combines a novel simplex-like weight generation method with expert insights and machine learning data-driven procedures to establish an intuitive methodology that empowers DMs to select a single alternative from a range of alternatives. In this paper, we illustrate the effectiveness of our methodology through an example and two real-world decision cases from the oil and gas industry, each involving 128 alternatives and five distinct objectives. Funding: This work was supported by Equinor [Grant 2017/15736-3]; Fundação de Amparo à Pesquisa do Estado de São Paulo [Grant 2017/15736-3].},
  archive      = {J_DECA},
  doi          = {10.1287/deca.2024.0188},
  journal      = {Decision Analysis},
  month        = {9},
  number       = {3},
  pages        = {189-205},
  shortjournal = {Decis. Anal.},
  title        = {A machine learning-assisted decision-making methodology based on simplex weight generation for non-dominated alternative selection},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantile-parameterized distributions for expert knowledge elicitation. <em>DECA</em>, <em>22</em>(3), 169-188. (<a href='https://doi.org/10.1287/deca.2024.0219'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a comprehensive overview of quantile-parameterized distributions (QPDs) as a tool for capturing expert predictions and parametric judgments. We survey a range of methods for constructing distributions that are parameterized by a set of quantile-probability pairs and describe an approach to generalizing them to enhance their tail flexibility. Furthermore, we explore the extension of QPDs to the multivariate setting, surveying the approaches to construct bivariate distributions, which can be adopted to obtain distributions with quantile-parameterized margins. Through this review and synthesis of the previously proposed methods, we aim to enhance the understanding and utilization of QPDs in various domains. Funding: U. Sahlin was funded by the Crafoord Foundation [ref 20200626]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/deca.2024.0219 .},
  archive      = {J_DECA},
  doi          = {10.1287/deca.2024.0219},
  journal      = {Decision Analysis},
  month        = {9},
  number       = {3},
  pages        = {169-188},
  shortjournal = {Decis. Anal.},
  title        = {Quantile-parameterized distributions for expert knowledge elicitation},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijaa">IJAA - 5</h2>
<ul>
<li><details>
<summary>
(2025). Transportation marketplace rate forecast using signature transform. <em>IJAA</em>, <em>55</em>(5), 424-436. (<a href='https://doi.org/10.1287/inte.2025.0251'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Freight transportation marketplace rates are typically challenging to forecast accurately. However, these forecasted rates impact a company’s overall costs and play a key role in the management of the company’s shipping network and the procurement of supply on the open marketplace. In this work, we develop a novel statistical technique based on signature transforms and build a predictive and adaptive model to forecast these marketplace rates. Our technique is based on two key elements of the signature transform: its universal nonlinearity property, which linearizes the feature space and, hence, translates the forecasting problem into a linear regression, and the signature kernel, which allows for comparing efficiently similarities between time series data. Combined, it allows for efficient feature generation and precise identification of seasonality and regime switching in the forecasting process. An algorithm based on our technique has been deployed by Amazon middle-mile trucking operations with far superior forecast accuracy and better interpretability versus commercially available industry models even during periods of extreme disruption, such as the COVID-19 pandemic beginning in 2020 and the onset of the Ukraine conflict in early 2022. Furthermore, our technique captures the influence of business cycles and the heterogeneity of the marketplace, improving prediction accuracy by more than fivefold with an estimated annualized savings of more than $50 million per year since 2021. History: This paper has been accepted for the INFORMS Journal on Applied Analytics Special Issue—2024 Daniel H. Wagner Prize for Excellence in the Practice of Advanced Analytics and Operations Research.},
  archive  = {J},
  doi      = {10.1287/inte.2025.0251},
  journal  = {INFORMS Journal on Applied Analytics},
  month    = {9-10},
  number   = {5},
  pages    = {424-436},
  title    = {Transportation marketplace rate forecast using signature transform},
  volume   = {55},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Redesigning zoning systems for equitable and efficient last-mile delivery at ninja van. <em>IJAA</em>, <em>55</em>(5), 412-423. (<a href='https://doi.org/10.1287/inte.2025.0247'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Efficient last-mile logistics is the key underpinning for sustainable e-commerce growth. As the final leg of delivery services, last-mile delivery is a time-consuming and labor-intensive process that requires careful operational planning and execution. In this paper, we describe the development of a novel zoning optimization framework that determines the assignment of customer locations to last-mile delivery stations for Ninja Van, a leading logistics service provider in Southeast Asia, to improve operational efficiency and work equity. The main technical development is a data-driven zoning optimization model that integrates the additively weighted Voronoi diagram and vehicle routing problem through a subgradient algorithm. The algorithm exploits the primal-dual formulation of the partitioning problem and is flexible enough to handle practical delivery scenarios with varying vehicle capacities and travel speeds. To the best of our knowledge, this is the first zoning optimization model that considers general multivehicle zones with uncertain demand, and these are the main contextual features of Ninja Van and many other logistics companies. The zoning algorithm we develop provides preferable theoretical guarantees. The implementation of the new zoning system at Ninja Van led to an average reduction of 6.6% in the work span for the delivery stations and a 3.5% reduction in driver delivery times. In addition to the monetary benefits from the shortened work hours, the new zoning system contributed to improved worker welfare by balancing workloads and limiting overtime. This zoning optimization also brought transparency and valuable insights into the management of delivery stations and drivers at Ninja Van. History: This paper has been accepted for the INFORMS Journal on Applied Analytics Special Issue—2024 Daniel H. Wagner Prize for Excellence in the Practice of Advanced Analytics and Operations Research. Funding: The research of S.F.W.T. Lim was supported by the Eli Broad College of Business 2024 Summer Research Grant.},
  archive  = {J},
  doi      = {10.1287/inte.2025.0247},
  journal  = {INFORMS Journal on Applied Analytics},
  month    = {9-10},
  number   = {5},
  pages    = {412-423},
  title    = {Redesigning zoning systems for equitable and efficient last-mile delivery at ninja van},
  volume   = {55},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing music station playlists on broadcast radio. <em>IJAA</em>, <em>55</em>(5), 399-411. (<a href='https://doi.org/10.1287/inte.2025.0248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We developed a mathematical optimization–based engine that generates 24/7 music playlists for radio stations subject to strategic scheduling goals and key business rules. Utilizing song metadata, such as tempo and mood; latest song research results produced by machine learning models; and radio listenership data, the engine produces music playlists that optimize strength and diversity simultaneously. The engine has been successfully deployed to production and has shown its power in efficiently and effectively creating customized music playlists for various radio stations. History: This paper has been accepted for the INFORMS Journal on Applied Analytics Special Issue—2024 Daniel H. Wagner Prize for Excellence in the Practice of Advanced Analytics and Operations Research.},
  archive  = {J},
  doi      = {10.1287/inte.2025.0248},
  journal  = {INFORMS Journal on Applied Analytics},
  month    = {9-10},
  number   = {5},
  pages    = {399-411},
  title    = {Optimizing music station playlists on broadcast radio},
  volume   = {55},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). JD.com improves fulfillment efficiency with data-driven integrated assortment planning and inventory allocation. <em>IJAA</em>, <em>55</em>(5), 386-398. (<a href='https://doi.org/10.1287/inte.2025.0245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper presents data-driven approaches for integrated assortment planning and inventory allocation that significantly improve fulfillment efficiency at JD.com, a leading e-commerce company. JD.com uses a two-level distribution network that includes regional distribution centers (RDCs) and front distribution centers (FDCs). Selecting products to stock at FDCs and then, optimizing daily inventory allocation from RDCs to FDCs are critical to improving fulfillment efficiency, which is crucial for enhancing customer experiences. For assortment planning, we propose efficient algorithms to maximize the number of orders that can be fulfilled by FDCs (local fulfillment). For inventory allocation, we develop a novel end-to-end algorithm that integrates forecasting, optimization, and simulation to minimize lost sales and inventory-transfer costs. Numerical experiments demonstrate that our methods outperform existing approaches, increasing local order fulfillment rates by 0.54%, and our inventory allocation algorithm increases FDC demand satisfaction rates by 1.05%. Considering the high-volume operations of JD.com, with millions of weekly orders per region, these improvements yield substantial benefits beyond the company’s established supply chain system. Implementation across JD.com’s network has reduced costs, improved stock availability, and increased local order fulfillment rates for millions of orders annually. History: This paper has been accepted for the INFORMS Journal on Applied Analytics Special Issue—2024 Daniel H. Wagner Prize for Excellence in the Practice of Advanced Analytics and Operations Research. Funding: This research is partially supported by the ITC Mainland-Hong Kong Joint Funding Scheme [MHP/192/23] and the RGC Theme-based Research Scheme [T32-707/22-N].},
  archive  = {J},
  doi      = {10.1287/inte.2025.0245},
  journal  = {INFORMS Journal on Applied Analytics},
  month    = {9-10},
  number   = {5},
  pages    = {386-398},
  title    = {JD.com improves fulfillment efficiency with data-driven integrated assortment planning and inventory allocation},
  volume   = {55},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Introduction: 2024 daniel h. wagner prize for excellence in the practice of advanced analytics and operations research. <em>IJAA</em>, <em>55</em>(5), 383-385. (<a href='https://doi.org/10.1287/inte.2025.intro.v55.n5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The judges for the 2024 Daniel H. Wagner Prize for Excellence in the Practice of Advanced Analytics and Operations Research selected the four finalist papers featured in this special issue of the INFORMS Journal on Applied Analytics . The prestigious Wagner Prize—awarded for achievement in implemented operations research, management science, and advanced analytics—emphasizes the quality and originality of mathematical models along with the clarity of written and oral exposition. This year’s winning application describes a decision support system that integrates optimization techniques and machine learning algorithms to determine the product assortment at front distribution centers (from which delivery operations are managed) and daily inventory allocations from regional distribution centers to front distribution centers across JD.com’s network in China and thus, substantially enhance order fulfillment efficiency and reduce inventory and transfer costs. The remaining three papers describe iHeartMedia’s use of mathematical optimization, song metadata, predictive analytics around song performance, and radio listenership data to create music playlists; the development of a zoning system for Ninja Van to enhance last-mile delivery efficiency and boost customer satisfaction; and the use of signature transforms to predict freight transportation marketplace rates for Amazon trucking operations.},
  archive  = {J},
  doi      = {10.1287/inte.2025.intro.v55.n5},
  journal  = {INFORMS Journal on Applied Analytics},
  month    = {9-10},
  number   = {5},
  pages    = {383-385},
  title    = {Introduction: 2024 daniel h. wagner prize for excellence in the practice of advanced analytics and operations research},
  volume   = {55},
  year     = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijds">IJDS - 5</h2>
<ul>
<li><details>
<summary>
(2025). Call for Papers—INFORMS journal on data science virtual special issue on the dual edge of AI: Catalyzing and challenging the future of energy systems. <em>IJDS</em>, <em>4</em>(3), iii-iv. (<a href='https://doi.org/10.1287/ijds.2026.cfp.v05.n1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJDS},
  doi          = {10.1287/ijds.2026.cfp.v05.n1},
  journal      = {INFORMS Journal on Data Science},
  month        = {7-9},
  number       = {3},
  pages        = {iii-iv},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {Call for Papers—INFORMS journal on data science virtual special issue on the dual edge of AI: Catalyzing and challenging the future of energy systems},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-based feature selection method under budget constraint for multiclass classification problems. <em>IJDS</em>, <em>4</em>(3), 265-282. (<a href='https://doi.org/10.1287/ijds.2024.0050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel graph-based method for budget-constrained feature selection (GB-BC-FS) in multiclass classification problems. The method identifies a subset of features that complement each other’s ability to distinguish between different classes, thereby utilizing the entire feature space while maintaining the model’s predictive performance and adhering to budget constraints on feature costs. This is achieved through an intuitive heuristic based on a scoring function, allowing users to calibrate the solution provided by GB-BC-FS. The calibration prioritizes selecting features with complementary qualities while minimizing the costs associated with feature collection, under constraint compliance. The approach is designed to handle practical limitations, making it suitable for applications where resources like cost and time are constrained. This not only improves computational efficiency but also aligns with broader implications related to optimizing resource utilization and ensuring practical applicability in data-driven industries. The effectiveness of GB-BC-FS was validated through extensive experimental analysis, including two comprehensive experiments with a real case study. These experiments demonstrated that GB-BC-FS significantly outperforms existing state-of-the-art approaches, achieving an average accuracy improvement of 10.4% and saving an average of 85.17% in run time compared with finding the optimal set of features, all while adhering to budget limits. Our code is fully documented and available online at https://github.com/davidlevinwork/gbfs/ . Funding: This work was supported by the Israeli Ministry of Innovation, Science and Technology [Grant 0004323]. Data Ethics & Reproducibility Note: The code capsule is available at https://github.com/davidlevinwork/gbfs/ and in the e-Companion to this article (available at https://doi.org/10.1287/ijds.2024.0050 ).},
  archive      = {J_IJDS},
  doi          = {10.1287/ijds.2024.0050},
  journal      = {INFORMS Journal on Data Science},
  month        = {7-9},
  number       = {3},
  pages        = {265-282},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {Graph-based feature selection method under budget constraint for multiclass classification problems},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic neighbourhood components analysis. <em>IJDS</em>, <em>4</em>(3), 248-264. (<a href='https://doi.org/10.1287/ijds.2023.0018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distance metric learning is a fundamental task in data mining and is known to enhance the performance of various distance-based algorithms. In this paper, we consider stochastic training data in which repeated feature vectors can belong to different classes, a scenario in which existing methods of metric learning are known to struggle. This type of data is common in stochastic simulations, where multidimensional, recurrent system states are subject to inherent randomness. Classification models on such high-resolution simulation-generated data play a critical role in real-time decision making across diverse applications. This paper presents and implements a stochastic version of the popular neighbourhood components analysis. We demonstrate its behaviour on stochastic data using simulation models and reveal its advantages when used for nearest neighbour classification. Meanwhile, the assumptions of stochastic labelling and repeated feature vectors extend to data from various domains, suggesting that the method can attain broad impact. For example, beyond its applications to system control and decision making with digital twin simulation, it may enhance the analysis of data from sensor networks, recommender systems, and crowdsourced platforms, where stochasticity and recurring feature patterns are typical. Funding: This work was supported by the Engineering and Physical Sciences Research Council–funded STOR-i Centre for Doctoral Training at Lancaster University [Grant EP/L015692/1]. In addition, Barry L. Nelson’s work was supported by the U.S. National Science Foundation [Grant DMS-1854562]. Data Ethics & Reproducibility Note: The code capsule is available on Code Ocean at https://doi.org/10.24433/CO.0189724.v5 and in the e-Companion to this article (available at https://doi.org/10.1287/ijds.2023.0018 ).},
  archive      = {J_IJDS},
  doi          = {10.1287/ijds.2023.0018},
  journal      = {INFORMS Journal on Data Science},
  month        = {7-9},
  number       = {3},
  pages        = {248-264},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {Stochastic neighbourhood components analysis},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimating hidden epidemic: A bayesian spatiotemporal compartmental modeling approach. <em>IJDS</em>, <em>4</em>(3), 230-247. (<a href='https://doi.org/10.1287/ijds.2023.0020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efforts to mitigate public health crises have been complicated by unreported cases and the ever-changing trends of those monitored health events across geographic regions and socioeconomic cultures. To resolve both challenges, we propose a Bayesian spatiotemporal susceptible-exposed-infected-recovered-removed (BayST-SEIRD) framework that builds the hidden effects of neighboring communities, local features, and the reporting rates into its transmission mechanism. To alleviate the computational burdens embedded in a fully Bayesian algorithm, we propose an alternating approach that learns the compartmental structure and the spatial effects separately. With a simulation study, we show that this algorithm can accurately retrieve our designed system. Then, we apply BayST-SEIRD to model the coronavirus disease 2019 (COVID-19) dynamics in the metropolitan Atlanta area. We observe that most counties’ reporting rates were below 10% of the projected total infected population and that age and educational level are negatively correlated with the exposing rate, suggesting the needs for stronger incentives for COVID-19 testing and quarantine among the younger population. Importantly, BayST-SEIRD facilitates the reconstruction of actual case counts of the monitored subject among neighboring communities, which is critical to designing impactful public health policy interventions. Funding: This research was supported by the National Center for Advancing Translational Sciences of the National Institutes of Health under Award Number UL1TR002378. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health. The work of K. Paynabar was partially supported by the Fouts Family Chair. Data Ethics & Reproducibility Note: The code capsule is available on Code Ocean at https://codeocean.com/capsule/6447675/tree/v1 and in the e-Companion to this article (available at https://doi.org/10.1287/ijds.2023.0020 ).},
  archive      = {J_IJDS},
  doi          = {10.1287/ijds.2023.0020},
  journal      = {INFORMS Journal on Data Science},
  month        = {7-9},
  number       = {3},
  pages        = {230-247},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {Estimating hidden epidemic: A bayesian spatiotemporal compartmental modeling approach},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Observational vs. experimental data when making automated decisions using machine learning. <em>IJDS</em>, <em>4</em>(3), 197-229. (<a href='https://doi.org/10.1287/ijds.2023.0012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decisions supported by machine learning often aim to improve outcomes through interventions, such as influencing purchasing behavior with ads or increasing customer retention with special offers. However, using observational data to estimate these effects can introduce confounding bias. Although experimental data can mitigate confounding, it is not always feasible to obtain and can be costly when it is. This paper presents theoretical results focusing on the impact of confounding on decision making, emphasizing that optimizing decisions often involves determining whether a causal effect exceeds a threshold rather than minimizing bias in the estimate. Consequently, models built with readily available but confounded data can sometimes yield decisions as good as or better than those based on costly, unconfounded data. This can occur when larger effects are more likely to be overestimated or when the benefits of larger, cheaper data sets outweigh the drawbacks of confounding. We validate the theoretical findings using benchmark data from the 2016 Atlantic Causal Inference Conference causal modeling competition, encompassing 77 scenarios and 7,700 data sets. We then introduce theoretical conditions, weaker than ignorability, that characterize when confounding preserves effect rankings. These conditions allow for empirical heuristic tests to assess whether observational data aligns with this structure. Finally, we apply our findings in a large-scale case study using advertising data, demonstrating how these insights can guide decision making in practice. Funding: This research, including Yanfang Hou’s contributions, was supported by the Research Grants Council [Grant 26500822]. The authors thank Ira Rennert and the New York University/Stern Fubon Center for support. Data Ethics & Reproducibility Note: The code capsule is available on Code Ocean at https://doi.org/10.24433/CO.6587526.v1 and in the e-Companion to this article (available at https://doi.org/10.1287/ijds.2023.0012 ).},
  archive      = {J_IJDS},
  doi          = {10.1287/ijds.2023.0012},
  journal      = {INFORMS Journal on Data Science},
  month        = {7-9},
  number       = {3},
  pages        = {197-229},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {Observational vs. experimental data when making automated decisions using machine learning},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijoc">IJOC - 18</h2>
<ul>
<li><details>
<summary>
(2025). On discrete subproblems in integer optimal control with total variation regularization in two dimensions. <em>IJOC</em>, <em>37</em>(4), 1121-1141. (<a href='https://doi.org/10.1287/ijoc.2024.0680'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze integer linear programs that we obtain after discretizing two-dimensional subproblems arising from a trust-region algorithm for mixed integer optimal control problems with total variation regularization. We discuss NP-hardness of the discretized problems and the connection to graph-based problems. We show that the underlying polyhedron exhibits structural restrictions in its vertices with regard to which variables can attain fractional values at the same time. Based on this property, we derive cutting planes by employing a relation to shortest-path and minimum bisection problems. We propose a branching rule and a primal heuristic which improves previously found feasible points. We validate the proposed tools with a numerical benchmark in a standard integer programming solver. We observe a significant speedup for medium-sized problems. Our results give hints for scaling toward larger instances in the future. History: Accepted by Andrea Lodi, Area Editor for Design & Analysis of Algorithms–Discrete. Funding: This work was supported by the Deutsche Forschungsgemeinschaft [Grant MA 10080/2-1]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2024.0680 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2024.0680 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2024.0680},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {1121-1141},
  shortjournal = {INFORMS J. Comput.},
  title        = {On discrete subproblems in integer optimal control with total variation regularization in two dimensions},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new approximation algorithm for minimum-weight (1,m)–Connected dominating set. <em>IJOC</em>, <em>37</em>(4), 1106-1120. (<a href='https://doi.org/10.1287/ijoc.2023.0306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider a graph with nonnegative node weight. A vertex subset is called a CDS (connected dominating set) if every other node has at least one neighbor in the subset and the subset induces a connected subgraph. Furthermore, if every other node has at least m neighbors in the subset, then the node subset is called a ( 1 , m ) CDS. The minimum-weight ( 1 , m ) CDS problem aims at finding a ( 1 , m ) CDS with minimum total node weight. In this paper, we present a new polynomial-time approximation algorithm for this problem, which improves previous ratio by a factor of 2/3. History: Accepted by Erwin Pesch, Area Editor for Heuristic Search & Approximation Algorithms. Funding: This work was supported by the National Natural Science Foundation of China [Grant U20A2068] and the National Science Foundation [Grant III-1907472]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0306 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0306 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0306},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {1106-1120},
  shortjournal = {INFORMS J. Comput.},
  title        = {A new approximation algorithm for minimum-weight (1,m)–Connected dominating set},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simulating confidence intervals for conditional value-at-risk via least-squares metamodels. <em>IJOC</em>, <em>37</em>(4), 1087-1105. (<a href='https://doi.org/10.1287/ijoc.2023.0394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metamodeling techniques have been applied to approximate portfolio loss as a function of financial risk factors, thus producing point estimates of various measures of portfolio risk based on Monte Carlo samples. Rather than point estimates, this paper focuses on the construction of confidence intervals (CIs) for a widely used risk measure, the so-called conditional value-at-risk (CVaR), when the least-squares method (LSM) is employed as a metamodel in the point estimation. To do so, we first develop lower and upper bounds of CVaR and construct CIs for these bounds. Then, the lower end of the CI for the lower bound and the upper end of the CI for the upper bound together form a CI of CVaR with justifiable statistical guarantee, which accounts for both the metamodel error and the noises of Monte Carlo samples. The proposed CI procedure reuses the samples simulated for LSM point estimation, thus requiring no additional simulation budget. We demonstrate via numerical examples that the proposed procedure may lead to a CI with the desired coverage probability and a much smaller width than that of an existing CI in the literature. History: Accepted by Bruno Tuffin, Area Editor for Simulation. Funding: This research was supported by the National Natural Science Foundation of China (NNSFC) [Grants 72101260 and 72471232], the Research Grants Council of Hong Kong (RGC-HK) [General Research Fund Project 11508620], InnoHK Initiative, the Government of the HKSAR, and Laboratory for AI-Powered Financial Technologies, and NNSFC/RGC-HK Joint Research Scheme [Project N_CityU 105/21]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0394 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0394 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0394},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {1087-1105},
  shortjournal = {INFORMS J. Comput.},
  title        = {Simulating confidence intervals for conditional value-at-risk via least-squares metamodels},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On interdicting dense clusters in a network. <em>IJOC</em>, <em>37</em>(4), 1069-1086. (<a href='https://doi.org/10.1287/ijoc.2023.0027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a vertex-weighted undirected graph with blocking costs of its vertices and edges, we seek a minimum cost subset of vertices and edges to block such that the weight of any γ -quasi-clique in the interdicted graph is at most some predefined threshold parameter. The value of γ ∈ ( 0 , 1 ] specifies the edge density of cohesive vertex groups of interest in the network. The considered weighted γ-quasi-clique interdiction problem can be viewed as a natural generalization of several variations of the clique blocker problem previously studied in the literature. From the application perspective, this setting is primarily motivated by the problem of disrupting adversarial (“dark”) networks (e.g., social or communication networks), where γ -quasi-cliques represent “tightly knit” groups of adversaries that we aim to dismantle. We first address the theoretical computational complexity of the problem. We then exploit some basic characterization of its feasible solutions to derive a linear integer programming (IP) formulation. This linear IP model can be solved using a lazy-fashioned branch-and-cut scheme. We also propose a combinatorial branch-and-bound algorithm for solving this problem. The computational performance of the developed exact solution schemes is studied using a test bed of randomly generated and real-life networks. Finally, some interesting insights and observations are also provided using a well-known example of a terrorist network. History: Accepted by Russel Bent, Area Editor for Network Optimization: Algorithms & Applications. Funding: The work of S. Butenko was partially supported by the Air Force Office of Scientific Research under Award FA9550-23-1-0300. The work of O. A. Prokopyev was partially supported by the Office of Naval Research under Award ONR N00014-22-1-2678. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0027 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0027 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ . The online appendix is available at https://doi.org/10.1287/ijoc.2023.0027 .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0027},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {1069-1086},
  shortjournal = {INFORMS J. Comput.},
  title        = {On interdicting dense clusters in a network},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An algorithm for clustering with confidence-based must-link and cannot-link constraints. <em>IJOC</em>, <em>37</em>(4), 1044-1068. (<a href='https://doi.org/10.1287/ijoc.2023.0419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study here the semisupervised k -clustering problem where information is available on whether pairs of objects are in the same or different clusters. This information is available either with certainty or with a limited level of confidence. We introduce the pair-wise confidence constraints clustering (PCCC) algorithm, which iteratively assigns objects to clusters while accounting for the information provided on the pairs of objects. Our algorithm uses integer programming for the assignment of objects, which allows us to include relationships as hard constraints that are guaranteed to be satisfied or as soft constraints that can be violated subject to a penalty. This flexibility distinguishes our algorithm from the state of the art, in which all pair-wise constraints are considered hard or all are considered soft. We developed an enhanced multistart approach and a model-size reduction technique for the integer program that contribute to the effectiveness and efficiency of the algorithm. Unlike existing algorithms, our algorithm scales to large-scale instances with up to 60,000 objects, 100 clusters, and millions of cannot-link constraints (which are the most challenging constraints to incorporate). We compare the PCCC algorithm with state-of-the-art approaches in an extensive computational study. Even though the PCCC algorithm is more general than the state-of-the-art approaches in its applicability, it outperforms the state-of-the-art approaches on instances with all hard or all soft constraints in terms of both run time and various metrics of solution quality. The code of the PCCC algorithm is publicly available on GitHub. History: Accepted by Ram Ramesh, Area Editor for Data Science and Machine Learning. Funding: The research of D. S. Hochbaum was supported by the AI Institute NSF Award [Grant 2112533]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0419 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0419 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0419},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {1044-1068},
  shortjournal = {INFORMS J. Comput.},
  title        = {An algorithm for clustering with confidence-based must-link and cannot-link constraints},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient optimization model and tabu Search–Based global optimization approach for the continuous p-dispersion problem. <em>IJOC</em>, <em>37</em>(4), 1018-1043. (<a href='https://doi.org/10.1287/ijoc.2023.0089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous p -dispersion problems with and without boundary constraints are NP-hard optimization problems with numerous real-world applications, notably in facility location and circle packing, which are widely studied in mathematics and operations research. In this work, we concentrate on general cases with a nonconvex multiply connected region that are rarely studied in the literature due to their intractability and the absence of an efficient optimization model. Using the penalty function approach, we design a unified and almost everywhere differentiable optimization model for these complex problems and propose a tabu search–based global optimization (TSGO) algorithm for solving them. Computational results over a variety of benchmark instances show that the proposed model works very well, allowing popular local optimization methods (e.g., the quasi-Newton methods and the conjugate gradient methods) to reach high-precision solutions due to the differentiability of the model. These results further demonstrate that the proposed TSGO algorithm is very efficient and significantly outperforms several popular global optimization algorithms in the literature, improving the best-known solutions for several existing instances in a short computational time. Experimental analyses are conducted to show the influence of several key ingredients of the algorithm on computational performance. History: Accepted by Erwin Pesch, Area Editor for Heuristic Search & Approximation Algorithms. Funding: This work was supported by the National Natural Science Foundation of China [Grants 72122006, 71821001, and 72471100] Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0089 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0089 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0089},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {1018-1043},
  shortjournal = {INFORMS J. Comput.},
  title        = {An efficient optimization model and tabu Search–Based global optimization approach for the continuous p-dispersion problem},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fraud detection by integrating multisource heterogeneous presence-only data. <em>IJOC</em>, <em>37</em>(4), 998-1017. (<a href='https://doi.org/10.1287/ijoc.2023.0366'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In credit fraud detection practice, certain fraudulent transactions often evade detection because of the hidden nature of fraudulent behavior. To address this issue, an increasing number of positive-unlabeled (PU) learning techniques have been employed by more and more financial institutions. However, most of these methods are designed for single data sets and do not take into account the heterogeneity of data when they are collected from different sources. In this paper, we propose an integrative PU learning method (I-PU) for pooling information from multiple heterogeneous PU data sets. A novel approach that penalizes group differences is developed to explicitly and automatically identify the cluster structures of coefficients across different data sets, thus offering a plausible interpretation of heterogeneity. Furthermore, we apply a bilevel selection method to detect the sparse structure at both the group level and within-group level. Theoretically, we show that our proposed estimator has the oracle property. Computationally, we design an expectation-maximization (EM) algorithm framework and propose an alternating direction method of multipliers (ADMM) algorithm to solve it. Simulation results show that our proposed method has better numerical performance in terms of variable selection, parameter estimation, and prediction ability. Finally, a real-world application showcases the effectiveness of our method in identifying distinct coefficient clusters and its superior prediction performance compared with direct data merging or separate modeling. This result also offers valuable insights for financial institutions in developing targeted fraud detection systems. History: Accepted by Ram Ramesh, Area Editor for Data Science & Machine Learning. Funding: This work was supported by the National Natural Science Foundation of China [Grants 72071169, 72231005, 72233002, and 72471169], the Fundamental Research Funds for the Central Universities of China [Grant 20720231060], the National Social Science Fund of China [Grant 21&ZD146], and Shuimu Tsinghua Scholar Program. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0366 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0366 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0366},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {998-1017},
  shortjournal = {INFORMS J. Comput.},
  title        = {Fraud detection by integrating multisource heterogeneous presence-only data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain-independent dynamic programming and constraint programming approaches for assembly line balancing problems with setups. <em>IJOC</em>, <em>37</em>(4), 977-997. (<a href='https://doi.org/10.1287/ijoc.2024.0603'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose domain-independent dynamic programming (DIDP) and constraint programming (CP) models to exactly solve type 1 and type 2 assembly line balancing problem with sequence-dependent setup times (SUALBPs). The goal is to assign tasks to assembly stations and to sequence these tasks within each station while satisfying precedence relations specified between a subset of task pairs. Each task has a given processing time and a setup time dependent on the previous task on the station to which the task is assigned. The sum of the processing and setup times of tasks assigned to each station constitute the station time and the maximum station time is called the cycle time. For the type 1 SUALBP (SUALBP-1), the objective is to minimize the number of stations, given a maximum cycle time. For the type 2 SUALBP (SUALBP-2), the objective is to minimize the cycle time, given the number of stations. On a set of diverse SUALBP instances, experimental results show that our approaches significantly outperform the state-of-the-art mixed integer programming models for SUALBP-1. For SUALBP-2, the DIDP model outperforms the state-of-the-art exact approach based on logic-based Benders decomposition. By closing 76 open instances for SUALBP-2, our results demonstrate the promise of DIDP for solving complex planning and scheduling problems. History: Accepted by Pascal Van Hentenryck, Area Editor for Computational Modeling: Methods and Analysis. Funding: This work was supported by Natural Sciences and Engineering Research Council of Canada [Grant RGPIN-2020-04039]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2024.0603 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2024.0603 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2024.0603},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {977-997},
  shortjournal = {INFORMS J. Comput.},
  title        = {Domain-independent dynamic programming and constraint programming approaches for assembly line balancing problems with setups},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A peaceman-rachford splitting method for the protein side-chain positioning problem. <em>IJOC</em>, <em>37</em>(4), 962-976. (<a href='https://doi.org/10.1287/ijoc.2023.0094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the NP-hard protein side-chain positioning ( SCP ) problem, an important final task of protein structure prediction. We formulate the SCP as an integer quadratic program and derive its doubly nonnegative (DNN) (convex) relaxation. Strict feasibility fails for this DNN relaxation. We apply facial reduction to regularize the problem. This gives rise to a natural splitting of the variables. We then use a variation of the Peaceman-Rachford splitting method to solve the DNN relaxation. The resulting relaxation and rounding procedures provide strong approximate solutions. Empirical evidence shows that almost all our instances of this NP-hard SCP problem, taken from the Protein Data Bank, are solved to provable optimality . Our large problems correspond to solving a DNN relaxation with 2,883,601 binary variables to provable optimality. History: Accepted by Paul Brooks, Area Editor for Applications in Biology, Medicine, & Healthcare. Funding: This research was supported by the Natural Sciences and Engineering Research Council of Canada [Grants 50503-10827 and RGPIN-2016-04660]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0094 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0094 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0094},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {962-976},
  shortjournal = {INFORMS J. Comput.},
  title        = {A peaceman-rachford splitting method for the protein side-chain positioning problem},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting urban traffic states with sparse data using hankel temporal matrix factorization. <em>IJOC</em>, <em>37</em>(4), 945-961. (<a href='https://doi.org/10.1287/ijoc.2022.0197'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting urban traffic states is crucial to transportation network monitoring and management, playing an important role in the decision-making process. Despite the substantial progress that has been made in developing accurate, efficient, and reliable algorithms for traffic forecasting, most existing approaches fail to handle sparsity, high-dimensionality, and nonstationarity in traffic time series and seldom consider the temporal dependence between traffic states. To address these issues, this work presents a Hankel temporal matrix factorization (HTMF) model using the Hankel matrix in the lower dimensional spaces under a matrix factorization framework. In particular, we consider an alternating minimization scheme to optimize the factor matrices in matrix factorization and the Hankel matrix in the lower dimensional spaces simultaneously. To perform traffic state forecasting, we introduce two efficient estimation processes on real-time incremental data, including an online imputation (i.e., reconstruct missing values) and an online forecasting (i.e., estimate future data points). Through extensive experiments on the real-world Uber movement speed data set in Seattle, Washington, we empirically demonstrate the superior forecasting performance of HTMF over several baseline models and highlight the advantages of HTMF for addressing sparsity, nonstationarity, and short time series. History: Accepted by Ram Ramesh, Area Editor for Data Science & Machine Learning. Funding: This research was supported by the Institute for Data Valorisation, the Interuniversity Research Centre on Enterprise Networks, Logistics and Transportation, the National Natural Science Foundation of China [Grants 12371456, 72101049, 72232001], the Sichuan Science and Technology Program [Grant 2024NSFJQ0038], and the Fundamental Research Funds for the Central Universities [Grant DUT23RC(3)045].},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0197},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {945-961},
  shortjournal = {INFORMS J. Comput.},
  title        = {Forecasting urban traffic states with sparse data using hankel temporal matrix factorization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining precision boosting with LP iterative refinement for exact linear optimization. <em>IJOC</em>, <em>37</em>(4), 933-944. (<a href='https://doi.org/10.1287/ijoc.2023.0409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies a combination of the two state-of-the-art algorithms for the exact solution of linear programs (LPs) over the rational numbers in practice, that is, without any roundoff errors or numerical tolerances. By integrating the method of precision boosting inside an LP iterative refinement loop, the combined algorithm is able to leverage the strengths of both methods: the speed of LP iterative refinement, in particular, in the majority of cases when a double-precision floating-point solver is able to compute approximate solutions with small errors, and the robustness of precision boosting whenever extended levels of precision become necessary. We compare the practical performance of the resulting algorithm with both pure methods on a large set of LPs and mixed-integer programs (MIPs). The results show that the combined algorithm solves more instances than a pure LP iterative refinement approach while being faster than pure precision boosting. When embedded in an exact branch-and-cut framework for MIPs, the combined algorithm is able to reduce the number of failed calls to the exact LP solver to zero while maintaining the speed of the pure LP iterative refinement approach. History: Accepted by Antonio Frangioni, Area Editor for Design and Analysis of Algorithms: Continuous. Funding: The work for this article has been conducted within the Research Campus Modal funded by the German Federal Ministry of Education and Research (BMBF) [Grants 05M14ZAM and 05M20ZBM].},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0409},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {933-944},
  shortjournal = {INFORMS J. Comput.},
  title        = {Combining precision boosting with LP iterative refinement for exact linear optimization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pairwise stability in weighted network formation games: Selection and computation. <em>IJOC</em>, <em>37</em>(4), 917-932. (<a href='https://doi.org/10.1287/ijoc.2024.0546'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the selection and computation of pairwise stable networks when agents have differentiable and concave utility functions. We show that a pairwise stable network can be obtained by finding a Nash equilibrium of a noncooperative game played by the nodes and links in the network. Based on this observation, we introduce a logarithmic tracing procedure and a path-following algorithm for network formation games. We apply the algorithm to several models in the literature and make comparisons with two existing algorithms: a path-following algorithm based on the linear tracing procedure (LinTP) and a decompose and exhaustive search method (DaE). Numerical results indicate that the proposed method is more than four times as efficient as LinTP. Although DaE demonstrates exceptional efficiency for small-scale problems, our method outperforms it significantly for large-scale problems, where DaE may fail to find a solution. We also show that the decomposition technique of DaE can be used to further accelerate our algorithm for a special class of problems. History: Accepted by Antonio Frangioni, Area Editor for Design & Analysis of Algorithms–Continuous. Funding: This work was supported in part by the National Natural Science Foundation of China [Grants 12201289, 12122107, and 72394363/72394360], the Natural Science Foundation of Jiangsu Province [Grant BK20220754], the Guangdong Basic and Applied Basic Research Foundation [Grant 2021A1515110207], the Young Elite Scientists Sponsorship Program by CAST [Grant 2023QNRC001], and the Open Research Fund from the Guangdong Provincial Key Laboratory of Big Data Computing [Grant B10120210117-OF05]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2024.0546 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2024.0546 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2024.0546},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {917-932},
  shortjournal = {INFORMS J. Comput.},
  title        = {Pairwise stability in weighted network formation games: Selection and computation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep stacking kernel machines for the data-driven multi-item, one-warehouse, multiretailer problems with backlog and lost sales. <em>IJOC</em>, <em>37</em>(4), 894-916. (<a href='https://doi.org/10.1287/ijoc.2022.0365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The data-driven, multi-item, one-warehouse, multiretailer (OWMR) problem is examined by leveraging historical data and using machine learning methods to improve the ordering decisions in a two-echelon supply chain. A deep stacking kernel machine (DSKM) and its adaptive reweighting extension (ARW-DSKM), fusing deep learning and support vector machines, are developed for the data-driven, multi-item OWMR problems with backlog and lost sales. Considering the temporal network structure and the constraints connecting the subproblems for each item and each retailer, a Lagrange relaxation–based, trilevel, optimization algorithm and a greedy heuristic with good theoretical properties are developed to train the proposed DSKM and ARW-DSKM at acceptable computational costs. Empirical studies are conducted on two retail data sets, and the performances of the proposed methods and some benchmark methods are compared. The DSKM and the ARW-DSKM obtained the best results among the proposed and benchmark methods for the applications of ordering decisions with and without censored demands and with and without new items. Moreover, the implications in selecting suitable, that is, prediction-then-optimization and joint-prediction-and-optimization, frameworks, models/algorithms, and features are investigated. History: Accepted by Ram Ramesh, Area Editor for Data Science and Machine Learning. Funding: This work was supported by the National Natural Science Foundation of China [Grant 72371062]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0365 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0365 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0365},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {894-916},
  shortjournal = {INFORMS J. Comput.},
  title        = {Deep stacking kernel machines for the data-driven multi-item, one-warehouse, multiretailer problems with backlog and lost sales},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clustering then estimation of spatio-temporal self-exciting processes. <em>IJOC</em>, <em>37</em>(4), 874-893. (<a href='https://doi.org/10.1287/ijoc.2022.0351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new estimation procedure for general spatio-temporal point processes that include a self-exciting feature. Estimating spatio-temporal self-exciting point processes with observed data is challenging, partly because of the difficulty in computing and optimizing the likelihood function. To circumvent this challenge, we employ a Poisson cluster representation for spatio-temporal self-exciting point processes to simplify the likelihood function and develop a new estimation procedure called “clustering-then-estimation” (CTE), which integrates clustering algorithms with likelihood-based estimation methods. Compared with the widely used expectation-maximization (EM) method, our approach separates the cluster structure inference of the data from the model selection. This has the benefit of reducing the risk of model misspecification. Our approach is computationally more efficient because it does not need to recursively solve optimization problems, which would be needed for EM. We also present asymptotic statistical results for our approach as theoretical support. Experimental results on several synthetic and real data sets illustrate the effectiveness of the proposed CTE procedure. History: Accepted by Ram Ramesh, Area Editor for Data Science & Machine Learning. Funding: J. Anderson is supported by NSF [Grant ECCS-2144634]. R. Righter is supported by the Ron Wolff Chaired Professorship. Z. Zheng is supported by NSF [Grant DMS-2220537]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0351 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0351 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0351},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {874-893},
  shortjournal = {INFORMS J. Comput.},
  title        = {Clustering then estimation of spatio-temporal self-exciting processes},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decision making under cumulative prospect theory: An alternating direction method of multipliers. <em>IJOC</em>, <em>37</em>(4), 856-873. (<a href='https://doi.org/10.1287/ijoc.2023.0243'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel numerical method for solving the problem of decision making under cumulative prospect theory (CPT), where the goal is to maximize utility subject to practical constraints, assuming only finite realizations of the associated distribution are available. Existing methods for CPT optimization rely on particular assumptions that may not hold in practice. To overcome this limitation, we present the first numerical method with a theoretical guarantee for solving CPT optimization using an alternating direction method of multipliers (ADMM). One of its subproblems involves optimization with the CPT utility subject to a chain constraint, which presents a significant challenge. To address this, we develop two methods for solving this subproblem. The first method uses dynamic programming, whereas the second method is a modified version of the pooling-adjacent-violators algorithm that incorporates the CPT utility function. Moreover, we prove the theoretical convergence of our proposed ADMM method and the two subproblem-solving methods. Finally, we conduct numerical experiments to validate our proposed approach and demonstrate how CPT’s parameters influence investor behavior, using real-world data. History: Accepted by Antonio Frangioni, Area Editor for Design & Analysis of Algorithms: Continuous. Funding: This research was supported by the National Natural Science Foundation of China [Grants 12171100, 71971083, and 72171138], the Natural Science Foundation of Shanghai [Grant 22ZR1405100], the Major Program of the National Natural Science Foundation of China [Grants 72394360, 72394364], the Program for Innovative Research Team of Shanghai University of Finance and Economics [Grant 2020110930], Fundamental Research Funds for the Central Universities, and the Open Research Fund of Key Laboratory of Advanced Theory and Application in Statistics and Data Science, Ministry of Education, East China Normal University. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0243 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0243 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0243},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {856-873},
  shortjournal = {INFORMS J. Comput.},
  title        = {Decision making under cumulative prospect theory: An alternating direction method of multipliers},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Production planning under demand and endogenous supply uncertainty. <em>IJOC</em>, <em>37</em>(4), 831-855. (<a href='https://doi.org/10.1287/ijoc.2023.0067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of determining how much finished goods inventory to source from different capacitated facilities in order to maximize profits resulting from sales of such inventory. We consider a problem wherein there is uncertainty in demand for finished goods inventory and production yields at facilities. Further, we consider that uncertainty in production yields is endogenous, as it depends on both the facilities where a product is produced and the volumes produced at those facilities. We model the problem as a two stage stochastic program and propose an exact, Benders-based algorithm for solving instances of the problem. We prove the correctness of the algorithm and with an extensive computational study demonstrate that it outperforms known benchmarks. Finally, we establish the value in modeling uncertainty in both demands and production yields. History: Accepted by Andrea Lodi, Area Editor for Design & Analysis of Algorithms–Discrete. Supplemental Material: Software that implements the algorithms found in this paper, as well as the instances used in the computational study, can be found at Hewitt and Pantuso (2024) . The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0067 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0067 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0067},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {831-855},
  shortjournal = {INFORMS J. Comput.},
  title        = {Production planning under demand and endogenous supply uncertainty},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The electric vehicle routing and overnight charging scheduling problem on a multigraph. <em>IJOC</em>, <em>37</em>(4), 808-830. (<a href='https://doi.org/10.1287/ijoc.2023.0404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the electric vehicle (EV) routing and overnight charging scheduling problem, a fleet of EVs must serve the demand of a set of customers with time windows. The problem consists in finding a set of minimum cost routes and determining an overnight EV charging schedule that ensures the routes’ feasibility. Because (i) travel time and energy consumption are conflicting resources, (ii) the overnight charging operations take considerable time, and (iii) the charging infrastructure at the depot is limited, we model the problem on a multigraph where each arc between two vertices represents a path with a different resource consumption trade-off. To solve the problem, we design a branch-price-and-cut algorithm that implements state-of-the-art techniques, including the ng -path relaxation, subset-row inequalities, and a specialized labeling algorithm. We report computational results showing that the method solves to optimality instances with up to 50 customers. We also present experiments evaluating the benefits of modeling the problem on a multigraph rather than on the more classical 1-graph representation. History: Accepted by Andra Lodi, Area Editor for Design and Analysis of Algorithms—Discrete. Funding: This work was supported by the Natural Sciences and Engineering Research Council of Canada through the Discovery grants [Grant RGPIN-2023-03791]. It was also partially funded by HEC Montréal through the research professorship on Clean Transportation Analytics. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0404 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0404 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0404},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {808-830},
  shortjournal = {INFORMS J. Comput.},
  title        = {The electric vehicle routing and overnight charging scheduling problem on a multigraph},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient node selection policy for monte carlo tree search with neural networks. <em>IJOC</em>, <em>37</em>(4), 785-807. (<a href='https://doi.org/10.1287/ijoc.2023.0307'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monte Carlo tree search (MCTS) has been gaining increasing popularity, and the success of AlphaGo has prompted a new trend of incorporating a value network and a policy network constructed with neural networks into MCTS, namely, NN-MCTS. In this work, motivated by the shortcomings of the widely used upper confidence bounds applied to trees (UCT) policy, we formulate the node selection problem in NN-MCTS as a multistage ranking and selection (R&S) problem and propose a node selection policy that efficiently allocates a limited search budget to maximize the probability of correctly selecting the best action at the root state. The value and policy networks in NN-MCTS further improve the performance of the proposed node selection policy by providing prior knowledge and guiding the selection of the final action, respectively. Numerical experiments on two board games and an OpenAI task demonstrate that the proposed method outperforms the UCT policy used in AlphaGo Zero and MuZero, implying the potential of constructing node selection policies in NN-MCTS with R&S procedures. History: Accepted by Bruno Tuffin, Area Editor for Simulation. Funding: This work was supported by the National Natural Science Foundation of China [Grants 72325007, 72250065, and 72022001], and a PKU-Boya Postdoctoral Fellowship 2406396158. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0307 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0307 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0307},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {785-807},
  shortjournal = {INFORMS J. Comput.},
  title        = {An efficient node selection policy for monte carlo tree search with neural networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijoo">IJOO - 4</h2>
<ul>
<li><details>
<summary>
(2025). On the tradeoff between distributional belief and ambiguity: Conservatism, finite-sample guarantees, and asymptotic properties. <em>IJOO</em>, <em>7</em>(3), 240-263. (<a href='https://doi.org/10.1287/ijoo.2024.0047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose and analyze a new data-driven tradeoff (TRO) approach for modeling uncertainty that serves as a middle ground between the optimistic approach, which adopts a distributional belief, and the pessimistic distributionally robust optimization approach, which hedges against distributional ambiguity. We equip the TRO model with a TRO ambiguity set characterized by a size parameter controlling the level of optimism and a shape parameter representing distributional ambiguity. We first show that constructing the TRO ambiguity set using a general star-shaped shape parameter with the empirical distribution as its star center is necessary and sufficient to guarantee the hierarchical structure of the sequence of TRO ambiguity sets. Then, we analyze the properties of the TRO model, including quantifying conservatism, quantifying bias and generalization error, and establishing asymptotic properties. Specifically, we show that the TRO model could generate a spectrum of decisions, ranging from optimistic to conservative decisions. Additionally, we show that it could produce an unbiased estimator of the true optimal value. Furthermore, we establish the almost-sure convergence of the optimal value and the set of optimal solutions of the TRO model to their true counterparts. We exemplify our theoretical results using an inventory control problem and a portfolio optimization problem. Funding: This material is based partially on work supported by the U.S. Department of Energy, Office of Energy Efficiency and Renewable Energy, specifically the Water Power Technology Office [Award DE-EE0009450]. Supplemental Material: The e-companion is available at https://doi.org/10.1287/ijoo.2024.0047 .},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2024.0047},
  journal      = {INFORMS Journal on Optimization},
  month        = {Summer},
  number       = {3},
  pages        = {240-263},
  shortjournal = {INFORMS J. Optim.},
  title        = {On the tradeoff between distributional belief and ambiguity: Conservatism, finite-sample guarantees, and asymptotic properties},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing green energy systems. <em>IJOO</em>, <em>7</em>(3), 214-239. (<a href='https://doi.org/10.1287/ijoo.2024.0051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy production throughout the world is transitioning from fossil fuels to renewable sources such as wind power and solar power. This transition has been gradual—over half of the world’s electricity is still produced by coal, oil, and gas—but must accelerate to meet global emission targets. This paper examines the contributions that mathematical optimization and equilibrium models can make to help accelerate this transition. The models we catalog cover a range of physical scales and timescales. Our focus is on novel model formulations that can help overcome the challenges of the transition by unpicking the complexity inherent in many settings and quantifying the trade-offs that must be made when developing energy policy. Funding: This research was performed while the authors were participating in the Architecture of Green Energy Systems Program hosted by the University of Chicago, which is supported by the National Science Foundation [Grant DMS-1929348]. A. B. Philpott acknowledges support from MBIE Catalyst Fund New Zealand German Platform for Green Hydrogen Integration (HINT) [Grant UOCX2117].},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2024.0051},
  journal      = {INFORMS Journal on Optimization},
  month        = {Summer},
  number       = {3},
  pages        = {214-239},
  shortjournal = {INFORMS J. Optim.},
  title        = {Optimizing green energy systems},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tractable continuous approximations for constraint selection via cardinality minimization. <em>IJOO</em>, <em>7</em>(3), 195-213. (<a href='https://doi.org/10.1287/ijoo.2024.0038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a cardinality minimization problem that simultaneously minimizes an objective function and the cardinality of unsatisfied soft constraints. This paper proposes two continuous approximation methods that reformulate the discrete cardinality as complementarity constraints and difference-of-convex functions, respectively. We show that under suitable conditions, local and stationary solutions of the approximation problems recover local minimizers of the cardinality minimization problem. To demonstrate effectiveness, we apply the proposed methods to applications where violating as few preference conditions (or soft constraints) is desired. Our numerical study supports the use of methods based on our new approximations for cardinality minimization that produce comparable solutions with other benchmark formulations. Funding: The authors acknowledge the Office of Engaged Learning at Southern Methodist University for its support of the work of D. Troxell. The work of M. Ahn was partially supported by NSF CRII [Grant IIS-1948341].},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2024.0038},
  journal      = {INFORMS Journal on Optimization},
  month        = {Summer},
  number       = {3},
  pages        = {195-213},
  shortjournal = {INFORMS J. Optim.},
  title        = {Tractable continuous approximations for constraint selection via cardinality minimization},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robotic warehousing operations: A learn-then-optimize approach to large-scale neighborhood search. <em>IJOO</em>, <em>7</em>(3), 171-194. (<a href='https://doi.org/10.1287/ijoo.2024.0033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid deployment of robotics technologies requires dedicated optimization algorithms to manage large fleets of autonomous agents. This paper supports robotic parts-to-picker operations in warehousing by optimizing order–workstation assignments, item–pod assignments, and the schedule of order fulfillment at workstations. The model maximizes throughput, managing human workload at the workstations and congestion in the facility. We solve it via large-scale neighborhood search with a novel learn-then-optimize approach to subproblem generation. The algorithm relies on an off-line machine learning procedure to predict objective improvements based on subproblem features and an online optimization model to generate a new subproblem at each iteration. In collaboration with Amazon Robotics, we show that our model and algorithm generate much stronger solutions for practical problems than state-of-the-art approaches. In particular, our solution enhances the utilization of robotic fleets by coordinating robotic tasks for human operators to pick multiple items at once and by coordinating robotic routes to avoid congestion in the facility. Funding: This research was partially funded by Amazon.com Services LLC under award number 2D-12552417. Supplemental Material: The online appendix and code and data files are available at https://doi.org/10.1287/ijoo.2024.0033 .},
  archive      = {J_IJOO},
  doi          = {10.1287/ijoo.2024.0033},
  journal      = {INFORMS Journal on Optimization},
  month        = {Summer},
  number       = {3},
  pages        = {171-194},
  shortjournal = {INFORMS J. Optim.},
  title        = {Robotic warehousing operations: A learn-then-optimize approach to large-scale neighborhood search},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="isre">ISRE - 34</h2>
<ul>
<li><details>
<summary>
(2025). Research spotlights. <em>ISRE</em>, <em>36</em>(3), iv-xii. (<a href='https://doi.org/10.1287/isre.2025.resspot.v36.n3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2025.resspot.v36.n3},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {iv-xii},
  shortjournal = {Inf. Syst. Res.},
  title        = {Research spotlights},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). About our authors. <em>ISRE</em>, <em>36</em>(3), 1938-1947. (<a href='https://doi.org/10.1287/isre.2025.abtheau.v36.n3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2025.abtheau.v36.n3},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1938-1947},
  shortjournal = {Inf. Syst. Res.},
  title        = {About our authors},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From anonymity to accountability: How virtual identity disclosure changes the quantity and quality of “Likes”. <em>ISRE</em>, <em>36</em>(3), 1926-1937. (<a href='https://doi.org/10.1287/isre.2020.0335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An integral component of user participation in community-based platforms is giving “likes” to content posted by others. At the same time, online social participation differs from offline social participation in that online users are often allowed to create a virtual identity unrelated to their real-world identity. The objective of this study is to identify the motivations behind users’ giving “likes” when their virtual identity (i.e., username) is hidden or shown. Specifically, we leverage a natural experiment to examine the effect of virtual identity disclosure on users’ “liking” behavior. Our identification strategy relies on an exogenous policy change in an online community-based platform, where likers’ username was not visible before but publicly shown after the change. Our results show that users “liked” fewer but higher-quality articles after the policy change, consistent with their protective self-presentation motivation. This study emphasizes the significance of virtual identity, arguing that a virtual identity devoid of real-world information should not be equated with anonymity. It also underscores the importance of protective self-presentation over acquisitive self-presentation, suggesting that research should focus not only on the actions users take but also on those they intentionally avoid taking. Furthermore, our study identifies “liking” as a key channel of self-presentation, complementing the focus on posting behaviors in the extant literature. Practically, platforms can refine their policies on virtual identity disclosure to enhance content engagement, whereas content creators should tailor their offerings to meet the self-presentation needs of their audience. History: Sam Ransbotham, Senior Editor; Jason Chan, Associate Editor. Funding: This research was supported by the National Natural Science Foundation of China (NSFC) [Grants 72121001, 72293562, 7247030852] and the Hong Kong Research Grant Council (RGC) [Grants GRF 14504524, 14500521, 165052947, 14501320]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2020.0335 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2020.0335},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1926-1937},
  shortjournal = {Inf. Syst. Res.},
  title        = {From anonymity to accountability: How virtual identity disclosure changes the quantity and quality of “Likes”},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The impact of mobile data cost on consumer price sensitivity: A study of a hotel booking app. <em>ISRE</em>, <em>36</em>(3), 1912-1925. (<a href='https://doi.org/10.1287/isre.2023.0450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancement of mobile internet technologies, such as 4G and 5 G, has greatly enhanced the accessibility and convenience of mobile shopping. However, along with these benefits, mobile data usage has introduced a novel form of search cost in consumers’ purchasing decisions compared with Wi-Fi. This arises from the perception that mobile data are more costly because of additional charges incurred when exceeding the fixed data quota, which contributes to the increase of mental cost during the search process. To examine the influence of mobile data cost on consumer price sensitivity, we conduct empirical research utilizing hotel search data obtained from a prominent hotel booking app. Our findings reveal that consumers exhibit approximately twice the level of price sensitivity when utilizing mobile data instead of Wi-Fi, resulting in an average US$17 less in revenue per hotel booking. To assess the causal relations between mobile data cost and consumer price sensitivity, we utilize an approach similar to difference-in-differences and observe that this impact is more pronounced when consumers book hotels at the end of the month (versus the beginning of the month). We further find that consumer search effort decreases when using mobile data (versus Wi-Fi) across decision stages of the search process, supporting the mechanism that mobile data cost drives consumers into the satisficing rather than maximizing search mode. Our research offers practical implications for businesses operating in mobile shopping environments and contributes to policy development in this field. History: Indranil Bardhan, Senior Editor; Tianshu Sun, Associate Editor. Funding: This research was supported by the HEC Foundation from HEC Paris and research fellowship from Hi! PARIS, a joint research center between HEC Paris and Institut Polytechnique de Paris. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2023.0450 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2023.0450},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1912-1925},
  shortjournal = {Inf. Syst. Res.},
  title        = {The impact of mobile data cost on consumer price sensitivity: A study of a hotel booking app},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flow of the game: A hidden markov model of player engagement in online mobile games. <em>ISRE</em>, <em>36</em>(3), 1898-1911. (<a href='https://doi.org/10.1287/isre.2021.0217'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of mobile technology and consumers’ increasing demand for portability, the mobile gaming market has experienced huge growth. To ensure the success of mobile games, game publishers need to keep their players engaged and, at the same time, seek monetization strategies that do not interrupt players’ engagement. This paper examines how in-game challenge-related factors (i.e., perceived challenge and fluctuation of perceived challenge) and a novel mobile game monetization strategy—reward ads—affect players’ engagement. Reward ads, a popular in-app advertising monetization model in which players can voluntarily watch an ad in exchange for a reward within the game, can help publishers generate revenue without breaking the flow of the game. We develop a Hidden Markov Model and employ detailed tap-stream data from a mobile game app to study how challenge-related factors and reward ads affect players’ dynamic engagement state evolution. First, we find that players’ perceived challenge level has a positive, but diminishing, marginal effect on players’ engagement state transitions. Second, a higher fluctuation of perceived challenge increases the probability that players move to a higher engagement state. Third, the scaffolding earned by watching reward ads can help players transition to a higher engagement level. Furthermore, we study the moderating effect of perceived challenge on reward ads, and we find that reward ads are more helpful in engaging players when the perceived challenge is higher. The findings enhance the understanding of players’ engagement with mobile games and provide design guidance for mobile game publishers. History: Juan Feng, Senior Editor; Jingjing Zhang, Associate Editor. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2021.0217 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2021.0217},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1898-1911},
  shortjournal = {Inf. Syst. Res.},
  title        = {Flow of the game: A hidden markov model of player engagement in online mobile games},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Customer engagement prediction on social media: A graph neural network method. <em>ISRE</em>, <em>36</em>(3), 1887-1897. (<a href='https://doi.org/10.1287/isre.2021.0281'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid prevalence and massive user growth of social media platforms, efficiently targeting potential customers on these platforms has grown in importance for companies. Enhancing the likelihood that a social media user will engage with brand posts holds profound implications for online marketing strategy design. However, predicting customer engagement on social media comes with its own set of challenges. In this work, we design a graph neural network model called the graph neural network with attention mechanism for customer engagement (GACE) to predict customer engagement (like/comment/share) of brand posts. We exploit large-scale content consumption information from the perspective of heterogeneous networks and learn latent customer representation by developing a graph neural network model. We examine GACE using a large-scale Facebook data set, and the comprehensive results show significant performance improvement over state-of-the-art baselines. Furthermore, we conduct an interpretability analysis, which sheds some light on the explanation of the proposed model. To illustrate the practical significance of our work, we provide examples to quantify the economic value of improved predictive power using a cost-revenue analysis in the context of targeted marketing. History: Olivia Liu Sheng, Senior Editor; Huimin Zhao, Associate Editor. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2021.0281 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2021.0281},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1887-1897},
  shortjournal = {Inf. Syst. Res.},
  title        = {Customer engagement prediction on social media: A graph neural network method},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging context: Re-thinking research processes to make “Contributions to theory”. <em>ISRE</em>, <em>36</em>(3), 1871-1886. (<a href='https://doi.org/10.1287/isre.2021.0048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ever-changing technology landscape has information systems (IS) researchers constantly facing new phenomena, especially in new settings, that must be understood. To address this challenge, building on calls for contextualization, this commentary complements prior works on contextualization and presents guidance within four general research steps—defining the problem, anchoring to prior research, seeking novelty, and reporting practices—in order to achieve rigorous contextualization. In doing this, the basic idea of scientific contribution in IS research is expanded from (a) the typical contribution of theory to the phenomenon (more than 80% of IS research articles from 2018 to 2021 from Information Systems Research, Journal of the Association for Information Systems, and MIS Quarterly ) to (b) include the less common contribution to theory, especially reference discipline theory, thus creating the opportunity for IS research to be more impactful and IS to grow as a reference discipline. Finally, guidelines for editors and reviewers are offered to facilitate the publication of impactful contextualized research. History: Yulin Fang, Senior Editor; Huigang Liang, Associate Editor. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2021.0048 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2021.0048},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1871-1886},
  shortjournal = {Inf. Syst. Res.},
  title        = {Leveraging context: Re-thinking research processes to make “Contributions to theory”},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Follow your heart or listen to users? the case of mobile app design. <em>ISRE</em>, <em>36</em>(3), 1846-1870. (<a href='https://doi.org/10.1287/isre.2023.0060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Firms strive to improve their products over time to compete effectively in the market. Typically, firms update their products by adding novel or differentiating features or by imitating competitors. With the ubiquity of social media, there is also the opportunity to obtain customer input on their preferred features for a product. In the case of mobile apps, user feedback in the form of reviews may include suggestions of novel features or those that are already present in competing apps but not in the focal app. Leveraging the information contained in reviews and version release notes of iOS apps, we develop a deep learning–based natural language processing approach to identify four types of app features: developer-initiated novel, developer-initiated imitative, user-suggested novel, and user-suggested imitative. We evaluate the impact of these feature categories on app demand. Our results demonstrate that only developer-initiated novel and user-suggested imitative features help increase app demand. We also find that the impact of user-suggested novel features is negative. However, this negative effect is limited to features that are contextually distant from user suggestions, whereas contextually close implementations have a positive effect. Although we observe that the aggregate impact of developer-initiated imitative features is statistically insignificant, features that are slightly modified from the original apps do have a positive effect on demand. The primary contribution of our study is to investigate user reviews as a source of ideas for new features and to evaluate their performance impacts relative to those of developer-initiated features. History: Param Singh, Senior Editor; Xitong Li, Associate Editor. Funding: This work is supported by NUS Start Up [Grant A-0008545-00-00] and McCommbs Research Excellence Grant. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2023.0060 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2023.0060},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1846-1870},
  shortjournal = {Inf. Syst. Res.},
  title        = {Follow your heart or listen to users? the case of mobile app design},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Push it cross the finish Line—Designing online interfaces to induce choice closure at the postdecision prepurchase stage. <em>ISRE</em>, <em>36</em>(3), 1821-1845. (<a href='https://doi.org/10.1287/isre.2021.0085'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As e-commerce and mobile commerce become prevalent, a notable issue indicating a lack of choice closure is that consumers do not complete their purchases after choosing a product (e.g., shopping cart abandonment). Choice closure refers to the psychological process by which decision makers come to perceive a decision to be complete and settled. To foster choice closure, online interface designs hold promising merits in terms of flexible implementations and practical implications. Drawing upon cognitive dissonance theory and self-justification theory, we examine how interface designs can tackle consumers’ negative cognitions to promote choice closure at the postdecision prepurchase stage, whereas the extant literature focuses mainly on enhancing consumers’ positive cognitions leading to their decision satisfaction. Particularly, we investigate the effects of online interface designs on reducing cognitive dissonance (i.e., a negative cognition as an antecedent of perceived choice closure) and examine the relationships between this construct, perceived choice closure, and decision satisfaction. We conducted a series of controlled experiments in a simulated e-commerce site by designing and presenting interface cues as direct and social decision reinforcements at a postdecision prepurchase stage. Our results attest to (1) the effectiveness of the proposed reinforcement cues for inducing choice closure via reduced cognitive dissonance and (2) the significant role of choice closure for consumers’ satisfaction with their decisions in online settings where product consumption/testing is often unfeasible. Theoretical and practical contributions are elaborated. History: Suprateek Sarker, Senior Editor; Yili (Kevin) Hong, Associate Editor. Funding: Financial support from the National Natural Science Foundation of China [Grant 72071172] and the C. Michael Armstrong Business Chair Professorship at the Farmer School of Business, Miami University is gratefully acknowledged.},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2021.0085},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1821-1845},
  shortjournal = {Inf. Syst. Res.},
  title        = {Push it cross the finish Line—Designing online interfaces to induce choice closure at the postdecision prepurchase stage},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The death of a technical skill. <em>ISRE</em>, <em>36</em>(3), 1799-1820. (<a href='https://doi.org/10.1287/isre.2022.0709'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze how the decline of a technology affects online labor market dynamics. We evaluate the effects of Steve Jobs’ announcement that Apple would no longer support Adobe Flash—a popular set of tools for creating internet applications. Despite a precipitous decline in Flash demand, there is no evidence of a reduction in Flash wages on this platform because the supply response was rapid, particularly among younger developers with readily available “fallback” skills. The key to this rapid adjustment was that the long-run value of the skills that developers expected to acquire on the job acted as a form of nonwage compensation that suddenly fell in its expected value, motivating many developers to switch to other technologies, even though wages themselves did not fall. Our findings underscore how the rise and fall of technologies influences matching in online markets and help to explain (i) why technological obsolescence leaves fewer, older participants in a skill and (ii) why technologies in decline can be contemporaneously characterized by wages that stay flat or even rise in a market setting. Management and policy implications are discussed. History: Bin Gu, Senior Editor; Mohammad Rahman, Associate Editor. Funding: This work was supported by the W.E. Upjohn Institute for Employment Research and the Alfred P. Sloan Foundation [Grant G-2012-10-23]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2022.0709 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2022.0709},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1799-1820},
  shortjournal = {Inf. Syst. Res.},
  title        = {The death of a technical skill},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Do reductions in search costs for partial information on online platforms lead to better consumer decisions? evidence of cognitive miser behavior from a natural experiment. <em>ISRE</em>, <em>36</em>(3), 1780-1798. (<a href='https://doi.org/10.1287/isre.2022.0432'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many online platforms have utilized information technology, such as artificial intelligence (AI), to reduce consumers’ information search costs and facilitate their decision-making processes. Given the variety of online information, these technologies are often effective in reducing the search cost for only specific information types: a concept we refer to as search cost reduction for partial information. For rational consumers, this can lead to improved decision making. However, consumers do not always behave rationally and may exhibit behavioral biases in their decision-making process. In this study, we propose that search cost reduction for partial information can induce cognitive miser behavior in consumers, ultimately leading to worse decision-making. To explore this understudied puzzle, we leverage a natural experiment on Yelp to examine the effect of enabling search cost reduction for partial information on the quality of consumers’ decisions regarding restaurants. We constructed a unique panel data set using matched pairs of restaurants across Yelp and TripAdvisor. By applying a difference-in-differences design, we aim to casually infer how consumer decision quality is affected following the introduction of Yelp’s new AI-powered image categorization feature in August 2015, which was designed to reduce the search cost of review images. We find that adding the AI-powered image categorization feature has a negative effect on consumer decision quality. Delving into the text analysis of consumer complaints using deep learning techniques, we further find that the inferior decision quality of consumers postfeature introduction is primarily due to reduced awareness of restaurants’ service quality—information that is readily available in review texts but not in review images. Our findings suggest that reducing search costs for partial information may hurt consumers as it may incentivize cognitive miser behavior. This occurs as consumers disproportionately pay attention to the product information of which the search cost has been reduced, whereas paying less attention to other relevant product information. We discuss the implications of these findings for online platforms. History: Mani Deepa, Senior Editor; Hong Xu, Associate Editor. Funding: This work was supported by the Behavioral Research Assistance Grant, generously provided by the C. T. Bauer College of Business, University of Houston. Supplemental Material: The online appendices are available at https://doi.org/10.1287/isre.2022.0432 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2022.0432},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1780-1798},
  shortjournal = {Inf. Syst. Res.},
  title        = {Do reductions in search costs for partial information on online platforms lead to better consumer decisions? evidence of cognitive miser behavior from a natural experiment},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A natural disaster reshapes prosocial microlending. <em>ISRE</em>, <em>36</em>(3), 1760-1779. (<a href='https://doi.org/10.1287/isre.2022.0723'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous studies have investigated how various factors influence prosocial microlending decisions under normal circumstances. Nevertheless, a natural disaster may result in a situation where lenders can hardly find appropriate loans from the disaster-affected region. When faced with the mismatch between the supply and demand of microloans, lenders can either simply choose not to make any contributions or divert their prosocial intentions toward a different group of beneficiaries. Drawing on the motivated information processing theory, we show that the outcome-focused nature of prosocial motivation drives lenders to seek alternative loans until they achieve the goal of helping others, and the other-focused psychological process prompts lenders to take the victims’ perspectives when deciding which loans to fund. Moreover, lenders’ attention paid to the surrounding regions is distributed in a gradient fashion associated with their geographical distance to the disaster. Using a natural experiment based on the Ebola outbreak in Africa in 2014, our research shows that a natural disaster increases (over the short-term) the average contribution size and decreases (over the long-term) the average fundraising time per dollar for prosocial microloans by borrowers from regions closer to the affected region. In contrast, a natural disaster decreases (over the long-term) the average contribution size and increases (over the long-term) the average fundraising time per dollar for prosocial microloans by borrowers from regions farther away from the affected region. This redistribution of prosocial microlending is an unintended consequence of a natural disaster that inflicts long-term economic hardship in some regions. Policymakers and researchers should closely monitor the redistribution of prosocial microlending resulting from a natural disaster so that prompt action can be taken to alleviate potential negative consequences that may arise. History: Martin Bichler, Senior Editor; Jason Chan, Associate Editor. Funding: Y. Ding gratefully acknowledges financial support from the Gillmore Centre for Financial Technology at Warwick Business School. H. Xu gratefully acknowledges the financial support from Shanghai Pujiang Program [Grant 21PJC072]. Supplemental Material: The web appendix is available at https://doi.org/10.1287/isre.2022.0723 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2022.0723},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1760-1779},
  shortjournal = {Inf. Syst. Res.},
  title        = {A natural disaster reshapes prosocial microlending},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Team makes you better: Evidence from online medical consultation platforms. <em>ISRE</em>, <em>36</em>(3), 1738-1759. (<a href='https://doi.org/10.1287/isre.2022.0689'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual teamwork has become a prevalent mode of collaboration. However, scant empirical attention has been given to the impact of virtual teamwork on individual members’ performance beyond the team setting. In this paper, we fill this gap by studying virtual teams in the context of online medical consultation (OMC) platforms. Specifically, we collect data from two OMC platforms during a time period when both platforms offered individual consultations (i.e., one patient connected with one physician) but only one offered team consultations (i.e., one patient connected with a team of physicians). Using a difference-in-difference-in-differences approach, we find that team participation has a robust, positive effect on physicians’ performance in individual consultations. We further explore the potential mechanisms through which team participation improves physicians’ performance. The empirical results indicate that the observed performance improvement is likely driven by peer effects in team settings. In particular, we find that physicians exert more effort in individual consultations after joining a team and that performance improvement is stronger when (1) a physician can easily observe the performance of the physician’s teammates (peers), (2) a physician has teammates (peers) who perform well in individual consultations, (3) a physician has teammates (peers) from the same hospital or the same city, or (4) a physician has a lower performance prior to joining in a team. Our findings shed new light on the boundary-spanning roles of virtual teams and provide timely insights into the ongoing development of OMC platforms. History: Pei-Yu Chen, Senior Editor; Yili (Kevin) Hong, Associate Editor. Funding: X. Zhang gratefully acknowledges the support of the National Natural Science Foundation of China [Grants 72271131, 72091311, and 72293584]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2022.0689 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2022.0689},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1738-1759},
  shortjournal = {Inf. Syst. Res.},
  title        = {Team makes you better: Evidence from online medical consultation platforms},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Walrasian pricing for combinatorial markets with compact-bidding languages: An application to truckload transportation. <em>ISRE</em>, <em>36</em>(3), 1718-1737. (<a href='https://doi.org/10.1287/isre.2023.0676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combinatorial auctions offer several economic advantages but also face multiple technical challenges, including bid generation, the need to solve a combinatorial allocation problem, and determining reasonable prices. These challenges are even more pronounced in a combinatorial exchange, where bidders can simultaneously buy and sell combinations of goods. Motivated by truckload transportation markets, we explore new mechanisms for finding linear and anonymous Walrasian equilibrium prices in combinatorial auctions and exchanges where bidders can use a compact-bidding language to express their potentially complex preferences. With the goal of improving economic efficiency and reducing the environmental impact of the trucking industry, we identify significant potential gains by developing a method for integrated allocation and price determination based on an industry-specific bidding language. We also demonstrate our proposed mechanism’s adaptability and flexibility by considering a number of practical constraints. History: Martin Bichler, Senior Editor; Pallab Sanyal, Associate Editor. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2023.0676 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2023.0676},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1718-1737},
  shortjournal = {Inf. Syst. Res.},
  title        = {Walrasian pricing for combinatorial markets with compact-bidding languages: An application to truckload transportation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An investigation of p-hacking in E-commerce A/B testing. <em>ISRE</em>, <em>36</em>(3), 1691-1717. (<a href='https://doi.org/10.1287/isre.2024.0872'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, randomized experiments (or “A/B tests”) have become commonplace in many industrial settings as managers increasingly seek the aid of scientific rigor in their decision making. However, just as this practice has proliferated among firms, the problem of p -hacking—whereby experimenters adjust their sample size or try several statistical analyses until they find one that produces a statistically significant p -value—has emerged as a prevalent concern in the scientific community. Notably, many commentators have highlighted how A/B testing software enables and may even encourage p -hacking behavior. To investigate this phenomenon, we analyze the prevalence of p -hacking in a primary sample of 2,270 experiments conducted by 242 firms on a large U.S.-based e-commerce A/B testing platform. Using multiple statistical techniques—including a novel approach we call the asymmetric caliper test —we analyze the p -values corresponding to each experiment’s designated target metric across multiple significance thresholds. Our findings reveal essentially no evidence for p -hacking in our data. In an extended sample that examines p -hacking across all outcome metrics (encompassing more than 16,000 p -values in total), we similarly observe no evidence of p -hacking behavior. We use simulations to determine that if a modest effect of p -hacking were present in our data set, our methods would have the power to detect it at our current sample size. We contrast our results with the prevalence of p -hacking in academic contexts and discuss a number of possible factors explaining the divergent results, highlighting the potential roles of organizational learning and economic incentives. History: Olivia Liu Sheng, Senior Editor; Gordon Burtch, Associate Editor. Funding: The authors are grateful to the Baker Retailing Center and the Mack Institute for Innovation Management at the University of Pennsylvania for helping fund this work. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2024.0872 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2024.0872},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1691-1717},
  shortjournal = {Inf. Syst. Res.},
  title        = {An investigation of p-hacking in E-commerce A/B testing},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Growing platforms by adding complementors without a contract. <em>ISRE</em>, <em>36</em>(3), 1670-1690. (<a href='https://doi.org/10.1287/isre.2023.0237'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multisided platforms often pursue growth strategies of expanding participants on one side (e.g., suppliers) and leveraging the cross-side network effect to attract participants on other sides (e.g., consumers). Whereas formal contractual agreements have traditionally been the norm for onboarding suppliers, an emerging trend involves platforms enabling consumers to interact with noncontracted suppliers via third-party enablers with both sharing profits from providing complementary services. This study examines this strategy of increasing market thickness in the context of food delivery platforms, focusing on the platforms’ inclusion of restaurants as “nonpartnered” restaurants. Nonpartnered restaurants do not pay commission fees for being listed on the platforms and do not control their menu or item prices. The platforms collect and transfer consumer orders to the third-party deliverers who place the order, pick it up, and deliver the food to consumers. The strategy has drawn regulatory scrutiny regarding its potential harm to nonpartnered restaurants and consumers. This research empirically investigates the impact of this noncontracted partnership on restaurants, leveraging two natural experiments: (1) a number of nonpartnered restaurants were listed on the platform, and (2) the restaurants were later delisted because of a governmental regulation. Our findings show that being added as a nonpartnered restaurant increases these restaurants’ revenue from takeout orders by about $1,410 per month. Adding nonpartnered restaurants also has a positive spillover effect on the revenue of partnered restaurants already on the platform. Finally, the delisting of nonpartnered restaurants leads to a drop in their takeout orders as well as a negative spillover on the revenue of partnered restaurants. In essence, a nonpartnered contract benefits most restaurants, especially independent restaurants. These insights can inform the design of platform and regulatory policies related to noncontracted growth strategies. History: Hsing Kenneth Cheng, Senior Editor; Gordon Burtch, Associate Editor. Funding: Authors acknowledge the financial support of NET Institute [Grant 21-14]. Z. Li is grateful to the National Science Foundation Division of Social and Economic Sciences for support provided through the CAREER award [Grant 2243736]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2023.0237 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2023.0237},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1670-1690},
  shortjournal = {Inf. Syst. Res.},
  title        = {Growing platforms by adding complementors without a contract},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lost time in crowdsourcing contests. <em>ISRE</em>, <em>36</em>(3), 1652-1669. (<a href='https://doi.org/10.1287/isre.2022.0502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdsourcing contests have become increasingly popular as a means of seeking innovative solutions to business problems. However, the abundance of concurrent contests on platforms can lead to disparities in solvers’ contest awareness, resulting in “lost time”—the time elapsed between the start of a contest and a solver’s first visit. This study investigates how lost time influences solvers’ submission behavior and its subsequent impact on matching inefficacy as measured by solver disqualification, which occurs when a solver fails to produce a submission meeting the seeker’s baseline criteria. Utilizing a proprietary data set from a European crowdsourcing platform, we employ a mediation analysis framework to examine the relationship between lost time and two key dimensions of submission behavior: time to first submission and number of submissions. Our findings reveal that higher levels of lost time are associated with fewer submissions, indicating reduced solver persistence. However, this negative effect is partially mitigated by solvers’ faster initial submissions when facing lost time. Importantly, we demonstrate that changes in submission behavior fully mediate the negative impact of lost time on solver disqualification, highlighting the crucial role of submission behavior in influencing solver disqualification. Furthermore, we provide evidence supporting latecomer disadvantage as an important mechanism driving solvers’ behavioral responses to lost time. Our study contributes to the crowdsourcing literature by uncovering the impact of lost time on solvers’ behavior and performance, offering valuable insights for contest design. By understanding and mitigating the effects of latecomer disadvantage, platforms can enhance the effectiveness of crowdsourcing in solving problems. History: Pei-yu Chen, Senior Editor; Chad Ho, Associate Editor. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2022.0502 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2022.0502},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1652-1669},
  shortjournal = {Inf. Syst. Res.},
  title        = {Lost time in crowdsourcing contests},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-sided impacts of service provider’s identity disclosure in e-customer service platforms: Evidence from two field experiments. <em>ISRE</em>, <em>36</em>(3), 1631-1651. (<a href='https://doi.org/10.1287/isre.2023.0499'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital advancements have revolutionized customer service by enabling customers to easily express dissatisfaction and request resolutions through online platforms. Customer complaint management platforms are especially unique in facilitating provider-customer interactions, but researchers overlook implications from service provider anonymity. In this article, two randomized field experiments are conducted to examine a customer complaint management platform to identify how disclosure of service provider identity affects service performance, customer satisfaction, and biases in customers. Study 1, a large-scale randomized field experiment involving 75,041 customers and 1,280 service providers across 672 companies, finds that identity disclosure improves provider performance. This improvement is achieved by removing the provider’s dissociative anonymity, mitigating deindividuation, instilling self-awareness, and motivating personal responsibility. This effect is stronger for inexperienced service providers who work with many colleagues and have more discretion in handling complaints. Customers who receive identity details about providers benefit from better service and perceive higher satisfaction with complaint resolution. Study 2, a field experiment involving 2,710 customers, shows that customers report more satisfaction when customers identify that providers belong to the majority ethnic group compared with when they belong to an ethnic minority. Intriguingly, minority customers showed lower satisfaction with same-ethnicity providers, indicating that ethnic cues and identity matching significantly influence customer satisfaction. Four follow-up studies involving 1,211 participants identify the underlying mechanisms that influence customer and provider behaviors. The article concludes with practical implications for firms and platforms dedicated to customer service. History: Indranil Bardhan, Senior Editor; Idris Adjerid, Associate Editor. Funding: This work was partially supported by the National Research Foundation of Korea [Grant NRF-2022S1A3A2A02089685] and the Ministry of Education of the Republic of Korea. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2023.0499 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2023.0499},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1631-1651},
  shortjournal = {Inf. Syst. Res.},
  title        = {Two-sided impacts of service provider’s identity disclosure in e-customer service platforms: Evidence from two field experiments},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mergers between on-demand service platforms: The impact on consumer surplus and labor welfare. <em>ISRE</em>, <em>36</em>(3), 1612-1630. (<a href='https://doi.org/10.1287/isre.2022.0553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On-demand service platforms connect customers with independent service providers (agents) by competitively setting service prices and wages. Mergers between on-demand service platforms have recently become prevalent, resulting in antitrust debates. A merger, although reducing competition, enables the agents on previously separate platforms to serve all the customers. In this paper, we develop a game-theoretical model to analyze the impact of a merger between two platforms. The two platforms compete on prices and wages before the merger, but are managed by a single firm after the merger. We show that a merger not only creates pooling benefits, but also enhances the cross-side network effect (i.e., customers benefit from more agents and vice versa). As a result, it can lead to a win-win-win outcome, where the platforms’ profits, consumer surplus, and labor welfare all improve after a merger. The win-win-win outcome is more probable if the premerger market is less saturated or if the market is more differentiated on the customer/agent side. Interestingly, a stronger within-side congestion effect may either strengthen or weaken a merger’s potential to benefit customers. Additionally, we show that a merger is less likely to improve consumer surplus and labor welfare if there are more multihoming agents in the market and that it is more likely to benefit labor welfare if there is less cross-side price transparency. Our results provide guidelines for antitrust policymakers to evaluate the impact of a merger between on-demand service platforms. History: Giri Kumar Tayi, Senior Editor; Jianqing Chen, Associate Editor. Funding: X. Lin received financial support from the National Natural Science Foundation of China [Grants 72471063 and 72001048], the Guangdong Basic and Applied Basic Research Foundation [Grant 2023A1515010857], and the Guangzhou Science and Technology Programme [Grant 2024A04J2557]. X. Wang received financial support from the National Natural Science Foundation of China [Grant 72495125], the Guanghua Talent Project of the Southwestern University of Finance and Economics, and the Research Grants Council of the Hong Kong Special Administrative Region, China [Grant 16210720]. G. Kou received financial support from the National Natural Science Foundation of China [Grants 72495125 and 71910107002]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2022.0553 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2022.0553},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1612-1630},
  shortjournal = {Inf. Syst. Res.},
  title        = {Mergers between on-demand service platforms: The impact on consumer surplus and labor welfare},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How product display orientation affects customers’ choice satisfaction in online purchase: A choice closure perspective. <em>ISRE</em>, <em>36</em>(3), 1587-1611. (<a href='https://doi.org/10.1287/isre.2022.0575'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online retailers often confront the problem of order cancellation due to customers’ poor satisfaction with their online purchase decision, termed as choice satisfaction in this study. However, very little e-commerce literature has addressed customer choice satisfaction, and none, to our knowledge, has investigated how to design product display interfaces to achieve it. Drawing from choice closure theory and eye and vision research, we examine how product display orientation of an online shopping web page affects customers’ choice satisfaction upon purchase. We propose that a horizontal (versus vertical) display of comparable products on an e-commerce website is more positively related to customer choice satisfaction by promoting a higher level of choice closure (a psychological process by which online customers come to perceive a decision as completed and settled). Through five carefully designed experiments (including one using an eye-tracking device), we find that online customers achieve a higher level of choice satisfaction from an assortment of comparable products displayed horizontally than vertically on e-commerce websites. This effect results from the fact that a horizontal product display increases the amount of comparisons customers make between product options prior to making a purchase decision and consequential sense of choice closure after the decision. We also find that a cue of finality (e.g., adding a textual note “The end” to the product display) can largely attenuate this effect. The implications for online retailers’ product showcase strategies are discussed, along with future research directions. History: Jason Thatcher, Senior Editor; Heng Xu, Associate Editor. Funding: Y. Jia received financial support from the Natural Science Foundation of Fujian Province of China [Grant 2022J01039]. Y. Fang received financial support from the National Natural Science Foundation of China [Grant 72071171] and the General Research Fund [Grant 11509420]. J. Ouyang received financial support from the Social Science Foundation of Fujian Province of China [Grant FJ2022BF025]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2022.0575 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2022.0575},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1587-1611},
  shortjournal = {Inf. Syst. Res.},
  title        = {How product display orientation affects customers’ choice satisfaction in online purchase: A choice closure perspective},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). And no one gets the short end of the stick: A blockchain-based approach to solving the two-sided opportunism problem in interorganizational information sharing. <em>ISRE</em>, <em>36</em>(3), 1565-1586. (<a href='https://doi.org/10.1287/isre.2022.0065'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The threat of opportunistic behavior is an enduring problem in interorganizational information sharing based on sensitive data. The two sides of opportunism in interorganizational information sharing— information poaching by the information recipient and information manipulation by the information provider—may preclude beneficial information sharing relationships altogether. Previously proposed organizational and technical countermeasures against the threat of opportunism either fail to reliably prevent information poaching and manipulation or prevent only one of them at a time. To address these shortcomings, we develop three design principles for an information system that facilitates reliable information sharing based on sensitive data in interorganizational business transactions without revealing the actual data. We instantiate our design principles in a multicompany research consortium for wear-based leasing contracts for machine tools. Through in-depth interview sessions with business and technology experts, we demonstrate the efficacy of our artifact in addressing the two-sided opportunism problem. A survey-based evaluation of the artifact’s utility in the context of machine tool leasing shows that organizations are willing to engage in more interorganizational information sharing, rely more on shared information, and draw on more sensitive data when provided with our solution. The study makes three key contributions. First, it contributes to the literature on interorganizational information sharing by identifying information poaching and information manipulation as two sides of the same problem and by showing empirically that opportunities for beneficial business arise if both forms of opportunism are addressed simultaneously. Second, our design principles constitute a blueprint of a shared information system that enables reliable (i.e., verifiably truthful) information sharing between business partners without revealing the data underlying the shared information. Third, the study contributes to the literature on blockchain systems by recombining specific blockchain technology components, namely, private data collections, smart contracts, and joint governance, in a useful, novel way. History: Monideepa Tarafdar, Senior Editor; Martin Wiener, Associate Editor. Funding: L. F. Bossler and A. Buchwald received funding through the project “Pay-per-Stress,” which is funded by the German Federal Ministry for Economic Affairs and Climate Action (Bundesministerium für Wirtschaft und Klimaschutz (BMWK)) within the framework “Smarte Datenwirtschaft” (Smart Data Economy) [Grant 01MD19011]. The authors are responsible for the content of this publication. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2022.0065 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2022.0065},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1565-1586},
  shortjournal = {Inf. Syst. Res.},
  title        = {And no one gets the short end of the stick: A blockchain-based approach to solving the two-sided opportunism problem in interorganizational information sharing},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resale royalty in non-fungible token marketplaces: Blessing or burden for creators and platforms?. <em>ISRE</em>, <em>36</em>(3), 1543-1564. (<a href='https://doi.org/10.1287/isre.2023.0035'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-fungible token (NFT) marketplaces enable users to mint and trade digital assets, such as collectibles, trading cards, and digital artwork. Many of these platforms accommodate resale royalties, which return a predetermined percentage of the proceeds from future resales of the digital asset to the creator. Although the adoption of resale royalties may seem beneficial for NFT creators by providing a recurring source of income, it could have unintended consequences on the sales price and the liquidity of the underlying NFT, potentially affecting both the platform’s commission revenue and the creator’s short-term return. In this paper, we aim to understand the antecedents and consequences of resale royalties. Specifically, we empirically investigate the impact of minting costs on royalty rates and subsequently, the effects of resale royalties on primary market sales prices and liquidity. Our identification strategy combines a difference-in-differences model that leverages a policy change that eliminated up-front minting fees for creators and an instrumental variables approach. We find that NFT creators reduce royalty rates when they mint an NFT without incurring minting costs. Furthermore, we observe that higher royalty rates lead to reduced sales prices in the primary market, suggesting the presence of a delayed gratification effect as creators hope for future royalty payments. We also investigate the underlying mechanisms, and we find that NFT creators who are more confident about future resales tend to lower their primary sale prices but are unable to recoup those losses in the short term, providing evidence of an overconfidence effect . Surprisingly, we find that the presence of resale royalties also negatively affects market liquidity despite reduced sales prices. Our findings offer immediate implications for creators and platforms regarding resale royalty strategies and whether to enforce royalties. History: Hsing Kenneth Cheng, Senior Editor; Tianshu Sun, Associate Editor. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2023.0035 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2023.0035},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1543-1564},
  shortjournal = {Inf. Syst. Res.},
  title        = {Resale royalty in non-fungible token marketplaces: Blessing or burden for creators and platforms?},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identity work in interdependent professional groups: The role of a target identity in enterprise systems implementation. <em>ISRE</em>, <em>36</em>(3), 1522-1542. (<a href='https://doi.org/10.1287/isre.2021.0534'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enterprise systems (ESs) can be important for the development and maintenance of professional role identities. Prior work shows that a new ES implementation can trigger significant identity work in individuals and groups if it alters their tasks or responsibilities. What has received less attention is that the introduction of a new ES may affect multiple, interdependent professional groups simultaneously, changing how these professional groups can or must interact based on the system properties. Consequently, the introduction of a new ES may also affect how these groups maintain distinctive professional role identities. This study examines how the introduction of a new ES affects the identity work of interdependent professional groups in an organization. Drawing on a revelatory context, we studied the identity work of management accountants and financial accountants in six cases where a new ES merged traditionally separate financial and management accounting modules into one general accounting module. To understand the emergent identity work, we present the construct of a target identity (i.e., a tentative enhanced professional role identity that professional groups actively strive to achieve) and describe three patterns of identity work. We derive five propositions about the conditions under which interdependent professional groups develop a target identity, about the consequences of (not) achieving a target identity, and about the willingness of interdependent professional groups to renegotiate their role boundaries. History: Suprateek Sarker, Senior Editor; Ning Su, Associate Editor. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2021.0534 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2021.0534},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1522-1542},
  shortjournal = {Inf. Syst. Res.},
  title        = {Identity work in interdependent professional groups: The role of a target identity in enterprise systems implementation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Should ad exchanges subsidize advertisers to acquire targeting data?. <em>ISRE</em>, <em>36</em>(3), 1502-1521. (<a href='https://doi.org/10.1287/isre.2023.0126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large volumes of online impressions are sold daily via real-time auctions to deliver targeted advertisements to consumers. Advertisers use data to learn about user preferences and select the most appropriate ad for each user, which also helps them optimize their bids in an ad auction. Although ad exchanges may provide some user data to advertisers, they are usually limited, and advertisers often acquire data from various sources to improve targeting performance. The acquisition of such data can significantly influence the revenue of the ad exchange, which motivates ad exchanges to take actions that reduce advertisers’ data acquisition costs and encourage them to buy data. Previous studies have examined the impact of ad exchanges revealing their data to advertisers, but little attention has been paid to the impact of ad exchanges subsidizing advertisers to acquire data from third parties. To address this gap, we propose three subsidy frameworks to increase ad exchange revenue by inducing more advertisers to acquire data: all subsidized (AS), winner subsidized (WS), and loser subsidized. Using a stylized model, we analyze the impact of subsidy provisions on the platform’s net revenue. Our results show that WS can be better or worse than AS depending on the cost of data acquisition, its beneficial impact on ad selection, and the distribution of impression values. History: Martin Bichler, Senior Editor; Khim Yong Goh, Associate Editor. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2023.0126 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2023.0126},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1502-1521},
  shortjournal = {Inf. Syst. Res.},
  title        = {Should ad exchanges subsidize advertisers to acquire targeting data?},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An explainable artificial intelligence approach using graph learning to predict intensive care unit length of stay. <em>ISRE</em>, <em>36</em>(3), 1478-1501. (<a href='https://doi.org/10.1287/isre.2023.0029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intensive care units (ICUs) are critical for treating severe health conditions but represent significant hospital expenditures. Accurate prediction of ICU length of stay (LoS) can enhance hospital resource management, reduce readmissions, and improve patient care. In recent years, widespread adoption of electronic health records and advancements in artificial intelligence (AI) have facilitated accurate predictions of ICU LoS. However, there is a notable gap in the literature on explainable artificial intelligence (XAI) methods that identify interactions between model input features to predict patient health outcomes. This gap is especially noteworthy as the medical literature suggests that complex interactions between clinical features are likely to significantly impact patient health outcomes. We propose a novel graph learning-based approach that offers state-of-the-art prediction and greater interpretability for ICU LoS prediction. Specifically, our graph-based XAI model can generate interaction-based explanations supported by evidence-based medicine, which provide rich patient-level insights compared with existing XAI methods. We test the statistical significance of our XAI approach using a distance-based separation index and utilize perturbation analyses to examine the sensitivity of our model explanations to changes in input features. Finally, we validate the explanations of our graph learning model using the conceptual evaluation property (Co-12) framework and a small-scale user study of ICU clinicians. Our approach offers interpretable predictions of ICU LoS grounded in design science research, which can facilitate greater integration of AI-enabled decision support systems in clinical workflows, thereby enabling clinicians to derive greater value. History: Olivia Sheng, Senior Editor; Abhay Mishra, Associate Editor. Funding: I. R. Bardhan is grateful for the financial support of the Foster Parker Centennial Professorship and the financial support from the McCombs School of Business [Dean’s Excellence Research Grant]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2023.0029 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2023.0029},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1478-1501},
  shortjournal = {Inf. Syst. Res.},
  title        = {An explainable artificial intelligence approach using graph learning to predict intensive care unit length of stay},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Player-vs.-player game design and pricing: A tournament design perspective. <em>ISRE</em>, <em>36</em>(3), 1461-1477. (<a href='https://doi.org/10.1287/isre.2023.0258'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Player-versus-player (PvP) games often allow users to purchase superior virtual gears to increase their winning odds in battles against others. This game design, known as “pay to win,” generates substantial revenues from paying players, but it may also adversely affect the gaming experience of nonpaying players and lead to a decline in the game’s popularity. Game developers thus need to strike a balance between revenue and player participation. This paper develops a model to analyze optimal versioning and pricing strategies for PvP games. Building on the classic product line design framework with network effects, we allow a monopolistic game developer to strategically manipulate gameplay (dis-)advantages across different versions, which we refer to as tournament design, and this generates version-specific network effects. We characterize the developer’s optimal strategy and obtain the following insights. First, tournament design improves the developer’s flexibility in pricing and versioning, and it effectively mitigates the extent of product cannibalization. Second, tournament design enables the developer to monetize free players’ participation by offering multiple free versions, and a “freemium” strategy (i.e., the combination of a free-to-play model and a pay-to-win system) can arise in the optimum. Third, tournament design is particularly effective in increasing the developer’s profit when players are willing to play the game but are reluctant to pay. Fourth, tournament design leads to a Pareto improvement for both the developer and all players. The practical implications of these findings are also discussed. History: Ravi Bapna, Senior Editor; Atanu Lahiri, Associate Editor. Funding: This research was supported by the National Natural Science Foundation of China [Grants 72222002, 72173002, and 72033003]; the Research Seed Fund of the School of Economics, Peking University; the Wu Jiapei Foundation of the China Information Economics Society [Grants  E21100383 and M22106023]; and the National Social Science Fund of China [Grant Major Project 21&ZD119]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2023.0258 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2023.0258},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1461-1477},
  shortjournal = {Inf. Syst. Res.},
  title        = {Player-vs.-player game design and pricing: A tournament design perspective},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). To partner or not to partner? the partnership between platforms and data brokers in two-sided markets. <em>ISRE</em>, <em>36</em>(3), 1437-1460. (<a href='https://doi.org/10.1287/isre.2022.0470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data have become an important competitive asset, especially for online advertising platforms, leading to the emergence of a new data broker industry. Platforms can partner with data brokers to acquire external data to enhance their targeting capabilities, but this practice has stoked growing consumer privacy concerns. This study develops a game-theoretic model to examine the economic mechanism underlying the partnership between competing platforms and a data broker in a two-sided market. Interestingly, our analysis shows that increasing consumer privacy concerns caused by the data broker may encourage platforms to partner with the data broker rather than discourage them. The driving force is that, because of negative cross-side network effects from advertisers to consumers, increased privacy concerns can serve as a strategic lever to soften price competition on the advertiser side. However, when both platforms partner with the data broker, a prisoner’s dilemma may arise in equilibrium even when the data broker can greatly improve the targeting capabilities. We find that the platform-data broker partnership hurts consumer surplus when platforms adopt a pure ad-sponsored model without charging consumers, but it may benefit consumer surplus when platforms adopt a mixed model with ad-sponsored and subscription-based revenue. Moreover, our analysis indicates that platforms may not have incentives to adopt high levels of privacy protection and may instead adopt asymmetric privacy protection strategies, with one platform adopting high privacy protection and the other opting for low protection. A series of model extensions confirm the robustness of our key findings. We conclude with a discussion of managerial and policy implications. History: Juan Feng, Senior Editor; Hong Guo, Associate Editor. Funding: This work was supported by the National Natural Science Foundation of China [Grants 72301267, 72301264, 72091215/72091210, 71921001] and the China Postdoctoral Science Foundation [Grant 2022M720135]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2022.0470 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2022.0470},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1437-1460},
  shortjournal = {Inf. Syst. Res.},
  title        = {To partner or not to partner? the partnership between platforms and data brokers in two-sided markets},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Return of the movie night? analyzing the impact of netflix subscriptions on offline movie spending. <em>ISRE</em>, <em>36</em>(3), 1418-1436. (<a href='https://doi.org/10.1287/isre.2022.0530'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The subscription-based business model is disruptive in the copyright industries. More than a digitalized distribution channel, it fundamentally transforms both supply and demand sides by offering new forms of content creation, provision, and consumption. However, the effects of these business models on the local offline industry are less well understood, especially in the case of the motion picture industry. This study investigates the impact of the subscription-based business model on offline activity consumption in the motion picture industry. Leveraging a unique data set with individuals’ every transaction record and a difference-in-differences approach, we show that Netflix subscription interestingly increases offline movie consumption. Based on the argument that individuals have unmet social and hedonic demands that are imperfectly met by subscription-based services, like Netflix, we show that offline movie consumption actually increases postsubscription, accompanied by social and hedonic activities, like dining and entertainment spending. We also provide evidence that the identified positive effect on offline movie consumption is more pronounced for individuals with higher social and hedonic needs (i.e., lower-income people and younger people). Our work provides clear implications for managers and policymakers who are involved in both subscription-based platforms, like Netflix, and the traditional offline movie industry. In addition, we provide theoretical implications for the study of subscription-based platforms, the imperfect substitution of channels, and the role of social and hedonic value in technology-supported platforms. History: Karthik Kannan, Senior Editor; Xitong Li, Associate Editor. Funding: This research is supported by the Ministry of Education, Singapore, under its Academic Research Fund Tier 1 [RG105/22]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2022.0530 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2022.0530},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1418-1436},
  shortjournal = {Inf. Syst. Res.},
  title        = {Return of the movie night? analyzing the impact of netflix subscriptions on offline movie spending},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Untangling the performance impact of E-marketplace sellers’ deployment of platform-based functions: A configurational perspective. <em>ISRE</em>, <em>36</em>(3), 1397-1417. (<a href='https://doi.org/10.1287/isre.2020.0539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous studies have shown great interest in examining the performance impact of platform-based functions (PBFs) used by e-marketplace sellers and the contingent role of salient variables, such as seller reputation, in the e-marketplace. Their findings, however, are fragmented and inconsistent, as they generally focus on the net, separate effect of a single PBF with debatable findings. The theorization of how sellers should configure multiple types of PBFs as a whole to achieve high sales performance lags far behind the booming competition practice. To identify an effective PBF combination, this study takes a configurational perspective to identify appropriate PBF configurations that can achieve high sales performance for sellers with different product positions and reputations. A fuzzy-set qualitative comparative analysis of a longitudinal data set of over 3,300 apparel sellers in a large e-marketplace yields interesting findings. The configuration results reveal recipes for PBF combinations for achieving high sales performance that vary across different levels of seller reputation and product positioning strategies. Our configuration findings suggest that sellers should configure PBFs according to distinctive product strategies accompanied by seller reputation conditions, where the resulting PBF configurations play an essential and multifaceted role in achieving high sales performances. Interestingly, our configuration analysis uncovers that for reputable sellers offering high-priced products, the utilization of pricing and marketing functions is counterproductive. Additionally, we observe complex interplays between after-sales functions and online reputation, characterized by complementary, substitutive, and independent relationships. Furthermore, our results demonstrate an asymmetry relationship between high and low sales configurations. It contributes to the emergent investigation of causal complexity in competitive strategy studies of e-marketplace sellers and provides specific causal recipes and holistic guidelines for sellers and platform operators. History: Manju K. Ahuja, Senior Editor; Yili (Kevin) Hong, Associate Editor. Funding: This work was supported by the National Natural Science Foundation of China [Grants 72071171, 72372032, 71972047, and 72371234]; the Research Grants Council of the Hong Kong Special Administrative Region, University Grants Committee [General Research Fund Grant 11509420]; the University of Hong Kong (HKU) Business School Shenzhen Research Center [Grant SZRI2023-CRF-02]; the HKU Seed Funding for Strategic Interdisciplinary Research Scheme [Grant 102010198]; the Ministry of Education in China Project of Humanities and Social Sciences [Grant 21YJC630058]; and the Fundamental Research Funds for the Central Universities [Grant WK2040000062]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2020.0539 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2020.0539},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1397-1417},
  shortjournal = {Inf. Syst. Res.},
  title        = {Untangling the performance impact of E-marketplace sellers’ deployment of platform-based functions: A configurational perspective},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Skill-biased technical change, again? online gig platforms and local employment. <em>ISRE</em>, <em>36</em>(3), 1354-1374. (<a href='https://doi.org/10.1287/isre.2022.0307'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online gig platforms have the potential to influence employment in existing industries. Popular press and academic research offer two competing predictions: First, online gig platforms may reduce the supply of incumbent workers by intensifying competition and obsoleting certain skills of workers; or, second, they may boost the supply of workers by increasing client-worker matching efficiency and creating new employment opportunities for workers. Yet, there has been limited understanding of the labor movements amid the rise of online gig platforms. Extending the skill-biased technical change literature, we study the impact of TaskRabbit—a location-based gig platform that matches freelance workers to local demand for domestic tasks (e.g., cleaning services)—on the local supply of incumbent, work-for-wages housekeeping workers. We also examine the heterogeneous effects across workers at different skill levels. Exploiting the staggered TaskRabbit expansion into U.S. cities, we identify a significant decrease in the number of incumbent housekeeping workers after TaskRabbit entry. Notably, this is mainly driven by a disproportionate decline in the number of middle-skilled workers (i.e., first-line managers, supervisors) whose tasks could easily be automated by TaskRabbit’s matching algorithms, but not low-skilled workers (i.e., janitors, cleaners) who typically perform manual tasks. Interestingly, TaskRabbit entry does not necessarily crowd out middle-skilled housekeeping workers, neither laying them off nor forcing them to other related occupations; rather, TaskRabbit entry supports self-employment within the housekeeping industry. These findings imply that online gig platforms may not naively be viewed as skill biased, especially for low-skilled workers; instead, they redistribute middle-skilled managerial workers whose cognitive tasks are automated by the sorting and matching algorithms to explore new self-employment opportunities for workers, stressing the need to reconsider online gig platforms as a means to reshape existing industries and stimulate entrepreneurial endeavors. History: Manju K. Ahuja, Senior Editor; Jason Chan, Associate Editor. Supplemental Material: The online appendices are available at https://doi.org/10.1287/isre.2022.0307 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2022.0307},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1354-1374},
  shortjournal = {Inf. Syst. Res.},
  title        = {Skill-biased technical change, again? online gig platforms and local employment},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Win by hook or crook? self-injecting favorable online reviews to fight adjacent rivals. <em>ISRE</em>, <em>36</em>(3), 1333-1353. (<a href='https://doi.org/10.1287/isre.2023.0179'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing literature has long assumed that unethical behaviors are fueled by competition. Under this premise, rivalry and competition are often treated interchangeably. This study seeks to challenge this prevailing notion by introducing a conceptual distinction between rivalry and competition. Specifically, we explore the multifaceted relationship between rivalry and unethical behaviors in the context of online review self-injecting behaviors. Drawing on the collective regulatory focus framework and deterrence theory, we posit that rivalry-induced deterrence triggers a shift in mindset from promotion focus to prevention focus, which leads to the formation of mutual forbearance in self-injecting behaviors. Mutual forbearance collapses when one party unilaterally engages in self-injection, prompting the other party to retaliate by increasing their self-injecting activities. Additionally, we propose that firm reputation plays a crucial role in reinforcing the formation of mutual forbearance while mitigating its collapse. Employing an exhaustive data set from Ctrip.com and Qunar.com that comprises 85,939 observations from 3,996 hotels and spans 2018–2020, we found that the presence of an additional rival leads to a 3.2% decrease in self-injecting intensity. Furthermore, self-injecting intensity increases by 0.095% for every 1% rise in that of the rivals and increases by 0.041% for a 1% rise in that of the nonrival competitors. Crucially, our study identifies that firm reputation acts as a significant factor that strengthens the negative relationship between the number of rivals and self-injecting intensity and weakens the positive relationship between a hotel’s self-injecting and its rival’s self-injecting intensity. These empirical findings are supported by a myriad of robust examinations, including the use of a set of subsample analyses, alternative measures of independent variables, alternative instrumental variables, alternative observation time windows, and multiple endogeneity tests. This study contributes to the literature by highlighting the pervasive and potent role of rivalry as an understudied inhibitor of self-injecting behaviors. Our empirical evidence offers critical managerial implications for platforms, sellers, and consumers. History: Juan Feng, Senior Editor; Xitong Li, Associate Editor. Funding: This work was supported by the National Natural Science Foundation of China [Grants 72171189, 71901172, and 72131005] and the 111 Project [D21007]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2023.0179 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2023.0179},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1333-1353},
  shortjournal = {Inf. Syst. Res.},
  title        = {Win by hook or crook? self-injecting favorable online reviews to fight adjacent rivals},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probing digital footprints and reaching for inherent preferences: A cause-disentanglement approach to personalized recommendations. <em>ISRE</em>, <em>36</em>(3), 1314-1332. (<a href='https://doi.org/10.1287/isre.2023.0181'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The abundance of multiple types of consumer digital footprints recorded on e-commerce platforms has fueled the design of personalized recommender systems for decision support. However, capturing consumers’ inherent preferences for effective recommendations based on consumer digital footprints can be challenging because of the multitude of factors driving consumer behaviors. Model training and recommendation outcomes may become biased if other factors are inappropriately recognized as consumers’ inherent preferences in the learning process. Drawing on consumer behavior theories, we tease out various factors that drive consumers’ digital footprints at different consumption stages. We develop a novel recommendation approach, namely, DISC (Disentangling consumers’ Inherent preferences, item Salience effect, and Conformity effect), which leverages disentangled representation learning with a causal graph to derive the effect of each factor driving consumer behaviors. This approach provides personalized and interpretable recommendations based on the inference of consumers’ normative inherent preferences. The DISC model’s identifiability is demonstrated through theoretical analysis, enabling rigorous causal inference based on observational data. To evaluate DISC’s performance, extensive experiments are conducted on real-world data sets with a carefully designed protocol. The results reveal that DISC outperforms state-of-the-art baselines significantly and possesses good interpretability. Moreover, we illustrate the potential impact of different marketing strategies’ by intervening on the disentangled causes through follow-up counterfactual analyses based on the causal graph. Our study contributes to the literature and practice by causally unpacking the behavioral mechanism behind consumers’ digital footprints and designing an interpretable personalized recommendation approach anchored in their inherent preferences. History: Olivia Liu Sheng, Senior Editor; Zhengrui Jiang, Associate Editor. Funding: This work was supported by the National Natural Science Foundation of China [Grants 72101007, 72293561, 72131001]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2023.0181 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2023.0181},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1314-1332},
  shortjournal = {Inf. Syst. Res.},
  title        = {Probing digital footprints and reaching for inherent preferences: A cause-disentanglement approach to personalized recommendations},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fashionable consumer technology, IT fashion, and consumer behavior. <em>ISRE</em>, <em>36</em>(3), 1293-1313. (<a href='https://doi.org/10.1287/isre.2020.0084'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally thought of as “uncomfortable bedfellows,” consumer IT and fashion are becoming increasingly intertwined, which has given rise to a unique phenomenon termed “consumer IT fashion”—the collective enthusiasm in society for consumer technology. Nevertheless, it remains uncertain how IT fashion is perceived by individual consumers and subsequently influences consumer behavior. Our research aims to bridge this gap. By differentiating between societal-level and individual-level perceptions of IT fashion, the paper introduces novel constructs associated with IT fashion and fashionable consumer technology, particularly perceived societal-level IT fashion (PSITF, reflecting a person’s perception of society’s views on a technology) and perceived fashionableness of IT (PFIT, capturing a person’s perception of the technology’s fashionableness). Moreover, we identify drivers underlying PSITF and PFIT: collective adoption and social endorsement are the drivers of PSITF, whereas the novelty of IT and IT-identity congruity are the drivers of PFIT. A research model is developed to illustrate how IT fashion influences consumer behaviors, such as adoption and purchasing decisions. We conducted two empirical studies to assess our research model. In Study 1, we focused on consumers’ adoption decision of fashionable technology. The findings validate our conceptualization of IT fashion-related constructs and suggest that consumers are inclined to adopt fashionable IT when they believe it enhances their sense of belonging to a group (i.e., external symbolic value) and allows for self-expression (i.e., internal symbolic value). In Study 2, we explored consumers’ purchasing behavior, focusing on their willingness to pay (WTP) for a fashionable technology compared with the alternative IT product with identical functionalities. The results indicate that whereas consumers do acknowledge the symbolic values associated with using fashionable IT, these values do not necessarily translate into a greater WTP. Our research opens novel theoretical avenues for the exploration of IT fashion and lays the groundwork for future investigations in this domain. History: Manju K. Ahuja, Senior Editor; Zhenhui (Jack) Jiang, Associate Editor. Supplemental Material: The online appendix is available at https://doi.org/10.1287/isre.2020.0084 .},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2020.0084},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1293-1313},
  shortjournal = {Inf. Syst. Res.},
  title        = {Fashionable consumer technology, IT fashion, and consumer behavior},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Digital development: Reimagining research beyond ICT4D. <em>ISRE</em>, <em>36</em>(3), 1269-1292. (<a href='https://doi.org/10.1287/isre.2025.editorial.v36.n3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This editorial introduces a conceptual framework that reimagines research on Information and Communication Technologies for Development (ICT4D) as “digital development,” recognizing the inseparable intertwining of digital and development trajectories. This framing is aimed at the broader information systems (IS) research community, which includes ICT4D researchers, based both in the Global South and the Global North. Digital development encompasses three dimensions: digital in development (institutional use), digital for development (conscious design for outcomes), and development in a digital world (digital entanglement in development practice.). We argue that this reimagination is necessary for three reasons. First, digital technologies are becoming increasingly entangled with many development initiatives, implying the need to be studied as a duality, not a dualism. Second, we are witnessing the rising complexity of contemporary and emergent development challenges, which are not just limited to the Global South, but to the world at large. Third, the IS and ICT4D research fields have long worked in relative isolation from each other, but they need to synergistically create new theories and methods to address the rising complexities inherent in the “digital” and “development.” We provide a brief overview of the existing ICT4D field to identify critical areas for reconceptualization and expansion. This is then illustrated by examples from four empirical domains, namely humanitarian governance, global health, financial inclusion, and digital nomadism, which are representative of contemporary and emerging digital development challenges. This leads to the development of theoretical, policy and practice, and methodological implications, which provide a basis to formulate a research agenda for digital development.},
  archive      = {J_ISRE},
  doi          = {10.1287/isre.2025.editorial.v36.n3},
  journal      = {Information Systems Research},
  month        = {9},
  number       = {3},
  pages        = {1269-1292},
  shortjournal = {Inf. Syst. Res.},
  title        = {Digital development: Reimagining research beyond ICT4D},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ited">ITED - 10</h2>
<ul>
<li><details>
<summary>
(2025). Game—The freight transportation game: Operational challenges for carriers in online spot market platforms. <em>ITED</em>, <em>26</em>(1), 91-101. (<a href='https://doi.org/10.1287/ited.2024.0091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the freight transport spot market, carriers face several challenges, including handling small-sized loads, managing short lead times, and dealing with uncertainties that can disrupt their existing networks and capacity. In this context, auction platforms assist carriers in developing strategies to maintain productivity and service levels. This paper introduces the freight transportation game, an online auction-based platform specifically designed for the freight spot market. The game equips players, acting as carriers, with tools to develop transportation strategies, optimize routes, and propose competitive rates to maximize profits. Players engage in decision making and competition, with key performance indicators evaluating their decisions. The game includes two scenarios; the first helps students understand the operational challenges that carriers face in spot market auctions, whereas the second encourages cooperation to enhance performance and overcome obstacles. Designed for a three-hour session, the game can be integrated into courses on supply chain management or transportation systems. The practical learnings for students from the game include understanding the complexity of constructing transport plans, recognizing the challenges of using online auction-based platforms, and experiencing the difficulties of managing spot market requests despite their benefits. Funding: This work was supported by the Physical Internet Chair at Mines Paris, PSL University funded through an “Appel à Manifestation d’Intérêt” titled “Skills and Jobs of the Future” launched by la Caisse des Dépôts. Supplemental Material: Supplemental materials are available at https://doi.org/10.1287/ited.2024.0091 .},
  archive      = {J_ITED},
  doi          = {10.1287/ited.2024.0091},
  journal      = {INFORMS Transactions on Education},
  month        = {9},
  number       = {1},
  pages        = {91-101},
  shortjournal = {Inf. Syst. Res.},
  title        = {Game—The freight transportation game: Operational challenges for carriers in online spot market platforms},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Case—Potty parity: Stadium restroom design. <em>ITED</em>, <em>26</em>(1), 87-90. (<a href='https://doi.org/10.1287/ited.2023.0051cs'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {History: This paper has been accepted for the INFORMS Transactions on Education Special Issue on Diversity, Equity and Inclusion in OR/MS Classrooms.},
  archive      = {J_ITED},
  doi          = {10.1287/ited.2023.0051cs},
  journal      = {INFORMS Transactions on Education},
  month        = {9},
  number       = {1},
  pages        = {87-90},
  shortjournal = {Inf. Syst. Res.},
  title        = {Case—Potty parity: Stadium restroom design},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Case Article—Potty parity: Stadium restroom design. <em>ITED</em>, <em>26</em>(1), 79-86. (<a href='https://doi.org/10.1287/ited.2023.0051ca'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In view of the long wait times for women and the lack of accessibility for LGBTQ+ individuals when they use restrooms, this case provides a set of analytical tools to evaluate wait time disparity among users for different restroom configurations. A stadium manager who faces complaints about excessive restroom wait times aims to retrofit the restroom layout to improve both efficiency, measured in terms of wait time, and fairness, measured in terms of totalitarian and Rawlsian scores. Given that customers have diverse preferences over the use of restroom types, in three modules, students learn to (i) evaluate queuing parameters for a mix of heterogeneous populations, (ii) evaluate queuing metrics for various restroom layouts and discuss their wait time disparities, and (iii) evaluate and discuss the fairness of access to restroom facilities from a diversity, equity, and inclusion (DEI) perspective. By completing this case, students gain an understanding of service systems, learn about process flexibility concepts, and become familiar with DEI concepts and measures. The primary objectives of the case for students are to understand the trade-offs between efficiency and fairness, develop an understanding of multiobjective problems, and improve their skills in employing queuing concepts and tools. History: This paper has been accepted for the INFORMS Transactions on Education Special Issue on Diversity, Equity and Inclusion in OR/MS Classrooms. Supplemental Material: The Teaching Note and Excel files are available at https://www.informs.org/Publications/Subscribe/Access-Restricted-Materials .},
  archive      = {J_ITED},
  doi          = {10.1287/ited.2023.0051ca},
  journal      = {INFORMS Transactions on Education},
  month        = {9},
  number       = {1},
  pages        = {79-86},
  shortjournal = {Inf. Syst. Res.},
  title        = {Case Article—Potty parity: Stadium restroom design},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Case—Optimizing food donation delivery for nonprofit company Logica&Co. <em>ITED</em>, <em>26</em>(1), 73-78. (<a href='https://doi.org/10.1287/ited.2023.0042cs'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The case addresses a real-world challenge encountered by the nonprofit organization Logica&Co. It revolves around optimizing the logistics involved in collecting food donations from local businesses and delivering them to soup kitchens, utilizing a fleet of bike riders. The focus is identifying efficient strategies to minimize transportation and warehouse costs while maximizing the impact of the donations and private sponsor monetary contributions. The study includes tasks such as determining optimal bike and e-bike warehouse locations and managing the allocation of resources among riders and soup kitchen volunteers.},
  archive      = {J_ITED},
  doi          = {10.1287/ited.2023.0042cs},
  journal      = {INFORMS Transactions on Education},
  month        = {9},
  number       = {1},
  pages        = {73-78},
  shortjournal = {Inf. Syst. Res.},
  title        = {Case—Optimizing food donation delivery for nonprofit company Logica&Co},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Case Article—Optimizing food donation delivery for the nonprofit company Logica&Co. <em>ITED</em>, <em>26</em>(1), 63-72. (<a href='https://doi.org/10.1287/ited.2023.0042ca'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article presents a case exercise that teaches students how to apply mathematical programming to a real-life context. The case deals with the management of the food donation supply chain. The case, using a project-based approach, proposes a realistic scenario that simulates the consulting interaction with a nonprofit company, Logica&Co, which acts as a two-sided platform connecting supply and demand. The objective is to define an effective strategy to collect and deliver food donations, using either bike or e-bike, from local businesses to soup kitchens, covering a semester-long timeframe. The form of the problem exhibits nonlinear characteristics, but the design allows for adjustable difficulty levels. Students can assess their performance during the class period thanks to an interactive offline tool, the SoS simulator , which is publicly available for download and can be customized by instructors. The case was proposed as a competitive group challenge for students of the bachelor’s or master’s program in management engineering at Sapienza University of Rome. However, given the embedded characteristics of flexibility, it can be easily adjusted for heterogeneous curricula of undergraduate- and graduate-level courses in engineering programs (this opportunity is extensively discussed in the Case Article and the Teaching Note). The students appreciated both the teaching methodology and the teamwork aspects and highlighted the utility of the SoS simulator tool. Supplemental Material: The Teaching Note and its supplemental material are available at https://www.informs.org/Publications/Subscribe/Access-Restricted-Materials .},
  archive      = {J_ITED},
  doi          = {10.1287/ited.2023.0042ca},
  journal      = {INFORMS Transactions on Education},
  month        = {9},
  number       = {1},
  pages        = {63-72},
  shortjournal = {Inf. Syst. Res.},
  title        = {Case Article—Optimizing food donation delivery for the nonprofit company Logica&Co},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Infrastructure decision preferences and the influence of social justice education. <em>ITED</em>, <em>26</em>(1), 48-62. (<a href='https://doi.org/10.1287/ited.2023.0052'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social justice considerations are critical in today’s engineering education. As an example, access to electricity will be crucial to the development of sub-Saharan Africa (SSA) by powering essential sectors and services that would yield economic growth and an improved quality of life. Because infrastructure investments are often allocated to urban areas, it is important for stakeholders to equally prioritize rural electrification in their efforts to achieve universal electrification. These stakeholders make decisions on allocating infrastructure investment based on their underlying values and preferences. It is therefore important to introduce and integrate ideas of fairness and social justice into the engineering curriculum. Our paper investigates the influence of social justice education on decision preferences among students tasked with planning electricity systems. We engaged graduate and undergraduate students in a discrete choice experiment to determine their preferences for equality. In our study, we find that an interactive social justice education module can be effective in increasing equality preferences among non–U.S.-citizen students by 22%. Among students with relatively low preferences for equality, we find that the education module was effective in increasing preference by 18% on average and up to 191%, which translated into more equitable resource allocation. As such, we show that an education intervention for stakeholders may be effective in improving equitable electrification in SSA. The preference elicitation and education module presented in this paper could be repurposed by instructors to include other contexts in their course content (e.g., money, water, housing, etc.) or to people wanting to educate decision makers about social justice. History: This paper has been accepted for the INFORMS Transactions on Education Special Issue on Diversity, Equity and Inclusion in OR/MS Classrooms. Funding: This work was supported by the National Science Foundation [Grant 2121730].},
  archive      = {J_ITED},
  doi          = {10.1287/ited.2023.0052},
  journal      = {INFORMS Transactions on Education},
  month        = {9},
  number       = {1},
  pages        = {48-62},
  shortjournal = {Inf. Syst. Res.},
  title        = {Infrastructure decision preferences and the influence of social justice education},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An agile approach to student consulting projects: Iteration and communication to improve decision making, presentations, and teamwork. <em>ITED</em>, <em>26</em>(1), 34-47. (<a href='https://doi.org/10.1287/ited.2023.0057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedding consulting projects into the curriculum presents an effective means of providing students with experiential applied learning opportunities. However, creating, planning, and managing such projects can be challenging. This paper introduces a unique approach to managing consulting projects: Agile Project Management with Scrum. By incorporating a commitment to iteration and communication as the core of the project experience, Agile with Scrum fosters an impactful, realistic, and engaging student consulting experience. This approach enhances decision making, presentations, and team dynamics. This article discusses how one supply chain management course embedded Agile with Scrum into a client consulting project to convert a mediocre experiential learning opportunity into a transformative one. After describing Agile with Scrum and explaining its potential in the classroom, this paper discusses the consulting project before and after Agile; the results; the lessons learned; and the value created for students, clients, and faculty. Supplemental Material: The online appendix is available at https://doi.org/10.1287/ited.2023.0057 .},
  archive      = {J_ITED},
  doi          = {10.1287/ited.2023.0057},
  journal      = {INFORMS Transactions on Education},
  month        = {9},
  number       = {1},
  pages        = {34-47},
  shortjournal = {Inf. Syst. Res.},
  title        = {An agile approach to student consulting projects: Iteration and communication to improve decision making, presentations, and teamwork},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An operations Research–Based teaching unit for grade 12: The ROAR experience, part III. <em>ITED</em>, <em>26</em>(1), 12-33. (<a href='https://doi.org/10.1287/ited.2023.0065'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we finish describing the project and the experimentation of Ricerca Operativa Applicazioni Reali (ROAR; in English, Real Applications of Operations Research), a three-year project for higher secondary schools. ROAR is composed of three teaching units addressed to grades 10, 11, and 12, respectively. To improve students’ interest, motivation, and skills related to science, technology, engineering, and mathematics disciplines, ROAR integrates the teaching of mathematics and computer science through operations research. Its implementation started in 2021 in a grade 10 class at the scientific high school IIS Antonietti in Iseo (Brescia, Italy). We provided the details of the first two units in previous papers. Here, we focus on the third and last unit, carried out from October 2022 to January 2023, with the same students, then in a grade 12 class. Similarly to the first two units, we describe objectives, prerequisites, topics and methods, the organization of the lectures, digital technologies used, and a challenging final project that, this time, involved the manufacturer company Filtrec S.p.A. with a case. After analyzing the feedback from students, teachers, and practitioners engaged in the experimentation, we reflect on the entire experimentation and provide some insights to replicate a similar experience. Funding: G. Colajanni was partially supported by the research project Programma Ricerca di Ateneo UNICT 2020-22 linea 2, Ottimizzazione di Modelli di Network slIce 5G con UAV, the Italian Ministry of University and Research and the European Union for the Programma Operativo Nazionale project on Research and Innovation 2014-2020, D.M. 1062/2021, and the GNAMPA-INdAM Group. A. Raffaele was partially supported by the National Group for Scientific Computation. E. Taranto was partially supported by the National Group for Algebraic and Geometric Structures, and their Applications. Supplemental Material: The online appendices are available at https://doi.org/10.1287/ited.2023.0065 .},
  archive      = {J_ITED},
  doi          = {10.1287/ited.2023.0065},
  journal      = {INFORMS Transactions on Education},
  month        = {9},
  number       = {1},
  pages        = {12-33},
  shortjournal = {Inf. Syst. Res.},
  title        = {An operations Research–Based teaching unit for grade 12: The ROAR experience, part III},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Case—Optimizing transportation and equity in a district zoning problem for ORville public schools. <em>ITED</em>, <em>26</em>(1), 8-11. (<a href='https://doi.org/10.1287/ited.2023.0046cs'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {History: This paper has been accepted for the INFORMS Transactions on Education Special Issue on Diversity, Equity and Inclusion in OR/MS Classrooms.},
  archive      = {J_ITED},
  doi          = {10.1287/ited.2023.0046cs},
  journal      = {INFORMS Transactions on Education},
  month        = {9},
  number       = {1},
  pages        = {8-11},
  shortjournal = {Inf. Syst. Res.},
  title        = {Case—Optimizing transportation and equity in a district zoning problem for ORville public schools},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Case Article—Optimizing transportation and equity in a district zoning problem for ORville public schools. <em>ITED</em>, <em>26</em>(1), 1-7. (<a href='https://doi.org/10.1287/ited.2023.0046ca'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This case asks students to solve a multiobjective optimization decision problem applied to school district zoning. In the case, residential areas in a school district must be assigned to middle schools having capacity limits. The operational considerations on the decision are the weighted distances traveled between students’ residences and their assigned middle school campuses. The ethical considerations pertain to equity in education and are measured using the numbers of economically disadvantaged students assigned to each middle school. This problem, including its two objectives, is motivated by a real zoning problem faced by a school district. Publicly available data from the school district and its rezoning efforts are used to populate the case. To complete the case, students model and solve an optimization problem both with and without the ethical considerations included. In doing so, they observe how ethical considerations can change the outputs generated by the optimization model. Evidence is provided from student surveys to indicate how completion of the case impacts perceptions of the importance of and understanding of how to include ethical considerations in optimization modeling. Results indicate statistically significant increases in those perceptions. History: This paper has been accepted for the INFORMS Transactions on Education Special Issue on Diversity, Equity and Inclusion in OR/MS Classrooms. Supplemental Material: The Teaching Note and DataAndMetricsDemo Excel workbook are available at https://www.informs.org/Publications/Subscribe/Access-Restricted-Materials .},
  archive      = {J_ITED},
  doi          = {10.1287/ited.2023.0046ca},
  journal      = {INFORMS Transactions on Education},
  month        = {9},
  number       = {1},
  pages        = {1-7},
  shortjournal = {Inf. Syst. Res.},
  title        = {Case Article—Optimizing transportation and equity in a district zoning problem for ORville public schools},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="mksc">MKSC - 13</h2>
<ul>
<li><details>
<summary>
(2025). Focus on authors. <em>MKSC</em>, <em>44</em>(5), 1212-1215. (<a href='https://doi.org/10.1287/mksc.2025.focusonaus.v44.5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MKSC},
  doi          = {10.1287/mksc.2025.focusonaus.v44.5},
  journal      = {Marketing Science},
  month        = {9-10},
  number       = {5},
  pages        = {1212-1215},
  shortjournal = {Market. Sci.},
  title        = {Focus on authors},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Search fatigue, choice deferral, and closure. <em>MKSC</em>, <em>44</em>(5), 1188-1211. (<a href='https://doi.org/10.1287/mksc.2023.0275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When gathering information to make decisions, individuals often have to delay making a decision because the process of gathering information is interrupted, and the individual is not yet ready to make a decision. The paper considers a model of choice deferral based on time-varying search costs, potentially based on search fatigue, in which individuals have to strategically decide whether to defer choice when information gathering is interrupted, taking into account the current available information, and when they will be able to resume gathering information. We find that individuals are more likely to defer choice when information gathering is interrupted less frequently, when individuals can resume gathering information sooner, and when they discount the future less. We also consider the case in which individuals incur costs of restarting a process of information gathering and cases in which the individual has greater or less information about the extent of search fatigue. The paper also considers optimal pricing, user interface design, and retargeting decisions, and it shows how they should respond to the length of consumer browsing sessions and gaps between browsing sessions. The paper illustrates the importance of modeling fatigue and interruptions in the search process. History: Anthony Dukes served as the senior editor. Supplemental Material: The online appendix is available at https://doi.org/10.1287/mksc.2023.0275 .},
  archive      = {J_MKSC},
  doi          = {10.1287/mksc.2023.0275},
  journal      = {Marketing Science},
  month        = {9-10},
  number       = {5},
  pages        = {1188-1211},
  shortjournal = {Market. Sci.},
  title        = {Search fatigue, choice deferral, and closure},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CCP estimation of dynamic discrete choice demand models with segment level data and continuous unobserved heterogeneity: Rethinking EV subsidies vs. infrastructure. <em>MKSC</em>, <em>44</em>(5), 1163-1187. (<a href='https://doi.org/10.1287/mksc.2024.0860'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When multiple groups of consumers reside in the same market, we determine that we can write each group’s conditional choice probabilities (CCPs) as a function of unobserved consumer heterogeneity. Moreover, we can specify choice probabilities of one group as a function of another by shifting the unobserved component. Armed with our novel CCP estimator, we develop an approach to identify and estimate a dynamic discrete demand model for durable goods with nonrandom attrition of consumers and continuous unobserved consumer heterogeneity but without the usual need for value function approximation or reducing the dimension of state space by ad hoc behavioral assumptions. We illustrate the empirical value of our method by estimating consumer demand for electric vehicles (EVs) in the state of Washington during the period of 2016–2019. We also determine the impact of a different federal tax credit based on the electric range of a car rather than the size of the battery, which was the existing policy during the data period, and we evaluate how best to seed a nascent market that presents indirect network effects to drive faster adoption. Should the government incentivize adoption through consumer tax credits or through EV infrastructure? History: Tat Chan served as the senior editor. Supplemental Material: The online appendices and data files are available at https://doi.org/10.1287/mksc.2024.0860 .},
  archive      = {J_MKSC},
  doi          = {10.1287/mksc.2024.0860},
  journal      = {Marketing Science},
  month        = {9-10},
  number       = {5},
  pages        = {1163-1187},
  shortjournal = {Market. Sci.},
  title        = {CCP estimation of dynamic discrete choice demand models with segment level data and continuous unobserved heterogeneity: Rethinking EV subsidies vs. infrastructure},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reputation for privacy. <em>MKSC</em>, <em>44</em>(5), 1145-1162. (<a href='https://doi.org/10.1287/mksc.2024.1006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As consumers become increasingly concerned about their privacy, firms can benefit from committing not to sell consumer data. However, the holdup problem prevents firms from doing so in a static setting. This paper studies whether reputation consideration of the firm can serve as a commitment device in a long-run game when consumers have imperfect monitoring technology. We find that a patient enough monopoly can commit because its reputation will suffer from a persistent punishment if consumers detect the data sale. In contrast, reputation may fail to serve as a commitment device when there are multiple firms. The penalty for selling data is temporary when consumers do not know exactly which firm sold the data. In addition, selling data imposes a negative externality on other firms, but each firm does not take it into account in equilibrium. We characterize conditions under which duopolistic firms lose the ability to commit even if they are arbitrarily patient. Reputation cannot serve as a commitment device under any conditions as the number of firms increases because each firm is penalized less for selling the data but not rewarded more for not doing so. Lastly, we explore several ways of restoring firms’ commitment power through regulation. History: Anthony Dukes served as the senior editor. Supplemental Material: The online appendix is available at https://doi.org/10.1287/mksc.2024.1006 .},
  archive      = {J_MKSC},
  doi          = {10.1287/mksc.2024.1006},
  journal      = {Marketing Science},
  month        = {9-10},
  number       = {5},
  pages        = {1145-1162},
  shortjournal = {Market. Sci.},
  title        = {Reputation for privacy},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Is the money spent on short-form video social platforms worth it? the role of advertising spillover in a large-scale randomized field experiment on ByteDance. <em>MKSC</em>, <em>44</em>(5), 1125-1144. (<a href='https://doi.org/10.1287/mksc.2023.0575'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-form videos have taken over social media and attracted attention from advertisers. But doubts remain about the advertising efficacy on these platforms. In a large-scale randomized experiment on ByteDance, we show that advertising spillover plays a pivotal role in the advertising campaign. Most of the advertising effect comes from advertising spillover beyond ByteDance with exposed users being eight times more likely to convert from outside than from within ByteDance. When considering advertising spillover outside ByteDance, the average cost per conversion, which brands commonly use to evaluate the cost of campaigns, shrinks by 5 or 25 times, depending on the methods used to calculate it. Advertising spillover can also affect a brand’s targeting strategy. Whereas commonly used demographic variables by the automobile brand are effective for target marketing with only platform data, they are not when considering advertising spillover outside ByteDance. Instead, a behavioral variable proposed herein (prior brand home page visits) effectively moderates the advertising effect but has no impact when ignoring advertising spillover in the analysis. Our findings underscore the importance of information sharing between platforms and brands, which in practice is typically not the case. History: Tat Chan served as the senior editor. Funding: This work was supported by the National Natural Science Foundation of China [Grants 72222006 and 71991461]. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mksc.2023.0575 .},
  archive      = {J_MKSC},
  doi          = {10.1287/mksc.2023.0575},
  journal      = {Marketing Science},
  month        = {9-10},
  number       = {5},
  pages        = {1125-1144},
  shortjournal = {Market. Sci.},
  title        = {Is the money spent on short-form video social platforms worth it? the role of advertising spillover in a large-scale randomized field experiment on ByteDance},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Banning unsolicited store flyers: Does helping the environment hurt retailing?. <em>MKSC</em>, <em>44</em>(5), 1104-1124. (<a href='https://doi.org/10.1287/mksc.2023.0020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retailers often use store flyers to communicate the availability, price, and promotions of their products. Many households inspect store flyers for promotions, and the majority still prefer to receive store flyers in print. Yet, many are said to throw out store flyers unread, creating excessive waste that is environmentally damaging because of the excess use of paper, ink, and logistics. Legislation to reduce the distribution and waste associated with unsolicited store flyers has been proposed, but if and how much such a cut in distribution would affect households’ grocery shopping behavior remain unclear. This paper investigates a recent policy change by seven Dutch municipalities that implemented a ban on unsolicited store flyers by moving from an opt-out policy to an opt-in policy at some point between 2018 and 2020. Using household scanner data, the authors assess changes in shopping behavior along nine comprehensive dimensions relevant to retailers, brand manufacturers, and policymakers using a stacked, synthetic difference-in-differences approach. Although store flyer distribution decreased by 50% under the new policy, the drastic change did not substantially affect grocery shopping behavior. These findings are robust to different time windows and modeling approaches. History: Puneet Manchanda served as the senior editor. Funding: This work was supported by the Marketing Science Institute [Grant 4001614]. Partial financial support was received from A Sustainable Future research platform. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mksc.2023.0020 .},
  archive      = {J_MKSC},
  doi          = {10.1287/mksc.2023.0020},
  journal      = {Marketing Science},
  month        = {9-10},
  number       = {5},
  pages        = {1104-1124},
  shortjournal = {Market. Sci.},
  title        = {Banning unsolicited store flyers: Does helping the environment hurt retailing?},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing scalable targeted marketing policies with constraints. <em>MKSC</em>, <em>44</em>(5), 1082-1103. (<a href='https://doi.org/10.1287/mksc.2023.0640'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Targeted marketing policies target different customers with different marketing actions. Although most research has focused on training targeting policies without managerial constraints, in practice, many firms face managerial constraints when implementing these policies. For example, firms may face volume constraints on the maximum or minimum number of actions they can take or on the minimum acceptable outcomes for different customer segments. They may also face similarity (fairness) constraints that require similar actions with different groups of customers. Traditional optimization methods face challenges when solving problems with either many customers or many constraints. We show how recent advances in linear programming can be adapted to the targeting of marketing actions. We provide a theoretical guarantee comparing how the proposed algorithm scales compared with state-of-the-art benchmarks (primal simplex, dual simplex, and barrier methods). We also extend existing guarantees on optimality and computation speed, by adapting them to accommodate the characteristics of targeting problems. We implement the proposed algorithm using data from a field experiment with over 2 million customers and six different marketing actions (including a no-action “Control”). We use this application to evaluate the computation speed and range of problems that the algorithm can solve, comparing it to benchmark methods. The findings confirm that the algorithm makes it feasible to train large-scale targeting problems that include volume and similarity constraints. History: Tat Chan served as the senior editor. Funding: Y. Zhu received financial support from by the Ministry of Education, Singapore [Grant WBS A-8001730-00-00] and the National University of Singapore (NUS) [Grant WBS A-8000489-00-00]. Cloud resources involved in this work were partially supported by the NUS Cloud Credits for Research Program. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mksc.2023.0640 .},
  archive      = {J_MKSC},
  doi          = {10.1287/mksc.2023.0640},
  journal      = {Marketing Science},
  month        = {9-10},
  number       = {5},
  pages        = {1082-1103},
  shortjournal = {Market. Sci.},
  title        = {Optimizing scalable targeted marketing policies with constraints},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The value of professional ties in B2B markets. <em>MKSC</em>, <em>44</em>(5), 1058-1081. (<a href='https://doi.org/10.1287/mksc.2022.0320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study how a particular form of social ties (i.e., professional ties proxied by past employment) affects price and profitability in business-to-business (B2B) markets. Although most of the work on social ties focuses on information diffusion in business-to-consumer markets, we ask the following. Do B2B buyers receive higher or lower prices from sellers with whom they have professional ties? Can professional ties benefit both buyers and sellers and create win-win exchanges? Answering these questions is challenging because it is difficult to observe B2B prices, the individual decision makers (IDMs), and elements of differentiation that drive price variation. Moreover, potentially endogenous formation of social ties exacerbates the identification challenge. We resolve these challenges by leveraging proprietary data from the Federal Reserve on the repo market, the largest market for short-term loans with daily transactions of more than $2 trillion. In addition, we use financial disclosure laws to unmask IDMs at sellers and use LinkedIn to reveal their ties. We leverage exogenous movement of IDMs in and out of decision-making positions to identify the effect of professional ties on price. We show that a seller IDM, who is the buyer’s former employee, charges the buyer 1/4 basis points more than other buyers with no ties (i.e., 25 basis points relative to median price, or 13% of average cross-sectional price variance). The mechanism driving this price increase is “supply reliability.” Sellers with a professional tie to the buyer act more reliably toward that buyer during supply-demand imbalances. We perform several robustness checks, including leveraging the Federal Reserve’s monetary policy actions in response to the COVID-19 pandemic, to show that an exogenous increase in the aggregate cash supply diminishes the effect of professional ties, consistent with a supply reliability mechanism. Our work suggests professional ties can affect B2B prices beyond observable supply-demand dynamics and provide value for sellers and buyers. History: Tat Chan served as the senior editor. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mksc.2022.0320 .},
  archive      = {J_MKSC},
  doi          = {10.1287/mksc.2022.0320},
  journal      = {Marketing Science},
  month        = {9-10},
  number       = {5},
  pages        = {1058-1081},
  shortjournal = {Market. Sci.},
  title        = {The value of professional ties in B2B markets},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sustainable consumption: A strategic analysis. <em>MKSC</em>, <em>44</em>(5), 1038-1057. (<a href='https://doi.org/10.1287/mksc.2023.0287'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consumers’ growing concern for the environment has motivated firms to offer sustainable products in several categories. An exploratory survey shows that many consumers desire sustainable products and are willing to pay more for them, but some consumers dislike sustainable products and want to pay less for them. Using a theoretical model where firms are horizontally differentiated and two groups of consumers have divergent preferences for sustainable products, we investigate the strategic implications of sustainable consumption. First, our analysis shows that when consumers’ dislike for sustainable products is moderate, the price could increase as the dislike increases. Moreover, price could decrease if consumers’ desire for sustainable products increases. Second, we find that competing firms’ profits can decrease with consumers’ desire for sustainability but increase with consumers’ dislike for sustainability. Third, we clarify when and why enforcing minimal sustainability standards for products can backfire and reduce consumer surplus. Finally, we extend the model to capture additional facets of sustainable consumption, such as multiproduct firms, sustainable luxury goods, and political orientation of consumers, and tease out its counterintuitive implications for the firms supplying sustainable products. History: Anthony Dukes served as the senior editor. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mksc.2023.0287 .},
  archive      = {J_MKSC},
  doi          = {10.1287/mksc.2023.0287},
  journal      = {Marketing Science},
  month        = {9-10},
  number       = {5},
  pages        = {1038-1057},
  shortjournal = {Market. Sci.},
  title        = {Sustainable consumption: A strategic analysis},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Expert’s recommendations in product choices: Information provision, conflicts of interest, and consumer protection among U.S. kidney disease patients. <em>MKSC</em>, <em>44</em>(5), 1017-1037. (<a href='https://doi.org/10.1287/mksc.2023.0191'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consumers in high-stakes product markets, such as healthcare or finance, often rely on experts’ recommendations before making a purchase decision. However, how an expert constructs a specific set of recommendations and how it subsequently affects consumer choices and outcomes have been understudied. We propose an empirical framework that econometrically recovers experts’ recommendations and combines them with heterogeneous consumers’ choice of products or services. We then apply the framework to examine kidney disease patients’ choice of dialysis facilities. Using detailed data on more than 16,900 U.S. patients with kidney disease who had consultations with over 750 physicians between 2015 and 2017, we study physicians’ dialysis facility recommendations and patients’ subsequent choice of facilities. We find that physicians are more likely to recommend facilities with which they are affiliated and those close to patients. Policy simulations suggest that quality information provision through five-star ratings has likely lowered mortality, thereby helping patients. In contrast, reducing conflicts of interest by banning the usage of affiliation as a basis for physicians’ facility recommendations can inadvertently hurt patients as evidenced by an increase in mortality. The study provides relevant consumer-centric insights into recent efforts to change market regulations and policies in this healthcare market. History: Puneet Manchanda served as the senior editor. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mksc.2023.0191 . Disclaimer: The data reported here have been supplied by the United States Renal Data System (USRDS). The interpretation and reporting of these data are the responsibility of the author(s) and in no way should be seen as an official policy or interpretation of the U.S. government.},
  archive      = {J_MKSC},
  doi          = {10.1287/mksc.2023.0191},
  journal      = {Marketing Science},
  month        = {9-10},
  number       = {5},
  pages        = {1017-1037},
  shortjournal = {Market. Sci.},
  title        = {Expert’s recommendations in product choices: Information provision, conflicts of interest, and consumer protection among U.S. kidney disease patients},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LOLA: LLM-assisted online learning algorithm for content experiments. <em>MKSC</em>, <em>44</em>(5), 995-1016. (<a href='https://doi.org/10.1287/mksc.2024.0990'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern media firms require automated and efficient methods to identify content that is most engaging and appealing to users. Leveraging a large-scale data set from Upworthy (a news publisher), which includes 17,681 headline A/B tests, we first investigate the ability of three pure–large language model (LLM) approaches to identify the catchiest headline: prompt-based methods, embedding-based methods, and fine-tuned open-source LLMs. Prompt-based approaches perform poorly, while both OpenAI embedding–based models and the fine-tuned Llama-3-8B achieve marginally higher accuracy than random predictions. In sum, none of the pure LLM–based methods can predict the best-performing headline with high accuracy. We then introduce the LLM-assisted online learning algorithm (LOLA), a novel framework that integrates LLMs with adaptive experimentation to optimize content delivery. LOLA combines the best pure-LLM approach with the upper confidence bound algorithm to allocate traffic and maximize clicks adaptively. Our numerical experiments on Upworthy data show that LOLA outperforms the standard A/B test method (the current status quo at Upworthy), pure bandit algorithms, and pure-LLM approaches, particularly in scenarios with limited experimental traffic. Our approach is scalable and applicable to content experiments across various settings where firms seek to optimize user engagement, including digital advertising and social media recommendations. History: Olivier Toubia served as the senior editor. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mksc.2024.0990 .},
  archive      = {J_MKSC},
  doi          = {10.1287/mksc.2024.0990},
  journal      = {Marketing Science},
  month        = {9-10},
  number       = {5},
  pages        = {995-1016},
  shortjournal = {Market. Sci.},
  title        = {LOLA: LLM-assisted online learning algorithm for content experiments},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mass shootings and their impact on retail. <em>MKSC</em>, <em>44</em>(5), 985-994. (<a href='https://doi.org/10.1287/mksc.2024.0752'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mass shootings in the United States have become more frequent, often targeting retail locations such as shopping malls that attract high foot traffic. We combine detailed data on mass shootings with debit and credit card transaction data at individual stores to assess the economic impact of mass shootings. Using a difference-in-differences framework, we find that affected stores experience lower demand, smaller order sizes, decreased foot traffic, and reduced customer dwell times, resulting in a significant decline in retail revenues. We also find the impact of mass shootings diminishes with distance, adversely affecting stores within a radius of up to 1.25 miles. Additionally, we examine the likelihood of store closures after incidents and factors contributing to store survival. Overall, we estimate the annual economic cost of mass shootings at $27 billion in lost revenues to retail businesses. Consistent with consumers’ fear and safety concerns, we observe heterogeneous effects by business type (e.g., nonessential stores are more impacted than essential stores), channel substitution from in-person to online shopping, and moderation by local exposure to gun-related violence. History: Catherine Tucker served as the senior editor. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mksc.2024.0752 .},
  archive      = {J_MKSC},
  doi          = {10.1287/mksc.2024.0752},
  journal      = {Marketing Science},
  month        = {9-10},
  number       = {5},
  pages        = {985-994},
  shortjournal = {Market. Sci.},
  title        = {Mass shootings and their impact on retail},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frontiers: The intended and unintended consequences of privacy regulation for consumer marketing. <em>MKSC</em>, <em>44</em>(5), 975-984. (<a href='https://doi.org/10.1287/mksc.2024.0901'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As businesses increasingly rely on granular consumer data, the public has increasingly pushed for enhanced regulation to protect consumers’ privacy. We provide a perspective based on the academic marketing literature that evaluates the various benefits and costs of existing and pending government regulations and corporate privacy policies. We make four key points. First, data-based personalized marketing is not automatically harmful. Second, consumers have heterogeneous privacy preferences, and privacy policies may unintentionally favor the preferences of the rich. Third, privacy regulations may stifle innovation by entrepreneurs who are more likely to cater to underserved, niche consumer segments. Fourth, privacy measures may favor large companies who have less need for third-party data and can afford compliance costs. We also discuss technology platforms’ recent proposals for privacy solutions that mitigate some of these harms but, again, in a way that might disadvantage small firms and entrepreneurs. History: Olivier Toubia served as the senior editor. Supplemental Material: The web appendix is available at https://doi.org/10.1287/mksc.2024.0901 .},
  archive      = {J_MKSC},
  doi          = {10.1287/mksc.2024.0901},
  journal      = {Marketing Science},
  month        = {9-10},
  number       = {5},
  pages        = {975-984},
  shortjournal = {Market. Sci.},
  title        = {Frontiers: The intended and unintended consequences of privacy regulation for consumer marketing},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="moor">MOOR - 30</h2>
<ul>
<li><details>
<summary>
(2025). Comparison between mean-variance and monotone mean-variance preferences under jump diffusion and stochastic factor model. <em>MOOR</em>, <em>50</em>(3), 2405-2432. (<a href='https://doi.org/10.1287/moor.2022.0331'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper compares the optimal investment problems based on monotone mean-variance (MMV) and mean-variance (MV) preferences in a Lévy market with an untradable stochastic factor. It is an open question proposed by Trybuła and Zawisza. Using the dynamic programming and Lagrange multiplier methods, we get the Hamilton-Jacobi-Bellman-Isaacs (HJBI) and Hamilton-Jacobi-Bellman (HJB) equations corresponding to the two investment problems. The equations are transformed into a new-type parabolic equation, from which the optimal strategies under both preferences are derived. We prove that the two optimal strategies and value functions coincide if and only if an important market assumption holds. When the assumption is violated, MMV investors act differently from MV investors. Thus, we conclude that the difference between continuous-time MMV and MV portfolio selections is due to the discontinuity of the market. In addition, we derive the efficient frontier and analyze the economic impact of the jump diffusion risky asset. We also provide empirical evidence to demonstrate the validity of the assumption in real financial markets. Funding: This research was supported by National Natural Science Foundation of China [Grants 12271290 and 11871036].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0331},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2405-2432},
  shortjournal = {Math. Oper. Res.},
  title        = {Comparison between mean-variance and monotone mean-variance preferences under jump diffusion and stochastic factor model},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual solutions in convex stochastic optimization. <em>MOOR</em>, <em>50</em>(3), 2375-2404. (<a href='https://doi.org/10.1287/moor.2022.0270'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies duality and optimality conditions for general convex stochastic optimization problems. The main result gives sufficient conditions for the absence of a duality gap and the existence of dual solutions in a locally convex space of random variables. It implies, in particular, the necessity of scenario-wise optimality conditions that are behind many fundamental results in operations research, stochastic optimal control, and financial mathematics. Our analysis builds on the theory of Fréchet spaces of random variables whose topological dual can be identified with the direct sum of another space of random variables and a space of singular functionals. The results are illustrated by deriving sufficient and necessary optimality conditions for several more specific problem classes. We obtain significant extensions to earlier models, for example, on stochastic optimal control, portfolio optimization, and mathematical programming.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0270},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2375-2404},
  shortjournal = {Math. Oper. Res.},
  title        = {Dual solutions in convex stochastic optimization},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Langevin dynamics based algorithm e-THεO POULA for stochastic optimization problems with discontinuous stochastic gradient. <em>MOOR</em>, <em>50</em>(3), 2333-2374. (<a href='https://doi.org/10.1287/moor.2022.0307'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new Langevin dynamics based algorithm, called the extended tamed hybrid ε -order polygonal unadjusted Langevin algorithm (e-TH ε O POULA), to solve optimization problems with discontinuous stochastic gradients, which naturally appear in real-world applications such as quantile estimation, vector quantization, conditional value at risk (CVaR) minimization, and regularized optimization problems involving rectified linear unit (ReLU) neural networks. We demonstrate both theoretically and numerically the applicability of the e-TH ε O POULA algorithm. More precisely, under the conditions that the stochastic gradient is locally Lipschitz in average and satisfies a certain convexity at infinity condition, we establish nonasymptotic error bounds for e-TH ε O POULA in Wasserstein distances and provide a nonasymptotic estimate for the expected excess risk, which can be controlled to be arbitrarily small. Three key applications in finance and insurance are provided, namely, multiperiod portfolio optimization, transfer learning in multiperiod portfolio optimization, and insurance claim prediction, which involve neural networks with (Leaky)-ReLU activation functions. Numerical experiments conducted using real-world data sets illustrate the superior empirical performance of e-TH ε O POULA compared with SGLD (stochastic gradient Langevin dynamics), TUSLA (tamed unadjusted stochastic Langevin algorithm), adaptive moment estimation, and Adaptive Moment Estimation with a Strongly Non-Convex Decaying Learning Rate in terms of model accuracy. Funding: Financial support was provided by the Alan Turing Institute, London, under the Engineering and Physical Sciences Research Council [Grant EP/N510129/1]; the Ministry of Education of Singapore Academic Research Fund [Tier 2 Grant MOE-T2EP20222-0013]; the European Union’s Horizon 2020 Research and Innovation Programme [Marie Skłodowska-Curie Grant Agreement 801215]; the University of Edinburgh’s Data-Driven Innovation Programme, part of the Edinburgh and South East Scotland City Region Deal; an Institute of Information and Communications Technology Planning and Evaluation grant funded by the Korean Ministry of Science and ICT (MIST) [Grant 2020-0-01336]; the Artificial Intelligence Graduate School Program of the Ulsan National Institute of Science and Technology; a National Research Foundation of Korea grant funded by the Korean government (MSIT) [Grant RS-2023-00253002]; and the Guangzhou–Hong Kong University of Science and Technology (Guangzhou) Joint Funding Program [Grant 2024A03J0630].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0307},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2333-2374},
  shortjournal = {Math. Oper. Res.},
  title        = {Langevin dynamics based algorithm e-THεO POULA for stochastic optimization problems with discontinuous stochastic gradient},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A retrospective approximation approach for smooth stochastic optimization. <em>MOOR</em>, <em>50</em>(3), 2301-2332. (<a href='https://doi.org/10.1287/moor.2022.0136'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic Gradient (SG) is the de facto iterative technique to solve stochastic optimization (SO) problems with a smooth (nonconvex) objective f and a stochastic first-order oracle. SG’s attractiveness is due in part to its simplicity of executing a single step along the negative subsampled gradient direction to update the incumbent iterate. In this paper, we question SG’s choice of executing a single step as opposed to multiple steps between subsample updates. Our investigation leads naturally to generalizing SG into Retrospective Approximation (RA), where, during each iteration, a “deterministic solver” executes possibly multiple steps on a subsampled deterministic problem and stops when further solving is deemed unnecessary from the standpoint of statistical efficiency. RA thus formalizes what is appealing for implementation—during each iteration, “plug in” a solver—for example, L-BFGS line search or Newton-CG— as is , and solve only to the extent necessary. We develop a complete theory using relative error of the observed gradients as the principal object, demonstrating that almost sure and L 1 consistency of RA are preserved under especially weak conditions when sample sizes are increased at appropriate rates. We also characterize the iteration and oracle complexity (for linear and sublinear solvers) of RA and identify a practical termination criterion leading to optimal complexity rates. To subsume nonconvex f , we present a certain “random central limit theorem” that incorporates the effect of curvature across all first-order critical points, demonstrating that the asymptotic behavior is described by a certain mixture of normals. The message from our numerical experiments is that the ability of RA to incorporate existing second-order deterministic solvers in a strategic manner might be important from the standpoint of dispensing with hyper-parameter tuning. Funding: R. Pasupathy received financial support from the Office of Naval Research [Grants N000141712295 and 13000991]. R. Bollapragada received financial support from the Lawrence Livermore National Laboratory and the National Science Foundation [Grant NSF DMS 2324643].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0136},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2301-2332},
  shortjournal = {Math. Oper. Res.},
  title        = {A retrospective approximation approach for smooth stochastic optimization},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The minimax property in infinite two-person win-lose games. <em>MOOR</em>, <em>50</em>(3), 2287-2300. (<a href='https://doi.org/10.1287/moor.2023.0352'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore a version of the minimax theorem for two-person win-lose games with infinitely many pure strategies. In the countable case, we give a combinatorial condition on the game which implies the minimax property. In the general case, we prove that a game satisfies the minimax property along with all its subgames if and only if none of its subgames is isomorphic to the “larger number game.” This generalizes a recent theorem of Hanneke, Livni, and Moran. We also propose several applications of our results outside of game theory.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0352},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2287-2300},
  shortjournal = {Math. Oper. Res.},
  title        = {The minimax property in infinite two-person win-lose games},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Envy-free division of multilayered cakes. <em>MOOR</em>, <em>50</em>(3), 2261-2286. (<a href='https://doi.org/10.1287/moor.2022.0350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dividing a multilayered cake under nonoverlapping constraints captures several scenarios (e.g., allocating multiple facilities over time where each agent can utilize at most one facility simultaneously). We establish the existence of an envy-free multidivision that is nonoverlapping and contiguous within each layer when the number of agents is a prime power, solving partially an open question by Hosseini et al. [Hosseini H, Igarashi A, Searns A (2020) Fair division of time: Multi-layered cake cutting. Proc. 29th Internat. Joint Conf. Artificial Intelligence (IJCAI) , 182–188; Hosseini H, Igarashi A, Searns A (2020) Fair division of time: Multi-layered cake cutting. Preprint, submitted April 28, http://arxiv.org/abs/2004.13397 ]. Our approach follows an idea proposed by Jojić et al. [Jojić D, Panina G, Živaljević R (2021) Splitting necklaces, with constraints. SIAM J. Discrete Math. 35(2):1268–1286] for envy-free divisions, relying on a general fixed-point theorem. We further design a fully polynomial-time approximation scheme for the two-layer, three-agent case, with monotone preferences. All results are actually established for divisions among groups of almost the same size. In the one-layer, three-group case, our algorithm is able to deal with any predetermined sizes, still with monotone preferences. For three groups, this provides an algorithmic version of a recent theorem by Segal-Halevi and Suksompong [Segal-Halevi E, Suksompong W (2021) How to cut a cake fairly: A generalization to groups. Amer. Math. Monthly 128(1):79–83]. Funding: This work was partially supported by the Japan Science and Technology Agency [Grant JPMJPR20C], Fusion Oriented REsearch for disruptive Science and Technology [Grant JPMJFR226O], and Exploratory Research for Advanced Technology [Grant JPMJER2301].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0350},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2261-2286},
  shortjournal = {Math. Oper. Res.},
  title        = {Envy-free division of multilayered cakes},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust online selection with uncertain offer acceptance. <em>MOOR</em>, <em>50</em>(3), 2226-2260. (<a href='https://doi.org/10.1287/moor.2023.0210'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online advertising has motivated interest in online selection problems. Displaying ads to the right users benefits both the platform (e.g., via pay-per-click) and the advertisers (by increasing their reach). In practice, not all users click on displayed ads, while the platform’s algorithm may miss the users most disposed to do so. This mismatch decreases the platform’s revenue and the advertiser’s chances to reach the right customers. With this motivation, we propose a secretary problem where a candidate may or may not accept an offer according to a known probability p . Because we do not know the top candidate willing to accept an offer, the goal is to maximize a robust objective defined as the minimum over integers k of the probability of choosing one of the top k candidates, given that one of these candidates will accept an offer. Using Markov decision process theory, we derive a linear program for this max-min objective whose solution encodes an optimal policy. The derivation may be of independent interest, as it is generalizable and can be used to obtain linear programs for many online selection models. We further relax this linear program into an infinite counterpart, which we use to provide bounds for the objective and closed-form policies. For p ≥ p * ≈ 0.6 , an optimal policy is a simple threshold rule that observes the first p 1 / ( 1 − p ) fraction of candidates and subsequently makes offers to the best candidate observed so far. Funding: Financial support from the U.S. National Science Foundation [Grants CCF-2106444, CCF-1910423, and CMMI 1552479] is gratefully acknowledged.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0210},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2226-2260},
  shortjournal = {Math. Oper. Res.},
  title        = {Robust online selection with uncertain offer acceptance},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The core of housing markets from an agent’s perspective: Is it worth sprucing up your home?. <em>MOOR</em>, <em>50</em>(3), 2199-2225. (<a href='https://doi.org/10.1287/moor.2023.0092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study housing markets as introduced by Shapley and Scarf. We investigate the computational complexity of various questions regarding the situation of an agent a in a housing market H : we show that it is NP -hard to find an allocation in the core of H in which (i) a receives a certain house, (ii) a does not receive a certain house, or (iii) a receives a house other than a ’s own. We prove that the core of housing markets respects improvement in the following sense: given an allocation in the core of H in which agent a receives a house h , if the value of the house owned by a increases, then the resulting housing market admits an allocation in its core in which a receives either h or a house that a prefers to h ; moreover, such an allocation can be found efficiently. We further show an analogous result in the S table R oommates setting by proving that stable matchings in a one-sided market also respect improvement. Funding: This work was supported by the Hungarian Scientific Research Fund [Grants K124171, K128611]. I. Schlotter is supported by the Hungarian Academy of Sciences under its Momentum Programme (LP2021-2) and its János Bolyai Research Scholarship. The research reported in this paper and carried out by T. Fleiner at the Budapest University of Technology and Economics was supported by the “TKP2020, National Challenges Program” of the National Research Development and Innovation Office [BME NC TKP2020 and OTKA K143858] and by the Higher Education Excellence Program of the Ministry of Human Capacities in the frame of the Artificial Intelligence research area of the Budapest University of Technology and Economics (BME FIKP-MI/SC). P. Biró gratefully acknowledges financial support from the Hungarian Scientific Research Fund, OTKA [Grant K143858] and the Hungarian Academy of Sciences [Momentum Grant LP2021-2].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0092},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2199-2225},
  shortjournal = {Math. Oper. Res.},
  title        = {The core of housing markets from an agent’s perspective: Is it worth sprucing up your home?},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of a class of minimization problems lacking lower semicontinuity. <em>MOOR</em>, <em>50</em>(3), 2175-2198. (<a href='https://doi.org/10.1287/moor.2023.0295'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimization of nonlower semicontinuous functions is a difficult topic that has been minimally studied. Among such functions is a Heaviside composite function that is the composition of a Heaviside function with a possibly nonsmooth multivariate function. Unifying a statistical estimation problem with hierarchical selection of variables and a sample average approximation of composite chance constrained stochastic programs, a Heaviside composite optimization problem is one whose objective and constraints are defined by sums of possibly nonlinear multiples of such composite functions. Via a pulled-out formulation, a pseudostationarity concept for a feasible point was introduced in an earlier work as a necessary condition for a local minimizer of a Heaviside composite optimization problem. The present paper extends this previous study in several directions: (a) showing that pseudostationarity is implied by (and thus, weaker than) a sharper subdifferential-based stationarity condition that we term epistationarity; (b) introducing a set-theoretic sufficient condition, which we term a local convexity-like property, under which an epistationary point of a possibly nonlower semicontinuous optimization problem is a local minimizer; (c) providing several classes of Heaviside composite functions satisfying this local convexity-like property; (d) extending the epigraphical formulation of a nonnegative multiple of a Heaviside composite function to a lifted formulation for arbitrarily signed multiples of the Heaviside composite function, based on which we show that an epistationary solution of the given Heaviside composite program with broad classes of B-differentiable component functions can in principle be approximately computed by surrogation methods. Funding: The work of Y. Cui was based on research supported by the National Science Foundation [Grants CCF-2153352, DMS-2309729, and CCF-2416172] and the National Institutes of Health [Grant 1R01CA287413-01]. The work of J.-S. Pang was based on research supported by the Air Force Office of Scientific Research [Grant FA9550-22-1-0045].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0295},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2175-2198},
  shortjournal = {Math. Oper. Res.},
  title        = {Analysis of a class of minimization problems lacking lower semicontinuity},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correlated equilibria in large anonymous bayesian games. <em>MOOR</em>, <em>50</em>(3), 2157-2174. (<a href='https://doi.org/10.1287/moor.2023.0278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider multipopulation Bayesian games with a large number of players. Each player aims at minimizing a cost function that depends on this player’s own action, the distribution of players’ actions in all populations, and an unknown state parameter. We study the nonatomic limit versions of these games and introduce the concept of Bayes correlated Wardrop equilibrium, which extends the concept of Bayes correlated equilibrium to nonatomic games. We prove that Bayes correlated Wardrop equilibria are limits of action flows induced by Bayes correlated equilibria of the game with a large finite set of small players. For nonatomic games with complete information admitting a convex potential, we prove that the set of correlated and of coarse correlated Wardrop equilibria coincide with the set of probability distributions over Wardrop equilibria and that all equilibrium outcomes have the same costs. We get the following consequences. First, all flow distributions of (coarse) correlated equilibria in convex potential games with finitely many players converge to mixtures of Wardrop equilibria when the weight of each player tends to zero. Second, for any sequence of flows satisfying a no-regret property, its empirical distribution converges to the set of distributions over Wardrop equilibria, and the average cost converges to the unique Wardrop cost. Funding: This work was partially supported by European Cooperation in Science and Technology Action 16228 GAMENET. F. Koessler acknowledges the support of the Agence Nationale de la Recherche [Grant StratCom ANR-19-CE26-0010-01]. M. Scarsini acknowledges the support of the Gruppo Nazionale per l’Analisi Matematica, la Probabilità e le loro Applicazioni project [Grant CUP_E53C22001930001], the Ministero dell’Università e della Ricerca Progetti di Rilevante Interesse Nazionale [Grant 2022EKNE5K], and the European Union-Next Generation EU, component M4C2, investment 1.1 (Ministero dell’Università e della Ricerca Progetti di Rilevante Interesse Nazionale Piano Nazionale di Ripresa e Resilienza) [Grant P2022XT8C8]. T. Tomala gratefully acknowledges the support of the HEC foundation and Agence Nationale de la Recherche/Investissements d’Avenir [Grant ANR-11-IDEX-0003/Labex Ecodec/ANR-11-LABX-0047].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0278},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2157-2174},
  shortjournal = {Math. Oper. Res.},
  title        = {Correlated equilibria in large anonymous bayesian games},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse integer programming is fixed-parameter tractable. <em>MOOR</em>, <em>50</em>(3), 2141-2156. (<a href='https://doi.org/10.1287/moor.2023.0162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the general integer programming problem where the number of variables n is a variable part of the input. We consider two natural parameters of the constraint matrix A : its numeric measure a and its sparsity measure d . We present an algorithm for solving integer programming in time g ( a , d ) poly ( n , L ) , where g is some computable function of the parameters a and d , and L is the binary encoding length of the input. In particular, integer programming is fixed-parameter tractable parameterized by a and d , and is solvable in polynomial time for every fixed a and d . Our results also extend to nonlinear separable convex objective functions. Funding: F. Eisenbrand, C. Hunkenschröder, and K.-M. Klein were supported by the Swiss National Science Foundation (SNSF) within the project “Convexity, geometry of numbers, and the complexity of integer programming” [Grant 163071]. A. Levin and S. Onn are partially supported by the Israel Science Foundation [Grant 308/18]. A. Levin is also partially supported by the Israel Science Foundation [Grant 1467/22]. S. Onn is also partially supported by the Dresner Chair at the Technion. M. Koutecký is partially supported by Charles University project UNCE 24/SCI/008, and by the project 22-22997S of the Grantová Agentura České Republiky (GA ČR).},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0162},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2141-2156},
  shortjournal = {Math. Oper. Res.},
  title        = {Sparse integer programming is fixed-parameter tractable},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On a network centrality maximization game. <em>MOOR</em>, <em>50</em>(3), 2112-2140. (<a href='https://doi.org/10.1287/moor.2022.0251'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a network formation game where n players, identified with the nodes of a directed graph to be formed, choose where to wire their outgoing links in order to maximize their PageRank centrality. Specifically, the action of every player i consists in the wiring of a predetermined number d i of directed out-links, and her utility is her own PageRank centrality in the network resulting from the actions of all players. We show that this is a potential game and that the best response correspondence always exhibits a local structure in that it is never convenient for a node i to link to other nodes that are at incoming distance more than d i from her. We then study the equilibria of this game determining necessary conditions for a graph to be a (strict, recurrent) Nash equilibrium. Moreover, in the homogeneous case, where players all have the same number d of out-links, we characterize the structure of the potential-maximizing equilibria, and in the special cases d = 1 and d = 2, we provide a complete classification of the set of (strict, recurrent) Nash equilibria. Our analysis shows in particular that the considered formation mechanism leads to the emergence of undirected and disconnected or loosely connected networks. Funding: This research was carried out within the framework of the Ministero dell’Università e della Ricerca (MIUR)-funded Progetto di Eccellenza of the Dipartimento di Scienze Matematiche G. L. Lagrange, Politecnico di Torino [CUP: E11G18000350001]. It received partial support from the MIUR-funded project PRIN 2017 “Advanced Network Control of Future Smart Grids” and from the Compagnia di San Paolo.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0251},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2112-2140},
  shortjournal = {Math. Oper. Res.},
  title        = {On a network centrality maximization game},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal ratcheting of dividends with capital injection. <em>MOOR</em>, <em>50</em>(3), 2073-2111. (<a href='https://doi.org/10.1287/moor.2023.0102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the optimal dividend problem with capital injection and ratcheting constraint with nondecreasing dividend payout rate. Capital injections are introduced in order to eliminate the possibility of bankruptcy. Under the Cramér–Lundberg risk model, the problem is formulated as a two-dimensional stochastic control problem. By applying the viscosity theory, we show that the value function is the unique viscosity solution to the associated Hamilton–Jacobi–Bellman equation. In order to obtain analytical results, we further study the problem with finite ratcheting constraint, where the dividend rate takes only a finite number of available values. We show that the value function under general ratcheting can be approximated arbitrarily closely by the one with finite ratcheting. Finally, we derive the expressions of value function when the threshold-type finite ratcheting dividend strategy with capital injection is applied, and we show the optimality of such a strategy under certain conditions of concavity. Numerical examples under various scenarios are provided at the end. Funding W. Wang was supported by the National Natural Science Foundation of China [Grants 12171405, 12271066, and 11661074] and the Fundamental Research Funds for the Central Universities of China [Grant 20720220044]. R. Xu was supported by the National Natural Science Foundation of China [Grants 12201506 and 12371468], the Natural Science Foundation of the Jiangsu Higher Education Institutions of China [Grant 21KJB110024], and Xi’an Jiaotong-Liverpool University Research Development Funding [Grant RDF-20-01-02].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0102},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2073-2111},
  shortjournal = {Math. Oper. Res.},
  title        = {Optimal ratcheting of dividends with capital injection},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the set of balanced games. <em>MOOR</em>, <em>50</em>(3), 2047-2072. (<a href='https://doi.org/10.1287/moor.2023.0379'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the geometric structure of the set of cooperative transferable utility games having a nonempty core, characterized by Bondareva and Shapley as balanced games. We show that this set is a nonpointed polyhedral cone, and we find the set of its extremal rays and facets. This study is also done for the set of balanced games whose value for the grand coalition is fixed, which yields an affine nonpointed polyhedral cone. Finally, the case of nonnegative balanced games with fixed value for the grand coalition is tackled. This set is a convex polytope, with remarkable properties. We characterize its vertices and facets, study the adjacency structure of vertices, develop an algorithm for generating vertices in a random uniform way, and show that this polytope is combinatorial and its adjacency graph is Hamiltonian. Last, we give a characterization of the set of games having a core reduced to a singleton. Funding: This work was supported by the Spanish Government [Grant PID2021-124933NB-I00].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0379},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2047-2072},
  shortjournal = {Math. Oper. Res.},
  title        = {On the set of balanced games},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parabolic regularity of spectral functions. <em>MOOR</em>, <em>50</em>(3), 2017-2046. (<a href='https://doi.org/10.1287/moor.2023.0010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to the study of the second-order variational analysis of spectral functions. It is well-known that spectral functions can be expressed as a composite function of symmetric functions and eigenvalue functions. We establish several second-order properties of spectral functions when their associated symmetric functions enjoy these properties. Our main attention is given to characterize parabolic regularity for this class of functions. It was observed recently that parabolic regularity can play a central rule in ensuring the validity of important second-order variational properties, such as twice epi-differentiability. We demonstrates that for convex spectral functions, their parabolic regularity amounts to that of their symmetric functions. As an important consequence, we calculate the second subderivative of convex spectral functions, which allows us to establish second-order optimality conditions for a class of matrix optimization problems. Funding: The research of A. Mohammadi is funded by a postdoctoral fellowship from Georgetown University. E. Sarabi is partially supported by the U.S. National Science Foundation [Grant DMS 2108546].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0010},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2017-2046},
  shortjournal = {Math. Oper. Res.},
  title        = {Parabolic regularity of spectral functions},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compact extended formulations for low-rank functions with indicator variables. <em>MOOR</em>, <em>50</em>(3), 1992-2016. (<a href='https://doi.org/10.1287/moor.2021.0281'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the mixed-integer epigraph of a special class of convex functions with nonconvex indicator constraints, which are often used to impose logical constraints on the support of the solutions. The class of functions we consider are defined as compositions of low-dimensional nonlinear functions with affine functions. Extended formulations describing the convex hull of such sets can easily be constructed via disjunctive programming although a direct application of this method often yields prohibitively large formulations, whose size is exponential in the number of variables. In this paper, we propose a new disjunctive representation of the sets under study, which leads to compact formulations with size exponential in the dimension of the nonlinear function but polynomial in the number of variables. Moreover, we show how to project out the additional variables for the case of dimension one, recovering or generalizing known results for the convex hulls of such sets (in the original space of variables). Our computational results indicate that the proposed approach can significantly improve the performance of solvers in structured problems. Funding: This work was supported by the National Science Foundation Division of Computing and Communication Foundations [Grant 2006762].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0281},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1992-2016},
  shortjournal = {Math. Oper. Res.},
  title        = {Compact extended formulations for low-rank functions with indicator variables},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information design and sharing in supply chains. <em>MOOR</em>, <em>50</em>(3), 1965-1991. (<a href='https://doi.org/10.1287/moor.2023.0008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the interplay between inventory replenishment policies and information sharing in the context of a two-tier supply chain with a single supplier and a single retailer serving an independent and identically distributed Gaussian market demand. We investigate how the retailer’s inventory policy impacts the supply chain’s cumulative expected long-term average inventory costs C in two extreme information-sharing cases: (a) full information sharing and (b) no information sharing. To find the retailer’s inventory policy that minimizes C , we formulate an infinite-dimensional optimization problem whose decision variables are the MA( ∞ ) coefficients that characterize a stationary ordering policy. Under full information sharing, the optimization problem admits a simple solution and the optimal policy is given by an MA(1) process. On the other hand, to solve the optimization problem under no information sharing, we reformulate the optimization from its time domain formulation to an equivalent z -transform formulation in which the decision variables correspond to elements of the Hardy space H 2 . This alternative representation allows us to use a number of results from H 2 theory to compute the optimal value of C and characterize a sequence of ϵ -optimal inventory policies under some mild technical conditions. By comparing the optimal solution under full information sharing and no information sharing, we derive a number of important practical takeaways. For instance, we show that there is value in information sharing if and only if the retailer’s optimal policy under full information sharing is not invertible with respect to the sequence of demand shocks. Furthermore, we derive a fundamental mathematical identity that reveals the value of information sharing by exploiting the canonical Smirnov–Beurling inner–outer factorization of the retailer’s orders when viewed as an element of H 2 . We also show that the value of information sharing can grow unboundedly when the cumulative supply chain costs are dominated by the supplier’s inventory costs. Funding: R. Caldentey acknowledges the University of Chicago Booth School of Business for financial support. Supplemental Material: The online appendix is available at https://doi.org/10.1287/moor.2023.0008 .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0008},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1965-1991},
  shortjournal = {Math. Oper. Res.},
  title        = {Information design and sharing in supply chains},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty propagation and dynamic robust risk measures. <em>MOOR</em>, <em>50</em>(3), 1939-1964. (<a href='https://doi.org/10.1287/moor.2023.0267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a framework for quantifying propagation of uncertainty arising in a dynamic setting. Specifically, we define dynamic uncertainty sets designed explicitly for discrete stochastic processes over a finite time horizon. These dynamic uncertainty sets capture the uncertainty surrounding stochastic processes and models, accounting for factors such as distributional ambiguity. Examples of uncertainty sets include those induced by the Wasserstein distance and f -divergences. We further define dynamic robust risk measures as the supremum of all candidates’ risks within the uncertainty set. In an axiomatic way, we discuss conditions on the uncertainty sets that lead to well-known properties of dynamic robust risk measures, such as convexity and coherence. Furthermore, we discuss the necessary and sufficient properties of dynamic uncertainty sets that lead to time-consistencies of dynamic robust risk measures. We find that uncertainty sets stemming from f -divergences lead to strong time-consistency whereas the Wasserstein distance results in a new time-consistent notion of weak recursiveness. Moreover, we show that a dynamic robust risk measure is strong time-consistent or weak recursive if and only if it admits a recursive representation of one-step conditional robust risk measures arising from static uncertainty sets. Funding: M. Mailhot and S. M. Pesenti acknowledge support from the Canadian Statistical Sciences Institute (CANSSI) and from the Natural Sciences and Engineering Research Council of Canada [Grants RGPIN-2015-05447, DGECR-2020-00333, and RGPIN-2020-04289]. M. R. Moresco thanks the Horizon Postdoctoral Fellowship for the support.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0267},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1939-1964},
  shortjournal = {Math. Oper. Res.},
  title        = {Uncertainty propagation and dynamic robust risk measures},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Erratum to: Linear convergence of dual coordinate descent on nonpolyhedral convex problems. <em>MOOR</em>, <em>50</em>(3), 1935-1938. (<a href='https://doi.org/10.1287/moor.2024.0500'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our proof of linear convergence for Dykstra’s algorithm was erroneous, and in fact, there even exists a counterexample showing that the result is false.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2024.0500},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1935-1938},
  shortjournal = {Math. Oper. Res.},
  title        = {Erratum to: Linear convergence of dual coordinate descent on nonpolyhedral convex problems},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fair shares: Feasibility, domination, and incentives. <em>MOOR</em>, <em>50</em>(3), 1901-1934. (<a href='https://doi.org/10.1287/moor.2022.0257'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider fair allocation of indivisible goods to n equally entitled agents. Every agent i has a valuation function v i from some given class of valuation functions. A share s is a function that maps ( v i , n ) to a nonnegative value. A share is feasible if for every allocation instance, there is an allocation that gives every agent i a bundle that is acceptable with respect to v i , one of value at least her share value s ( v i , n ) . We introduce the following concepts. A share is self-maximizing if reporting the true valuation maximizes the minimum true value of a bundle that is acceptable with respect to the report. A share s ρ-dominates another share s ′ if s ( v i , n ) ≥ ρ · s ′ ( v i , n ) for every valuation function. We initiate a systematic study of feasible and self-maximizing shares and a systematic study of ρ -domination relation between shares, presenting both positive and negative results. Funding: The research of M. Babaioff is supported in part by a Golda Meir Fellowship. The research of U. Feige is supported in part by the Israel Science Foundation [Grant 1122/22].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0257},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1901-1934},
  shortjournal = {Math. Oper. Res.},
  title        = {Fair shares: Feasibility, domination, and incentives},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An augmented lagrangian approach to conically constrained nonmonotone variational inequality problems. <em>MOOR</em>, <em>50</em>(3), 1868-1900. (<a href='https://doi.org/10.1287/moor.2023.0167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider a nonmonotone (mixed) variational inequality (VI) model with (nonlinear) convex conic constraints. Through developing an equivalent Lagrangian function-like primal-dual saddle point system for the VI model in question, we introduce an augmented Lagrangian primal-dual method, called ALAVI (Augmented Lagrangian Approach to Variational Inequality) in the paper, for solving a general constrained VI model. Under an assumption, called the primal-dual variational coherence condition in the paper, we prove the convergence of ALAVI. Next, we show that many existing generalized monotonicity properties are sufficient—though by no means necessary—to imply the abovementioned coherence condition and thus are sufficient to ensure convergence of ALAVI. Under that assumption, we further show that ALAVI has in fact an o ( 1 / k ) global rate of convergence where k is the iteration count. By introducing a new gap function, this rate further improves to be O ( 1 / k ) if the mapping is monotone. Finally, we show that under a metric subregularity condition, even if the VI model may be nonmonotone, the local convergence rate of ALAVI improves to be linear. Numerical experiments on some randomly generated highly nonlinear and nonmonotone VI problems show the practical efficacy of the newly proposed method. Funding: L. Zhao and D. Zhu were partially supported by the Major Project of the National Natural Science Foundation of China [Grant 72293582], the National Key R&D Program of China [Grant 2023YFA0915202], and the Fundamental Research Funds for the Central Universities (the Interdisciplinary Program of Shanghai Jiao Tong University) [Grant YG2024QNA36]. L. Zhao was partially supported by the Startup Fund for Young Faculty at SJTU (SFYF at SJTU) [Grant 22X010503839].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0167},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1868-1900},
  shortjournal = {Math. Oper. Res.},
  title        = {An augmented lagrangian approach to conically constrained nonmonotone variational inequality problems},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonzero-sum optimal stopping game with continuous vs. periodic exercise opportunities. <em>MOOR</em>, <em>50</em>(3), 1832-1867. (<a href='https://doi.org/10.1287/moor.2023.0123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new nonzero-sum game of optimal stopping with asymmetric exercise opportunities. Given a stochastic process modeling the value of an asset, one player observes and can act on the process continuously, whereas the other player can act on it only periodically at independent Poisson arrival times. The first one to stop receives a reward, different for each player, whereas the other one gets nothing. We study how each player balances the maximization of gains against the maximization of the likelihood of stopping before the opponent. In such a setup driven by a Lévy process with positive jumps, we not only prove the existence but also explicitly construct a Nash equilibrium with values of the game written in terms of the scale function. Numerical illustrations with put-option payoffs are also provided to study the behavior of the players’ strategies as well as the quantification of the value of available exercise opportunities. Funding: K. Yamazaki was partly supported by The Japan Society for the Promotion of Science (JSPS) Grant-in-Aid for Scientific Research (KAKENHI) [Grants 19H01791, 20K03758, and 24K06844], Open Partnership Joint Research Projects [Grant JPJSBP120209921], and the University of Queensland [start-up grant].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0123},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1832-1867},
  shortjournal = {Math. Oper. Res.},
  title        = {Nonzero-sum optimal stopping game with continuous vs. periodic exercise opportunities},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploration noise for learning linear-quadratic mean field games. <em>MOOR</em>, <em>50</em>(3), 1762-1831. (<a href='https://doi.org/10.1287/moor.2021.0157'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of this paper is to demonstrate that common noise may serve as an exploration noise for learning the solution of a mean field game. This concept is here exemplified through a toy linear-quadratic model, for which a suitable form of common noise has already been proven to restore existence and uniqueness. We here go one step further and prove that the same form of common noise may force the convergence of the learning algorithm called fictitious play, and this without any further potential or monotone structure. Several numerical examples are provided to support our theoretical analysis. Funding: F. Delarue acknowledges the financial support of the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme [AdG ELISA project, Grant 101054746]. A. Vasileiadis acknowledge the financial support of French ANR project ANR-19-P3IA-0002-3IA Côte d'Azur-Nice-Interdisciplinary Institute for Artificial Intelligence.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0157},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1762-1831},
  shortjournal = {Math. Oper. Res.},
  title        = {Exploration noise for learning linear-quadratic mean field games},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A moment-sum-of-squares hierarchy for robust polynomial matrix inequality optimization with sum-of-squares convexity. <em>MOOR</em>, <em>50</em>(3), 1734-1761. (<a href='https://doi.org/10.1287/moor.2023.0361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a class of polynomial optimization problems with a robust polynomial matrix inequality (PMI) constraint where the uncertainty set itself is also defined by a PMI. These can be viewed as matrix generalizations of semi-infinite polynomial programs because they involve actually infinitely many PMI constraints in general. Under certain sum-of-squares (SOS)-convexity assumptions, we construct a hierarchy of increasingly tight moment-SOS relaxations for solving such problems. Most of the nice features of the moment-SOS hierarchy for the usual polynomial optimization are extended to this more complicated setting. In particular, asymptotic convergence of the hierarchy is guaranteed, and finite convergence can be certified if some flat extension condition holds true. To extract global minimizers, we provide a linear algebra procedure for recovering a finitely atomic matrix-valued measure from truncated matrix-valued moments. As an application, we are able to solve the problem of minimizing the smallest eigenvalue of a polynomial matrix subject to a PMI constraint. If SOS convexity is replaced by convexity, we can still approximate the optimal value as closely as desired by solving a sequence of semidefinite programs and certify global optimality in case that certain flat extension conditions hold true. Finally, an extension to the nonconvexity setting is provided under a rank 1 condition. To obtain the above-mentioned results, techniques from real algebraic geometry, matrix-valued measure theory, and convex optimization are employed. Funding: This work was supported by the National Key Research and Development Program of China [Grant 2023YFA1009401] and the National Natural Science Foundation of China [Grants 11571350 and 12201618].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0361},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1734-1761},
  shortjournal = {Math. Oper. Res.},
  title        = {A moment-sum-of-squares hierarchy for robust polynomial matrix inequality optimization with sum-of-squares convexity},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Risk-averse markov decision processes through a distributional lens. <em>MOOR</em>, <em>50</em>(3), 1707-1733. (<a href='https://doi.org/10.1287/moor.2023.0211'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By adopting a distributional viewpoint on law-invariant convex risk measures, we construct dynamic risk measures (DRMs) at the distributional level. We then apply these DRMs to investigate Markov decision processes, incorporating latent costs, random actions, and weakly continuous transition kernels. Furthermore, the proposed DRMs allow risk aversion to change dynamically. Under mild assumptions, we derive a dynamic programming principle and show the existence of an optimal policy in both finite and infinite time horizons. Moreover, we provide a sufficient condition for the optimality of deterministic actions. For illustration, we conclude the paper with examples from optimal liquidation with limit order books and autonomous driving. Funding: This work was supported by Natural Sciences and Engineering Research Council of Canada [Grants RGPAS-2018-522715 and RGPIN-2018-05705].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0211},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1707-1733},
  shortjournal = {Math. Oper. Res.},
  title        = {Risk-averse markov decision processes through a distributional lens},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the convex formulations of robust markov decision processes. <em>MOOR</em>, <em>50</em>(3), 1681-1706. (<a href='https://doi.org/10.1287/moor.2022.0284'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust Markov decision processes (MDPs) are used for applications of dynamic optimization in uncertain environments and have been studied extensively. Many of the main properties and algorithms of MDPs, such as value iteration and policy iteration, extend directly to RMDPs. Surprisingly, there is no known analog of the MDP convex optimization formulation for solving RMDPs. This work describes the first convex optimization formulation of RMDPs under the classical sa-rectangularity and s-rectangularity assumptions. By using entropic regularization and exponential change of variables, we derive a convex formulation with a number of variables and constraints polynomial in the number of states and actions, but with large coefficients in the constraints. We further simplify the formulation for RMDPs with polyhedral, ellipsoidal, or entropy-based uncertainty sets, showing that, in these cases, RMDPs can be reformulated as conic programs based on exponential cones, quadratic cones, and nonnegative orthants. Our work opens a new research direction for RMDPs and can serve as a first step toward obtaining a tractable convex formulation of RMDPs. Funding: The work in the paper was supported, in part, by NSF [Grants 2144601 and 1815275]; and Agence Nationale de la Recherche [Grant 11-LABX-0047].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0284},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1681-1706},
  shortjournal = {Math. Oper. Res.},
  title        = {On the convex formulations of robust markov decision processes},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimality conditions in control problems with random state constraints in probabilistic or almost sure form. <em>MOOR</em>, <em>50</em>(3), 1654-1680. (<a href='https://doi.org/10.1287/moor.2023.0177'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we discuss optimality conditions for optimization problems involving random state constraints, which are modeled in probabilistic or almost sure form. Although the latter can be understood as the limiting case of the former, the derivation of optimality conditions requires substantially different approaches. We apply them to a linear elliptic partial differential equation with random inputs. In the probabilistic case, we rely on the spherical-radial decomposition of Gaussian random vectors in order to formulate fully explicit optimality conditions involving a spherical integral. In the almost sure case, we derive optimality conditions and compare them with a model based on robust constraints with respect to the (compact) support of the given distribution. Funding: The authors thank the Deutsche Forschungsgemeinschaft [Projects B02 and B04 in the “Sonderforschungsbereich/Transregio 154 Mathematical Modelling, Simulation and Optimization Using the Example of Gas Networks”] for support. C. Geiersbach acknowledges support from the Deutsche Forschungsgemeinschaft [Germany’s Excellence Strategy–the Berlin Mathematics Research Center MATH+ Grant EXC-2046/1, Project 390685689]. R. Henrion acknowledges support from the Fondation Mathématique Jacques Hadamard [Program Gaspard Monge in Optimization and Operations Research, including support to this program by Electricité de France].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0177},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1654-1680},
  shortjournal = {Math. Oper. Res.},
  title        = {Optimality conditions in control problems with random state constraints in probabilistic or almost sure form},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Order independence in sequential, issue-by-issue voting. <em>MOOR</em>, <em>50</em>(3), 1635-1653. (<a href='https://doi.org/10.1287/moor.2022.0342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study when the voting outcome is independent of the order of issues put up for vote in a spatial multidimensional voting model. Agents equipped with norm-based preferences that use a norm to measure the distance from their ideal policy vote sequentially and issue by issue via simple majority. If the underlying norm is generated by an inner product—such as the Euclidean norm—then the voting outcome is order independent if and only if the issues are orthogonal. If the underlying norm is a general one, then the outcome is order independent if the basis defining the issues to be voted upon satisfies the following property; for any vector in the basis, any linear combination of the other vectors is Birkhoff–James orthogonal to it. We prove a partial converse in the case of two dimensions; if the underlying basis fails this property, then the voting order matters. Finally, despite existence results for the two-dimensional case and for the general l p case, we show that nonexistence of bases with this property is generic. Funding: The research of A. Gershkov is supported by the Israel Science Foundation [Grant 1118/22]. The research of B. Moldovanu is supported by the German Science Foundation through the Hausdorff Center for Mathematics and The Collaborative Research Center Transregio 224. The research of X. Shi is supported by the Social Sciences and Humanities Research Council of Canada.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0342},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1635-1653},
  shortjournal = {Math. Oper. Res.},
  title        = {Order independence in sequential, issue-by-issue voting},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large independent sets in recursive markov random graphs. <em>MOOR</em>, <em>50</em>(3), 1611-1634. (<a href='https://doi.org/10.1287/moor.2022.0215'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing the maximum size of an independent set in a graph is a famously hard combinatorial problem that has been well studied for various classes of graphs. When it comes to random graphs, the classic Erdős–Rényi–Gilbert random graph G n , p has been analyzed and shown to have the largest independent sets of size Θ ( log n ) with high probability (w.h.p.) This classic model does not capture any dependency structure between edges that can appear in real-world networks. We define random graphs G n , p r whose existence of edges is determined by a Markov process that is also governed by a decay parameter r ∈ ( 0 , 1 ] . We prove that w.h.p. G n , p r has independent sets of size ( 1 − r 2 + ε ) n log n for arbitrary ε > 0 . This is derived using bounds on the terms of a harmonic series, a Turán bound on a stability number, and a concentration analysis for a certain sequence of dependent Bernoulli variables that may also be of independent interest. Because G n , p r collapses to G n , p when there is no decay, it follows that having even the slightest bit of dependency (any r < 1 ) in the random graph construction leads to the presence of large independent sets, and thus, our random model has a phase transition at its boundary value of r = 1. This implies that there are large matchings in the line graph of G n , p r , which is a Markov random field. For the maximal independent set output by a greedy algorithm, we deduce that it has a performance ratio of at most 1 + log n ( 1 − r ) w.h.p. when the lowest degree vertex is picked at each iteration and also show that, under any other permutation of vertices, the algorithm outputs a set of size Ω ( n 1 / 1 + τ ) , where τ = 1 / ( 1 − r ) and, hence, has a performance ratio of O ( n 1 2 − r ) . Funding: The initial phase of this research was supported by the National Science Foundation [Grant DMS-1913294].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0215},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1611-1634},
  shortjournal = {Math. Oper. Res.},
  title        = {Large independent sets in recursive markov random graphs},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rockafellian relaxation and stochastic optimization under perturbations. <em>MOOR</em>, <em>50</em>(3), 1585-1610. (<a href='https://doi.org/10.1287/moor.2022.0122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practice, optimization models are often prone to unavoidable inaccuracies because of dubious assumptions and corrupted data. Traditionally, this placed special emphasis on risk-based and robust formulations, and their focus on “conservative” decisions. We develop, in contrast, an “optimistic” framework based on Rockafellian relaxations in which optimization is conducted not only over the original decision space but also jointly with a choice of model perturbation. The framework enables us to address challenging problems with ambiguous probability distributions from the areas of two-stage stochastic optimization without relatively complete recourse, probability functions lacking continuity properties, expectation constraints, and outlier analysis. We are also able to circumvent the fundamental difficulty in stochastic optimization that convergence of distributions fails to guarantee convergence of expectations. The framework centers on the novel concepts of exact and limit-exact Rockafellians, with interpretations of “negative” regularization emerging in certain settings. We illustrate the role of Phi-divergence, examine rates of convergence under changing distributions, and explore extensions to first-order optimality conditions. The main development is free of assumptions about convexity, smoothness, and even continuity of objective functions. Numerical results in the setting of computer vision and text analytics with label noise illustrate the framework. Funding: This work was supported by the Air Force Office of Scientific Research (Mathematical Optimization Program) under the grant: “Optimal Decision Making under Tight Performance Requirements in Adversarial and Uncertain Environments: Insight from Rockafellian Functions.”},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0122},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1585-1610},
  shortjournal = {Math. Oper. Res.},
  title        = {Rockafellian relaxation and stochastic optimization under perturbations},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ms">MS - 45</h2>
<ul>
<li><details>
<summary>
(2025). Adaptive pricing in combinatorial auctions. <em>MS</em>, <em>71</em>(10), 8967-8993. (<a href='https://doi.org/10.1287/mnsc.2024.4993'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the first adaptively priced iterative combinatorial auction design, which gradually extends price expressiveness as the rounds progress. This mechanism achieves both high efficiency and fast convergence across a wide range of valuation domains. We implement our auction design using polynomial prices, show how to detect when the current price structure is insufficient to clear the market, and show how to correctly expand the polynomial structure to guarantee progress. An experimental evaluation confirms that our auction is competitive with bundle-price auctions in domains where these excel, namely multiminded valuations, but also performs well in domains favorable to linear prices, such as valuations with pairwise synergy. This paper was accepted by Axel Ockenfels, behavioral economics and decision analysis. Supplemental Material: The data files are available at https://doi.org/10.1287/mnsc.2024.4993 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2024.4993},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8967-8993},
  shortjournal = {Manag. Sci.},
  title        = {Adaptive pricing in combinatorial auctions},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exchanges for government bonds? evidence during COVID-19. <em>MS</em>, <em>71</em>(10), 8948-8966. (<a href='https://doi.org/10.1287/mnsc.2023.02344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We leverage the unique institutional feature that the Israeli government bond market operates on an exchange rather than over-the-counter to analyze whether and why having an exchange affects market liquidity during a crisis. We document how the liquidity crisis in March 2020 affected the Israeli government bond market and conduct difference-in-differences analyses, comparing bid-ask spreads in exchange markets, such as the Israeli government bond market, with markets lacking an exchange. Our findings support the idea that having an exchange enhances market liquidity. A counterfactual analysis using trade data from the Israeli exchange suggests that this is due to the ability of investors to readily provide liquidity to one another and the efficient netting of trade flows on an exchange. This paper was accepted by Lukas Schmid, finance. Supplemental Material: The online appendices and data files are available at https://doi.org/10.1287/mnsc.2023.02344 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2023.02344},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8948-8966},
  shortjournal = {Manag. Sci.},
  title        = {Exchanges for government bonds? evidence during COVID-19},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating mortgage renegotiation strategies: A data-driven framework for investors. <em>MS</em>, <em>71</em>(10), 8927-8947. (<a href='https://doi.org/10.1287/mnsc.2022.02672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper offers a novel framework to quantify the expected gains from renegotiating delinquent loans. The framework accounts for important trade-offs between concessions to borrowers, postdelinquency loan performance, and expected collateral values. The framework’s parameters are calibrated using data on renegotiated 30-year residential fixed-rate mortgages that went delinquent during the Great Recession. Our model-implied expected gains increase during the 2007–2009 period coinciding with an increase in the rate of loan renegotiation. Counterfactual analyses show that larger expected gains can be generated from employing principal forbearance and extensions of the term to maturity compared with principal write-downs and interest-rate reductions. On the other hand, principal write-downs can be a powerful tool when borrowers are deeply underwater. Our analyses illustrate how lenders or policymakers might deploy this framework when faced with another delinquency crisis. This paper was accepted by Tomasz Piskorski, finance. Funding: The author thanks the Fisher Center for Real Estate and Urban Economics at the University of California, Berkeley and the Center for Investors and Financial Markets at the University of Virginia for funding for this paper. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.02672 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2022.02672},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8927-8947},
  shortjournal = {Manag. Sci.},
  title        = {Evaluating mortgage renegotiation strategies: A data-driven framework for investors},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On greedy-like policies in online matching with reusable network resources and decaying rewards. <em>MS</em>, <em>71</em>(10), 8908-8926. (<a href='https://doi.org/10.1287/mnsc.2023.02588'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We build a unified modeling framework for classical online matching problems and emerging online matching problems with three additional practical features: reusable resources, network resources, and decaying rewards. For online matching problems in the unified framework, we provide a unified performance analysis tool for the greedy policy and its simple variants, which we refer to as greedy-like policies. We prove that greedy-like policies can achieve near-optimal performances for online matching problems in the unified framework, where the policy performance is measured by competitive ratios under adversarial environments. We then analyze several representative special classes of online matching problems, which incorporate additional realistic structural assumptions on top of the unified framework. Specifically, we consider online matching problems with each of the following three additional structures: (i) singleton resources with time-decaying rewards; (ii) network resources with accept/reject decisions; and (iii) network resources with interval-type bundles. We show that for these special classes of online matching problems, slight modifications to greedy-like policies can successfully utilize additional structural information to further enhance policy performances. This work may suggest that the greedy policy and its variants, despite its simplicity, can achieve reliable performances for a number of emerging online matching problems. This paper was accepted by J. George Shanthikumar, data science. Funding: The work of D. Simchi-Levi and F. Zhu is partially supported by the Massachusetts Institute of Technology Data Science Laboratory. Supplemental Material: The online appendix is available at https://doi.org/10.1287/mnsc.2023.02588 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2023.02588},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8908-8926},
  shortjournal = {Manag. Sci.},
  title        = {On greedy-like policies in online matching with reusable network resources and decaying rewards},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How do domestic and foreign firms respond to a reduction in competition from the public sector? evidence from vaccine markets in india. <em>MS</em>, <em>71</em>(10), 8884-8907. (<a href='https://doi.org/10.1287/mnsc.2024.06174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines how domestic and foreign firms in the private sector respond to a reduction in competition from the public sector. Our analysis exploits the sudden suspension of production licenses of vaccine-manufacturing public sector units (PSUs) in January 2008 in India, home to more than 1.2 billion people at that time. Although the suspension presented a window of opportunity for private sector firms, the opportunity was laden with high uncertainty. Despite this uncertainty, we find that the suspension was associated with revenue gains driven by new product introductions and that these gains persist even after the supply suspension revocation in February 2010. Importantly, unlike domestic firms, foreign firms gain little. We explore potential mechanisms and find evidence consistent with one of them being the major reason for the differing impact: Domestic firms better navigate the challenges arising from political pluralism, an institutional feature characterized by a lack of political alignment between national and subnational governments. In the presence of political alignment, domestic firms do not have a comparative advantage over foreign firms. Our evidence thus highlights that even an uncertain and transitory window of opportunity arising from a controversial reduction in competition from the public sector can lead to a fundamental market restructuring in ways that can diverge from the intended policy objective. In particular, domestic firms’ ability to manage political pluralism is a core mechanism explaining their comparative advantage over foreign firms in the wake of a national crisis. This paper was accepted by Alfonso Gambardella, business strategy. Funding: This work was supported by the National University of Singapore [Start-Up Research Grant A-0003843-00-00], the University of Minnesota [Summer Research Grant], and the Indian School of Business [Research Grant]. Supplemental Material: The online appendices and data files are available at https://doi.org/10.1287/mnsc.2024.06174 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2024.06174},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8884-8907},
  shortjournal = {Manag. Sci.},
  title        = {How do domestic and foreign firms respond to a reduction in competition from the public sector? evidence from vaccine markets in india},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Economics of social media fake accounts. <em>MS</em>, <em>71</em>(10), 8865-8883. (<a href='https://doi.org/10.1287/mnsc.2022.02616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Amid the rise of the influencer economy, fake social media accounts have become prevalent on many social media platforms. Yet the problem of fake accounts is still poorly understood, and so is the effectiveness of coping strategies. This research models the ecosystem of fake accounts in an influencer economy and obtains insights on fake account purchasing behaviors, the impact of antifake efforts, and the roles of various contextual factors. We show that as the antifake effort increases, the equilibrium may transition from a “pooling” equilibrium, where a low-quality influencer buys fake accounts to mimic a high-quality one, to a “costly separating” equilibrium, where a high-quality influencer may buy fake accounts to prevent mimicry from a low-quality influencer, and to a “naturally separating” equilibrium where low- and high-quality influencers are separated without buying fake accounts. We find that increasing antifake efforts and increasing social media literacy may sometimes result in more fake accounts. A purely profit-driven platform always prefers a pooling equilibrium with zero antifake effort. As a platform puts more weight on consumer welfare, it may exert a positive effort to induce a separating equilibrium, but the platform’s preferred antifake effort tends to be lower than that of consumers. We also find that the platform sometimes prefers a lower social media literacy and a lower fake account base price, whereas consumers prefer the opposite. In contrast, improving the antifake technology level can benefit both the platform and consumers. Our main insights are applicable to scenarios with more influencer types and repeated interactions. This paper was accepted by D. J. Wu, information systems. Supplemental Material: The online appendix is available at https://doi.org/10.1287/mnsc.2022.02616 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2022.02616},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8865-8883},
  shortjournal = {Manag. Sci.},
  title        = {Economics of social media fake accounts},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Platform competition and interoperability: The net fee model. <em>MS</em>, <em>71</em>(10), 8842-8864. (<a href='https://doi.org/10.1287/mnsc.2023.02810'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Is more competition the key to mitigating dominance by large tech platforms? Could regulation of such markets be a better alternative? We study the effects of competition and interoperability regulation in platform markets. To do so, we propose an approach of competition in net fees, which is well-suited to situations in which users pay additional charges, after joining, for on-platform interactions. Compared with existing approaches, the net fee model expands the tractable scope to allow variable total demand, platform asymmetry, and merger analysis. Regarding competition, we find that adding more platforms to the market may lead to the emergence of a dominant firm. In contrast, we find that interoperability can play a key role in reducing market dominance and lowering prices. Broadly speaking, our results favor policy interventions that assure the formidability of the competition that dominant platforms face. This paper was accepted by Joshua Gans, business strategy. Funding: L. Wu thanks the NET Institute ( www.netinst.org ) for financial support.},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2023.02810},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8842-8864},
  shortjournal = {Manag. Sci.},
  title        = {Platform competition and interoperability: The net fee model},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selling data to marketers. <em>MS</em>, <em>71</em>(10), 8823-8841. (<a href='https://doi.org/10.1287/mnsc.2023.01350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The supply and the demand for data analytics are growing rapidly. Recent years have seen a surge in the availability of massive consumer data and in the emergence of data sellers (e.g., brokers and intermediaries). Unlike standard products, the value of data analytics for marketers depends on how their business decisions can be enabled and improved. In this paper, we investigate how a monopoly seller can offer a menu of data-based service plans to screen heterogenous marketers that can decide whether to take an action (e.g., direct selling, targeting, lending) with uncertain value and privately known cost. We characterize how, and for which marketers, the provision of information may be distorted in the optimal design. We present conditions under which optimally supplied information can be socially excessive or insufficient. It is shown that selling data appends may yield double reversals in the optimal service plans, in comparison with those when the seller’s offerings serve as marketing lists (i.e., the action is infeasible under the marketers’ outside option). We articulate how these results are coherently driven by the same underlying mechanism regarding how the marginal value of information is endogenously derived from the improvement in the marketers’ decision making over their default action. We also examine how our results can be enriched in alternative settings on the production and the costs of information. This paper was accepted by Dmitri Kuksov, marketing.},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2023.01350},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8823-8841},
  shortjournal = {Manag. Sci.},
  title        = {Selling data to marketers},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The effect of on-the-job experience on base-rate neglect: Evidence from medical professionals. <em>MS</em>, <em>71</em>(10), 8807-8822. (<a href='https://doi.org/10.1287/mnsc.2024.05461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the effect of on-the-job experience on base-rate neglect, which is a common bias in assessing conditional probabilities. We do so by carrying out experiments with medical professionals, who are routinely exposed to conditional-probability problems in the form of diagnostic tests, and nonmedical professionals, who are not. As such, medical workers with more years of experience will have had more exposure to base-rate type problems than nonmedical workers with similar years of experience. We estimate the effect of on-the-job experience by comparing the answers of more or less experienced professionals in both the medical and nonmedical domains. Although the incidence of the bias is high for both groups and all levels of experience, we find that more experienced medical workers (a) have lower rates of perfect base-rate neglect (i.e., completely ignoring the base rates), (b) provide more accurate posterior estimates, and (c) adjust their estimates more in response to changes in the base rates. We observe no such difference for nonmedical workers. We conduct a number of robustness checks and consider possible mechanisms, such as education, job or survey attrition, selectivity into medical professions, and experience with false positives. Our results suggests that on-the-job experience mitigates, but does not eliminate, base-rate neglect. This paper was accepted by Lauren Cohen, finance. Funding: This work was supported by Lehigh University [FRG Grant]. Supplemental Material: The online appendices and data files are available at https://doi.org/10.1287/mnsc.2024.05461 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2024.05461},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8807-8822},
  shortjournal = {Manag. Sci.},
  title        = {The effect of on-the-job experience on base-rate neglect: Evidence from medical professionals},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CEO hometown preference in corporate environmental policies. <em>MS</em>, <em>71</em>(10), 8783-8806. (<a href='https://doi.org/10.1287/mnsc.2022.02560'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We exploit within-firm variations in plant-level toxic releases to examine the effect of managerial hometown preference on corporate environmental policies. We find that pollution levels are about 30% lower for plants located near chief executive officers’ (CEOs’) hometowns. This reduction is achieved through resource-intensive pollution control efforts, including source reduction and waste management activities. Analyses using CEO turnover provide causal inferences. Local residents benefit from CEO hometown pollution reduction as localities hosting more hometown plants experience improved environmental conditions and better residential health outcomes. On the other hand, some evidence suggests that CEOs’ hometown preference is related to agency frictions. Overall, our findings reveal the impact of CEOs’ personal motivations on corporate pollution dynamics and their consequential effects on the well-being of local communities. This paper was accepted by Ranjani Krishnan, accounting. Funding: Q. Xu gratefully acknowledges research support from the University of Illinois Urbana-Champaign. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.02560 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2022.02560},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8783-8806},
  shortjournal = {Manag. Sci.},
  title        = {CEO hometown preference in corporate environmental policies},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Source theory: A tractable and positive ambiguity theory. <em>MS</em>, <em>71</em>(10), 8767-8782. (<a href='https://doi.org/10.1287/mnsc.2023.03307'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces source theory, a new theory for decision under ambiguity (unknown probabilities). It shows how Savage’s subjective probabilities, with source-dependent nonlinear weighting functions, can model Ellsberg’s ambiguity. It can do so in Savage’s framework of state-contingent assets, permits nonexpected utility for risk, and avoids multistage complications. It is tractable, shows ambiguity attitudes through simple graphs, is empirically realistic, and can be used prescriptively. We provide a new tool to analyze weighting functions: pmatchers. They give Arrow–Pratt-like transformations but operate “within” rather than “outside” functions. We further show that ambiguity perception and inverse S probability weighting, seemingly unrelated concepts, are two sides of the same “insensitivity” coin. This paper was accepted by Manel Baucells, behavioral economics and decision analysis. Funding: H. Bleichrodt acknowledges financial support from the Spanish Ministry of Science, Innovation and Universities [Project PID2022-142356NB-I00 financed by Grant MICIU/AEI/10.13039/501100011033 and by FEDER] and from the Consellería de Innovación Universidades, Ciencia y Sociedad Digital de la Generalitat Valenciana [Grant Prometeo/2021/073]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/mnsc.2023.03307 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2023.03307},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8767-8782},
  shortjournal = {Manag. Sci.},
  title        = {Source theory: A tractable and positive ambiguity theory},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long lags and large returns: Experimental evidence from advertising to businesses. <em>MS</em>, <em>71</em>(10), 8750-8766. (<a href='https://doi.org/10.1287/mnsc.2023.02661'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using a multiyear experiment, we show that advertising to businesses can generate very different responses than has been observed for consumers. First, we estimate larger advertising returns than typically found for consumers: a return on ad spend of 12.0 (95% CI: 4.8–24.5). Second, we estimate longer lags between ad delivery and purchase: 1–5 months for first-time purchases and 5–12 months or longer for repeat purchases. Third, we find that existing business customers are responsible for most of the revenue lift from advertising, though this appears to be driven by existing business customers purchasing new parts. Additionally, our results demonstrate that geography-based switchback experiments that randomize the time between treatments can provide an effective means of estimating lagged effects. For this study we randomized the delivery of digital display ads for electronic components offered by a semiconductor manufacturer; nearly all electronic products require such components. This paper was accepted by Duncan Simester, marketing. Funding: M. Goic acknowledges partial funding by ANID Chile [Grants PIA AFB230002 and Fondecyt No. 1221711] and the Institute for Research in Market Imperfections and Public Policy (IS130002 ANID); K. Kalyanam acknowledges financial support from the co-operating company; and M. Thomas acknowledges financial support from National University of Singapore [Startup Grant A-0003320-01-00]. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2023.02661 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2023.02661},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8750-8766},
  shortjournal = {Manag. Sci.},
  title        = {Long lags and large returns: Experimental evidence from advertising to businesses},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A structural model of a firm’s operating cash flow with applications. <em>MS</em>, <em>71</em>(10), 8727-8749. (<a href='https://doi.org/10.1287/mnsc.2021.03790'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective management of a firm’s operating cash flow is essential for supporting growth, servicing debt, and maintaining overall financial health. Mismanagement of cash flows can result in severe liquidity challenges and even business failure. However, managing operating cash flow is complex because of its intricate, endogenous relationships with operational variables, like sales, operating costs, inventory, payables, and the impact of exogenous macroeconomic factors on a firm. In this paper, we present a structural model of operating cash flow that untangles this endogeneity, allows us to estimate causal relationships among these variables, and provides a valuable tool for evaluating cash flow management policies. Applying our model to quarterly financial data from S&P’s Compustat database spanning from 1990 to 2020 along with macroeconomic indicators, we provide empirical evidence of the endogenous nature of cash flow with other operational variables. We then showcase the practical value of our model by (i) identifying the characteristics of structural shocks and the new equilibria they induce within the system; (ii) offering a tool for evaluating alternative managerial actions or policy decisions to counteract these shocks; (iii) predicting the impacts of macroeconomic events, such as global recessions and fluctuations in economic sentiment, on firm performance; and (iv) demonstrating superior forecasting performance compared with traditional univariate models. In summary, our structural model of operating cash flow enhances our understanding of its dynamics, enabling better-informed decision making and more effective cash flow management in firms. This paper was accepted by David Simchi Levi, operations management. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2021.03790 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2021.03790},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8727-8749},
  shortjournal = {Manag. Sci.},
  title        = {A structural model of a firm’s operating cash flow with applications},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consumption commitments and housing dynamics. <em>MS</em>, <em>71</em>(10), 8670-8697. (<a href='https://doi.org/10.1287/mnsc.2022.01996'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using a measure of local long-run growth prospects, I uncover a novel link between economic fundamentals and house prices. Whereas excess housing returns are positively associated with economic growth prospects, housing valuations are negatively associated with shocks to growth prospects. I document an explanation in metro-area consumption: housing consumption is asymmetrically exposed to economic prospects in that it expands more quickly when prospects are strong than it contracts when prospects are poor. I explain these findings through the lens of an asset pricing model that focuses on a trade-off between nonseparable committed housing and nonhousing consumption. This paper was accepted by Lukas Schmid, finance. Supplemental Material: Data files are available at https://doi.org/10.1287/mnsc.2022.01996 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2022.01996},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8670-8697},
  shortjournal = {Manag. Sci.},
  title        = {Consumption commitments and housing dynamics},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Speed matters: Limited attention and supply chain information diffusion. <em>MS</em>, <em>71</em>(10), 8642-8669. (<a href='https://doi.org/10.1287/mnsc.2023.00291'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a measure of the speed of firm-level information diffusion, study how it is affected by limited attention, and examine its effect on real corporate decisions. Using local flu epidemics as exogenous attention shocks, we show that inattention from dual-covering analysts and cross-holding institutions reduces the speed of information diffusion from customer to supplier stock prices. We find that the speed of information diffusion along the supply chain affects the price feedback effect for corporate investment decisions and facilitates coordination between customers and suppliers. Our findings demonstrate that coattention from key market participants affects information efficiency and generates real economic outcomes. This paper was accepted by Camelia Kuhnen, finance. Funding: L. Cen acknowledges financial support from the Chinese University of Hong Kong and General Research Fund [Grant 14504920] from the Hong Kong Research Grants Council. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2023.00291 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2023.00291},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8642-8669},
  shortjournal = {Manag. Sci.},
  title        = {Speed matters: Limited attention and supply chain information diffusion},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Do institutional investors stabilize equity markets in crisis periods? evidence from COVID-19. <em>MS</em>, <em>71</em>(10), 8623-8641. (<a href='https://doi.org/10.1287/mnsc.2022.03411'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the COVID-19 stock market crash, U.S. stocks with higher institutional ownership (IO) performed worse than those with lower IO. By studying firm-level changes, we identify two mechanisms behind this effect: a sudden downscaling of institutional capital in the equity market and a collective attempt by institutions to reposition their equity portfolios toward more COVID-resilient stocks. The stock price effects of their “portfolio downscaling” trades quickly reversed in the market’s recovery phase, whereas those of their “portfolio repositioning” trades lingered. The institutional rush for firm resilience also caused price pressures, with retail investors providing liquidity to stocks sold by institutional investors, both during the crisis and afterward. Overall, our results indicate that when a tail risk is realized, institutional investors amplify price crashes. This paper was accepted by Lukas Schmid, finance. Funding: S. Glossner and P. Matos acknowledge financial support from the Richard A. Mayo Center for Asset Management at the Darden School of Business. S. Ramelli and A. F. Wagner acknowledge financial support from the University of Zurich Research Priority Program “Financial Market Regulation.” Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.03411 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2022.03411},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8623-8641},
  shortjournal = {Manag. Sci.},
  title        = {Do institutional investors stabilize equity markets in crisis periods? evidence from COVID-19},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trading volume manipulation and competition among centralized crypto exchanges. <em>MS</em>, <em>71</em>(10), 8604-8622. (<a href='https://doi.org/10.1287/mnsc.2021.02903'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How competition affects manipulation by firms of information about important attributes of their products and how such information manipulation impacts firms’ short-term and long-term performance are open empirical questions. We use a setting that is especially suitable for answering these questions—centralized crypto exchanges, on which information manipulation takes the form of inflated trading volume. We find that static and dynamic competition measures are positively associated with volume inflation, indicating that competition may lead to increased information manipulation. Exchanges that manipulate volume obtain short-run benefits but are punished in the long run, consistent with the trade-off between short-lived increases in rents and future losses because of damaged reputation. This paper was accepted by Agostino Capponi, finance. Funding: The authors thank the Israel Science Foundation [Grant 2225/21], the Coller School of Management Blockchain Research Institute, the Henry Crown Institute for Business Research in Israel, and the Cornell Fintech Initiative for financial support. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2021.02903 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2021.02903},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8604-8622},
  shortjournal = {Manag. Sci.},
  title        = {Trading volume manipulation and competition among centralized crypto exchanges},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining ad targeting techniques: Evidence from a field experiment in the auto industry. <em>MS</em>, <em>71</em>(10), 8586-8603. (<a href='https://doi.org/10.1287/mnsc.2023.02310'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retargeted advertising that tries to entice potential customers back to a website is widely used by advertisers and has often replaced more traditional forms of targeting, such as contextual targeting that tries to match ads to website content. However, existing research has not investigated the extent to which these different targeting techniques compete with or complement each other. To investigate this, we conduct a large-scale field experiment with an automobile manufacturer to investigate how retargeting meshes with more traditional techniques of contextual targeting online and in turn how that should affect ad content. We investigate this using three different measures of online advertising effectiveness: website visits, engagement, and soft conversions. We find that combining contextual targeting and retargeting is more effective for all three measures. However, to unleash this effectiveness, marketers have to pay attention to the ad content in their retargeted ads. We find that when combining retargeted advertising with contextual targeting, ads that prompt users to customize an offering are the most effective. Last, we provide empirical evidence for understanding the underlying mechanism associated with our findings and replicate those findings with a laboratory experiment. This paper was accepted by David Simchi-Levi, marketing. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2023.02310 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2023.02310},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8586-8603},
  shortjournal = {Manag. Sci.},
  title        = {Combining ad targeting techniques: Evidence from a field experiment in the auto industry},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The effects of MiFID II on voluntary disclosure. <em>MS</em>, <em>71</em>(10), 8565-8585. (<a href='https://doi.org/10.1287/mnsc.2023.00286'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine the effect of the Markets in Financial Instruments Directive (MiFID) II’s controversial unbundling provision on corporate voluntary disclosure. Although prior research has largely focused on changes in sell-side research post-MiFID II, changes in voluntary disclosure and their effects on the information environment are less known. We find that European Union (EU) firms significantly increased the propensity and frequency of management earnings guidance issuance after MiFID II enactment. This effect is more pronounced among firms experiencing a decline in the quantity of sell-side research or a reduction in the consumption and dissemination of analyst reports and is more muted among firms witnessing improvements in research quality. Furthermore, we find that post-MiFID earnings guidance by EU firms becomes more thorough and elicits stronger market reactions. Moreover, we demonstrate that the increased guidance effectively alleviates the negative liquidity effects of MiFID II. Collectively, we contribute to the ongoing debate on the efficacy of MiFID II’s unbundling provision by providing evidence that voluntary disclosure plays a key role in mitigating the unintended net negative consequences on the information environment following the regulation. This paper was accepted by Suraj Srinivasan, accounting. Funding: Financial support from the New York University Stern School of Business, Seoul National University, the Baruch College Zicklin School of Business, and George Washington University is gratefully acknowledged. C. Kim also received financial support from the Institute of Management Research of Seoul National University. Supplemental Material: The data files are available at https://doi.org/10.1287/mnsc.2023.00286 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2023.00286},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8565-8585},
  shortjournal = {Manag. Sci.},
  title        = {The effects of MiFID II on voluntary disclosure},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Auditing with a chance of whistleblowing. <em>MS</em>, <em>71</em>(10), 8549-8564. (<a href='https://doi.org/10.1287/mnsc.2024.04808'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the impact of promoting whistleblowing on audit quality and the efficiency of detecting misstatements. On the one hand, whistleblowing alerts the enforcer to the possibility of a misstatement and intensifies the regulatory effort, thereby incentivizing the auditor to improve audit quality. On the other hand, promoting whistleblowing reduces the enforcer’s investigative effort when there is no whistleblowing allegation, which in turn dampens the auditor’s incentive to enhance audit quality. We demonstrate that, under certain conditions, encouraging more whistleblowing can impair audit quality and reduce detection efficiency. We also examine the socially optimal whistleblowing program, and our analysis implies that the optimal whistleblowing intensity is increasing in investment cost and the quality of the whistleblower’s information. This paper was accepted by Ranjani Krishnan, accounting. Funding: C. Tang acknowledges financial support from the Hong Kong Research Grant Council [Project 16503921]. M. Ye thanks the Canadian Social Sciences and Humanities Research Council for funding support [Grant 435-2022-0093]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/mnsc.2024.04808 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2024.04808},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8549-8564},
  shortjournal = {Manag. Sci.},
  title        = {Auditing with a chance of whistleblowing},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Choose your battles wisely: The consequences of protesting government procurement contracts. <em>MS</em>, <em>71</em>(10), 8526-8548. (<a href='https://doi.org/10.1287/mnsc.2021.02055'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine the relationship between a firm’s successful protest of a government agency’s conduct or terms of a procurement contract and the amount of business the firm conducts with the government going forward. We find firms receive fewer and less valuable government contracts, face more contract cancellations, and experience significant reductions in sales growth and employee growth. Despite widespread belief, successful bid protesters do not delay government procurement because of lengthy dispute resolutions. Overall, we provide the first analysis of corporate interactions with the United States government bid protest system. This paper was accepted by Tomasz Piskorski, finance. Supplemental Material: The internet appendix and data files are available at https://doi.org/10.1287/mnsc.2021.02055 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2021.02055},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8526-8548},
  shortjournal = {Manag. Sci.},
  title        = {Choose your battles wisely: The consequences of protesting government procurement contracts},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retention or acquisition? behavior-based quality disclosure. <em>MS</em>, <em>71</em>(10), 8510-8525. (<a href='https://doi.org/10.1287/mnsc.2022.01081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Firms frequently extend their brand by introducing products in new categories and offering free samples or demonstrations for customers to learn about the quality of the new products before purchasing. When introducing new products based on customers’ purchase behavior in the former category, firms face two customer segments: their own customers and the competitor’s customers. Firms can practice behavior-based pricing (BBP) by charging different prices in the two segments. Moreover, firms can practice behavior-based quality disclosure (BBD) by disclosing quality information to the two customer segments differently. In this paper, we examine how firms practice BBD in addition to BBP. We find that in contrast to the acquisition-focused BBP, firms perform retention-focused BBD by increasing quality disclosure to their own customers and decreasing it to the competitor’s customers. Unlike BBP, which decreases second-period profit and increases first-period profit, BBD increases second-period profit but decreases first-period profit when the disclosure cost is low. We also show that when firms endogenously choose BBD, the equilibrium is a prisoner’s dilemma when the disclosure cost is low and a win-win outcome when the disclosure cost is high. This paper was accepted by Raphael Thomadsen, marketing. Funding: This research was supported by the National Natural Science Foundation of China [Grant 72171103] and the Blanche “Peg” Philpott Professorship. Supplemental Material: The online appendix is available at https://doi.org/10.1287/mnsc.2022.01081 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2022.01081},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8510-8525},
  shortjournal = {Manag. Sci.},
  title        = {Retention or acquisition? behavior-based quality disclosure},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Managing channel profits with positive demand externalities. <em>MS</em>, <em>71</em>(10), 8491-8509. (<a href='https://doi.org/10.1287/mnsc.2021.00008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Demand externalities arise when past sales stimulate future demand. They pervade many consumer markets. To penetrate such markets, how should manufacturers contract with retailers? We formulate the problem as a dynamic game, wherein the retailer can privately observe and control evolving market conditions, and consumers can act either myopically or strategically. Our contribution is threefold. (i) We characterize the optimal contract: It resolves a dynamic tradeoff between exploiting demand externalities, screening new information, and optimizing channel efficiency; moreover, it has a simple implementation of quantity discount. (ii) We characterize the dual role of demand externalities. Although demand externalities can improve channel surplus by expanding market size, they can also exacerbate information friction by enhancing the retailer’s ability to manipulate the market. Ignoring the dark side of the agency cost, previous studies may have overestimated the benefit of demand externalities. (iii) We provide new practical guidance. We show private information per se need not hurt channel efficiency: The manufacturer can use recursive advance selling to extract new information for free. Our results also shed light on when and why manufacturers should moderate demand externalities and prefer long-term contracts. By highlighting the dual role of demand externalities in long-run channel performance, this study sharpens our understanding of channel theory and practice. This paper was accepted by Dmitri Kuksov, marketing. Funding: L. Gao was partly supported by Academic Senate COR Grants of UCR. Supplemental Material: The online appendices are available at https://doi.org/10.1287/mnsc.2021.00008 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2021.00008},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8491-8509},
  shortjournal = {Manag. Sci.},
  title        = {Managing channel profits with positive demand externalities},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Secondary market monetization and willingness to share personal data. <em>MS</em>, <em>71</em>(10), 8471-8490. (<a href='https://doi.org/10.1287/mnsc.2022.03423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People are often unaware that their personal data can serve as valuable inputs for economic activities in secondary data markets. However, whether secondary monetization of personal data determines privacy preferences remains unclear. I examine whether privacy decisions are motivated by the data recipient’s ability to benefit from trading individuals’ data with a third party. A large online laboratory experiment involving personally identifiable psychometric data is implemented with real data-sharing consequences and monetary benefits. I find that individuals decrease their willingness to share data—both in terms of their likelihood of participating in the data market and the prices demanded for such participation—when the recipient’s ability to monetize the data through secondary trade is salient. Strategic responses to updated beliefs about the recipient’s gain from the trade are ruled out via the chosen price elicitation. I find that increased data exposure (to more recipients) does not explain the significant revealed disutility from secondary monetization. These findings are also robust to controlling for the risk exposure differences between data recipients and third parties. This paper was accepted by Anindya Ghose, information systems. Funding: This project was funded in part by the Institute for the Social Sciences, Cornell University. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.03423 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2022.03423},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8471-8490},
  shortjournal = {Manag. Sci.},
  title        = {Secondary market monetization and willingness to share personal data},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Limits of disclosure regulation in the municipal bond market. <em>MS</em>, <em>71</em>(10), 8452-8470. (<a href='https://doi.org/10.1287/mnsc.2022.02289'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine the effectiveness of recent federal disclosure regulation aiming to improve transparency in the $4 trillion municipal bond market. Governments fail to disclose material private placements 50%–60% of the time and, conditional on disclosure, filings often omit contract details essential for bond pricing. Noncompliant issuers are significantly riskier than compliers, with disclosure decreasing in the potential of privately placed debt to adversely affect bondholders. We show that disclosure reveals positive news and is especially informative to investors in low-rated bonds or during market crises. Overall, privately placed debt continues to pose significant risks to municipal bond investors. This paper was accepted by Victoria Ivashina, finance. Funding: T. Zimmermann has received financial support from the Deutsche Forschungsgemeinschaft under Germany’s Excellence Strategy [EXC2126/139083886]. Supplemental Material: The online appendices and data files are available at https://doi.org/10.1287/mnsc.2022.02289 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2022.02289},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8452-8470},
  shortjournal = {Manag. Sci.},
  title        = {Limits of disclosure regulation in the municipal bond market},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Market ambiguity attitude restores the risk-return trade-off. <em>MS</em>, <em>71</em>(10), 8430-8451. (<a href='https://doi.org/10.1287/mnsc.2023.03595'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A positive relation between the conditional mean and conditional volatility of aggregate stock returns, although viewed as a fundamental law of finance, has been challenging to find empirically. We consider a representative agent asset pricing model with Knightian uncertainty and demonstrate that this risk-return trade-off depends on the agent’s ambiguity attitude (reflecting the agent’s degree of optimism or pessimism). The model predicts that the conditional equity premium is increasing in market volatility, but its slope flattens as market optimism rises. We develop a methodology to extract the representative agent’s ambiguity attitude from our asset pricing model. Results validate our model predictions. We document the significant in-sample and out-of-sample explanatory power of ambiguity attitude in explaining the risk-return trade-off. In our sample, market volatility is not significant in forecasting returns. However, including the market ambiguity attitude leads to a significant positive relationship between volatility and future returns. Hence, our model and results identify market ambiguity attitude as a missing state variable that can explain why the literature has found it difficult to empirically validate the risk-return trade-off. This paper was accepted by Manel Baucells, behavioral economics and decision analysis. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2023.03595 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2023.03595},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8430-8451},
  shortjournal = {Manag. Sci.},
  title        = {Market ambiguity attitude restores the risk-return trade-off},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gender differences in high-stakes performance and college admission policies. <em>MS</em>, <em>71</em>(10), 8413-8429. (<a href='https://doi.org/10.1287/mnsc.2023.02979'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Gale-Shapley algorithm is one of the most popular college allocation mechanisms around the world. A crucial policy question in its setting is designing admission priorities for students, understanding how they disadvantage certain demographic groups, and whether these differences relate to differences in college performance potential. Studying a policy change in Spain, we find a negative effect of increasing the weight of standardized high-stakes exams on female college admission grades, driven by students expected to be at the top. The impact on admission grades does not affect enrollment, but the percentage of female students in the most selective degrees declines, along with their career prospects. Using data on the college performance of prereform cohorts, we find that female students most likely to lose from the reform tend to do better in college than male students expected to benefit from the reform. The results show that rewarding high-stakes performance in selection processes may come along with gender differences unrelated to the determinants of subsequent performance. This paper was accepted by Dorothea Kubler, behavioral economics and decision analysis. Funding: A. Arenas received financial support from the Spanish Ministry of Science [Grant PID2020-120359RA-I00]. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2023.02979 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2023.02979},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8413-8429},
  shortjournal = {Manag. Sci.},
  title        = {Gender differences in high-stakes performance and college admission policies},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stressed banks? evidence from the largest-ever supervisory review. <em>MS</em>, <em>71</em>(10), 8390-8412. (<a href='https://doi.org/10.1287/mnsc.2020.01714'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study short-term and medium-term changes in bank risk-taking as a result of supervision and the associated real effects. For identification, we exploit the European Central Bank’s asset-quality-review (AQR) in conjunction with security and credit registers. After the AQR announcement, reviewed banks reduce riskier securities and credit supply, with the greatest effect on riskiest securities. We find negative spillovers on asset prices and firm-level credit availability. Moreover, nonbanks with higher exposure to reviewed banks acquire the shed risk. After the AQR compliance, reviewed banks reload riskier securities but not riskier credit, resulting in negative medium-term firm-level real effects. These effects are especially strong for firms with high ex ante credit risk. Among these nonsafe firms, even those with high ex ante productivity, experience negative real effects. Our findings suggest that banks’ liquid assets help them to mask risk from supervisors and risk adjustments banks make in response to supervision have persistent corporate real effects. This paper was accepted by Victoria Ivashina, finance. Funding: J.-L. Peydró acknowledges financial support from the BBVA Foundation [2018 Leonardo Grant for Researchers and Cultural Creators], the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme [Grant Agreement 648398], the MCIU/AEI/FEDER, UE [Grant PGC2018-102133-B-I00], and the Spanish Ministry of Economy and Competitiveness, through the Severo Ochoa Programme for Centres of Excellence in R&D [Grant SEV-2015-0563]. The analysis, conclusions, and opinions set forth in the paper are solely those of the authors and do not necessarily represent the views of the Bundesbank, Eurosystem, Federal Reserve Board, or the United States. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2020.01714 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2020.01714},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8390-8412},
  shortjournal = {Manag. Sci.},
  title        = {Stressed banks? evidence from the largest-ever supervisory review},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consumer privacy in online retail supply chains. <em>MS</em>, <em>71</em>(10), 8371-8389. (<a href='https://doi.org/10.1287/mnsc.2022.01819'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploitation of consumer data allows online retailers to enhance services provided to consumers but at the risk of causing unintended privacy issues. There has been debate about whether to devise regulation policies to restrict data collection and usage by online retailers. This paper studies the implications of newly adopted privacy policies, such as the General Data Protection Regulation (GDPR), for an online retail supply chain comprising a retailer and a supplier. We find that despite the GDPR’s intention to safeguard consumer privacy, it may inadvertently hurt consumer surplus while benefiting the retailer. In fact, the GDPR may lead to an outcome detrimental to all parties involved, including the retailer, supplier, and consumers, thereby resulting in a triple-lose situation. Our results hold significant implications for consumers, supply chain firms, and policymakers alike, contributing to the existing literature on evaluating the impact of privacy regulations on technology innovation and adoption. This paper was accepted by Karan Girotra, operations management. Supplemental Material: The online appendix is available at https://doi.org/10.1287/mnsc.2022.01819 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2022.01819},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8371-8389},
  shortjournal = {Manag. Sci.},
  title        = {Consumer privacy in online retail supply chains},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Short of capital: Stock market implications of short sellers’ losses. <em>MS</em>, <em>71</em>(10), 8347-8370. (<a href='https://doi.org/10.1287/mnsc.2023.01356'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide evidence that losses constrain short sellers but not the transmission of information to prices. Using unique data on U.S. equity lending, we document a negative impact of the mark-to-market losses of a stock’s short sellers, but no impact of their gains, on the future shorting of the stock. Consistent with funding and institutional constraints limiting short selling, we further show that the effect is highly asymmetric across different loss levels and stronger among stocks facing higher margin requirements. However, loss-making short selling has no impact on price efficiency or predictive power for returns, suggesting that these constraints affect mostly uninformed shorting activity. This paper was accepted by Agostino Capponi, finance. Funding: This work was supported by the University of Melbourne [Faculty Research Grant]. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2023.01356 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2023.01356},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8347-8370},
  shortjournal = {Manag. Sci.},
  title        = {Short of capital: Stock market implications of short sellers’ losses},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pricing durable add-ons: Selling vs. leasing. <em>MS</em>, <em>71</em>(10), 8336-8346. (<a href='https://doi.org/10.1287/mnsc.2023.03064'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many firms offer products that consist of a durable base good (e.g., a vehicle) and a durable add-on (e.g., autopilot software). Some lease the add-on, whereas others sell it through intertemporal price discrimination or bundled pricing. Motivated by these practices, we examine whether a monopolistic firm should lease or sell the add-on when offering both durables. The literature suggests that leasing is preferable for a single durable good as it avoids the time inconsistency problem associated with selling. However, because leasing lacks an intertemporal link, it is less efficient than selling in balancing surplus extraction across consumers, leading to what we call the intraperiod imbalance problem. When the firm sells the base good, this can resolve the time inconsistency of add-on selling but perpetuate the intraperiod imbalance of add-on leasing. Thus, selling the add-on can be more profitable than leasing it. When the firm can choose between selling or leasing the base good, selling both the base good and the add-on can be more profitable than leasing both. This paper was accepted by Dmitri Kuksov, marketing. Funding: P. Yu was supported by the National Natural Science Foundation of China [Grants 72371038, 72033003]. L. Lei was supported by the National Natural Science Foundation of China [Grants 72301042, 72250065]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/mnsc.2023.03064 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2023.03064},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8336-8346},
  shortjournal = {Manag. Sci.},
  title        = {Pricing durable add-ons: Selling vs. leasing},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revenue sharing at music streaming platforms. <em>MS</em>, <em>71</em>(10), 8319-8335. (<a href='https://doi.org/10.1287/mnsc.2023.03830'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of sharing the revenues raised from subscriptions to music streaming platforms among content providers. We provide direct, axiomatic, and game-theoretical foundations for two focal (and somewhat polar) methods widely used in practice: pro rata and user centric . The former rewards artists proportionally to their number of total streams. With the latter, each user’s subscription fee is proportionally divided among the artists streamed by that user. We also provide foundations for two families of methods addressing the rising concern in the music industry to explore new streaming models that better align the interests of artists, fans, and streaming services. One of the families offers a natural compromise between the pro rata and user-centric methods. The other family generalizes the user-centric method while capturing various formalizations of incentives for artists and users. This paper was accepted by Manel Baucells, behavioral economics and decision analysis. Funding: This work was supported by Xunta de Galicia [Grant ED431B2022/03] and MCIU/AEI/10.13039/501100011033 and FSE+ [Grants PID2020-113440GBI00, PID2020-115011GB-I00, and PID2023-146364NB-I00].},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2023.03830},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8319-8335},
  shortjournal = {Manag. Sci.},
  title        = {Revenue sharing at music streaming platforms},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Play it again, sam? reference-point formation and product differentiation in the music industry. <em>MS</em>, <em>71</em>(10), 8304-8318. (<a href='https://doi.org/10.1287/mnsc.2022.03319'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Newly released music is never assessed in isolation by audiences, who tend to compare objective (sonic attributes) and subjective (genre affiliations) elements of its identity with the previous musical catalog of the corresponding artist, his or her musically proximal peers, and the most successful releases in the market. In this paper, we provide a general framework that disentangles the objective and subjective identities of new musical releases and evaluates how differentiation affects audience reactions. We posit that radio stations, who seek commercial success, have different preferences toward differentiation in comparison with critics, who grant cultural legitimacy in the industry. Combining play numbers, reviews, and music description data from different sources, we find that radio stations prefer consistency in the musical style of successive releases by the focal artist and especially favor albums that sound similar to chart toppers. Critics, however, exhibit opposite preferences, preferring novelty compared with past works of the artist, while remaining uninfluenced by contemporaneous music dynamics. Our moderation checks reveal that decisions around genre affiliations and scheduling of new releases aid music producers to effectively manage audience expectations. This suggests that data-driven decision support systems can help artists to strategically release new products that cater to heterogeneous tastes. This paper was accepted by David Simchi-Levi, entrepreneurship and innovation. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.03319 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2022.03319},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8304-8318},
  shortjournal = {Manag. Sci.},
  title        = {Play it again, sam? reference-point formation and product differentiation in the music industry},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The value of specific knowledge: Evidence from disruptions to the Patient–Physician relationship. <em>MS</em>, <em>71</em>(10), 8289-8303. (<a href='https://doi.org/10.1287/mnsc.2021.03884'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When a member of a work team leaves, some knowledge is lost to the organization. Exploiting quasi-random turnover among military physicians because of deployments, I estimate the effects of turnover on patients and other providers in the same care team. I find that a discontinuity in primary care leads to a 3%–5% increase in costs driven primarily by an increase in the use and intensity of specialty care with no observable benefit to the patient as measured by potential reductions in hospitalization rates and emergency department usage. This indicates that the full cost of turnover includes a reduction in access to knowledge among remaining members of the team. This paper was accepted by Carri Chan, healthcare management. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2021.03884 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2021.03884},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8289-8303},
  shortjournal = {Manag. Sci.},
  title        = {The value of specific knowledge: Evidence from disruptions to the Patient–Physician relationship},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). To ask or not to ask: The effects of broadly and narrowly adopted peer-recognition systems on help seeking. <em>MS</em>, <em>71</em>(10), 8267-8288. (<a href='https://doi.org/10.1287/mnsc.2023.00318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many companies now use peer-recognition systems that allow employees to publicly recognize their peers for positive behaviors. Practitioners have touted the potential for these systems to increase helping among employees. However, the extent to which employees actually use these systems to recognize their peers varies across organizations; some are used broadly by many employees across all functional, specialty, geographic, and hierarchical subgroups of the organization, whereas others are only narrowly used by some, but not all, subgroups. Across three experiments, we examine how peer-recognition systems impact employees’ propensity to ask others for help (i.e., help seeking) based on whether the system is broadly used by all subgroups or only narrowly used by specific subgroups. We predict and find that a peer-recognition system broadly used by all subgroups strengthens employees’ perception of a help-seeking norm. This perception increases employees’ propensity to seek help directly through norm conformity and indirectly by reducing the perceived psychological costs of help seeking. We also predict and find that the effect of peer-recognition systems that are narrowly used by specific subgroups is moderated by whether employees belong to the subgroups using the system; whereas it increases help-seeking propensity for members of the subgroups using the system, it decreases help-seeking propensity for nonmembers relative to when there is no peer-recognition system. Our theory and results suggest that peer-recognition systems can increase help seeking, but these same systems could decrease help seeking for employees belonging to subgroups that do not use the system. This paper was accepted by Ranjani Krishnan, accounting. Funding: Supported by the University of Illinois at Urbana-Champaign; Indiana University. Supplemental Material: The data files are available at https://doi.org/10.1287/mnsc.2023.00318 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2023.00318},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8267-8288},
  shortjournal = {Manag. Sci.},
  title        = {To ask or not to ask: The effects of broadly and narrowly adopted peer-recognition systems on help seeking},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sharing the fame but taking the blame: When declaring a single person responsible solves a free rider problem. <em>MS</em>, <em>71</em>(10), 8252-8266. (<a href='https://doi.org/10.1287/mnsc.2024.06567'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Teams are formed because input from different people is needed. Providing incentives to team members, however, can be difficult. According to received wisdom, declaring all members responsible fails because real responsibility for team output “diffuses.” But why? Also, why and when does formally declaring one member “responsible” mean that this member can be attributed real responsibility? We offer a model that answers these questions. We identify when jointly declaring a team responsible results in reputation free riding. We show that declaring one person responsible can overcome this problem but only if all other team members are protected from being sanctioned. This paper was accepted by Dorothea Kübler, behavioral economics and decision analysis.},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2024.06567},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8252-8266},
  shortjournal = {Manag. Sci.},
  title        = {Sharing the fame but taking the blame: When declaring a single person responsible solves a free rider problem},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine data: Market and analytics. <em>MS</em>, <em>71</em>(10), 8230-8251. (<a href='https://doi.org/10.1287/mnsc.2023.00674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine data (MD), that is, data generated by machines, are increasingly gaining importance, potentially surpassing the value of the extensively discussed personal data. We present a theoretical analysis of the MD market, addressing challenges such as data fragmentation, ambiguous property rights, and the public-good nature of MD. We consider machine users producing data and data aggregators providing MD analytics services (e.g., with digital twins for real-time simulation and optimization). By analyzing machine learning algorithms, we identify critical properties for the value of MD analytics, Scale, Scope, and Synergy. We leverage these properties to explore market scenarios, including anonymous and secret contracting, competition among MD producers, and multiple competing aggregators. We identify significant inefficiencies and market failures, highlighting the need for nuanced policy interventions. This paper was accepted by Joshua Gans, business strategy. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2023.00674 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2023.00674},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8230-8251},
  shortjournal = {Manag. Sci.},
  title        = {Machine data: Market and analytics},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A preregistered falsification test of the decision by sampling model and rank-order effect. <em>MS</em>, <em>71</em>(10), 8218-8229. (<a href='https://doi.org/10.1287/mnsc.2022.03611'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many social scientists have assumed that people’s preferences can be described by stable and coherent “utility” functions. This notion of stable utility functions has been challenged by cognitive psychologists who suggest that preferences are malleable and constructed in the moment, but neither camp has explained how the subjective valuations underpinning preferences arise. One influential attempt to do so is the Decision by Sampling (DbS) model, which suggests that a quantitative attribute’s (e.g., money sum’s) subjective value is its rank order in a momentarily activated memory sample. DbS thus implies that manipulating the recently experienced attribute distribution should change people’s subsequent valuations of that attribute: for example, from the typically assumed concave shape of the utility function to a convex shape. However, recent studies have pointed out methodological concerns in the evidence previously thought to support this prediction (and thus, DbS). In this preregistered study, we replicate the previous paradigm but address the methodological concerns to test if such a “rank-order” manipulation does change valuations. We derive qualitative predictions from DbS to verify that our conditions yield distinct predictions. We find strong evidence against the DbS’s prediction that a “rank-order” manipulation changes what options the participants select and how strongly they prefer the options. We also find extreme evidence in favor of a contextualization effect, implying that people value formally identical gambles differently depending on whether they cue a real-life setting or not. Although we encourage replication by independent laboratories, these results suggest that the DbS is falsified for this binary choice task. This paper was accepted by Yuval Rottenstreich, behavioral economics and decision analysis. Funding: This research was funded by the Marcus and Amalia Wallenberg Foundation [Grant MAW 2016.0132] and the Swedish Research School of Management and IT. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.03611 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2022.03611},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8218-8229},
  shortjournal = {Manag. Sci.},
  title        = {A preregistered falsification test of the decision by sampling model and rank-order effect},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sampling-based approximation for series inventory systems. <em>MS</em>, <em>71</em>(10), 8200-8217. (<a href='https://doi.org/10.1287/mnsc.2022.01876'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study inventory management of an infinite-horizon, series system with multiple stages. Each stage orders from its immediate upstream stage, and the most upstream stage orders from an external supplier. Random demand with unknown distribution occurs at the most downstream stage. Each stage incurs inventory holding cost while the most downstream stage also incurs demand backlogging cost when it experiences inventory shortage. The objective is to minimize the expected total discounted cost over the planning horizon. We apply the sample average approximation (SAA) method to obtain a heuristic policy (SAA policy) using the empirical distribution function constructed from a demand sample (of the underlying demand distribution). We derive an upper bound of sample size (viz., distribution-free bound) that guarantees that the performance of the SAA policy be close (i.e., with arbitrarily small relative error) to the optimal policy under known demand distribution with high probability. This result is obtained by first deriving a separable and tight cost upper bound of the whole system that depends on (given) echelon base-stock levels and then showing that the cost difference between the SAA and optimal policies can be measured by the distance between the empirical and the underlying demand distribution functions. We also provide a lower bound of sample size that matches the upper bound (in the order of relative error). Furthermore, when the demand distribution is continuous and has an increasing failure rate (IFR), we derive a tighter sample size upper bound (viz., distribution-dependent bound). Both distribution-free and distribution-dependent bounds for the newsvendor problem, a special case of our series system, improve the previous results. In addition, we show that both bounds increase polynomially as the number of stages increases. The performance of SAA policy and the sample size bounds are illustrated numerically. Finally, we extend the results to finite-horizon series systems. This paper was accepted by David Simchi-Levi, operations management. Funding: K. Zhang is partially supported by the National Nature Science Foundation of China [Grants 71901200 and 72471220]. X. Gao is partially supported by the Hong Kong Research Grants Council General Research Fund [Grant CUHK-14506620]. Z. Wang is partially supported by the National Nature Science Foundation of China [Grant 72401146]. S. X. Zhou is partially supported by the Hong Kong Research Grants Council General Research Fund [Grant CUHK-14500921], the National Natural Science Foundation of China [Grant 72394395], and the Asian Institute of Supply Chains and Logistics. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.01876 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2022.01876},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8200-8217},
  shortjournal = {Manag. Sci.},
  title        = {Sampling-based approximation for series inventory systems},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Can socially minded governance control the artificial general intelligence beast?. <em>MS</em>, <em>71</em>(10), 8188-8199. (<a href='https://doi.org/10.1287/mnsc.2024.05529'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper robustly concludes that it cannot. A model is constructed under idealized conditions that presume that the risks associated with artificial general intelligence (AGI) are real, that safe AGI products are possible, and that there exist socially minded funders who are interested in funding safe AGI, even if this does not maximize profits. It is demonstrated that a socially minded entity formed by such funders would not be able to minimize harm from AGI that unrestricted products released by for-profit firms might create. The reason is that a socially minded entity can only minimize the use of unrestricted AGI products in ex post competition with for-profit firms at a prohibitive financial cost and so, does not preempt the AGI developed by for-profit firms ex ante. This paper was accepted by Maria Guadalupe, business strategy.},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2024.05529},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8188-8199},
  shortjournal = {Manag. Sci.},
  title        = {Can socially minded governance control the artificial general intelligence beast?},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Designing information to engage customers. <em>MS</em>, <em>71</em>(10), 8169-8187. (<a href='https://doi.org/10.1287/mnsc.2022.03503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative customization is common in many markets. Sellers and customers can collectively discover the value of the product’s basic design. Customers’ willingness to pay can also be increased by being engaged to improve the product design. We study how a seller can design the information structure of collective learning about the product’s basic value to induce costly customer engagement. We consider a setting in which the parties’ expected payoffs are determined endogenously through the strategic interaction between seller pricing and customer engagement and purchase. The customer tends to be engaged in equilibrium, as the uncertainty on the product’s basic value becomes higher to dilute the responsiveness of the optimal price to customer engagement. Therefore, the seller seeks to maximize the probability of generating an intermediate posterior belief. Thus, the optimal information design involves either exaggerating or downplaying the product’s basic value when the prior is low or high, respectively. We show that considering restrictive information structures can generate qualitatively different implications. We also examine how the unobservability of engagement may influence the parties’ strategic interaction, their expected payoffs, and the seller-optimal information design. Interestingly, unobservability may lead to lower equilibrium engagement, hurt the seller, render the customer’s equilibrium expected payoff to increase as customer engagement becomes less important or more costly, and yield more or less information provision. This paper was accepted by Dmitri Kuksov, marketing.},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2022.03503},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8169-8187},
  shortjournal = {Manag. Sci.},
  title        = {Designing information to engage customers},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cultural homophily and collaboration in superstar teams. <em>MS</em>, <em>71</em>(10), 8149-8168. (<a href='https://doi.org/10.1287/mnsc.2022.01799'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One may reasonably think that cultural homophily, defined as the tendency to associate with others of similar culture, affects collaboration in multinational teams in general but not in superstar teams of professionals at the top of their industry. The analysis of an exhaustive data set on the passes made by professional European football players in the top five men’s leagues reveals that on the contrary, cultural homophily is persistent, pervasive, and consequential, even in superstar multinational teams of very-high-skill individuals with clear common objectives and aligned incentives who are involved in interactive tasks that are well defined and not particularly culture intensive. This paper was accepted by Olav Sorenson, organizations. Funding: G. Békés thanks the Hungarian Academy of Sciences [Grant “Firms, Strategy and Performance” Lendület] for support. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.01799 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2022.01799},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8149-8168},
  shortjournal = {Manag. Sci.},
  title        = {Cultural homophily and collaboration in superstar teams},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revealed wisdom of the crowd: Bids predict loan quality. <em>MS</em>, <em>71</em>(10), 8127-8148. (<a href='https://doi.org/10.1287/mnsc.2022.02575'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the popularity of the phrase “wisdom of the crowd,” not all crowds are wise because not everyone in them acts in an informed, rational manner. Identifying informative actions, therefore, can help to isolate the truly wise part of a crowd. Motivated by this idea, we evaluate the informational value of investors’ bids using data from online, debt-based crowdfunding, in which we were able to track both investment decisions and ultimate repayment statuses for individual loans. We propose several easily scalable variables derived from the heterogeneity of investors’ bids in terms of size and timing. We first show that loans funded with larger bids relative to the typical bid amount in the market or to the bidder’s historical baseline, particularly early in the bidding period, are less likely to default. More importantly, we perform theory-driven feature engineering and find that these variables improve the predictive performance of state-of-the-art models that have been proposed in this context. Even during the fundraising process, these variables improve predictions of both funding likelihood and loan quality. We discuss the implications of these variables, including loan pricing in secondary markets, crowd wisdom in different market mechanisms, and financial inclusion. Crowdfunding platforms can easily implement these variables to improve market efficiency without compromising investor privacy. This paper was accepted by David Simchi-Levi, information systems. Funding: We gratefully acknowledge the financial support of the Business Analytics Center in the Scheller College of Business and the Ewing Marion Kauffman Foundation. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.02575 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2022.02575},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8127-8148},
  shortjournal = {Manag. Sci.},
  title        = {Revealed wisdom of the crowd: Bids predict loan quality},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Innovation diffusion among coworkers: Evidence from senior doctors. <em>MS</em>, <em>71</em>(10), 8109-8126. (<a href='https://doi.org/10.1287/mnsc.2023.00496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using a novel 15-year data set on surgeon adoption of a complex surgical innovation in the English National Health Service and an identification strategy based on surgeon mobility, this paper disentangles three channels of coworker influence on innovation diffusion: (1) peer network size, (2) influential “key players,” and (3) cumulative peer adoption. We find that a one standard deviation in peer connections boost innovation by 16%. Key players can either amplify or dampen diffusion, and peer adoption has a greater impact on less experienced individuals. These results highlight the value of targeting training to high impact network members to speed up diffusion. This work advances our understanding of how professional networks shape innovation diffusion, with implications for technology implementation. This paper was accepted by Stefan Scholtes, healthcare management. Funding: This work was supported by the European Research Council (ANR-17-EURE-0010, POEMH, Advanced Investigator Award HealthCareLabour REP-SCI-788529), the Australian Research Council (Discovery Project DP220101043) and the Health Foundation (Efficiency Research Programme). Supplemental Material: The online appendix and data files are available at https://doi.org/https://doi.org/10.1287/mnsc.2023.00496 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2023.00496},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8109-8126},
  shortjournal = {Manag. Sci.},
  title        = {Innovation diffusion among coworkers: Evidence from senior doctors},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Who is AI replacing? the impact of generative AI on online freelancing platforms. <em>MS</em>, <em>71</em>(10), 8097-8108. (<a href='https://doi.org/10.1287/mnsc.2024.05420'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the impact of generative artificial intelligence (AI) technologies on the demand for online freelancers using a large data set from a leading global freelancing platform. We identify the types of jobs that are more affected by generative AI and quantify the magnitude of the heterogeneous impact. Our findings indicate a 21% decrease in the number of job posts for automation-prone jobs related to writing and coding compared with jobs requiring manual-intensive skills within eight months after the introduction of ChatGPT. We show that the reduction in the number of job posts increases competition among freelancers, whereas the remaining automation-prone jobs are of greater complexity and offer higher pay. We also find that the introduction of image-generating AI technologies led to a 17% decrease in the number of job posts related to image creation. We use Google Trends to show that the more pronounced decline in the demand for freelancers within automation-prone jobs correlates with their higher public awareness of ChatGPT’s substitutability. This paper was accepted by Duncan Simester, marketing. Supplemental Material: The online appendices and data files are available at https://doi.org/10.1287/mnsc.2024.05420 .},
  archive      = {J_MS},
  doi          = {10.1287/mnsc.2024.05420},
  journal      = {Management Science},
  month        = {10},
  number       = {10},
  pages        = {8097-8108},
  shortjournal = {Manag. Sci.},
  title        = {Who is AI replacing? the impact of generative AI on online freelancing platforms},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="msom">MSOM - 20</h2>
<ul>
<li><details>
<summary>
(2025). Advance selling and upgrading in priority queues. <em>MSOM</em>, <em>27</em>(5), 1664-1682. (<a href='https://doi.org/10.1287/msom.2023.0410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem definition : We study advance selling and upgrading in a priority queue setting that emerges in the amusement park industry. Customers choose to buy fast-track or regular tickets depending on their heterogeneous waiting costs. At the park entrance, customers can choose tickets based on the observed congestion levels. Customers who purchase tickets in advance suffer from congestion uncertainty. Upgrading options allow customers to purchase regular tickets in advance and upgrade on-site if the congestion turns out to be high. The seller’s objective is to find the optimal pricing scheme to maximize revenue. Methodology/results : We analyze a two-stage model in a queueing game framework. Under full coverage and fixed regular ticket prices, the seller sets the priority ticket prices to maximize the revenue. We investigate two pricing schemes, both with and without upgrading options, under different scenarios depending on the proportion of customers who have access to advance ticket purchasing. When all customers have access to advance ticket purchasing, our findings indicate that the advance-and-spot selling scheme yields the same maximum revenue as the scheme that includes the upgrading option if the spot regular ticket price is not too large; thus, the upgrading option becomes unnecessary. Otherwise, allowing upgrading generates more revenue (and social welfare). Interestingly, although upgrading options offer consumers greater flexibility, they reduce consumer surplus in scenarios where upgrading increases revenue. When some customers only purchase tickets on the spot, our numerical analysis shows that allowing upgrading results in higher revenue when the probability of high system congestion is large and highlights cases when the revenue gap is significant. Finally, we extend our analysis to account for customers’ balking behavior and the additional waiting time incurred when purchasing tickets on the spot, providing a robust check on scheme comparison. Managerial implications : Our paper is one of the first to investigate—in the context of queueing economics—the advance selling strategy together with upgrading option, taking into account arrival rate uncertainty. Our results offer guidance on selling scheme design for ticket sellers and provide one economic explanation for the various pricing policies seen in the amusement park industry. Funding: Financial support from the National Natural Science Foundation of China [Grants 72101248, 72471215, 72122019, 72471005, and 72031006] is gratefully acknowledged. Supplemental Material: The online appendix is available at https://doi.org/10.1287/msom.2023.0410 .},
  archive      = {J_MSOM},
  doi          = {10.1287/msom.2023.0410},
  journal      = {Manufacturing & Service Operations Management},
  month        = {9-10},
  number       = {5},
  pages        = {1664-1682},
  shortjournal = {Manuf. Serv. Oper. Manag.},
  title        = {Advance selling and upgrading in priority queues},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiproduct dynamic pricing with reference effects under logit demand. <em>MSOM</em>, <em>27</em>(5), 1645-1663. (<a href='https://doi.org/10.1287/msom.2024.0801'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem definition : We consider the dynamic pricing problem of multiple products under (asymmetric) reference effects over an infinite horizon. Unlike existing literature, which is mostly focused on the single-product setting, our multiproduct setting takes into account the cross-product effects among substitutes and incorporates the memory-based reference prices into the multinomial logit (MNL) demand model. Even with the single-product logit demand, the structure of the optimal pricing policy is intractable. Therefore, we focus on the long-run patterns of the optimal pricing policy and also discuss the performance of the myopic pricing policy. Methodology/results : We first provide a comprehensive characterization of the myopic pricing policy, including its solution, long-run convergence behavior, and optimality gap. For the optimal pricing policy, we show an intricate connection between its long-run dynamics and types of reference effects. We demonstrate that the presence of any gain-seeking product renders a long-run constant pricing policy suboptimal. Conversely, the constant policy (or optimal steady state) can exist in both loss-neutral and loss-averse scenarios, where we provide a sufficient condition for such existence and give the analytical expression for the optimal steady state. We further show that when pricing perfect substitutes, the true optimal policy under the multiproduct framework is more likely to yield a long-run cyclic pattern than the policy derived from the single-product framework, a phenomenon that aligns well with the periodic discounts in real-world markets. Managerial implications : This discrepancy in the long-run behaviors between multi- and single-product-based policies highlights the importance of employing the multiproduct framework and addressing the cross-product effects, as sticking to the single-product framework while managing multiple substitutes can misrepresent long-run dynamics and result in suboptimality. In the multiproduct domain, our model suggests that retailers are more likely to benefit from appropriate price variations than maintaining a constant pricing policy. Funding: H. Jiang acknowledges support from the Natural Sciences and Engineering Research Council of Canada [NSERC Discovery Grant RGPIN 2024 05796]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/msom.2024.0801 .},
  archive      = {J_MSOM},
  doi          = {10.1287/msom.2024.0801},
  journal      = {Manufacturing & Service Operations Management},
  month        = {9-10},
  number       = {5},
  pages        = {1645-1663},
  shortjournal = {Manuf. Serv. Oper. Manag.},
  title        = {Multiproduct dynamic pricing with reference effects under logit demand},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coastal groundwater management: Seawater intrusion prevention, artificial recharge, and climate adaptation. <em>MSOM</em>, <em>27</em>(5), 1625-1644. (<a href='https://doi.org/10.1287/msom.2022.0441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem definition : Most of the world’s population relies on coastal aquifers for freshwater supplies. Groundwater is experiencing substantial overdrafts and facing ever-mounting freshwater demand. Existing groundwater management strategies are myopic and fail to coordinate production and the operation of protection approaches, including seawater intrusion barriers (SWIBs) and managed aquifer recharge (MAR). Motivated by the urgency of sustainable groundwater management, we investigate how to optimize the joint operations of groundwater production, protection (by injecting fresh water through SWIBs), and replenishment (via MAR). Methodology/results : We model a central planner’s decision on groundwater production, freshwater injection quantities, and artificial replenishment using stochastic dynamic models and identify that the optimal groundwater management policies follow a threshold-type structure. We find that SWIBs and MAR are strategic complements, except in cases with very high groundwater levels, when they turn into strategic substitutes. When the penalty for low groundwater levels decreases, the planner should use SWIBs more aggressively if groundwater levels are low and more conservatively if they are high. A similar pattern holds when natural recharge becomes more abundant, assuming that the natural recharge quantity has no impact on the purchasing cost of imported water. Moreover, we calibrate our model using real data sets in Orange County, California and find that the joint operations of SWIBs and MAR expand groundwater operational flexibility. In contrast, employing SWIBs alone comes at the expense of a lower groundwater level. Managerial implications : Our analysis offers strategic guidance on when to use SWIBs and MAR as complements or substitutes based on groundwater levels. It highlights the value of their joint operation in stabilizing groundwater, especially amid worsening droughts. Funding: This work was partially supported by the National Natural Science Foundation of China [Grants 72242106, 72242107, and 72188101]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/msom.2022.0441 .},
  archive      = {J_MSOM},
  doi          = {10.1287/msom.2022.0441},
  journal      = {Manufacturing & Service Operations Management},
  month        = {9-10},
  number       = {5},
  pages        = {1625-1644},
  shortjournal = {Manuf. Serv. Oper. Manag.},
  title        = {Coastal groundwater management: Seawater intrusion prevention, artificial recharge, and climate adaptation},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cheap thrills! an empirical analysis of the impact of supercenters on consumer waste. <em>MSOM</em>, <em>27</em>(5), 1604-1624. (<a href='https://doi.org/10.1287/msom.2023.0207'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem definition : To generate more sales, retailers are incentivized to open large stores. However, large store formats can carry negative environmental externalities. Entry of large stores in a community may stimulate mass consumption through its impact on consumer behaviors and local competition. In this study, we examine the local impact on the amount of consumer waste generated following an expansion of retail Supercenters. Methodology/results : We leverage the staggered expansion of Walmart Supercenters and adopt a difference-in-differences approach to investigate the impact of Supercenter entry on consumer waste. Our difference-in-differences estimates suggest that Supercenter entry results in up to a 6.97% increase in consumer waste in the affected counties. The increase is larger for new Supercenter launches compared with Supercenter conversions. In addition, we examine the roles of convenience stores and circular economy channels in mitigating the impact of Supercenter expansion. Managerial implications : For policymakers, our results also highlight a silver lining: the negative environmental effect of Supercenter entry can be mitigated through a balanced retail strategy that includes both convenience stores and Supercenters. Furthermore, we show that developing and promoting local circular economy channels may also mitigate the Supercenter effect. Supplemental Material: The online appendix is available at https://doi.org/10.1287/msom.2023.0207 .},
  archive      = {J_MSOM},
  doi          = {10.1287/msom.2023.0207},
  journal      = {Manufacturing & Service Operations Management},
  month        = {9-10},
  number       = {5},
  pages        = {1604-1624},
  shortjournal = {Manuf. Serv. Oper. Manag.},
  title        = {Cheap thrills! an empirical analysis of the impact of supercenters on consumer waste},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Designing emission permits regulation for multiple compliance periods. <em>MSOM</em>, <em>27</em>(5), 1587-1603. (<a href='https://doi.org/10.1287/msom.2023.0341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem definition : This paper investigates the effectiveness of emission permits policies with varying levels of temporal flexibility, including different compliance periods and the allowance/prohibition of intertemporal banking and borrowing. We also explore advanced policy designs aimed at improving social welfare. Methodology/results : Our analysis reveals that extreme policies, such as fully flexible or fully nonflexible permits, are generally suboptimal from a welfare perspective. Restricting temporal flexibility can be beneficial, particularly when pollution damage is severe or production costs are highly volatile. This finding arises from the tradeoff between the positive industrial impacts and the negative environmental consequences of temporal flexibility. We further demonstrate that partially flexible permits—such as transfer cap/discount and permits-tax hybrid—can achieve a better balance between industrial efficiency and environmental protection, even surpassing the classic welfare bound associated with fully flexible permits. Additionally, we find that temporal flexibility may reduce overall industrial profits by intensifying market competition, and allocating additional permits can widen profit gaps among firms. Managerial implications : This study provides actionable insights for regulators aiming to enhance emission permits policies and offers a deeper understanding of their impacts on firms’ profitability and operations. Funding: X. Fu acknowledges financial support from the University of New South Wales [Start-Up Grant, UNSW Business School Dean’s Research Fellowship]. P. Gao’s research is supported by the National Natural Science Foundation of China [Grants 72201234 and 72192805], Collaborative Research Funds [Grant C6032-21G] of the Hong Kong Research Grants Council, and the Guangdong Provincial Key Laboratory of Mathematical Foundations for Artificial Intelligence [Grant 2023B1212010001]. Y.-J. Chen acknowledges financial support from the Hong Kong Research Grants Council [Grants 16501722, 16212821, and C6020-21GF]. G. Gallego is supported by Collaborative Research Funds [Grant C6032-21G] of the Hong Kong Research Grants Council. M. Lu is supported by Collaborative Research Funds [Grants C6032-21G, C5004-23G, and C5002-22Y] and the General Research Fund [Grant 16300424] of the Hong Kong Research Grants Council. This work also contributes to the UNESCO-endorsed program “Seamless Prediction and Services for Sustainable Natural and Built Environments (SEPRESS) 2025–2032” under their International Decade of Science for Sustainable Development. Supplemental Material: The online appendices are available at https://doi.org/10.1287/msom.2023.0341 .},
  archive      = {J_MSOM},
  doi          = {10.1287/msom.2023.0341},
  journal      = {Manufacturing & Service Operations Management},
  month        = {9-10},
  number       = {5},
  pages        = {1587-1603},
  shortjournal = {Manuf. Serv. Oper. Manag.},
  title        = {Designing emission permits regulation for multiple compliance periods},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The impact of automation on workers when workers are strategic: The case of ride-hailing. <em>MSOM</em>, <em>27</em>(5), 1571-1586. (<a href='https://doi.org/10.1287/msom.2023.0416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem definition : Motivated by the behavior of drivers on ride-hailing platforms (individual drivers decide whether to work based on the offered wage and where to locate themselves in anticipation of future fares), we examine how the introduction of autonomous vehicles impacts the strategic behavior of human drivers and driver welfare. Specifically, we consider a setting in which a ride-hailing platform deploys a mixed fleet of conventional vehicles (CVs) and autonomous vehicles (AVs). The CVs are operated by human drivers who make independent decisions about whether to work for the platform and where to position themselves when they become idle. The AVs are under the control of the platform. The platform decides on the wage it pays the drivers, the size of the AV fleet, and how the AVs are positioned spatially when they are idle. The platform can also make decisions on whether to prioritize the AVs or the CVs in assigning vehicles to customer requests. Methodology/results : We use a fluid model to characterize the optimal decisions of the platform and contrast those with the optimal decisions in the absence of AVs. We examine the impact of automation on strategic drivers and the ride-hailing platform. We show that, although the introduction of AVs can displace drivers and depress effective wages, there are settings in which the introduction of AVs leads to higher effective wages and more drivers being hired. We discuss how these results can, in part, be explained by the interplay of two counteracting effects: (i) the introduction of AVs provides the platform with an additional source of supply and renders human driver substitutable (displacement effect), and (ii) having access to and control over AVs enables the platform to influence the strategic behavior of CVs, thereby reducing the inefficiency from self-interested behavior (incentive effect). The relative strength of these two effects depends on the cost of AVs and the vehicle dispatching policy. Managerial implications : Our results uncover a new effect through which the introduction of AVs affects the welfare of human drivers (the incentive effect) and another mechanism to mitigate inefficiencies because of human drivers acting strategically. Our results have potentially broader applications to other areas in which automation is introduced and workers are strategic. Funding: This work was supported by the National Science Foundation [Grant SCC-1831140]. The Guangdong (China) Provincial Key Laboratory of Mathematical Foundations for Artificial Intelligence [2023B1212010001]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/msom.2023.0416 .},
  archive      = {J_MSOM},
  doi          = {10.1287/msom.2023.0416},
  journal      = {Manufacturing & Service Operations Management},
  month        = {9-10},
  number       = {5},
  pages        = {1571-1586},
  shortjournal = {Manuf. Serv. Oper. Manag.},
  title        = {The impact of automation on workers when workers are strategic: The case of ride-hailing},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Market formation, pricing, and value generation in ride-hailing services. <em>MSOM</em>, <em>27</em>(5), 1551-1570. (<a href='https://doi.org/10.1287/msom.2022.0502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem definition : We empirically study the market for ride-hailing services. In particular, we explore the following questions: (i) How do the two-sided market and prices jointly form in ride-hailing marketplaces? (ii) Does surge pricing create value, and for whom? How can its efficiency be improved? (iii) Can platforms’ strategy on revenue sharing with drivers be improved? (iv) What is the value generated by ride-hailing services, including hosting rival taxi services on ride-hailing apps? Methodology/results : We develop a discrete choice model for the formation of mutually dependent demand (customer side) and supply (driver side) that jointly determine pricing. Using this model and a comprehensive data set obtained from the largest mobile ride platform in China, we estimate customer and driver price elasticities and other factors that affect market participation for the company’s two main markets, namely, basic ride-hailing and taxi services. Based on these estimation results and counterfactual analysis, we demonstrate that surge pricing improves customer and driver welfare as well as platform revenues while counterintuitively reducing taxi revenues on the platform. However, surge pricing should be avoided during nonpeak hours because it can hurt both customer and platform surplus. We show that platform revenues can be improved by increasing drivers’ revenue share from the current levels. Finally, we estimate that the platform’s basic ride-hailing services generated customer value equivalent to $13.25 billion in China in 2024, and hosting rival taxi services on the platform boosted customer surplus by $3.6 billion. Managerial implications : Our empirical framework provides ride-hailing companies a way to estimate demand and supply functions, which can help with optimization of multiple aspects of their operations. Our findings suggest that ride-hailing platforms can improve profits by containing surge-pricing to peak hours only and boosting supply by increasing driver compensation. Finally, our results demonstrate that restricting ride-hailing services create significant welfare losses, whereas including taxi services on ride-hail platforms generates substantial economic value. Supplemental Material: The online appendix is available at https://doi.org/10.1287/msom.2022.0502 .},
  archive      = {J_MSOM},
  doi          = {10.1287/msom.2022.0502},
  journal      = {Manufacturing & Service Operations Management},
  month        = {9-10},
  number       = {5},
  pages        = {1551-1570},
  shortjournal = {Manuf. Serv. Oper. Manag.},
  title        = {Market formation, pricing, and value generation in ride-hailing services},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Managing quality on two-sided platforms in the presence of provider competition. <em>MSOM</em>, <em>27</em>(5), 1532-1550. (<a href='https://doi.org/10.1287/msom.2023.0326'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem definition : We study two-sided markets in which competing platforms enforce service standards to control access of providers with heterogeneous service quality and employ pricing strategies to balance supply and demand. We further investigate the effectiveness of launching regulations, aimed to maximize social welfare, in enhancing quality, and we examine multihoming to yield additional insights. Methodology/results : We build a game-theoretic model wherein two platforms enforce service standards and prices, based on which heterogeneous providers and consumers decide whether and which platform to enroll. The transaction revenue from service matches is shared between the platform and the providers according to a pricing scheme, which comprises a service fee and a commission rate. Our results reveal that platforms’ strategies for balancing supply and demand depend on the consumer-to-provider ratio (termed as consumer size) and the value of high-quality service relative to that of low-quality service (termed as service value). Managerial implications : The standards enforced by platforms are not always monotone with respect to consumer size or service value. A large influx of consumers prompts platforms to enforce a high standard when service value is sufficiently high. Platforms can enforce different service standards, albeit only when they compete to balance providers and consumers. Platform competition can be a substitute for regulation in upholding and enhancing quality, especially when the commission rate is high. Regulation is more effective in enhancing quality on a monopolistic platform than on competing platforms. Relative to single homing, multihoming has inconsequential effects on the pattern for the enforcement of service standards, whereas it may lead platforms to raise prices. We alert regulators to consumer size, service value, and pricing scheme in addressing quality concerns in two-sided markets. Fostering competition can be more effective than launching regulations to enhance quality on platforms. Funding: The research of L. Jiang is supported in part by the National Natural Science Foundation of China [Grant 72171204] and the Research Grants Council of the Hong Kong General Research Fund [Grant PolyU15500922]. The research of X. Zhao is supported in part by the Natural Sciences and Engineering Research Council of Canada [Discovery Grant 06690], the Einwechter Faculty Research Grant, and the Lazaridis Institute Seed Fund. Supplemental Material: The online appendix is available at https://doi.org/10.1287/msom.2023.0326 .},
  archive      = {J_MSOM},
  doi          = {10.1287/msom.2023.0326},
  journal      = {Manufacturing & Service Operations Management},
  month        = {9-10},
  number       = {5},
  pages        = {1532-1550},
  shortjournal = {Manuf. Serv. Oper. Manag.},
  title        = {Managing quality on two-sided platforms in the presence of provider competition},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balancing supply with demand on ride-hailing platforms in markets with price regulations: An operational approach. <em>MSOM</em>, <em>27</em>(5), 1515-1531. (<a href='https://doi.org/10.1287/msom.2022.0216'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem definition : Ride-hailing platforms face a supply-demand imbalance. During peak periods, the demand from passengers far exceeds the supply of drivers, whereas during off-peak periods, there is an abundance of supply but weak demand. The well-studied surge pricing can be challenging to implement in markets where prices are subject to regulation and are inflexible to adjust. We study an alternative operational approach that shifts the supply of drivers from off-peak to peak periods to address the supply-demand imbalance. Methodology/results : We propose two novel incentive schemes: the qualification scheme and the prioritization scheme. Specifically, the platform sets a work target for the peak period. Under the qualification scheme, the platform assigns off-peak service requests only to drivers who meet the peak period target. Under the prioritization scheme, the platform prioritizes off-peak requests for drivers who meet the peak period target. We analyze the effectiveness of these schemes, considering the openness of the platform’s supply system. For platforms with a closed system that only allows full-time drivers to provide service, the qualification scheme improves the total matching volume to a greater extent but hurts full-time drivers more than the prioritization scheme. For platforms with an open system that also allows the abundant part-time drivers to serve off-peak requests, the prioritization scheme outperforms the qualification scheme in improving total matching volume. Furthermore, the implementation of an incentive scheme in an open system may benefit both the platform and full-time drivers. Managerial implications : Our study suggests an alternative to surge pricing for on-demand platforms to address the supply-demand imbalance when prices are inflexible. It provides insights for platforms with varying levels of supply system openness in choosing appropriate incentive schemes. The welfare results offer guidance for platforms and policymakers regarding both matching volume and worker welfare. Funding: This work was supported by the National Natural Science Foundation of China [Grant 61771331]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/msom.2022.0216 .},
  archive      = {J_MSOM},
  doi          = {10.1287/msom.2022.0216},
  journal      = {Manufacturing & Service Operations Management},
  month        = {9-10},
  number       = {5},
  pages        = {1515-1531},
  shortjournal = {Manuf. Serv. Oper. Manag.},
  title        = {Balancing supply with demand on ride-hailing platforms in markets with price regulations: An operational approach},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mental accounting in allocating capacity. <em>MSOM</em>, <em>27</em>(5), 1497-1514. (<a href='https://doi.org/10.1287/msom.2024.0804'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem definition : This study investigates a seller’s allocation of a limited resource to sequentially arriving customers when the seller is influenced by two types of mental accounting bias: prospective accounting (overestimating future revenue) and behavioral discounting (underestimating future revenue). Methodology/results : We establish structural properties on how mental accounting affects capacity allocation decisions and performance. Interestingly, whereas additional capacity consistently benefits the seller, the same does not hold true for additional demands. That is, an additional class of demand can hurt the seller, depending on the type of mental accounting. This is true even if the additional demand class has a higher reservation price than existing ones. Managerial implications : This result highlights the importance for companies to address and mitigate biases in decision makers before embarking on market expansion initiatives through promotions and advertising campaigns. Supplemental Material: The online appendix is available at https://doi.org/10.1287/msom.2024.0804 .},
  archive      = {J_MSOM},
  doi          = {10.1287/msom.2024.0804},
  journal      = {Manufacturing & Service Operations Management},
  month        = {9-10},
  number       = {5},
  pages        = {1497-1514},
  shortjournal = {Manuf. Serv. Oper. Manag.},
  title        = {Mental accounting in allocating capacity},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal policy for inventory management with periodic and controlled resets. <em>MSOM</em>, <em>27</em>(5), 1484-1496. (<a href='https://doi.org/10.1287/msom.2022.0318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem definition : Inventory management problems with periodic and controllable resets occur in the context of managing water storage in the developing world and dynamically optimizing endcap promotion duration in retail outlets. In this paper, we consider a set of sequential decision problems in which the decision maker must not only balance holding and shortage costs but discard all inventory before a fixed number of decision epochs with the option for an early inventory reset. Methodology/results : Finding optimal policies for these problems through dynamic programming presents unique challenges because of the nonconvex nature of the resulting value functions. Moreover, this structure cannot be readily analyzed even with extended convexity definitions, such as K -convexity. Managerial implications : Our key contribution is to present sufficient conditions that ensure the optimal policy has an easily interpretable structure, which generalizes the well-known ( s , S ) policy from the operations management literature. Furthermore, we demonstrate that, under these rather mild conditions, the optimal policy exhibits a four-threshold structure. We then conclude with computational experiments, thereby illustrating the policy structures that can be extracted in various inventory management scenarios. Funding: This work was supported by the National Science Foundation [Grant CMMI-1847666] and the Division of Graduate Education [Grant DGE-2125913]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/msom.2022.0318 .},
  archive      = {J_MSOM},
  doi          = {10.1287/msom.2022.0318},
  journal      = {Manufacturing & Service Operations Management},
  month        = {9-10},
  number       = {5},
  pages        = {1484-1496},
  shortjournal = {Manuf. Serv. Oper. Manag.},
  title        = {Optimal policy for inventory management with periodic and controlled resets},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The value of online interactions for store execution. <em>MSOM</em>, <em>27</em>(5), 1464-1483. (<a href='https://doi.org/10.1287/msom.2024.1290'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem definition : Omnichannel retailers interact with customers both online and offline. So far, they have used the richer information available—gathered from customer interactions across digital and physical channels—to optimize the sales process by designing the right channel and supply chain structures and by personalizing offers, pricing, and promotions. We advance an additional dimension of omnichannel value: retailers can use online clickstreams to better understand customer needs and optimize store layouts to maximize webrooming conversion , which we define as the ratio of sales to webrooming activity. Methodology/results : We develop a model in which in-store purchases depend on the customer’s shopping list and the effort required to locate and reach the products within the store. Category location in the store thus drives the likelihood of a sale. We then apply our model to a large home improvement retailer and find that shoppers’ preferences are revealed by nearby online traffic and hard-to-reach locations lead to lower webrooming conversion. Finally, we optimize category location assignments using our demand model and find that putting higher-interest and higher-price items in the most effective locations can increase revenues by about 2%–5% in comparison with models that ignore online clicks. Managerial implications : We show how using online clickstream information for optimizing offline operations can create significant value. More fundamentally, our results provide a word of caution that in some retailing segments such as home improvement, longer in-store paths might not necessarily be better. Funding: V. Martínez-de-Albéniz acknowledges the financial support provided by the Agencia Estatal de Investigación (AEI) from the Spanish Ministry of Science and Innovation [Grant PID2020-116135GB-I00 MCIN/AEI/10.13039/501100011033]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/msom.2024.1290 .},
  archive      = {J_MSOM},
  doi          = {10.1287/msom.2024.1290},
  journal      = {Manufacturing & Service Operations Management},
  month        = {9-10},
  number       = {5},
  pages        = {1464-1483},
  shortjournal = {Manuf. Serv. Oper. Manag.},
  title        = {The value of online interactions for store execution},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-control in the face of multiple projects. <em>MSOM</em>, <em>27</em>(5), 1449-1463. (<a href='https://doi.org/10.1287/msom.2025.0426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem definition : We study how people with present bias make choices when they face multiple projects. Each project consists of a starting and a finishing stage, both requiring costly effort to complete but yield rewards only after project completion. Methodology/results : We derive people’s perception-perfect strategies for project scheduling. Naifs may start a project, but never finish it. They may multitask; that is, start a new project before finishing an old project. They may not prioritize projects by NPV. Sophisticates do not start a project but not finish it. However, like naifs, they may multitask and not prioritize projects by NPV. What happens if people can choose the cost structure endogenously? If people multitask when the cost structure is exogenously given, then when the cost structure can be chosen by them, naifs delay the costs to the finishing stages as much as possible, resulting in either multitasking or procrastination. If, in addition, the project with a higher NPV has a lower total cost, then naifs prioritize projects by NPV. Sophisticates, however, may not always delay the costs to finishing stages when given a choice because delaying the costs may lead to multitasking, which decreases the utility and they, unlike naifs, are fully aware of. Therefore, under endogenous cost structure, sophisticates may or may not multitask or prioritize projects by NPV. Managerial implications : Enhancing individuals’ awareness of their present bias makes them less likely to behave sub-optimally. Increasing load can also, though not always, alleviate procrastination and reduce the possibility of multitasking and not prioritizing projects based on NPV. When project portfolios are predetermined, increasing awareness of present bias always improves people’s long-run utility. However, when project portfolios are selected endogenously, sophistication does not always pay because naifs may either complete more projects or complete a more profitable project than sophisticates. Funding: P. Yu was supported by the National Natural Science Foundation of China [Grants 72371038 and 72033003]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/msom.2025.0426 .},
  archive      = {J_MSOM},
  doi          = {10.1287/msom.2025.0426},
  journal      = {Manufacturing & Service Operations Management},
  month        = {9-10},
  number       = {5},
  pages        = {1449-1463},
  shortjournal = {Manuf. Serv. Oper. Manag.},
  title        = {Self-control in the face of multiple projects},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Waiting time prediction with invisible customers. <em>MSOM</em>, <em>27</em>(5), 1433-1448. (<a href='https://doi.org/10.1287/msom.2022.0098'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem definition : Motivated by technological advances in real-time data collection about customers location in service systems, we study the effect of partial visibility of customers on waiting time prediction. We consider systems where the predictor observes only a subset of the customers interacting with the system while serving all customers indiscriminately. Methodology/results : We formulate a novel model of a partially visible queue and analyze the waiting time prediction problem, deriving a closed-form expression for the optimal prediction. This facilitates quantifying the performance loss of arbitrary prediction methods because of partial visibility and their inherent limitations (i.e., bias and variance). We compare the performance of a wide range of commonly used predictive methods and examine how partial visibility along with other system parameters affects their performance. We further extend these numerical analyses to queueing systems that exhibit characteristics that are common in practice and that were studied in the service operations literature. Managerial implications : Our analysis shows that the phenomenon of invisible customers profoundly impacts the ability to accurately predict waiting times and should, therefore, be considered an important factor in the development of prediction tools. Such tools cannot be effectively deployed if technological barriers or operational limitations prevent a sufficiently high level of data integrity. This work provides specific insights into the effectiveness of various commonly used prediction methods, some of which are shown to be highly sensitive to partial visibility and other queueing systems characteristics. Our findings suggest that machine learning methods that use carefully chosen features offer the most effective generic solution for waiting time prediction in the presence of invisible customers and explain the mechanisms through which partial visibility deteriorates the performance of prediction methods. Supplemental Material: The online appendix is available at https://doi.org/10.1287/msom.2022.0098 .},
  archive      = {J_MSOM},
  doi          = {10.1287/msom.2022.0098},
  journal      = {Manufacturing & Service Operations Management},
  month        = {9-10},
  number       = {5},
  pages        = {1433-1448},
  shortjournal = {Manuf. Serv. Oper. Manag.},
  title        = {Waiting time prediction with invisible customers},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Does transparency hinder technological novelty? evidence from large pharmaceutical firms. <em>MSOM</em>, <em>27</em>(5), 1415-1432. (<a href='https://doi.org/10.1287/msom.2023.0527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem definition : The drug development process has historically lacked transparency, leading to selective reporting of clinical trial results. Although clinical trial transparency aims to address this issue, increased public scrutiny may make managers more risk averse, potentially stifling novel research and development (R&D) initiatives. This raises the following question. Does transparency hinder technologically novel R&D? Methodology/results : Using data from nearly 10,000 clinical trials from 2000 to 2014, we examine how a 2005 policy to increase transparency affects drug novelty. Using a continuous difference-in-differences approach, we find that transparency prompts firms to rely more on previously used technologies (i.e., exploitative R&D) without reducing their pursuit of never-before-tested technologies (i.e., exploratory R&D). We identify negative informational spillovers as a mechanism; technology failures that are now more visible because of transparency could erode confidence in related trials, prompting firms toward familiar technologies to avoid reputational damage. Consistent with this mechanism, the impact of transparency is strongest among firms with less-diversified portfolios that are the most exposed to negative informational spillovers. Managerial implications : Our primary theoretical contribution is in demonstrating the unintended negative impact of transparency on novelty. For managers, we highlight diversification as a mitigation strategy. We urge policymakers to create incentives to support novel R&D despite transparency pressures. Supplemental Material: The online appendix is available at https://doi.org/10.1287/msom.2023.0527 .},
  archive      = {J_MSOM},
  doi          = {10.1287/msom.2023.0527},
  journal      = {Manufacturing & Service Operations Management},
  month        = {9-10},
  number       = {5},
  pages        = {1415-1432},
  shortjournal = {Manuf. Serv. Oper. Manag.},
  title        = {Does transparency hinder technological novelty? evidence from large pharmaceutical firms},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic care unit placements under unknown demand with learning. <em>MSOM</em>, <em>27</em>(5), 1396-1414. (<a href='https://doi.org/10.1287/msom.2022.0260'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem definition : Care units are the facilities where admitted hospital patients receive treatment and monitoring services. This paper studies the problem of deciding which patients to place into the various available care units at any time. To determine placements in practice, hospitals rely on clinicians to discern a patient’s care needs and appropriately trade-off between future demand and limited bed availability. Making the right decisions remains challenging because patients are heterogeneous, and demand is uncertain. Methodology/results : We develop a dynamic resource allocation algorithm to decide unit placements by learning the care needs of different patient types. We model hospital beds as reusable resources and assume decision feedback is not immediately available, but rather delayed for an unknown and random length of time. Lastly, we consider the demand to be unknown and allow patient arrivals to be arbitrarily sequenced for robustness. The applicability of our algorithm is demonstrated with real-patient data from a hospital collaboration, where we evaluate our proposed approach using unplanned readmission rates as the performance metric. From extensive simulations, our results suggest the proposed algorithm tends to outperform several greedy benchmarks as well as a hospital benchmark model. A theoretical performance guarantee for our algorithm is provided to complement the case study. Managerial implications : This paper contributes new insights into designing dynamic decision-making models for hospital admissions operations. Our work presents a simple but effective data-driven support tool to help clinicians trade-off between available bed capacity and a patient’s care needs when making care unit placements. We also demonstrate how our algorithm can support the reduction of unplanned readmissions through improved placement decisions. Funding: This work was supported by National Science Foundation Graduate Research Fellowship Program [Grant DGE 1256260]. Partial support for this research was provided to the first-author (A. Dean) by the National Science Foundation Graduate Research Fellowship under Grant DGE1841052. Any opinion, findings, and conclusions or recommendations expressed in this material are those of the authors(s) and do not necessarily reflect the views of the National Science Foundation. Supplemental Material: The online appendix is available at https://doi.org/10.1287/msom.2022.0260 .},
  archive      = {J_MSOM},
  doi          = {10.1287/msom.2022.0260},
  journal      = {Manufacturing & Service Operations Management},
  month        = {9-10},
  number       = {5},
  pages        = {1396-1414},
  shortjournal = {Manuf. Serv. Oper. Manag.},
  title        = {Dynamic care unit placements under unknown demand with learning},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Waiting online vs. in person: An empirical study on outpatient clinic visit incompletion. <em>MSOM</em>, <em>27</em>(5), 1377-1395. (<a href='https://doi.org/10.1287/msom.2023.0365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem definition : The adoption of online services, such as telemedicine, has increased rapidly over the last few years. To better manage online services and effectively integrate them with in-person services, we need to better understand customer behaviors under the two service modalities. Utilizing data from two large internal medicine outpatient clinics, we take an empirical approach to study service incompletion, which can be because of either patient no-show or leaving without being seen. Methodology/results : We focus on estimating the causal effect of whether the provider has cleared prior appointments—used as a proxy of intraday delay—on service incompletion for in-person and telemedicine appointments, respectively. When providers have not cleared prior appointments, patients may have to wait, making them more likely to leave without being seen, leading to a higher service incompletion rate. We introduce a multivariate probit model with instrumental variables to handle estimation challenges because of endogeneity, sample selection, and measurement error. We also conduct a numerical analysis of the intraday sequencing rule when having both telemedicine and in-person patients. Our estimation results show that intraday delay increases the telemedicine service incompletion rate by 7.40%, but it does not have a significant effect on the in-person service incompletion rate. Managerial implications : Our study suggests that telemedicine patients may leave without being seen, whereas in-person patients are not sensitive to intraday delay. More importantly, failing to properly distinguish between incompletions caused by intraday delays and those resulting from no-shows can lead to highly inferior patient sequencing decisions. Supplemental Material: The online appendix is available at https://doi.org/10.1287/msom.2023.0365 .},
  archive      = {J_MSOM},
  doi          = {10.1287/msom.2023.0365},
  journal      = {Manufacturing & Service Operations Management},
  month        = {9-10},
  number       = {5},
  pages        = {1377-1395},
  shortjournal = {Manuf. Serv. Oper. Manag.},
  title        = {Waiting online vs. in person: An empirical study on outpatient clinic visit incompletion},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Test allocation and pool composition in heterogenous populations under strict capacity constraints. <em>MSOM</em>, <em>27</em>(5), 1362-1376. (<a href='https://doi.org/10.1287/msom.2021.0149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem definition : Motivated by the persistent lack of testing capacity in the first year of the COVID-19 pandemic, we study the question “who should be tested?” when there are general costs and rewards, testing capacity is strictly limited, tests have errors, and patients differ in their prior probability of being infected. We specifically study how the answer to that question changes when pooled testing, a method of grouping samples to conserve tests, is an option. Methodology/results : We use a two-stage stochastic optimization model with recourse, incorporating costs and rewards for different test outcomes, under a conservative capacity constraint that reflects severe shortages of tests or high uncertainty about future test availability. This setting reflects the situation decision makers faced at the beginning of the COVID-19 pandemic in March 2020. Although health officials might intuitively prioritize testing patients who are highly likely to be infected, we find that it may be better to focus on patients who are less likely to be infected, particularly when the test has low sensitivity (i.e., the false-negative rate is substantial). Moreover, it may be optimal to test two groups of individuals: those who are very unlikely to be infected (in pools) and those who are very likely to be infected (individually). Managerial implications : We develop a heuristic policy supported by the analysis, which indicates when pooling should be used and which type of samples should be tested. In some settings, the decision may be characterized simply by understanding the costs and rewards involved. In more complex testing settings, the characteristics of the test and the size of the pool affect the desirability of pooling: Lower specificity, higher sensitivity, and larger pool sizes all result in testing environments that are more favorable to pooling. Managers and policymakers should understand how characteristics of the test and the setting impact whether it is optimal to test patients who are deemed likely to test positive or those who are likely to test negative. Incorporating pooling as a test strategy may change which patients should be prioritized for a test. Our results can inform both public health policy and healthcare operations management in settings where testing capacity is strictly limited. Funding: This work was supported by the Division of Civil, Mechanical and Manufacturing Innovation [Grant 1634822]. S. Ziya was supported by the National Science Foundation [Award CMMI1635574]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/msom.2021.0149 .},
  archive      = {J_MSOM},
  doi          = {10.1287/msom.2021.0149},
  journal      = {Manufacturing & Service Operations Management},
  month        = {9-10},
  number       = {5},
  pages        = {1362-1376},
  shortjournal = {Manuf. Serv. Oper. Manag.},
  title        = {Test allocation and pool composition in heterogenous populations under strict capacity constraints},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The role of family engagement in influencing patient satisfaction and readmission. <em>MSOM</em>, <em>27</em>(5), 1344-1361. (<a href='https://doi.org/10.1287/msom.2023.0734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem definition : Family engagement (FE) is an ongoing partnership between health professionals and patients’ families to enhance healthcare quality, safety, and delivery. Although FE is increasingly considered an essential component of patient-centered care, its importance in influencing healthcare delivery outcomes is unclear. This study examines the impact of FE on patient care outcomes (PCOs)—specifically, patient satisfaction (PS) and readmission (Readm)—in the context of varying severity of illness (SOI). Methodology/results : Using secondary data from South Korea, this study develops an integrated framework to examine the relationships between FE, SOI, and PCOs. The methodology involves a two-stage treatment effects model to address endogeneity in FE, supplemented by instrumental variable estimations for SOI. The findings reveal that patients with FE exhibit improved PS and lower Readm. Additionally, FE lessens the negative impact of SOI on these outcomes. The study also explores how the benefits of FE vary depending on the nature of the patient’s relationship with their family, distinguishing between family members living together and separately. We also conduct structured interviews to validate the mechanisms supporting these relationships and identify implications for practice. Managerial implications : The findings have significant implications for healthcare operations management (HOM). Hospitals can develop family-centered policies and training programs, emphasizing the importance of FE in patient care, especially for severely ill patients. Healthcare professionals can benefit from understanding the dynamics between FE, SOI, and PCOs, guiding the development of curricula that focus on family-centered care. Overall, the study underscores the importance of integrating FE into HOM to enhance the quality of patient care. Supplemental Material: The online appendix is available at https://doi.org/10.1287/msom.2023.0734 .},
  archive      = {J_MSOM},
  doi          = {10.1287/msom.2023.0734},
  journal      = {Manufacturing & Service Operations Management},
  month        = {9-10},
  number       = {5},
  pages        = {1344-1361},
  shortjournal = {Manuf. Serv. Oper. Manag.},
  title        = {The role of family engagement in influencing patient satisfaction and readmission},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OM Forum–Working with practitioners in operations management. <em>MSOM</em>, <em>27</em>(5), 1333-1343. (<a href='https://doi.org/10.1287/msom.2025.0147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem definition : Collaborations between researchers and practitioners in operations management are becoming more common, and they can bridge the gap between theory and real-world application. This paper explores the process of managing such collaborations, emphasizing the importance of mutual trust, stakeholder management, and the alignment of academic rigor with practical value. Methodology/results : Drawing on experience and previous operations management literature, the study describes the operational steps of working with practitioners. It outlines a five-phase framework that can guide successful practitioner collaboration research: relationship building, stakeholder management, study design, study implementation, and poststudy management. The framework illustrates how rigorous research methods can be embedded in partner relationships that are governed by trust and ethical sensitivity, the success of which may sustain long-term academic-practitioner collaborations. Managerial implications : This paper offers a five-step road map for academics to undertake collaborations with practitioners that can generate theoretically sound as well as impactful research outcomes.},
  archive      = {J_MSOM},
  doi          = {10.1287/msom.2025.0147},
  journal      = {Manufacturing & Service Operations Management},
  month        = {9-10},
  number       = {5},
  pages        = {1333-1343},
  shortjournal = {Manuf. Serv. Oper. Manag.},
  title        = {OM Forum–Working with practitioners in operations management},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="or">OR - 32</h2>
<ul>
<li><details>
<summary>
(2025). A robust optimization approach to network control using local information exchange. <em>OR</em>, <em>73</em>(5), 2849-2866. (<a href='https://doi.org/10.1287/opre.2020.0217'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing policies for a network of agents is typically done by formulating an optimization problem where each agent has access to state measurements of all the other agents in the network. Such policy designs with centralized information exchange result in optimization problems that are typically hard to solve, require establishing substantial communication links, and do not promote privacy since all information is shared among the agents. Designing policies based on arbitrary communication structures can lead to nonconvex optimization problems that are typically NP-hard. In this work, we propose an optimization framework for decentralized policy designs. In contrast to the centralized information exchange, our approach requires only local communication exchange among the neighboring agents matching the physical coupling of the network. Thus, each agent only requires information from its direct neighbors, minimizing the need for excessive communication and promoting privacy amongst the agents. Using robust optimization techniques, we formulate a convex optimization problem with a loosely coupled structure that can be solved efficiently. We numerically demonstrate the efficacy of the proposed approach in energy management and supply chain applications. We show that the proposed approach leads to solutions that closely approximate those obtained by the centralized formulation only at a fraction of the computational effort. Funding: This research was supported by the Swiss National Science Foundation [Grant 51NF40_180545 under the National Centres of Competence in Research (NCCR) Automation and Grant P2ELP2_195149, Early Postdoc Mobility Fellowship]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2020.0217 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2020.0217},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2849-2866},
  shortjournal = {Oper. Res.},
  title        = {A robust optimization approach to network control using local information exchange},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Regular variable returns to scale production frontier and efficiency measurement. <em>OR</em>, <em>73</em>(5), 2830-2848. (<a href='https://doi.org/10.1287/opre.2021.0470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The most frequently used empirical production frontier in data envelopment analysis, the variable returns to scale frontier, has a convex technology set and displays a special structure in economics, called the regular variable returns to scale in this paper; the production technology exhibits increasing returns to scale at the beginning of the production process followed by constant returns to scale and decreasing returns to scale. When the assumption of convexity is relaxed, modeling regular variable returns to scale becomes difficult, and currently, no satisfactory solution is available in multioutput production. Overcoming these difficulties, this paper adopts a suggestion in literature to incorporate regular variable returns to scale into the free disposal hull frontier under multiple outputs. We establish a framework for analyzing regular variable returns to scale and recommend an empirical production frontier for measuring technical efficiency with such pattern and multiple outputs. In the presence of regular variable returns to scale without convexity, the value of the technical efficiency measure computed from this new frontier is closer to the “true” value than that from the free disposal hull frontier, and the conventional variable returns to scale frontier may cause misleading implications. Funding: This research was partially supported by the National Natural Science Foundation of China [Grants 72001061 and 72243002], Hong Kong Shue Yan University [University Research Grant URG/20/01], and the Research Grants Council of the Hong Kong Special Administrative Region [Faculty Development Scheme/UGC/FDS15/E02/21]. Supplemental Material: The computer code and data that support the findings of this study are available within this article’s supplemental material at https://doi.org/10.1287/opre.2021.0470 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0470},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2830-2848},
  shortjournal = {Oper. Res.},
  title        = {Regular variable returns to scale production frontier and efficiency measurement},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robustifying conditional portfolio decisions via optimal transport. <em>OR</em>, <em>73</em>(5), 2801-2829. (<a href='https://doi.org/10.1287/opre.2021.0243'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a data-driven portfolio selection model that integrates side information, conditional estimation, and robustness using the framework of distributionally robust optimization. Conditioning on the observed side information, the portfolio manager solves an allocation problem that minimizes the worst-case conditional risk-return tradeoff, subject to all possible perturbations of the covariate-return probability distribution in an optimal transport ambiguity set. Despite the nonlinearity of the objective function in the probability measure, we show that the distributionally robust portfolio allocation with a side information problem can be reformulated as a finite-dimensional optimization problem. If portfolio decisions are made based on either the mean-variance or the mean-conditional value-at-risk criterion, the reformulation can be further simplified to second-order or semidefinite cone programs. Empirical studies in the U.S. equity market demonstrate the advantage of our integrative framework against other benchmarks. Funding: The material in this paper is based on work supported by the Air Force Office of Scientific Research [Award FA9550-20-1-0397]. Additional support is gratefully acknowledged from the National Science Foundation [Grants 1915967, 1820942, and 1838676], the Natural Sciences and Engineering Research Council of Canada [Grant RGPIN-2016-05208], and the China Merchant Bank. V. A. Nguyen gratefully acknowledges the generous support from the Chinese University of Hong Kong [Improvement on Competitiveness in Hiring New Faculties Funding Scheme] and the Chinese University of Hong Kong [Direct Grant 4055191]. S. Wang is partially supported by the National Natural Science Foundation of China [Grant 72371022]. Finally, this research was enabled in part by support provided by Compute Canada. Supplemental Material: The computer code and data that support the findings of this study and the online appendix are available within this article’s supplemental material at https://doi.org/10.1287/opre.2021.0243 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0243},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2801-2829},
  shortjournal = {Oper. Res.},
  title        = {Robustifying conditional portfolio decisions via optimal transport},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hierarchical approach to robust stability of multiclass queueing networks. <em>OR</em>, <em>73</em>(5), 2782-2800. (<a href='https://doi.org/10.1287/opre.2023.0147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit the global—relative to control policies—stability of multiclass queueing networks. In these, as is known, it is generally insufficient that the nominal utilization at each server is below 100%. Certain policies, although work conserving, may destabilize a network that satisfies the nominal-load conditions; additional conditions on the primitives are needed for global stability (stability under any work-conserving policy). The global-stability region was fully characterized for two-station networks in Dai and Vande Vate [Dai JG, Vande Vate JH (1996) Global stability of two-station queueing networks. Stochastic Networks (Springer, New York), 1–26.] but a general framework for networks with more than two stations remains elusive. In this paper, we offer progress on this front by considering a subset of nonidling control policies, namely, queue-ratio (QR) policies. These include as special cases all static-priority policies. With this restriction, we are able to introduce a complete framework that applies to networks of any size. Our framework breaks the analysis of robust QR stability (stability under any QR policy) into (i) robust state-space collapse, and (ii) robust stability of the Skorohod problem (SP) representing the fluid workload. Sufficient conditions for both are specified in terms of simple optimization problems. We use these optimization problems to prove that the family of QR policies satisfies a weak form of convexity relative to policies. A direct implication of this convexity is that if the SP is stable for all static-priority policies (the “extreme” QR policies), then it is also stable under any QR policy. Whereas robust QR stability is weaker than global stability, our framework recovers necessary and sufficient conditions for global stability in specific networks. Funding: This work was supported by the National Science Foundation [Grant CMMI-1856511]. Supplemental Material: All supplemental materials, including the computer code and data that support the findings of this study, are available at https://doi.org/10.1287/opre.2023.0147 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0147},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2782-2800},
  shortjournal = {Oper. Res.},
  title        = {A hierarchical approach to robust stability of multiclass queueing networks},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convolution bounds on quantile aggregation. <em>OR</em>, <em>73</em>(5), 2761-2781. (<a href='https://doi.org/10.1287/opre.2021.0765'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantile aggregation with dependence uncertainty has a long history in probability theory, with wide applications in finance, risk management, statistics, and operations research. Using a recent result on inf-convolution of quantile-based risk measures, we establish new analytical bounds for quantile aggregation, which we call convolution bounds. Convolution bounds both unify every analytical result available in quantile aggregation and enlighten our understanding of these methods. These bounds are the best available in general. Moreover, convolution bounds are easy to compute, and we show that they are sharp in many relevant cases. They also allow for interpretability on the extremal dependence structure. The results directly lead to bounds on the distribution of the sum of random variables with arbitrary dependence. We discuss relevant applications in risk management and economics. Funding: This work was supported by the Guangdong Provincial Key Laboratory of Mathematical Foundations for Artificial Intelligence [Grant 2023B1212010001]; The Chinese University of Hong Kong (Shenzhen) research startup fund [Grant UDF01003336]; Natural Sciences and Engineering Research Council of Canada [Grants CRC-2022-00141 and RGPIN-2024-03728]; Shenzhen Science and Technology Program [Grant RCBS20231211090814028]; National Science Foundation [Grants 1915967, 2118199, 2229011, CAREER CMMI-1834710, and IIS-1849280]; Air Force Office of Scientific Research [Grant FA9550-20-1-0397]; and National Natural Science Foundation of China [Grant 12401624]. Supplemental Material: All supplemental materials, including the computer code and data that support the findings of this study, are available at https://doi.org/10.1287/opre.2021.0765 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0765},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2761-2781},
  shortjournal = {Oper. Res.},
  title        = {Convolution bounds on quantile aggregation},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Near-optimal adaptive policies for serving stochastically departing customers. <em>OR</em>, <em>73</em>(5), 2744-2760. (<a href='https://doi.org/10.1287/opre.2022.0548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a multistage stochastic optimization problem, studying how a single server should prioritize stochastically departing customers. In this setting, our objective is to determine an adaptive service policy that maximizes the expected total reward collected along a discrete planning horizon, in the presence of customers who are independently departing between one stage and the next with known stationary probabilities. Despite its deceiving structural simplicity, we are unaware of nontrivial results regarding the rigorous design of optimal or truly near-optimal policies at present time. Our main contribution resides in proposing a quasi-polynomial-time approximation scheme for serving impatient customers. Specifically, letting n be the number of underlying customers, our algorithm identifies in O ( n O ϵ ( log 2 n ) ) time a service policy whose expected reward is within factor 1 − ϵ of the optimal adaptive reward. Our method for deriving this approximation scheme synthesizes various stochastic analyses in order to investigate how the adaptive optimum is affected by alterations to several instance parameters, including the reward values, the departure probabilities, and the collection of customers itself. Funding: This work was supported by the Israel Science Foundation [1407/20]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2022.0548 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0548},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2744-2760},
  shortjournal = {Oper. Res.},
  title        = {Near-optimal adaptive policies for serving stochastically departing customers},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximating the set of nash equilibria for convex games. <em>OR</em>, <em>73</em>(5), 2729-2743. (<a href='https://doi.org/10.1287/opre.2023.0541'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Feinstein and Rudloff (2024) , it was shown that the set of Nash equilibria for any noncooperative N player game coincides with the set of Pareto optimal points of a certain vector optimization problem with nonconvex ordering cone. To avoid dealing with a nonconvex ordering cone, an equivalent characterization of the set of Nash equilibria as the intersection of the Pareto optimal points of N multi-objective problems (i.e., with the natural ordering cone) is proven. So far, algorithms to compute the exact set of Pareto optimal points of a multi-objective problem exist only for the class of linear problems, which reduces the possibility of finding the true set of Nash equilibria by those algorithms to linear games only. In this paper, we will consider the larger class of convex games. Because typically only approximate solutions can be computed for convex vector optimization problems, we first show, in total analogy to the result above, that the set of ϵ -approximate Nash equilibria can be characterized by the intersection of ϵ -approximate Pareto optimal points for N convex multi-objective problems. Then, we propose an algorithm based on results from vector optimization and convex projections that allows for the computation of a set that, on one hand, contains the set of all true Nash equilibria and is, on the other hand, contained in the set of ϵ -approximate Nash equilibria. In addition to the joint convexity of the cost function for each player, this algorithm works provided the players are restricted by either shared polyhedral constraints or independent convex constraints. Funding: This work was supported by Austrian Science Funds (FWF) [W1260-N35]. Supplemental Material: The computer code and data that support the findings of this study are available within this article’s supplemental material at https://doi.org/10.1287/opre.2023.0541 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0541},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2729-2743},
  shortjournal = {Oper. Res.},
  title        = {Approximating the set of nash equilibria for convex games},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The analytics of robust satisficing: Predict, optimize, satisfice, then fortify. <em>OR</em>, <em>73</em>(5), 2708-2728. (<a href='https://doi.org/10.1287/opre.2023.0199'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel approach to prescriptive analytics that leverages robust satisficing techniques to determine optimal decisions in situations of distribution ambiguity and parameter estimation uncertainty. Our decision model relies on a reward function that incorporates uncertain parameters, which can be predicted using available side information. However, the accuracy of the linear prediction model depends on the quality of regression coefficient estimates derived from the available data. To achieve a desired level of fragility under distribution ambiguity, we begin by solving a residual-based robust satisficing model in which the residuals from the regression are used to construct an estimated empirical distribution and a target is established relative to the predict-then-optimize objective value. In the face of estimation uncertainty, we then solve an estimation-fortified robust satisficing model that minimizes the influence of estimation uncertainty while ensuring that the solution would maintain at most the same level of fragility in achieving a less ambitious guarding target. Our approach is supported by statistical justifications, and we propose tractable models for various scenarios, such as saddle functions, two-stage linear optimization problems, and decision-dependent predictions. We demonstrate the effectiveness of our approach through case studies involving a wine portfolio investment problem and a multiproduct pricing problem using real-world data. Our numerical studies show that our approach outperforms the predict-then-optimize approach in achieving higher expected rewards and at lower risks when evaluated on the actual distribution. Notably, we observe significant improvements over the benchmarks, particularly in cases of limited data availability. Funding: The research of M. Sim was supported by the Ministry of Education, Singapore under its 2019 Academic Research Fund Tier 3 [Grant MOE-2019-T3-1-010]. The research of Q. Tang was supported by Nanyang Technological University [Start-Up Grant 020022-00001] and the Ministry of Education, Singapore [Tier 1 Grant 25010057]. The research of M. Zhou was supported by the National Natural Science Foundation of China [Grants 72301075 and 72293564/72293560]. The research of T. Zhu was supported by the National Natural Science Foundation of China [Grant 72401058]. Any opinions, findings, conclusions, or recommendations expressed in the material are those of the authors and do not necessarily reflect the views of the Ministry of Education, Singapore. Supplementary Material: The online appendix and computer code and data that support the findings of this study are available within this article’s supplemental material at https://doi.org/10.1287/opre.2023.0199 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0199},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2708-2728},
  shortjournal = {Oper. Res.},
  title        = {The analytics of robust satisficing: Predict, optimize, satisfice, then fortify},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ranking and contextual selection. <em>OR</em>, <em>73</em>(5), 2695-2707. (<a href='https://doi.org/10.1287/opre.2023.0378'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new ranking-and-selection procedure, called ranking and contextual selection, in which covariates provide context for data-driven decisions. Our procedure optimizes over a set of covariate design points off-line and then, given an actual observation of the covariate, makes an online decision based on classification—a distinctly new approach. We prove the existence of an experimental design that yields a pointwise probability of good selection guarantee and derive a postexperiment assessment of our procedure that provides an optimality gap upper bound with guaranteed coverage for decisions with respect to future covariates. We illustrate ranking and contextual selection with an application to assortment optimization using data available from Yahoo!. Funding: This work was supported by the National Science Foundation [Grant CMMI-2206973]. Supplemental Material: This article includes an online appendix and computer code and data supporting the study’s findings at https://doi.org/10.1287/opre.2023.0378 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0378},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2695-2707},
  shortjournal = {Oper. Res.},
  title        = {Ranking and contextual selection},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributionally constrained black-box stochastic gradient estimation and optimization. <em>OR</em>, <em>73</em>(5), 2680-2694. (<a href='https://doi.org/10.1287/opre.2021.0307'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider stochastic gradient estimation using only black-box function evaluations, where the function argument lies within a probability simplex. This problem is motivated from gradient-descent optimization procedures in multiple applications in distributionally robust analysis and inverse model calibration involving decision variables that are probability distributions. We are especially interested in obtaining gradient estimators where one or few sample observations or simulation runs apply simultaneously to all directions. Conventional zeroth-order gradient schemes such as simultaneous perturbation face challenges as the required moment conditions that allow the “canceling” of higher-order biases cannot be satisfied without violating the simplex constraints. We investigate a new set of required conditions on the random perturbation generator, which leads us to a class of implementable gradient estimators using Dirichlet mixtures. We study the statistical properties of these estimators and their utility in constrained stochastic approximation. We demonstrate the effectiveness of our procedures and compare with benchmarks via several numerical examples. Funding: The authors gratefully acknowledge support from the National Science Foundation [Grants CAREER CMMI-1834710 and IIS-1849280]. Supplemental Material: The computer code and data that support the findings of this study are available within this article’s supplemental material at https://doi.org/10.1287/opre.2021.0307 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0307},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2680-2694},
  shortjournal = {Oper. Res.},
  title        = {Distributionally constrained black-box stochastic gradient estimation and optimization},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning in inverse optimization: Incenter cost, augmented suboptimality loss, and algorithms. <em>OR</em>, <em>73</em>(5), 2661-2679. (<a href='https://doi.org/10.1287/opre.2023.0254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In inverse optimization (IO), an expert agent solves an optimization problem parametric in an exogenous signal. From a learning perspective, the goal is to learn the expert’s cost function given a data set of signals and corresponding optimal actions. Motivated by the geometry of the IO set of consistent cost vectors, we introduce the “incenter” concept, a new notion akin to the recently proposed circumcenter concept. Discussing the geometric and robustness interpretation of the incenter cost vector, we develop corresponding tractable convex reformulations that are in contrast with the circumcenter, which we show is equivalent to an intractable optimization program. We further propose a novel loss function called augmented suboptimality loss (ASL), a relaxation of the incenter concept for problems with inconsistent data. Exploiting the structure of the ASL, we propose a novel first-order algorithm, which we name stochastic approximate mirror descent . This algorithm combines stochastic and approximate subgradient evaluations, together with mirror descent update steps, which are provably efficient for the IO problems with discrete feasible sets with high cardinality. We implement the IO approaches developed in this paper as a Python package called InvOpt. Our numerical experiments are reproducible, and the underlying source code is available as examples in the InvOpt package. Funding: This work was partially supported by the European Research Council [Grant TRUST-949796]. Supplemental Review: The empirical results in this paper were replicated. The code, data, and files required to reproduce the results were reviewed and are available at https://doi.org/10.1287/opre.2023.0254.cd . Supplemental Material: This article includes an online appendix, computer code and data supporting the study’s findings, and replication files. All supplemental materials, including the code, data, and files required to reproduce the results, are available at https://doi.org/10.1287/opre.2023.0254.cd .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0254},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2661-2679},
  shortjournal = {Oper. Res.},
  title        = {Learning in inverse optimization: Incenter cost, augmented suboptimality loss, and algorithms},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven clustering and feature-based retail electricity pricing with smart meters. <em>OR</em>, <em>73</em>(5), 2636-2660. (<a href='https://doi.org/10.1287/opre.2022.0112'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider an electric utility company that serves retail electricity customers over a discrete-time horizon. In each period, the company observes the customers’ consumption and high-dimensional features on customer characteristics and exogenous factors. A distinctive element of our work is that these features exhibit three types of heterogeneity—over time, customers, or both. Based on the consumption and feature observations, the company can dynamically adjust the retail electricity price at the customer level. The consumption depends on the features: there is an underlying structure of clusters in the feature space, and the relationship between consumption and features is different in each cluster. Initially, the company knows neither the underlying cluster structure nor the corresponding consumption models. We design a data-driven policy of joint spectral clustering and feature-based pricing and show that our policy achieves near-optimal performance; that is, its average regret converges to zero at the fastest achievable rate. This work is the first to theoretically analyze joint clustering and feature-based pricing with different types of feature heterogeneity. Our case study based on real-life smart meter data from Texas illustrates that our policy increases company profits by more than 100% over a three-month period relative to the company policy and is robust to various forms of model misspecification. Supplemental Material: The online appendices are available at https://doi.org/10.1287/opre.2022.0112 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0112},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2636-2660},
  shortjournal = {Oper. Res.},
  title        = {Data-driven clustering and feature-based retail electricity pricing with smart meters},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Technical Note–Dynamic duopolistic competition with sticky prices. <em>OR</em>, <em>73</em>(5), 2627-2635. (<a href='https://doi.org/10.1287/opre.2023.0473'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A paradoxical conclusion arises in a series of game-theoretic models: the limit equilibria retain frictional qualities even as frictions seemingly vanish. This originates in textbook models, such as the differential game by Fershtman and Kamien [Fershtman C, Kamien MI (1987) Dynamic duopolistic competition with sticky prices. Econometrica 55(5):1151–1164] on duopolistic competition with sticky prices. We show that this paradox is an artifact of the type of limit restricted by continuous-time modeling. Fershtman and Kamien find that the closed-loop equilibrium remains surprisingly distinct from the static Cournot equilibrium as price adjustment becomes infinitely fast. We formulate and solve a discrete-time analog that nests their continuous-time model. Contrary to their conclusion, we show that the frictionless closed-loop equilibrium converges to the static Cournot equilibrium. Price stickiness persists instantaneously in the continuous-time setting because this approach cannot control the extent of price adjustment per period. Because of this subtle limitation, limit results differ between continuous- and discrete-time formulations of the model.},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0473},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2627-2635},
  shortjournal = {Oper. Res.},
  title        = {Technical Note–Dynamic duopolistic competition with sticky prices},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A reciprocity between tree ensemble optimization and multilinear optimization. <em>OR</em>, <em>73</em>(5), 2610-2626. (<a href='https://doi.org/10.1287/opre.2022.0150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we establish a low-degree polynomially-sized reduction between tree ensemble optimization and optimization of multilinear functions over a Cartesian product of simplices. We use this insight to derive new formulations for tree ensemble optimization problems and to obtain new convex hull results for multilinear polytopes. A computational experiment on multicommodity transportation problems with costs modeled using tree ensembles shows the practical advantage of our formulation relative to existing formulations of tree ensembles and other piecewise-linear modeling techniques. Funding: This work was supported by Division of Civil, Mechanical and Manufacturing Innovation [Grants 1727989, 1917323]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2022.0150 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0150},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2610-2626},
  shortjournal = {Oper. Res.},
  title        = {A reciprocity between tree ensemble optimization and multilinear optimization},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deepest cuts for benders decomposition. <em>OR</em>, <em>73</em>(5), 2591-2609. (<a href='https://doi.org/10.1287/opre.2021.0503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since its inception, Benders decomposition (BD) has been successfully applied to a wide range of large-scale mixed-integer (linear) problems. The key element of BD is the derivation of Benders cuts, which are often not unique. In this paper, we introduce a novel unifying Benders cut selection technique based on a geometric interpretation of cut depth, produce deepest Benders cuts based on ℓ p -norms, and study their properties. Specifically, we show that deepest cuts resolve infeasibility through minimal deviation (in a distance sense) from the incumbent point, are relatively sparse, and may produce optimality cuts even when classic Benders would require a feasibility cut. Leveraging the duality between separation and projection, we develop a guided projections algorithm for producing deepest cuts, exploiting the combinatorial structure and decomposability of problem instances. We then propose a generalization of our Benders separation problem, which not only brings several well-known cut selection strategies under one umbrella, but also, when endowed with a homogeneous function, enjoys several properties of geometric separation problems. We show that, when the homogeneous function is linear, the separation problem takes the form of the minimal infeasible subsystems (MIS) problem. As such, we provide systematic ways of selecting the normalization coefficients of the MIS method and introduce a directed depth-maximizing algorithm for deriving these cuts. Inspired by the geometric interpretation of distance-based cuts and the repetitive nature of two-stage stochastic programs, we introduce a tailored algorithm to further facilitate deriving these cuts. Our computational experiments on various benchmark problems illustrate effectiveness of deepest cuts in reducing both computation time and number of Benders iterations and producing high-quality bounds at early iterations. Supplemental Material: The computer code and data that support the findings of this study are available within this article’s supplemental material at https://doi.org/10.1287/opre.2021.0503 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0503},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2591-2609},
  shortjournal = {Oper. Res.},
  title        = {Deepest cuts for benders decomposition},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Search in the dark: The case with recall and gaussian learning. <em>OR</em>, <em>73</em>(5), 2572-2590. (<a href='https://doi.org/10.1287/opre.2023.0150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classic sequential search problem rewards the decision maker with the highest sampled value minus a cost per sample. If the sampling distribution is unknown, then a Bayesian decision maker faces a complex balance between exploration and exploitation. We solve the stopping problem of sampling from a normal distribution with unknown mean and variance and a conjugate prior, a longstanding open problem. The optimal stopping region may be empty (it may be optimal to continue the search regardless of the offer one receives, especially at the early stages), or it may consist of one or two bounded intervals. Whereas a single reservation price cannot describe the optimal rule, we do find an optimal index policy taking the form of a standardized reservation rule: stop if and only if the standardized value of the current best exceeds a threshold that depends on the standardized search cost. We also provide an algorithm to compute the index function, producing a practical way to implement the optimal stopping rule for any given prior, sampling history, and sampling horizon. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2023.0150 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0150},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2572-2590},
  shortjournal = {Oper. Res.},
  title        = {Search in the dark: The case with recall and gaussian learning},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Technical Note–Stability of a queue fed by scheduled traffic at critical loading. <em>OR</em>, <em>73</em>(5), 2567-2571. (<a href='https://doi.org/10.1287/opre.2023.0039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the workload process for a single server queue with deterministic service times in which customers arrive according to a scheduled traffic process. A scheduled arrival sequence is one in which customers are scheduled to arrive at constant interarrival times, but each customer’s actual arrival time is perturbed from her scheduled arrival time by a random perturbation. In this paper, we consider a critically loaded queue in which the service rate equals the arrival rate. Unlike a queue fed by renewal traffic, this queue can be stable even in the presence of critical loading. We show that for finite mean perturbations, a necessary and sufficient condition for stability is when the positive part of the perturbation has bounded support, with no requirement on the negative part of the perturbation. Perhaps surprisingly, this criterion is not reversible, in the sense that such a queue can be stable for a scheduled traffic process in forward time, but unstable for the time-reversal of the same traffic process.},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0039},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2567-2571},
  shortjournal = {Oper. Res.},
  title        = {Technical Note–Stability of a queue fed by scheduled traffic at critical loading},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Markdown policies for demand learning with forward-looking customers. <em>OR</em>, <em>73</em>(5), 2550-2566. (<a href='https://doi.org/10.1287/opre.2019.0402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the markdown pricing problem of a firm that sells a product to a mixture of myopic and forward-looking customers. The firm faces uncertainty about the customers’ forward-looking behavior, arrival pattern, and valuations for the product, which we collectively refer to as the demand model. Over a multiperiod selling season, the firm sequentially marks down the product’s price and makes demand observations to learn about the underlying demand model. Because forward-looking customers create an intertemporal dependency, we identify that the keys to achieving good profit performance are (i) judiciously accumulating information on the demand model and (ii) preserving the market size in early sales periods. Based on these, we construct and analyze markdown policies that exhibit near-optimal performance under a wide variety of forward-looking customer behaviors. Funding: Financial support from Duke University Fuqua School of Business; the University of Chicago Booth School of Business; and CUHK Business School, the Chinese University of Hong Kong is gratefully acknowledged. H. (K.) Chen thanks the Hong Kong Research Grants Council [Grant GRF14506622]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2019.0402 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2019.0402},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2550-2566},
  shortjournal = {Oper. Res.},
  title        = {Markdown policies for demand learning with forward-looking customers},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On consistency of signature using lasso. <em>OR</em>, <em>73</em>(5), 2530-2549. (<a href='https://doi.org/10.1287/opre.2024.1133'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Signatures are iterated path integrals of continuous and discrete-time processes, and their universal nonlinearity linearizes the problem of feature selection in time series data analysis. This paper studies the consistency of signature using Lasso regression, both theoretically and numerically. We establish conditions under which the Lasso regression is consistent both asymptotically and in finite sample. Furthermore, we show that the Lasso regression is more consistent with the Itô signature for time series and processes that are closer to the Brownian motion and with weaker interdimensional correlations, whereas it is more consistent with the Stratonovich signature for mean-reverting time series and processes. We demonstrate that signature can be applied to learn nonlinear functions and option prices with high accuracy, and the performance depends on properties of the underlying process and the choice of the signature. Funding: R. Zhang’s research was supported by the National Key Research and Development Program of China [Grant 2022YFA1007900], the National Natural Science Foundation of China [Grant 72342004 and Grant 12271013], the Fundamental Research Funds for the Central Universities (Peking University), and Yinhua Education Foundation. Supplemental Material: All supplemental materials, including the code, data, and files required to reproduce the results, are available at https://doi.org/10.1287/opre.2024.1133 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2024.1133},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2530-2549},
  shortjournal = {Oper. Res.},
  title        = {On consistency of signature using lasso},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Policy learning with competing agents. <em>OR</em>, <em>73</em>(5), 2515-2529. (<a href='https://doi.org/10.1287/opre.2022.0687'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision makers often aim to learn a treatment assignment policy under a capacity constraint on the number of agents that they can treat. When agents can respond strategically to such policies, competition arises, complicating estimation of the optimal policy. In this paper, we study capacity-constrained treatment assignments in the presence of such interference. We consider a dynamic model in which the decision maker allocates treatments at each time step and heterogeneous agents myopically best respond to the previous treatment assignment policy. When the number of agents is large but finite, we show that the threshold for receiving treatment under a given policy converges to the policy’s mean-field equilibrium threshold. Based on this result, we develop a consistent estimator for the policy gradient. In a semisynthetic experiment with data from the National Education Longitudinal Study of 1988, we demonstrate that this estimator can be used for learning capacity-constrained policies in the presence of strategic behavior. Funding: This work was supported by National Science Foundation (NSF) [Grant SES-2242876]. R. Sahoo is supported by NSF Graduate Research Fellowship Program [Grant DGE-1656518], a Stanford University Data Science Fellowship, and a Stanford University Ethics in Society Fellowship. Supplemental Material: All supplemental materials, including the code, data, and files required to reproduce the results, are available at https://doi.org/10.1287/opre.2022.0687 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0687},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2515-2529},
  shortjournal = {Oper. Res.},
  title        = {Policy learning with competing agents},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blind network revenue management and bandits with knapsacks under limited switches. <em>OR</em>, <em>73</em>(5), 2496-2514. (<a href='https://doi.org/10.1287/opre.2020.0753'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the impact of limited switches on resource-constrained dynamic pricing with demand learning. We focus on the classical price-based blind network revenue management problem and extend our results to the bandits with knapsacks problem. In both settings, a decision maker faces stochastic and distributionally unknown demand, and must allocate finite initial inventory across multiple resources over time. In addition to standard resource constraints, we impose a switching constraint that limits the number of allowable action changes over the time horizon. We establish matching upper and lower bounds on the optimal regret and develop computationally efficient limited-switch algorithms that achieve it. We show that the optimal regret rate is fully characterized by a piecewise-constant function of the switching budget, which further depends on the number of resource constraints. Our results highlight the fundamental role of resource constraints in shaping the statistical complexity of online learning under limited switches. Extensive simulations demonstrate that our algorithms maintain strong cumulative reward performance while significantly reducing the number of switches. Supplemental Material: All supplemental materials, including the code, data, and files required to reproduce the results, are available at https://doi.org/10.1287/opre.2020.0753 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2020.0753},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2496-2514},
  shortjournal = {Oper. Res.},
  title        = {Blind network revenue management and bandits with knapsacks under limited switches},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Instrumenting while experimenting: An empirical method for competitive pricing at scale. <em>OR</em>, <em>73</em>(5), 2477-2495. (<a href='https://doi.org/10.1287/opre.2022.0157'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate operational decisions require precise knowledge of the causal effects of such decisions on outcomes, a task that becomes increasingly complex in dynamic business environments. We propose an idea of “instrumenting while experimenting,” whereby researchers can create their own instruments by “injecting” small, random variations directly into the decision-making process and then use such variations to obtain causal estimates of the impact of varying business decisions at scale without disrupting everyday operations. To illustrate the effectiveness of this idea, we partner with a leading U.S. e-commerce retailer and develop a competitive pricing method in the context of increasing competition in online retailing. Our method allows retailers to respond more accurately to competitors’ price changes at scale. Operationally, we first construct a parsimonious demand model to capture the key trade-offs in competitive pricing. This model accounts for potential shifts in customer behaviors based on whether the focal retailer holds a price advantage relative to its competitors. Next, we design and implement a large-scale randomized price experiment on over 10,000 products. Leveraging the experiment as well as the control function approach, we are able to obtain unbiased estimates of key pricing components in the demand model, in particular, price elasticities of customers in both price advantage and disadvantage regions as well as the sales lift when undercutting competitors in price. Lastly, we recommend price responses by solving a constrained optimization problem that uses the estimated demand model as an input. We test this pricing method through another large-scale controlled field experiment on over 10,000 products and demonstrate significant improvements—increasing revenue by over 15% and increasing profit by over 10%. Simulation analyses reveal that these improvements are attributable to the joint implementation of demand modeling (contributing 17% of the total improvement), price optimization (36%), and our proposed estimation method (48%). Supplemental Material: All supplemental materials, including the code, data, and files required to reproduce the results, are available at https://doi.org/10.1287/opre.2022.0157 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0157},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2477-2495},
  shortjournal = {Oper. Res.},
  title        = {Instrumenting while experimenting: An empirical method for competitive pricing at scale},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online learning with sample selection bias. <em>OR</em>, <em>73</em>(5), 2458-2476. (<a href='https://doi.org/10.1287/opre.2023.0223'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of personalized recommendations on online platforms, where user preferences are unknown, and users interact with the platform through a series of sequential decisions (such as clicking to watch on video platforms or clicking to donate on donation platforms). The platform aims to maximize the final outcome (e.g., viewing duration on video platforms or donations on donation platforms). However, the platform only observes the final outcome for users who complete the first stage (clicking on the recommendation). The final outcome for users who do not complete the first stage (not clicking on the recommendation) remains unobserved (also referred to as funneling ). This censoring of outcomes creates a selection bias issue, as the observed outcomes at different stages are often correlated. We demonstrate that failing to account for this selection bias results in biased estimates and suboptimal recommendations. In fact, well-performing personalized learning algorithms perform poorly and incur linear regret in this setting. Therefore, we propose the sample selection bandit (SSB) algorithm, which combines Heckman’s two-step estimator with the “optimism under uncertainty” principle to address the sample selection bias issue. We show that the SSB algorithm achieves a rate-optimal regret rate (up to logarithmic terms) of O ˜ ( T ) . Furthermore, we conduct extensive numerical experiments on both synthetic data and real donation data collected from GoFundMe (a crowdfunding platform), demonstrating significant improvements over benchmark state-of-the-art learning algorithms in this setting. Supplemental Material: All supplemental materials, including the code, data, and files required to reproduce the results, are available at https://doi.org/10.1287/opre.2023.0223 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0223},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2458-2476},
  shortjournal = {Oper. Res.},
  title        = {Online learning with sample selection bias},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Better regularization for sequential decision spaces: Fast convergence rates for nash, correlated, and team equilibria. <em>OR</em>, <em>73</em>(5), 2430-2457. (<a href='https://doi.org/10.1287/opre.2021.0633'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the application of iterative first-order methods to the problem of computing equilibria of large-scale extensive-form games. First-order methods must typically be instantiated with a regularizer that serves as a distance-generating function (DGF) for the decision sets of the players. In this paper, we introduce a new weighted entropy-based distance-generating function. We show that this function is equivalent to a particular set of new weights for the dilated entropy distance–generating function on a treeplex while retaining the simpler structure of the regular entropy function for the unit cube. This function achieves significantly better strong-convexity properties than existing weight schemes for the dilated entropy while maintaining the same easily implemented closed-form proximal mapping as the prior state of the art. Extensive numerical simulations show that these superior theoretical properties translate into better numerical performance as well. We then generalize our new entropy distance function, as well as general dilated distance functions, to the scaled extension operator. The scaled extension operator is a way to recursively construct convex sets, which generalizes the decision polytope of extensive-form games as well as the convex polytopes corresponding to correlated and team equilibria. Correspondingly, we give the first efficiently computable distance-generating function for all those strategy polytopes. By instantiating first-order methods with our regularizers, we achieve several new results, such as the first method for computing ex ante correlated team equilibria with a guaranteed 1 / T rate of convergence and efficient proximal updates. Similarly, we show that our regularizers can be used to speed up the computation of correlated solution concepts. Funding: G. Farina was supported by the National Science Foundations [Grant CCF-2443068] and by T. Sandholm’s grants listed below and a Facebook fellowship. C. Kroer was supported by the Office of Naval Research [Grants N00014-22-1-2530 and N00014-23-1-2374] and the National Science Foundation [Grants IIS-2147361 and IIS-2238960]. T. Sandholm was supported by the Vannevar Bush Faculty Fellowship, Office of Naval Research [Grant ONR N00014-23-1-2876], the National Science Foundation Division of Information and Intelligent Systems [Grants RI-1718457, RI-2312342, RI-1901403, and CCF-1733556], the Army Research Office [Grants W911NF2010081 and W911NF2210266], and the National Institutes of Health [Grant A240108S001]. This work was further supported by the National Science Foundation Division of Information and Intelligent Systems [Grant 1617590] and the Army Research Office [Grant W911NF-17-1-0082]. Supplemental Material: All supplemental materials, including the code, data, and files required to reproduce the results, are available at https://doi.org/10.1287/opre.2021.0633 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0633},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2430-2457},
  shortjournal = {Oper. Res.},
  title        = {Better regularization for sequential decision spaces: Fast convergence rates for nash, correlated, and team equilibria},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Change-point detection in dynamic networks with missing links. <em>OR</em>, <em>73</em>(5), 2417-2429. (<a href='https://doi.org/10.1287/opre.2021.0413'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural changes occur in dynamic networks quite frequently and their detection is an important question in many situations, such as fraud detection or cybersecurity. Real-life networks are often incompletely observed because of individual nonresponse or network size. In the present paper, we consider the problem of change-point detection at a temporal sequence of partially observed networks. The goal is to test whether there is a change in the network parameters. Our approach is based on the matrix cumulative sum test statistic and allows growing the size of networks. We show that the proposed test is minimax optimal and robust to missing links. We also demonstrate the good behavior of our approach in practice through simulation study and a real-data application. Funding: The work of O. Klopp was funded by the CY Initiative [Grant Investissements d’Avenir Agence Nationale de Recherche-16-Initiatives d’Excellence-0008] and Labex MME-DII [Grant ANR11-LBX-0023-01]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2021.0413 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0413},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2417-2429},
  shortjournal = {Oper. Res.},
  title        = {Change-point detection in dynamic networks with missing links},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal abort policy for mission-critical systems under imperfect condition monitoring. <em>OR</em>, <em>73</em>(5), 2396-2416. (<a href='https://doi.org/10.1287/opre.2022.0643'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although most on-demand mission-critical systems are engineered to be reliable to support critical tasks, occasional failures may still occur during missions. To increase system survivability, a common practice is to abort the mission before an imminent failure. We consider optimal mission abort for a system whose deterioration follows a general three-state (normal, defective, failed) semi-Markov chain. The failure is assumed self-revealed, whereas the healthy and defective states have to be inferred from imperfect condition-monitoring data. Because of the non-Markovian process dynamics, optimal mission abort for this partially observable system is an intractable stopping problem. For a tractable solution, we introduce a novel tool of Erlang mixtures to approximate nonexponential sojourn times in the semi-Markov chain. This allows us to approximate the original process by a surrogate continuous-time Markov chain whose optimal control policy can be solved through a partially observable Markov decision process (POMDP). We show that the POMDP optimal policies converge almost surely to the optimal abort decision rules when the Erlang rate parameter diverges. This implies that the expected cost by adopting the POMDP solution converges to the optimal expected cost. Next, we provide comprehensive structural results on the optimal policy of the surrogate POMDP. Based on the results, we develop a modified point-based value iteration algorithm to numerically solve the surrogate POMDP. We further consider mission abort in a multitask setting where a system executes several tasks consecutively before a thorough inspection. Through a case study on an unmanned aerial vehicle, we demonstrate the capability of real-time implementation of our model, even when the condition-monitoring signals are generated with high frequency. Funding: This work was supported in part by the National Science Foundation of China [Grants 72171037, 72471144, 72371161, and 72071071], Singapore MOE AcRF Tier 2 grants [Grants A-8001052-00-00 and A-8002472-00-00], and the Future Resilient Systems project supported by the National Research Foundation Singapore under its CREATE program. Supplemental Material: All supplemental materials, including the code, data, and files required to reproduce the results, are available at https://doi.org/10.1287/opre.2022.0643 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0643},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2396-2416},
  shortjournal = {Oper. Res.},
  title        = {Optimal abort policy for mission-critical systems under imperfect condition monitoring},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). D-optimal orienteering for post-earthquake reconnaissance planning. <em>OR</em>, <em>73</em>(5), 2375-2395. (<a href='https://doi.org/10.1287/opre.2023.0470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Immediately following a major earthquake, reconnaissance surveys seek to assess structural damage throughout the region with the help of a limited number of on-ground inspections. The goal is to collect informative and representative data that will guide subsequent relief efforts. We formulate a new type of vehicle routing problem, in which vehicles are tasked with data collection, and the objective function measures data quality using a nonlinear, nonseparable experimental design criterion. We create novel exact methods for this problem and demonstrate their practical potential in a realistic case study using a state-of-the-art earthquake simulator. Funding: J. Wang, I. O. Ryzhov, N. Marković, and G. Ou acknowledge the support of the National Science Foundation (NSF) Division of Civil, Mechanical and Manufacturing Innovation [Grant 2112828]. W. Xie acknowledges the support of the NSF Division of Computing and Communication Foundations [Grant 2246417]. Supplemental Material: All supplemental materials, including the code, data, and files required to reproduce the results, are available at https://doi.org/10.1287/opre.2023.0470 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0470},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2375-2395},
  shortjournal = {Oper. Res.},
  title        = {D-optimal orienteering for post-earthquake reconnaissance planning},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stationary mean-field equilibrium model of irreversible investment in a two-regime economy. <em>OR</em>, <em>73</em>(5), 2351-2374. (<a href='https://doi.org/10.1287/opre.2023.0250'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a mean-field model of firms competing à la Cournot on a commodity market, where the commodity price is given in terms of a power inverse demand function of the industry-aggregate production. Investment is irreversible and production capacity depreciates at a constant rate. Production is subject to Gaussian productivity shocks, whereas large nonanticipated macroeconomic events driven by a two-state continuous-time Markov chain can change the volatility of the shocks, as well as the price function. Firms wish to maximize expected discounted revenues of production, net of investment, and operational costs. Investment decisions are based on the long-run stationary price of the commodity. We prove existence, uniqueness, and characterization of the stationary mean-field equilibrium of the model. The equilibrium investment strategy is of barrier type, and it is triggered by a couple of endogenously determined investment thresholds, one per state of the economy. We provide a quasi-closed form expression of the stationary density of the state, and we show that our model can produce Pareto distribution of firms’ size. This is a feature that is consistent both with observations at the aggregate level of industries and at the level of a particular industry. We provide evidence that persistent periods of economic downturn increase market concentration. We demonstrate that firms with slowly depreciating production capacities fare better in a stable, average economy, whereas firms with quickly depreciating assets can benefit from sequences of boom and bust. Funding: This work was supported by the Agence Nationale de la Recherche [Grants ANR-19-CE05-0042 and MIRTE ANR-23-EXMA-0011] and the Deutsche Forschungsgemeinschaft [Grant SFB 1283/22021-317210226].},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0250},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2351-2374},
  shortjournal = {Oper. Res.},
  title        = {A stationary mean-field equilibrium model of irreversible investment in a two-regime economy},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Political districting to optimize the polsby-popper compactness score with application to voting rights. <em>OR</em>, <em>73</em>(5), 2330-2350. (<a href='https://doi.org/10.1287/opre.2024.1078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the academic literature and in expert testimony, the Polsby-Popper score is the most popular way to measure the compactness of a political district. Given a district with area A and perimeter P , its Polsby-Popper score is given by ( 4 π A ) / P 2 . This score takes values between zero and one, with circular districts achieving a perfect score of one. In this paper, we propose the first mathematical optimization models to draw districts (or districting plans) with optimum Polsby-Popper score. Specifically, we propose new mixed-integer second-order cone programs (MISOCPs), which can be solved with existing optimization software. Experiments show that they can identify the most compact single districts at the precinct level and the most compact plans at the county level. Then, we turn to the problem of drawing compact plans with a large number of majority-minority districts. This is the task faced by plaintiffs in Voting Rights Act cases who must show that an alternative plan exists in which the minority group could achieve better representation, a legal hurdle known as the first Gingles precondition. For this task, we propose new MISOCP-based heuristics that often outperform enacted maps on standard criteria, sometimes by substantial margins. They also perform well against state-of-the-art heuristics like short bursts and can be used to polish maps with hundreds of thousands of census blocks. Our techniques could assist plaintiffs when seeking to overturn maps that dilute the voting strength of minority groups. Our code is available on GitHub. Funding: This work was supported by the National Science Foundation [Grant 1942065].},
  archive      = {J_OR},
  doi          = {10.1287/opre.2024.1078},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2330-2350},
  shortjournal = {Oper. Res.},
  title        = {Political districting to optimize the polsby-popper compactness score with application to voting rights},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the almost threshold policy for multisourcing under uncertain supplies. <em>OR</em>, <em>73</em>(5), 2319-2329. (<a href='https://doi.org/10.1287/opre.2024.1193'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With extended supply chains and increased global sourcing, the uncertainty in supply streams has become a major consideration in formulating procurement strategies. Many studies in the existing literature characterize the optimal procurement policies under specific assumptions of the supply and demand distributions. In several special cases, a threshold policy or an almost threshold policy is shown to be optimal. A recent study by Feng and Shathikumar [Feng Q, Shanthikumar JG (2018) Supply and demand functions in inventory models. Oper. Res. 66(1):77–91] generalizes the previous results by establishing the optimality of an almost threshold policy under any demand distribution and a set of conditions on the stochastic supply functions, including stochastic linearity in midpoint, stochastic increasing in the dispersive order, and vanishing of the no-delivery probability. In this note, we significantly enhance this result and for the first time, fully characterize the optimal multisourcing policy for general stochastic supply functions that are stochastically linear in midpoint, the weakest known condition to ensure the concavity of the associated dynamic program. Using an iterative constructive approach, we prove that an almost threshold policy is optimal. This result is extended to price-dependent demands and positively dependent supplies.},
  archive      = {J_OR},
  doi          = {10.1287/opre.2024.1193},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2319-2329},
  shortjournal = {Oper. Res.},
  title        = {On the almost threshold policy for multisourcing under uncertain supplies},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Near-optimal mixed (s,S) policy for a multiwarehouse, multistore inventory system with lost sales and fixed cost. <em>OR</em>, <em>73</em>(5), 2306-2318. (<a href='https://doi.org/10.1287/opre.2024.0717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a firm managing a multiperiod, multiwarehouse, multistore (MWMS) inventory problem with fixed ordering cost at each store over a finite time horizon. The warehouses are endowed with initial inventories at the start of the horizon, and the stores are periodically replenished from the warehouses. The decisions are the order quantities from each store at each period. The optimal policy for this problem is complex and computationally intractable. We construct a mixed ( s , S ) policy based on the optimal solutions of a Lagrangian relaxation. Under this policy, each store makes use of at most two ( s , S ) policies; one is applied during the first phase of the selling horizon, and the second is applied in the remaining periods. We prove that this policy is near optimal as the length of the time horizon grows. In contrast to the existing works on the MWMS problem without fixed cost for which near-optimal policies can be developed using an optimal Lagrangian solution, with fixed cost, it is crucial to adopt a mixture of Lagrangian solutions, and simply applying a pure optimal Lagrangian solution can be highly suboptimal. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2024.0717 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2024.0717},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2306-2318},
  shortjournal = {Oper. Res.},
  title        = {Near-optimal mixed (s,S) policy for a multiwarehouse, multistore inventory system with lost sales and fixed cost},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-item online order fulfillment in a two-layer network. <em>OR</em>, <em>73</em>(5), 2297-2305. (<a href='https://doi.org/10.1287/opre.2022.0100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The global e-commerce boom has driven rapid expansion of fulfillment infrastructure, with e-retailers building more warehouses to offer faster deliveries. However, fulfillment costs have surged over the past decade. This paper addresses the problem of minimizing these costs, where an e-retailer must decide in real time which warehouse(s) will fulfill each order, considering inventory constraints. Orders can be split among warehouses at an additional cost. We focus on a regional distribution center (RDC)–front distribution center (FDC) distribution network used by major e-retailers, which consists of larger RDCs and smaller FDCs. We analyze the performance of a simple myopic policy that selects the least expensive fulfillment option for each order without considering future impacts. We provide theoretical bounds on the performance ratio of the myopic policy compared with an optimal clairvoyant policy and demonstrate the strengths of the myopic policy within this two-layer network. Supplemental Material: All supplemental materials, including the code, data, and files required to reproduce the results, are available at https://doi.org/10.1287/opre.2022.0100 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0100},
  journal      = {Operations Research},
  month        = {9-10},
  number       = {5},
  pages        = {2297-2305},
  shortjournal = {Oper. Res.},
  title        = {Multi-item online order fulfillment in a two-layer network},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="orsc">ORSC - 20</h2>
<ul>
<li><details>
<summary>
(2025). CROSSROADS—Promoting cooperation: Insights and challenges. <em>ORSC</em>, <em>36</em>(5), 2055-2059. (<a href='https://doi.org/10.1287/orsc.2025.21141'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This piece distills lessons for increasing the impact of social science research based on our work at the Massachusetts Institute of Technology Applied Cooperation Initiative, which facilitates collaborations between social scientists and practitioners to promote real-world prosocial behaviors. We describe an iterative model of collaboration—intervention, randomized trial, publication, and press—that has sustained a robust research pipeline, broadening the dissemination and application of findings. We highlight two promising directions for future research in organizational contexts: (i) adapting interventions to intraorganizational dynamics, in which norms and incentives differ from public settings, and (ii) developing strategies for establishing or reforming counterproductive norms that may hinder organizational performance. We conclude with recommendations for supporting translational research: introducing article types dedicated to translation, removing barriers to publishing practitioner-relevant review articles, streamlining institutional review board and legal processes, and funding cross-institutional collaborations. History: This manuscript is part of the five-piece crossroads collection “Organization Research as an Applied Science,” edited by Gokhan Ertug and Stephen Zhang. The companion pieces are Zhang and Ertug (2025) , Croson and Croson (2025) , Eesley and Gerber (2025) , and Berry (2025) .},
  archive      = {J_ORSC},
  doi          = {10.1287/orsc.2025.21141},
  journal      = {Organization Science},
  month        = {9-10},
  number       = {5},
  pages        = {2055-2059},
  shortjournal = {Organ. Sci.},
  title        = {CROSSROADS—Promoting cooperation: Insights and challenges},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CROSSROADS—Applied science deserves a bigger role in business research. <em>ORSC</em>, <em>36</em>(5), 2052-2054. (<a href='https://doi.org/10.1287/orsc.2025.20585'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The business world has much to gain from the direct application of research findings to daily business operations. Nevertheless, a large gap remains between the work of business academics and that of business practitioners. With an eye toward closing that gap in applied science, medical publishing has three important lessons for business journals and scholars. First, borrow selectively from medical publishing’s best practices—most notably, by emphasizing evidence over discursive prose; seeing application of research findings as intrinsic to the very purpose of research; elevating the prominence of expert opinions on how and why to implement research; and accelerating research-publication timelines while maintaining rigor. Second, make novel innovations in publishing, such as academic–practitioner coauthorship, recruitment of carefully vetted practitioners to be on industry advisory boards to journals, and journal sponsorship of conferences where academics and practitioners freely exchange ideas. Third, explicitly encourage business researchers to see their published work as actually intending to influence business practices and societal well-being. Just as medical publishing aims, at its core, to improve people’s lives, business research should seek to make a concrete difference in people’s lived experiences.},
  archive      = {J_ORSC},
  doi          = {10.1287/orsc.2025.20585},
  journal      = {Organization Science},
  month        = {9-10},
  number       = {5},
  pages        = {2052-2054},
  shortjournal = {Organ. Sci.},
  title        = {CROSSROADS—Applied science deserves a bigger role in business research},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CROSSROADS—Designing institutions for applied impact: Lessons from engineering for organizational research. <em>ORSC</em>, <em>36</em>(5), 2044-2051. (<a href='https://doi.org/10.1287/orsc.2025.21020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Organizational researchers increasingly call for applied impact, yet institutional structures continue to privilege theoretical novelty over practical relevance. In contrast, engineering fields have built mechanisms that legitimize rigorously validated, usable contributions—often publishing proven solutions before fully developed theories. Drawing on our experiences in both engineering and organizational research, we examine how institutional design—not just individual motivation—shapes what counts as legitimate scholarship. We identify structural levers that support applied impact across three institutional pillars: cognitive (what counts as knowledge), normative (what confers prestige), and regulative (what gets published and rewarded). By analyzing how engineering disciplines use diverse publication formats, evaluation rubrics, and inclusive authorship norms, we outline feasible reforms for organizational research. We propose a framework for institutional redesign that expands the definition of scholarly value while preserving rigor. History: This manuscript is part of the five-piece crossroads collection "Organization Research as an Applied Science," edited by Gokhan Ertug and Stephen Zhang. The companion pieces are Zhang and Ertug (2025) , Croson and Croson (2025) , Berry (2025) , and Yoeli and Rand (2025) . Funding: E. Gerber gratefully acknowledges funding from the National Science Foundation (NSF). C. Eesley gratefully acknowledges funding from the Stanford Technology Ventures Program (STVP).},
  archive      = {J_ORSC},
  doi          = {10.1287/orsc.2025.21020},
  journal      = {Organization Science},
  month        = {9-10},
  number       = {5},
  pages        = {2044-2051},
  shortjournal = {Organ. Sci.},
  title        = {CROSSROADS—Designing institutions for applied impact: Lessons from engineering for organizational research},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CROSSROADS—Increasing the impact of organization science research: Lessons from economics. <em>ORSC</em>, <em>36</em>(5), 2040-2043. (<a href='https://doi.org/10.1287/orsc.2025.20953'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of organization science has many important insights to offer to practice, but often those insights go unnoticed. This article uses examples from a related discipline, economics, to suggest actions that the organization science field could consider in order to increase its impact. History: This manuscript is part of the five-piece crossroads collection “Organization Research as an Applied Science,” edited by Gokhan Ertug and Stephen Zhang. The companion pieces are Zhang and Ertug (2025) , Eesley and Gerber (2025) , Berry (2025) , and Yoeli and Rand (2025) .},
  archive      = {J_ORSC},
  doi          = {10.1287/orsc.2025.20953},
  journal      = {Organization Science},
  month        = {9-10},
  number       = {5},
  pages        = {2040-2043},
  shortjournal = {Organ. Sci.},
  title        = {CROSSROADS—Increasing the impact of organization science research: Lessons from economics},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CROSSROADS—Organization research as an applied science: Lessons from fields that shape practice and policy. <em>ORSC</em>, <em>36</em>(5), 2028-2039. (<a href='https://doi.org/10.1287/orsc.2025.20459'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous calls over decades have urged scholars to pursue research that is more relevant to problems faced by organizations and their members. Yet the relevance and impact of our field remains limited compared with other applied sciences. Whereas individual aspects of our research practice, such as expectations about methods, theoretical novelty, and motivating a study, are frequently discussed in our field, less attention is paid to the publication system. Our perspective is that to bring about a field-wide change would require us to identify and address the systemic sources of the issue. Accordingly, we compare publication systems across applied sciences, contrasting organization research with those of impactful applied sciences, such as health sciences, engineering, economics, and design science. We focus on four fundamental elements of publication systems: balance between evidence and theory, diversity of research types accommodated, system responsiveness to real-world challenges, and relationship between exploration and replication. These elements are interdependent, and understanding them together reveals how publication systems can enable or constrain what gets published and its impact, enabling us to identify pathways to reorient publication systems in our field to become a more impactful applied science. History: This is the lead manuscript in the five-piece crossroads collection “Organization Research as an Applied Science,” edited by Gokhan Ertug and Stephen Zhang. The companion pieces are Croson and Croson (2025) , Eesley and Gerber (2025) , Berry (2025) , and Yoeli and Rand (2025) . Supplemental Material: The online appendix is available at https://doi.org/https://doi.org/10.1287/orsc.2025.20459 .},
  archive      = {J_ORSC},
  doi          = {10.1287/orsc.2025.20459},
  journal      = {Organization Science},
  month        = {9-10},
  number       = {5},
  pages        = {2028-2039},
  shortjournal = {Organ. Sci.},
  title        = {CROSSROADS—Organization research as an applied science: Lessons from fields that shape practice and policy},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Can stereotype reactance prompt women to compete? a field experiment. <em>ORSC</em>, <em>36</em>(5), 2008-2027. (<a href='https://doi.org/10.1287/orsc.2024.19563'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Women are consistently underrepresented in leadership roles. One contributor may be that women are generally less willing than equally-qualified men to enter competitions (e.g., for jobs or promotions). We draw from research on “stereotype reactance”—the idea that telling people about stereotyped expectations can encourage defiance—to propose and test whether telling women about the gender gap in competition entry can increase their willingness to compete. Our prediction contrasts with prior work on stereotype threat and descriptive norms suggesting that highlighting the gender competition gap might lead women to refrain from competing. In two incentive-compatible, preregistered online experiments, we find that informing women about the gender competition gap increases their likelihood of competing for higher pay, and this effect is mediated by stereotype reactance, consistent with our theorizing. Moreover, exposing both men and women to information about the gender competition gap closes the gap. We then test this informational intervention in a large-scale field experiment on an executive job search platform ( n = 4,245), examining whether telling women about the gender competition gap increases their willingness to compete for leadership roles relative to a control message that tells them about an identity-irrelevant competition gap. We find that relative to our control message, informing women about the gender gap in willingness to compete increases submitted job applications by over 20% on the day of condition assignment. This suggests that women’s willingness to compete is affected not just by confidence, but also by cultural expectations and motivation to defy stereotypical norms. Funding: The authors thank the Wharton School (and in particular, the Wharton Behavioral Laboratory and Analytics at Wharton) for funding support. Supplemental Material: The online appendix is available at https://doi.org/10.1287/orsc.2024.19563 .},
  archive      = {J_ORSC},
  doi          = {10.1287/orsc.2024.19563},
  journal      = {Organization Science},
  month        = {9-10},
  number       = {5},
  pages        = {2008-2027},
  shortjournal = {Organ. Sci.},
  title        = {Can stereotype reactance prompt women to compete? a field experiment},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meating expectations: Category legitimation and transmutation. <em>ORSC</em>, <em>36</em>(5), 1980-2007. (<a href='https://doi.org/10.1287/orsc.2023.17957'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates how market actors legitimize new categories that challenge the foundational understandings of established ones while simultaneously seeking to compete in the same market space. We analyze the development of the U.S. plant-based meat category from 2012 to 2019, focusing on how plant-based meat producers positioned their products as legitimate competitors within the meat category despite their nonanimal origins. We identify three key legitimation strategies used by entrepreneurs: reconfiguring the category basis by reframing the core attributes of meat from animal origin to shared biochemical components; creating experiential congruence by replicating the sensory qualities and social practices associated with traditional meat; and instilling value superiority by emphasizing health, environmental, and ethical benefits along with forward-thinking innovation. Our observations also lead us to theorize what we term category transmutation —a construct for understanding how the successful legitimation of a new category might reshape the meaning and boundaries of an existing one. We envision category transmutation as a process through which an existing category evolves to incorporate both traditional and new subcategories, thereby vertically modifying the category structure. This study advances our understanding of category dynamics and extends the role of cultural entrepreneurship beyond gaining legitimacy to reshaping category systems and market structures, with the potential to drive positive societal changes.},
  archive      = {J_ORSC},
  doi          = {10.1287/orsc.2023.17957},
  journal      = {Organization Science},
  month        = {9-10},
  number       = {5},
  pages        = {1980-2007},
  shortjournal = {Organ. Sci.},
  title        = {Meating expectations: Category legitimation and transmutation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Looking at the trees to see the forest: Construal level shift in strategic problem framing and formulation. <em>ORSC</em>, <em>36</em>(5), 1962-1979. (<a href='https://doi.org/10.1287/orsc.2024.19134'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective strategy development, evaluation, and implementation starts with a comprehensive understanding of strategic problems. However, developing such an understanding is often challenging due to the complexity of such problems and because how they can be solved is not yet known. Managers often oversimplify these problems by focusing on a few symptoms and obvious causes. Research indicates that big picture, abstract thinking helps managers explore underlying causes more flexibly, but it can also lead to overlooking key symptoms that do not fit existing frameworks. Instead, concrete thinking is likely essential for individuals to identify the full range of symptoms characterizing strategic problems. Because symptoms are essential for fully understanding strategic problems—they are the building blocks for managers to build theories about causes—both concrete and abstract thinking may be necessary. Drawing on construal level theory, we propose a construal level shift model. The central claim of our model is that managers benefit from first adopting a low construal level (concrete) thinking when framing strategic problems to identify all relevant symptoms. The benefit of a high construal level (abstract) thinking lies in combining these symptoms more flexibly to theorize more comprehensively about the underlying causes. Two experimental studies and one correlational study, involving samples of working individuals, managers, and experienced executives, support our model. Our findings contribute to the behavioral and knowledge-based views of the firm, the theory-based view of strategy, and managerial cognition research. Supplemental Material: The online appendix is available at https://doi.org/10.1287/orsc.2024.19134 .},
  archive      = {J_ORSC},
  doi          = {10.1287/orsc.2024.19134},
  journal      = {Organization Science},
  month        = {9-10},
  number       = {5},
  pages        = {1962-1979},
  shortjournal = {Organ. Sci.},
  title        = {Looking at the trees to see the forest: Construal level shift in strategic problem framing and formulation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The effects of competition and scarcity on interpersonal communication in organizations. <em>ORSC</em>, <em>36</em>(5), 1939-1961. (<a href='https://doi.org/10.1287/orsc.2023.18288'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When an organization’s environment changes, communication between its members is essential for a timely response. However, past observational studies suggest that communication declines when an organization is exposed to an adverse environmental event. To understand why this might happen, I examine the effects of competition and scarcity—two common features of adverse events—on information sharing and seeking—the microfoundations of organizational communication. In the present study, interactive groups of experimental participants play a novel n -armed bandit game where they work as salespeople for companies that offer a lot of different products (The Sales Game). Some groups experience stable customer demand, while others are exposed to negative or positive demand shifts. Participants earn variable rewards based on their individual performance, and competition is induced in half of the groups through a small bonus based on relative performance. Participants can choose to exchange information with their peers throughout the task. When participants freely exchange information, the increase in individual performance-based rewards is larger than the tiny competitive bonus. But, participants exposed to this competition share information significantly less often than those who are not. This produces a pattern of communication network contraction consistent with prior observational studies of organizations exposed to adverse events. In contrast to prior research, scarcity (negative demand shifts) has no effect on information exchange. These findings advance our understanding of the relationship between competition, scarcity, and interpersonal communication in organizations. They also have important implications for the design of incentive schemes in modern firms. Funding: This research was supported by funds from the Chicago Booth Graduate School of Business and the Division of Social and Economic Sciences [Grant 2018173]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/orsc.2023.18288 .},
  archive      = {J_ORSC},
  doi          = {10.1287/orsc.2023.18288},
  journal      = {Organization Science},
  month        = {9-10},
  number       = {5},
  pages        = {1939-1961},
  shortjournal = {Organ. Sci.},
  title        = {The effects of competition and scarcity on interpersonal communication in organizations},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Working with the “Enemy”: Supervised space, free space, and cross-border collaboration amid geopolitical rivalry. <em>ORSC</em>, <em>36</em>(5), 1909-1938. (<a href='https://doi.org/10.1287/orsc.2021.15574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the world grapples with intensifying geopolitical competition and ideological conflict, many organizations face the daunting task of navigating the complexities of geopolitics and fostering effective cross-border partnerships. For members of these organizations, such political dynamics might create new barriers to their ability to carry out collaborative activities. In a historical case study of the Apollo–Soyuz Test Project—an unprecedented partnership between the space programs of the United States and the Soviet Union at the height of the Cold War—we identify how organizational members navigated the turbulent geopolitical environment. We found that collaborative meetings between organizational members were limited to a supervised space that ensured government oversight but created interactional barriers. Organizational members realized that their ability to overcome these challenges would require them to develop practices outside of the organization, using boundary work to carve out free space outside the purview of political supervision. The free space served as a laboratory in which they reconciled informational, techno-cultural, and ideological differences and created solutions to the challenges they faced in the supervised space through translation work. Our study theorizes how geopolitics complicates the interactional processes of cross-border partnerships and underscores the importance of free space for fostering collaboration amid geopolitical rivalry. Supplemental Material: The online appendix is available at https://doi.org/10.1287/orsc.2021.15574 .},
  archive      = {J_ORSC},
  doi          = {10.1287/orsc.2021.15574},
  journal      = {Organization Science},
  month        = {9-10},
  number       = {5},
  pages        = {1909-1938},
  shortjournal = {Organ. Sci.},
  title        = {Working with the “Enemy”: Supervised space, free space, and cross-border collaboration amid geopolitical rivalry},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generation gap? the branching influence of historical myths. <em>ORSC</em>, <em>36</em>(5), 1881-1908. (<a href='https://doi.org/10.1287/orsc.2022.16982'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite recent theorizing on the power of rhetorical histories, scholars have yet to consider the dynamics of organizational generations (i.e., collectives defined by temporally proximal organizational entry and shared experiences and memories of organizational events) involved in their creation and long-term effects. Based on a comparative case study of two union organizations that participated in failed initiatives, we produce a parallel process model of cross-generational historical branching explaining the divergent and long-term influences of using history strategically across generational lines. Our model unpacks how theoretically distinct forms of what has been deemed “historical myth” offered by senior generations, while harboring similar utility in building cross-generational support, underlie divergent outcomes regarding how members across generations respond to subsequent failure and, in turn, historically position the initiative. We further suggest these processes have a lingering impact on an organization’s willingness to engage in a subsequent initiative. Our theory sheds light on the ways in which historical myths shared across generational divides, in tandem with the cross-generational mnemonic communities they create, engender divergent, long-term, and potentially unexpected consequences. Funding: This work was supported by Ministry of Education of the Republic of Korea and National Research Foundation of Korea [Grant NRF-2020S1A5A8042404], the Japan Society for the Promotion of Science [KAKENHI Grant JP16K17159], and the Yonsei Signature Research Cluster Program [Grant 2024-22-0167].},
  archive      = {J_ORSC},
  doi          = {10.1287/orsc.2022.16982},
  journal      = {Organization Science},
  month        = {9-10},
  number       = {5},
  pages        = {1881-1908},
  shortjournal = {Organ. Sci.},
  title        = {Generation gap? the branching influence of historical myths},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning in temporally complex problems: The role of external knowledge. <em>ORSC</em>, <em>36</em>(5), 1861-1880. (<a href='https://doi.org/10.1287/orsc.2022.16469'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore how decision makers utilize external and internal knowledge in problems characterized by temporal complexity where there is a separation between action and outcome. Many strategic and organizational decisions have longer-term consequences, yet behavioral models of learning have underexplored this class of problems. Consequently, we do not know much about the role of external knowledge in tackling temporally complex problems, let alone how it interacts with internal knowledge from experiential learning processes. Our computational analyses show that, although having a greater level of external knowledge is generally advantageous, its positive impact diminishes notably or can even become negative when external knowledge is limited. Surprisingly, decision makers operating with limited external knowledge can perform worse than those without any external guidance at all. In a temporally complex problem, knowing what to do at any given point is not sufficient as one still needs to undertake a long sequence of actions before reaching the goal. In other words, external knowledge does not guarantee that optimal actions will be chosen in subsequent decision-making situations. This dynamic may lead the decision makers to overvalue actions that serve as stepping stones to the available external knowledge and undervalue alternative actions that may provide more desirable paths toward the goal. Funding: This research was supported by the Yonsei University Research Fund of 2021 [2021-22-0098]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/orsc.2022.16469 .},
  archive      = {J_ORSC},
  doi          = {10.1287/orsc.2022.16469},
  journal      = {Organization Science},
  month        = {9-10},
  number       = {5},
  pages        = {1861-1880},
  shortjournal = {Organ. Sci.},
  title        = {Learning in temporally complex problems: The role of external knowledge},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Concerted quantification: How knowledge workers limit overwork while maintaining client satisfaction. <em>ORSC</em>, <em>36</em>(5), 1834-1860. (<a href='https://doi.org/10.1287/orsc.2023.17738'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge workers are increasingly overworked, with negative consequences for both individuals and organizations. Pressures for long hours often come from clients, and the quantification of work has, in many cases, amplified these pressures. We examine when and how workers might rely upon quantification to limit overwork. We draw on data from a 21-month ethnography of information technology worker teams that develop software for clients in finance. We find that although these workers faced overwork pressures, they managed this tension through a process we label “concerted quantification.” This process has three steps. First, team members constructed quantified units based on disparate work tasks to coordinate on a specific set of tasks that would likely limit overwork. Second, workers leveraged these quantified units to create flexibility in when specific work tasks were performed, allowing workers to limit overwork when facing fluctuating work demands. Third, workers promoted quantified units to clients as a standard measure of performance, establishing the completion of these units as a key criterion for work success. Particular substantiations of common characteristics of knowledge work—team autonomy, task expertise, and shared quality norms—are conditions for concerted quantification. Overall, we find that quantifying processes (a) help teams determine an appropriate amount of work to take on without engaging in overwork and (b) set clients’ expectations for the amount of work to be completed. We contribute to research on overwork and quantification by highlighting how quantification can, under certain conditions, support workers in limiting overwork.},
  archive      = {J_ORSC},
  doi          = {10.1287/orsc.2023.17738},
  journal      = {Organization Science},
  month        = {9-10},
  number       = {5},
  pages        = {1834-1860},
  shortjournal = {Organ. Sci.},
  title        = {Concerted quantification: How knowledge workers limit overwork while maintaining client satisfaction},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When lives are at stake: Managing temporal complexity with a strategy process repertoire. <em>ORSC</em>, <em>36</em>(5), 1803-1833. (<a href='https://doi.org/10.1287/orsc.2022.17173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humanitarian organizations assisting victims of armed conflict face fragmented and potentially conflicting temporal demands on strategy making. Annual donor funding requires detailed planning, unpredictable outbreaks of war and violence demand quick and flexible decisions, and long-term societal challenges must be addressed over the next decades. Few studies have examined how organizations can achieve temporal fit in such temporally complex environments without accepting internal fragmentation or decoupling from certain temporal demands. We draw on a longitudinal case study of the International Committee of the Red Cross (ICRC), a humanitarian organization with the mandate to aid victims of armed conflict, to explore this gap. We find that the ICRC has developed a repertoire of multiple distinct strategy processes tailored to the fragmented temporal demands. These processes include emergency responses, strategic planning, and long-term strategizing. Although each strategy process retained its distinctiveness, their loose coupling ensured a sufficient alignment of resource allocation in pursuit of the organization’s humanitarian mandate. Strong shared principles and an episodic activation of strategy processes helped to manage the inherent complexity of loose coupling. Thus, strategy process repertoires may form a capability supporting strategic decision making in temporally complex environments. Our study contributes to strategy process research by introducing loose coupling as a mechanism for integrating multiple strategy processes with different temporalities, complementing previous studies on strategy processes as a tightly coupled structural context. Furthermore, we advance theorizing on ambitemporality by analyzing how the loose coupling of internal temporal structures may help organizations cope with temporal complexity.},
  archive      = {J_ORSC},
  doi          = {10.1287/orsc.2022.17173},
  journal      = {Organization Science},
  month        = {9-10},
  number       = {5},
  pages        = {1803-1833},
  shortjournal = {Organ. Sci.},
  title        = {When lives are at stake: Managing temporal complexity with a strategy process repertoire},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Algorithmic recommendation tools and experiential learning in clinical care. <em>ORSC</em>, <em>36</em>(5), 1786-1802. (<a href='https://doi.org/10.1287/orsc.2022.16738'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines the relationship between the adoption of algorithmic recommendation tools and experiential learning. We argue that the adoption of an algorithmic recommendation tool will harm experiential learning in organizations by limiting knowledge retention and retrieval. We further argue that the adverse relationship between algorithmic tool adoption and experiential learning will be stronger in organizations operating in low-task-difficulty environments than those in high-task-difficulty ones because organizational members in such organizations are likely to rely more on algorithmic recommendations, experiencing higher skill erosion. In addition, the relationship will be stronger in organizations facing low task variety than in those with high task variety, as these organizations are likely to have more rigid routines and in turn experience higher routine disruption after adopting an algorithmic tool. We utilize data on the adoption of an algorithmic tool called a clinical decision support system (CDSS) in a sample of emergency departments in California and utilize a fixed-effects panel regression with control function to test our arguments. We find that the relationship between cumulative experience and mortality becomes significantly weaker after CDSS adoption, suggesting flatter learning curves. We also find evidence that the effect is moderated by task difficulty and task variety. Supplemental Material: The online appendix is available at https://doi.org/10.1287/orsc.2022.16738 .},
  archive      = {J_ORSC},
  doi          = {10.1287/orsc.2022.16738},
  journal      = {Organization Science},
  month        = {9-10},
  number       = {5},
  pages        = {1786-1802},
  shortjournal = {Organ. Sci.},
  title        = {Algorithmic recommendation tools and experiential learning in clinical care},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On resource complementarity among startups, accelerators, and financial investors: A large-scale analysis of sorting and value creation. <em>ORSC</em>, <em>36</em>(5), 1764-1785. (<a href='https://doi.org/10.1287/orsc.2022.16730'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a theoretical framework and provide empirical evidence on how resource complementarity or substitutability between entrepreneurs and seed investors drives selection and value creation in the context of high-tech startups. Specifically, we argue that seed investors specialized in training programs—startup accelerators—are the ideal match for entrepreneurial teams equipped with strong technological competencies but lacking business knowledge. On the other hand, when entrepreneurs with extensive business knowledge pair up with accelerators, the value created is typically less. Combining information from Crunchbase and LinkedIn, we provide robust empirical evidence based on the assortative matching of start-ups and investors and the ex- post analysis of joint value creation. Funding: S. Breschi gratefully acknowledges financial support from the projects Multilayered Urban Sustainability Action (project code ECS 000037) and Growing Resilient, Inclusive, and Sustainable (project code PE00000018), funded by the European Union’s NextGenerationEU initiative under the National Recovery and Resilience Plan. S. Santamaria gratefully acknowledges financial support from the National University of Singapore [Grant R-313-000-140-133]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/orsc.2022.16730 .},
  archive      = {J_ORSC},
  doi          = {10.1287/orsc.2022.16730},
  journal      = {Organization Science},
  month        = {9-10},
  number       = {5},
  pages        = {1764-1785},
  shortjournal = {Organ. Sci.},
  title        = {On resource complementarity among startups, accelerators, and financial investors: A large-scale analysis of sorting and value creation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The role of reviewer characteristics on the diversity of successful applicants. <em>ORSC</em>, <em>36</em>(5), 1726-1744. (<a href='https://doi.org/10.1287/orsc.2023.17910'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In their efforts to foster diversity and talent, organizations, banks, and venture capitalists utilize the expertise of reviewers to evaluate applications from a broad range of applicants. Reviewers make decisions under different types of cognitive load, such as the necessity to aggregate complex information and workload pressure. To cope with the stress, reviewers might use automatic biases to make decisions faster, which can result in lower organizational diversity. We explore the characteristics of reviewers in a particular setting—patent applications at the U.S. Patent and Trademark Office (USPTO). We leverage quasi-exogenous variation from the random assignment of patent examiners, allowing us to find the causal impact of applicant gender and examiner characteristics on the application success rate. We find evidence that applicants with more female-sounding names have a 3.6-percentage-point lower likelihood of patent approval. We find that a high workload of the examiner leads to a decrease in the likelihood that the patent application of a female inventor would be approved, consistent with theories on coping strategies when experiencing cognitive load. Our results extend to applications filed by teams of inventors. These results suggest that it is essential to manage the stress related to reviewers’ workloads to guarantee a variety of successful candidates. Supplemental Material: The online appendix is available at https://doi.org/10.1287/orsc.2023.17910 .},
  archive      = {J_ORSC},
  doi          = {10.1287/orsc.2023.17910},
  journal      = {Organization Science},
  month        = {9-10},
  number       = {5},
  pages        = {1726-1744},
  shortjournal = {Organ. Sci.},
  title        = {The role of reviewer characteristics on the diversity of successful applicants},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analyst reaction to war-related language: Source domains and the role of market structure and market share. <em>ORSC</em>, <em>36</em>(5), 1690-1725. (<a href='https://doi.org/10.1287/orsc.2021.15728'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Corporate executives often use metaphors, particularly those derived from war imagery, when communicating their strategic intentions. This study examines the influence of metaphorical framing in corporate communication, particularly its effect on analyst reactions to firms’ acquisition announcements. We theorize and analyze the impact of metaphor families that either emphasize or downplay competition while considering the diverse source domains from which these metaphors originate. We propose a theoretical framework that integrates conceptual metaphor theory with the risk-as-feelings perspective, suggesting that certain metaphors can evoke visceral perceptions of danger. Our findings reveal that using metaphors in acquisition announcements generally elicits negative reactions. Notably, metaphors from the competition family, especially war-related ones signifying competitive aggression, evoke stronger adverse reactions. The detrimental impact of war language substantially diminishes in contexts where aggressive competition is expected. We contribute to strategic communication research by highlighting the contingent influence of metaphorical framing on audience reactions, emphasizing the importance of metaphor families, source domains, and contextual factors. Funding: J. C. Salvado acknowledges funding through the FCT – Foundation for Science and Technology, I.P., within the scope of the grant “UID/GES/00407/2020”. D. Crilly was supported by the H2020 European Research Council [Grant 820075].},
  archive      = {J_ORSC},
  doi          = {10.1287/orsc.2021.15728},
  journal      = {Organization Science},
  month        = {9-10},
  number       = {5},
  pages        = {1690-1725},
  shortjournal = {Organ. Sci.},
  title        = {Analyst reaction to war-related language: Source domains and the role of market structure and market share},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The misfit bias. <em>ORSC</em>, <em>36</em>(5), 1676-1689. (<a href='https://doi.org/10.1287/orsc.2023.17462'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consumers and other audiences often penalize products that combine unrelated elements. In this paper, we document the consequences of that penalty for the evaluation of the elements being combined. Building on the idea that audiences cannot fully disentangle the quality of “fit” between elements from the quality of the elements individually, we argue that audiences are likely to direct their dislike of a misfit product to the individual elements being combined. Using an archival study of the music industry and an online experiment with photographic galleries, we find that evaluations of individual elements (songs, photographs) are influenced by product-level fit (albums, galleries). Elements of misfit products are evaluated less favorably than they would have been otherwise. Moreover, this bias is exacerbated when the evaluation of the whole product is emphasized. We discuss the implications of this “misfit bias” for the innovation, entrepreneurship, and categories literatures. Supplemental Material: The online appendix is available at https://doi.org/10.1287/orsc.2023.17462 .},
  archive      = {J_ORSC},
  doi          = {10.1287/orsc.2023.17462},
  journal      = {Organization Science},
  month        = {9-10},
  number       = {5},
  pages        = {1676-1689},
  shortjournal = {Organ. Sci.},
  title        = {The misfit bias},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Confronting the limits of symbolic actions: How entrepreneurs narrow the presentation-performance gap. <em>ORSC</em>, <em>36</em>(5), 1643-1675. (<a href='https://doi.org/10.1287/orsc.2023.17904'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entrepreneurs often skillfully leverage symbolic actions to manage impressions and gain acceptance for their innovations. Impression management can generate interest but also heighten expectations beyond an innovation’s capabilities, creating a gap between entrepreneurs’ symbolic presentations and an innovation’s performance. To convince critical audiences, entrepreneurs need to not just manage impressions but also show how their innovations will integrate and work in situ. Yet, little research explains what happens when symbolic actions meet their limits. How do entrepreneurs respond when critical audiences challenge their symbolic actions? We examine how 28 digital health start-ups were challenged by a critical audience (buyers), revealing a gap between entrepreneurs’ symbolic presentations and the performance of their innovations. We examine how entrepreneurs managed this gap with buyers at 13 organizations and identify three pathways. Continuing to manage impressions obfuscated the discovery of integration work, widening the gap. Iterating with substantive adaptations did not sufficiently narrow the gap. Only entrepreneurs who recalibrated expectations were able to enlist buyers in the mutual discovery of integration work. These entrepreneurs shared the costs of narrowing the gap with buyers, despite earlier symbolic promises. We contribute to an emerging appreciation of the duality of symbolic actions by explaining what happens when entrepreneurs’ symbolic actions are challenged and how their responses can exacerbate or eradicate that challenge. Funding: The authors acknowledge the financial support of the Harvard Business School and the Questrom School of Business, Boston University.},
  archive      = {J_ORSC},
  doi          = {10.1287/orsc.2023.17904},
  journal      = {Organization Science},
  month        = {9-10},
  number       = {5},
  pages        = {1643-1675},
  shortjournal = {Organ. Sci.},
  title        = {Confronting the limits of symbolic actions: How entrepreneurs narrow the presentation-performance gap},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="serv">SERV - 4</h2>
<ul>
<li><details>
<summary>
(2025). Clothing consumers’ aesthetic preferences and sustainable marketing model system based on kansei engineering. <em>SERV</em>, <em>17</em>(2-3), 111-126. (<a href='https://doi.org/10.1287/serv.2024.0179'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {China’s online retail sales growth rate of men’s plain color shirts had declined because they could not meet customers’ aesthetic value needs. This study aims to determine consumers’ aesthetic value preferences and corresponding design elements. Based on Kansei Engineering, a semantic differential scale questionnaire was conducted with seven crucial Kansei words and styling specimens. Then, researchers validated these Kansei words using principal component analysis. More significantly, this study used partial least squares to construct a relationship between crucial Kansei words and styling design elements. Furthermore, researchers obtained the matching colors corresponding to Kansei words in the color image scale. Thus, Kansei words, styling design elements, and corresponding colors made up the recommendation guidelines. Lastly, questionnaires and interviews were used to verify the effectiveness of these guidelines. These recommendation guidelines were the most important results of this study. Besides, this study also found that the recent popular oversized fit appeared in distinctive and casual styles, but the audience is relatively small. Purchasers preferred a one-button square cuff, and the separate left-side pocket is more popular than both-side pockets. Purchasers liked the wide-spread collar compared with the classical pointed collar because it appeared most frequently in recommendation guidelines. Classic fit was still the mainstream, but its popularity would decline. In addition, modern fit and slim fit would become increasingly popular. Funding: B. Ge has two funding projects (100%): the Soft Science Research Program of Henan Province, China [Project 252400410636] and the general project of Colleges and Universities Humanities and Social Sciences of the Henan Provincial Department of Education, China [Project 2025-ZDJH-776].},
  archive      = {J_SERV},
  doi          = {10.1287/serv.2024.0179},
  journal      = {Service Science},
  month        = {6-9},
  number       = {2-3},
  pages        = {111-126},
  shortjournal = {Serv. Sci.},
  title        = {Clothing consumers’ aesthetic preferences and sustainable marketing model system based on kansei engineering},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Collaboration between an airline and railways to reduce the cancellation-risk of waitlisted passengers and improve seat utilization. <em>SERV</em>, <em>17</em>(2-3), 92-110. (<a href='https://doi.org/10.1287/serv.2024.0146'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a setting in which two rivals, an airline and railways, create value through a new joint service that reduces the cancellation-risk of waitlisted passengers. This setting is motivated by a recent collaboration between a railway company and two low-cost airlines in India. Under this arrangement, the railways offers train ticket holders whose reservations are not confirmed the option to upgrade to a flight ticket on the same route for an additional fee. The airline sets the price for the upgrade while the railways charges the airline a referral commission. The new service creates value for waitlisted passengers and thereby stimulates additional demand for the railways and the airline. We analyze the strategic interactions that arise from this collaboration, derive the equilibrium upgrade prices and commission, and compare the outcomes to those under centralized decision-making. Our findings demonstrate that cooperation between two competing service providers can create a mutually beneficial outcome for both firms as well as for consumers. Notably, the airline and the railways can generate profit from the collaboration only if they engage in a sequential game; a simultaneous-move game fails to generate any value. Furthermore, we identify scenarios in which increasing railway capacity also benefits the airline by stimulating additional demand. Finally, we analyze the case of strategic consumers who reduce the value created from the collaboration, and we show that the price difference between early and late booking mitigates such strategic behavior. Supplemental Material: The online appendix is available at https://doi.org/10.1287/serv.2024.0146 .},
  archive      = {J_SERV},
  doi          = {10.1287/serv.2024.0146},
  journal      = {Service Science},
  month        = {6-9},
  number       = {2-3},
  pages        = {92-110},
  shortjournal = {Serv. Sci.},
  title        = {Collaboration between an airline and railways to reduce the cancellation-risk of waitlisted passengers and improve seat utilization},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Psychological distance and algorithm aversion: Congruency and advisor confidence. <em>SERV</em>, <em>17</em>(2-3), 74-91. (<a href='https://doi.org/10.1287/serv.2023.0054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Employees and consumers have varying preferences between human and algorithmic advisors. Drawing on construal level theory, I hypothesize that individual differences in algorithm aversion can be explained by the perception that algorithms are psychologically farther away than human advisors. The first set of studies ( n = 266) shows that algorithms are viewed as abstract and distant compared with humans, even when their outputs are perceived at a low-level construal, challenging prior research. Leveraging construal congruency, the second set of studies ( n = 1,148) shows that farther within-task psychological distance generally increases preference for algorithmic advisors due to differences in advisor confidence. Specifically, I contribute to the literature by showing that a far psychological distance within a task reduces confidence in human advisors. In contrast, confidence in algorithms remains stable, increasing algorithm appreciation at farther within-task distances. History: This paper has been accepted for the Service Science Special Section on Navigating the Use of Technology in Service Marketing. Supplemental Material: The online appendix is available at https://doi.org/10.1287/serv.2023.0054 .},
  archive      = {J_SERV},
  doi          = {10.1287/serv.2023.0054},
  journal      = {Service Science},
  month        = {6-9},
  number       = {2-3},
  pages        = {74-91},
  shortjournal = {Serv. Sci.},
  title        = {Psychological distance and algorithm aversion: Congruency and advisor confidence},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Introduction to service science special section on navigating the use of technology in service marketing. <em>SERV</em>, <em>17</em>(2-3), 73. (<a href='https://doi.org/10.1287/serv.2025.intro.v17.n2-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SERV},
  doi          = {10.1287/serv.2025.intro.v17.n2-3},
  journal      = {Service Science},
  month        = {6-9},
  number       = {2-3},
  pages        = {73},
  shortjournal = {Serv. Sci.},
  title        = {Introduction to service science special section on navigating the use of technology in service marketing},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="stsc">STSC - 5</h2>
<ul>
<li><details>
<summary>
(2025). Signposts for problemistic search: Reference points and adaptation in rugged landscapes. <em>STSC</em>, <em>10</em>(3), 263-279. (<a href='https://doi.org/10.1287/stsc.2023.0072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reference points form an essential element of organizations’ problemistic search and adaptation behavior. Yet, if search is triggered by shortfalls compared with peers but alternatives are discovered on the fly, it is not clear whether and when peer comparison leads to better search outcomes. We contribute to the literature by studying how reference points guide search and which outcomes they allow organizations to achieve. Specifically, we develop a model of search in complex landscapes in which agents’ search behavior is guided by an upper (aspiration-level) social reference point and a lower (survival-point) social reference point. In our model, agents move across a subjective “terraced” landscape that is a simplified transformation of the “real” one. The vertical positions and shapes of these terraces are determined by the agents’ reference points and change over time as a result of their own and their peers’ performance evolution. In turn, these terraces define the search space that is navigated and the outcomes that can be reached. We show that the upper and lower bounds play fundamentally different roles in the search process, with the upper bound being more important in the short run and the lower bound more important in the long run. Studying heterogeneous populations, we find that reference points drive dynamic trade-offs between how easily decision makers can reach their aspiration level and how much they benefit from doing so. We highlight the importance of both internal fit between reference points and external fit with environmental factors. Supplemental Material: The online appendix is available at https://doi.org/10.1287/stsc.2023.0072 .},
  archive      = {J_STSC},
  doi          = {10.1287/stsc.2023.0072},
  journal      = {Strategy Science},
  month        = {9},
  number       = {3},
  pages        = {263-279},
  shortjournal = {Strat. Sci.},
  title        = {Signposts for problemistic search: Reference points and adaptation in rugged landscapes},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extending intellectual property research in copyright: A new data set from the U.S. copyright office. <em>STSC</em>, <em>10</em>(3), 245-262. (<a href='https://doi.org/10.1287/stsc.2023.0130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a newly available data set containing U.S. copyright records for 1978–2021. The data include nearly 19 million copyright registrations, as well as more than 12 million records of copyright renewals, terminations of granted rights, rights transfers, and other activities. The data include both raw and processed files, along with code books, documentation, and our data processing scripts; we provide tips and guidelines for using these data. We facilitate further research by linking copyright registration records with firm identifiers in Compustat as well as U.S. federal litigation data. We then use the data for three descriptive exercises. First, we characterize the relative usage of patenting and copyright protection across firms and industries. Second, we document the propensities for firms registering copyrights to be involved in copyright litigation. Third, we compare actual data on the incidence of copyright and patent registration with commonly used proxies: advertising and research and development expenditure. We hope that the availability of these data can facilitate progress on copyright research to parallel the broader intellectual property literature that has blossomed since patent data became widely available. Supplemental Material: The online appendix is available at https://doi.org/10.1287/stsc.2023.0130 .},
  archive      = {J_STSC},
  doi          = {10.1287/stsc.2023.0130},
  journal      = {Strategy Science},
  month        = {9},
  number       = {3},
  pages        = {245-262},
  shortjournal = {Strat. Sci.},
  title        = {Extending intellectual property research in copyright: A new data set from the U.S. copyright office},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Management by originals: Inventor CEOs and firms’ strategic change. <em>STSC</em>, <em>10</em>(3), 226-244. (<a href='https://doi.org/10.1287/stsc.2023.0058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We build upon theories and studies regarding inventors and strategic leadership to explain how inventor CEOs are likely to drive a firm’s strategic change. We explain why inventor CEOs have the unique attributes of divergent thinking and intrinsic motivation and, accordingly, pursue strategies that deviate from the past. We further suggest that the positive relationship between inventor CEO status and strategic change is strengthened by CEO liberalism, CEO career variety, and industry dynamism. Using a comprehensive longitudinal database of S&P 1500 firms, we test our theoretical predictions and find empirical support for most of our hypotheses except for the moderating effect of industry dynamism. In highlighting the prevalence of inventor CEOs and showing how this achievement-based experience of CEOs is related to strategic change, our study identifies an important and novel antecedent of this important strategic outcome. Supplemental Material: The online appendix is available at https://doi.org/10.1287/stsc.2023.0058 .},
  archive      = {J_STSC},
  doi          = {10.1287/stsc.2023.0058},
  journal      = {Strategy Science},
  month        = {9},
  number       = {3},
  pages        = {226-244},
  shortjournal = {Strat. Sci.},
  title        = {Management by originals: Inventor CEOs and firms’ strategic change},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From church leadership to firm leadership: Religion of early state residents, state institutions, and present-day corporate female executives. <em>STSC</em>, <em>10</em>(3), 207-225. (<a href='https://doi.org/10.1287/stsc.2024.0244'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I argue that early residents of a U.S. state have left imprints in the state constitution to reflect their religious preferences. Such imprints help explain the varying constitutions across U.S. states, which in turn affect the present-day female representation in corporate leadership. Analyzing a firm-level data set supplemented by a state-level sample and extensive robustness checks, I find that the prevalence of Protestantism at the time of a U.S. state’s admission to the Union is positively related to female representation in the leadership teams of S&P 1500 firms. One mechanism for the persistence of the Protestant imprinting is state constitutions’ emphasis on equality issues. In addition, the historical Catholic immigration to different states, serving as a counter-imprinting force, has weakened this effect. My study contributes to imprinting theory by considering dynamics and developing a regional-level institutional imprinting perspective. I also contribute to a more nuanced understanding of historical antecedents and contemporary firm consequences of subnational institutions, tracing the persistent heterogeneities among firms to some deep historical roots.},
  archive      = {J_STSC},
  doi          = {10.1287/stsc.2024.0244},
  journal      = {Strategy Science},
  month        = {9},
  number       = {3},
  pages        = {207-225},
  shortjournal = {Strat. Sci.},
  title        = {From church leadership to firm leadership: Religion of early state residents, state institutions, and present-day corporate female executives},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CEO succession and patenting in family firms. <em>STSC</em>, <em>10</em>(3), 185-206. (<a href='https://doi.org/10.1287/stsc.2023.0122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Much research has examined whether family firms led by family or professional CEOs differ in terms of financial performance. Yet, whether family CEOs promote or hinder innovation remains an open question. Given the importance of innovation as well as the ubiquity of family enterprises, this is a major gap. In this study, we focus on a large sample of Danish firms and examine the patenting performance (in terms of patent counts and citations) of these firms. We exploit the gender of departing CEOs’ first-born children to yield exogenous variations in the decision to appoint a family or professional CEO. Our difference-in-differences results indicate that appointing a family CEO leads to an increase in patent counts and citations relative to appointing a professional CEO. These effects are driven by incoming family CEOs who hold a university degree in engineering and, to a lesser extent, business. Appointing a family CEO also leads to fewer job terminations, which suggests that the increase in patenting might stem from higher job stability and tolerance for failure among employees. Our study has implications for the growing literature on the management of family firms and, more broadly, for strategy research on CEO succession. Funding: The ICRIOS Research Center at Bocconi University provided financial support.},
  archive      = {J_STSC},
  doi          = {10.1287/stsc.2023.0122},
  journal      = {Strategy Science},
  month        = {9},
  number       = {3},
  pages        = {185-206},
  shortjournal = {Strat. Sci.},
  title        = {CEO succession and patenting in family firms},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="stsy">STSY - 3</h2>
<ul>
<li><details>
<summary>
(2025). Almost sure one-endedness of a random graph model of distributed ledgers. <em>STSY</em>, <em>15</em>(3), 252-272. (<a href='https://doi.org/10.1287/stsy.2023.0045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed ledgers (DLs) are modern decentralized databases where trusted network members can transparently update data while maintaining security. IOTA is an exemplar alternative to the well-known Bitcoin protocol, and such alternatives, which aim to overcome shortcomings, have gained increasing attention recently. These systems warrant deeper theoretical analysis using directed acyclic graph (DAG) models. One essential property of a properly functioning DL is that all network members holding a copy of the database agree on the sequence of information added, which is referred to as consensus and is known to be related to a structural property of DAGs called one-endedness. In this paper, we consider a model of a DL with sequential stochastic arrivals that mimic IOTA’s attachment rules. Although the resulting DAG model is more complex than Bitcoin, we demonstrate that as time goes to infinity, the IOTA DAG almost surely achieves one-endedness.},
  archive      = {J_STSY},
  doi          = {10.1287/stsy.2023.0045},
  journal      = {Stochastic Systems},
  month        = {9},
  number       = {3},
  pages        = {252-272},
  shortjournal = {Stoch. Syst.},
  title        = {Almost sure one-endedness of a random graph model of distributed ledgers},
  volume       = {15},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal control of queueing systems with error-prone servers. <em>STSY</em>, <em>15</em>(3), 220-251. (<a href='https://doi.org/10.1287/stsy.2024.0061'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider a Markovian tandem line with finite intermediate buffers and an equal number of stations and servers. Servers are flexible but noncollaborative, so that a job can be processed by at most one server at any time. When a job is being processed, it can be damaged and wasted depending on the proficiency of the server. We identify the dynamic server assignment policy that maximizes the long-run average throughput of the system with two stations and two servers. We find that the optimal policy is either a single or a double threshold policy on the number of jobs in the buffer, where the thresholds depend on the service rates and defect probabilities of the two servers at the two stations. For larger systems, we show that the optimal policy may involve server idling and that improving the service rate at any station is always beneficial. Finally, we propose heuristic server assignment policies motivated by experimentation for small systems with finite buffers and analysis of larger systems with infinite buffers. Numerical results suggest that our heuristics yield near-optimal performance. Funding: This research was supported by the National Science Foundation [Grants CMMI-1536990 and CMMI-2127778]. S. Andradóttir was also supported by the National Science Foundation [Grant CMMI-2348409].},
  archive      = {J_STSY},
  doi          = {10.1287/stsy.2024.0061},
  journal      = {Stochastic Systems},
  month        = {9},
  number       = {3},
  pages        = {220-251},
  shortjournal = {Stoch. Syst.},
  title        = {Optimal control of queueing systems with error-prone servers},
  volume       = {15},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Queueing, predictions, and large language models: Challenges and open problems. <em>STSY</em>, <em>15</em>(3), 195-219. (<a href='https://doi.org/10.1287/stsy.2025.0106'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Queueing systems present many opportunities for applying machine learning predictions, such as estimated service times, to improve system performance. This integration raises numerous open questions about how predictions can be effectively leveraged to improve scheduling decisions. Recent studies explore queues with predicted service times, typically aiming to minimize job time in the system. We review these works, highlight the effectiveness of predictions, and present open questions on queue performance. We then move to consider an important practical example of using predictions in scheduling, namely large language model (LLM) systems, which presents novel scheduling challenges and highlights the potential for predictions to improve performance. In particular, we consider LLMs performing inference. Inference requests (jobs) in LLM systems are inherently complex; they have variable inference times, dynamic memory footprints that are constrained by key-value store memory limitations, and multiple possible preemption approaches that affect performance differently. We provide background on the important aspects of scheduling in LLM systems and introduce new models and open problems that arise from them. We argue that there are significant opportunities for applying insights and analysis from queueing theory to scheduling in LLM systems. Funding: M. Mitzenmacher was supported in part by the National Science Foundation [Grant CCF-2101140]. R. Shahout was supported in part by the Schmidt Futures Initiative and the Zuckerman Institute. M. Mitzenmacher and R. Shahout were supported in part the National Science Foundation [Grants CNS-2107078 and DMS-2023528].},
  archive      = {J_STSY},
  doi          = {10.1287/stsy.2025.0106},
  journal      = {Stochastic Systems},
  month        = {9},
  number       = {3},
  pages        = {195-219},
  shortjournal = {Stoch. Syst.},
  title        = {Queueing, predictions, and large language models: Challenges and open problems},
  volume       = {15},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="trsc">TRSC - 13</h2>
<ul>
<li><details>
<summary>
(2025). Learning state-dependent policy parametrizations for dynamic technician routing with rework. <em>TRSC</em>, <em>59</em>(5), 1153-1171. (<a href='https://doi.org/10.1287/trsc.2024.0844'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Home repair and installation services require technicians to visit customers and resolve tasks of different complexities. Technicians often have heterogeneous skills. The geographical spread of customers makes achieving only “ideal” matches between technician skills and task requirements impractical. Additionally, technicians are regularly absent, for example, due to sickness. With only nonideal assignments regarding task requirement and technician skill, some tasks may remain unresolved and require a revisit and rework at a later day, leading to delayed service. For this sequential decision problem, every day, we iteratively build tours by adding “important” customers. The importance bases on analytical considerations and is measured by respecting urgency of service, routing efficiency, and risk of rework in an integrated fashion. We propose a state-dependent balance of these factors via reinforcement learning. We rely on proximal policy optimization (PPO) tailored to the problem specifics, analyzing the implications of specific algorithmic augmentations. A comprehensive study shows that taking a few nonideal assignments can be quite beneficial for the overall service quality. Furthermore, in states where a higher number of technicians are sick and many customers have overdue service deadlines, prioritizing service urgency is crucial. Conversely, in states with fewer sick technicians and fewer customers with overdue deadlines, routing efficiency should take precedence. We further demonstrate the value provided by a state-dependent parametrization via PPO. Funding: This work was supported by the Deutsche Forschungsgemeinschaft [Grants 413322447 and 444657906]. Supplemental Material: The online appendices are available at https://doi.org/10.1287/trsc.2024.0844 .},
  archive      = {J_TRSC},
  doi          = {10.1287/trsc.2024.0844},
  journal      = {Transportation Science},
  month        = {9-10},
  number       = {5},
  pages        = {1153-1171},
  shortjournal = {Trans. Sci.},
  title        = {Learning state-dependent policy parametrizations for dynamic technician routing with rework},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing warehouse operations with autonomous mobile robots. <em>TRSC</em>, <em>59</em>(5), 1130-1152. (<a href='https://doi.org/10.1287/trsc.2024.0800'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous mobile robots (AMRs) can support human pickers in warehouse picking operations by reducing picker walking distance and increasing the warehouse’s throughput. AMR-assisted order picking is becoming popular as it can be conveniently implemented in conventional warehouses. This study proposes an integrated optimization model for scheduling the operations in AMR-assisted picker-to-parts warehouse systems. The model aims to minimize the makespan of all picking operations for a batch of orders by assigning batched orders to AMRs, selecting storage racks for AMRs and pickers to visit, and determining the routes of the AMRs and the pickers. A column- and row-generation algorithm is designed to solve the model using synchronization constraints between AMRs and pickers. Numerical experiments are conducted to validate the applicability of our proposed algorithm in a warehouse that handles 16,000 orders per day. Our algorithm can solve small-scale instances to optimality. Our algorithm can also obtain better solutions in less time than a column generation (CG)–based method. Extensive experiments are conducted to derive managerial insights. Funding: This research was supported by the National Natural Science Foundation of China [Grants 72025103, 72394360, 72394362, 72401179, 72361137001, and 72371221], the Project of Science and Technology Commission of Shanghai Municipality China [Grant 23JC1402200], and the Research Grants Council of the Hong Kong Special Administrative Region, China (Project number HKSAR RGC TRS T32-707/22-N). Supplemental Material: The online appendix is available at https://doi.org/10.1287/trsc.2024.0800 .},
  archive      = {J_TRSC},
  doi          = {10.1287/trsc.2024.0800},
  journal      = {Transportation Science},
  month        = {9-10},
  number       = {5},
  pages        = {1130-1152},
  shortjournal = {Trans. Sci.},
  title        = {Optimizing warehouse operations with autonomous mobile robots},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparison of two models for rolling stock scheduling. <em>TRSC</em>, <em>59</em>(5), 1101-1129. (<a href='https://doi.org/10.1287/trsc.2024.0505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A major step in the planning process of passenger railway operators is the assignment of rolling stock, that is, train units, to the trips of the timetable. A wide variety of mathematical optimization models have been proposed to support this task, which we discuss and argue to be justified in order to deal with operational differences between railway operators, and hence different planning requirements, in the best possible way. Our investigation focuses on two commonly used models, the composition model and the hypergraph model, that were developed for Netherlands Railways (NS) and DB Fernverkehr AG (DB), respectively. We compare these models in two distinct problem settings, an NS setting and DB-light setting and consider different model variants to tune the models to these settings. We prove that in both of these settings, the linear programming bounds of the two models are equally strong as long as a number of reasonable assumptions are met. However, through a numerical evaluation on NS and DB-light instances, we show that the numerical performance of the models strongly depends on the instances. Although the composition model is the most compact and fastest model for the NS instances, an adjusted version of this model grows quickly for the DB-light instances and is then outperformed by the considered hypergraph model variants. Moreover, we show that a depot-extended version of the hypergraph model is able to combine strengths of both models and show good performance on both the NS and DB-light instances. Funding: This work was supported by the Bundesministerium für Bildung und Forschung [Grant 05M14ZAM] and the Stichting Erasmus Trustfonds.},
  archive      = {J_TRSC},
  doi          = {10.1287/trsc.2024.0505},
  journal      = {Transportation Science},
  month        = {9-10},
  number       = {5},
  pages        = {1101-1129},
  shortjournal = {Trans. Sci.},
  title        = {A comparison of two models for rolling stock scheduling},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrated learning and optimization for joint routing and loading decisions in preowned automobile shipping. <em>TRSC</em>, <em>59</em>(5), 1076-1100. (<a href='https://doi.org/10.1287/trsc.2024.0712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study highway-based shipping of preowned automobiles by auto carriers, an important although overlooked problem in the automobile shipping literature. The special structure associated with auto carriers implies many different ways of loading a set of automobiles to an auto carrier with different loading costs. Thus, in addition to vehicle routing decisions, loading decisions are essential in automobile shipping optimization. The objective of our problem is to maximize the total revenue minus the total routing and loading cost subject to time windows and loading constraints among others. Most existing automobile shipping studies treat loading and routing separately; some studies partially address the loading aspect in routing optimization but only check the loading feasibility without evaluating the quality of loading decisions. We, thus, contribute to the literature by fully integrating loading decisions into routing decision making. An integrated machine learning (ML) and optimization approach is proposed to solve the problem. The overall approach follows a column generation–based solution framework, in which an insertion heuristic is proposed to find new routes based on existing routes, and ML is employed to predict the loading feasibility and estimate the minimum loading cost of a given route without solving the complex loading optimization problem. The integration of the ML approach and the insertion heuristic enables us to find high-quality new routes quickly in each column generation iteration. Two variants of this integrated approach are evaluated against a benchmark sequential approach in which routing and loading are tackled separately and another benchmark approach in which routing and loading are optimized jointly without using ML. Computational experiments demonstrate that the proposed integrated ML and optimization approach generates significantly better solutions than the sequential benchmark approach with only slightly more computation time and similar solutions to the joint optimization benchmark approach but with significantly less computation time. The proposed solution approach can be adopted by automobile shipping companies. It can also be adapted for other joint optimization problems, such as those in aircraft load planning. Funding: Y. Sun is partially supported by the National Science Foundation [Grants 2332161, 2100745, and 2055347]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/trsc.2024.0712 .},
  archive      = {J_TRSC},
  doi          = {10.1287/trsc.2024.0712},
  journal      = {Transportation Science},
  month        = {9-10},
  number       = {5},
  pages        = {1076-1100},
  shortjournal = {Trans. Sci.},
  title        = {Integrated learning and optimization for joint routing and loading decisions in preowned automobile shipping},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Outbound load planning in parcel delivery service networks using machine learning and optimization. <em>TRSC</em>, <em>59</em>(5), 1057-1075. (<a href='https://doi.org/10.1287/trsc.2024.0672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The load planning problem is a critical challenge in service network design for parcel carriers: it decides how many trailers (or loads), perhaps of different types, to assign for dispatch over time between pairs of terminals. Another key challenge is to determine a flow plan that specifies how parcel volumes are assigned to planned loads. This paper considers the Outbound Load Planning Problem (OLPP) that considers flow and load planning challenges jointly to adjust loads and flows as demand forecast changes over time before the day of terminal operations. The paper develops a decision support tool to inform planners making these decisions at terminals across the network. It formulates the OLPP as a mixed-integer programming (MIP) model and shows that it admits a large number of symmetries in a network where each commodity can be routed through primary and alternate terminals. As a result, an optimization solver may return fundamentally different solutions to closely related problems (i.e., OLPPs with slightly different inputs), confusing planners and reducing trust in optimization. To remedy this limitation, the first contribution of the paper is to propose a lexicographical optimization approach that eliminates those symmetries by generating optimal solutions while staying close to a reference plan. The second contribution of the paper is the design of an optimization proxy that addresses the computational challenges of the optimization model. The optimization proxy combines a machine learning model and an MIP-based repair procedure to find near-optimal solutions that satisfy real-time constraints imposed by planners in the loop. An extensive computational study on industrial instances shows that the optimization proxy is around 10 times faster than the commercial solver in obtaining solutions of similar quality; the optimization proxy is also orders of magnitude faster for generating solutions that are consistent with each other. The proposed approach also demonstrates the benefits of the OLPP for load consolidation and the significant savings obtained from combining machine learning and optimization. Funding: This work was supported by the NSF AI Institute for Advances in Optimization [Grant Award 2112533]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/trsc.2024.0672 .},
  archive      = {J_TRSC},
  doi          = {10.1287/trsc.2024.0672},
  journal      = {Transportation Science},
  month        = {9-10},
  number       = {5},
  pages        = {1057-1075},
  shortjournal = {Trans. Sci.},
  title        = {Outbound load planning in parcel delivery service networks using machine learning and optimization},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scenario predict-then-optimize for data-driven online inventory routing. <em>TRSC</em>, <em>59</em>(5), 1032-1056. (<a href='https://doi.org/10.1287/trsc.2024.0613'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The real-time joint optimization of inventory replenishment and vehicle routing is essential for cost-efficiently operating one-warehouse, multiple-retailer systems. This is complex because future demand predictions should capture (auto)correlation and lumpy retailer demand, and based upon such predictions, inventory replenishment and vehicle-routing decisions must be taken. Traditionally, such decisions are made by either making distributional assumptions or using machine-learning-based point forecasts. The former approach ignores nonstationary demand patterns, whereas the latter approach provides only a point forecast ignoring the inherent forecast error. Consequently, in practice, service levels often do not meet their targets, and truck fill rates fall short, harming the efficiency and sustainability of daily operations. We propose Scenario Predict-then-Optimize. This fully data-driven approach for online inventory routing consists of two subsequent steps at each real-time decision epoch. The scenario-predict step exploits neural networks—specifically multi-horizon quantile recurrent neural networks—to predict future demand quantiles, upon which we design a scenario sampling approach. The subsequent scenario-optimize step then solves a scenario-based two-stage stochastic programming approximation. Results show that our approach outperforms a classic sequential learning and (stochastic) optimization approach, distributional approaches, empirical sampling methods, residuals-based sample average approximation, and a state-of-the-art integrated learning and (stochastic) optimization approach. We show this on both synthetic data and large-scale real-life data from our industry partner. Our approach is appealing to practitioners. It is fast, does not rely on any distributional assumption, and does not face the burden of single-scenario forecasts. It also outperforms residuals-based scenario generation techniques. We show that it is robust for various demand and cost parameters, enhancing the efficiency and sustainability of daily inventory replenishment and truck-routing decisions. Finally, scenario Predict-then-Optimize is general and can be easily extended to account for other operational constraints, making it a useful tool in practice. Supplemental Material: The online appendix is available at https://doi.org/10.1287/trsc.2024.0613 .},
  archive      = {J_TRSC},
  doi          = {10.1287/trsc.2024.0613},
  journal      = {Transportation Science},
  month        = {9-10},
  number       = {5},
  pages        = {1032-1056},
  shortjournal = {Trans. Sci.},
  title        = {Scenario predict-then-optimize for data-driven online inventory routing},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing an on-demand delivery mode based on trucks and drones. <em>TRSC</em>, <em>59</em>(5), 1008-1031. (<a href='https://doi.org/10.1287/trsc.2024.0693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore a novel on-demand delivery mode based on cooperation between trucks and drones. A fleet of trucks, each of which carries several drones, travels along a closed-loop route, and the drones are launched from the trucks to pick up (or deliver) ordered parcels from their origin (or to their destination). The fulfillment of an order (i.e., delivering the parcel from its origin to its destination) includes three steps: pick up by a drone, transport by a truck, and delivery by a drone. We investigate how to fulfill all of the orders in one batch in order to minimize the total operational cost. We build a mixed-integer programming (MIP) model for this new on-demand delivery system in a network of multiple routes with transshipment. For drones, the assignment decision regarding the fulfillment stages for the orders and the location decision regarding the launching from and landing onto trucks are optimized by the proposed MIP model. An exact branch-and-price algorithm is designed to efficiently solve the model on large-scale instances. We validate the advantages of our algorithm in terms of computing time and solution quality through experiments on both artificial and real data. We validate the benefits of both implementing this new delivery mode and allowing transshipments among routes using a drone to serve multiple orders in one flying trip and consolidating orders. We also investigate the influences of the number of drones, speed, endurance time, unit penalty cost, and the geographic distribution of orders on the system’s operational cost. Funding: This research was supported by the National Natural Science Foundation of China [Grants 72025103, 72394360, 72394362, 72361137001, and 7237122]; the China Postdoctoral Science Foundation [Grant 2024M761921]; the Project of Science and Technology Commission of Shanghai Municipality China [Grant 23JC1402200]; and the Research Grants Council of the Hong Kong Special Administrative Region, China [Grant HKSAR RGC TRS T32-707/22-N]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/trsc.2024.0693 .},
  archive      = {J_TRSC},
  doi          = {10.1287/trsc.2024.0693},
  journal      = {Transportation Science},
  month        = {9-10},
  number       = {5},
  pages        = {1008-1031},
  shortjournal = {Trans. Sci.},
  title        = {Optimizing an on-demand delivery mode based on trucks and drones},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Classifying pedestrian crossing flows: A data-driven approach using fundamental diagrams and machine learning. <em>TRSC</em>, <em>59</em>(5), 990-1007. (<a href='https://doi.org/10.1287/trsc.2024.0996'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the dynamics of pedestrian crossing flows with varying crossing angles to classify different scenarios and derive implications for crowd management. Probability density functions of four key features—velocity, density, avoidance number, and intrusion number—were analyzed to characterize pedestrian behavior. Velocity–density fundamental diagrams were constructed for each crossing angle and fitted with functional forms from existing literature. Classification attempts using avoidance–intrusion numbers and velocity–density phase spaces revealed significant overlaps, highlighting the limitations of these metrics alone for scenario differentiation. To address this, machine learning models, such as logistic regression and random forest, were employed using all four features. Results showed robust classification performance with velocity and avoidance number emerging as the most influential features. Insights from feature importance metrics and classification accuracy offer practical guidance for managing high-density crowds, optimizing pedestrian flow, and designing safer public spaces. Funding: This research was supported by the National Science Center, Poland through SONATA [Grant 2022/47/D/HS4/02576]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/trsc.2024.0996 .},
  archive      = {J_TRSC},
  doi          = {10.1287/trsc.2024.0996},
  journal      = {Transportation Science},
  month        = {9-10},
  number       = {5},
  pages        = {990-1007},
  shortjournal = {Trans. Sci.},
  title        = {Classifying pedestrian crossing flows: A data-driven approach using fundamental diagrams and machine learning},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Manage the curb: Optimization of time-varying parking zones in micromobility systems. <em>TRSC</em>, <em>59</em>(5), 972-989. (<a href='https://doi.org/10.1287/trsc.2024.0855'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Station based and free floating are the two established parking regimes of micromobility systems. The former restricts pickup and drop-off to designated stations, which is less convenient for users but reduces the nuisance of sloppily parked rental bikes and scooters. Free-floating micromobility allows users to use any public parking space within the operating area, which increases user flexibility but creates organizational overhead to deal with improperly parked vehicles. Time-varying parking zones, realized via curbside management software (CMS) and geofencing technology, promise a reasonable compromise in the convenience-clutter trade-off. Based on spatiotemporal information, the city administration can either permanently (e.g., pedestrian zones) or temporarily (e.g., weekly farmers’ market) block certain urban areas in their CMS. The micromobility providers, also having access to the CMS, must ensure that vehicles are not returned to undesignated areas with digital fences during the announced times. This paper introduces an optimization approach for micromobility providers to plan time-varying parking zones, given the dynamic municipal parking limitations. Opening and closing urban areas for parking not only requires a digital reaction (i.e., (un)blocking via geofencing) but also produces costs (e.g., removing the remaining scooters of previous periods from the market square). Hence, our optimization task aims to minimize the total costs associated with dynamic parking zones, whereas representative user trips are guaranteed travel within a given time budget. Based on this setting, we show that most urban stakeholders can profit from time-varying parking zones (compared with a static operating area). Our case study based on Berlin-Mitte shows that dynamic parking zones reduce urban space usage at decreasing service costs and only slight user concessions regarding their convenience. Supplemental Material: The online appendix is available at https://doi.org/10.1287/trsc.2024.0855 .},
  archive      = {J_TRSC},
  doi          = {10.1287/trsc.2024.0855},
  journal      = {Transportation Science},
  month        = {9-10},
  number       = {5},
  pages        = {972-989},
  shortjournal = {Trans. Sci.},
  title        = {Manage the curb: Optimization of time-varying parking zones in micromobility systems},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cognitive hierarchy in day-to-day network flow dynamics. <em>TRSC</em>, <em>59</em>(5), 951-971. (<a href='https://doi.org/10.1287/trsc.2024.0890'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When making route decisions, travelers may engage in a certain degree of reasoning about what others will do in the upcoming day, rendering yesterday’s shortest routes less attractive. This phenomenon was manifested in a recent virtual experiment that mimicked travelers’ repeated daily trip-making process. Unfortunately, prevailing day-to-day traffic dynamic models failed to faithfully reproduce the collected flow evolution data therein. To this end, we propose a day-to-day traffic behavior modeling framework based on the cognitive hierarchy theory, in which travelers with different levels of strategic reasoning capabilities form their own beliefs about lower step travelers’ capabilities when choosing their routes. Two widely studied day-to-day models, the network tatonnement process dynamic and the logit dynamic, are extended into the framework and studied as examples. Calibration of the virtual experiment is performed using the extended network tatonnement process dynamic, which fits the experimental data reasonably well. Our analysis reveals that both extended dynamics exhibit multiple equilibria, one of which corresponds to the classic user equilibrium. We further analyze and characterize these nonuser equilibrium states. Whereas analyzing global stability is intractable because of the presence of multiple equilibria, local stability criteria near equilibria are developed analytically. General insights on how key parameters affect the stability of user equilibria are unveiled. Funding: This work was supported by the National Natural Science Foundation of China [Grants 72201214, 72025104], the Sichuan Science and Technology Program [Grant 2023NSFSC1035], and the Central Guidance for Local Science and Technology Development Fund Projects [Grant 2024ZYD0108]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/trsc.2024.0890 .},
  archive      = {J_TRSC},
  doi          = {10.1287/trsc.2024.0890},
  journal      = {Transportation Science},
  month        = {9-10},
  number       = {5},
  pages        = {951-971},
  shortjournal = {Trans. Sci.},
  title        = {Cognitive hierarchy in day-to-day network flow dynamics},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic confirmation, compensation and routing for combined urban transportation of passengers and parcels. <em>TRSC</em>, <em>59</em>(5), 932-950. (<a href='https://doi.org/10.1287/trsc.2024.0827'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Passengers and parcels have long been served by separate vehicle fleets in urban areas. This study investigates the integration of parcel delivery and passenger ride services by a single fleet of mobility-on-demand companies. While this integration holds significant promise for enhancing profitability, it poses a challenge for operational sustainability: the detours required for parcel deliveries could adversely affect the passenger experience. We explore the viability of offering compensations as incentives for detours in a dynamic and stochastic environment. In this scenario, service requests are received dynamically, and the passengers’ acceptance of detours remains uncertain. We propose an innovative anticipatory policy, which integrates confirmation, compensation, and routing decisions. The proposed policy is underpinned by a novel regression-tree-based value function approximation. The numerical experiments have validated the efficacy of proposed policy. Moreover, we also explore the advantage of this combined transportation, which could effectively enhance profitability with few marginal costs. The study serves as a valuable reference for mobility-on-demand companies regarding the combined transportation of passengers and parcels. Funding: This work was supported by Research Grants Council of the Hong Kong Special Administrative Region, China [Grant PolyU 15222822]; Department of Industrial and Systems Engineering, Hong Kong Polytechnic University [Grant 4-ZZSF]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/trsc.2024.0827 .},
  archive      = {J_TRSC},
  doi          = {10.1287/trsc.2024.0827},
  journal      = {Transportation Science},
  month        = {9-10},
  number       = {5},
  pages        = {932-950},
  shortjournal = {Trans. Sci.},
  title        = {Dynamic confirmation, compensation and routing for combined urban transportation of passengers and parcels},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing underutilized bus routes with advance reservations and semiflexible routing. <em>TRSC</em>, <em>59</em>(5), 909-931. (<a href='https://doi.org/10.1287/trsc.2024.0561'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper seeks to improve an underutilized conventional bus route by converting it into a semiflexible transit system where passengers provide advance notice of their intended stops, allowing buses to skip downstream stops without demand by taking shortcuts. This approach increases stop density, reduces walking distances to and from bus stops, and maintains operational efficiency. To design this system, we develop optimization models that maximize the number of stops while adhering to tour duration and arrival time constraints. A case study in Allegany County, Maryland, demonstrates significant enhancements for routes that were both underutilized (where the probability of a stop lacking demand exceeded 45%) and had layouts conducive to substantial shortcuts. In these instances, the number of stops can be increased by up to 160%, with the actual improvement depending on route configuration, passenger demand, and advance notice requirements. Funding: Financial support from the the National Science Foundation [Grant 2055347] is gratefully acknowledged. Supplemental Material: The online appendix is available at https://doi.org/10.1287/trsc.2024.0561 .},
  archive      = {J_TRSC},
  doi          = {10.1287/trsc.2024.0561},
  journal      = {Transportation Science},
  month        = {9-10},
  number       = {5},
  pages        = {909-931},
  shortjournal = {Trans. Sci.},
  title        = {Enhancing underutilized bus routes with advance reservations and semiflexible routing},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On an interlocking flexible car use restriction policy: Theory, learning and experiment. <em>TRSC</em>, <em>59</em>(5), 883-908. (<a href='https://doi.org/10.1287/trsc.2024.0837'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Car use restrictions, such as the commonly implemented license plate restriction policy (PRP), are regarded as effective strategies for alleviating traffic congestion in many cities worldwide. Although these regulations help reduce daily vehicle volumes and evenly distribute them, they also limit commuters’ freedom to choose when to drive. A recent flexible car use restriction policy (FRP) allows commuters to select specific days to refrain from using their cars within a restriction cycle, enhancing travelers’ flexibility in urgent situations. Although the original FRP (O-FRP) may incur slightly higher average driving costs compared with the PRP due to uneven car use distribution, it can ultimately lower overall travel costs by accommodating more car uses during emergencies. This study introduces an interlocking FRP (IL-FRP), which groups travelers and assigns them different restriction cycles starting from distinct weekdays. Theoretical analysis reveals that, even under relaxed nonlinear travel cost assumptions, the user equilibrium solution of the IL-FRP, under ideal conditions, converges with the system optimal solution and further reaches the FRP’s theoretical lower bound while minimizing both driving and transit costs. Additionally, we develop two IL-FRP variants that are applicable regardless of the urgency probability distribution: the equally grouped FRP (ILE-FRP) and the arbitrarily grouped FRP (Arb-FRP). To derive equilibrium solutions for all FRPs under different parameter settings, we present a three-step learning algorithm using the mean field game framework. Numerical experiments validate the effectiveness of this algorithm and demonstrate that IL-FRP, ILE-FRP, and Arb-FRP offer advantages over O-FRP in terms of total travel cost. A series of laboratory experiments was conducted to support our theoretical findings. The results indicate some bounded rationality among individuals but align consistently with our theoretical predictions and learning outcomes. Funding: This work was supported by the National Natural Science Foundation of China [Grants 52302406 and 72201065] and the Natural Science Foundation of Fujian Province [Grants 2023J05022 and 2023J05099]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/trsc.2024.0837 .},
  archive      = {J_TRSC},
  doi          = {10.1287/trsc.2024.0837},
  journal      = {Transportation Science},
  month        = {9-10},
  number       = {5},
  pages        = {883-908},
  shortjournal = {Trans. Sci.},
  title        = {On an interlocking flexible car use restriction policy: Theory, learning and experiment},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
