<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>FTSP</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ftsp">FTSP - 1</h2>
<ul>
<li><details>
<summary>
(2025). Zero-shot visual deepfake detection: Can AI predict and prevent fake content before it is created?. <em>FTSP</em>, <em>19</em>(3), 212-370. (<a href='https://doi.org/10.1561/2000000136'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial networks (GANs) and diffusion models have dramatically advanced deepfake technology, and its threats to digital security, media integrity, and public trust have increased rapidly. This research explored zero-shot deepfake detection – an emerging method even when the models have never seen a particular deepfake variation. In this work, we studied self-supervised learning, transformer-based zero-shot classifier, generative model fingerprinting, and meta-learning techniques that better adapt to the ever-evolving deepfake threat. In addition, we suggested AI-driven prevention strategies that mitigated the underlying generation pipeline of the deepfakes before they occurred. They consisted of adversarial perturbations for creating deepfake generators, digital watermarking for content authenticity verification, real-time AI monitoring for content creation pipelines, and blockchain-based content verification frameworks. Despite these advancements, zero-shot detection and prevention faced critical challenges such as adversarial attacks, scalability constraints, ethical dilemmas, and the absence of standardized evaluation benchmarks. These limitations were addressed by discussing future research directions on explainable AI for deepfake detection, multimodal fusion based on image, audio, and text analysis, quantum AI for enhanced security, and federated learning for privacy-preserving deepfake detection. This further highlighted the need for an integrated defense framework for digital authenticity that utilized zero-shot learning in combination with preventive deepfake mechanisms. Finally, we highlighted the important role of interdisciplinary collaboration between AI researchers, cybersecurity experts, and policymakers to create resilient defenses against the rising tide of deepfake attacks.},
  archive      = {J_FTSP},
  author       = {Ayan Sar and Sampurna Roy and Tanupriya Choudhury and Ajith Abraham},
  doi          = {10.1561/2000000136},
  journal      = {Foundations and Trends® in Signal Processing},
  month        = {8},
  number       = {3},
  pages        = {212-370},
  shortjournal = {Found. Trends Signal Process.},
  title        = {Zero-shot visual deepfake detection: Can AI predict and prevent fake content before it is created?},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
