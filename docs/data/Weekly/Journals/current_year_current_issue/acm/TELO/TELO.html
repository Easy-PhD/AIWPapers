<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TELO</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="telo">TELO - 7</h2>
<ul>
<li><details>
<summary>
(2025). Hardening active directory graphs via evolutionary diversity optimization-based policies. <em>TELO</em>, <em>5</em>(3), 1-36. (<a href='https://doi.org/10.1145/3688401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Active Directory (AD) is the default security management system for Windows domain networks. An AD environment can be described as a cyber-attack graph, with nodes representing computers, accounts, and so forth, and edges indicating existing accesses or known exploits that enable attackers to move from one node to another. This article explores a Stackelberg game model between one attacker and one defender on an AD attack graph. The attacker’s goal is to maximize their chances of successfully reaching the destination before getting detected. The defender’s aim is to block a constant number of edges to minimize the attacker’s chance of success. The article shows that the problem is #P-hard and, therefore, intractable to solve exactly. To defend the AD graph from cyberattackers, this article proposes two defensive approaches. In the first approach, we convert the attacker’s problem to an exponential-sized Dynamic Program that is approximated by a neural network (NN). Once trained, the NN serves as an efficient fitness function for defender’s Evolutionary Diversity Optimization-based defensive policy. The diversity emphasis on the defender’s solution provides a diverse set of training samples, improving the training accuracy of our NN for modeling the attacker. In the second approach, we propose a RL-based policy to solve the attacker’s problem and Critic network-assisted Evolutionary Diversity Optimization-based defensive policy to solve defender’s problem. Experimental results on synthetic AD graphs show that the proposed defensive policies are scalable, highly effective, approximate attacker’s problem accurately and generate good defensive plans.},
  archive  = {J},
  author   = {Diksha Goel and Max Ward and Aneta Neumann and Frank Neumann and Hung Nguyen and Mingyu Guo},
  doi      = {10.1145/3688401},
  journal  = {ACM Transactions on Evolutionary Learning},
  month    = {8},
  number   = {3},
  pages    = {1-36},
  title    = {Hardening active directory graphs via evolutionary diversity optimization-based policies},
  volume   = {5},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surrogate modeling to address the absence of protected membership attributes in fairness evaluation. <em>TELO</em>, <em>5</em>(3), 1-25. (<a href='https://doi.org/10.1145/3700145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {It is imperative to ensure that AI models perform well for all groups including those from underprivileged populations. By comparing the performance of models for the protected group with respect to the rest of the population, we can uncover and prevent unwanted bias. However, a significant drawback of such binary fairness evaluation is its dependency on protected group membership attributes. In various real-world scenarios, protected status for individuals is sparse, unavailable, or even illegal to collect. This article extends the previous work on binary fairness metrics to relax the requirement on deterministic membership to its surrogate counterpart under a probabilistic setting. We show how to conduct binary fairness evaluation when exact protected attributes are not available, but their surrogates as likelihoods are accessible. In theory, we prove that inferred metrics calculated from surrogates are valid under standard statistical assumptions. In practice, we demonstrate the effectiveness of our approach using publicly available data from the Home Mortgage Disclosure Act and simulated benchmarks that mimic real-world conditions under different levels of model disparity. We extend the results from previous work to include comparisons with alternative model-based methods and we develop further practical guidance based on our extensive simulation. Finally, we embody our method in open source software that is readily available for use in other applications.},
  archive  = {J},
  author   = {Serdar Kadioğlu and Melinda Thielbar},
  doi      = {10.1145/3700145},
  journal  = {ACM Transactions on Evolutionary Learning},
  month    = {8},
  number   = {3},
  pages    = {1-25},
  title    = {Surrogate modeling to address the absence of protected membership attributes in fairness evaluation},
  volume   = {5},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining multi-objective bayesian optimization with reinforcement learning for TinyML. <em>TELO</em>, <em>5</em>(3), 1-21. (<a href='https://doi.org/10.1145/3715012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Deploying deep neural networks (DNNs) on microcontrollers (TinyML) is a common trend to process the increasing amount of sensor data generated at the edge, but in practice, resource and latency constraints make it difficult to find optimal DNN candidates. Neural architecture search (NAS) is an excellent approach to automate this search and can easily be combined with DNN compression techniques commonly used in TinyML. However, many NAS techniques are not only computationally expensive, especially hyperparameter optimization (HPO), but also often focus on optimizing only a single objective, e.g., maximizing accuracy, without considering additional objectives such as memory requirements or computational complexity of a DNN, which are key to making deployment at the edge feasible. In this article, we propose a novel NAS strategy for TinyML based on multi-objective Bayesian optimization (MOBOpt) and an ensemble of competing parametric policies trained using augmented random search (ARS) reinforcement learning (RL) agents. Our methodology aims at efficiently finding tradeoffs between a DNN’s predictive accuracy, memory requirements on a given target system, and computational complexity. Our experiments show that we consistently outperform existing MOBOpt approaches on different datasets and architectures such as ResNet-18 and MobileNetv3.},
  archive  = {J},
  author   = {Mark Deutel and Georgios Kontes and Christopher Mutschler and Jürgen Teich},
  doi      = {10.1145/3715012},
  journal  = {ACM Transactions on Evolutionary Learning},
  month    = {8},
  number   = {3},
  pages    = {1-21},
  title    = {Combining multi-objective bayesian optimization with reinforcement learning for TinyML},
  volume   = {5},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing batch diversity in surrogate optimization: A determinantal point processes approach. <em>TELO</em>, <em>5</em>(3), 1-30. (<a href='https://doi.org/10.1145/3721296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The exploration–exploitation tradeoff poses a significant challenge in surrogate optimization for expensive black-box functions, particularly when dealing with batch evaluation settings. Despite efforts to develop batch sampling techniques, they often fall short of sufficiently prioritizing diversity within the selected batch. In this article, we propose a fundamentally novel approach called Determinantal Point Processes (DPP)-Based Surrogate Optimization (DPPSO), which serves as a consolidated framework. DPPSO introduces a novel discretization scheme and sampling algorithm that fuses exploration and exploitation objectives by harnessing the power of DPP decomposition. An essential aspect of this project is the development of effective scoring functions to incorporate the quality of the sampled points in the decomposition. We provide theoretical guarantees achieving lower bounds on the probability of convergence. We demonstrate the effectiveness of DPPSO across different benchmarks, comparing its performance against various baseline methods.},
  archive  = {J},
  author   = {Nazanin Nezami and Hadis Anahideh},
  doi      = {10.1145/3721296},
  journal  = {ACM Transactions on Evolutionary Learning},
  month    = {8},
  number   = {3},
  pages    = {1-30},
  title    = {Enhancing batch diversity in surrogate optimization: A determinantal point processes approach},
  volume   = {5},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to cut generation in branch-and-cut algorithms for combinatorial optimization. <em>TELO</em>, <em>5</em>(3), 1-27. (<a href='https://doi.org/10.1145/3728371'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Branch-and-cut is one of the most successful methods to exactly solve combinatorial optimization problems. A key decision problem in branch-and-cut is cut generation —the problem of deciding whether to generate cuts or to branch at each node of the search tree. This decision significantly impacts performance: generating efficient cuts can remove a substantial portion of the infeasible region and reduce tree size. However, in many cases, generating cuts slows runtime as separation routines could be time-consuming, and the violated cuts found by these routines could be inefficient. Hence, a smart strategy for generating cuts is crucial for the efficiency of branch-and-cut algorithms. There are two main types of cuts: generic cuts derived from the integrality of variables and combinatorial cuts based on the facial structure of the convex hull of feasible solutions. Combinatorial cuts are particularly determinant in branch-and-cut for many NP-hard combinatorial optimization problems, e.g., the Traveling Salesman Problem and the Max-Cut problem. In this article, we propose a framework combining supervised learning and deep reinforcement learning to learn strategies for generating combinatorial cuts in branch-and-cut. Our framework contains two components: a cut detector to predict the cut existence and a cut evaluator to choose between generating cuts and branching. We conduct experiments on two well-known combinatorial cut classes: subtour elimination constraints for the Traveling Salesman problem and cycle inequalities for the Max-Cut problem. Our results show that the proposed framework outperforms the commonly used strategies for cut generation, even on instances larger than those used for training.},
  archive  = {J},
  author   = {Trang Vo and Mourad Baiou and Viet Hung Nguyen and Paul Weng},
  doi      = {10.1145/3728371},
  journal  = {ACM Transactions on Evolutionary Learning},
  month    = {8},
  number   = {3},
  pages    = {1-27},
  title    = {Learning to cut generation in branch-and-cut algorithms for combinatorial optimization},
  volume   = {5},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RunAndSchedule2Survive: Algorithm scheduling based on Run2Survive. <em>TELO</em>, <em>5</em>(3), 1-17. (<a href='https://doi.org/10.1145/3737705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The algorithm selection problem aims to identify the most suitable algorithm for a given problem instance under specific time constraints, where suitability typically refers to a performance metric such as algorithm runtime. While previous work has employed machine learning techniques to tackle this challenge, methods from survival analysis have proven particularly effective. This article presents RunAndSchedule2Survive to address the more general and complex problem of algorithm scheduling, where the objective is to allocate computational resources across multiple algorithms to maximize performance within specified time constraints. Our approach combines survival analysis with evolutionary algorithms to optimize algorithm schedules by leveraging runtime distributions modeled as survival functions. Experimental results across various standard benchmarks demonstrate that our approach significantly outperforms previous methods for algorithm scheduling and yields more robust results than its algorithm selection variant. More specifically, RunAndSchedule2Survive achieves superior performance in 20 out of 25 benchmark scenarios, surpassing hitherto state-of-the-art approaches.},
  archive  = {J},
  author   = {Valentin Margraf and Tom Koerner and Alexander Tornede and Marcel Wever},
  doi      = {10.1145/3737705},
  journal  = {ACM Transactions on Evolutionary Learning},
  month    = {8},
  number   = {3},
  pages    = {1-17},
  title    = {RunAndSchedule2Survive: Algorithm scheduling based on Run2Survive},
  volume   = {5},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Introduction to the special issue on learning and intelligent optimization. <em>TELO</em>, <em>5</em>(3), 1-2. (<a href='https://doi.org/10.1145/3757070'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Kevin Tierney and Meinolf Sellmann},
  doi     = {10.1145/3757070},
  journal = {ACM Transactions on Evolutionary Learning},
  month   = {8},
  number  = {3},
  pages   = {1-2},
  title   = {Introduction to the special issue on learning and intelligent optimization},
  volume  = {5},
  year    = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
