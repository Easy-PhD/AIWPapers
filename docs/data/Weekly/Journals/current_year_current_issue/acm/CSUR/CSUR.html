<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>CSUR</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="csur">CSUR - 28</h2>
<ul>
<li><details>
<summary>
(2025). A survey of recent advances and challenges in deep audio-visual correlation learning. <em>CSUR</em>, <em>57</em>(12), 1-46. (<a href='https://doi.org/10.1145/3696445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audio-visual correlation learning aims at capturing and understanding natural phenomena between audio and visual data. The rapid growth of dl propelled the development of proposals that process audio-visual data and can be observed in the number of proposals in the past years. Thus encouraging the development of a comprehensive survey. Besides analyzing the models used in this context, we also discuss some tasks of definition and paradigm applied in AI multimedia. In addition, we investigate objective functions frequently used and discuss how audio-visual data is exploited in the optimization process, i.e., the different methodologies for representing knowledge in the audio-visual domain. In fact, we focus on how human-understandable mechanisms, i.e., structured knowledge that reflects comprehensible knowledge, can guide the learning process. Most importantly, we provide a summarization of the recent progress of ()avcl and discuss the future research directions.},
  archive      = {J_CSUR},
  author       = {Luís Vilaça and Yi Yu and Paula Viana},
  doi          = {10.1145/3696445},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-46},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of recent advances and challenges in deep audio-visual correlation learning},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative AI for intelligent transportation systems: Road transportation perspective. <em>CSUR</em>, <em>57</em>(12), 1-45. (<a href='https://doi.org/10.1145/3719290'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent transportation systems are vital for modern traffic management and optimization, greatly improving traffic efficiency and safety. With the rapid development of generative artificial intelligence (Generative AI) technologies in areas like image generation and natural language processing, generative AI has also played a crucial role in addressing key issues in intelligent transportation systems (ITS), such as data sparsity, difficulty in observing abnormal scenarios, and in modeling data uncertainty. In this review, we systematically investigate the relevant literature on generative AI techniques in addressing key issues in different types of tasks in ITS tailored specifically for road transportation. First, we introduce the principles of different generative AI techniques. Then, we classify tasks in ITS into four types: traffic perception, traffic prediction, traffic simulation, and traffic decision-making. We systematically illustrate how generative AI techniques addresses key issues in these four different types of tasks. Finally, we summarize the challenges faced in applying generative AI to ITS, and discuss future research directions based on different application scenarios.},
  archive      = {J_CSUR},
  author       = {Huan Yan and Yong Li},
  doi          = {10.1145/3719290},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-45},
  shortjournal = {ACM Comput. Surv.},
  title        = {Generative AI for intelligent transportation systems: Road transportation perspective},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Benchmarking relaxed differential privacy in private learning: A comparative survey. <em>CSUR</em>, <em>57</em>(12), 1-34. (<a href='https://doi.org/10.1145/3729216'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential privacy (DP), a rigorously quantifiable privacy preservation technique, has found widespread application within the domain of machine learning. As DP techniques are implemented in machine learning algorithms, a significant and intricate tradeoff between privacy and utility emerges, garnering extensive attention from researchers. In the pursuit of striking a delicate equilibrium between safeguarding sensitive data and optimizing its utility, researchers have introduced various variants of Relaxed Differential Privacy (RDP) definitions. These nuanced formulations, however, exhibit substantial diversity in their underlying principles and interpretations of the core concept of DP, thereby engendering a current void in the comprehensive synthesis of these related works. The principal objective of this article is twofold. Firstly, it aims to provide a comprehensive summary of pertinent research endeavors pertaining to RDP within the realm of machine learning. Secondly, it endeavors to empirically assess the impact on both privacy and utility stemming from machine learning algorithms founded upon these RDP definitions. Additionally, this article undertakes a systematic analysis of the foundational principles underpinning distinct variants of relaxed definitions, culminating in the development of a taxonomy that categorizes these RDP definitions.},
  archive      = {J_CSUR},
  author       = {Zhaolong Zheng and Lin Yao and Haibo Hu and Guowei Wu},
  doi          = {10.1145/3729216},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Benchmarking relaxed differential privacy in private learning: A comparative survey},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unravelling digital forgeries: A systematic survey on image manipulation detection and localization. <em>CSUR</em>, <em>57</em>(12), 1-36. (<a href='https://doi.org/10.1145/3731243'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning has made significant strides, especially in computer vision applications and, more specifically, in information forensics. On the other hand, data-driven approaches have shown much promise in identifying manipulations in images and videos. However, most forensic tools ignore deep learning in favour of more traditional methodologies. This article thoroughly analyses the current state-of-the-art methods for detecting and localizing image alteration using classical and deep learning-based algorithms. In addition, this review includes the latest developments in the digital image forensics field, including Convolutional Neural Networks (CNNs), while incorporating insights from classical approaches and machine learning models. Furthermore, the most significant data-driven techniques to address the issue of image manipulation detection and localization are presented and segregated into four subtopics: copy-move, splicing, object removal, and contrast enhancement. This study provides an exhaustive and up-to-date survey of the field for researchers and practitioners working in this domain. In addition, it covers the current challenges and future directions in deep learning for image manipulation detection and localization. Finally, this review’s discussion of relevant approaches and experiments will aid future exploration and development in this field.},
  archive      = {J_CSUR},
  author       = {VijayaKumar Kadha and Sambit Bakshi and Santos Kumar Das},
  doi          = {10.1145/3731243},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Unravelling digital forgeries: A systematic survey on image manipulation detection and localization},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intrusion detection based on federated learning: A systematic review. <em>CSUR</em>, <em>57</em>(12), 1-65. (<a href='https://doi.org/10.1145/3731596'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolution of cybersecurity is closely linked to the development and improvement of artificial intelligence (AI). As a key tool for realizing more cybersecure ecosystems, Intrusion Detection Systems (IDSs) have evolved tremendously in recent years by integrating machine learning (ML) techniques to detect increasingly sophisticated cybersecurity attacks hidden in big data. However, traditional approaches rely on centralized learning, in which data from end nodes are shared with data centers for analysis. Recently, the application of federated learning (FL) in this context has attracted great interest to come up with collaborative intrusion detection approaches where data does not need to be shared. Due to the recent rise of this field, this work presents a complete, contemporary taxonomy for FL-enabled IDS approaches that stems from a comprehensive survey of the literature from 2018 to 2022. Precisely, our discussion includes an analysis of the main ML models, datasets, aggregation functions, as well as implementation libraries employed by the proposed FL-enabled IDS approaches. On top of everything else, we provide a critical view of the current state of the research around this topic, and describe the main challenges and future directions based on the analysis of the literature and our own experience in this area.},
  archive      = {J_CSUR},
  author       = {Jose Luis Hernandez-Ramos and Georgios Karopoulos and Efstratios Chatzoglou and Vasileios Kouliaridis and Enrique Marmol and Aurora Gonzalez-Vidal and Georgios Kambourakis},
  doi          = {10.1145/3731596},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-65},
  shortjournal = {ACM Comput. Surv.},
  title        = {Intrusion detection based on federated learning: A systematic review},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on off-chain networks: Frameworks, technologies, solutions and challenges. <em>CSUR</em>, <em>57</em>(12), 1-35. (<a href='https://doi.org/10.1145/3735124'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Off-chain networks that support transactions outside of the blockchain can handle large numbers of transactions and relieve the pressure on on-chain storage, showing great potential in mitigating scalability challenges of blockchain. However, since off-chain networks are still in the early stage of development, how to ensure off-chain data security, off-chain trust, off-chain transaction privacy and efficiency has become an important challenge. Against this background, this article provides a comprehensive review on off-chain networks. We first introduce the background, including design motivations, overview, and application scenarios. We then propose key issues related to off-chain networks. After that, we introduce off-chain technologies, including security and privacy based technologies, intelligent off-chain networking and routing technologies, off-chain edge computing technologies, and off-chain transaction scheduling technologies. Subsequently, we summarize mainstream solutions for corresponding key issues and provide learned lessons. Finally, we discuss some research challenges and open issues.},
  archive      = {J_CSUR},
  author       = {Xiaojie Wang and Hanxue Li and Ling Yi and Zhaolong Ning and Xiaoming Tao and Song Guo and Yan Zhang},
  doi          = {10.1145/3735124},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on off-chain networks: Frameworks, technologies, solutions and challenges},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic literature review on neonatal fingerprint recognition. <em>CSUR</em>, <em>57</em>(12), 1-34. (<a href='https://doi.org/10.1145/3735551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neonatal biometrics, especially those based on fingerprint traits, can potentially improve early childhood identification with decisive applications in healthcare, identity management, and other critical social domains. Although many biometric approaches to human recognition exist, most of them cannot be directly applied to neonates. The main barrier is the reduced size of children’s biometric traits, which affects image quality as these traits are still developing. Another issue is the lack of child biometric databases, as a periodic recollection of images is a fundamental part of neonatal identification regarding the feasibility evaluation of temporal recognition. Several works can be found in the literature addressing some of these issues. However, there is still no systematic review allowing a general understanding of these solutions, discussing their links, gaps, comparisons, and open challenges. In this sense, this article presents a systematic literature review on neonatal biometrics. In total, 1,878 papers were screened and classified, resulting in 45 being selected to be analyzed in this study. We detail and compare the results of datasets, scanners, methods, and techniques to achieve and improve neonatal recognition. Finally, research trends are identified and discussed based on the main gaps in the literature.},
  archive      = {J_CSUR},
  author       = {Luiz Fernando Puttow Southier and Gustavo Alexandre Tuchlinowicz Nunes and João Henrique Pereira Machado and Matheus Buratti and Pedro Henrique de Viveiros Trentin and Wesley Augusto Catuzzo de Bona and Barbara de Oliveira Koop and Elioenai Markson Ferreira Diniz and João Victor Costa Mazzochin and João Leonardo Harres Dall Agnol and Lucas Caldeira de Oliveira and Marcelo Filipak and Luiz Antonio Zanlorensi and Marcos Belançon and Jefferson Oliva and Marcelo Teixeira and Dalcimar Casanova},
  doi          = {10.1145/3735551},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic literature review on neonatal fingerprint recognition},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting misuse of security APIs: A systematic review. <em>CSUR</em>, <em>57</em>(12), 1-39. (<a href='https://doi.org/10.1145/3735968'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Security Application Programming Interfaces (APIs) are crucial for ensuring software security. However, their misuse introduces vulnerabilities, potentially leading to severe data breaches and substantial financial loss. Complex API design, inadequate documentation, and insufficient security training often lead to unintentional misuse by developers. The software security community has devised and evaluated several approaches to detecting security API misuse to help developers and organizations. This study rigorously reviews the literature on detecting misuse of security APIs to gain a comprehensive understanding of this critical domain. Our goal is to identify and analyze security API misuses, the detection approaches developed, and the evaluation methodologies employed along with the open research avenues to advance the state-of-the-art in this area. Employing the systematic literature review (SLR) methodology, we analyzed 69 research articles. Our review has yielded (a) identification of 6 security API types; (b) classification of 30 distinct misuses; (c) categorization of detection techniques into heuristic-based and ML-based approaches; and (d) identification of 10 performance measures and 9 evaluation benchmarks. The review reveals a lack of coverage of detection approaches in several areas. We recommend that future efforts focus on aligning security API development with developers’ needs and advancing standardized evaluation methods for detection technologies.},
  archive      = {J_CSUR},
  author       = {Zahra Mousavi and Chadni Islam and Muhammad Ali Babar and Alsharif Abuadbba and Kristen Moore},
  doi          = {10.1145/3735968},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Detecting misuse of security APIs: A systematic review},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A taxonomy and systematic review of gaze interactions for 2D displays: Promising techniques and opportunities. <em>CSUR</em>, <em>57</em>(12), 1-37. (<a href='https://doi.org/10.1145/3736250'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaze input offers strong potential for creating intuitive and engaging user interfaces, but remains constrained by inherent limitations in accuracy and precision. Although extensive research has explored gaze-based interaction over the past three decades, a systematic framework that fully captures the diversity of gaze interaction techniques is still lacking. To address this gap, we present a novel two-dimensional taxonomy that classifies gaze interactions by (1) the type of input , distinguishing between gaze-only and gaze-assisted modalities, and (2) the type of target , differentiating between those requiring absolute gaze coordinates and thus higher accuracy, and those using relative coordinates, which tolerate lower accuracy. Our taxonomy explicitly captures the required input accuracy and interface constraints of each technique, providing clearer guidance for designers of gaze-based interfaces. We apply this taxonomy to review and classify 125 studies of active gaze interactions on 2D displays. The findings highlight promising techniques and identify research opportunities to advance gaze interaction design.},
  archive      = {J_CSUR},
  author       = {Asma Shakil and Christof Lutteroth and Gerald Weber},
  doi          = {10.1145/3736250},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A taxonomy and systematic review of gaze interactions for 2D displays: Promising techniques and opportunities},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised learning for electroencephalogram: A systematic survey. <em>CSUR</em>, <em>57</em>(12), 1-38. (<a href='https://doi.org/10.1145/3736574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) is a non-invasive technique to record bioelectrical signals. Integrating supervised deep learning techniques with EEG signals has recently facilitated automatic analysis across diverse EEG-based tasks. However, the label issues of EEG signals have constrained the development of EEG-based deep models. Obtaining EEG annotations is difficult and requires domain experts to guide collection and labeling, and the variability of EEG signals among different subjects causes significant label shifts. To solve the above challenges, self-supervised learning (SSL) has been proposed to extract representations from unlabeled samples through well-designed pretext tasks. This article concentrates on integrating SSL frameworks with temporal EEG signals to achieve efficient representations and proposes a systematic survey of the SSL for EEG signals. In this article, (1) We introduce the concept and theory of self-supervised learning and typical SSL frameworks. (2) We provide a comprehensive survey of SSL for EEG analysis, including taxonomy, methodology, and technical details of the existing EEG-based SSL frameworks, and discuss the differences between these methods. (3) We investigate the adaptation of the SSL approach to various downstream tasks, including the task description and related benchmark datasets, and further explore its application in large-scale pre-trained foundation models for EEG signals. (4) Finally, we discuss the potential directions for future SSL-EEG research.},
  archive      = {J_CSUR},
  author       = {Weining Weng and Yang Gu and Shuai Guo and Yuan Ma and Zhaohua Yang and Yuchen Liu and Yiqiang Chen},
  doi          = {10.1145/3736574},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Self-supervised learning for electroencephalogram: A systematic survey},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sentiment diffusion in online social networks: A survey from the computational perspective. <em>CSUR</em>, <em>57</em>(12), 1-35. (<a href='https://doi.org/10.1145/3736750'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of mobile technologies, users can easily access Online social networks (OSNs), consequently, massive contents including personal experiences, observations, or opinions are generated online. These contents are being shared and exchanged in OSNs, which have a significant influence on the minds of people toward politics, societies, economics, and so on. In this case, sentiment diffusion which focuses on how the process of information diffusion in OSNs is affected by sentiments has become an important issue. In this survey, we conduct a comprehensive review of the problem. Specifically, we first present the definition and classification of sentiment, introduce the most advanced computational sentiment analysis techniques, list their applications, and disclose available sentiment analysis resources. Then the main OSN components, functionalities, and structural features applied in modeling social networks are analyzed and summarized. Next, a thorough overview of the information diffusion technologies in OSNs, including graph and non-graph models is made. At last, a systematic and in-depth overview of the current state and issues of research on sentiment diffusion in OSNs is provided. This survey provides the necessary knowledge and new insights for relevant researchers to better understand the research state, remaining challenges, and future directions in this field.},
  archive      = {J_CSUR},
  author       = {Han Xu and Minghua Xu and Xianjun Deng and Bang Wang},
  doi          = {10.1145/3736750},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Sentiment diffusion in online social networks: A survey from the computational perspective},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maintainability and scalability in machine learning: Challenges and solutions. <em>CSUR</em>, <em>57</em>(12), 1-36. (<a href='https://doi.org/10.1145/3736751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid advancements in Machine Learning (ML) introduce unique maintainability and scalability challenges. Our research addresses the evolving challenges and identifies ML maintainability and scalability solutions by conducting a thorough literature review of over 17,000 papers, ultimately refining our focus to 124 relevant sources that meet our stringent selection criteria. We present a catalogue of 41 Maintainability and 13 Scalability challenges and solutions across Data, Model Engineering and the overall development of ML applications and systems. This study equips practitioners with insights on building robust ML applications, laying the groundwork for future research on improving ML system robustness at different workflow stages.},
  archive      = {J_CSUR},
  author       = {Karthik Shivashankar and Ghadi Al Hajj and Antonio Martini},
  doi          = {10.1145/3736751},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Maintainability and scalability in machine learning: Challenges and solutions},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive review of causal inference in banking, finance, and insurance. <em>CSUR</em>, <em>57</em>(12), 1-36. (<a href='https://doi.org/10.1145/3736752'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This is a comprehensive survey of the applications of causal inference in the Banking, Financial Services and Insurance (BFSI) domain based on 45 papers published from 1992 to 2023. It categorizes papers into (i) Banking and risk management (ii) Finance (covering investment, asset and portfolio management; behavioral finance and time series), (iii) Financial markets and (iv) Insurance. Exploring methods such as Bayesian Causal Network, Granger Causality, and counterfactuals, the article emphasizes significance of causal inference in explaining predictions of AI/ML models. This survey also recommends promising future research directions in the intersection of causal inference and these domains making it helpful for the professionals working therein.},
  archive      = {J_CSUR},
  author       = {Satyam Kumar and Yelleti Vivek and Vadlamani Ravi and Indranil Bose},
  doi          = {10.1145/3736752},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive review of causal inference in banking, finance, and insurance},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent root cause localization in MicroService systems: A survey and new perspectives. <em>CSUR</em>, <em>57</em>(12), 1-37. (<a href='https://doi.org/10.1145/3736755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Root cause localization is the process of monitoring system behavior and analyzing fault patterns from behavioral data. It is applicable in software development, network operations, and cloud computing. However, with the advent of microservice architectures and cloud-native technologies, root cause localization becomes an arduous task. Frequent updates in systems result in large-scale data and complex dependencies. Traditional analysis methods relying on manual experience and predefined rules have limited data processing and cannot learn new fault patterns from historical knowledge. Artificial Intelligence techniques have emerged as powerful tools to leverage historical knowledge and are now widely used in root cause localization. In this article, we provide a structured overview and a qualitative analysis of root cause localization in microservice systems. To begin with, we review the literature in this area and abstract a workflow of root cause localization, including multimodal data collection, intelligent root cause analysis, and performance evaluation. In particular, we highlight the role played by Artificial Intelligence techniques. Finally, we discuss some open challenges and research directions and propose an end-to-end framework from a new perspective, providing insights for future works.},
  archive      = {J_CSUR},
  author       = {Nan Fu and Guang Cheng and Yue Teng and Guangye Dai and Shui Yu and Zihan Chen},
  doi          = {10.1145/3736755},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Intelligent root cause localization in MicroService systems: A survey and new perspectives},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Supervised learning from data streams: An overview and update. <em>CSUR</em>, <em>57</em>(12), 1-31. (<a href='https://doi.org/10.1145/3737279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The literature on machine learning in the context of data streams is vast and growing. This indicates not only an ongoing interest, but also an ongoing need for a synthesis of new developments in this area. Here, we reformulate the definitions of supervised data-stream learning, alongside consideration of contemporary concept drift and temporal dependence. Equipped with this, carry out a fresh discussion of what constitutes a supervised data-stream learning task; including continual and reinforcement learning; highlighting major assumptions and constraints. We carry out a fresh reconsideration of approaches and methods, with regard to their suitability to modern settings. But more than a categorization of state-of-the-art streaming methods, we provide a re-introduction to what is supervised stream learning, and our emphasis here is a survey of settings, and algorithmic settings. Our main goal is to pull theory and practice of supervised learning over data streams closer together. We conclude that practical stream learning does not mandate an online-learning regime. In the modern context, learning regimes should be selected and developed according to the factual data arrival mode, resource constraints, and maximum robustness and trustworthiness. We finish with a set of recommendations to this effect.},
  archive      = {J_CSUR},
  author       = {Jesse Read and Indre Zliobaite},
  doi          = {10.1145/3737279},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-31},
  shortjournal = {ACM Comput. Surv.},
  title        = {Supervised learning from data streams: An overview and update},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A functionally-grounded benchmark framework for XAI methods: Insights and foundations from a systematic literature review. <em>CSUR</em>, <em>57</em>(12), 1-40. (<a href='https://doi.org/10.1145/3737445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) is transforming industries, offering new opportunities to manage and enhance innovation. However, these advancements bring significant challenges for scientists and businesses, with one of the most critical being the ‘trustworthiness” of AI systems. A key requirement of trustworthiness is transparency , closely linked to explicability . Consequently, the exponential growth of eXplainable AI (XAI) has led to the development of numerous methods and metrics for explainability. Nevertheless, this has resulted in a lack of standardized and formal definitions for fundamental XAI properties (e.g., what do soundness, completeness, and faithfulness of an explanation entail? How is the stability of an XAI method defined?). This lack of consensus makes it difficult for XAI practitioners to establish a shared foundation, thereby impeding the effective benchmarking of XAI methods. This survey article addresses these challenges with two primary objectives. First, it systematically reviews and categorizes XAI properties, distinguishing them between human-centered (relying on empirical studies involving explainees) or functionally-grounded (quantitative metrics independent of explainees). Second, it expands this analysis by introducing a hierarchically structured, functionally grounded benchmark framework for XAI methods, providing formal definitions of XAI properties. The framework’s practicality is demonstrated by applying it to two widely used methods: LIME and SHAP.},
  archive      = {J_CSUR},
  author       = {Dulce Canha and Sylvain Kubler and Kary Främling and Guy Fagherazzi},
  doi          = {10.1145/3737445},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {A functionally-grounded benchmark framework for XAI methods: Insights and foundations from a systematic literature review},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of subgraph optimization for expert team formation. <em>CSUR</em>, <em>57</em>(12), 1-40. (<a href='https://doi.org/10.1145/3737455'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expert Team Formation is the search for gathering a team of experts who are expected to collaboratively work toward accomplishing a given project, a problem that has historically been solved in a variety of ways, including manually in a time-consuming and bias-filled manner, and algorithmically within disciplines like social sciences and management. In the present effort, while providing a taxonomy to distinguish between search-based versus learning-based approaches, we survey graph-based studies from the search-based category, motivated as they comprise the mainstream. We present a unifying and vetted overview of the various definitions in this realm, scrutinize assumptions, and identify shortfalls. We start by reviewing initial approaches to the Expert Team Formation problem to lay the conceptual foundations and set forth the necessary notions for a more grounded view of this realm. Next, we provide a detailed view of graph-based Expert Team Formation approaches based on the objective functions they optimize. We lay out who builds on whom and how algorithms have evolved to solve the drawbacks of previous works. Furthermore, we categorize evaluation schemas and elaborate on metrics and insights that can be drawn from each. Referring to the evaluation schemas and metrics, we compare works and propose future directions.},
  archive      = {J_CSUR},
  author       = {Mahdis Saeedi and Hawre Hosseini and Christine Wong and Hossein Fani},
  doi          = {10.1145/3737455},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of subgraph optimization for expert team formation},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Myoelectric prosthetic hands: A review of muscle synergy, machine learning and edge computing. <em>CSUR</em>, <em>57</em>(12), 1-33. (<a href='https://doi.org/10.1145/3742471'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, the integration of electromyography (EMG) techniques with machine learning has significantly advanced prosthetic device control. Researchers have developed sophisticated deep learning classifiers for gesture recognition and created EMG controllers capable of simultaneous proportional control across multiple degrees of freedom. However, the increasing complexity of these machine learning models demands greater computational power, creating challenges for real-time deployment on embedded prosthetic controllers. Various optimization techniques - including hyperdimensional computing, pruning, and quantization - have demonstrated effectiveness in reducing computational requirements while preserving system performance. Concurrently, biomedical research has explored muscle and task synergies as methods to simplify inputs for machine learning models. This review examines synergy extraction in upper limb prosthetics research and identifies the need for standardized hardware specifications to facilitate proper validation and comparison of research outcomes. Furthermore, it explores how optimization techniques from Internet of Things (IoT) applications could enhance EMG controllers in biomedical settings. The analysis identifies sensor fusion and high-density EMG as particularly promising approaches for achieving robust, generalized control of upper limb prosthetics.},
  archive      = {J_CSUR},
  author       = {Hamdy O. Farag and Mohamed Medhat Gaber and Mohammed Ibrahim Awad and Nancy E. Elhady},
  doi          = {10.1145/3742471},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Myoelectric prosthetic hands: A review of muscle synergy, machine learning and edge computing},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An end-to-end pipeline perspective on video streaming in best-effort networks: A survey and tutorial. <em>CSUR</em>, <em>57</em>(12), 1-47. (<a href='https://doi.org/10.1145/3742472'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remaining a dominant force in Internet traffic, video streaming captivates end users, service providers, and researchers. This article takes a pragmatic approach to reviewing recent advances in the field by focusing on the prevalent streaming paradigm that involves delivering long-form two-dimensional videos over the best-effort Internet with client-side adaptive bitrate (ABR) algorithms and assistance from content delivery networks (CDNs). To enhance accessibility, we supplement the survey with tutorial material. Unlike existing surveys that offer fragmented views, our work provides a holistic perspective on the entire end-to-end streaming pipeline, from video capture by a camera-equipped device to playback by the end user. Our novel perspective covers the ingestion, processing, and distribution stages of the pipeline and addresses key challenges such as video compression, upload, transcoding, ABR algorithms, CDN support, and quality of experience. We review over 200 papers and classify streaming designs by problem-solving methodology, whether based on intuition, theory, or machine learning. The survey further refines these methodology-based categories and characterizes each design by additional traits such as compatible codecs. We connect the reviewed research to real-world applications by discussing the practices of commercial streaming platforms. Finally, the survey highlights prominent current trends and outlines future directions in video streaming.},
  archive      = {J_CSUR},
  author       = {Leonardo Peroni and Sergey Gorinsky},
  doi          = {10.1145/3742472},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-47},
  shortjournal = {ACM Comput. Surv.},
  title        = {An end-to-end pipeline perspective on video streaming in best-effort networks: A survey and tutorial},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph deep learning for time series forecasting. <em>CSUR</em>, <em>57</em>(12), 1-34. (<a href='https://doi.org/10.1145/3742784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph deep learning methods have become popular tools to process collections of correlated time series. Unlike traditional multivariate forecasting methods, graph-based predictors leverage pairwise relationships by conditioning forecasts on graphs spanning the time series collection. The conditioning takes the form of architectural inductive biases on the forecasting architecture, resulting in a family of models called spatiotemporal graph neural networks. These biases allow for training global forecasting models on large collections of time series while localizing predictions w.r.t. each element in the set (nodes) by accounting for correlations among them (edges). Recent advances in graph neural networks and deep learning for time series forecasting make the adoption of such processing framework appealing and timely. However, most studies focus on refining existing architectures by exploiting modern deep-learning practices. Conversely, foundational and methodological aspects have not been subject to systematic investigation. To fill this void, this tutorial paper aims to introduce a comprehensive methodological framework formalizing the forecasting problem and providing design principles for graph-based predictors, as well as methods to assess their performance. In addition, together with an overview of the field, we provide design guidelines and best practices, as well as an in-depth discussion of open challenges and future directions.},
  archive      = {J_CSUR},
  author       = {Andrea Cini and Ivan Marisca and Daniele Zambon and Cesare Alippi},
  doi          = {10.1145/3742784},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Graph deep learning for time series forecasting},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating EEG microstate analysis in cognitive software engineering tasks: A systematic mapping study and taxonomy. <em>CSUR</em>, <em>57</em>(12), 1-36. (<a href='https://doi.org/10.1145/3742899'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performing software engineering (SE) tasks requires the activation of software developers’ brain neural networks. Electroencephalography (EEG) microstate analysis emerges as a promising neurophysiological method to investigate the spatiotemporal dynamics of brain networks at high temporal resolution. An EEG microstate represents a unique topography of electric potentials over the multichannel EEG records. However, academia has neglected classifying published studies on EEG microstate analysis related to SE. Hence, a careful understanding of state-of-the-art studies remains limited and inconclusive. This article aims at classifying studies on the EEG microstate analysis in cognitive SE tasks. We conducted a systematic mapping study following well-established guidelines to answer ten research questions. After careful filtering, 54 primary studies (out of 1.545) were selected from 8 electronic databases. The main results are that most primary studies focus on revealing brain dynamics, exploring a wide range of EEG microstate application contexts and experimental tasks, running empirical studies in a controlled environment, using K -means as a clustering method, applying ICA-based strategy to filter artifacts, such as muscle activity and eye blinks. However, No study has applied EEG microstate analysis to SE, highlighting a significant gap and the need for further research. Finally, this article presents a classification taxonomy and identifies critical challenges and future research directions.},
  archive      = {J_CSUR},
  author       = {Willian Bolzan and Kleinner Farias},
  doi          = {10.1145/3742899},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Investigating EEG microstate analysis in cognitive software engineering tasks: A systematic mapping study and taxonomy},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of program analysis for distributed software systems. <em>CSUR</em>, <em>57</em>(12), 1-45. (<a href='https://doi.org/10.1145/3742900'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed software systems are pervasive today and they are increasingly developed/deployed to meet the growing needs for scalable computing. Given their critical roles in modern information infrastructures, assuring the quality of distributed software is crucial. As a fundamental methodology for software quality assurance in general, program analysis underlies a range of techniques and tools for constructing and assuring distributed systems. Yet to this date, there remains a lack of systematical understanding of what have been done and how far we are in the field of program analysis for distributed systems. To gain a comprehensive and coherent view of this area hence inform relevant future research, this article provides a systematic literature review of the (1) technical approaches , including analysis methodology, modality, underlying representation, algorithmic design, data utilized, and scope, (2) applications , with respect to the quality aspects served, and (3) evaluation , including the datasets and metrics considered, of various program analyses in the domain of distributed software in the past 30 years (1995–2024). In addition to knowledge systematization, we also extend our insights into the limitations of and challenges faced by current technique and evaluation designs, which shed light on potentially promising future research directions .},
  archive      = {J_CSUR},
  author       = {Haipeng Cai},
  doi          = {10.1145/3742900},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-45},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of program analysis for distributed software systems},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on event prediction methods from a systems perspective: Bringing together disparate research areas. <em>CSUR</em>, <em>57</em>(12), 1-37. (<a href='https://doi.org/10.1145/3743672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event prediction is the ability of anticipating future events, i.e., future real-world occurrences, and aims to support the user in deciding on actions that change future events towards a desired state. An event prediction method learns the relation between features of past events and future events. It is applied to newly observed events to predict corresponding future events that are evaluated with respect to the user’s desired future state. If the predicted future events do not comply with this state, actions are taken towards achieving desirable future states. Evidently, event prediction is valuable in many application domains such as business and natural disasters. The diversity of application domains results in a diverse range of methods that are scattered across various research areas which, in turn, use different terminology for event prediction methods. Consequently, sharing methods and knowledge for developing future event prediction methods is restricted. To facilitate knowledge sharing on account of a comprehensive integration and assessment of event prediction methods, we take a systems perspective to integrate event prediction methods into a single system, elicit requirements, and assess existing work with respect to the requirements. Based on the assessment, we identify open challenges and discuss future research directions.},
  archive      = {J_CSUR},
  author       = {Janik-Vasily Benzin and Stefanie Rinderle-Ma},
  doi          = {10.1145/3743672},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on event prediction methods from a systems perspective: Bringing together disparate research areas},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-augmented graph machine learning for drug discovery: A survey. <em>CSUR</em>, <em>57</em>(12), 1-38. (<a href='https://doi.org/10.1145/3744237'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence has become integral to intelligent drug discovery, with Graph Machine Learning (GML) emerging as a powerful structure-based method for modelling graph-structured biomedical data and investigating their properties. However, GML faces challenges such as limited interpretability and heavy dependency on abundant high-quality training data. On the other hand, knowledge-based methods leverage biomedical knowledge databases, e.g., Knowledge Graphs (KGs), to explore unknown knowledge. Nevertheless, KG construction is resource-intensive and often neglects crucial structural information in biomedical data. In response, recent studies have proposed integrating external biomedical knowledge into the GML pipeline to realise more precise and interpretable drug discovery with scarce training data. Nevertheless, a systematic definition for this burgeoning research direction is yet to be established. This survey formally summarises Knowledge-augmented Graph Machine Learning (KaGML) for drug discovery and organises collected KaGML works into four categories following a novel-defined taxonomy. We also present a comprehensive overview of long-standing drug discovery principles and provide the foundational concepts and cutting-edge techniques for graph-structured data and knowledge databases. To facilitate research in this promptly emerging field, we share collected practical resources that are valuable for intelligent drug discovery and provide an in-depth discussion of the potential avenues for future advancements.},
  archive      = {J_CSUR},
  author       = {Zhiqiang Zhong and Anastasia Barkova and Davide Mottin},
  doi          = {10.1145/3744237},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Knowledge-augmented graph machine learning for drug discovery: A survey},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Smart water-IoT: Harnessing IoT and AI for efficient water management. <em>CSUR</em>, <em>57</em>(12), 1-36. (<a href='https://doi.org/10.1145/3744338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The treatment, monitoring, and distribution of drinking water is an integral component of critical national infrastructure and therefore places continually increasing demands on Water Distribution Networks (WDNs). This domain and its sub-sectors face several major problems, namely climate change and drought-induced rises in water consumption from surface and underground reservoirs, in addition to the existence of significant water leaks during transmission to end users. These problems can be addressed by deploying Internet of Things (IoT) systems and smart distribution grids to improve the efficiency and safety of water distribution and to easily detect leaks or unauthorized consumption. This type of smart grid is referred to as Smart Water-IoT (SW-IoT), a novel, comprehensive water management concept. This review article discusses the application of IoT components and artificial intelligence (AI) in five basic categories (agriculture, water treatment, security, WDNs, and wastewater). Relevant legislation in the EU, USA, Canada, Australia, China, Japan, and India is also reviewed. In this context, the mandatory implementation of smart remote data reading solutions into the critical infrastructure of EU member states is outlined to highlight the importance of responsible water handling. The article provides a detailed analysis of the current research in SW-IoT and defines the main research challenges for future investigation.},
  archive      = {J_CSUR},
  author       = {Vlastimil Slany and Eva Krcalova and Jiri Balej and Martin Zach and Tereza Kucova and Michal Prauzek and Radek Martinek},
  doi          = {10.1145/3744338},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Smart water-IoT: Harnessing IoT and AI for efficient water management},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing the effectiveness of ChatGPT in secure code development: A systematic literature review. <em>CSUR</em>, <em>57</em>(12), 1-32. (<a href='https://doi.org/10.1145/3744553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ChatGPT, a Large Language Model (LLM) maintained by OpenAI, has demonstrated a remarkable ability to seemingly comprehend and contextually generate text. Among its myriad applications, its capability to autonomously generate and analyze computer code stands out as particularly promising. This functionality has piqued substantial interest due to its potential to streamline the software development process. However, this technological advancement also brings to the forefront significant apprehensions concerning the security of code produced by LLMs. In this article, we survey recent research that examines the use of ChatGPT to generate secure code, detect vulnerabilities in code, or perform other tasks related to secure code development. Beyond categorizing and synthesizing these studies, we identify important insights into ChatGPT’s potential impact on secure programming. Key findings indicate that while ChatGPT shows great promise as an aid in writing secure code, challenges remain. Its effectiveness varies across security tasks, depending on the context of experimentation (programming language, CWE, code length, etc.) and the benchmark used for comparison–whether against other LLMs, traditional analysis tools, or its own versions. The overall trend indicates that GPT-4 consistently surpasses its predecessor in most tasks.},
  archive      = {J_CSUR},
  author       = {Rezika Bouzid and Raphaël Khoury},
  doi          = {10.1145/3744553},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-32},
  shortjournal = {ACM Comput. Surv.},
  title        = {Assessing the effectiveness of ChatGPT in secure code development: A systematic literature review},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resource provisioning in fog computing - A survey. <em>CSUR</em>, <em>57</em>(12), 1-26. (<a href='https://doi.org/10.1145/3744662'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The internet world has created an era where any device can interconnect with each other. Gathering intelligence from streaming data is challenging and can create wonders and valuable innovations for humanity. The shortcomings of connectivity due to the remote location of the cloud induce latency and performance issues in real-time. Thus, a traditional cloud may not be suitable for all applications. A secure, low latent bandwidth infrastructure under research led to Fog Computing . The fog nodes have limited resources, and effective utilization can boost the application’s performance. Ensuring effective routing of the tasks and load balancing among the nodes is essential and tedious in any network. Resource management becomes challenging due to heterogeneity, dynamic workload, unpredictability of the computing environment, and so on. In such cases, using Artificial Intelligence (AI) can be promising, provided the complexity and the computing are handled. Proactive load handling based on the changes in network traffic has a huge scope for research. This article gives a detailed survey of the various fog network architectures and the intelligent methodologies in resource allocation in a fog network using machine learning algorithms. Furthermore, the article shows the directions of research in intelligent resource allocation and handling.},
  archive      = {J_CSUR},
  author       = {Divya Vetriveeran and Leena Sri R},
  doi          = {10.1145/3744662},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-26},
  shortjournal = {ACM Comput. Surv.},
  title        = {Resource provisioning in fog computing - A survey},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causality in bandits: A survey. <em>CSUR</em>, <em>57</em>(12), 1-30. (<a href='https://doi.org/10.1145/3744917'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The literature on bandits has developed largely independently of advances in causal inference. Work in the last few years has started investigating the close connections between these two areas and that has led to fruitful ideas that have produced advances in bandit algorithms. We present the first survey focusing specifically on the intersection of these two areas. We first provide a taxonomy for categorizing research in this area, and then place important works within this structure. We also describe various algorithms and methods, and provide the highlights. Finally, we point out promising directions for future research in this area.},
  archive      = {J_CSUR},
  author       = {Chandrasekar Subramanian and Balaraman Ravindran},
  doi          = {10.1145/3744917},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-30},
  shortjournal = {ACM Comput. Surv.},
  title        = {Causality in bandits: A survey},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
