<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>taylor</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aai">AAI - 55</h2>
<ul>
<li><details>
<summary>
(2025). Sentiment analysis of conversational implicature: A computational pragmatics approach. <em>AAI</em>, <em>39</em>(1), Article: 2565173. (<a href='https://doi.org/10.1080/08839514.2025.2565173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process of inferring the intention of conversational implicatures involves the interpretation of the speaker’s sentiment. However, the relationship between implicatures and sentiments has not been clear enough, and there is no research explaining the relationship between the response orientation of conversational implicature and sentiment score. Therefore, based on the dialogue snippets of conversational implicature, this paper uses automatic sentiment analysis, statistical testing and other methods to identify the statistical dependencies between implicatures and sentiments, and compare the sentiment scores of implicatures and literal meanings. The results show that the response orientation of implicature has a significant impact on the sentiment score, and its source only contains response utterance. In addition, within the response utterance, whether there is a significant difference between the sentiment scores of implicature and literal meaning is related to the selected algorithms of sentiment analysis. The sentiment lexicon-based method like Pattern cannot distinguish the sentimental difference between implicature and literal meaning, but the sentiment score obtained by the VADER-based method that considers grammatical and syntactical heuristics has significant differences in implicatures and literal meanings. Finally, the methodological implications of the experiments and results for the development of computational pragmatics are provided in this paper.},
  archive      = {J_AAI},
  author       = {Xianbo Li and Kunpei Xu},
  doi          = {10.1080/08839514.2025.2565173},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2565173},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Sentiment analysis of conversational implicature: A computational pragmatics approach},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing wheat single-nucleotide polymorphism data analysis with explainable deep learning models. <em>AAI</em>, <em>39</em>(1), Article: 2565169. (<a href='https://doi.org/10.1080/08839514.2025.2565169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of machine learning (ML) and deep learning (DL) is transforming scientific fields, including foodomics. This study advances the application of artificial neural networks (ANNs) for analyzing single-nucleotide polymorphism (SNP) data in foodomics. We introduce underutilized mechanisms in fields, such as data augmentation, dropout, batch normalization, learning rate scheduling, and Bayesian optimization for hyper-parameter optimization (HPO), enabling more robust and generalizable models. Our ANN achieves state-of-the-art performance on a publicly available dataset from prior work, with an average RMSE reduction of 0.017 (10.5%) over the previous ANN model and statistically significant improvements on strong traditional baselines, including Random Forest, XGBoost, LASSO, and Ridge regression. To enhance interpretability, we integrate SHAP (SHapley Additive exPlanations), which highlights the most influential SNP markers contributing to predictions, potentially identifying novel genomic markers. We also emphasize reproducibility, following best practices in code and data sharing. By making both our code and preprocessed dataset publicly available, we aim to support transparency and foster further research. Our results show that ANNs can serve not only as high-performing predictive models but also as explainable tools for SNP analysis in foodomics, contributing to the foundation of explainable artificial intelligence in this emerging field.},
  archive      = {J_AAI},
  author       = {Dario Ruggeri and László Vidács},
  doi          = {10.1080/08839514.2025.2565169},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2565169},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Advancing wheat single-nucleotide polymorphism data analysis with explainable deep learning models},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated machine learning approach (AutoML) to alzheimer’s disease diagnosis and prognosis. <em>AAI</em>, <em>39</em>(1), Article: 2565166. (<a href='https://doi.org/10.1080/08839514.2025.2565166'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is a neurodegenerative disorder characterized by memory loss. While applying Machine Learning (ML) demands a certain level of expertise, which is often a barrier for healthcare professionals, automated machine learning (AutoML) significantly lowers this barrier. This study analyzes an AutoML tool (PyCaret) for AD classification and prediction. Two experiments were designed to evaluate its diagnostic and prognostic capabilities with AD, Mild cognitive impairment (MCI), and Normal Controls (NC). SHapley Additive exPlanations (SHAP) was used to explain the ML models. For diagnosis, it had an accuracy of 98.6% for NC vs AD, 91.3%, for NC vs MCI, 92.5% for MCI vs AD, and 89.5% for the multiclass NC vs MCI vs AD. Regarding the prognosis capabilities, prediction of future cognitive states four years after their initial visit produced an accuracy of 92.8% for NC vs AD, 82.7% for NC vs MCI, 90.2% for MCI vs AD, and 81.4% for NC vs MCI vs AD. These results are in range and, in some cases, improve the state of the art even when compared to deep learning solutions. They confirm the potential of AutoML tools to automate ML algorithm selection and tuning for a specific medical application.},
  archive      = {J_AAI},
  author       = {Pablo Guillén and Enrique Frias-Martinez},
  doi          = {10.1080/08839514.2025.2565166},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2565166},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Automated machine learning approach (AutoML) to alzheimer’s disease diagnosis and prognosis},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining stochastic defenses to resist gradient inversion: An ablation study. <em>AAI</em>, <em>39</em>(1), Article: 2565165. (<a href='https://doi.org/10.1080/08839514.2025.2565165'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient Inversion (GI) attacks are a ubiquitous threat in Federated Learning (FL) as they exploit gradient leakage to reconstruct supposedly private training data. Common defense mechanisms such as Differential Privacy (DP) or stochastic Privacy Modules (PMs) introduce randomness during gradient computation to prevent such attacks. However, we pose that if an attacker effectively mimics a client’s stochastic gradient computation, the attacker can circumvent the defense and reconstruct clients’ private training data. This paper introduces several targeted GI attacks that leverage this principle to bypass common defense mechanisms. As a result, we demonstrate that no individual defense provides sufficient privacy protection. To address this issue, we propose to combine multiple defenses. We conduct an extensive ablation study to evaluate the influence of various combinations of defenses on privacy protection and model utility. We observe that only the combination of DP and a stochastic PM was sufficient to decrease the Attack Success Rate (ASR) from 100% to 0%, thus preserving privacy. Moreover, we found that this combination of defenses consistently achieves the best trade-off between privacy and model utility.},
  archive      = {J_AAI},
  author       = {Daniel Scheliga and Patrick Mäder and Marco Seeland},
  doi          = {10.1080/08839514.2025.2565165},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2565165},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Combining stochastic defenses to resist gradient inversion: An ablation study},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting inland waterway container on barge volume: A machine learning approach using economic features. <em>AAI</em>, <em>39</em>(1), Article: 2550462. (<a href='https://doi.org/10.1080/08839514.2025.2550462'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a machine learning approach to predict Container-on-Barge (COB) volume in Inland Waterway Transportation (IWT) systems, focusing exclusively on using economic features as predictors. Five machine learning models were trained using European economic features to forecast COB volume, while historical COB volume was used solely for validation and hyperparameter tuning. Among these models, the convolutional neural network combined with long short-term memory (CNN-LSTM) exhibited superior performance, achieving a mean absolute percentage error (MAPE) of 1.08% when forecasting eight consecutive quarters of COB volume in Europe. The results demonstrate the feasibility of accurately forecasting COB volume using economic features. This research develops an alternative method to forecast COB volume and provides a foundation for developing transfer learning models to predict COB volume in other emerging markets where historical COB volume data is limited. The findings are expected to assist in strategic planning and infrastructure investment for efficient and sustainable COB IWT systems.},
  archive      = {J_AAI},
  author       = {Fan Bu and Heather Nachtmann},
  doi          = {10.1080/08839514.2025.2550462},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2550462},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Forecasting inland waterway container on barge volume: A machine learning approach using economic features},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-based framework for automated symbol recognition and wiring design in electrical diagrams. <em>AAI</em>, <em>39</em>(1), Article: 2548834. (<a href='https://doi.org/10.1080/08839514.2025.2548834'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The digitization of electrical diagrams plays a crucial role in modern construction industries, enabling efficient reuse, seamless distribution, and accurate archiving. Despite technological advances, many of these diagrams remain in undigitized formats, leading to labor-intensive manual analysis for tasks such as cost estimation and wiring design. These challenges are aggravated by the diversity of symbols, high inter-class similarities, and the inherent complexities of wiring layouts, which require advanced recognition and efficient wiring design. This paper presents a deep learning framework that integrates an attention mechanism for symbol recognition, followed by a graph-based algorithm for fully automated wiring design. Through comparative evaluation, Efficient Channel Attention emerged as the most effective attention module, improving the mean average precision by 3.2%. The wiring algorithm leverages an improved pathfinding approach that reduces bends and total wiring length by 43% while adhering to boundary constraints and electrical rules. Extensive experiments on proprietary and public datasets demonstrate that the proposed framework significantly improves the recognition of complex electrical symbols, outperforming the baseline model. This research sets a new benchmark for automating electrical diagram analysis, offering substantial cost savings while reducing the manual effort associated with large-scale construction projects.},
  archive      = {J_AAI},
  author       = {Ikenna Ekeke and Carlos Francisco Moreno-García and Eyad Elyan},
  doi          = {10.1080/08839514.2025.2548834},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2548834},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Attention-based framework for automated symbol recognition and wiring design in electrical diagrams},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-phase feature selection framework for intrusion detection system: Balancing relevance and computational efficiency (2P-FSID). <em>AAI</em>, <em>39</em>(1), Article: 2539396. (<a href='https://doi.org/10.1080/08839514.2025.2539396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of data demands robust security mechanisms to prevent unauthorized access, making ML-based intrusion detection systems essential. However, high-dimensional data necessitates the need for effective feature selection. This study proposes the Two-Phase Feature Selection framework for Intrusion Detection (2P-FSID) to enhance model performance and interpretability. In Phase 1, a filter-based approach is employed to select a relevant subset of features, yielding an initial subset S1. These features are further assessed using Mutual Information (MI), Correlation (Corr), and Feature Importance (FI) as part of the Feature Relevance Estimation (FRE) process. A hybrid pruning strategy, comprising dynamic pruning and static pruning, is employed to refine the subset into S3. In Phase 2, Shapley Additive Explanations (SHAP) values are computed to quantify each feature’s influence on classification performance. Features are categorized into either positively or negatively influential. The model is initially trained using positively influential features, and then negatively influential features are iteratively added and evaluated for potential performance improvement, resulting in the final optimized subset S4. Experimental results on the NSL-KDD and UNSW-NB15 datasets demonstrate a reduction in feature space from 41 to 19 and 44 to 17 features, respectively, while achieving high detection accuracies of 95.18% and 92.79%.},
  archive      = {J_AAI},
  author       = {C. Rajathi and Rukmani Panjanathan},
  doi          = {10.1080/08839514.2025.2539396},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2539396},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A two-phase feature selection framework for intrusion detection system: Balancing relevance and computational efficiency (2P-FSID)},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel univariate feature selection with ANOVA F-test-based machine learning model for intrusion detection framework of robotics system. <em>AAI</em>, <em>39</em>(1), Article: 2539395. (<a href='https://doi.org/10.1080/08839514.2025.2539395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic systems have become popular across various industries, ranging from manufacturing and healthcare to logistics and space exploration. However, increasing the integration of robotic systems into critical infrastructures exposes devices to cybersecurity threats. The intrusion detection system (IDS) plays a vital role in safeguarding the systems from malicious activities and unauthorized access. This paper presents a novel, robotics-aware IDS framework incorporating hybrid feature selection and tailored classification strategies for robotic system. To evaluate the efficacy of the presented framework, an algorithm is also designed and tested using multiple machine-learning techniques. The NSL-KDD dataset is utilized for training and evaluating machine learning models due to the inclusion of a wide range of attack scenarios and normal instances. The results demonstrate that the proposed IDS effectively classifies cyberattacks relevant to robotic systems. The presented framework is also evaluated against existing IDS approaches in robotic systems. The results demonstrate that the proposed approach exhibits better results in terms of accuracy, robustness, and adaptability to emerging cyber threats.},
  archive      = {J_AAI},
  author       = {Narinder Verma and Neerendra Kumar and Kuljeet Singh and Abeer Aljohani and Anurag Sinha and Syed Abid Hussain},
  doi          = {10.1080/08839514.2025.2539395},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2539395},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A novel univariate feature selection with ANOVA F-test-based machine learning model for intrusion detection framework of robotics system},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multivariate time series anomaly detection using directed hypergraph neural networks. <em>AAI</em>, <em>39</em>(1), Article: 2538519. (<a href='https://doi.org/10.1080/08839514.2025.2538519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series anomaly detection is a challenging problem because there can be a number of complex relationships between variables in multivariate time series. Although graph neural networks have been shown to be effective in capturing variable-variable relationships (i.e. relationships between two variables), they are hard to capture variable-group relationships (i.e. relationships between variables and groups of variables). To overcome this limitation, we propose a novel method called DHG-AD for multivariate time series anomaly detection. DHG-AD employs directed hypergraphs to model variable-group relationships within multivariate time series. For each time window, DHG-AD constructs two different directed hypergraphs to represent relationships between variables and groups of positively and negatively correlated variables, enabling the model to capture both types of relationships effectively. The directed hypergraph neural networks learn node representations from these hypergraphs, allowing comprehensive multivariate interaction modeling for anomaly detection. We show through experiments using various evaluation metrics that our proposed method achieves the best scores among the compared methods on two real-world datasets.},
  archive      = {J_AAI},
  author       = {Tae Wook Ha and Myoung Ho Kim},
  doi          = {10.1080/08839514.2025.2538519},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2538519},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Multivariate time series anomaly detection using directed hypergraph neural networks},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting software anomalies in robots by means of one-class classifiers. <em>AAI</em>, <em>39</em>(1), Article: 2538459. (<a href='https://doi.org/10.1080/08839514.2025.2538459'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing dependence on collaborative robots in essential industrial and service sectors raises urgent concerns regarding their reliability and ability to handle faults. Undetected software issues can degrade performance, jeopardize safety, and result in expensive downtimes. Incorporating collaborative robots into daily life and industrial settings requires strong and dependable systems, especially concerning software. While most anomaly detection research has focused on hardware anomalies, this study addresses the underexplored challenge of software anomaly detection in component-based robotic systems. Leveraging a publicly available dataset with labeled software-induced anomalies, six one-class classification techniques were evaluated: Approximate Convex Hull, Autoencoder Neural Networks, K-Means, K-Nearest Neighbors, Principal Component Analysis, and Support Vector Data Description. Each classifier was assessed across preprocessing methods and hyperparameter configurations, using the Area Under the Curve (AUC) as the primary performance metric. The results show that Principal Component Analysis outperforms other methods in most scenarios, although the optimal performance varies depending on the anomaly type. The results confirm that the suggested one-class classification method is an efficient means of early identification of software anomalies in robotic systems, potentially improving operational reliability and reducing downtime.},
  archive      = {J_AAI},
  author       = {Héctor Quintián and Esteban Jove and Francisco Zayas-Gato and Nuño Basurto and Carlos Cambra and Álvaro Herrero},
  doi          = {10.1080/08839514.2025.2538459},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2538459},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Detecting software anomalies in robots by means of one-class classifiers},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Context-aware intrusion detection in vehicular communication networks: Enhanced attack modeling and dataset. <em>AAI</em>, <em>39</em>(1), Article: 2538453. (<a href='https://doi.org/10.1080/08839514.2025.2538453'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular Communication Networks (VCNs) are essential for autonomous vehicles and Intelligent Transportation Systems but face challenges in security vulnerabilities and data sparsity. Traditional attack models inadequately represent VCN dynamics, weakening threat detection, while existing datasets lack real-world mobility and spatiotemporal details. This study addresses these gaps by developing a comprehensive attack simulation framework, enhancing critical network attacks i.e. position spoofing, Sybil, and wormhole through realistic mobility patterns, positional dynamics, and temporal interactions. The resulting dataset contains legitimate and malicious instances: Spoofing (45,975 legitimate, 589 malicious), Wormhole (52,237 legitimate, 5,219 malicious), and Sybil (14,829 legitimate, 1,753 malicious). It includes essential vehicular-specific features such as mobility dynamics, inter-vehicle distances, and end-to-end communication patterns. For validation, machine learning algorithms, including Random Forest, K-Nearest Neighbors, and Logistic Regression were employed. Detection performance was evaluated using accuracy, precision, recall, and two F1-score variants (standard and macro). Results indicate high detection efficacy, with Random Forest achieving accuracy between 93.6% and 99.8% and F1-macro scores from 88.5% to 97.7%. Compared to previous studies lacking spatiotemporal considerations, our dataset’s enhanced realism demonstrates significant potential in advancing data-driven anomaly detection and real-world threat mitigation in dynamic vehicular environments.},
  archive      = {J_AAI},
  author       = {Muhammad Danish Khan and Vinh-Thong Ta and Husnain Rafiq and Nonso Nnamoko},
  doi          = {10.1080/08839514.2025.2538453},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2538453},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Context-aware intrusion detection in vehicular communication networks: Enhanced attack modeling and dataset},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting chinese disinformation with Fine–Tuned BERT and contextual techniques. <em>AAI</em>, <em>39</em>(1), Article: 2525127. (<a href='https://doi.org/10.1080/08839514.2025.2525127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the digital age, misinformation poses a significant threat to social cohesion, digital platform integrity, and political stability, particularly in countries with large online populations like China. Objectives – We examine how model architecture (BERT versus RoBERTa) and advanced strategies influence accuracy, precision, and recall on the multi – source MCFEND corpus. Building on large language models (LLMs) like BERT (Bidirectional Encoder Representations from Transformers) provides a promising avenue for addressing this challenge. This study presents a novel approach to specifically detecting Chinese misinformation using fine-tuned BERT models, incorporating techniques such as Contextual Unit Obscuration, Multi-span Concealment, and Adaptive Concealment. These methods enhance the models’ ability to capture linguistic nuances and contextual cues specific to Chinese text. Our BERT-based and RoBERTa-based fine-tuned models demonstrate superior performance compared to traditional fine-tuning methods and other state-of-the-art approaches, achieving an accuracy of 83.1% —surpassing state-of-the-art approaches – and achieve notable precision and recall scores over 0.73, marks a significant improvement over many existing detection frameworks. This research supports global efforts to combat misinformation by providing a robust framework across linguistic and cultural contexts. Integrating these models with media literacy and policy initiatives is vital to enhancing digital platform integrity, building a resilient information ecosystem, and promoting informed public discourse.},
  archive      = {J_AAI},
  author       = {Lixin Yun and Sheng Yun and Haoran Xue},
  doi          = {10.1080/08839514.2025.2525127},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2525127},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Detecting chinese disinformation with Fine–Tuned BERT and contextual techniques},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A pipeline for automating emergency medicine documentation using LLMs with retrieval-augmented text generation. <em>AAI</em>, <em>39</em>(1), Article: 2519169. (<a href='https://doi.org/10.1080/08839514.2025.2519169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and efficient documentation of patient information is vital in emergency healthcare settings. Traditional manual documentation methods are often time-consuming and prone to errors, potentially affecting patient outcomes. Large Language Models (LLMs) offer a promising solution to enhance medical communication systems; however, their clinical deployment, particularly in non-English languages such as German, presents challenges related to content accuracy, clinical relevance, and data privacy. This study addresses these challenges by developing and evaluating an automated pipeline for emergency medical documentation in German. The research objectives include (1) generating synthetic dialogues with known ground truth data to create controlled datasets for evaluating NLP performance and (2) designing an innovative pipeline to retrieve essential clinical information from these dialogues. A subset of 100 anonymized patient records from the MIMIC-IV-ED dataset was selected, ensuring diversity in demographics, chief complaints, and conditions. A Retrieval-Augmented Generation (RAG) system extracted key nominal and numerical features using chunking, embedding, and dynamic prompts. Evaluation metrics included precision, recall, F1-score, and sentiment analysis. Initial results demonstrated high extraction accuracy, particularly in medication data (F1-scores: 86.21%–100%), though performance declined in nuanced clinical language, requiring further refinement for real-world emergency settings.},
  archive      = {J_AAI},
  author       = {Denis Moser and Matthias Bender and Murat Sariyar},
  doi          = {10.1080/08839514.2025.2519169},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2519169},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A pipeline for automating emergency medicine documentation using LLMs with retrieval-augmented text generation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting and explaining postpartum depression in real-time with generative artificial intelligence. <em>AAI</em>, <em>39</em>(1), Article: 2515063. (<a href='https://doi.org/10.1080/08839514.2025.2515063'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among the many challenges mothers undergo after childbirth, postpartum depression (PPD) is a severe condition that significantly impacts their mental and physical well-being. Consequently, the rapid detection of PPD and their associated risk factors is critical for in-time assessment and intervention through specialized prevention procedures. Accordingly, this work addresses the need to help practitioners make decisions with the latest technological advancements to enable real-time screening and treatment recommendations. Mainly, our work contributes to an intelligent PPD screening system that combines Natural Language Processing, Machine Learning (ML), and Large Language Models (LLMS) toward an affordable, real-time, and noninvasive free speech analysis. Moreover, it addresses the black box problem since the predictions are described to the end users thanks to the combination of LLMS with interpretable ML models ( i.e . tree-based algorithms) using feature importance and natural language. The results obtained are 90 on PPD detection for all evaluation metrics, outperforming the competing solutions in the literature. Ultimately, our solution contributes to the rapid detection of PPD and their associated risk factors, critical for in-time and proper assessment and intervention.},
  archive      = {J_AAI},
  author       = {Silvia García-Méndez and Francisco de Arriba-Pérez},
  doi          = {10.1080/08839514.2025.2515063},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2515063},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Detecting and explaining postpartum depression in real-time with generative artificial intelligence},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing robustness in feature importance methods with NAFIC and CESHAP for improved interpretability. <em>AAI</em>, <em>39</em>(1), Article: 2515062. (<a href='https://doi.org/10.1080/08839514.2025.2515062'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding and interpreting machine learning models is crucial in high-stakes industries like steel manufacturing, where decisions impact energy efficiency and environmental sustainability. Traditional feature importance methods often struggle with robustness under noisy conditions, leading to unreliable insights. To address this problem, we introduce the Complexity and Interaction Enhanced SHAP (CESHAP), a novel feature importance method that incorporates model complexity and feature interactions. Alongside, we propose the Noise-Adjusted Feature Importance Change (NAFIC) metric to assess the robustness of feature importance methods against varying levels of noise. Experiments conducted on an energy consumption dataset from the steel industry, with systematically introduced Gaussian noise levels (5%, 10%, 15%, 20%), demonstrate that CESHAP offers superior robustness in tree-based models compared to SHapley Additive exPlanations (SHAP) and Permutation Feature Importance (PFI). Our findings underscore the effectiveness of CESHAP in enhancing interpretability and reliability in complex, non-linear models, ultimately supporting more informed decision-making in energy-intensive industries.},
  archive      = {J_AAI},
  author       = {Grigorios Tzionis and Georgia Kougka and Ilias Gialampoukidis and Stefanos Vrochidis and Ioannis Kompatsiaris and Maro Vlachopoulou},
  doi          = {10.1080/08839514.2025.2515062},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2515062},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Enhancing robustness in feature importance methods with NAFIC and CESHAP for improved interpretability},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSFE-net: Multi-scale feature enhancement network for remote sensing object detection. <em>AAI</em>, <em>39</em>(1), Article: 2514324. (<a href='https://doi.org/10.1080/08839514.2025.2514324'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense objects detection in remote sensing is challenging due to similar neighboring features, causing redundant boxes and positioning errors. To address this, we propose MSFE-Net, a multi-scale feature enhancement network designed to effectively suppress background interference and detect adjacent similar targets. Our Cascading Feature Fusion Module (CFFM) and Weighted Dilated Convolutional Pyramid (WDCP) enhance shallow texture and deep semantic features, respectively. To further reduce redundant target boxes, the Weighted Feature Fusion Enhancement Module (WFFEM) learns differential and fused features across multiple branches, thereby enriching target contextual features and suppressing background noise. Ultimately, the Multi-scale Feature Stairstep-upsampling Fusion Module (MFSFM) refines high-resolution texture and semantic features for targets across scales, using a stairstep-upsampling fusion strategy with outputs from the CFFM, WDCP, and WFFEM. Experimental results on the NWPU VHR-10 dataset show that MSFE-Net achieves 92.8% in mAP50 and 62.6% in mAP75, outperforming state-of-the-art methods such as YOLOv6 and YOLOv7. Compared to other models, MSFE-Net balances between parameter counts and computational demand, with Params slightly higher than YOLOv5s and YOLOv7-tiny and GFLOPs in a moderately high range. These results underscore MSFE-Net’s efficacy in balancing accuracy with computational demands, rendering it a highly practical option for dense object detection in remote sensing.},
  archive      = {J_AAI},
  author       = {Kai Yuan and Xing Li and Yaoyao Ren and Lianpeng Zhang and Wei Liu and Erzhu Li},
  doi          = {10.1080/08839514.2025.2514324},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2514324},
  shortjournal = {Appl. Artif. Intell.},
  title        = {MSFE-net: Multi-scale feature enhancement network for remote sensing object detection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Augmentation of semantic processes for deep learning applications. <em>AAI</em>, <em>39</em>(1), Article: 2506788. (<a href='https://doi.org/10.1080/08839514.2025.2506788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The popularity of Deep Learning (DL) methods used in business process management research and practice is constantly increasing. One important factor that hinders the adoption of DL in certain areas is the availability of sufficiently large training datasets, particularly affecting domains where process models are mainly defined manually with a high knowledge-acquisition effort. In this paper, we examine process model augmentation in combination with semi-supervised transfer learning to enlarge existing datasets and train DL models effectively. The use case of similarity learning between manufacturing process models is discussed. Based on a literature study of existing augmentation techniques, a concept is presented with different categories of augmentation from knowledge-light approaches to knowledge-intensive ones, e. g. based on automated planning. Specifically, the impacts of augmentation approaches on the syntactic and semantic correctness of the augmented process models are considered. The concept also proposes a semi-supervised transfer learning approach to integrate augmented and non-augmented process model datasets in a two-phased training procedure. The experimental evaluation investigates augmented process model datasets regarding their quality for model training in the context of similarity learning between manufacturing process models. The results indicate a large potential with a reduction of the prediction error of up to 53%.},
  archive      = {J_AAI},
  author       = {Maximilian Hoffmann and Lukas Malburg and Ralph Bergmann},
  doi          = {10.1080/08839514.2025.2506788},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2506788},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Augmentation of semantic processes for deep learning applications},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EXplainable artificial intelligence for hip fracture recognition. <em>AAI</em>, <em>39</em>(1), Article: 2502568. (<a href='https://doi.org/10.1080/08839514.2025.2502568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting hip fractures from X-rays is a critical area where artificial intelligence can significantly reduce diagnostic errors, minimize reliance on advanced imaging techniques, and expedite the diagnostic process and subsequent surgical interventions. In this paper, we present an approach of eXplainable Artificial Intelligence, which focuses not only on the accuracy of models but also on their interpretability and the ability of users to understand and trust the decisions made by the automatic system. We present a model for the automatic classification of hip fractures in radiographs based on Convolutional Neural Networks, which is enhanced by a twin Case-Based Reasoning methodology for acquiring explanatory experiences and learning how to generate textual explanations. These findings underscore the practical benefits of incorporating explanations into medical diagnostics, paving the way for improved patient outcomes and more reliable diagnostic processes.},
  archive      = {J_AAI},
  author       = {Enrique Queipo-de-Llano and Marius Ciurcau and Alejandro Paz-Olalla and Belén Díaz-Agudo and Juan A. Recio-García},
  doi          = {10.1080/08839514.2025.2502568},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2502568},
  shortjournal = {Appl. Artif. Intell.},
  title        = {EXplainable artificial intelligence for hip fracture recognition},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time series forecasting using recurrent neural networks based on recurrent sigmoid piecewise linear neurons. <em>AAI</em>, <em>39</em>(1), Article: 2490057. (<a href='https://doi.org/10.1080/08839514.2025.2490057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new recurrent sigmoid piecewise linear neuron that can be used in neural networks to perform time series forecasting. The neuron model guarantees its dynamical stability for any sequence of input values and any number of recurrent steps and provides an upper bound for the variance of context vector elements. The neuron can be used as a drop-in replacement for the popular long short-term memory and gated recurrent unit neurons. In addition to theoretical analysis experiments on real-world time series were performed to evaluate networks with different structures and neuron types. Experiments show that networks with the new neuron achieve better test accuracy while using a considerably smaller number of trainable parameters.},
  archive      = {J_AAI},
  author       = {Victor Sineglazov and Vladyslav Horbatiuk},
  doi          = {10.1080/08839514.2025.2490057},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2490057},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Time series forecasting using recurrent neural networks based on recurrent sigmoid piecewise linear neurons},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized recommendation system of E-commerce in the digital economy era: Enhancing social connections with graph attention networks. <em>AAI</em>, <em>39</em>(1), Article: 2487417. (<a href='https://doi.org/10.1080/08839514.2025.2487417'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of digital economy, e-commerce platforms face significant challenges in providing personalized recommendations due to data sparsity, a result of limited user-product interactions. This research introduces a model that enhances e-commerce personalization by leveraging graph attention networks to mine and integrate information from user-item (U-I) score graphs and user-user (U-U) social graphs. The U-U social graph captures user relationships, providing supplementary information to uncover social connections and preferences, especially among users with sparse interactions, thereby alleviating data sparsity concerns. Additionally, the model incorporates graph contrastive learning to extract universal features of users and items, further mitigating the sparse data challenge. Our approach, when applied to the CiaoDVD and Epinions datasets, demonstrated a 1.21% improvement in Mean Absolute Error (MAE) and a 2.22% improvement in Root Mean Square Error (RMSE) on the CiaoDVD dataset, and a 1.71% improvement in MAE and a 2.11% improvement in RMSE on the Epinions dataset, outperforming all baseline methods.},
  archive      = {J_AAI},
  author       = {Yuan He and Yonghong Du and Xiaofei Pu},
  doi          = {10.1080/08839514.2025.2487417},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2487417},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Personalized recommendation system of E-commerce in the digital economy era: Enhancing social connections with graph attention networks},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image logic and semantics of user motion interaction language based on deep learning. <em>AAI</em>, <em>39</em>(1), Article: 2482989. (<a href='https://doi.org/10.1080/08839514.2025.2482989'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of science and technology, exploring the image logic semantics of users’ Chinese language using deep learning is crucial for understanding users’ interactions in virtual space. To address the challenges of recognizing existential sentences in Chinese language images, this research introduces a Tree-LSTM encoder, combined with an improved Transformer attention mechanism, to construct a logical semantic recognition model. The model was validated using a dataset from the Modern Dictionary database. Results showed that the proposed model achieved a recognition accuracy of 90.01%, surpassing other models by at least 2.99%. After incorporating Wikipedia data, the model’s performance in handling complex sentence structures and technical terminology was particularly outstanding. When all the extended data sources were integrated, the model’s accuracy reached 92.31%, representing a 2.3% improvement over the original dataset. This success is due to the Tree-LSTM’s ability to capture hierarchical and logical relationships within sentences. The model also effectively learns and recognizes low-frequency new words, enhancing overall performance.},
  archive      = {J_AAI},
  author       = {Yanlan Liu and Yixi Zhai and Liqing Chu and Dandan Wang and Yufei Wu},
  doi          = {10.1080/08839514.2025.2482989},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2482989},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Image logic and semantics of user motion interaction language based on deep learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards automated frequency response analysis of power transformers with deep learning. <em>AAI</em>, <em>39</em>(1), Article: 2479223. (<a href='https://doi.org/10.1080/08839514.2025.2479223'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequency response analysis (FRA) has emerged as one of the standard techniques for monitoring the integrity of the mechanical structure of power transformer windings. Interpreting FRA test results, though, is still largely dependent on expert identification of graphical features. Machine learning, however, presents an opportunity to automate and improve this feature identification process. In this study, FRA measurements were simulated and then image and series data representations were used to train three neural networks. The Xception network, trained with image magnitude data, obtained the best performance, with an F1 score of 98.6%. The ResNet and Fully Connected Neural Network, trained with series magnitude data, obtained F1 scores of 94.6% and 91.4%, respectively. Results revealed that networks trained using image-encoded FRA data outperformed those trained using series FRA data.},
  archive      = {J_AAI},
  author       = {Micah Phillip and Arvind Singh and Craig J. Ramlal},
  doi          = {10.1080/08839514.2025.2479223},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2479223},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Towards automated frequency response analysis of power transformers with deep learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring healthcare and public health implications via temporal analysis of Human–Virus interactions leveraging adversarial networks and saliency maps. <em>AAI</em>, <em>39</em>(1), Article: 2476237. (<a href='https://doi.org/10.1080/08839514.2025.2476237'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Viruses are prone to rapid mutations that enhance traits like transmissibility and resistance to treatments. The adaptability complicates the development of effective vaccines. The study investigates the dynamic interactions between humans and COVID-19 virus through time-series analysis, focusing on how these interactions evolve over time. A novel approach was introduced using adversarial networks to model the relationship between human and viral entities, capturing their temporal dynamics. Two interdependent models are trained within a framework, allowing us to forecast interactions and identify influential features. Saliency maps were utilized to visualize the factors affecting these interactions over time. The technique helps reveal how specific viral properties shift in response to human factors. The findings of the study aim to enhance the understanding of human-virus dynamics, particularly for COVID-19, offering potential insights for public health strategies and interventions. By combining adversarial networks with saliency visualization, the study provides an intensive study for analyzing and interpreting complex temporal interactions between humans and viruses.},
  archive      = {J_AAI},
  author       = {Nihal Srivastava and Logesh Ravi and Malathi Devarajan and Amal John Kachapilly and Jaisuraj Bantupalli and Sanjukta Roy},
  doi          = {10.1080/08839514.2025.2476237},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2476237},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Exploring healthcare and public health implications via temporal analysis of Human–Virus interactions leveraging adversarial networks and saliency maps},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting trip duration and distance in bike-sharing systems using dynamic time warping. <em>AAI</em>, <em>39</em>(1), Article: 2474786. (<a href='https://doi.org/10.1080/08839514.2025.2474786'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bike-sharing systems (BSSs) have recently become important in urban transportation due to several factors, such as their cost-effectiveness and environmental considerations. The BSS provides an enormous amount of data that is recorded regarding trips. This huge volume of bike sharing data raises various challenges and opportunities. Many research studies have used bike sharing datasets to understand the geographical, social, financial, and behavioral aspects of bike user behaviors. While existing literature primarily focuses on predicting the number of rentals and returns per station, this study addresses the complementary aspect of predicting the trip duration and distance of the trip. Accurate prediction of ride duration allows a better estimate of bike availability at stations, while distance predictions assist in maintenance planning based on bike usage patterns. The contribution of this work is twofold. First, the proposed work clusters the BSS dataset into k sub-datasets based on similarity of dataset instances. Then, the predictive model is trained to predict the data of each sub-dataset separately. Thus, there will be k models for the k sub-dataset. Next, the performance of the proposed method, the average score of the k models, will be compared to the performance of a model trained on the complete dataset on predicting BSSs ride duration and distance of the trip. The rationale for splitting the dataset into k sub-datasets is to separate similar patterns in one sub-dataset. Second, the utilization of the dynamic time warping (DTW) algorithm on the BSSs data was proposed for the clustering purpose, as the DTW usage is very limited in the current literature of BSSs. The dataset clustering is based on the similarity of the curves representing the number of trips between each pair of bike stations throughout the day hours. Then, the DTW algorithm is used to measure the curve similarity between these bike station pairs’ curves. These two contributions of the proposed approach complement existing prediction models for rentals and returns, providing a comprehensive solution for BSS optimization. The proposed method was thoroughly evaluated on two real datasets of different sizes. For the two datasets, the obtained results show that the best improvements of the predictive model’s accuracy are 30% and 42% on average for predicting trip duration and distance of the trip, respectively.},
  archive      = {J_AAI},
  author       = {Ahmed Ali and Ahmad Salah and Mahmoud Bekhit and Ahmed Fathalla},
  doi          = {10.1080/08839514.2025.2474786},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2474786},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Predicting trip duration and distance in bike-sharing systems using dynamic time warping},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot learning for triplet-based EV energy consumption estimation. <em>AAI</em>, <em>39</em>(1), Article: 2474785. (<a href='https://doi.org/10.1080/08839514.2025.2474785'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the energy consumption of an electric vehicle (EV) is often relevant when planning and managing electric mobility. The prediction is challenging as EV energy consumption is highly variable and dependent on context . First, this paper proposes an integrated framework for the collection of online telematic data, processing of this data, online maintenance of statistics, and machine-learning-based prediction of travel time and energy consumption. A key feature of the proposed framework is the preprocessing of the trajectory data into triplets , a convenient data unit that captures the relevant context necessary for effective energ y prediction. The second contribution of the paper addresses the effective management of drastic change in context through robust energy prediction models. In particular, using few-shot learning techniques, we tackle the problem of the need to create different energy prediction models for different EV types, from small EVs to electric buses. Experimental results on three different data sets demonstrate how energy prediction models adapt to different EV types.},
  archive      = {J_AAI},
  author       = {Alminas Čivilis and Linas Petkevičius and Simonas Šaltenis and Kristian Torp and Ieva Markucevičiūtė-Vinckė},
  doi          = {10.1080/08839514.2025.2474785},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2474785},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Few-shot learning for triplet-based EV energy consumption estimation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MagneticPillars++: Efficient LiDAR odometry via deep frame-to-keyframe point cloud registration. <em>AAI</em>, <em>39</em>(1), Article: 2472105. (<a href='https://doi.org/10.1080/08839514.2025.2472105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Downstream applications for point cloud registration, like LiDAR Odometry, often conduct Iterative Closest Points (ICP) in the initial frame-to-frame matching and/or subsequent map refinement. However, due to its distance-based processing nature, ICP relies on an accurate pose initialization while implicating increased computational complexity with a growing number of points. To meet specific runtime requirements, methods often apply the extensive mapping step at low frequencies, e.g. every 10 frames, which in turn leads to increased noise on the calculated trajectory. To tackle the discrepancy between runtime and accuracy, we present MagneticPillars++, an extension of our previous point cloud registration approach optimized for LiDAR Odometry, introducing novel intermediate cell correspondence filtering and accelerated match normalization. Furthermore, we propose a frame-to-keyframe matching technique replacing the simple frame-to-frame matching within a LiDAR Odometry pipeline. This can tremendously reduce noise without the need for expensive ICP corrections. We conduct extensive experiments for various tasks like point cloud registration, LiDAR Odometry, and loop closure estimation, demonstrating the versatility of our approach, where we are able to outperform state-of-the-art approaches in terms of accuracy and runtime, resulting in residual translation and rotation errors of up to 4.7 cm and 0.231 with an average runtime of.},
  archive      = {J_AAI},
  author       = {Kai Fischer and Martin Simon and Stefan Milz and Patrick Mäder},
  doi          = {10.1080/08839514.2025.2472105},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2472105},
  shortjournal = {Appl. Artif. Intell.},
  title        = {MagneticPillars++: Efficient LiDAR odometry via deep frame-to-keyframe point cloud registration},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSNet: A novel deep learning framework for efficient missing seedling detection in maize fields. <em>AAI</em>, <em>39</em>(1), Article: 2469372. (<a href='https://doi.org/10.1080/08839514.2025.2469372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine vision application in agriculture has spurred significant interest in crop-missing detection. This study targets critical challenges, such as comprehensive aerial imagery coverage, tiny seedlings easily mistaken for weeds, and the absence of adaptive learning in traditional row classification. We propose a novel methodology for missing seedling detection, which comprises three essential stages: seedling localization, row classification, and missing region prediction. We present SeedNet, a detector that leverages row direction information to enhance small seedling detection performance. By incorporating this information, SeedNet improves recall by 25.3 % and AP by 15.4 % compared to the baseline. Additionally, we introduce PeakNet, a deep learning-based classifier for row segmentation that efficiently adapts to row spacing without any prior assumptions, achieving an accuracy of 99.69 % . Finally, missing areas are predicted by analyzing the relative distances between adjacent seedlings within the same row. Under challenging outdoor conditions, this method achieves a missing detection accuracy of 98 % , meeting practical requirements for field testing. SeedNet and PeakNet demonstrate exceptional performance in real-time processing, achieving inference speeds of 105 FPS and 2295 FPS, respectively. These results indicate strong potential for practical applications in real-time agricultural systems. The proposed approach provides a high-performance, low-cost solution for crop missing detection.},
  archive      = {J_AAI},
  author       = {Yong Shi and Ruijie Xu and Zhiquan Qi},
  doi          = {10.1080/08839514.2025.2469372},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2469372},
  shortjournal = {Appl. Artif. Intell.},
  title        = {MSNet: A novel deep learning framework for efficient missing seedling detection in maize fields},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Handling class imbalanced data in sarcasm detection with ensemble oversampling techniques. <em>AAI</em>, <em>39</em>(1), Article: 2468534. (<a href='https://doi.org/10.1080/08839514.2025.2468534'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of social media has amplified online sharing, necessitating businesses to comprehend public sentiment. Traditional sentiment analysis struggles with sarcasm detection and class imbalance. To address this, we introduce Synthetic Ensemble Oversampling methods (SEO) that effectively leverage the strengths of various oversampling algorithms. By incorporating ensemble learning principles into oversampling techniques, our proposed methods offer distinct strategies for selecting newly generated sarcastic data. In this study, we employ five oversampling algorithms: Synthetic Minority Oversampling TEchnique (SMOTE), Adaptive Synthetic Sampling (ADASYN), polynom-fit-SMOTE, Proximity Weighted Synthetic Sampling (ProWSyn), and SMOTE with Instance Prioritization and Filtering (SMOTE_IPF). We work with two imbalanced sarcasm detection datasets, iSarcasmEval and SARC-reduced, collected from Twitter and Reddit. After extracting features from using Word2Vec, Global Vectors (GloVe), and FastText, we apply oversampling and ensemble techniques. Evaluated across six classifiers – Support Vector Machine, Decision Tree, Random Forest, Extreme Gradient Boosting, Logistic Regression, and BERT – the results demonstrate that the SEO2 framework consistently enhances classifier performance compared to single oversampling techniques. Notably, the Cluster Uncentered method frequently provides the best improvements across datasets, achieving significant gains in both AUC and F1 scores. These findings highlight the potential of ensemble-based oversampling in addressing class imbalance for sarcasm detection.},
  archive      = {J_AAI},
  author       = {Ya-Han Hu and Ting-Hsuan Liu and Chih-Fong Tsai and Yu-Jung Lin},
  doi          = {10.1080/08839514.2025.2468534},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2468534},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Handling class imbalanced data in sarcasm detection with ensemble oversampling techniques},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prior waveform guided network (PWGN) for laser detection in fog. <em>AAI</em>, <em>39</em>(1), Article: 2463725. (<a href='https://doi.org/10.1080/08839514.2025.2463725'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of autonomous vehicles and mobile robotics, lidar has been one of the most popular researches in the world. But the poor ranging accuracy and detection range in the foggy situation have limited the application of lidar. In this paper, the detection of pulsed lidar in fog is investigated. The transmission model in the fog of the laser signal is established by considering laser backscattering in the fog. A Prior Waveform Guided Network (PWGN) based on the Convolutional Neural Network (CNN) is proposed. The results of simulation and experiments show that the PWGN can effectively remove the interference of fog in the detection of pulsed laser signal. The mean of absolute errors(MAE) of the detection achieves 3.13 cm at the range of 10 m at the scattering rate of 30%. The MAE may be half or 1/3 of the MAEs of other approaches at the detection range of 42 m.},
  archive      = {J_AAI},
  author       = {Haowei Zhu and Long Wu and Xu Yang and Lu Xu and Shuyu Chen and Yong Zhang and Jianlong Zhang and Chenghua Yang and Wei Zhang},
  doi          = {10.1080/08839514.2025.2463725},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2463725},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Prior waveform guided network (PWGN) for laser detection in fog},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Establishing a dynamic recommendation system for E-commerce by integrating online reviews, product feature expansion, and deep learning. <em>AAI</em>, <em>39</em>(1), Article: 2463723. (<a href='https://doi.org/10.1080/08839514.2025.2463723'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing fragmentation of the consumer journey complicates understanding consumer behavior and tracking digital footprints. Product feature tags should dynamically adapt to consumer preferences, marketing campaigns, and trending internet topics, leveraging crawler technology to address this. However, many e-commerce platforms still rely on manual tagging or static product attribute classification, with limited adoption of machine learning approaches. This study proposes a dynamic tagging and recommendation system using deep learning for product image recognition and similarity comparison. By integrating crawler technology, internet trends can serve as dynamic product tags. These tags, combined with consumer behavior data, enable the creation of a recommendation system capable of automatically generating relevant tags. Sales data from 3,132 cartoon products on a Taiwanese e-commerce platform were analyzed. A convolutional neural network was employed to establish a tagging and image recognition model, and it was trialed over 24 weeks. Results showed significant improvements in consumer engagement: average clicks per product increased by 36.1%, views by 22.9%, products added to carts by 32.3%, orders by 28.3%, and payment transactions by 30.4%. Aligning recommendation systems with consumer expectations enhances their ability to identify preferences and drive purchasing behavior.},
  archive      = {J_AAI},
  author       = {Tsung-Yin Ou and Chun-Hung Chen and Wen-Lung Tsai},
  doi          = {10.1080/08839514.2025.2463723},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2463723},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Establishing a dynamic recommendation system for E-commerce by integrating online reviews, product feature expansion, and deep learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI ethics: Integrating transparency, fairness, and privacy in AI development. <em>AAI</em>, <em>39</em>(1), Article: 2463722. (<a href='https://doi.org/10.1080/08839514.2025.2463722'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expansion of Artificial Intelligence in sectors such as healthcare, finance, and communication has raised critical ethical concerns surrounding transparency, fairness, and privacy. Addressing these issues is essential for the responsible development and deployment of AI systems. This research establishes a comprehensive ethical framework that mitigates biases and promotes accountability in AI technologies. A comparative analysis of international AI policy frameworks from regions including the European Union, United States, and China is conducted using analytical tools such as Venn diagrams and Cartesian graphs. These tools allow for a visual and systematic evaluation of the ethical principles guiding AI development across different jurisdictions. The results reveal significant variations in how global regions prioritize transparency, fairness, and privacy, with challenges in creating a unified ethical standard. To address these challenges, we propose technical strategies, including fairness-aware algorithms, routine audits, and the establishment of diverse development teams to ensure ethical AI practices. This paper provides actionable recommendations for integrating ethical oversight into the AI lifecycle, advocating for the creation of AI systems that are both technically sophisticated and aligned with societal values. The findings underscore the necessity of global collaboration in fostering ethical AI development.},
  archive      = {J_AAI},
  author       = {Petar Radanliev},
  doi          = {10.1080/08839514.2025.2463722},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2463722},
  shortjournal = {Appl. Artif. Intell.},
  title        = {AI ethics: Integrating transparency, fairness, and privacy in AI development},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metadata enriched multi-instance contrastive learning for high-quality facial skin visual representations. <em>AAI</em>, <em>39</em>(1), Article: 2462389. (<a href='https://doi.org/10.1080/08839514.2025.2462389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Utilizing self-supervised learning to learn meaningful representations from unlabeled data can be a cost-effective strategy, particularly in medical domains where expert labeling incurs high costs. Contrastive learning typically employs a single contrastive relationship based on individual instances. However, depending on the task-related characteristics, such as facial skin images, this approach may be unsuitable for learning useful representations. In this work, we propose an advanced contrastive learning method to learn high-quality facial skin representations that are useful for various downstream applications related to skin disorders, such as wrinkles and pigmentation. Our method leverages metadata to establish effective multi-instance contrastive relationships specifically for facial skin images. To this end, we employ mini-batches, constructed through the integration of multiple contrastive relationships, to enable a model to learn the multifaceted features of facial skin. Using a facial skin image dataset, we demonstrate that the proposed method is effective in classifying facial wrinkles and pigmentation severity compared to conventional contrastive learning. The features learned by the proposed method adapt well to other skin lesion datasets from different sources, demonstrating the transferability of the learned skin representations. Our study highlights the potential of application-specific batch configurations leveraging metadata to enhance the effectiveness of self-supervised learning.},
  archive      = {J_AAI},
  author       = {Jihyo Kim and Sungchul Kim and Seungwon Seo and Bumsoo Kim and Daejeong Mun and Hoonjae Lee and Sangheum Hwang},
  doi          = {10.1080/08839514.2025.2462389},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2462389},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Metadata enriched multi-instance contrastive learning for high-quality facial skin visual representations},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DHMDL: Dynamically hashed multimodal deep learning framework for racket video summarization using audio and visual markers. <em>AAI</em>, <em>39</em>(1), Article: 2462382. (<a href='https://doi.org/10.1080/08839514.2025.2462382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sports videos are being streamed over a large range of social media platforms, and they always have a huge audience base and viewer history. In order to provide more excitement for the users in watching a completed game, automatic video summarization is an inevitable solution. While sports like soccer, cricket have been the main focus of the video summarization research, little attention has been centered over racket sports. Our proposed dynamically hashed multimodal deep learning (DHMDL) sports video summarization framework fuses excitement scores by utilizing deep learning architectures to extract cues from multi modalities namely commentator voice, spectators’ cheers and player’s expression and then leverages to generate video segment as highlight by using hash codes mapped to weighted sum of excitement score. Also, the proposed synchronized parallel processing ranking based hash map framed using the merge sorting technique for categorizing the excitement scores is applied in video summarization. The framework is tested on U.S. Open and Wimbledon match videos and the results show superior results against state-of-art techniques with normalized discounted cumulative gain (nDCG) score improved by 2%, positive matching highlight segment identification increased by 20% on YouTube Videos.},
  archive      = {J_AAI},
  author       = {G. Priyanka and J. Senthil Kumar and M. Prasha Meena},
  doi          = {10.1080/08839514.2025.2462382},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2462382},
  shortjournal = {Appl. Artif. Intell.},
  title        = {DHMDL: Dynamically hashed multimodal deep learning framework for racket video summarization using audio and visual markers},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-based energy consumption prediction model for green industrial parks. <em>AAI</em>, <em>39</em>(1), Article: 2462375. (<a href='https://doi.org/10.1080/08839514.2025.2462375'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancing the accuracy of industrial building energy consumption forecasts is beneficial for improving energy management and addressing the imbalance between supply and demand in building electricity use. To overcome the limitations of existing energy consumption forecasting methods, which inadequately consider the specific energy usage characteristics and user behaviors in parks and often perform poorly at predicting extreme values, this study proposes a hybrid energy consumption forecasting model combines Singular Spectrum Analysis (SSA) and Long Short-Term Memory (LSTM) neural networks. Initially, SSA is used to extract the autocorrelation of the electricity consumption series and eliminate the mutual interference caused by component mixing. Then, fuzzy entropy values are utilized to differentiate the complexity of various components, reconstructing them into high-frequency and low-frequency components. These components are then predicted using a multi-factor LSTM model optimized by improved particle swarm optimization, with the results aggregated for the final forecast. The results indicate that the model’s root mean square error is only 12.116 kWh, which is lower compared to the LSTM multi-factor model, the EMD-LSTM model, and the SSA-LSTM model. The model shows a closer fit to the original series trend and more accurate predictions at extreme points, aligning more closely with actual values.},
  archive      = {J_AAI},
  author       = {Chaoan Lai and Yina Wang and Jianhua Zhu and Xuequan Zhou},
  doi          = {10.1080/08839514.2025.2462375},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2462375},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Deep learning-based energy consumption prediction model for green industrial parks},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variable selection algorithm for explaining anomalies in real-world regenerative thermal oxidizers. <em>AAI</em>, <em>39</em>(1), Article: 2462374. (<a href='https://doi.org/10.1080/08839514.2025.2462374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of regenerative thermal oxidizers (RTOs), which reduce hazardous air pollution and save energy, has increased with the rapid growth of industrial technology. Therefore, detecting and explaining anomalies in RTOs have become important. To accurately detect anomalies in RTOs, it is required to apply reconstruction-based anomaly detection (AD) models, which is currently proposed as a main AD research area. However, traditional explainable artificial intelligence (XAI) cannot explain reconstruction-based AD models to identify main facilities in RTOs. To address this problem, we developed a method to improve the accuracy of XAI in explaining reconstruction-based AD models. Specifically, we first grouped the variables based on correlation and the clustering analysis. We then calculated the impact of each group on normal/abnormal events in terms of the maximum mean discrepancy and cosine similarity. Using the most influencing variables based on our method, XAI correctly identified the main variables without considering unnecessary variables. Experimental results on a real-world RTO dataset showed that our method improve the accuracy of XAI that determine the main variables compared to the traditional XAI.},
  archive      = {J_AAI},
  author       = {Min-Ji Seo and Myung-Ho Kim},
  doi          = {10.1080/08839514.2025.2462374},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2462374},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Variable selection algorithm for explaining anomalies in real-world regenerative thermal oxidizers},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A composite recognition method based on multimode mutual attention fusion network. <em>AAI</em>, <em>39</em>(1), Article: 2462371. (<a href='https://doi.org/10.1080/08839514.2025.2462371'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the problem of single-mode vulnerability to complex environments, a multimode fusion network with mutual attention is proposed. This network combines the use of laser, infrared and millimeter wave modalities to leverage the advantages of each mode in different environments, increasing the network’s resilience to interference. The study begins with the construction of pixel-level fusion networks, feature-weighted fusion networks and the multimode mutual attention fusion network. A comprehensive introduction to the multimode mutual attention fusion network is given, as well as a comparison with the other two networks. The model is then trained and evaluated using data from glide rocket and drone experiments. Finally, an analysis of the anti-outlier interference capability of the multimode fusion network with mutual attention is carried out. The test results show that the multimode mutual attention fusion network containing a feature fusion attention mechanism has the highest detection performance and anti-interference ability. Without interference, the network achieves a remarkable accuracy of 0.98 for multi-target recognition. In addition, with an accuracy of 0.96, it ensures a high level of stability in various interference environments. In addition, the introduction of multi-scale fusion has improved the rocket’s speed adaptability by about 75%.},
  archive      = {J_AAI},
  author       = {Xing Ding and Xiangrong Zhang and Chao Liang and Bo Liu and Lanjie Niu},
  doi          = {10.1080/08839514.2025.2462371},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2462371},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A composite recognition method based on multimode mutual attention fusion network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DC-BiLSTM-CNN algorithm for sentiment analysis of chinese product reviews. <em>AAI</em>, <em>39</em>(1), Article: 2461809. (<a href='https://doi.org/10.1080/08839514.2025.2461809'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of e-commerce has led to a significant increase in user feedback, especially in the form of post-purchase comments on online platforms. These reviews not only reflect customer sentiments but also crucially influence other users’ purchasing decisions due to their public accessibility. The sheer volume and complexity of product reviews make manual sorting challenging, necessitating businesses to autonomously process and discern customer sentiments. Chinese, a predominant language on e-commerce platforms, presents unique challenges in sentiment analysis due to its character-based nature. This paper introduces an innovative Dual-Channel BiLSTM-CNN (DC-BiLSTM-CNN) algorithm. Based on the language characteristics of Chinese product reviews, a sentiment analysis algorithm, dual channel BiLSTM-CNN (DC-BiLSTM-CNN), is proposed. The algorithm constructs two channels, transforming text into both character and word vectors and inputting them into Bidirectional Long Short-Term Memory (BiLSTM), and Convolutional Neural Network (CNN) models. The combination of these channels facilitates a more comprehensive feature extraction from reviews. Comparative analysis revealed that DC-BiLSTM-CNN significantly outperforms baseline models, substantially enhancing the classification of product reviews. We conclude that the proposed DC-BiLSTM-CNN algorithm offers an effective solution for handling Chinese product reviews, carrying positive implications for businesses seeking to enhance product and service quality, ultimately resulting in heightened user satisfaction.},
  archive      = {J_AAI},
  author       = {Yuanfang Dong and Xiaofei Li and Meiling He and Jun Li},
  doi          = {10.1080/08839514.2025.2461809},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2461809},
  shortjournal = {Appl. Artif. Intell.},
  title        = {DC-BiLSTM-CNN algorithm for sentiment analysis of chinese product reviews},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Torque prediction in deep hole drilling: Artificial neural networks versus nonlinear regression model. <em>AAI</em>, <em>39</em>(1), Article: 2459482. (<a href='https://doi.org/10.1080/08839514.2025.2459482'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main challenges when drilling small and deep holes is the difficulty of chip evacuation. As the hole depth increases, chips tend to become tightly compressed, causing chip jamming. It leads to a rapid increase in cutting forces and strong random fluctuations. The discontinuous chip evacuation process makes the cutting force signal strongly nonlinear and random, making it difficult to predict accurately. In this paper, we have developed a two-layer artificial neural network (ANN) model for training using the Levenberg-Marquardt algorithm to predict torque during deep drilling. Unlike many previous studies, this model uses hole depth as an input vector element instead of hole diameter. The model has been validated through experiments drilling AISI-304 stainless steel with hole depth-to-diameter ratios of 8 under continuous drilling conditions with ultrasonic-assisted vibration. The performance of the ANN model was compared with the exponential model and evaluated by the MAPE index. Results show that the ANN model has better predictive capability, the average MAPE value approximately four times smaller and higher reliability with a standard deviation approximately 3.5 times smaller than the exponential function model. This model can be further refined to predict torque for drilling deep holes for future studies.},
  archive      = {J_AAI},
  author       = {Ngoc Hung- Chu and Hoai Nam- Nguyen and Van Du- Nguyen and Dang Binh- Nguyen},
  doi          = {10.1080/08839514.2025.2459482},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2459482},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Torque prediction in deep hole drilling: Artificial neural networks versus nonlinear regression model},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spectrogram features-based automatic speaker identification for smart services. <em>AAI</em>, <em>39</em>(1), Article: 2459476. (<a href='https://doi.org/10.1080/08839514.2025.2459476'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic speaker identification (ASI) is an exciting area of research with numerous applications such as surveillance, voice authentication, identity verification, and electronic voice eavesdropping. This study investigates ASI based on features derived from spectrogram images through a convolution neural network (CNN) with rectangular-shaped kernels. Traditionally, CNN employs square-shaped kernel and max-pooling operations at different layers, a design optimized to handle 2D data. Nevertheless, encoding of information differs slightly to deal with spectrograms. The frequency is displayed along the y-axis, and the x-axis presents the time of the audio. Amplitude is denoted by intensity within the spectrogram image at certain point. The main contributions of this study are 1: To analyze audio signals effectively using spectrograms, this study proposed the utilization of spectrogram features with different sizes and shapes of rectangular kernels to derive distinctive features by improving the recognition accuracy of the speaker identification system. 2. The extracted spectrogram-based features and models are evaluated on the ELSDSR, TSP, and LibriSpeech datasets and achieved the weighted accuracy of 96.0%, 99.2%, and 97.6%, respectively. 3. The proposed rectangular-shaped CNN approach effectively derives suitable features from spectrogram images and outperformed several baseline techniques when performance was assessed on ELSDSR, TSP, and LibriSpeech datasets.},
  archive      = {J_AAI},
  author       = {Rashid Jahangir and Mohammed Alreshoodi and Fawaz Khaled Alarfaj},
  doi          = {10.1080/08839514.2025.2459476},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2459476},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Spectrogram features-based automatic speaker identification for smart services},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ergonomic road sign evaluation and multi-criteria sorting based on q-rung orthopair fuzzy information embedded in CRITIC and TOPSIS-sort. <em>AAI</em>, <em>39</em>(1), Article: 2459470. (<a href='https://doi.org/10.1080/08839514.2025.2459470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a novel multi-criteria sorting approach for evaluating the compliance of road signs based on ergonomic principles and sign comprehension using an integrated Criteria Importance Through Intercriteria Correlation (CRITIC) and Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) sorting (TOPSIS-Sort) under an environment that handles uncertainty via q -rung orthopair fuzzy sets ( q -ROFS). The q -ROF-CRITIC assigns the priority weights of the attributes (i.e. comprehension and ergonomic principles), whereas the q -ROF-TOPSIS-Sort evaluates and classifies the compliance levels of road signs in view of a set of pre-defined categories, consequently bridging the limitations of the TOPSIS-Sort in handling imprecise evaluations. Demonstrated in an actual case study of evaluating 83 road signs in the Philippines, results show that prohibitive signs have the highest comprehension levels, while parking and stop signs, together with road obstacle signs, belong to the medium compliance level. Low-level compliance is observed for supplementary and intersection road signs due to unfamiliarity, while horizontal signs are ergonomically low on spatial and physical attributes. The proposed approach is supported by sensitivity analysis of q values and comparative assessments with other methods. The findings encourage further investigation into comprehensibility evaluations and open avenues for exploring the factors that influence road sign comprehension.},
  archive      = {J_AAI},
  author       = {Maria Gemel Palconit and Dyonne Bernadine Mirasol and Dyanne Brendalyn Mirasol-Cavero and Ferdinand Batayola and Hana Astrid Canseco-Tuñacao and Charldy Wenceslao and Nadine May Atibing and Lanndon Ocampo},
  doi          = {10.1080/08839514.2025.2459470},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2459470},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Ergonomic road sign evaluation and multi-criteria sorting based on q-rung orthopair fuzzy information embedded in CRITIC and TOPSIS-sort},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel RNN architecture to improve the precision of ship trajectory predictions. <em>AAI</em>, <em>39</em>(1), Article: 2459465. (<a href='https://doi.org/10.1080/08839514.2025.2459465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring maritime transport activities is crucial for ensuring the security and safety of people and goods. This type of monitoring often relies on the use of navigation systems such as the Automatic Identification System (AIS). AIS data has been used to support the defense teams when identifying equipment defects, locating suspicious activity, ensuring ship collision avoidance, and detecting hazardous events. In this context, Ship Trajectory Prediction (STP) has been conducted using AIS data to support the estimation of vessel routes and locations, contributing to maritime safety and situational awareness. Currently, the Ornstein-Uhlenbeck (OU) model is considered the state-of-the-art for STP. However, this model can be time-consuming and can only represent a single vessel track. To solve these challenges, Recurrent Neural Network (RNN) models have been applied to STP to allow scalability for large data sets and to capture larger regions or anomalous vessels behavior. This research proposes a new RNN architecture that decreases the prediction error up to 50% for cargo vessels when compared to the OU model. Results also confirm that the proposed Decimal Preservation layer can benefit other RNN architectures developed in the literature by reducing their prediction errors for complex data sets.},
  archive      = {J_AAI},
  author       = {Martha Dais Ferreira and Jessica N. A. Campbell},
  doi          = {10.1080/08839514.2025.2459465},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2459465},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A novel RNN architecture to improve the precision of ship trajectory predictions},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trust-based consensus and ABAC for blockchain using deep learning to secure internet of things. <em>AAI</em>, <em>39</em>(1), Article: 2459461. (<a href='https://doi.org/10.1080/08839514.2025.2459461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid increase in Internet of Things (IoT) applications has exposed critical security vulnerabilities, particularly concerning user privacy and identity forgery. To address these concerns, Blockchain technology offers a promising solution by providing strong security and ensuring data integrity through its transparent ledger system. By leveraging blockchain, IoT systems can enhance their security protocols, making it more difficult for attackers to exploit vulnerabilities and access sensitive data. We proposed Attribute-Based Access Control (ABAC) integrated with trust-based delegated consensus blockchain (TDCB) technology. The ABAC scheme employs Fully Homomorphic Encryption (FHE) processes to encrypt attributes and access regulations, enabling analytical operations directly on encrypted data. Dueling Double Deep Q-Networks with Prioritized Experience Replay (D3P) with Deep Reinforcement Learning (DRL) collaborate with Multiple blockchain nodes to decode the ABAC system’s data and optimize the performances of the blockchain. Our proposed scheme ABAC-TDBC-D3P enhances throughput and security and reduces total computing costs. The simulation results demonstrate that the suggested ABAC-TDCB-D3P scheme has a percentage of 86% for Collusive Rumour Attack (CRA) and 91% for Naive Malicious Attack (NMA). Significant improvements in blockchain security, particularly in mitigating the impact of malicious nodes, were compared to previous schemes.},
  archive      = {J_AAI},
  author       = {Arunkumar Muniswamy and R. Rathi},
  doi          = {10.1080/08839514.2025.2459461},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2459461},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Trust-based consensus and ABAC for blockchain using deep learning to secure internet of things},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PegasosQSVM: A quantum machine learning approach for accurate fake news detection. <em>AAI</em>, <em>39</em>(1), Article: 2457207. (<a href='https://doi.org/10.1080/08839514.2025.2457207'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid spread of fake news on social media poses a significant threat to modern societies. Traditional machine learning approaches have limitations in handling the ever-increasing volume and complexity of data. This research explores quantum machine learning for fake news classification by proposing Pegasos Quantum Support Vector Machines, a novel algorithm combining Pegasos Support Vector Machines with quantum kernels, and advanced data encoding. Through experimentation on the IBM Qasm Simulator, Pegasos Quantum Support Vector Machines scored 90.67% in accuracy. This study is primarily focused on local simulation, where the proposed algorithm scored as high as 95.63%, with 95.44% precision, 99.52% recall, and 96.76% f1-score. The achieved results outperform other machine learning methods on the BUZZFEED dataset, including Quantum Neural Networks and Quantum K-Nearest Neighbors. Its successful implementation paves the way for further refinement of quantum machine learning techniques in fake news classification. The PegasosQSVM algorithm encounters, however, some implementation issues on real world Quantum Processing Units(QPU). Noisy Intermediate-Scale Quantum era QPU are prone to noise effects that affect the computations negatively, and by extension, the results of quantum machine learning algorithms. Further implementation on real QPU and use of error mitigation techniques, are needed for optimal results on quantum hardware.},
  archive      = {J_AAI},
  author       = {Mehdi Khalil and Chi Zhang and Zhiwei Ye and Peng Zhang},
  doi          = {10.1080/08839514.2025.2457207},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2457207},
  shortjournal = {Appl. Artif. Intell.},
  title        = {PegasosQSVM: A quantum machine learning approach for accurate fake news detection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence in design process: An analysis using text mining. <em>AAI</em>, <em>39</em>(1), Article: 2453782. (<a href='https://doi.org/10.1080/08839514.2025.2453782'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The progress of Artificial Intelligence (AI) offers modern designers opportunities to explore innovative design processes. Particularly, generative AI that creates images and other content through text can contribute to the creative processes in various design fields such as graphics, industrial design, UX, and fashion. However, there is a lack of comprehensive research on AI’s role and applications throughout the entire design process, and current papers often employ qualitative methods such as interviews and case studies. Therefore, this paper aims to quantitatively analyze experts’ views on AI’s utilization in the whole design process through text mining of literature. The researchers selected 126 papers through scientific databases such as ScienceDirect, Web of Science, and utilized the keyword matching method to extract the frequency of keywords for each stage of the design process – Research, Ideation, Mock-up, Production, and Evaluation. Through text mining, research findings indicate that AI is predominantly discussed in the later stages of design, particularly in the production process, while its use in the mock-up stage is perceived to be low. Additionally, distinct differences in AI use across design disciplines were identified: graphics focusing on ideation; UX on evaluation; and fashion on production.},
  archive      = {J_AAI},
  author       = {Younjung Hwang and Seokjun Jeong and Yi Wu},
  doi          = {10.1080/08839514.2025.2453782},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2453782},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Artificial intelligence in design process: An analysis using text mining},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From baseline to best practice: An advanced feature selection, feature resampling and grid search techniques to improve injury severity prediction. <em>AAI</em>, <em>39</em>(1), Article: 2452675. (<a href='https://doi.org/10.1080/08839514.2025.2452675'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses the need for precise prediction models that predict the severity of injuries sustained in traffic crashes as a regression task. To this end, we thoroughly analyzed traffic crashes in Rome between 2016 and 2019, gathering data on vehicle attributes and environmental factors. Fourth predictive systems are employed to investigate the intricate problem of predicting the severity of injuries sustained in traffic crashes using different regression algorithms, such as Random Forest, Decision Trees, XGBoost, and Artificial Neural Networks. Compared to comparable systems without feature selection, feature resampling, and optimization methods, the results demonstrate that employing optimized XGBoost along with grid search in conjunction with SelectKBest and SMOTE strategy has resulted in greater performance, with an 89% R2 score. Our findings provide insight into the requirement for accurate forecasting models in optimization and balanced approaches to enhancing traffic safety. These findings offer a viable way to improve traffic safety tactics. As far as we know and as of right now, there hasn’t been much interest in supporting a fusion-based system that critically reviews machine learning techniques using grid search optimization, feature selection, and smote technique and examines how injury severity prediction is affected by road crashes.},
  archive      = {J_AAI},
  author       = {Soukaina EL Ferouali and Zouhair Elamrani Abou Elassad and Sara Qassimi and Abdelmounaîm Abdali},
  doi          = {10.1080/08839514.2025.2452675},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2452675},
  shortjournal = {Appl. Artif. Intell.},
  title        = {From baseline to best practice: An advanced feature selection, feature resampling and grid search techniques to improve injury severity prediction},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalised affective classification through enhanced EEG signal analysis. <em>AAI</em>, <em>39</em>(1), Article: 2450568. (<a href='https://doi.org/10.1080/08839514.2025.2450568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AAI},
  author       = {Joseph Barrowclough and Nonso Nnamoko and Ioannis Korkontzelos},
  doi          = {10.1080/08839514.2025.2450568},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2450568},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Personalised affective classification through enhanced EEG signal analysis},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Encrypted search method for cloud computing data under attack based on TF-IDF and apriori algorithm. <em>AAI</em>, <em>39</em>(1), Article: 2449303. (<a href='https://doi.org/10.1080/08839514.2024.2449303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper designs the MKSE and SEMSS methods. Among them, MKSE uses an improved TF-IDF weight calculation method to extract keywords and applies virtual keywords to construct inverted indexes, making it difficult for malicious attackers to infer the index content easily. SEMSS uses the Apriori algorithm to mine the co-occurrence relationship between words and find the keyword set that meets the minimum support threshold to improve the recall rate of search results. Finally, the security of the scheme is verified from the aspects of semantic security, effici this paper designsency, data integrity, etc. The results showed that the data encryption time of MKSE and TRSE methods increased gradually with the increase in document collection storage. The index build time was increased as the document set grew. The accuracy of the improved TF-IDF method was 63.8%. The running time of Apriori decreased with the increase of minimum support. When the minimum support was 12.0%, the Apriori algorithm ran for 211 seconds. The MKSE method was more efficient than the TRSE method in searching documents by query keywords. When the document set size was 3000, the SEMSS method had a full search rate of 81.09%. This research realizes the semantic security of outsourced data, which can efficiently and comprehensively carry out cryptographic retrieval based on keyword sorting.},
  archive      = {J_AAI},
  author       = {Demei Mao and Mingzhu Wang},
  doi          = {10.1080/08839514.2024.2449303},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2449303},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Encrypted search method for cloud computing data under attack based on TF-IDF and apriori algorithm},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discrete wavelet transform sampling for image super resolution. <em>AAI</em>, <em>39</em>(1), Article: 2449296. (<a href='https://doi.org/10.1080/08839514.2024.2449296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In battlefield environments, drones depend on high-resolution imagery for critical tasks such as target identification and situational awareness. However, acquiring clear images of distant targets presents a significant challenge. To address this, we propose a supervised learning approach for image super-resolution. Our network architecture builds upon the U-Net framework, incorporating enhancements to the encoder and decoder through techniques such as Discrete Wavelet Transform, Channel Attention Residual Modules, Selective Kernel Feature Fusion, Weight Normalization, and Dropout. We evaluate our model on a super-resolution dataset and compare its performance against other networks, highlighting the importance of minimizing trainable parameters for real-time deployment on resource-constrained drone platforms. The effWicacy of our proposed network is further validated through image recognition tasks and real-world scenario testing. By enhancing image clarity at extended ranges, our approach enables drones to detect adversaries earlier, facilitating proactive countermeasures and improving mission success rates},
  archive      = {J_AAI},
  author       = {Chieh-Li Chen and Heng-Lin Yao and Bo-Lin Jian},
  doi          = {10.1080/08839514.2024.2449296},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2449296},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Discrete wavelet transform sampling for image super resolution},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A blockchain-integrated federated learning approach for secure data sharing and privacy protection in multi-device communication. <em>AAI</em>, <em>39</em>(1), Article: 2442770. (<a href='https://doi.org/10.1080/08839514.2024.2442770'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The secure transmission of communication data between different devices still faces numerous potential challenges, such as data tampering, data integrity, network attacks, and the risks of information leakage or forgery. This approach aims to handle the distributed trust issues of federated learning users and update data states rapidly. By modeling multi-source devices through federated learning, the model parameters and reputation values of participating devices are stored on the blockchain. This method incorporates factors such as experience, familiarity, and timeliness to more quickly gather reliable information about nodes to assess their behavior. Simulation results on the MNIST dataset show that when the proportion of selfish nodes is below 50%, the convergence time increases with the proportion of selfish nodes. Compared to advanced algorithms, the proposed model saves approximately 6% of interaction time. As the number of transactions significantly increases, the system’s TPS (Transactions Per Second) decreases, with an average TPS of only 3079.35 when the maximum number of transactions is 4000. The proposed scheme can filter out high-quality data sources during real-time dynamic data exchange, enhancing the accuracy of federated learning training and ensuring privacy security.},
  archive      = {J_AAI},
  author       = {Kejun Li},
  doi          = {10.1080/08839514.2024.2442770},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2442770},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A blockchain-integrated federated learning approach for secure data sharing and privacy protection in multi-device communication},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fractal neural network approach for analyzing satellite images. <em>AAI</em>, <em>39</em>(1), Article: 2440839. (<a href='https://doi.org/10.1080/08839514.2024.2440839'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Satellites play a critical role in modern technology by providing images for various applications, such as detecting infrastructure and assessing environmental impacts. The author’s work investigates the application of Fractal Neural Networks (FractalNet) for automating the detection of specific objects in satellite images. The study aims to improve processing speed and accuracy compared to traditional Convolutional Neural Networks (CNNs). The research involves developing and comparing FractalNet with CNNs, focusing on their effectiveness in image classification. The architecture of FractalNet, characterized by recursive structures and deep layers, is evaluated against CNNs like VGG16 and ResNet50. Data collection included manually gathering high-resolution satellite images of specific objects from Google Earth. The neural network models were trained and tested with varying hyperparameters, including learning rates and batch sizes. FractalNet demonstrated superior performance over CNNs, particularly in deep network configurations. The results improved significantly with data augmentation and optimized hyperparameters, achieving a test accuracy of up to 93.26% with a 32-layer model. Fractal neural networks offer a promising approach for automating satellite image analysis, providing better accuracy and robustness compared to traditional CNNs architectures.},
  archive      = {J_AAI},
  author       = {Volodymyr Shymanskyi and Oleh Ratinskiy and Nataliya Shakhovska},
  doi          = {10.1080/08839514.2024.2440839},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2440839},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Fractal neural network approach for analyzing satellite images},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image segmentation deep learning model for early detection of banana diseases. <em>AAI</em>, <em>39</em>(1), Article: 2440837. (<a href='https://doi.org/10.1080/08839514.2024.2440837'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bananas are among the most widely produced perennial fruits and staple food crops that are highly affected by numerous diseases. When not managed early, Fusarium Wilt and Black Sigatoka are two of the most detrimental banana diseases in East Africa, resulting in production losses of 30% to 100%. Early detection of these banana diseases is necessary for designing proper management practices to avoid further yields and financial losses. The recent advances and successes of deep learning in detecting plant diseases have inspired this study. This study assessed a U-Net semantic segmentation deep learning model for the early detection and segmentation of Fusarium Wilt and Black Sigatoka banana diseases. This model was trained using 18,240 banana leaf and stalk images affected by these two banana diseases. The dataset was collected from the farms using mobile phone cameras with the guidance of agricultural experts and was annotated to label the images. The results showed that the U-Net model achieved a Dice Coefficient of 96.45% and an Intersection over Union (IoU) of 93.23%. The model accurately segmented areas where the banana leaves and stalks were damaged by Fusarium Wilt and Black Sigatoka diseases.},
  archive      = {J_AAI},
  author       = {Christian A. Elinisa and Ciira Wa Maina and Anthony Vodacek and Neema Mduma},
  doi          = {10.1080/08839514.2024.2440837},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2440837},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Image segmentation deep learning model for early detection of banana diseases},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application of immunological and swarm intelligence learning-based algorithm for industrial grade computer sales prediction. <em>AAI</em>, <em>39</em>(1), Article: 2440836. (<a href='https://doi.org/10.1080/08839514.2024.2440836'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper strives to raise the imitating effectiveness of radial basis function-based neural network (RNNet) through biological learning (BL) and swarm intelligence (SI) optimization algorithms. Latter, the artificial immune system (AIS) and particle swarm optimization (PSO) algorithms are utilized for RNNet to regulate. The proposed synthesis of AIS-inspired and PSO-inspired (SAIPS) algorithm incorporates the complementary development and prospecting abilities to realize optimized resolution. The attribute of population variation has shown high frequency to meet the global optimum to replace local optimum being restricted and outperforms in five standard nonlinear trial functions. The experimental results have represented that the consolidation of AIS-inspired and PSO-inspired algorithms is an outstanding approach and therefore a hybrid algorithm is proposed, which aims to obtain an expression that can cultivate optimum precision among related algorithms in this research. The algorithm then evaluates results from five standard inspections and an empirical industrial grade computer (IgC) sales prediction instance in Taiwan, which reveals that the proposed SAIPS algorithm exceeds the performance among related algorithms as well as the relevant auto-regressive integrated moving average (ARIMA) models in terms of accuracy and time spent.},
  archive      = {J_AAI},
  author       = {Zhen-Yao Chen},
  doi          = {10.1080/08839514.2024.2440836},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2440836},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Application of immunological and swarm intelligence learning-based algorithm for industrial grade computer sales prediction},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). System logs anomaly detection. are we on the right path?. <em>AAI</em>, <em>39</em>(1), Article: 2440692. (<a href='https://doi.org/10.1080/08839514.2024.2440692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {System logs are universally used for monitoring user access, performance, and behavior in software applications. Large-scale industrial systems generate an immense volume of logs, which are difficult to handle with human capabilities. Therefore, an automated method is essential for filtering vast amounts of data. System log anomaly detection is crucial in the security field for identifying system failures, sophisticated internal attacks, and other deviations from the norm. This research area requires further development, as most Deep Learning solutions in the literature are semi-supervised. This poses a significant limitation since these solutions are impractical for large-scale ecosystems due to the high cost of labeling data. This paper introduces a method that replaces the supervised phase of semi-supervised methods with fully unsupervised heuristics, utilizing the elbow method, interquartile range, and Simulated Annealing. The unsupervised results are comparable to the semi-supervised State of the Art while demonstrating greater applicability in real-world applications. This work proposes a more suitable benchmark for the log anomaly outlier detection problem, where the training data include both normal and abnormal sequences and precede the test sessions in time. Additionally, it presents metrics on distinct log sequences to mitigate the impact of unbalanced anomaly types.},
  archive      = {J_AAI},
  author       = {Ramona-Georgiana Albert},
  doi          = {10.1080/08839514.2024.2440692},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2440692},
  shortjournal = {Appl. Artif. Intell.},
  title        = {System logs anomaly detection. are we on the right path?},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating LLMs for code generation in HRI: A comparative study of ChatGPT, gemini, and claude. <em>AAI</em>, <em>39</em>(1), Article: 2439610. (<a href='https://doi.org/10.1080/08839514.2024.2439610'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the effectiveness of Large Language Models (LLMs) in generating code for Human-Robot Interaction (HRI) applications. We present the first direct comparison of ChatGPT 3.5, Gemini 1.5 Pro, and Claude 3.5 Sonnet in the specific context of generating code for Human-Robot Interaction applications. Through a series of 20 carefully designed prompts, ranging from simple movement commands to complex object manipulation scenarios, we evaluate the models’ ability to generate accurate and context-aware code. Our findings reveal significant variations in performance, with Claude 3.5 Sonnet achieving a 95% success rate, Gemini 1.5 Pro at 60%, and ChatGPT 3.5 at 20%. The study highlights the rapid advancement in LLM capabilities for specialized programming tasks while also identifying persistent challenges in spatial reasoning and adherence to specific constraints. These results suggest promising applications for LLMs in robotics development and education while emphasizing the continued need for human oversight and specialized training in AI-assisted programming for HRI.},
  archive      = {J_AAI},
  author       = {Andrei Sobo and Awes Mubarak and Almas Baimagambetov and Nikolaos Polatidis},
  doi          = {10.1080/08839514.2024.2439610},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2439610},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Evaluating LLMs for code generation in HRI: A comparative study of ChatGPT, gemini, and claude},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Friend link prediction method based on heterogeneous multigraph and hierarchical attention. <em>AAI</em>, <em>39</em>(1), Article: 2427545. (<a href='https://doi.org/10.1080/08839514.2024.2427545'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of location-based social network (LBSN), rich data comprising social behaviors and location information among users has emerged. Predicting potential friendships accurately from abundant information has become a pivotal research area. While graph neural network (GNN) have shown significant promise in prediction, existing approaches often fail to fully exploit the heterogeneous data characteristics in LBSN. Key challenges include inadequate modeling of the intricate relationships between users and points of interest (POI), overlooking the significance of spatial-temporal information in user trajectories, and underutilizing rich edge features. To address these challenges, we design a novel GRU-enhanced Heterogeneous Multigraph Attention Network (GEHMAN), which is a GNN model enhanced by GRU. We construct a heterogeneous multigraph to comprehensively capture user-POI relationships. We then employ a skip-gram model to embed POI nodes from user sub-trajectories and use RNN with GRU units to embed user nodes. GEHMAN utilize hierarchical attention mechanism to consolidate node information by aggregating diverse types of neighboring nodes and connecting edges. Experiments on six real city datasets show that compared with the best performance of six benchmark methods including LBSN2vec++, Metapath2vec and HAN, the average improvement percentages of GEHMAN in AUC, AP, and Top@K are 2.225%, 1.948%, and 6.353%, respectively.},
  archive      = {J_AAI},
  author       = {Aoxue Liu and Boyu Li and Yong Wang and Ziteng Yang},
  doi          = {10.1080/08839514.2024.2427545},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2427545},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Friend link prediction method based on heterogeneous multigraph and hierarchical attention},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="csci">CSCI - 34</h2>
<ul>
<li><details>
<summary>
(2025). Hybrid CNN XGBoost intrusion detection approach tuned by modified sine cosine algorithm towards better cloud security. <em>CSCI</em>, <em>37</em>(1), Article: 2549581. (<a href='https://doi.org/10.1080/09540091.2025.2549581'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing (CC) delivers processing power and data storage on demand. It is one of the most significant computer science technologies, contributing to healthcare, industry, and the Internet of Things. One of CC's biggest security concerns are intrusion detection and separating harmful from legitimate communication, similar to computer networks. Although a wide range of intrusion detection systems is available today, they often suffer from misclassification issues, where the system can fail to recognize an attack as a threat or to mark normal traffic as malicious. This research proposes classifying network traffic using a convolutional neural network and extreme gradient boosting model. Additionally, a modified sine cosine algorithm is used to tune model hyperparameters for optimal performance. The presented framework was tested on major real-world TON IoT intrusion detection datasets. The proposed optimizer is compared to many recent metaheuristics in a matched experimental setting. The simulation results show that the suggested technique is superior to other methods for both datasets, with the best-performing optimized models achieving an accuracy of 96.667 on Windows 10 and 98.6731 on Windows 7 simulation.},
  archive      = {J_CSCI},
  author       = {Nikola Savanovic and Aleksandra Bozovic and Milos Antonijevic and Goran Kvascev and Bosko Nikolic and K. Venkatachalam and Nebojsa Bacanin and Miodrag Zivkovic},
  doi          = {10.1080/09540091.2025.2549581},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2549581},
  shortjournal = {Connect. Sci.},
  title        = {Hybrid CNN XGBoost intrusion detection approach tuned by modified sine cosine algorithm towards better cloud security},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A homotopy-CNN framework for continuous deformation in low-light image enhancement. <em>CSCI</em>, <em>37</em>(1), Article: 2546911. (<a href='https://doi.org/10.1080/09540091.2025.2546911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a homotopy-guided image enhancement framework for Low-Light Image Enhancement (LLIE), where a low-light image is progressively transformed into a well-lit version using a parametric deformation model. The enhancement pipeline incorporates a convolutional neural network that predicts structure-aware filtering parameters, which are applied via a 12-directional convolution kernel fusion, followed by adaptive gamma, contrast, and saturation refinements. Instead of relying solely on reference-free or black-box learning, the model leverages perceptual quality metrics such as SSIM and PSNR during training to optimise enhancement along the homotopy path. Notably, we explore the modulation of brightness across the range b ∈ [ − 2.0 , 2.0 ] , observing that b ≤ 0 yields outputs closer to ground-truth references, while b ≥ 0 enhances perceptual vividness. Experiments on the LOL dataset show that the method produces superior visual quality and strong quantitative performance, all while remaining efficient on standard CPUs without the need for GPU acceleration.},
  archive      = {J_CSCI},
  author       = {S. Shivam Kumar Jha and N. Mohana},
  doi          = {10.1080/09540091.2025.2546911},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2546911},
  shortjournal = {Connect. Sci.},
  title        = {A homotopy-CNN framework for continuous deformation in low-light image enhancement},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-constraints active learning assisted deep-ensemble spatio-textural feature learning model for violence detection in surveillance dataset. <em>CSCI</em>, <em>37</em>(1), Article: 2544539. (<a href='https://doi.org/10.1080/09540091.2025.2544539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents Vi-mCALNET, a multi-constraint active learning-assisted deep-ensemble spatio-textural feature learning model for violence detection in surveillance videos. Unlike traditional approaches, Vi-mCALNET integrates active learning-driven frame selection with deep ensemble learning to enhance classification accuracy while reducing computational complexity. Traditional deep learning vision models for violent crime detection face limitations including inability to use contextual details, long-term dependency issues, gradient vanishing, and accuracy degradation. Vi-mCALNET addresses these challenges through a comprehensive approach. The model employs GLCM, ResNet101, and DenseNet121 for feature extraction, followed by a heterogeneous ensemble classifier comprising SVM, DT, k-NN, NB, and RF. Extracted features are fused into a composite feature vector, processed through PCA and z-score normalization to prevent local minima, convergence issues, and overfitting.The heterogeneous ensemble classifier uses maximum voting to classify videos as violent or non-violent. Vi-mCALNET achieved superior performance with 99.51% accuracy, 99.32% precision, 99.36% recall, and 0.994 F-measure on publicly available datasets.Ablation studies and statistical significance analysis confirmed Vi-mCALNET's robust performance with lower variance, making it suitable for real-time, scalable surveillance applications while reducing annotation costs and computational demands.},
  archive      = {J_CSCI},
  author       = {Duba Sriveni and Loganathan R},
  doi          = {10.1080/09540091.2025.2544539},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2544539},
  shortjournal = {Connect. Sci.},
  title        = {Multi-constraints active learning assisted deep-ensemble spatio-textural feature learning model for violence detection in surveillance dataset},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An experimental evaluation of deep learning-based models for acne severity classification in humans. <em>CSCI</em>, <em>37</em>(1), Article: 2533867. (<a href='https://doi.org/10.1080/09540091.2025.2533867'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the context of acne severity, this paper presents a novel comparison between three convolutional neural network models: SqueezeNet, CenterNet and VGG-16 for the evaluation of acne severity on a custom-annotated dataset through Hayashi Grading Criterion. Unlike previous works, which mainly focus on single-model performance, this paper systematically presents the classification abilities of these three distinct architectures. The models were compared against real labels by the predictions for every group of images used in training that have been graded 0 through 3 in terms of acne severity. According to the results, CenterNet has the highest accuracy of 79.45%, followed by VGG-16 with 78.08% and then SqueezeNet having 76.71%. These findings add to the literature on AI models in acne classification and suggest that CenterNet is the most accurate model which can be incorporated into clinical practice for the management of acne vulgaris. The ACNE04 dataset contains both local lesion number and global acne severity have been utilised to assess the effectiveness of acne classification of the listed deep learning models.},
  archive      = {J_CSCI},
  author       = {Ayesha Shaik and Jincy Jis Kanichai and Aleena Bosco Kurumthottam and Vidul Garg and Balasundaram Ananthakrishnan},
  doi          = {10.1080/09540091.2025.2533867},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2533867},
  shortjournal = {Connect. Sci.},
  title        = {An experimental evaluation of deep learning-based models for acne severity classification in humans},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel architecture for efficient pedestrian detection in autonomous vehicles. <em>CSCI</em>, <em>37</em>(1), Article: 2529261. (<a href='https://doi.org/10.1080/09540091.2025.2529261'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public safety and intelligent surveillance systems rely heavily on accurate pedestrian detection to ensure effective monitoring and response. However, real-world challenges such as complex backgrounds, occlusions, and small target sizes significantly impact detection performance. To address these issues, this study proposes YOLO-SPD, an optimised YOLOv8-based architecture specifically designed for pedestrian detection. The model enhances multi-scale feature fusion by integrating a Bi-directional Feature Pyramid Network (BiFPN) in the neck structure, reducing computational complexity while preserving fine-grained details. Additionally, the Coordinate Attention (CA) mechanism is embedded within the Spatial Pyramid Pooling Fast (SPPF) module to improve localisation by effectively capturing both local and global spatial dependencies. Furthermore, pedestrian-specific bounding box regression is refined using the Complete Intersection over Union (CIoU) loss function, ensuring precise localisation and better edge positioning. The proposed approach is evaluated on the Caltech Pedestrian and KITTI datasets. Extensive experiments demonstrate its effectiveness, achieving 97.85% precision on the KITTI dataset and 96.18% precision on the Caltech Pedestrian dataset. These results highlight the robustness and reliability of YOLO-SPD in detecting pedestrians across diverse environments, making it a promising solution for real-time autonomous driving and intelligent surveillance applications.},
  archive      = {J_CSCI},
  author       = {Wajdi Farhat and Olfa Ben Rhaiem and Hassene Faiedh and Chokri Souani},
  doi          = {10.1080/09540091.2025.2529261},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2529261},
  shortjournal = {Connect. Sci.},
  title        = {A novel architecture for efficient pedestrian detection in autonomous vehicles},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SMARDY: The CORE of zero-trust FAIR marketplace for research data. <em>CSCI</em>, <em>37</em>(1), Article: 2523965. (<a href='https://doi.org/10.1080/09540091.2025.2523965'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supporting discovery through good and open management of existing datasets is the core of progress in data-rich research environments. Open Data and FAIR (Findable, Accessible, Interoperable, and Reusable) principles drive the exploitation of current results to a better and more trustworthy scientific era, but the wide adoption in Science is hindered by concerns regarding the proper handling of sensitive or extra-valuable copyrighted datasets. We present Smardy, our proposal for extending Open Data Repositories for research datasets with components meant to protect data sovereignty and trust in transfer. Our implementation of a cross-platform is the core of a FAIR Dataset Marketplace, which allows the authors to trade their datasets with the unconditional security of a Zero-Trust environment, and helps them to protect their IP over data using undisputable, Blockchain-based proofs of their authorship. The depicted aspects include application-code design, functional schemes, fingerprinting, and encryption steps for properly handling datasets and generating authorship proofs.},
  archive      = {J_CSCI},
  author       = {Cosmin-Andrei Ioniţe and Ion-Dorinel Filip and Alba González–Cebrián and Ciprian Dobre},
  doi          = {10.1080/09540091.2025.2523965},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2523965},
  shortjournal = {Connect. Sci.},
  title        = {SMARDY: The CORE of zero-trust FAIR marketplace for research data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differential privacy in statistical queries for synthetic trajectories generated by generative adversarial networks. <em>CSCI</em>, <em>37</em>(1), Article: 2523964. (<a href='https://doi.org/10.1080/09540091.2025.2523964'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread adoption of smartphones and the rapid advancement of information and communication technologies, the use of Location-Based Services (LBS) has significantly increased across various domains. Consequently, the collection and utilisation of user trajectory data are also growing rapidly. While such data can provide valuable insights for personalised services and other analyses, it inherently contains sensitive location information, posing serious privacy risks if used without proper anonymization. Previous studies have attempted to mitigate privacy concerns by applying Differential Privacy (DP) to prefix tree structures for statistical analysis. However, these approaches often suffer from diminished data utility due to the excessive noise required by DP mechanisms. To address this issue, we propose a two-stage trajectory privacy framework. In the first stage, we employ a Category Auxiliary Classifier-Generative Adversarial Network (CAC-GAN) to generate synthetic trajectory data that preserves the statistical characteristics of the original data, thereby providing primary privacy protection. In the second stage, we apply a prefix tree-based DP algorithm to the synthetic data, offering enhanced privacy during statistical analysis and query processing. Experimental results demonstrate that the proposed CAC-GAN method achieves approximately 53% improvement in both data utility and anonymity compared to existing methods. Furthermore, relative error analysis across various ϵ values confirms that our two-stage protection scheme maintains superior statistical accuracy. This study presents a novel methodology that effectively balances trajectory data privacy and utility.},
  archive      = {J_CSCI},
  author       = {Jihwan Shin and Yeji Song and Minsoo Jang and Jinhyun Ahn and Taewhi Lee and Dong-Hyuk Im},
  doi          = {10.1080/09540091.2025.2523964},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2523964},
  shortjournal = {Connect. Sci.},
  title        = {Differential privacy in statistical queries for synthetic trajectories generated by generative adversarial networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ReinforceAdapt: Multi-objective approach for environmental adaptation method. <em>CSCI</em>, <em>37</em>(1), Article: 2523960. (<a href='https://doi.org/10.1080/09540091.2025.2523960'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective optimization (MOO) underpins numerous real-world applications requiring the simultaneous optimization of conflicting objectives. Evolutionary Algorithms (EAs), particularly Multi-Objective Evolutionary Algorithms (MOEAs), have demonstrated exceptional capabilities in approximating Pareto-optimal solutions. However, their reliance on static operator configurations often results in suboptimal performance in dynamic and high-dimensional search spaces. To address this limitation, we propose a novel framework that integrates Deep Reinforcement Learning (DRL) with MOEAs, enabling adaptive and context-aware operator selection. Our methodology formulates operators as actions and solution states within a reinforcement learning paradigm. By leveraging Q -learning, the framework dynamically evaluates and selects operators that balances exploration and exploitation to optimise convergence and diversity. The implementation incorporates modular optimization, adaptive credit assignment, and decomposition-based subproblem partitioning which ensures scalability across diverse problem domains. Experimental evaluations on benchmark suites reveal that the proposed DRL-MOEA framework achieves superior performance, significantly improving Inverted Generational Distance (IGD) metrics while enhancing Pareto front diversity compared to state-of-the-art approaches. The results shows the framework's robustness and adaptability, establishing it as a powerful tool for addressing the challenges of multi-objective optimization in complex and dynamic environments.},
  archive      = {J_CSCI},
  author       = {Ravi Prakash and Brajesh Kumar Umrao and Ranvijay},
  doi          = {10.1080/09540091.2025.2523960},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2523960},
  shortjournal = {Connect. Sci.},
  title        = {ReinforceAdapt: Multi-objective approach for environmental adaptation method},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detection and classification of enhanced periapical lesion images with YOLO algorithms. <em>CSCI</em>, <em>37</em>(1), Article: 2522706. (<a href='https://doi.org/10.1080/09540091.2025.2522706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, artificial intelligence has become a reliable technology in clinical decision support systems with the solutions it offers in the dental field. This success also indicates a significant potential in detecting five different types of lesions on the tooth root through radiographic images. Because the periapical X-ray-taking process may vary depending on the individual's physical, psychological, and mental conditions. Also, environmental parameters may negatively affect the image acquisition process. It is possible to tolerate these disadvantageous situations with artificial intelligence-based algorithms and image processing approaches. In this study, it was planned to in-depth analysis of the periapical lesion data types in the original dataset called Periapical X-rays provided from the Kaggle public database. For this, the original adaptive image processing approach developed by integrating the ABC optimisation algorithm was applied to the dataset for five different lesion types. Then, the enhanced images enriched with the data augmentation approach were trained with YOLOv7, YOLOv8, YOLOv9 and YOLOv10 algorithms. As a result of the training, the enhanced images compared to the original images reached 96% F Criterion thanks to the network architecture of YOLOv8 algorithm. This shows that the YOLOv8 network architecture in enhanced lesion images is more successful.},
  archive      = {J_CSCI},
  author       = {Fatma Akalin and Tuğçenur Yildiz},
  doi          = {10.1080/09540091.2025.2522706},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2522706},
  shortjournal = {Connect. Sci.},
  title        = {Detection and classification of enhanced periapical lesion images with YOLO algorithms},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An NLP-driven e-learning platform with LLMs and graph databases for personalised guidance. <em>CSCI</em>, <em>37</em>(1), Article: 2518991. (<a href='https://doi.org/10.1080/09540091.2025.2518991'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information is ubiquitously available at our fingertips, transforming the way we learn, work and engage with the world around us. The challenge is not just accessing data but discerning its relevance and utility. This constant flow of information demands selective attention and strategic thinking about how we integrate new findings for professional growth. In this context, we propose an e-learning platform that recommends career paths based on user-uploaded PDFs. Our solution extracts keywords with Natural Language Processing (NLP). Using OpenAI, we enable interaction with the PDF files, allowing the user to ask questions and receive summaries. Then, we generate embeddings and index them with Facebook AI Similarity Search (FAISS). Next, we use a dataset of job listings and, with BERT, skills and technologies are extracted. An interconnected graph using a graph database system (Neo4j) based on these skills and technologies is built. Keywords from the uploaded documents are analyzed and matched to skills, leading to job recommendations or guidance on additional skills needed to secure employment. Mean Reciprocal Rank (MRR) is calculated to compare the results of different job recommendation systems.},
  archive      = {J_CSCI},
  author       = {Gabriela Dobriţa and Simona-Vasilica Oprea and Adela Bâra},
  doi          = {10.1080/09540091.2025.2518991},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2518991},
  shortjournal = {Connect. Sci.},
  title        = {An NLP-driven e-learning platform with LLMs and graph databases for personalised guidance},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSLWNet: A dual-stream lightweight deep learning network for the detection of epileptic seizures using EEG signals. <em>CSCI</em>, <em>37</em>(1), Article: 2518985. (<a href='https://doi.org/10.1080/09540091.2025.2518985'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is one of the most prevalent neurological disorders, and the accurate detection of epileptic seizures is challenging. Therefore, a dual-stream deep learning network is proposed in this research to extract the deep features by utilising the scalograms and time-series EEG signals. In this, first, the convolutional neural network (CNN) extracts the spatial dimensional features from the scalogram images, and then the squeeze and excitation (SE) technique enhances the relevant informative features by adjusting the channel weights. Correspondingly, the gated recurrent unit (GRU) extracts the temporal characteristics from the time-series EEG signal, and then for assigning more weights to the significant features the confined attention (CA) mechanism is included. Next, the extracted features are fused to form a deep feature set for the accurate detection of seizures using the support vector machine (SVM) classifier. Further, to improve the seizure detection rate, the regression at the end of variational mode extraction techniques (VME) is employed in the preprocessing stage. In addition, the performance of the proposed dual-stream lightweight seizure network (DSLWNet) is evaluated using the CHB-MIT and Bonn datasets. The experimental outcomes show the superiority of the proposed work in seizure detection by achieving an accuracy of 98.67% and 99.5%, respectively.},
  archive      = {J_CSCI},
  author       = {Bommala Silpa and Malaya Kumar Hota},
  doi          = {10.1080/09540091.2025.2518985},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2518985},
  shortjournal = {Connect. Sci.},
  title        = {DSLWNet: A dual-stream lightweight deep learning network for the detection of epileptic seizures using EEG signals},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LPIF-based image enhancement and hybrid ensemble models for brain tumor detection. <em>CSCI</em>, <em>37</em>(1), Article: 2518983. (<a href='https://doi.org/10.1080/09540091.2025.2518983'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumors represent one of the most critical neurological disorders where early and accurate diagnosis significantly impacts treatment outcomes. This paper presents a comprehensive deep learning framework for automated brain tumor classification using MRI scans, validated across both binary (DS1) and multi-class (DS2) datasets. Our approach introduces three key innovations: (1) a novel Local Pixel Inhomogeneity Factor (LPIF) based preprocessing pipeline that enhances tumor visibility while suppressing noise through adaptive local intensity processing, (2) AugmentFusion – a hybrid data augmentation strategy combining CLAHE with geometric transformations and noise injection to improve model generalisation, and (3) a hybrid ensemble model integrating DenseNet121 and VGG16 through majority voting, optimised using Adaptive Lookahead-AdamW with Cyclic Learning (ALACL). Extensive experiments demonstrate state-of-the-art performance, with our ensemble achieving 99.46% accuracy (AUC: 0.995, F1-score: 0.992) on the DS1 dataset (normal vs. tumor classification) and 98.63% accuracy (AUC: 0.986, F1-score: 0.99) on the more challenging DS2 dataset (multi-class tumor classification). These results significantly outperform existing approaches including transformer-based methods (98.6% accuracy) and 3D CNN architectures (98.4% accuracy). The framework maintains robust performance across all evaluation metrics while demonstrating computational efficiency suitable for clinical deployment. Our solution provides radiologists with a reliable decision support tool that combines high diagnostic accuracy with interpretability, potentially improving early detection and treatment planning for brain tumor patients.},
  archive      = {J_CSCI},
  author       = {Prabhat Kumar Sahu},
  doi          = {10.1080/09540091.2025.2518983},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2518983},
  shortjournal = {Connect. Sci.},
  title        = {LPIF-based image enhancement and hybrid ensemble models for brain tumor detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PSPNet EPO-SEB: A novel attention-enhanced hybrid model for accurate histopathological image segmentation. <em>CSCI</em>, <em>37</em>(1), Article: 2508357. (<a href='https://doi.org/10.1080/09540091.2025.2508357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise histopathological image segmentation is vital for accurate diagnosis and treatment planning. This manuscript proposes a hybrid framework, PSPNet EPO-SEB, combining PSPNet with an emperor penguin optimizer and an attention-enhanced module for improved segmentation performance. The model was rigorously evaluated on two prominent datasets, BACH and Camelyon17, encompassing high-resolution and whole-slide histopathological images, respectively. Experimental results demonstrate that PSPNet EPO-SEB outperforms conventional segmentation models, achieving dice coefficients (DC) of 0.9237 and 0.9186, and intersection over union (IoU) values of 0.8629 and 0.8622 on the BACH and Camelyon17 datasets, respectively. These metrics surpass those of competing models such as U-Net, V-Net, PA-Net, FANet18, Mask R-CNN, R2UNet, with PSPNet EPO-SEB showing enhanced boundary accuracy, True positive rates (TPR) above 0.93, and minimized false positive rates (FPR) at 0.1211 on BACH and 0.1108 on Camelyon17. Furthermore, the proposed model maintains low average error rates (AER) and achieves boundary precision with Hausdorff distances (HD) as low as 12.68 on BACH and 13.04 on Camelyon17, underscoring its accuracy in delineating complex tissue structures. Despite a slight increase in computational time due to optimization and attention mechanisms, the enhanced segmentation precision and boundary adherence make PSPNet EPO-SEB a highly effective solution for complex histopathological image analysis.},
  archive      = {J_CSCI},
  author       = {Prem Purusottam Jena and Debahuti Mishra and Kaberi Das and Sashikala Mishra and Mandakini Priyadarshani Behera},
  doi          = {10.1080/09540091.2025.2508357},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2508357},
  shortjournal = {Connect. Sci.},
  title        = {PSPNet EPO-SEB: A novel attention-enhanced hybrid model for accurate histopathological image segmentation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QIR: A novel quaternion-based image representation for reversible image steganography. <em>CSCI</em>, <em>37</em>(1), Article: 2507830. (<a href='https://doi.org/10.1080/09540091.2025.2507830'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image steganography involves concealing data within a digital image. Reversible steganography is considered as the complete restoration of the original image after the embedded secret data have been extracted. In this research work, a novel quaternion-based image representation technique is proposed for effective representation of images for processing it in quantum computational units. The proposed model is evaluated by implementing the representation of images for reversible image steganography where the images that are represented should be decrypted without loss. The images that were used in this study involve three different sizes 256 × 256 , 512 × 512 , 1024 × 1024 . Here the numerical results of the proposed work shows that the average PSNR value of the original image to the stego image is 44 dB and the average PSNR value to the original image and quantum decrypted image using quaternion function is 74 dB approximately which is 40% greater than the previous quantum representation and the SSIM and MSE values obtained are 95% similar to the previous works. The importance of our contribution is the stego image which is represented using 3-D quaternion rotation undergoes a decryption using LSB–MSB technique which then recovers the original secret and cover image with minimum loss. This shows that the stego image is not affected by the proposed quantum representation.},
  archive      = {J_CSCI},
  author       = {R. Deepika and Kalaipriyan Thirugnanasambandam and K. Muthunagai},
  doi          = {10.1080/09540091.2025.2507830},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2507830},
  shortjournal = {Connect. Sci.},
  title        = {QIR: A novel quaternion-based image representation for reversible image steganography},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparative linguistic analysis framework of human-written vs. machine-generated text. <em>CSCI</em>, <em>37</em>(1), Article: 2507183. (<a href='https://doi.org/10.1080/09540091.2025.2507183'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Writing content with the assistance of artificial intelligence has increased in popularity and influenced every domain, yet the challenge of understanding the differences between machine-generated and human-authored writing remains. To address this issue, our research aims to propose a detailed framework for deciphering the characteristics of machine-written language by identifying distinct linguistic features, analyzing stylistic differences, evaluating sentiment consistency, and validating the performance of selected generative models in replicating human writing across different types of writing. Using free resources from Hugging Face, we selected three models: GPT-Neo 1.3B, Qwen2.5-1.5B-Instruct, and BloomZ-560M, and employed them without fine-tuning in a Google Colab environment using a consistent prompt. These models were used to generate introductions for corresponding human-authored texts. We compared the extracted features of 2,121 texts, using visualisation methods such as histograms, boxplots and Q-Q plots, alongside the Shapiro–Wilk test and the non-parametric Kruskal – Wallis test and Dunn’s post-hoc test. Our findings highlight both the advancements of open-source text-generating models and the persistent gaps in replicating the depth and richness of human writing, providing and contributing to the knowledge about artificial intelligence and its progress in the generative field, supporting the validation of open-source text-generative models through statistical comparisons.},
  archive      = {J_CSCI},
  author       = {Lia Cornelia Culda and Raluca Andreea Nerişanu and Marian Pompiliu Cristescu and Dumitru Alexandru Mara and Adela Bâra and Simona-Vasilica Oprea},
  doi          = {10.1080/09540091.2025.2507183},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2507183},
  shortjournal = {Connect. Sci.},
  title        = {Comparative linguistic analysis framework of human-written vs. machine-generated text},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-stage deep learning based method for diabetic retinopathy classification. <em>CSCI</em>, <em>37</em>(1), Article: 2507182. (<a href='https://doi.org/10.1080/09540091.2025.2507182'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR) is a major cause of blindness, but current classification models suffer from low interpretability and difficulty in adjustment. To address these issues, a two-stage deep learning method for DR classification has been proposed, featuring lesion-sliced detection and DR classification stages. In the lesion-sliced detection stage, an improved neural process model extracts information from fundus images by fusing lesion details from various image locations, significantly enhancing accuracy. In the DR classification stage, an enhanced deep forest model was used to identify critical features influencing DR grades, boosting the credibility of the grading outcomes. Tests on the IDRiD and E-ophtha datasets demonstrated superior performance and generalisation ability of the lesion-sliced detection model compared to mainstream neural networks. Meanwhile, experiments on the Kaggle dataset confirmed that the deep forest-based DR classification model outperformed both traditional forest models and residual networks, marking its first application in DR classification. This approach achieves high accuracy and reliability, with improvements in both detection efficiency and generalisation.},
  archive      = {J_CSCI},
  author       = {Chen Zhang and Shaoqi Dong and Ziyun Song and Liming Liu and Jiaxu Ning and Bin Zhang and Changsheng Zhang},
  doi          = {10.1080/09540091.2025.2507182},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2507182},
  shortjournal = {Connect. Sci.},
  title        = {A two-stage deep learning based method for diabetic retinopathy classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EXING-IoT conceptual framework for explainability integration in next generation-IoT. <em>CSCI</em>, <em>37</em>(1), Article: 2507180. (<a href='https://doi.org/10.1080/09540091.2025.2507180'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) paradigm is evolving and the Next-Generation IoT (NG-IoT) ecosystem will incorporate distributed ledger and blockchain technology, AI-adapted components, and intelligent edge solutions that take advantage of edge computing, Artificial Intelligence (AI), networks, and communications. In addition to the low integration of eXplainable Artificial Intelligence (XAI) in the IoT or NG-IoT contexts, the explainability of these systems is rarely evaluated. Due to these limitations, we thoroughly examined the current state of XAI integration with IoT services. We propose a new conceptual framework called eXING-IoT (eXplainability Integrated in the Next Generation IoT) for better NG-IoT systems' explainability integration and evaluation. This includes a list of qualities that future NG-IoT environments should have, thus paving the way for the advancement of NG-IoT beyond the state of the art.},
  archive      = {J_CSCI},
  author       = {Alexandra Vultureanu-Albişi and Costin Bădică and Mirjana Ivanović},
  doi          = {10.1080/09540091.2025.2507180},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2507180},
  shortjournal = {Connect. Sci.},
  title        = {EXING-IoT conceptual framework for explainability integration in next generation-IoT},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ensuring unbiasedness: Foundational insights into integrating GSTARIMA and DNN models for rainfall prediction. <em>CSCI</em>, <em>37</em>(1), Article: 2507179. (<a href='https://doi.org/10.1080/09540091.2025.2507179'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The GSTARIMA (Generalied Space–Time Autoregressive Integrated Moving Average) model is commonly used to analyse time series and spatial data with temporal and spatial dependencies. This paper focuses on estimating the autoregressive and moving average parameters of the GSTARIMA model using Maximum Likelihood Estimation (MLE). We theoretically demonstrate the unbiasedness of these estimates, proving that the expected values of the estimates match the true parameters. Empirical experiments further verify this property, both before and after applying Deep Neural Network (DNN) interventions to correct model errors. The results show that the parameter estimates remain unbiased, and error properties (zero mean and constant variance) are preserved even after DNN processing. This study highlights the robustness of MLE in providing unbiased estimates within the GSTARIMA framework, even when integrated with machine learning techniques.},
  archive      = {J_CSCI},
  author       = {Devi Munandar and Budi Nurani Ruchjana and Atje Setiawan Abdullah and Hilman Ferdinandus Pardede},
  doi          = {10.1080/09540091.2025.2507179},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2507179},
  shortjournal = {Connect. Sci.},
  title        = {Ensuring unbiasedness: Foundational insights into integrating GSTARIMA and DNN models for rainfall prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning computer vision system for estimating sheep age using teeth images. <em>CSCI</em>, <em>37</em>(1), Article: 2506456. (<a href='https://doi.org/10.1080/09540091.2025.2506456'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the use of deep learning neural networks and transfer learning to estimate the age of sheep from their dental images. This is an important aspect of agriculture for meat quality, animal welfare, breeding, and health management. Using cutting-edge techniques, MobileNet, ResNet50, and ResNet102, we compare two deep learning approaches: fine-tuning and feature extraction using the pre-trained version of these models as part of our investigation. We collected 540 images of sheep from nearby farms, concentrating on three age groups: young, middle-aged, and elderly, for the purpose of our study. With an interesting recognition accuracy of 96.9%, the experimental results demonstrate that ResNet102 is the best performer both when fine-tuned and when employing its deep features that are retrieved from its pre-trained version. These findings highlight how cutting-edge machine learning techniques have the potential to completely transform long-standing methods in the sheep sector and pave the way for developing a novel mobile application that improves economic outcomes and cultural conformity concerning sheep age recognition.},
  archive      = {J_CSCI},
  author       = {Ahmad B. Hassanat and Mohammad A. Al-Sarayreh and Ahmad S. Tarawneh and Mohammad A. Abbadi and Khalid Almohammadi and Mansoor Alghamdi and Maha Alamri and Abdulkareem Alzahrani and Ghada A. Altarawneh},
  doi          = {10.1080/09540091.2025.2506456},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2506456},
  shortjournal = {Connect. Sci.},
  title        = {Deep learning computer vision system for estimating sheep age using teeth images},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visual data security in healthcare and cloud applications using a novel 2D-HCFCM, polynomial chains and NLDSR. <em>CSCI</em>, <em>37</em>(1), Article: 2491340. (<a href='https://doi.org/10.1080/09540091.2025.2491340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past two decades, numerous encryption schemes leveraging chaotic systems have been developed to ensure data integrity in healthcare and cloud environments. In this paper, we first assess the performance of a two-dimensional Higher Complexity Folium Chaotic Map (2D-HCFCM) and then introduce a robust encryption algorithm for 8-bit and 24-bit images. The algorithm constructs polynomials of 0 ≤ d ≤ 7 with 2D-HCFCM, followed by polynomial chaining and 8-bit conditional logical operation ( CL O 8 bit ), driven by ζ ( υ ) = ( ⌊ csin ⁡ ( x 2 + y 2 ) ⌋ + x y ) mod 2 to introduce additional dynamic control. Furthermore, the Nested Layered with Diagonal Swapping and Relocation (NLDSR) technique introduces nonlinearity and resistance to chosen plaintext attacks. In summary, the algorithm offers an encryption key of 800 bits and demonstrates satisfactory security performance, with a χ 2 of 236.0598, an NBCR of 49.7%, and an NPCR value of 99.6389, with optimal computational efficiency. The security analysis confirms that the algorithm is effective in preserving the integrity of visual data.},
  archive      = {J_CSCI},
  author       = {Sajid Khan and Hao Peng and Abdul Haseeb and Sardar Usman},
  doi          = {10.1080/09540091.2025.2491340},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2491340},
  shortjournal = {Connect. Sci.},
  title        = {Visual data security in healthcare and cloud applications using a novel 2D-HCFCM, polynomial chains and NLDSR},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel classification of meditation techniques via optimised chi-squared 1D-CNN method based on complexity, continuity and connectivity features. <em>CSCI</em>, <em>37</em>(1), Article: 2467387. (<a href='https://doi.org/10.1080/09540091.2025.2467387'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intricate world of human–computer interaction deeply explores how people gain knowledge and blend technology into daily life. Electroencephalography (EEG) is one of several methods for measuring brain activity, it is non-invasive, portable, inexpensive and time-sensitive. Research shows a strong link between meditation and changes in EEG patterns, spanning various techniques. With machine learning playing a major role, EEG datasets have made comprehensive study possible. This paper investigates the efficacy of 1D-CNN (One-Dimensional Convolutional Neural Network) classification, using complexity, continuity and connectivity features. It remarkably outperforms and achieves 60% training accuracy, showcasing model robustness in meditation classification. This novel methodology enables to differentiates neural oscillations in type of meditator and control. Prior research used power spectrum density, entropy, and connectivity for meditation distinctions. EEG data from practitioners of Himalayan Yoga (HYT), Isha Shoonya (SYN) and Vipassana (VIP) as well as untrained controls (CTR) are examined in this research. Employing chi-square, CNN and hyperparameter models, outcomes reveal distinctive cognitive aspects among meditation styles, allowing effective differentiation.},
  archive      = {J_CSCI},
  author       = {Abhishek Jain and Rohit Raja and Manoj Kumar and Pawan Kumar Verma},
  doi          = {10.1080/09540091.2025.2467387},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2467387},
  shortjournal = {Connect. Sci.},
  title        = {A novel classification of meditation techniques via optimised chi-squared 1D-CNN method based on complexity, continuity and connectivity features},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel CNN architecture for image restoration with implicit frequency selection. <em>CSCI</em>, <em>37</em>(1), Article: 2465448. (<a href='https://doi.org/10.1080/09540091.2025.2465448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration aims to recover clear images from degraded ones, with deep neural networks becoming the dominant approach. While earlier methods focused on spatial-domain information, recent models have explored frequency-domain data to improve performance. However, explicit frequency-domain processing introduces significant computational overhead. To address this, we propose the Implicit Frequency Selective Image Restoration Network (IFSR-Net), which implicitly captures frequency information without explicit transformations, achieving high performance with reduced computational cost. Our analysis indicates that the main spectral variations between the clear and degraded images are centred on the high-frequency components in the feature maps; the convolution operator tends to amplify the amplitude and variance of these components. Building on this observation, we designed an Implicit Frequency Selection Module (IFSM) to enrich high-frequency components and an Implicit Frequency Selection Attention (IFSA) mechanism to emphasize and integrate beneficial frequency features. We integrated and optimized design elements from existing image restoration models to further refine the overall architecture of IFSR-Net. Extensive experiments across seven datasets and three tasks demonstrate the effectiveness of our approach. Ablation studies confirm the validity of our design choices, offering insights for future research in image restoration.},
  archive      = {J_CSCI},
  author       = {Jiaxing Hu and Zhibo Wang},
  doi          = {10.1080/09540091.2025.2465448},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2465448},
  shortjournal = {Connect. Sci.},
  title        = {A novel CNN architecture for image restoration with implicit frequency selection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Password region attribute classification based on multi-granularity cascade fusion. <em>CSCI</em>, <em>37</em>(1), Article: 2461092. (<a href='https://doi.org/10.1080/09540091.2025.2461092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The composition of the password is markedly disparate contingent on the configuration strategy and the individual user's predilections. The objective of this paper is to mine the region attribute information behind the password text through text classification. In contrast to the traditional text classification approach, the classification of password region attribution represents a distinct challenge namely ultra-short text classification. The issue of password regional attribute classification is particularly tricky due to its inherent lexical polysemy, the scarcity of text features, the lack of context and the difficulty in explicitly identifying semantics. To address the aforementioned issues, we propose a multi-granularity cascade fusion approach for password region attribution classification. Firstly, the model employs series of segmentation techniques to split password into multi-dimensional fine-grained subword representations. Subsequently, multiple segmented representations of the same password are fed into a localised feature encoder to mine the private local features. Finally, a multi-level cascade fusion method is designed to integrate different granularity of password features into a unified representation to classification. Our approach can effectively addresses the limitations of scarce information and the challenge of integrating multiple representations for password text. Experiments on a large amount of real password data demonstrate that, our model can converge rapidly and achieve an accuracy of 88.18%, a precision of 88.31%, a recall of 87.73%, and an F1-score of 88.02%, significantly outperforming traditional models.},
  archive      = {J_CSCI},
  author       = {Wei Yu and Cheng Liu and Lvlin Ni and Yu Shi and Qingbing Ji},
  doi          = {10.1080/09540091.2025.2461092},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2461092},
  shortjournal = {Connect. Sci.},
  title        = {Password region attribute classification based on multi-granularity cascade fusion},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved data labelling method for news headlines classification in cloud environment. <em>CSCI</em>, <em>37</em>(1), Article: 2461088. (<a href='https://doi.org/10.1080/09540091.2025.2461088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In several domains, such as computer vision, natural language processing, and speech recognition, automatic data labelling is a critical task. Automatic data labelling is the process of utilising machine learning techniques to automatically label substantial amounts of data. Two largest news datasets like, the Kaggle dataset and the AG News dataset are used as benchmark for the performance analysis of the proposed algorithms. A novel four-dimensional matrix-based input representation that depicts the intra – and inter-word associations is used to obtain the feature vectors. Density-Based Spatial Clustering of Applications with Noise (DBSCAN) helps to remove the outliers which improves the overall accuracy of Convolutional Neural Networks (CNN). The proposed approach also reduces the dependency on human annotators. The DBSCAN algorithm is utilised o automatically cluster similar data points, thereby reducing the need for manual labelling. These clusters are then fed into a CNN with a rethinking mechanism, which allows the network to revise its initial predictions based on additional context. This integration of clustering and deep learning techniques aims to improve the accuracy and efficiency. The cloud computing method is used to achieve high-throughput news headlines classification in order to achieve accurate and efficient data labelling.},
  archive      = {J_CSCI},
  author       = {A. Sherly Alphonse and S. Abinaya and Nirvik Verma},
  doi          = {10.1080/09540091.2025.2461088},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2461088},
  shortjournal = {Connect. Sci.},
  title        = {Improved data labelling method for news headlines classification in cloud environment},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Software defect prediction using wrapper-based dynamic arithmetic optimization for feature selection. <em>CSCI</em>, <em>37</em>(1), Article: 2461080. (<a href='https://doi.org/10.1080/09540091.2025.2461080'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software Defect Prediction (SDP) empowers the creators to diagnose and unscramble defects in the introductory legs of the software evolution process to reduce the effort and cost invested in creating high-quality software. Feature Selection (FS) is critical to pinpoint the most pertinent features for defect prediction. This paper intends to employ a peculiar wrapper-based FS mode, dubbed DAOAFS, rooted on the dynamic arithmetic optimization algorithm (DAOA). Subsequently, this work evaluates the competence of the proposed FS mode using ten benchmark NASA datasets on four supervised learning classifiers, namely NB, DT, SVM, and KNN using accuracy and error curve as the standard performance measure metrics. This paper also correlates the proposed FS mode's conduct with existing FS techniques based on widely utilized meta-heuristic approaches such as GA, PSO, DE, ACO, FA, and SWO. This work employed Friedman and Holm test to ratify the proposed FS mode's statistical connotation. The investigatory outcomes supported the assertion that the recommended DAOAFS mode was effective in enhancing the efficacy of the defect forecasting model by achieving the highest mean accuracy of 94.76%. The findings also revealed that the proposed approach established its supremacy over the other studied FS techniques with bettered veracity in most instances.},
  archive      = {J_CSCI},
  author       = {Kunal Anand and Ajay Kumar Jena and Himansu Das and S. S. Askar and Mohamed Abouhawwash},
  doi          = {10.1080/09540091.2025.2461080},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2461080},
  shortjournal = {Connect. Sci.},
  title        = {Software defect prediction using wrapper-based dynamic arithmetic optimization for feature selection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative adversarial deep learning model for producing location-based synthetic trajectory data. <em>CSCI</em>, <em>37</em>(1), Article: 2458502. (<a href='https://doi.org/10.1080/09540091.2025.2458502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid expansion of location-based services has triggered the acquisition and analysis of various types of individual trajectory recordings. However, the sensitive nature of such kind of data inevitably leads to privacy constraints and regulations on its use and sharing. This paper addresses the problem in a distinctive perspective. Instead of blurring or modifying original trajectory samples, we aim to generate a completely synthetic dataset, whose samples are singularly different from the original ones, but whose collective sets share similar global characteristics and performances. We propose a generative deep learning solution for location-based trajectory formats, with the goal of producing realistic synthetic location sequences: the process relies on a generative adversarial network (GAN) framework, involving long short-term memory (LSTM) recurrent layers to capture trajectory characteristics, and neural embeddings to model mobility relations between places. We leverage multiple metrics to assess the realistic character of synthetic data and their similarity with the original source; moreover, we evaluate downstream performance differences with regard to the next place prediction problem. Tested on a real-world large-scale dataset of long-distance trips, and compared with baselines and traditional geomasking techniques, our approach presents better characteristics, providing novel insights into GeoAI solutions for human mobility analysis.},
  archive      = {J_CSCI},
  author       = {Alessandro Crivellari and Yuhui Shi},
  doi          = {10.1080/09540091.2025.2458502},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2458502},
  shortjournal = {Connect. Sci.},
  title        = {Generative adversarial deep learning model for producing location-based synthetic trajectory data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incremental learning based two-level multimodal data fusion model for alzheimer disease prediction on different data modalities. <em>CSCI</em>, <em>37</em>(1), Article: 2458501. (<a href='https://doi.org/10.1080/09540091.2025.2458501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer's disease (AD) is a complex neurodegenerative condition that affects millions of people worldwide, necessitating early and accurate diagnosis for optimal patient care. This study presents a novel Two-Level Multimodal Data Fusion Integrated Incremental Learner Ensemble Classifier (TMDFILE) for Alzheimer's detection. This method integrates temporal, spatial, spectral, audio, and text data modalities, utilising a gating mechanism to optimise the contribution of each modality. Incremental learning is employed to adjust evolving data patterns and, enhance long-term performance. The proposed TMDFILE was evaluated across five diverse datasets: achieving an accuracy of 94.5%, precision of 93.5%, recall of 95.1%, and F-measure of 94.1% on the ADNI dataset; an accuracy of 94.9%, with precision, recall, and F-measure values of 94.5%, 94.1%, and 94.3%, respectively, on the OASIS dataset; an accuracy of 93.5%, precision of 95.1%, and recall of 94.1% on the EEG Emotion Recognition dataset; an accuracy of 94.5%, precision of 93.5%, and recall of 95.1% on the Aberystwyth Dementia dataset, providing reliable classifications that contribute to early cognitive decline detection; and showed robust performance with an accuracy of 94.5%, precision of 93.5%, and recall of 95.1% on the BRATS dataset, relevant to brain imaging analysis for Alzheimer's detection. TMDFILE consistently outperformed traditional classifiers, including Support Vector Machines, Random Forest, and Convolutional Neural Networks, achieving an average precision of 93.5%, recall of 95.1%, F-measure of 94.1%, and accuracy of 94.5%. These findings underscore TMDFILE's effectiveness in diagnostic accuracy and reliability, establishing it as a promising tool for Alzheimer's disease detection across clinical and research applications.},
  archive      = {J_CSCI},
  author       = {M. Leela and K. Helenprabha},
  doi          = {10.1080/09540091.2025.2458501},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2458501},
  shortjournal = {Connect. Sci.},
  title        = {Incremental learning based two-level multimodal data fusion model for alzheimer disease prediction on different data modalities},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel deep learning model for stock market prediction using a sentiment analysis system from authoritative financial website’s data. <em>CSCI</em>, <em>37</em>(1), Article: 2455070. (<a href='https://doi.org/10.1080/09540091.2025.2455070'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of deep learning, specifically time series neural networks, in predicting stock market trends has emerged as a significant use case in financial analysis. However, the complex interrelationships and instability of the stock market have made the timely and accurate prediction of its behaviour as a confronting endeavour. To address this difficulty, in this research work a stock market index prediction model called SenT-In, which combines the with a sentiment awareness model. A sentiment awareness model using Convolutional Neural Networks (CNN) and Gated Recurrent Unit (GRU) is proposed to calculate the sentiment index of a large volume of news articles collected from reputable financial websites. In addition, a sentiment attention method is developed to combine stock data and news sentiment index as the input for training and predicting using the SenT-In network, which is both simple and efficient. The proposed model is evaluated in four different stock market datasets which include FSTE, SSE, Nifty 50 and S&P 500. On comparing the results with conventional deep learning algorithms such as GRU, LSTM, CNN and SVM, proposed SenT-In outperforms existing methods in accuracy with 9%, F1-Score with 7%, AUC-ROC curve with 13% and PR-AUC curve with 9% efficiency (on average).},
  archive      = {J_CSCI},
  author       = {Jitendra Kumar Chauhan and Tanveer Ahmed and Amit Sinha},
  doi          = {10.1080/09540091.2025.2455070},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2455070},
  shortjournal = {Connect. Sci.},
  title        = {A novel deep learning model for stock market prediction using a sentiment analysis system from authoritative financial website’s data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Classification of heart sound signals with whisper model. <em>CSCI</em>, <em>37</em>(1), Article: 2449943. (<a href='https://doi.org/10.1080/09540091.2025.2449943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart sounds, or phonocardiograms (PCG), are important for diagnosing cardiovascular conditions, providing a non-invasive means to assess heart function through auscultation. Accurate classification of PCG signals can facilitate early detection of cardiac abnormalities, significantly improving patient outcomes. However, the complexity and variability of heart sound recordings present significant challenges for traditional classification methods, necessitating advanced approaches that can effectively handle the nuances of cardiac acoustics. This paper introduces a novel transfer learning approach that adapts OpenAI's Whisper model, originally designed for robust speech recognition, to the task of heart sound classification. In particular, we employ Whisper's encoder architecture to effectively capture acoustic features that generalize to cardiac auscultation, making it a promising candidate for PCG analysis. To tailor the model for this specialized task, we implement a modified encoder architecture optimized for heart sound characteristics. We process the input to the model using a Log-Mel spectrogram pipeline specifically designed to highlight the unique acoustic properties of PCG signals. Experimental results demonstrate that the adapted Whisper model achieves state-of-the-art performance, surpassing existing methods in both accuracy and robustness.},
  archive      = {J_CSCI},
  author       = {Maryam Alotaibi and Yakoub Bazi and Mohamad Mahmoud Al Rahhal and Nassim Ammour and Mansour Zuair},
  doi          = {10.1080/09540091.2025.2449943},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2449943},
  shortjournal = {Connect. Sci.},
  title        = {Classification of heart sound signals with whisper model},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimising source code vulnerability detection using deep learning and deep graph network. <em>CSCI</em>, <em>37</em>(1), Article: 2447373. (<a href='https://doi.org/10.1080/09540091.2024.2447373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enhance the effectiveness of vulnerability detection in software developed using C and C++ programming languages, our study introduces a novel correlation calculation method for analyzing and evaluating Code Property Graphs (CPG). The intelligent computation method proposed in this study comprises three key stages. In the first stage, we present a method for extracting features from the CPG source code. To accomplish this, we integrate three distinct data exploration methods: employing Graph Convolutional Neural (GCN) to extract node features from CPG, utilizing Convolutional Neural Network (CNN) to extract edge features from CPG, and finally employing the Doc2vec natural language processing algorithm to extract source code from CPG nodes. The second stage involves proposing a method for synthesizing CPG source code features. Building on the features acquired in the first stage, our paper introduces a synthesis and construction method to generate feature vectors for the source code. The final stage, stage three, executes the detection of source code vulnerabilities. The experimental results demonstrate that our proposed model in this study achieves higher efficiency compared to other studies, with an improvement ranging from 3% to 4%.},
  archive      = {J_CSCI},
  author       = {Cho Do Xuan and Tran Thi Luong and Ma Cong Thanh},
  doi          = {10.1080/09540091.2024.2447373},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2447373},
  shortjournal = {Connect. Sci.},
  title        = {Optimising source code vulnerability detection using deep learning and deep graph network},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selecting hybrids of metaheuristics for resource-constraint project scheduling problems with discounted cashflows. <em>CSCI</em>, <em>37</em>(1), Article: 2447365. (<a href='https://doi.org/10.1080/09540091.2024.2447365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving resource-constrained project scheduling problems with discounted cash flows (RCPSP-DC) is a critical challenge for project and finance managers, as efficient resource allocation can significantly impact a company’s financial success. While prior research addresses this NP-hard problem, most approaches depend on hybrid metaheuristics requiring expertise in hybridisation and lack systematic methods for architecture selection, often relying on a single criterion with trial-and-error parameter tuning. In this paper, we propose a novel collaborative parallel hybridisation framework that integrates Thompson sampling and multicriteria decision analysis (MCDA) to holistically evaluate and identify the best hybrid architecture from a diverse set of options. Unlike conventional approaches, our method employs onboard Taguchi design of experiments (DOE) for structured and efficient parameter tuning. Additionally, Thompson sampling, applied in the form of Bayesian learning, mitigates the stochastic nature of metaheuristics through multiple experiments. This framework was used to select the best architecture from 57 hybrid combinations of six metaheuristics for solving RCPSP-DC. Extensive experiments using standard datasets demonstrate that the proposed framework achieves statistically significant performance improvements, selecting a hybrid architecture that outperforms state-of-the-art methods. The selected architecture’s competitiveness is validated through a Z-test of proportions, underscoring its effectiveness in solving RCPSP-DC problems.},
  archive      = {J_CSCI},
  author       = {Tshewang Phuntsho and Tad Gonsalves},
  doi          = {10.1080/09540091.2024.2447365},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2447365},
  shortjournal = {Connect. Sci.},
  title        = {Selecting hybrids of metaheuristics for resource-constraint project scheduling problems with discounted cashflows},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human body contour extraction method based on human skeleton key point guidance. <em>CSCI</em>, <em>37</em>(1), Article: 2445805. (<a href='https://doi.org/10.1080/09540091.2024.2445805'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By extracting human contours from 2D images captured by the camera and then obtaining human size data, the cost of garment custom measurement can be effectively reduced and the efficiency of custom measurement can be improved. The extraction of human contours plays an important role in the collection of online human size data. We propose a method to extract human contours by fusing the prior information of human skeleton key points into the salience target detection network. Specifically, the skeleton key point information extracted based on OpenPose is fused into the encoder-decoder network for rough detection of the human body target, and the residual refinement network is used to fine-adjust the human body matting, so as to achieve accurate human contour extraction. In this paper, the accuracy and superiority of the algorithm are verified in the public data set P3M-10K of human body matting and applied to the 2D body measurement WeChat applet on mobile phone and computer website.},
  archive      = {J_CSCI},
  author       = {Zhongwei Hua and Yong Ren and Yulu Wang and Zhuriyao Jin},
  doi          = {10.1080/09540091.2024.2445805},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2445805},
  shortjournal = {Connect. Sci.},
  title        = {Human body contour extraction method based on human skeleton key point guidance},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards enhanced assessment question classification: A study using machine learning, deep learning, and generative AI. <em>CSCI</em>, <em>37</em>(1), Article: 2445249. (<a href='https://doi.org/10.1080/09540091.2024.2445249'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to benchmark the performance of machine learning (ML), deep learning (DL), and generative AI (GenAI) models in categorising assessment questions based on Bloom’s Taxonomy. Previous studies have lacked comprehensive investigations into the performance of these approaches. Further, the GenAI remains unexplored, offering a promising avenue for groundbreaking explorations. Therefore, we explore the effectiveness of various ML models by incorporating domain-specific term weighting and utilising word embeddings. The study also analyses the performance of Recurrent Neural Networks (RNNs) and Convolutional Neural Network (CNN) with and without bidirectional connections, as well as an approach that combines RNNs and CNN. Furthermore, we evaluate several transformer-based models by fine-tuning them alongside GenAI models text-davinci-003, gpt-3.5-turbo, PaLM2, and Gemini Pro in zero-shot classification settings. The results demonstrate that ML models outperformed DL models, achieving a best accuracy of 0.871 and F1 score of 0.872. Additionally, domain-specific term weighting is found to be superior to word embeddings. Furthermore, most ML and DL models performed better than GenAI models, with GenAI models achieving a best accuracy of 0.618 and a best F1 score of 0.627. Therefore, the outcome suggests considering the ML models with domain-specific term weighting as benchmark models in future research.},
  archive      = {J_CSCI},
  author       = {Mohammed Osman Gani and Ramesh Kumar Ayyasamy and Saadat M. Alhashmi and Khondaker Sajid Alam and Anbuselvan Sangodiah and Khondaker Khaleduzzman and Chinnasamy Ponnusamy},
  doi          = {10.1080/09540091.2024.2445249},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2445249},
  shortjournal = {Connect. Sci.},
  title        = {Towards enhanced assessment question classification: A study using machine learning, deep learning, and generative AI},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating robustness dynamics of shallow machine learning techniques: Beyond basic natural variations in image classification. <em>CSCI</em>, <em>37</em>(1), Article: 2435654. (<a href='https://doi.org/10.1080/09540091.2024.2435654'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the widespread adoption of deep learning models, shallow machine learning (SML) algorithms are still used for image classification due to simplicity, interpretability and efficiency. This study aims to bridge this gap by investigating the robustness dynamics of SML techniques under more complex scenarios, such as adversarial perturbations and geometric transformation. Five popular classification algorithms, including k-nearest neighbour and support vector machines, were employed to build classification models. Methodology involves investigating the robustness of proposed  methods, first, on original and corrupted data by utilising benchmark datasets across several image domains. To strengthen the investigation, the models were trained using a new low-rank representation (LRR) strategy. This hybrid model simultaneously addresses two key limitations in classical LRR models: overcoming the sequential learning process and effectively capturing both local and global data structures. By introducing a dual regularisation mechanism, it integrates a k-nearest neighbour graph to preserve local consistency, while a global low-rank constraint ensures coherent data representation. Experimental results reveal significant drops in accuracy of most SML methods, especially under adversarial attacks and geometric transformations, but LRR approach mitigates these effects to a notable extent, boosting performance across data variations. The results also show that the proposed  method outperforms state-of-the-art LRR techniques in most experiments.},
  archive      = {J_CSCI},
  author       = {Mengtong Li},
  doi          = {10.1080/09540091.2024.2435654},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2435654},
  shortjournal = {Connect. Sci.},
  title        = {Investigating robustness dynamics of shallow machine learning techniques: Beyond basic natural variations in image classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="cybs">CYBS - 4</h2>
<ul>
<li><details>
<summary>
(2025). Deriving a multi-objective function using hybrid meta-heuristic approach for optimal CH selection and optimal routing in WSN. <em>CYBS</em>, <em>56</em>(7), 1085-1126. (<a href='https://doi.org/10.1080/01969722.2025.2468191'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to advent of sensors with less in weight, tiny in size and low power, it designates as Wireless Sensor Networks (WSNs). However in recent times, the key issue is noted in WSN is reducing the lifetime of the system. Hence in this paper, an advanced selection of Cluster Head (CH) and optimal routing is implemented by utilizing the improved heuristic algorithm. The developed Hybrid Walrus and Chameleon Swarm Algorithm (HWCSA) is performed by optimally select the CH and the multi-objective functions with constraints like residual energy, distance, and delay are derived in the CH selection approach. Moreover, the same HWCSA is used for performing the routing process to provide better communication between Base Station (BS) and sensor nodes. Here, multi-objective function with constraints like throughput, distance, packet delivery ratio, and hop count are optimally derived by optimizing the shortest path. In the end, the designed HWCSA approach is estimated with several performance metrics. Validating cost function analysis, the proposed model achieves 4%, 7.6%, 9.4%, and 8.5% better than BMO, OOA, WOA, and CSA algorithms. Throughout the empirical analysis, the designed model attains effective performance than state-of-the-art-methods.},
  archive      = {J_CYBS},
  author       = {M. Raghupathy and Chukka Rajasekhar},
  doi          = {10.1080/01969722.2025.2468191},
  journal      = {Cybernetics and Systems},
  month        = {10},
  number       = {7},
  pages        = {1085-1126},
  shortjournal = {Cybern. Sci.},
  title        = {Deriving a multi-objective function using hybrid meta-heuristic approach for optimal CH selection and optimal routing in WSN},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Failure mode and effects analysis method on the air system of an aircraft turbofan engine in multi-criteria open group decision-making environment. <em>CYBS</em>, <em>56</em>(7), 1053-1084. (<a href='https://doi.org/10.1080/01969722.2025.2468189'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failure mode and effects analysis (FMEA), an proactive risk management approach, has been widely applied in a variety of industries, especially in aircraft industry. In the process of implementation, the influence and uncertainty among different experts is inevitable. In order to handle the uncertainty in the assessments of FMEA experts, Dempster-Shafer evidence theory was introduced to FMEA for its flexibility and superiority in coping with uncertain and subjective assessments. However, traditional Dempster combination rule have difficulty in dealing with highly conflicting evidence that given from FMEA experts’ assessments. Moreover, experts themselves may influence each other though process such as chatting, judging, decision-making and voting. In this paper, we explore the problem of conflict evidence fusion from a correlation perspective among FMEA experts. We use ambiguity measure and Gaussian distribution to deal with the highly conflicting evidence. We use ambiguity measure to calculate the variance of Gaussian distribution. Then, we use Gaussian model to generalize expert assessments. After that, we use Dempster combination rule to fuze assessments from different experts. Finally, we calculate the risk priority number to rank the risk level of the FMEA items. The experiment results in the air system of an aircraft turbofan engine shows the efficiency and accuracy of the proposed method.},
  archive      = {J_CYBS},
  author       = {Yongchuan Tang and Zixi Fei and Lei Huang and Wenyi Zhang and Bingying Zhao and He Guan and Yubo Huang},
  doi          = {10.1080/01969722.2025.2468189},
  journal      = {Cybernetics and Systems},
  month        = {10},
  number       = {7},
  pages        = {1053-1084},
  shortjournal = {Cybern. Sci.},
  title        = {Failure mode and effects analysis method on the air system of an aircraft turbofan engine in multi-criteria open group decision-making environment},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heart disease detection and prognosis using IoT-based ECG sensor data with hybrid deep learning architecture and optimal resource allocation. <em>CYBS</em>, <em>56</em>(7), 1002-1052. (<a href='https://doi.org/10.1080/01969722.2025.2459959'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart disease remains a major global cause of mortality, underscoring the need for advancements in early detection and prognosis to enhance patient recovery. This study proposes an innovative framework integrating deep learning (DL) models and optimal resource allocation strategies to improve heart disease detection and prognosis. The framework begins with rigorous preprocessing of the Internet of Things (IoT) captured Electrocardiogram (ECG) data, employing min–max normalization, and advanced median filtering techniques for noise reduction and baseline wander correction. Statistical features are extracted from the preprocessed data, while features such Improved Empirical Mode Decomposition (EMD), RR interval, R peak, and PR interval are derived from ECG signals. These features are then augmented using a min–max technique to enhance dataset diversity and model robustness. Furthermore, the study introduces a hybrid model combining a Deep Residual Network (DRN) and an Improved Bidirectional Gated Recurrent Unit for severity classification heart disease detection, leveraging augmented features. Optimal resource allocation is facilitated by the Improved Walrus Optimization Algorithm (WaOA), optimizing ventilator, Intensive Care Unit (ICU) bed, medical staff, and medication allocation based on predicted disease severity. Evaluation with real-world datasets demonstrates superior diagnostic accuracy and resource utilization efficiency, highlighting the transformative potential of IoT and AI-driven approaches in cardiovascular healthcare.},
  archive      = {J_CYBS},
  author       = {Pranali P. Lokhande and Kotadi Chinnaiah},
  doi          = {10.1080/01969722.2025.2459959},
  journal      = {Cybernetics and Systems},
  month        = {10},
  number       = {7},
  pages        = {1002-1052},
  shortjournal = {Cybern. Sci.},
  title        = {Heart disease detection and prognosis using IoT-based ECG sensor data with hybrid deep learning architecture and optimal resource allocation},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of modified ECC-based secured FoG-assisted healthcare data management system in IoT-enabled WSN. <em>CYBS</em>, <em>56</em>(7), 971-1001. (<a href='https://doi.org/10.1080/01969722.2024.2343985'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) consists of a massive count of connected devices with different sensing support, particularly in medical health constraints sensing. In these summaries, secure communication and data collection to centralized servers is rather difficult for preventing the occurrence of diverse attacks for illegal data access. To tackle these problems, this task plans to design and implement the FoG-based secure data management system in IoT-WSN using adaptive encryption and decryption processes. As the FoG server is away from the corresponding aggregator node, it is transmitted via the other nodes using the proposed modified Elliptic Curve Cryptography (ECC)-based encryption process. For secured data transmission the designed method undergoes two main stages as message receiving stage, and the message-extraction stage. The hybridized meta-heuristic algorithm termed Jaya-Galactic Swarm Optimization (J-GSO) is used for modifying the ECC with an optimized key. From the simulation findings, the performance of the suggested scheme at the data size of three bytes is 3.08%, 3.22%, 3.65%, and 3.33% better than the MFO-m-ECC, PSO-m-ECC, GSO-m-ECC, and JA-m-ECC at the ECC curve variation of “secp192r1”. Experimental results reveal the superiority of the designed method when tested with baseline schemes regarding time complexity, space complexity, and cost function.},
  archive      = {J_CYBS},
  author       = {A. Tina Victoria and M. Kowsigan},
  doi          = {10.1080/01969722.2024.2343985},
  journal      = {Cybernetics and Systems},
  month        = {10},
  number       = {7},
  pages        = {971-1001},
  shortjournal = {Cybern. Sci.},
  title        = {Development of modified ECC-based secured FoG-assisted healthcare data management system in IoT-enabled WSN},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="engo">ENGO - 12</h2>
<ul>
<li><details>
<summary>
(2025). A novel reinforcement learning-based method for structure optimization. <em>ENGO</em>, <em>57</em>(9), 2629-2648. (<a href='https://doi.org/10.1080/0305215X.2024.2411412'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of deep learning technology, Reinforcement Learning (RL) has garnered considerable acclaim within the realm of structural optimization owing to its excellent exploration mechanism. However, the widespread application of RL in this field is limited owing to the excessive number of iterations required to converge and the expensive computational cost it brings. To address these challenges, this article presents a novel RL framework for structural optimization, combining Monte Carlo tree search with the proximal policy optimization method, called LMPOM. The key contributions of LMPOM encompass: (1) an enhanced Monte Carlo tree search strategy for partitioning the hybrid design space; (2) a strategy for adaptively updating surrogate models to reduce simulation costs; and (3) the introduction of a novel termination condition for the RL algorithms. Through tests on three benchmark problems, compared with previous RL algorithms, LMPOM consistently shows fewer iterations and better optimization results.},
  archive      = {J_ENGO},
  author       = {Zijian Mei and Zhouwang Yang and Jingrun Chen},
  doi          = {10.1080/0305215X.2024.2411412},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2629-2648},
  shortjournal = {Eng. Optim.},
  title        = {A novel reinforcement learning-based method for structure optimization},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A Q-learning multi-objective grey wolf optimizer for the distributed hybrid flowshop scheduling problem. <em>ENGO</em>, <em>57</em>(9), 2609-2628. (<a href='https://doi.org/10.1080/0305215X.2024.2410844'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing research focuses on a single objective for the distributed hybrid flowshop scheduling problem (DHFSP). This article focuses on a multi-objective DHFSP with sequence-dependent set-up time (DHFSP-SDST). A Q-learning multi-objective grey wolf optimizer (QMOGWO) is designed to optimize the makespan, total energy consumption and total tardiness. A mathematical model for DHFSP-SDST is established. Several initialization strategies and a random method are introduced to improve the quality of the initial population. The new individual is developed by the discrete solution updating mechanism of QMOGWO. Based on the Q-learning, local search strategies are designed to avoid local optima. To verify the performance of the proposed QMOGWO, different scales of instances are tested in various factories and at different stages, and the simulation results show that the QMOGWO outperforms the comparison methods.},
  archive      = {J_ENGO},
  author       = {Jianguo Zheng and Shuilin Chen},
  doi          = {10.1080/0305215X.2024.2410844},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2609-2628},
  shortjournal = {Eng. Optim.},
  title        = {A Q-learning multi-objective grey wolf optimizer for the distributed hybrid flowshop scheduling problem},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal box contraction for solving linear systems via simulated and quantum annealing. <em>ENGO</em>, <em>57</em>(9), 2597-2608. (<a href='https://doi.org/10.1080/0305215X.2024.2408686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving linear systems of equations is an important problem in engineering. Many quantum algorithms, such as the Harrow–Hassidim–Lloyd algorithm and the box algorithm, have been proposed for solving such systems. The focus of this article is on improving the efficiency of the box algorithm. The basic principle behind this algorithm is to transform the linear system into a series of quadratic unconstrained binary optimization (QUBO) problems, which are then solved on annealing machines. The computational efficiency of the box algorithm is entirely determined by the number of iterations, which, in turn, depends on the box contraction ratio, typically set to 0.5. Here, it is shown through theoretical analysis that a contraction ratio of 0.5 is sub-optimal and that a computational speed-up can be achieved with a contraction ratio of 0.2. This is confirmed through numerical experiments where a computational speed-up between 20 % to 60 % is observed when the optimal contraction ratio is used.},
  archive      = {J_ENGO},
  author       = {Sanjay Suresh and Krishnan Suresh},
  doi          = {10.1080/0305215X.2024.2408686},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2597-2608},
  shortjournal = {Eng. Optim.},
  title        = {Optimal box contraction for solving linear systems via simulated and quantum annealing},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Employing an optimal control strategy for systems with measurement and actuation faults: A swarm optimization approach. <em>ENGO</em>, <em>57</em>(9), 2560-2596. (<a href='https://doi.org/10.1080/0305215X.2024.2408491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various industries involve interconnected coupled tank systems to control fluid level, which poses significant challenge for traditional controllers. A tilt-integral-derivative controller offers enhanced adaptability for such systems. However, tuning of these controllers is highly challenging. This work focuses on enhancing the liquid level control in coupled tank systems using a tilt-integral-derivative controller. Tuning for the control algorithm is achieved through the application of Harris's hawks optimization. An objective function is designed by imposing constraints on performance metrics such as integral square error, integral absolute error, integral time absolute error, and closed-loop gain, which are then solved using Harris's hawks optimization. Further, the robust behaviour of the system is exhibited using μ -analysis to assess its stability. Simulation studies confirm the control algorithm's effectiveness, showing superior performance in reducing settling-time and minimizing overshoot. Additionally, the robustness of the controller in handling sensor and actuator faults under varying operating conditions is demonstrated.},
  archive      = {J_ENGO},
  author       = {Achu Govind K. R. and Subhasish Mahapatra and Atanu Panda},
  doi          = {10.1080/0305215X.2024.2408491},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2560-2596},
  shortjournal = {Eng. Optim.},
  title        = {Employing an optimal control strategy for systems with measurement and actuation faults: A swarm optimization approach},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization of a roller coaster bogie considering fatigue life. <em>ENGO</em>, <em>57</em>(9), 2529-2559. (<a href='https://doi.org/10.1080/0305215X.2024.2408479'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the effectiveness of fatigue-life constrained topology optimization in roller coaster engineering, a previously unexplored field. Emphasizing the importance of fatigue life considerations, the research focuses on key components of roller coasters: the wheel assemblies. By integrating stress–life fatigue constraints, such an approach can lead to longer lasting and more efficiently designed roller coaster components. Multiaxial fatigue topology optimization using the method of moving asymptotes gradient-based optimization is examined to address the complex loading experienced by these bogies given a substantial load-time history in the high-cycle fatigue region. Using a validated optimization methodology, this study aims to reduce the bogie volume in selected domains while ensuring structural integrity and potentially extending service life. The optimization process successfully reduces the number of designable elements, resulting in decreased global volume and mass, and the results quantifiably demonstrate the impact of applying high-cycle fatigue constraints on the bogie’s performance.},
  archive      = {J_ENGO},
  author       = {Dylan Eisen and Il Yong Kim},
  doi          = {10.1080/0305215X.2024.2408479},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2529-2559},
  shortjournal = {Eng. Optim.},
  title        = {Optimization of a roller coaster bogie considering fatigue life},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A sustainable network design for municipal solid waste management considering waste-to-energy conversion under uncertainty. <em>ENGO</em>, <em>57</em>(9), 2505-2528. (<a href='https://doi.org/10.1080/0305215X.2024.2408478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research proposes a sustainable municipal solid waste management (MSWM) system to address population growth, consumerism, and resource scarcity. It introduces a two-phase decision structure combining multi-attribute decision-making (MADM) tools. Phase one develops a hybrid risk-oriented fuzzy MADM tool for selecting optimal waste-to-energy technologies, considering environmental and technological factors. Phase two uses a fuzzy bi-objective multi-period mixed-integer linear programming model to design the MSWM supply chain efficiently under uncertainty. A case study in North Tehran demonstrates the framework’s practical applicability and effectiveness in real-world scenarios, highlighting that effective source separation boosts recycling, reduces costs, and provides social benefits. Sensitivity analyses offer insights to enhance waste segregation practices. The study emphasizes integrating economic, environmental, and social sustainability in waste management decision-making. By offering a novel, holistic approach, this research addresses existing gaps in systematic decision-making processes and provides a robust tool for municipalities to optimize strategies under uncertainty.},
  archive      = {J_ENGO},
  author       = {Pantea Saatchi and Farima Salamian and Neda Manavizadeh and Masoud Rabbani},
  doi          = {10.1080/0305215X.2024.2408478},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2505-2528},
  shortjournal = {Eng. Optim.},
  title        = {A sustainable network design for municipal solid waste management considering waste-to-energy conversion under uncertainty},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid simulated annealing–slime mould algorithm for the non-permutation flow-shop scheduling problem. <em>ENGO</em>, <em>57</em>(9), 2492-2504. (<a href='https://doi.org/10.1080/0305215X.2024.2408477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The non-permutation flow-shop scheduling problem (NPFSP) is a more general type of flow-shop scheduling problem than the permutation flow-shop scheduling problem (PFSP). It features a large solution space and is highly complex. In this study, a novel metaheuristic algorithm is proposed for the NPFSP, where makespan is the scheduling objective. The specific implementation process is as follows. First, a mathematical model of the NPFSP is constructed. Secondly, the encoding and decoding rules are designed to establish the association between the solutions for PFSP and NPFSP. Subsequently, a metaheuristic hybrid simulated annealing–slime mould algorithm is proposed. Finally, a series of control experiments is conducted based on the Demirkol benchmark. The statistical results show the effectiveness of the proposed algorithm in solving the NPFSP.},
  archive      = {J_ENGO},
  author       = {Anran Zhao and Peng Liu and Xiyu Gao and Denghang Ding and Guotai Huang},
  doi          = {10.1080/0305215X.2024.2408477},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2492-2504},
  shortjournal = {Eng. Optim.},
  title        = {Hybrid simulated annealing–slime mould algorithm for the non-permutation flow-shop scheduling problem},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bi-level optimization and integrated multiple-criteria decision making under uncertainty for structural design of insulated bearings. <em>ENGO</em>, <em>57</em>(9), 2467-2491. (<a href='https://doi.org/10.1080/0305215X.2024.2402467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the premature failure of insulated bearings, this article proposes a design method for the structure of bearings to prolong their service life. First, a bi-level optimization model is established to determine the structural parameters of bearings considering their insulating and mechanical properties. Upper-level problems include bearing voltage ratio, porosity of insulating coatings, minimum thickness of oil film and Hertz contact area. Lower-level problems include fatigue life of bearings and adhesion of insulating coatings. Second, a non-dominated sorting genetic algorithm-III based on space decomposition and penalty-based boundary intersection (NSGA-III-SD-PBI) is designed to solve the optimization model. Third, the integrated multiple-criteria decision-making (MCDM) using the fuzzy best–worst method (BWM) and fuzzy technique for order preference by similarity to an ideal solution (TOPSIS) is developed to determine the best structural parameters of bearings. A case study demonstrates the effectiveness and superiority of the proposed method, with fatigue life increased by 20%.},
  archive      = {J_ENGO},
  author       = {Ruosong Ji and Yixiong Feng and Zhaoxi Hong and Jiugen Wang and Junjie Song and Yong Wang and Xu Hao and Lianbin Gao and Jianrong Tan},
  doi          = {10.1080/0305215X.2024.2402467},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2467-2491},
  shortjournal = {Eng. Optim.},
  title        = {Bi-level optimization and integrated multiple-criteria decision making under uncertainty for structural design of insulated bearings},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An integrated optimization method for the damper placements, shape and size of truss structures. <em>ENGO</em>, <em>57</em>(9), 2446-2466. (<a href='https://doi.org/10.1080/0305215X.2024.2401557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work extends the application of the approximation concept in dynamic topology optimization for truss structures. The corresponding problem contains both continuous and discrete variables, encompassing damper placements, truss shape and cross-sectional area. First, the utilization of a branched multipoint approximation (BMA) function establishes sequential approximation problems that also involve such mixed variables, marking its innovative application in dynamic optimization. Then, a modified genetic algorithm (GA) is used to optimize discrete variables. To enhance convergence stationarity, the concept of ‘adjacent individuals’ is proposed to control the degree of difference in topology configuration between initial population members and the current optimal. Additionally, adjustments to the sequence-based crossover process ensure compliance with damper quantity constraints. Examples demonstrate that the introduction of adjacent individuals is beneficial to convergence stationarity, and the shape change of the truss increases the mode damping ratio by more than 20%. The created optimization platform can also tackle other mixed variables optimization problems.},
  archive      = {J_ENGO},
  author       = {Shuanjun Liu and Hai Huang and Shenyan Chen and Ziqi Dai and Weipeng Li},
  doi          = {10.1080/0305215X.2024.2401557},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2446-2466},
  shortjournal = {Eng. Optim.},
  title        = {An integrated optimization method for the damper placements, shape and size of truss structures},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differential evolution-based topology optimization using karhunen-loève expansion. <em>ENGO</em>, <em>57</em>(9), 2419-2445. (<a href='https://doi.org/10.1080/0305215X.2024.2400558'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topology optimization is a widely adopted structural optimization approach that aims to maximize desired performance based on mathematical and physical principles. Gradient-based methods are common for obtaining optimal configurations; however, they struggle with problems involving numerous local optima and non-differentiable problems, which prevent the derivation of design sensitivity. To address these issues, this study explores the application of the Success History-Based Differential Evolution with Linear Population Size Reduction and Semi-Parameter Adaptation, which is regarded as LSHADE-SPA algorithm, known for its strong search capabilities. Nevertheless, its computational cost makes it impractical for topology optimization, especially as the number of design variables increases. To overcome this challenge, a novel structure representation method utilizing the Karhunen-Loève (KL) expansion is constructed. Applying truncated KL expansion instead of conventional density methods to represent structural configurations reduces the number of design variables. This article introduces a differential evolution-based topology optimization method utilizing truncated KL expansion and validates its effectiveness through applications in various structural and fluid problems. The method is particularly suited to highly nonlinear problems, such as negative Poisson's ratio structures and micro-mixer designs. The findings here indicate that differential evolution with truncated KL expansion can serve as an efficient and robust topology optimization method, proving particularly effective for solving optimization problems that are challenging for conventional gradient-based approaches. Notably, the proposed methodology not only delivers superior results but also alleviates computational burdens, thereby advancing the prospects of topology optimization in various engineering applications.},
  archive      = {J_ENGO},
  author       = {Kozo Furuta and Yasutoshi Tsukuda and Takamitsu Sasaki and Naoyuki Ishida and Kazuhiro Izui and Shinji Nishiwaki and Shinya Watanabe},
  doi          = {10.1080/0305215X.2024.2400558},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2419-2445},
  shortjournal = {Eng. Optim.},
  title        = {Differential evolution-based topology optimization using karhunen-loève expansion},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective-derived efficient energy saving in multipath routing for mobile ad hoc networks with the modified aquila–firefly heuristic strategy. <em>ENGO</em>, <em>57</em>(9), 2383-2418. (<a href='https://doi.org/10.1080/0305215X.2024.2399656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile ad hoc networks (MANETs) suffer from a major problem with the energy drainage of network nodes, as the mobile nodes rely on batteries and do not have a permanent power supply. Therefore, a new multipath routing technique, using a novel hybrid heuristic algorithm, is designed to solve the diverse metrics of a multi-objective function, including energy consumption, distance, routing overhead ratio, throughput, end-to-end delay and packet delivery ratio. This approach implements a new hybrid algorithm termed the modified aquila–firefly heuristic strategy (MA-FHS), which integrates the aquila optimizer and the firefly algorithm. This derived fitness function is applied to achieve optimal paths in multipath routing with minimization of the multi-objective function. The simulation demonstrates that the developed routing protocols outperformed traditional protocols under several network constraints.},
  archive      = {J_ENGO},
  author       = {P. Satyanarayana and G. Diwakar and V. Priyanka Brahmaiah and S. Marlin and N. V. Phani Sai Kumar and S. Gopalakrishnan},
  doi          = {10.1080/0305215X.2024.2399656},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2383-2418},
  shortjournal = {Eng. Optim.},
  title        = {Multi-objective-derived efficient energy saving in multipath routing for mobile ad hoc networks with the modified aquila–firefly heuristic strategy},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal product pricing and lot sizing decisions for an omni-channel supply chain. <em>ENGO</em>, <em>57</em>(9), 2349-2382. (<a href='https://doi.org/10.1080/0305215X.2024.2399642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an omni-channel supply chain, companies offer customers multiple channels to interact with their brand. This allows for greater outreach and sales, resulting in increased customer loyalty and trust. Furthermore, there has been little discussion on the simultaneous consideration of strategic and tactical decisions under return policies in omni-channel supply chains. To maximize total profit, this research proposes a two-echelon supply chain, comprising a manufacturer and multiple retailers, including traditional, electronic and omni-channels. The non-deterministic demand function takes into account the sales price, refund price, delivery time and order quantities. A heuristic algorithm based on analysis of Karush–Kuhn–Tucker optimality conditions used to solve a nonlinear programming model. This research presents an analysis of the factors influencing the decision variables and profit of the entire supply chain and offers retailers a unique way to evaluate their performance and make operational decisions regarding price, delivery time and order quantities.},
  archive      = {J_ENGO},
  author       = {Ghazaleh Saboori and G. Reza Nasiri and Hossein Salehi},
  doi          = {10.1080/0305215X.2024.2399642},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2349-2382},
  shortjournal = {Eng. Optim.},
  title        = {Optimal product pricing and lot sizing decisions for an omni-channel supply chain},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijcon">IJCON - 20</h2>
<ul>
<li><details>
<summary>
(2025). Output feedback near-optimal control of atomic force microscope. <em>IJCON</em>, <em>98</em>(9), 2245-2264. (<a href='https://doi.org/10.1080/00207179.2025.2454925'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a compact atomic force microscope (AFM) model based on a singular perturbation approach tailored for systems with relatively high cantilever stiffness. This method simplifies the model, allowing for a faster response to the Van der Waals interaction forces between the measurement sample and the cantilever tip. For scenarios where the tip-sample interaction force is unknown, the proposed model serves as the basis for designing a nonlinear, near-optimal feedback control technique. This control approach guides the cantilever tip along a desired trajectory while maintaining it vertically aligned at the balance point of attraction and repulsion forces. Additionally, a cascaded high-gain observer is designed to estimate AFM dynamics using only the measured piezo tube position. Combined with the near-optimal feedback control, this observer addresses the output feedback control problem. The proposed controller is validated through a simulation example.},
  archive      = {J_IJCON},
  author       = {Joshua L. Sutton and Mohammad Al Saaideh and Mohammad Al Janaideh and Almuatazbellah Boker},
  doi          = {10.1080/00207179.2025.2454925},
  journal      = {International Journal of Control},
  month        = {9},
  number       = {9},
  pages        = {2245-2264},
  shortjournal = {Int. J. Control},
  title        = {Output feedback near-optimal control of atomic force microscope},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel improved structural controllability method on complex temporal networks based on temporal ACO algorithm. <em>IJCON</em>, <em>98</em>(9), 2231-2244. (<a href='https://doi.org/10.1080/00207179.2025.2454916'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The controllability of complex temporal networks is an area of research focused on understanding how to guide or influence the behaviour of dynamic. Structural controllability is considered as one of the most prominent network controllability methods. Structural controllability uses the maximum matching algorithm to find the minimum set of control nodes. The maximum matching algorithm on temporal networks is a class of NP-hard problems. In this paper, a novel method based on temporal ACO algorithm is proposed to solve the maximum matching problem in structural controllability. The ACO algorithm has been adapted to temporal networks. The results of implementing the proposed method on real-world datasets demonstrate that the ACO algorithm has a good performance and has converged to the optimal solution with high speed. The results demonstrate that the proposed method has higher efficiency in finding driver nodes and algorithm execution speed compared to the basic structural controllability.},
  archive      = {J_IJCON},
  author       = {Zhengwei Xia and Feiyun Zhang and Na Li and Peyman Arebi},
  doi          = {10.1080/00207179.2025.2454916},
  journal      = {International Journal of Control},
  month        = {9},
  number       = {9},
  pages        = {2231-2244},
  shortjournal = {Int. J. Control},
  title        = {A novel improved structural controllability method on complex temporal networks based on temporal ACO algorithm},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strong stability exponential bound improvement for mode-constrained switching impulsive systems. <em>IJCON</em>, <em>98</em>(9), 2217-2230. (<a href='https://doi.org/10.1080/00207179.2025.2454912'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strong stability, defined by bounds that decay not only over time but also with the number of impulses, has been established as a requirement to ensure robustness properties for impulsive systems with respect to inputs or disturbances. Most existing results, however, only consider weak stability, where the bounds only decay with time. In this paper, we provide a method for calculating the maximum overshoot and the decay rate for strong global uniform exponential stability for nonlinear switched impulsive systems. We consider mode constrained switching, where not all transitions between subsystems are allowed, and where subsystems may exhibit unstable dynamics in the flow and/or jump maps. Based on direct and reverse mode-dependent average dwell-time and activation-time constraints, we derive stability bounds that can be improved by considering longer switching sequences. We provide an example that shows how to ensure the stability robustness of nonlinear systems with a global state weak linearisation.},
  archive      = {J_IJCON},
  author       = {Alexis J. Vallarella and José Luis Mancilla-Aguilar and Hernan Haimovich},
  doi          = {10.1080/00207179.2025.2454912},
  journal      = {International Journal of Control},
  month        = {9},
  number       = {9},
  pages        = {2217-2230},
  shortjournal = {Int. J. Control},
  title        = {Strong stability exponential bound improvement for mode-constrained switching impulsive systems},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Static anti-windup compensator design for autonomous guidance and control of quadrotors*. <em>IJCON</em>, <em>98</em>(9), 2205-2216. (<a href='https://doi.org/10.1080/00207179.2025.2454910'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of anti-windup compensator (AWC) design for implementation in the autonomous guidance and control of quadrotors is addressed. The flight environment contains obstacles with no prior knowledge of their locations. Instead, obstacles location are determined in real time, and the locations are used by a guidance algorithm for avoidance. Wind disturbances are also considered since their presence can potentially result in saturation of the propellers. When this occurs, the flight can become unstable, leading to a crash. Designing an AWC to mitigate the effects of saturation in the control system of a quadrotor can be a challenging task due to the heavy couplings and complex nonlinear dynamics. For this reason, we propose a new structure to design a static AWC-based control system to solve this problem. The effectiveness of the proposed theoretical results are verified by comparing results from simulation experiments.},
  archive      = {J_IJCON},
  author       = {Majid Shahbazzadeh and Christopher M. Richards},
  doi          = {10.1080/00207179.2025.2454910},
  journal      = {International Journal of Control},
  month        = {9},
  number       = {9},
  pages        = {2205-2216},
  shortjournal = {Int. J. Control},
  title        = {Static anti-windup compensator design for autonomous guidance and control of quadrotors*},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-consistent per-loss reinsurance and investment strategies in correlated markets with smooth ambiguity. <em>IJCON</em>, <em>98</em>(9), 2191-2204. (<a href='https://doi.org/10.1080/00207179.2025.2454908'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the time-consistent per-loss reinsurance and investment strategies in correlated markets for an insurer to maximise its mean-variance criterion, where the insurance market and financial market are correlated due to the so-called thinning dependence generated from an external stochastic source. We also consider the insurer's ambiguity towards the external source. Specifically, the intensity of the number of events from the external stochastic source cannot be estimated accurately, and hence is treated as a random variable following the insurer's prior distribution. We investigate the mean-variance optimisation problem under smooth ambiguity, which aims to search the optimal strategies in average case. By solving the extended Hamilton-Jacobi-Bellman(HJB) equations and using the Lagrange multiplier method, we derive the closed-form expressions for the equilibrium reinsurance and investment strategies. The results suggest that reinsurance may take two different forms, and that reinsurance strategies and investment strategies are influenced by each other. Finally, we analyse the property of strategies under one single factor and the interaction between thinning dependence and smooth ambiguity.},
  archive      = {J_IJCON},
  author       = {Fudong Wang and Zhibin Liang and Kam Chuen Yuen and Caibin Zhang},
  doi          = {10.1080/00207179.2025.2454908},
  journal      = {International Journal of Control},
  month        = {9},
  number       = {9},
  pages        = {2191-2204},
  shortjournal = {Int. J. Control},
  title        = {Time-consistent per-loss reinsurance and investment strategies in correlated markets with smooth ambiguity},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mobile robot path planning based on ORCA and improved DWA method. <em>IJCON</em>, <em>98</em>(9), 2175-2190. (<a href='https://doi.org/10.1080/00207179.2025.2454905'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focussed on the development of a dynamic and efficient obstacle avoidance path planning algorithm based on ORCA-DWA algorithm, which combines the Optimal Reciprocal Collision Avoidance (ORCA) algorithm and an improved Dynamic Window Approach (DWA), for improving the quality and efficiency of globally planned paths and ensuring obstacle avoidance between robots for local path planning. This combined ORCA-DWA approach effectively combines the speed of DWA planning with the preferred speed of the ORCA algorithm, it not only solves the problem of the ORCA algorithm's difficulty in determining the preferred speed, but also does not deviate from its optimal trajectory while avoiding obstacles. Additionally, an improved dynamic windowing method is proposed to enhance the adaptability to the environment. As a result, the mobile robot can not only use the DWA algorithm to achieve global path optimisation during navigation, but also achieve obstacle avoidance with the shortest time and path while following the robot's own constraints and considering the robot's radius. Simulation results prove that the method can greatly reduce the length and time of path planning and show that this new algorithm can make the robot's speed smoother.},
  archive      = {J_IJCON},
  author       = {Juan Dai and Yanzhang Jing and Zhong Su and Cui Zhu},
  doi          = {10.1080/00207179.2025.2454905},
  journal      = {International Journal of Control},
  month        = {9},
  number       = {9},
  pages        = {2175-2190},
  shortjournal = {Int. J. Control},
  title        = {Mobile robot path planning based on ORCA and improved DWA method},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tracking control of fully actuated ocean vehicles in a viscous incompressible fluid. <em>IJCON</em>, <em>98</em>(9), 2162-2174. (<a href='https://doi.org/10.1080/00207179.2025.2453501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of tracking control with a position tracking error constraint of ocean vehicles inside a viscous incompressible fluid, which is described by Navier–Stokes equations (NSEs) perturbed by fluid body force within a bounded domain in three-dimensional space. Since only weak solutions of the NSEs exist globally while global existence of their strong/smooth solutions is a millennium problem, point-wise fluid forces and moments acting on the ocean vehicle are not able to bound. This difficulty is overcome by an appropriate design of control laws and stability analysis of the closed-loop system including the NSEs using a proper extension of the vehicle body. The proposed control design ensures existence of a weak solution and practical exponential stability of the closed-loop system. A simulation on an omni-directional intelligent navigator illustrates the results.},
  archive      = {J_IJCON},
  author       = {K. D. Do},
  doi          = {10.1080/00207179.2025.2453501},
  journal      = {International Journal of Control},
  month        = {9},
  number       = {9},
  pages        = {2162-2174},
  shortjournal = {Int. J. Control},
  title        = {Tracking control of fully actuated ocean vehicles in a viscous incompressible fluid},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fillmore theorem-based approach to reduce zero sensitivity in discrete-time LTI controllers with infinite lifespan in homomorphic encrypted control systems. <em>IJCON</em>, <em>98</em>(9), 2155-2161. (<a href='https://doi.org/10.1080/00207179.2025.2453497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need of resetting a discrete-time LTI controller to work in an infinite time horizon in a homomorphic encrypted control system is avoided if this controller can be realised by a state space form possessing a state matrix with integer elements. Motivated by the usability of such state space forms in encrypted control systems, this paper proposes an approach to reduce the zero sensitivity resulted from the finite word-length effect by finding an appropriate state space realisation with an integer state matrix for a designed controller from an initial canonical realisation. This approach is constructed based on using the Fillmore theorem in linear algebra and matrix theory. The applicability of the proposed approach is evaluated by reducing the zero sensitivity in realisation of a sample controller previously applied in the relevant literature.},
  archive      = {J_IJCON},
  author       = {Mohammad Saleh Tavazoei},
  doi          = {10.1080/00207179.2025.2453497},
  journal      = {International Journal of Control},
  month        = {9},
  number       = {9},
  pages        = {2155-2161},
  shortjournal = {Int. J. Control},
  title        = {A fillmore theorem-based approach to reduce zero sensitivity in discrete-time LTI controllers with infinite lifespan in homomorphic encrypted control systems},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detection of kullback-leibler divergence-based attacks using coding matrix approach. <em>IJCON</em>, <em>98</em>(9), 2144-2154. (<a href='https://doi.org/10.1080/00207179.2025.2451713'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of detecting Kullback-Leibler (K-L) divergence-based attacks in cyber-physical systems (CPSs) is investigated. The influence of encryption matrix on K-L divergence has been analysed. In order to zoom in the K-L divergence of innovations in the presence and absence of attacks such that detection of the attack can be facilitated, a coding matrix is designed and inserted into the wireless transmission process. It has been proved that the K-L divergence between innovations in presence and absence of the attack will intrude the detection threshold if the secret coding matrix is designed appropriately. Sufficient conditions for the detection threshold to be intruded are provided, which essentially provide clues on how the coding matrix should be designed. Finally, simulation results are provided to verify the effectiveness of proposed detection strategy.},
  archive      = {J_IJCON},
  author       = {Chuanyi Ning and Zhiyu Xi},
  doi          = {10.1080/00207179.2025.2451713},
  journal      = {International Journal of Control},
  month        = {9},
  number       = {9},
  pages        = {2144-2154},
  shortjournal = {Int. J. Control},
  title        = {Detection of kullback-leibler divergence-based attacks using coding matrix approach},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prescribed-time stabilisation of stochastic high-order nonlinear systems with time-varying powers. <em>IJCON</em>, <em>98</em>(9), 2134-2143. (<a href='https://doi.org/10.1080/00207179.2025.2451712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A control strategy for stochastic nonlinear systems with time-varying high-order dynamics is presented in this paper, which is specifically designed for prescribed-time state-feedback stabilisation. The approach, based on the backstepping design, constructs a time-varying controller, utilising scaled quartic Lyapunov functions and the given scaling function is not used for coordinate transformation. The fundamental characteristic is that the system has a unique and strong solution, almost surely, is implemented for arbitrary initial conditions. The designed scheme ensures mean-square convergence of both state and input within a prescribed time. The validity of the theoretical framework is vividly verified through a numerical example, showcasing the practical application and efficiency of the control method.},
  archive      = {J_IJCON},
  author       = {Jianyang Du and Guici Chen and Song Zhu and Junhao Hu},
  doi          = {10.1080/00207179.2025.2451712},
  journal      = {International Journal of Control},
  month        = {9},
  number       = {9},
  pages        = {2134-2143},
  shortjournal = {Int. J. Control},
  title        = {Prescribed-time stabilisation of stochastic high-order nonlinear systems with time-varying powers},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-triggered resilient control of nonlinear multi-agent systems with disturbances under DoS attacks and directed switching topologies. <em>IJCON</em>, <em>98</em>(9), 2123-2133. (<a href='https://doi.org/10.1080/00207179.2025.2451707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the issue of resilient event-triggered consensus control for nonlinear multi-agent systems (MASs) operating in non-ideal communication networks. Specifically, it focuses on the challenges posed by directed switching topologies, disturbances and denial-of-service (DoS) attacks. A new approach is introduced to study the consensus tracking problem with a dynamic leader. The proposed strategy utilises a resilient event-triggered consensus tracking control framework, which comprises an event-triggered controller (ETC) and an event-triggering mechanism (ETM). By establishing matrix inequalities and considering parameters associated with DoS attacks and average dwell time, sufficient conditions for solving H ∞ consensus tracking problem are derived. One characteristic of the designed ETM is that events only occur at the triggering or switching time, preventing Zeno behaviour. Furthermore, a resilient event-triggered control strategy is suggested to tackle the containment problem with multiple dynamic leaders. Finally, the effectiveness of the designed control strategies is demonstrated through numerical simulations.},
  archive      = {J_IJCON},
  author       = {Dai Gao and Xi Jian and Jianting Lyu},
  doi          = {10.1080/00207179.2025.2451707},
  journal      = {International Journal of Control},
  month        = {9},
  number       = {9},
  pages        = {2123-2133},
  shortjournal = {Int. J. Control},
  title        = {Event-triggered resilient control of nonlinear multi-agent systems with disturbances under DoS attacks and directed switching topologies},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stability margins for multivariable linear time-invariant systems. <em>IJCON</em>, <em>98</em>(9), 2111-2122. (<a href='https://doi.org/10.1080/00207179.2025.2451706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, Singular Perturbation Margin (SPM) and Generalized Gain Margin (GGM) are used as the classical Phase Margin (PM) and Gain Margin (GM) like stability metrics for multivariable Linear Time-Invariant (LTI) systems established from the view of the singular perturbation and the regular perturbation, respectively. The bijective relationship between the SPM and PM of a multivariable LTI system is established as corresponding lemmas and theorems, which is a generalisation of the single input single output cases. The analysis process for SPM and GGM are provided here. All the theoretical results are shown by a two-input-two-output LTI system (a simple model of a two-body spacecraft with non-collocated sensors and actuators using position feedback) as an application example. Such results are one essential step towards the big map of establishing a set of both theoretically rigorous and physically meaningful stability margin metrics for NLTV systems.},
  archive      = {J_IJCON},
  author       = {Xiaojing Yang and J. Jim Zhu},
  doi          = {10.1080/00207179.2025.2451706},
  journal      = {International Journal of Control},
  month        = {9},
  number       = {9},
  pages        = {2111-2122},
  shortjournal = {Int. J. Control},
  title        = {Stability margins for multivariable linear time-invariant systems},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-consistent consumption, investment, and proportional reinsurance in market models with markovian regime switching. <em>IJCON</em>, <em>98</em>(9), 2089-2110. (<a href='https://doi.org/10.1080/00207179.2025.2451705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper outlines an analysis of equilibrium strategies within a game-theoretic framework addressing discounting stochastic scenarios involving consumption, investment, and reinsurance problems. The controlled state process follows a multi-dimensional linear stochastic differential equation influenced by Brownian motion and Poison jump process under a Markovian regime-switching environment. The objective functional encompasses both running and terminal costs explicitly linked to general discount functions, introducing time inconsistency in the model. Open-loop Nash equilibrium controls are detailed, supported by necessary and sufficient equilibrium conditions and a verification outcome. Furthermore, a state feedback equilibrium strategy is attained through a specific partial differential–difference equation. The study delves into investment consumption and equilibrium, reinsurance/new business strategies, specifically examining power and logarithmic utility functions in select cases. To validate the theoretical findings, a numerical example is presented, demonstrating their efficacy.},
  archive      = {J_IJCON},
  author       = {Nour El Houda Bouaicha and Farid Chighoub and Abhishek Pal Majumder},
  doi          = {10.1080/00207179.2025.2451705},
  journal      = {International Journal of Control},
  month        = {9},
  number       = {9},
  pages        = {2089-2110},
  shortjournal = {Int. J. Control},
  title        = {Time-consistent consumption, investment, and proportional reinsurance in market models with markovian regime switching},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-triggered synchronisation of unknown heterogeneous coupled harmonic oscillators. <em>IJCON</em>, <em>98</em>(9), 2081-2088. (<a href='https://doi.org/10.1080/00207179.2025.2450824'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This note concentrates on event-triggered synchronisation problem of unknown heterogeneous coupled harmonic oscillators (CHOs). We develop an event-triggered synchronisation algorithm that does not rely on any continuous information transmission among oscillators and global topology information. For this end, we first design an observer to estimate unknown system parameter for each oscillator. Second, each oscillator uses information received from its neighbours to estimate the frequency of leader oscillator and its neighbours' states. Based on estimated frequencies and states, we design an adaptive synchronisation algorithm for CHOs to solve synchronisation problem. We prove that CHOs, under proposed synchronisation algorithm, reach state synchronisation, and there is no Zeno behaviour. In the end, a simulation is presented to check proposed synchronisation algorithm.},
  archive      = {J_IJCON},
  author       = {Jiaojiao Zhuang and Zhenxing Li and Chengdong Yang and Mahmoud Abdel-Aty and Jinde Cao},
  doi          = {10.1080/00207179.2025.2450824},
  journal      = {International Journal of Control},
  month        = {9},
  number       = {9},
  pages        = {2081-2088},
  shortjournal = {Int. J. Control},
  title        = {Event-triggered synchronisation of unknown heterogeneous coupled harmonic oscillators},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized backstepping tracking control using reinforcement learning for strict-feedback nonlinear systems with monotone tube performance boundaries. <em>IJCON</em>, <em>98</em>(9), 2068-2080. (<a href='https://doi.org/10.1080/00207179.2024.2449132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently proposed monotone tube boundaries enhance performance but exacerbate the challenge of the entry capture problem (ECP). This article addresses the ECP under monotone tube boundaries and employs optimal control strategies combined with reinforcement learning (RL) to enhance performance in unknown state situations. By utilising error scaling functions (ESF), the proposed method effectively confines the error to a predefined neighbourhood in a specified time, without knowing the specific value of the initial error. Furthermore, this article innovatively incorporates the actor-critic structure into the monotone tube boundaries, significantly enhancing system performance. Due to the condition of state immeasurability, a neural network (NN)-based state observer is designed to estimate the states of the system. Additionally, command filters are used to simplify the multiple derivative calculations in traditional backstepping methods, addressing the ‘explosion of complexity’ problem. Mathematical derivations and simulation confirm its ability to meet predefined performance criteria.},
  archive      = {J_IJCON},
  author       = {Gengning Zhang and Xin Wang and Ziming Wang and Ning Pang},
  doi          = {10.1080/00207179.2024.2449132},
  journal      = {International Journal of Control},
  month        = {9},
  number       = {9},
  pages        = {2068-2080},
  shortjournal = {Int. J. Control},
  title        = {Optimized backstepping tracking control using reinforcement learning for strict-feedback nonlinear systems with monotone tube performance boundaries},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gain scheduled h∞ and h2 static output feedback control of discrete-time stochastic delayed systems. <em>IJCON</em>, <em>98</em>(9), 2057-2067. (<a href='https://doi.org/10.1080/00207179.2024.2449084'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of 𝐻 ∞ zero-order output-feedback control of state-delayed, discrete-time, state-multiplicative retarded linear systems with white noise signals multiplying both the delayed and non-delayed states of the system and the input signal. Based on the Bounded Real lemma (BRL) of these systems, a simple Linear Matrix Inequality (LMI) condition is obtained for the nominal case. The same condition is reshaped to solve the control problem for systems with polytopic-type uncertainties. The paper also addresses the stochastic H 2 counterpart of the H ∞ control problem for both nominal and uncertain polytopic cases. The approach proposed in the paper offers a simple and efficient solution to the H ∞ and H 2 control problems, especially for systems with uncertainties, and is expected to have practical applications in control engineering. The paper includes a numerical example that demonstrates the results of the various solution methods in this study.},
  archive      = {J_IJCON},
  author       = {E. Gershon and U. Shaked},
  doi          = {10.1080/00207179.2024.2449084},
  journal      = {International Journal of Control},
  month        = {9},
  number       = {9},
  pages        = {2057-2067},
  shortjournal = {Int. J. Control},
  title        = {Gain scheduled h∞ and h2 static output feedback control of discrete-time stochastic delayed systems},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed data-driven optimal synchronisation of multi-agent systems with input saturation. <em>IJCON</em>, <em>98</em>(9), 2040-2056. (<a href='https://doi.org/10.1080/00207179.2024.2447570'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses the optimal synchronisation problem of multi-agent systems with unknown system dynamics, where each agent is subject to both input saturation and external disturbances. A novel data-driven control approach is developed in this paper based on low-gain technique, output regulation, differential game theory, and adaptive dynamic programming (ADP). Unlike existing approaches to the data-driven optimal synchronisation problem, our method eliminates the need for an initially admissible stabilising control policy, and the proposed distributed control law ensures asymptotic tracking even in the presence of both modelling disturbances and unmodeled disturbances.},
  archive      = {J_IJCON},
  author       = {Xuan Cai and Gang Wang and Shuxin Liu},
  doi          = {10.1080/00207179.2024.2447570},
  journal      = {International Journal of Control},
  month        = {9},
  number       = {9},
  pages        = {2040-2056},
  shortjournal = {Int. J. Control},
  title        = {Distributed data-driven optimal synchronisation of multi-agent systems with input saturation},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stabilisation for multi-phase switched reluctance machine by a novel synchronisation of harmonic eradication mechanisms without resistance measurement and input-output relationships. <em>IJCON</em>, <em>98</em>(9), 2021-2039. (<a href='https://doi.org/10.1080/00207179.2024.2447060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concentrates on dealing with two problems of 8/6-type Multi-phase Switched Reluctance Machines (MSRMs). Two problems are the stabilisation of rotational speed and minimising the output torque ripple for this machine. For the first issue, the output torque of 8/6 MSRMs is stabilised by determining an optimal holding time for the switching process. Minimising the total output torque ripple facilitates the 8/6 MSRMs operating more smoothly and counteracts the mechanical vibrations. For the second issue, this paper proposed a new synchronisation of high-order harmonic eradication mechanisms (HF-HEM) based on the Radial Basis Function (RBF) neural network and a hyperbolic-secant-like-function hierarchical method. The proposed scheme not only eliminates the high-frequency harmonics but also stabilises the rotational speed of 8/6 MSRMs at the desired values. Finally, the mathematical analyses are given by theorems. All the stable performance and impressive effectiveness of the proposals will be validated in the simulation section.},
  archive      = {J_IJCON},
  author       = {Cam Thuy Vo Thi and Dung Manh Do and Khoat Nguyen Duc and Hai Xuan Le and Xuan Minh Phan},
  doi          = {10.1080/00207179.2024.2447060},
  journal      = {International Journal of Control},
  month        = {9},
  number       = {9},
  pages        = {2021-2039},
  shortjournal = {Int. J. Control},
  title        = {Stabilisation for multi-phase switched reluctance machine by a novel synchronisation of harmonic eradication mechanisms without resistance measurement and input-output relationships},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Practical predefined-time event-triggered consensus for second-order leader–follower multiagent systems with actuator faults. <em>IJCON</em>, <em>98</em>(9), 2008-2020. (<a href='https://doi.org/10.1080/00207179.2024.2446850'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article centres on the practical predefined-time event-triggered consensus tracking issue for second-order multiagent systems (MASs) with actuator faults. First, an adaptive disturbance observer is presented for accurately estimating the lumped disturbances within predefined time. Second, a predefined-time estimator is constructed to obtain estimations of the tracking errors. Finally, a novel event-triggered fault-tolerant control scheme is developed to realise consensus tracking within a predefined time. The Lyapunov method is used to demonstrate that MAS can realise the practical predefined-time leader–follower consensus and rule out Zeno behaviour completely. Furthermore, in contrast to existing findings, the settling time of the presented predefined-time control scheme is determined entirely by a preset value, which benefits the construction of the control scheme based on convergence time requirements. Finally, the presented scheme is applied to the attitude of cooperative control of multi-spacecraft systems, and numerical simulations confirm their effectiveness and superiority.},
  archive      = {J_IJCON},
  author       = {Hong Mei and Xin Wen and Wei Zhang and Dizhi Long and Jian Wang},
  doi          = {10.1080/00207179.2024.2446850},
  journal      = {International Journal of Control},
  month        = {9},
  number       = {9},
  pages        = {2008-2020},
  shortjournal = {Int. J. Control},
  title        = {Practical predefined-time event-triggered consensus for second-order leader–follower multiagent systems with actuator faults},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel output feedback disturbance rejection controller for Bouc–Wen hysteresis control systems. <em>IJCON</em>, <em>98</em>(9), 1999-2007. (<a href='https://doi.org/10.1080/00207179.2024.2443942'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper utilises the disturbance rejection technique to address a category of Bouc–Wen (BW) hysteresis systems, employing the equivalent input disturbance (EID) method. A novel output feedback hysteresis state estimator is formulated to estimate the virtual hysteresis state. Additionally, a constructed EID estimator is utilised to estimate the impact of the exogenous disturbances on the proposed system. It is necessary to construct a novel control law that integrates the EID estimation to provide adequate disturbance rejection performance. Utilising both a Lyapunov approach and the EID technique, we derive a collection of adequate conditions to guarantee the stability of the BW hysteresis systems. The representation of these conditions takes the form of linear matrix inequalities (LMIs). Finally, a numerical example illustrating the efficacy and practicality of the devised control strategy is used in conjunction with a real-world application called a piezo-positioning mechanical system.},
  archive      = {J_IJCON},
  author       = {Arumugam Arunkumar and Jenq-Lang Wu},
  doi          = {10.1080/00207179.2024.2443942},
  journal      = {International Journal of Control},
  month        = {9},
  number       = {9},
  pages        = {1999-2007},
  shortjournal = {Int. J. Control},
  title        = {A novel output feedback disturbance rejection controller for Bouc–Wen hysteresis control systems},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijss">IJSS - 10</h2>
<ul>
<li><details>
<summary>
(2025). Difference flatness of discrete-time linear time-delay systems and transformation to fully actuated systems. <em>IJSS</em>, <em>56</em>(13), 3243-3256. (<a href='https://doi.org/10.1080/00207721.2025.2530187'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the difference flatness of discrete-time linear time-delay systems (TDSs). Initially, by employing matrix augmentation techniques and model reduction methods, the discrete-time linear TDSs can be transformed into the discrete-time linear delay-free systems while preserving controllability equivalence. Subsequently, a coprime factorisation approach for the transfer function matrix of discrete-time linear delay-free systems is utilised to construct the flat output of the discrete-time linear TDSs. Based on this, the discrete-time linear TDSs can be equivalently transformed into the discrete-time fully actuated system (FAS) with the constructed flat output as the generalised state, and the pole assignment problem of discrete-time TDSs can be directly addressed. Numerical examples demonstrates the effectiveness of the proposed approach.},
  archive      = {J_IJSS},
  author       = {Yu Liu and Zhao-Yan Li and Xijing Hu},
  doi          = {10.1080/00207721.2025.2530187},
  journal      = {International Journal of Systems Science},
  month        = {10},
  number       = {13},
  pages        = {3243-3256},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Difference flatness of discrete-time linear time-delay systems and transformation to fully actuated systems},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active disturbance rejection control of hydraulic turbine based on fully actuated system theory. <em>IJSS</em>, <em>56</em>(13), 3234-3242. (<a href='https://doi.org/10.1080/00207721.2025.2506007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of stabilisation control of hydroelectric generating units. Firstly, the fully actuated system model of the linear hydraulic turbine is established by using the theory of fully actuated system. Then the control law is designed by using the direct parameterisation method, which can configure the closed-loop poles of the hydraulic turbine system expectation or region and ensure the stable operation of the hydraulic turbine regulating system with a small control gain. Finally, a nonlinear active disturbance rejection control method is proposed for the internal and external disturbances in the control of the fully actuated system. The simulation results demonstrate the effectiveness of the proposed control method.},
  archive      = {J_IJSS},
  author       = {Gengke Wang and Delong Yang and Lingling Lv and Zhongyang Li and Shuchun Zhao and Nan Zhao and Kangle Zheng and Qiuyan Li},
  doi          = {10.1080/00207721.2025.2506007},
  journal      = {International Journal of Systems Science},
  month        = {10},
  number       = {13},
  pages        = {3234-3242},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Active disturbance rejection control of hydraulic turbine based on fully actuated system theory},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrated control design for orbit injection of launchers via fully-actuated system approach. <em>IJSS</em>, <em>56</em>(13), 3216-3233. (<a href='https://doi.org/10.1080/00207721.2025.2487547'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the strong coupling and nonlinearity in dynamics, launchers often employ separate designs for guidance loop trajectory planning and attitude loop tracking control. While this simplified approach reduces problem complexity, it neglects the interaction between guidance and attitude control. In this paper, an integrated control design for orbit injection of launchers is proposed using a fully-actuated system approach, which offers interpretability and high flexibility for nonlinear systems. First, a refined time-varying model of the launcher is established, accounting for mass property variations caused by propellant consumption. Next, both guidance and attitude closed-loop error dynamics are parameterised through the fully-actuated system approach. Furthermore, the Lyapunov stability of the integrated closed-loop system is demonstrated by explicitly considering the influence of attitude tracking error on control force generation. Additionally, a constraint-compatible online optimisation scheme for feedback controller gains is proposed to adaptively meet multiple desired performance indicators as the system state evolves. Finally, a numerical simulation of orbit injection of a launcher is conducted to validate the effectiveness of the proposed controller.},
  archive      = {J_IJSS},
  author       = {Feng Zhang and Hao Sun and Haipeng Chen and Shengbao Wu},
  doi          = {10.1080/00207721.2025.2487547},
  journal      = {International Journal of Systems Science},
  month        = {10},
  number       = {13},
  pages        = {3216-3233},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Integrated control design for orbit injection of launchers via fully-actuated system approach},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-order fully actuated system approach for quadrotor control based on extended state observers. <em>IJSS</em>, <em>56</em>(13), 3194-3215. (<a href='https://doi.org/10.1080/00207721.2025.2512208'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quadrotor dynamics are characterized by underactuation, strong coupling, and susceptibility to external disturbances. Advanced control strategies are required to overcome these challenges and effectively execute desired maneuvers. This paper investigates the position and yaw tracking control of a 6-DOF quadrotor under practical disturbances. A high-order fully actuated (HOFA) approach is applied to reformulate the quadrotor model into three HOFA subsystems, which introduce high-order derivative terms of inputs, system states, and disturbances. To observe high-order terms and reject disturbances for control design, extended state observers (ESOs) are designed for the HOFA systems. The convergence of these ESOs is rigorously established using the Lyapunov stability theory. Simulation and experimental results are demonstrated to validate the effectiveness of the HOFA control design based on ESOs for quadrotors with practical disturbances, such as wind disturbances, aerodynamic drag, and ground effects.},
  archive      = {J_IJSS},
  author       = {Shi Lu and Konstantinos Tsakalis and Yan Chen},
  doi          = {10.1080/00207721.2025.2512208},
  journal      = {International Journal of Systems Science},
  month        = {10},
  number       = {13},
  pages        = {3194-3215},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {High-order fully actuated system approach for quadrotor control based on extended state observers},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Behavioral control for multiple omnidirectional mobile robots via fully actuated system approach. <em>IJSS</em>, <em>56</em>(13), 3177-3193. (<a href='https://doi.org/10.1080/00207721.2025.2506004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the collision-free formation control issue is investigated for a group of omnidirectional mobile robots with uncertain dynamics and external disturbances. To address this, a fully actuated behavioural control scheme is proposed by integrating the fully actuated system theory into the null-space-based behavioural control method. First, three distributed formation behaviours are developed by transforming the behavioural functions into a fully actuated configuration. Then, the asymptotic stability of these three behaviours and their null-space-based projection fusion are established using Lyapunov theory. Furthermore, a fully actuated sliding mode controller is designed for the over-actuated omnidirectional mobile robots to ensure asymptotic convergence at the dynamic level, thereby enabling the precise tracking of desired kinematic commands in the task space under model uncertainty. Finally, simulation results are provided to demonstrate that the closed-loop system is asymptotically stable, revealing the effectiveness of the proposed scheme. To ensure the repeatability, our codes are available on Github: https://github.com/EzekielMok/Fully-Actuated-Behavioral-Control.git .},
  archive      = {J_IJSS},
  author       = {Zhibin Mo and Wanquan Liu and Hui-Jie Sun},
  doi          = {10.1080/00207721.2025.2506004},
  journal      = {International Journal of Systems Science},
  month        = {10},
  number       = {13},
  pages        = {3177-3193},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Behavioral control for multiple omnidirectional mobile robots via fully actuated system approach},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parameter identification of FIR systems with binary-valued observations: When the event-driven communication mechanism encounters DoS attacks. <em>IJSS</em>, <em>56</em>(13), 3156-3176. (<a href='https://doi.org/10.1080/00207721.2025.2469814'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of technology, finite impulse response(FIR) is widely used in signal processing, communication and other fields, so it is of great significance to study its parameter identification problem. In the communication process of FIR systems, denial-of-service(DoS) attacks cause data packet loss, and the introduction of event-driven communication mechanism can reduce the sensitivity of the system to DoS attacks, however, the coupling of the two increases the difficulty of parameter identification. In this paper, we explore the problem of FIR parameter identification in the presence of DoS attacks and event-driven communication from the perspective of the defense side. Initially, the inadequacy of the original identification algorithm in estimating parameters during attacks is acknowledged. Compared to the original algorithm, the improved algorithm incorporates parameters of a model based on DoS attacks and analyzes its convergence performance. Subsequently, the trace of the asymptotic normal variance matrix of the improved identification algorithm is utilised as a metric to gauge the attack's effectiveness, leading to the design of an optimal attack strategy. Building upon the enhanced identification algorithm, adjustments are made to the event-driven mechanism, and an adaptive identification algorithm is formulated. The convergence performance of this algorithm is analysed, followed by the calculation of a communication rate aimed at optimisation based on selected indicators. Lastly, the paper concludes with an examination of the correctness and validity of the findings through numerical simulation.},
  archive      = {J_IJSS},
  author       = {Jiahua Fan and Ruizhe Jia and Kun Zhang and Jin Guo},
  doi          = {10.1080/00207721.2025.2469814},
  journal      = {International Journal of Systems Science},
  month        = {10},
  number       = {13},
  pages        = {3156-3176},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Parameter identification of FIR systems with binary-valued observations: When the event-driven communication mechanism encounters DoS attacks},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global prescribed-time control for a class of fully actuated nonlinear systems. <em>IJSS</em>, <em>56</em>(13), 3146-3155. (<a href='https://doi.org/10.1080/00207721.2025.2505713'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the prescribed-time stabilisation problem for a class of fully actuated nonlinear systems by utilising a unique prescribed-time adjustment function and a solution-parameter Lyapunov function. We introduce a control scheme that is tailored for these systems and offers simplicity and streamlined design compared to backstepping-based methods. Furthermore, we develop an adaptive control strategy for systems with uncertain parameters, introducing a time-varying adaptive controller that ensures stability within a predetermined timeframe. We validate the effectiveness of our approach through two simulation examples.},
  archive      = {J_IJSS},
  author       = {Pengju Ning and Changchun Hua and Hao Li},
  doi          = {10.1080/00207721.2025.2505713},
  journal      = {International Journal of Systems Science},
  month        = {10},
  number       = {13},
  pages        = {3146-3155},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Global prescribed-time control for a class of fully actuated nonlinear systems},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust model predictive control for robotic manipulators with fully actuated system approach based on learning modelling. <em>IJSS</em>, <em>56</em>(13), 3135-3145. (<a href='https://doi.org/10.1080/00207721.2025.2504639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article puts forward a robust model predictive control (MPC) strategy fortified by a learning model within the framework of fully actuated system (FAS) approach. The proposed strategy is crafted to tackle the control difficulties of robotic manipulators under the limitations of joint angles and angular velocities. By leveraging a radial basis function neural network (RBFNN) to offset the inaccuracies in the manipulator’s dynamic modelling, a FAS model with RBFNN is constructed. Based on this, the FAS approach is utilised to formulate the nominal controller, which can efficiently manage the nonlinear and coupled dynamics of the system. To deal with the disparities between the learning model and the actual system dynamics, the robust MPC is incorporated. This also ensures compliance with operating limits and improves the accuracy of the tracking control. Moreover, the iterative feasibility and stability analysis are completed. The effectiveness of the proposed method is validated through simulations with the Franka robotic numerical model.},
  archive      = {J_IJSS},
  author       = {Yi Heng Yang and Kai Zhang and Zhi Hua Chen and Bin Li},
  doi          = {10.1080/00207721.2025.2504639},
  journal      = {International Journal of Systems Science},
  month        = {10},
  number       = {13},
  pages        = {3135-3145},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Robust model predictive control for robotic manipulators with fully actuated system approach based on learning modelling},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). H∞ consensus control for high-order fully actuated multi-agent systems with external disturbances. <em>IJSS</em>, <em>56</em>(13), 3117-3134. (<a href='https://doi.org/10.1080/00207721.2025.2492301'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the H ∞ consensus control problem for high-order fully actuated multi-agent systems subject to external disturbances. Leveraging the unique characteristics of high-order fully actuated systems, distributed control protocols are designed that eliminate nonlinearities in the open-loop dynamics while establishing new closed-loop system behaviours. The H ∞ consensus problem is tackled for both undirected and directed communication graphs using the Kronecker product, inequality techniques, and the bounded real lemma. Linear matrix inequalities are employed to derive the design parameters for the control protocols. Additionally, a multi-spacecraft attitude model based on high-order fully actuated systems is proposed. Two illustrative examples are provided, one for an undirected graph and the other for a directed graph, to show the effectiveness and practical application of the proposed approach.},
  archive      = {J_IJSS},
  author       = {Qing-Hao Zhang and Jun-Guo Lu},
  doi          = {10.1080/00207721.2025.2492301},
  journal      = {International Journal of Systems Science},
  month        = {10},
  number       = {13},
  pages        = {3117-3134},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {H∞ consensus control for high-order fully actuated multi-agent systems with external disturbances},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fully actuated system theory and applications: New developments in 2024. <em>IJSS</em>, <em>56</em>(13), 3115-3116. (<a href='https://doi.org/10.1080/00207721.2025.2545079'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJSS},
  doi          = {10.1080/00207721.2025.2545079},
  journal      = {International Journal of Systems Science},
  month        = {10},
  number       = {13},
  pages        = {3115-3116},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Fully actuated system theory and applications: New developments in 2024},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jasa">JASA - 59</h2>
<ul>
<li><details>
<summary>
(2025). Objective bayesian inference. <em>JASA</em>, <em>120</em>(550), 1321-1322. (<a href='https://doi.org/10.1080/01621459.2025.2454051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JASA},
  author       = {Jaeyong Lee},
  doi          = {10.1080/01621459.2025.2454051},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1321-1322},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Objective bayesian inference},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Soccer analytics: An introduction using r. <em>JASA</em>, <em>120</em>(550), 1320-1321. (<a href='https://doi.org/10.1080/01621459.2024.2435110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JASA},
  author       = {Alexander Aue},
  doi          = {10.1080/01621459.2024.2435110},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1320-1321},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Soccer analytics: An introduction using r},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Handbook of bayesian, fiducial, and frequentist inference. <em>JASA</em>, <em>120</em>(550), 1318-1320. (<a href='https://doi.org/10.1080/01621459.2025.2454048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JASA},
  author       = {Mengyang Gu},
  doi          = {10.1080/01621459.2025.2454048},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1318-1320},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Handbook of bayesian, fiducial, and frequentist inference},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep regression learning with optimal loss function. <em>JASA</em>, <em>120</em>(550), 1305-1317. (<a href='https://doi.org/10.1080/01621459.2024.2412364'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we develop a novel efficient and robust nonparametric regression estimator under a framework of a feedforward neural network (FNN). There are several interesting characteristics for the proposed estimator. First, the loss function is built upon an estimated maximum likelihood function, which integrates the information from observed data as well as the information from the data distribution. Consequently, the resulting estimator has desirable optimal properties, such as efficiency. Second, different from the traditional maximum likelihood estimation (MLE), the proposed method avoids the specification of the distribution, making it adaptable to various distributions such as heavy tails and multimodal or heterogeneous distributions. Third, the proposed loss function relies on probabilities rather than direct observations as in least square loss, contributing to the robustness of the proposed estimator. Finally, the proposed loss function involves a nonparametric regression function only. This enables the direct application of the existing packages, simplifying the computational and programming requirements. We establish the large sample property of the proposed estimator in terms of its excess risk and minimax near-optimal rate. The theoretical results demonstrate that the proposed estimator is equivalent to the true MLE where the density function is known in terms of excess risk. Our simulation studies show that the proposed estimator outperforms the existing methods based on prediction accuracy, efficiency and robustness. Particularly, it is comparable to the MLE with the known density and even gets slightly better as the sample size increases. This implies that the adaptive and data-driven loss function from the estimated density may offer an additional avenue for capturing valuable information. We further apply the proposed method to four real data examples, resulting in significantly reduced out-of-sample prediction errors compared to existing methods. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Xuancheng Wang and Ling Zhou and Huazhen Lin},
  doi          = {10.1080/01621459.2024.2412364},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1305-1317},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Deep regression learning with optimal loss function},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust permutation tests in linear instrumental variables regression. <em>JASA</em>, <em>120</em>(550), 1294-1304. (<a href='https://doi.org/10.1080/01621459.2024.2412363'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article develops permutation versions of identification-robust tests in linear instrumental variables regression. Unlike the existing randomization and rank-based tests in which independence between the instruments and the error terms is assumed, the permutation Anderson-Rubin (AR), Lagrange Multiplier (LM) and Conditional Likelihood Ratio (CLR) tests are asymptotically similar and robust to conditional heteroscedasticity under standard exclusion restriction, that is, the orthogonality between the instruments and the error terms. Moreover, when the instruments are independent of the structural error term, the permutation AR tests are exact, hence, robust to heavy tails. As such, these tests share the strengths of the rank-based tests and the wild bootstrap AR tests. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Purevdorj Tuvaandorj},
  doi          = {10.1080/01621459.2024.2412363},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1294-1304},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Robust permutation tests in linear instrumental variables regression},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A sparse beta regression model for network analysis. <em>JASA</em>, <em>120</em>(550), 1281-1293. (<a href='https://doi.org/10.1080/01621459.2024.2411073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For statistical analysis of network data, the 𝛽 -model has emerged as a useful tool, thanks to its flexibility in incorporating nodewise heterogeneity and theoretical tractability. To generalize the β -model, this article proposes the Sparse β -Regression Model (S β RM) that unites two research themes developed recently in modeling homophily and sparsity. In particular, we employ differential heterogeneity that assigns weights only to important nodes and propose penalized likelihood with an l 1 penalty for parameter estimation. While our estimation method is closely related to the LASSO method for logistic regression, we develop a new theory emphasizing the use of our model for dealing with a parameter regime that can handle sparse networks usually seen in practice. More interestingly, the resulting inference on the homophily parameter demands no debiasing normally employed in LASSO type estimation. We provide extensive simulation and data analysis to illustrate the use of the model. As a special case of our model, we extend the Erdős-Rényi model by including covariates and develop the associated statistical inference for sparse networks, which may be of independent interest. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Stefan Stein and Rui Feng and Chenlei Leng},
  doi          = {10.1080/01621459.2024.2411073},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1281-1293},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {A sparse beta regression model for network analysis},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Iterative methods for vecchia-laplace approximations for latent gaussian process models. <em>JASA</em>, <em>120</em>(550), 1267-1280. (<a href='https://doi.org/10.1080/01621459.2024.2410004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Latent Gaussian process (GP) models are flexible probabilistic nonparametric function models. Vecchia approximations are accurate approximations for GPs to overcome computational bottlenecks for large data, and the Laplace approximation is a fast method with asymptotic convergence guarantees to approximate marginal likelihoods and posterior predictive distributions for non-Gaussian likelihoods. Unfortunately, the computational complexity of combined Vecchia-Laplace approximations grows faster than linearly in the sample size when used in combination with direct solver methods such as the Cholesky decomposition. Computations with Vecchia-Laplace approximations can thus become prohibitively slow precisely when the approximations are usually the most accurate, that is, on large datasets. In this article, we present iterative methods to overcome this drawback. Among other things, we introduce and analyze several preconditioners, derive new convergence results, and propose novel methods for accurately approximating predictive variances. We analyze our proposed methods theoretically and in experiments with simulated and real-world data. In particular, we obtain a speed-up of an order of magnitude compared to Cholesky-based calculations and a 3-fold increase in prediction accuracy in terms of the continuous ranked probability score compared to a state-of-the-art method on a large satellite dataset. All methods are implemented in a free C++ software library with high-level Python and R packages. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Pascal Kündig and Fabio Sigrist},
  doi          = {10.1080/01621459.2024.2410004},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1267-1280},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Iterative methods for vecchia-laplace approximations for latent gaussian process models},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive learning of the latent space of wasserstein generative adversarial networks. <em>JASA</em>, <em>120</em>(550), 1254-1266. (<a href='https://doi.org/10.1080/01621459.2024.2408778'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative models based on latent variables, such as generative adversarial networks (GANs) and variational auto-encoders (VAEs), have gained lots of interests due to their impressive performance in many fields. However, many data such as natural images usually do not populate the ambient Euclidean space but instead reside in a lower-dimensional manifold. Thus an inappropriate choice of the latent dimension fails to uncover the structure of the data, possibly resulting in mismatch of latent representations and poor generative qualities. Toward addressing these problems, we propose a novel framework called the latent Wasserstein GAN (LWGAN) that fuses the Wasserstein auto-encoder and the Wasserstein GAN so that the intrinsic dimension of the data manifold can be adaptively learned by a modified informative latent distribution. We prove that there exist an encoder network and a generator network in such a way that the intrinsic dimension of the learned encoding distribution is equal to the dimension of the data manifold. We theoretically establish that our estimated intrinsic dimension is a consistent estimate of the true dimension of the data manifold. Meanwhile, we provide an upper bound on the generalization error of LWGAN, implying that we force the synthetic data distribution to be similar to the real data distribution from a population perspective. Comprehensive empirical experiments verify our framework and show that LWGAN is able to identify the correct intrinsic dimension under several scenarios, and simultaneously generate high-quality synthetic data by sampling from the learned latent distribution. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Yixuan Qiu and Qingyi Gao and Xiao Wang},
  doi          = {10.1080/01621459.2024.2408778},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1254-1266},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Adaptive learning of the latent space of wasserstein generative adversarial networks},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inferring covariance structure from multiple data sources via subspace factor analysis. <em>JASA</em>, <em>120</em>(550), 1239-1253. (<a href='https://doi.org/10.1080/01621459.2024.2408777'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Factor analysis provides a canonical framework for imposing lower-dimensional structure such as sparse covariance in high-dimensional data. High-dimensional data on the same set of variables are often collected under different conditions, for instance in reproducing studies across research groups. In such cases, it is natural to seek to learn the shared versus condition-specific structure. Existing hierarchical extensions of factor analysis have been proposed, but face practical issues including identifiability problems. To address these shortcomings, we propose a class of SUbspace Factor Analysis (SUFA) models, which characterize variation across groups at the level of a lower-dimensional subspace. We prove that the proposed class of SUFA models lead to identifiability of the shared versus group-specific components of the covariance, and study their posterior contraction properties. Taking a Bayesian approach, these contributions are developed alongside efficient posterior computation algorithms. Our sampler fully integrates out latent variables, is easily parallelizable and has complexity that does not depend on sample size. We illustrate the methods through application to integration of multiple gene expression datasets relevant to immunology. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Noirrit Kiran Chandra and David B. Dunson and Jason Xu},
  doi          = {10.1080/01621459.2024.2408777},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1239-1253},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Inferring covariance structure from multiple data sources via subspace factor analysis},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A model-agnostic graph neural network for integrating local and global information. <em>JASA</em>, <em>120</em>(550), 1225-1238. (<a href='https://doi.org/10.1080/01621459.2024.2404668'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have achieved promising performance in a variety of graph-focused tasks. Despite their success, however, existing GNNs suffer from two significant limitations: a lack of interpretability in their results due to their black-box nature, and an inability to learn representations of varying orders. To tackle these issues, we propose a novel Model-agnostic Graph Neural Network (MaGNet) framework, which is able to effectively integrate information of various orders, extract knowledge from high-order neighbors, and provide meaningful and interpretable results by identifying influential compact graph structures. In particular, MaGNet consists of two components: an estimation model for the latent representation of complex relationships under graph topology, and an interpretation model that identifies influential nodes, edges, and node features. Theoretically, we establish the generalization error bound for MaGNet via empirical Rademacher complexity, and demonstrate its power to represent layer-wise neighborhood mixing. We conduct comprehensive numerical studies using simulated data to demonstrate the superior performance of MaGNet in comparison to several state-of-the-art alternatives. Furthermore, we apply MaGNet to a real-world case study aimed at extracting task-critical information from brain activity data, thereby highlighting its effectiveness in advancing scientific research. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Wenzhuo Zhou and Annie Qu and Keiland W. Cooper and Norbert Fortin and Babak Shahbaba},
  doi          = {10.1080/01621459.2024.2404668},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1225-1238},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {A model-agnostic graph neural network for integrating local and global information},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimating higher-order mixed memberships via the l2,∞ tensor perturbation bound. <em>JASA</em>, <em>120</em>(550), 1214-1224. (<a href='https://doi.org/10.1080/01621459.2024.2404265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Higher-order multiway data is ubiquitous in machine learning and statistics and often exhibits community-like structures, where each component (node) along each different mode has a community membership associated with it. In this article we propose the sub-Gaussian) tensor mixed-membership blockmodel , a generalization of the tensor blockmodel positing that memberships need not be discrete, but instead are convex combinations of latent communities. We establish the identifiability of our model and propose a computationally efficient estimation procedure based on the higher-order orthogonal iteration algorithm (HOOI) for tensor SVD composed with a simplex corner-finding algorithm. We then demonstrate the consistency of our estimation procedure by providing a per-node error bound under sub-Gaussian noise, which showcases the effect of higher-order structures on estimation accuracy. To prove our consistency result, we develop the l 2 , ∞ tensor perturbation bound for HOOI under independent, heteroscedastic, sub-Gaussian noise that may be of independent interest. Our analysis uses a novel leave-one-out construction for the iterates, and our bounds depend only on spectral properties of the underlying low-rank tensor under nearly optimal signal-to-noise ratio conditions such that tensor SVD is computationally feasible. Finally, we apply our methodology to real and simulated data, demonstrating some effects not identifiable from the model with discrete community memberships. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Joshua Agterberg and Anru R. Zhang},
  doi          = {10.1080/01621459.2024.2404265},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1214-1224},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Estimating higher-order mixed memberships via the l2,∞ tensor perturbation bound},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive transfer learning framework for functional classification. <em>JASA</em>, <em>120</em>(550), 1201-1213. (<a href='https://doi.org/10.1080/01621459.2024.2403788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we study the transfer learning problem in functional classification, aiming to improve the classification accuracy of the target data by leveraging information from related source datasets. To facilitate transfer learning, we propose a novel transferability function tailored for classification problems, enabling a more accurate evaluation of the similarity between source and target dataset distributions. Interestingly, we find that a source dataset can offer more substantial benefits under certain conditions than another dataset with an identical distribution to the target dataset. This observation renders the commonly-used debiasing step in the parameter-based transfer learning algorithm unnecessary under some circumstances to the classification problem. In particular, we propose two adaptive transfer learning algorithms based on the functional Distance Weighted Discrimination (DWD) classifier for scenarios with and without prior knowledge regarding informative sources. Furthermore, we establish the upper bound on the excess risk of the proposed classifiers, providing the statistical gain via transfer learning mathematically provable. Simulation studies are conducted to thoroughly examine the finite-sample performance of the proposed algorithms. Finally, we implement the proposed method to Beijing air-quality data, and significantly improve the prediction of the PM 2.5 level of a target station by effectively incorporating information from source datasets. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Caihong Qin and Jinhan Xie and Ting Li and Yang Bai},
  doi          = {10.1080/01621459.2024.2403788},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1201-1213},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {An adaptive transfer learning framework for functional classification},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large-scale low-rank gaussian process prediction with support points. <em>JASA</em>, <em>120</em>(550), 1189-1200. (<a href='https://doi.org/10.1080/01621459.2024.2403188'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-rank approximation is a popular strategy to tackle the “big n problem” associated with large-scale Gaussian process regressions. Basis functions for developing low-rank structures are crucial and should be carefully specified. Predictive processes simplify the problem by inducing basis functions with a covariance function and a set of knots. The existing literature suggests certain practical implementations of knot selection and covariance estimation; however, theoretical foundations explaining the influence of these two factors on predictive processes are lacking. In this article, the asymptotic prediction performance of the predictive process and Gaussian process predictions are derived and the impacts of the selected knots and estimated covariance are studied. The use of support points as knots, which best represent data locations, is advocated. Extensive simulation studies demonstrate the superiority of support points and verify our theoretical results. Real data of precipitation and ozone are used as examples, and the efficiency of our method over other widely used low-rank approximation methods is verified. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Yan Song and Wenlin Dai and Marc G. Genton},
  doi          = {10.1080/01621459.2024.2403188},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1189-1200},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Large-scale low-rank gaussian process prediction with support points},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-based clustering of categorical data based on the hamming distance. <em>JASA</em>, <em>120</em>(550), 1178-1188. (<a href='https://doi.org/10.1080/01621459.2024.2402568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A model-based approach is developed for clustering categorical data with no natural ordering. The proposed method exploits the Hamming distance to define a family of probability mass functions to model the data. The elements of this family are then considered as kernels of a finite mixture model with an unknown number of components. Conjugate Bayesian inference has been derived for the parameters of the Hamming distribution model. The mixture is framed in a Bayesian nonparametric setting, and a transdimensional blocked Gibbs sampler is developed to provide full Bayesian inference on the number of clusters, their structure, and the group-specific parameters, facilitating the computation with respect to customary reversible jump algorithms. The proposed model encompasses a parsimonious latent class model as a special case when the number of components is fixed. Model performances are assessed via a simulation study and reference datasets, showing improvements in clustering recovery over existing approaches. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Raffaele Argiento and Edoardo Filippi-Mazzola and Lucia Paci},
  doi          = {10.1080/01621459.2024.2402568},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1178-1188},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Model-based clustering of categorical data based on the hamming distance},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neyman-pearson multi-class classification via cost-sensitive learning. <em>JASA</em>, <em>120</em>(550), 1164-1177. (<a href='https://doi.org/10.1080/01621459.2024.2402567'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing classification methods aim to minimize the overall misclassification error rate. However, in applications such as loan default prediction, different types of errors can have varying consequences. To address this asymmetry issue, two popular paradigms have been developed: the Neyman-Pearson (NP) paradigm and the cost-sensitive (CS) paradigm. Previous studies on the NP paradigm have primarily focused on the binary case, while the multi-class NP problem poses a greater challenge due to its unknown feasibility. In this work, we tackle the multi-class NP problem by establishing a connection with the CS problem via strong duality and propose two algorithms. We extend the concept of NP oracle inequalities, crucial in binary classifications, to NP oracle properties in the multi-class context. Our algorithms satisfy these NP oracle properties under certain conditions. Furthermore, we develop practical algorithms to assess the feasibility and strong duality in multi-class NP problems, which can offer practitioners the landscape of a multi-class NP problem with various target error levels. Simulations and real data studies validate the effectiveness of our algorithms. To our knowledge, this is the first study to address the multi-class NP problem with theoretical guarantees. The proposed algorithms have been implemented in the R package npcs , which is available on CRAN. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Ye Tian and Yang Feng},
  doi          = {10.1080/01621459.2024.2402567},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1164-1177},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Neyman-pearson multi-class classification via cost-sensitive learning},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On optimality of mallows model averaging. <em>JASA</em>, <em>120</em>(550), 1152-1163. (<a href='https://doi.org/10.1080/01621459.2024.2402566'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past decades, model averaging (MA) has attracted much attention as it has emerged as an alternative tool to the model selection (MS) statistical approach. Hansen introduced a Mallows model averaging (MMA) method with model weights selected by minimizing a Mallows’ C p criterion. The main theoretical justification for MMA is an asymptotic optimality (AOP), which states that the risk/loss of the resulting MA estimator is asymptotically equivalent to that of the best but infeasible averaged model. MMA’s AOP is proved in the literature by either constraining weights in a special discrete weight set or limiting the number of candidate models. In this work, it is first shown that under these restrictions, however, the optimal risk of MA becomes an unreachable target, and MMA may converge more slowly than MS. In this background, a foundational issue that has not been addressed is: When a suitably large set of candidate models is considered, and the model weights are not harmfully constrained, can the MMA estimator perform asymptotically as well as the optimal convex combination of the candidate models? We answer this question in both nested and non-nested settings. In the nested setting, we provide finite sample inequalities for the risk of MMA and show that without unnatural restrictions on the candidate models, MMA’s AOP holds in a general continuous weight set under certain mild conditions. In the non-nested setting, a sufficient condition and a negative result are established for the achievability of the optimal MA risk. Implications on minimax adaptivity are given as well. The results from simulations and real data analysis back up our theoretical findings. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Jingfu Peng and Yang Li and Yuhong Yang},
  doi          = {10.1080/01621459.2024.2402566},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1152-1163},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {On optimality of mallows model averaging},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust estimation for number of factors in high dimensional factor modeling via spearman correlation matrix. <em>JASA</em>, <em>120</em>(550), 1139-1151. (<a href='https://doi.org/10.1080/01621459.2024.2402565'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining the number of factors in high-dimensional factor modeling is essential but challenging, especially when the data are heavy-tailed. In this article, we introduce a new estimator based on the spectral properties of Spearman sample correlation matrix under the high-dimensional setting, where both dimension and sample size tend to infinity proportionally. Our estimator is robust against heavy tails in either the common factors or idiosyncratic errors. The consistency of our estimator is established under mild conditions. Numerical experiments demonstrate the superiority of our estimator compared to existing methods. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Jiaxin Qiu and Zeng Li and Jianfeng Yao},
  doi          = {10.1080/01621459.2024.2402565},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1139-1151},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Robust estimation for number of factors in high dimensional factor modeling via spearman correlation matrix},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Valid inference after causal discovery. <em>JASA</em>, <em>120</em>(550), 1127-1138. (<a href='https://doi.org/10.1080/01621459.2024.2402089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal discovery and causal effect estimation are two fundamental tasks in causal inference. While many methods have been developed for each task individually, statistical challenges arise when applying these methods jointly: estimating causal effects after running causal discovery algorithms on the same data leads to “double dipping,” invalidating the coverage guarantees of classical confidence intervals. To this end, we develop tools for valid post-causal-discovery inference. Across empirical studies, we show that a naive combination of causal discovery and subsequent inference algorithms leads to highly inflated miscoverage rates; on the other hand, applying our method provides reliable coverage while allowing for a trade-off between causal discovery accuracy and confidence interval width. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Paula Gradu and Tijana Zrnic and Yixin Wang and Michael I. Jordan},
  doi          = {10.1080/01621459.2024.2402089},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1127-1138},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Valid inference after causal discovery},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving tensor regression by optimal model averaging. <em>JASA</em>, <em>120</em>(550), 1115-1126. (<a href='https://doi.org/10.1080/01621459.2024.2398164'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensors have broad applications in neuroimaging, data mining, digital marketing, etc. CANDECOMP/PARAFAC (CP) tensor decomposition can effectively reduce the number of parameters to gain dimensionality-reduction and thus plays a key role in tensor regression. However, in CP decomposition, there is uncertainty about which rank to use. In this article, we develop a model averaging method to handle this uncertainty by weighting the estimators from candidate tensor regression models with different ranks. When all candidate models are misspecified, we prove that the model averaging estimator is asymptotically optimal. When correct models are included in the set of candidate models, we prove the consistency of parameters and the convergence of the model averaging weight. Simulations and empirical studies illustrate that the proposed method has superiority over the competition methods and has promising applications. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Qiushi Bu and Hua Liang and Xinyu Zhang and Jiahui Zou},
  doi          = {10.1080/01621459.2024.2398164},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1115-1126},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Improving tensor regression by optimal model averaging},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Off-policy evaluation in doubly inhomogeneous environments. <em>JASA</em>, <em>120</em>(550), 1102-1114. (<a href='https://doi.org/10.1080/01621459.2024.2395593'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work aims to study off-policy evaluation (OPE) under scenarios where two key reinforcement learning (RL) assumptions—temporal stationarity and individual homogeneity are both violated. To handle the “double inhomogeneities”, we propose a class of latent factor models for the reward and transition functions, under which we develop a general OPE framework that consists of both model-based and model-free approaches. To our knowledge, this is the first article that develops statistically sound OPE methods in offline RL with double inhomogeneities. It contributes to a deeper understanding of OPE in environments, where standard RL assumptions are not met, and provides several practical approaches in these settings. We establish the theoretical properties of the proposed value estimators and empirically show that our approach outperforms state-of-the-art methods. Finally, we illustrate our method on a dataset from the Medical Information Mart for Intensive Care. An R implementation of the proposed procedure is available at https://github.com/ZeyuBian/2FEOPE . Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Zeyu Bian and Chengchun Shi and Zhengling Qi and Lan Wang},
  doi          = {10.1080/01621459.2024.2395593},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1102-1114},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Off-policy evaluation in doubly inhomogeneous environments},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-based causal feature selection for general response types. <em>JASA</em>, <em>120</em>(550), 1090-1101. (<a href='https://doi.org/10.1080/01621459.2024.2395588'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discovering causal relationships from observational data is a fundamental yet challenging task. Invariant causal prediction (ICP, Peters, Bühlmann, and Meinshausen) is a method for causal feature selection which requires data from heterogeneous settings and exploits that causal models are invariant. ICP has been extended to general additive noise models and to nonparametric settings using conditional independence tests. However, the latter often suffer from low power (or poor Type I error control) and additive noise models are not suitable for applications in which the response is not measured on a continuous scale, but reflects categories or counts. Here, we develop transformation-model ( tram ) based ICP, allowing for continuous, categorical, count-type, and uninformatively censored responses (these model classes, generally, do not allow for identifiability when there is no exogenous heterogeneity). As an invariance test, we propose tram -GCM based on the expected conditional covariance between environments and score residuals with uniform asymptotic level guarantees. For the special case of linear shift tram s, we also consider tram -Wald, which tests invariance based on the Wald statistic. We provide an open-source R package tramicp and evaluate our approach on simulated data and in a case study investigating causal features of survival in critically ill patients. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Lucas Kook and Sorawit Saengkyongam and Anton Rask Lundborg and Torsten Hothorn and Jonas Peters},
  doi          = {10.1080/01621459.2024.2395588},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1090-1101},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Model-based causal feature selection for general response types},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zigzag path connects two monte carlo samplers: Hamiltonian counterpart to a piecewise deterministic markov process. <em>JASA</em>, <em>120</em>(550), 1077-1089. (<a href='https://doi.org/10.1080/01621459.2024.2395587'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zigzag and other piecewise deterministic Markov process samplers have attracted significant interest for their non-reversibility and other appealing properties for Bayesian posterior computation. Hamiltonian Monte Carlo is another state-of-the-art sampler, exploiting fictitious momentum to guide Markov chains through complex target distributions. We establish an important connection between the zigzag sampler and a variant of Hamiltonian Monte Carlo based on Laplace-distributed momentum. The position and velocity component of the corresponding Hamiltonian dynamics travels along a zigzag path paralleling the Markovian zigzag process; however, the dynamics is non-Markovian in this position-velocity space as the momentum component encodes non-immediate pasts. This information is partially lost during a momentum refreshment step, in which we preserve its direction but resample magnitude. In the limit of increasingly frequent momentum refreshments, we prove that Hamiltonian zigzag converges strongly to its Markovian counterpart. This theoretical insight suggests that, when retaining full momentum information, Hamiltonian zigzag can better explore target distributions with highly correlated parameters by suppressing the diffusive behavior of Markovian zigzag. We corroborate this intuition by comparing performance of the two zigzag cousins on high-dimensional truncated multivariate Gaussians, including a 11,235-dimensional target arising from a Bayesian phylogenetic multivariate probit modeling of HIV virus data. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Akihiko Nishimura and Zhenyu Zhang and Marc A. Suchard},
  doi          = {10.1080/01621459.2024.2395587},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1077-1089},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Zigzag path connects two monte carlo samplers: Hamiltonian counterpart to a piecewise deterministic markov process},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monte carlo inference for semiparametric bayesian regression. <em>JASA</em>, <em>120</em>(550), 1063-1076. (<a href='https://doi.org/10.1080/01621459.2024.2395586'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data transformations are essential for broad applicability of parametric regression models. However, for Bayesian analysis, joint inference of the transformation and model parameters typically involves restrictive parametric transformations or nonparametric representations that are computationally inefficient and cumbersome for implementation and theoretical analysis, which limits their usability in practice. This article introduces a simple, general, and efficient strategy for joint posterior inference of an unknown transformation and all regression model parameters. The proposed approach directly targets the posterior distribution of the transformation by linking it with the marginal distributions of the independent and dependent variables, and then deploys a Bayesian nonparametric model via the Bayesian bootstrap. Crucially, this approach delivers (a) joint posterior consistency under general conditions, including multiple model misspecifications, and (b) efficient Monte Carlo (not Markov chain Monte Carlo) inference for the transformation and all parameters for important special cases. These tools apply across a variety of data domains, including real-valued, positive, and compactly-supported data. Simulation studies and an empirical application demonstrate the effectiveness and efficiency of this strategy for semiparametric Bayesian analysis with linear models, quantile regression, and Gaussian processes. The R package SeBR is available on CRAN. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Daniel R. Kowal and Bohan Wu},
  doi          = {10.1080/01621459.2024.2395586},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1063-1076},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Monte carlo inference for semiparametric bayesian regression},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal network pairwise comparison. <em>JASA</em>, <em>120</em>(550), 1048-1062. (<a href='https://doi.org/10.1080/01621459.2024.2393471'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are interested in the problem of two-sample network hypothesis testing: given two networks with the same set of nodes, we wish to test whether the underlying Bernoulli probability matrices of the two networks are the same or not. We propose Interlacing Balance Measure (IBM) as a new two-sample testing approach. We consider the Degree-Corrected Mixed-Membership (DCMM) model for undirected networks, where we allow severe degree heterogeneity, mixed-memberships, flexible sparsity levels, and weak signals. In such a broad setting, how to find a test that has a tractable limiting null and optimal testing performances is a challenging problem. We show that IBM is such a test: in a broad DCMM setting with only mild regularity conditions, IBM has N ( 0 , 1 ) as the limiting null and achieves the optimal phase transition. While the above is for undirected networks, IBM is a unified approach and is directly implementable for directed networks. For a broad directed-DCMM (extension of DCMM for directed networks) setting, we show that IBM has N ( 0 , 1 / 2 ) as the limiting null and continues to achieve the optimal phase transition. We have also applied IBM to the Enron email network and a gene co-expression network, with interesting results. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Jiashun Jin and Zheng Tracy Ke and Shengming Luo and Yucong Ma},
  doi          = {10.1080/01621459.2024.2393471},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1048-1062},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Optimal network pairwise comparison},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised triply robust inductive transfer learning. <em>JASA</em>, <em>120</em>(550), 1037-1047. (<a href='https://doi.org/10.1080/01621459.2024.2393463'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a Semi-supervised Triply Robust Inductive transFer LEarning (STRIFLE) approach, which integrates heterogeneous data from a label-rich source population and a label-scarce target population and uses a large amount of unlabeled data simultaneously to improve the learning accuracy in the target population. Specifically, we consider a high dimensional covariate shift setting and employ two nuisance models, a density ratio model and an imputation model, to combine transfer learning and surrogate-assisted semi-supervised learning strategies effectively and achieve triple robustness. While the STRIFLE approach assumes the target and source populations to share the same conditional distribution of outcome Y given both the surrogate features S and predictors X , it allows the true underlying model of Y⏧ X to differ between the two populations due to the potential covariate shift in S and X . Different from double robustness, even if both nuisance models are misspecified or the distribution of Y⏧ S , X is not the same between the two populations when the shifted source population and the target population share enough similarities, the triply robust STRIFLE estimator can still partially use the source population when the shifted source population and the target population share enough similarities. Moreover, it is guaranteed to be no worse than the target-only surrogate-assisted semi-supervised estimator with an additional error term from transferability detection. These desirable properties of our estimator are established theoretically and verified in finite samples via extensive simulation studies. We use the STRIFLE estimator to train a Type II diabetes polygenic risk prediction model for the African American target population by transferring knowledge from electronic health records linked genomic data observed in a larger European source population. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Tianxi Cai and Mengyan Li and Molei Liu},
  doi          = {10.1080/01621459.2024.2393463},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1037-1047},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Semi-supervised triply robust inductive transfer learning},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Euclidean mirrors and dynamics in network time series. <em>JASA</em>, <em>120</em>(550), 1025-1036. (<a href='https://doi.org/10.1080/01621459.2024.2392912'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing changes in network evolution is central to statistical network inference. We consider a dynamic network model in which each node has an associated time-varying low-dimensional latent vector of feature data, and connection probabilities are functions of these vectors. Under mild assumptions, the evolution of latent vectors exhibits low-dimensional manifold structure under a suitable distance. This distance can be approximated by a measure of separation between the observed networks themselves, and there exist Euclidean representations for underlying network structure, as characterized by this distance. These Euclidean representations, called Euclidean mirrors, permit the visualization of network dynamics and lead to methods for change point and anomaly detection in networks. We illustrate our methodology with real and synthetic data, and identify change points corresponding to massive shifts in pandemic policies in a communication network of a large organization. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Avanti Athreya and Zachary Lubberts and Youngser Park and Carey Priebe},
  doi          = {10.1080/01621459.2024.2392912},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1025-1036},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Euclidean mirrors and dynamics in network time series},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Statistical inference for networks of high-dimensional point processes. <em>JASA</em>, <em>120</em>(550), 1014-1024. (<a href='https://doi.org/10.1080/01621459.2024.2392907'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fueled in part by recent applications in neuroscience, the multivariate Hawkes process has become a popular tool for modeling the network of interactions among high-dimensional point process data. While evaluating the uncertainty of the network estimates is critical in scientific applications, existing methodological and theoretical work has primarily addressed estimation. To bridge this gap, we develop a new statistical inference procedure for high-dimensional Hawkes processes. The key ingredient for the inference procedure is a new concentration inequality on the first- and second-order statistics for integrated stochastic processes, which summarize the entire history of the process. Combining recent martingale central limit theorem with the new concentration inequality, we then characterize the convergence rate of the test statistics in a continuous time domain. Finally, to account for potential non-stationarity of the process in practice, we extend our statistical inference procedure to a flexible class of Hawkes processes with time-varying background intensities and unknown transition functions. The finite sample validity of the inferential tools is illustrated via extensive simulations and further applied to a neuron spike train dataset. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Xu Wang and Mladen Kolar and Ali Shojaie},
  doi          = {10.1080/01621459.2024.2392907},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1014-1024},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Statistical inference for networks of high-dimensional point processes},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust regression with covariate filtering: Heavy tails and adversarial contamination. <em>JASA</em>, <em>120</em>(550), 1002-1013. (<a href='https://doi.org/10.1080/01621459.2024.2392906'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of linear regression where both covariates and responses are potentially (i) heavy-tailed and (ii) adversarially contaminated. Several computationally efficient estimators have been proposed for the simpler setting where the covariates are sub-Gaussian and uncontaminated; however, these estimators may fail when the covariates are either heavy-tailed or contain outliers. In this work, we show how to modify the Huber regression, least trimmed squares, and least absolute deviation estimators to obtain estimators which are simultaneously computationally and statistically efficient in the stronger contamination model. Our approach is quite simple, and consists of applying a filtering algorithm to the covariates, and then applying the classical robust regression estimators to the remaining data. We show that the Huber regression estimator achieves near-optimal error rates in this setting, whereas the least trimmed squares and least absolute deviation estimators can be made to achieve near-optimal error after applying a postprocessing step. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Ankit Pensia and Varun Jog and Po-Ling Loh},
  doi          = {10.1080/01621459.2024.2392906},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1002-1013},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Robust regression with covariate filtering: Heavy tails and adversarial contamination},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Natural gradient variational bayes without fisher matrix analytic calculation and its inversion. <em>JASA</em>, <em>120</em>(550), 990-1001. (<a href='https://doi.org/10.1080/01621459.2024.2392904'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a method for efficiently approximating the inverse of the Fisher information matrix, a crucial step in achieving effective variational Bayes inference. A notable aspect of our approach is the avoidance of analytically computing the Fisher information matrix and its explicit inversion. Instead, we introduce an iterative procedure for generating a sequence of matrices that converge to the inverse of Fisher information. The natural gradient variational Bayes algorithm without analytic expression of the Fisher matrix and its inversion is provably convergent and achieves a convergence rate of order O ( log s / s ) , with s the number of iterations. We also obtain a central limit theorem for the iterates. Implementation of our method does not require storage of large matrices, and achieves a linear complexity in the number of variational parameters. Our algorithm exhibits versatility, making it applicable across a diverse array of variational Bayes domains, including Gaussian approximation and normalizing flow Variational Bayes. We offer a range of numerical examples to demonstrate the efficiency and reliability of the proposed variational Bayes method. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {A. Godichon-Baggioni and D. Nguyen and M.-N. Tran},
  doi          = {10.1080/01621459.2024.2392904},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {990-1001},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Natural gradient variational bayes without fisher matrix analytic calculation and its inversion},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient multiple change point detection and localization for high-dimensional quantile regression with heteroscedasticity. <em>JASA</em>, <em>120</em>(550), 976-989. (<a href='https://doi.org/10.1080/01621459.2024.2392903'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data heterogeneity is a challenging issue for modern statistical data analysis. There are different types of data heterogeneity in practice. In this article, we consider potential structural changes and complicated tail distributions. There are various existing methods proposed to handle either structural changes or heteroscedasticity. However, it is difficult to handle them simultaneously. To overcome this limitation, we consider statistically and computationally efficient change point detection and localization in high-dimensional quantile regression models. Our proposed framework is general and flexible since the change points and the underlying regression coefficients are allowed to vary across different quantile levels. The model parameters, including the data dimension, the number of change points, and the signal jump size, can be scaled with the sample size. Under this framework, we construct a novel two-step estimation of the number and locations of the change points as well as the underlying regression coefficients. Without any moment constraints on the error term, we present theoretical results, including consistency of the change point number, oracle estimation of change point locations, and estimation for the underlying regression coefficients with the optimal convergence rate. Finally, we present simulation results and an application to the S&P 100 dataset to demonstrate the advantage of the proposed method. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Xianru Wang and Bin Liu and Xinsheng Zhang and Yufeng Liu},
  doi          = {10.1080/01621459.2024.2392903},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {976-989},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Efficient multiple change point detection and localization for high-dimensional quantile regression with heteroscedasticity},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parallel sampling of decomposable graphs using markov chains on junction trees. <em>JASA</em>, <em>120</em>(550), 963-975. (<a href='https://doi.org/10.1080/01621459.2024.2388908'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian inference for undirected graphical models is mostly restricted to the class of decomposable graphs, as they enjoy a rich set of properties making them amenable to high-dimensional problems. While parameter inference is straightforward in this setup, inferring the underlying graph is a challenge driven by the computational difficulty in exploring the space of decomposable graphs. This work makes two contributions to address this problem. First, we provide sufficient and necessary conditions for when multi-edge perturbations maintain decomposability of the graph. Using these, we characterize a simple class of partitions that efficiently classify all edge perturbations by whether they maintain decomposability. Second, we propose a novel parallel nonreversible Markov chain Monte Carlo sampler for distributions over junction tree representations of the graph. At every step, the parallel sampler executes simultaneously all edge perturbations within a partition. Through simulations, we demonstrate the efficiency of our new edge perturbation conditions and class of partitions. We find that our parallel sampler yields improved mixing properties in comparison to the single-move variate, and outperforms current state-of-the-art methods in terms of accuracy and computational efficiency. The implementation of our work is available in the Python package parallelDG. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Mohamad Elmasri},
  doi          = {10.1080/01621459.2024.2388908},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {963-975},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Parallel sampling of decomposable graphs using markov chains on junction trees},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal network membership estimation under severe degree heterogeneity. <em>JASA</em>, <em>120</em>(550), 948-962. (<a href='https://doi.org/10.1080/01621459.2024.2388903'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real networks often have severe degree heterogeneity, with maximum, average, and minimum node degrees differing significantly. This article examines the impact of degree heterogeneity on statistical limits of network data analysis. Introducing the heterogeneity distribution (HD) under a degree-corrected mixed membership model, we show that the optimal rate of mixed membership estimation is an explicit functional of the HD. This result confirms that severe degree heterogeneity decelerates the error rate, even when the overall sparsity remains unchanged. To obtain a rate-optimal method, we modify an existing spectral algorithm, Mixed-SCORE, by adding a pre-PCA normalization step. This step normalizes the adjacency matrix by a diagonal matrix consisting of the b th power of node degrees, for some b ∈ R . We discover that b = 1/2 is universally favorable. The resulting spectral algorithm is rate-optimal for networks with arbitrary degree heterogeneity. A technical component in our proofs is entry-wise eigenvector analysis of the normalized graph Laplacian. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Zheng Tracy Ke and Jingming Wang},
  doi          = {10.1080/01621459.2024.2388903},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {948-962},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Optimal network membership estimation under severe degree heterogeneity},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Controlling the false split rate in tree-based aggregation. <em>JASA</em>, <em>120</em>(550), 935-947. (<a href='https://doi.org/10.1080/01621459.2024.2376285'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many domains, data measurements can naturally be associated with the leaves of a tree, expressing the relationships among these measurements. For example, companies belong to industries, which in turn belong to ever coarser divisions such as sectors; microbes are commonly arranged in a taxonomic hierarchy from species to kingdoms; street blocks belong to neighborhoods, which in turn belong to larger-scale regions. The problem of tree-based aggregation that we consider in this article asks which of these tree-defined subgroups of leaves should really be treated as a single entity and which of these entities should be distinguished from each other. We introduce the false split rate , an error measure that describes the degree to which subgroups have been split when they should not have been. While expressible as the false discovery rate in a special case, we show that these measures can be quite different for the general tree structures common in our setting. We then propose a multiple hypothesis testing algorithm for tree-based aggregation, which we prove controls this error measure. We focus on two main examples of tree-based aggregation, one which involves aggregating means and the other hich involves aggregating regression coefficients. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Simeng Shao and Jacob Bien and Adel Javanmard},
  doi          = {10.1080/01621459.2024.2376285},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {935-947},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Controlling the false split rate in tree-based aggregation},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust matrix completion with heavy-tailed noise. <em>JASA</em>, <em>120</em>(550), 922-934. (<a href='https://doi.org/10.1080/01621459.2024.2375037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies noisy low-rank matrix completion in the presence of heavy-tailed and possibly asymmetric noise, where we aim to estimate an underlying low-rank matrix given a set of highly incomplete noisy entries. Though the matrix completion problem has attracted much attention in the past decade, there is still lack of theoretical understanding when the observations are contaminated by heavy-tailed noises. Prior theory falls short of explaining the empirical results and is unable to capture the optimal dependence of the estimation error on the noise level. In this article, we adopt an adaptive Huber loss to accommodate heavy-tailed noise, which is robust against large and possibly asymmetric errors when the parameter in the Huber loss function is carefully designed to balance the Huberization biases and robustness to outliers. Then, we propose an efficient nonconvex algorithm via a balanced low-rank Burer-Monteiro matrix factorization and gradient descent with robust spectral initialization. We prove that under merely a bounded second-moment condition on the error distributions, rather than the sub-Gaussian assumption, the Euclidean errors of the iterates generated by the proposed algorithm decrease geometrically fast until achieving a minimax-optimal statistical estimation error, which has the same order as that in the sub-Gaussian case. The key technique behind this significant advancement is a powerful leave-one-out analysis framework. The theoretical results are corroborated by our numerical studies. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Bingyan Wang and Jianqing Fan},
  doi          = {10.1080/01621459.2024.2375037},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {922-934},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Robust matrix completion with heavy-tailed noise},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Statistical inference for Hüsler–Reiss graphical models through matrix completions. <em>JASA</em>, <em>120</em>(550), 909-921. (<a href='https://doi.org/10.1080/01621459.2024.2371978'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The severity of multivariate extreme events is driven by the dependence between the largest marginal observations. The Hüsler–Reiss distribution is a versatile model for this extremal dependence, and it is usually parameterized by a variogram matrix. In order to represent conditional independence relations and obtain sparse parameterizations, we introduce the novel Hüsler–Reiss precision matrix. Similarly to the Gaussian case, this matrix appears naturally in density representations of the Hüsler–Reiss Pareto distribution and encodes the extremal graphical structure through its zero pattern. For a given, arbitrary graph we prove the existence and uniqueness of the completion of a partially specified Hüsler–Reiss variogram matrix so that its precision matrix has zeros on non-edges in the graph. Using suitable estimators for the parameters on the edges, our theory provides the first consistent estimator of graph structured Hüsler–Reiss distributions. If the graph is unknown, our method can be combined with recent structure learning algorithms to jointly infer the graph and the corresponding parameter matrix. Based on our methodology, we propose new tools for statistical inference of sparse Hüsler–Reiss models and illustrate them on large flight delay data in the United States, as well as Danube river flow data. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Manuel Hentschel and Sebastian Engelke and Johan Segers},
  doi          = {10.1080/01621459.2024.2371978},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {909-921},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Statistical inference for Hüsler–Reiss graphical models through matrix completions},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contextual dynamic pricing with strategic buyers. <em>JASA</em>, <em>120</em>(550), 896-908. (<a href='https://doi.org/10.1080/01621459.2024.2370613'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized pricing, which involves tailoring prices based on individual characteristics, is commonly used by firms to implement a consumer-specific pricing policy. In this process, buyers can also strategically manipulate their feature data to obtain a lower price, incurring certain manipulation costs. Such strategic behavior can hinder firms from maximizing their profits. In this article, we study the contextual dynamic pricing problem with strategic buyers. The seller does not observe the buyer’s true feature, but a manipulated feature according to buyers’ strategic behavior. In addition, the seller does not observe the buyers’ valuation of the product, but only a binary response indicating whether a sale happens or not. Recognizing these challenges, we propose a strategic dynamic pricing policy that incorporates the buyers’ strategic behavior into the online learning to maximize the seller’s cumulative revenue. We first prove that existing nonstrategic pricing policies that neglect the buyers’ strategic behavior result in a linear Ω ( T ) regret with T the total time horizon, indicating that these policies are not better than a random pricing policy. We then establish an O ( T ) regret upper bound of our proposed policy and an Ω ( T ) regret lower bound for any pricing policy within our problem setting. This underscores the rate optimality of our policy. Importantly, our policy is not a mere amalgamation of existing dynamic pricing policies and strategic behavior handling algorithms. Our policy can also accommodate the scenario when the marginal cost of manipulation is unknown in advance. To account for it, we simultaneously estimate the valuation parameter and the cost parameter in the online pricing policy, which is shown to also achieve an O ( T ) regret bound. Extensive experiments support our theoretical developments and demonstrate the superior performance of our policy compared to other pricing policies that are unaware of the strategic behaviors. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Pangpang Liu and Zhuoran Yang and Zhaoran Wang and Will Wei Sun},
  doi          = {10.1080/01621459.2024.2370613},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {896-908},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Contextual dynamic pricing with strategic buyers},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synthetic likelihood in misspecified models. <em>JASA</em>, <em>120</em>(550), 884-895. (<a href='https://doi.org/10.1080/01621459.2024.2370594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian synthetic likelihood is a widely used approach for conducting Bayesian analysis in complex models where evaluation of the likelihood is infeasible but simulation from the assumed model is tractable. We analyze the behavior of the Bayesian synthetic likelihood posterior when the assumed model differs from the actual data generating process. We demonstrate that the Bayesian synthetic likelihood posterior can display a wide range of nonstandard behaviors depending on the level of model misspecification, including multimodality and asymptotic non-Gaussianity. Our results suggest that likelihood tempering, a common approach for robust Bayesian inference, fails for synthetic likelihood whilst recently proposed robust synthetic likelihood approaches can ameliorate this behavior and deliver reliable posterior inference under model misspecification. All results are illustrated using a simple running example. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {David T. Frazier and David J. Nott and Christopher Drovandi},
  doi          = {10.1080/01621459.2024.2370594},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {884-895},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Synthetic likelihood in misspecified models},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Supervised dynamic PCA: Linear dynamic forecasting with many predictors. <em>JASA</em>, <em>120</em>(550), 869-883. (<a href='https://doi.org/10.1080/01621459.2024.2370592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel dynamic forecasting method using a new supervised Principal Component Analysis (PCA) when a large number of predictors are available. The new supervised PCA provides an effective way to bridge the gap between predictors and the target variable of interest by scaling and combining the predictors and their lagged values, resulting in an effective dynamic forecasting. Unlike the traditional diffusion-index approach, which does not learn the relationships between the predictors and the target variable before conducting PCA, we first rescale each predictor according to their significance in forecasting the targeted variable in a dynamic fashion, and a PCA is then applied to a rescaled and additive panel, which establishes a connection between the predictability of the PCA factors and the target variable. We also propose to use penalized methods such as the LASSO to select the significant factors that have superior predictive power over the others. Theoretically, we show that our estimators are consistent and outperform the traditional methods in prediction under some mild conditions. We conduct extensive simulations to verify that the proposed method produces satisfactory forecasting results and outperforms most of the existing methods using the traditional PCA. An example of predicting U.S. macroeconomic variables using a large number of predictors showcases that our method fares better than most of the existing ones in applications. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Zhaoxing Gao and Ruey S. Tsay},
  doi          = {10.1080/01621459.2024.2370592},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {869-883},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Supervised dynamic PCA: Linear dynamic forecasting with many predictors},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced response envelope via envelope regularization. <em>JASA</em>, <em>120</em>(550), 859-868. (<a href='https://doi.org/10.1080/01621459.2024.2368844'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The response envelope model provides substantial efficiency gains over the standard multivariate linear regression by identifying the material part of the response to the model and by excluding the immaterial part. In this article, we propose the enhanced response envelope by incorporating a novel envelope regularization term based on a nonconvex manifold formulation. It is shown that the enhanced response envelope can yield better prediction risk than the original envelope estimator. The enhanced response envelope naturally handles high-dimensional data for which the original response envelope is not serviceable without necessary remedies. In an asymptotic high-dimensional regime where the ratio of the number of predictors over the number of samples converges to a nonzero constant, we characterize the risk function and reveal an interesting double descent phenomenon for the envelope model. A simulation study confirms our main theoretical findings. Simulations and real data applications demonstrate that the enhanced response envelope does have significantly improved prediction performance over the original envelope method, especially when the number of predictors is close to or moderately larger than the number of samples. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Oh-Ran Kwon and Hui Zou},
  doi          = {10.1080/01621459.2024.2368844},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {859-868},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Enhanced response envelope via envelope regularization},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tyranny-of-the-minority regression adjustment in randomized experiments. <em>JASA</em>, <em>120</em>(550), 846-858. (<a href='https://doi.org/10.1080/01621459.2024.2366043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regression adjustment is widely used in the analysis of randomized experiments to improve the estimation efficiency of the treatment effect. This article reexamines a weighted regression adjustment method termed t yranny- o f-the- m inority (ToM), wherein units in the minority group are given greater weights. We demonstrate that ToM regression adjustment is more robust than Lin ’s regression adjustment with treatment-covariate interactions, even though these two regression adjustment methods are asymptotically equivalent in completely randomized experiments. Moreover, ToM regression adjustment can be easily extended to stratified randomized experiments and completely randomized survey experiments. We obtain the design-based properties of the ToM regression-adjusted average treatment effect estimator under such designs. In particular, we show that the ToM regression-adjusted estimator improves the asymptotic estimation efficiency compared to the unadjusted estimator, even when the regression model is misspecified, and is optimal in the class of linearly adjusted estimators. We also study the asymptotic properties of various heteroscedasticity-robust standard errors and provide recommendations for practitioners. Simulation studies and real data analysis demonstrate ToM regression adjustment’s superiority over existing methods. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Xin Lu and Hanzhong Liu},
  doi          = {10.1080/01621459.2024.2366043},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {846-858},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Tyranny-of-the-minority regression adjustment in randomized experiments},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Test and measure for partial mean dependence based on machine learning methods. <em>JASA</em>, <em>120</em>(550), 833-845. (<a href='https://doi.org/10.1080/01621459.2024.2366030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is of importance to investigate the significance of a subset of covariates W for the response Y given covariates Z in regression modeling. To this end, we propose a significance test for the partial mean independence problem based on machine learning methods and data splitting. The test statistic converges to the standard Chi-squared distribution under the null hypothesis while it converges to a normal distribution under the fixed alternative hypothesis. Power enhancement and algorithm stability are also discussed. If the null hypothesis is rejected, we propose a partial Generalized Measure of Correlation (pGMC) to measure the partial mean dependence of Y given W after controlling for the nonlinear effect of Z . We present the appealing theoretical properties of the pGMC and establish the asymptotic normality of its estimator with the optimal root- N convergence rate. Furthermore, the valid confidence interval for the pGMC is also derived. As an important special case when there are no conditional covariates Z , we introduce a new test of overall significance of covariates for the response in a model-free setting. Numerical studies and real data analysis are also conducted to compare with existing approaches and to demonstrate the validity and flexibility of our proposed procedures. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Leheng Cai and Xu Guo and Wei Zhong},
  doi          = {10.1080/01621459.2024.2366030},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {833-845},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Test and measure for partial mean dependence based on machine learning methods},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonparametric multiple-output center-outward quantile regression. <em>JASA</em>, <em>120</em>(550), 818-832. (<a href='https://doi.org/10.1080/01621459.2024.2366029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building on recent measure-transportation-based concepts of multivariate quantiles, we are considering the problem of nonparametric multiple-output quantile regression. Our approach defines nested conditional center-outward quantile regression contours and regions with given conditional probability content, the graphs of which constitute nested center-outward quantile regression tubes with given unconditional probability content; these (conditional and unconditional) probability contents do not depend on the underlying distribution—an essential property of quantile concepts. Empirical counterparts of these concepts are constructed, yielding interpretable empirical contours, regions, and tubes which are shown to consistently reconstruct (in the Pompeiu-Hausdorff topology) their population versions. Our method is entirely nonparametric and performs well in simulations—with possible heteroscedasticity and nonlinear trends. Its potential as a data-analytic tool is illustrated on some real datasets. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Eustasio del Barrio and Alberto González Sanz and Marc Hallin},
  doi          = {10.1080/01621459.2024.2366029},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {818-832},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Nonparametric multiple-output center-outward quantile regression},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). False discovery rate control for structured multiple testing: Asymmetric rules and conformal Q-values. <em>JASA</em>, <em>120</em>(550), 805-817. (<a href='https://doi.org/10.1080/01621459.2024.2359739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effective utilization of structural information in data while ensuring statistical validity poses a significant challenge in false discovery rate (FDR) analyses. Conformal inference provides rigorous theory for grounding complex machine learning methods without relying on strong assumptions or highly idealized models. However, existing conformal methods have limitations in handling structured multiple testing, as their validity often requires the deployment of symmetric decision rules, which assume the exchangeability of data points and permutation-invariance of fitting algorithms. To overcome these limitations, we introduce the pseudo local index of significance (PLIS) procedure, which is capable of accommodating asymmetric rules and requires only pairwise exchangeability between the null conformity scores. We demonstrate that PLIS offers finite-sample guarantees in FDR control and the ability to assign higher weights to relevant data points. Numerical results confirm the effectiveness and robustness of PLIS and demonstrate improvements in power compared to existing model-free methods in various scenarios. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Zinan Zhao and Wenguang Sun},
  doi          = {10.1080/01621459.2024.2359739},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {805-817},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {False discovery rate control for structured multiple testing: Asymmetric rules and conformal Q-values},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mediation analysis with the mediator and outcome missing not at random. <em>JASA</em>, <em>120</em>(550), 794-804. (<a href='https://doi.org/10.1080/01621459.2024.2359132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mediation analysis is widely used for investigating direct and indirect causal pathways through which an effect arises. However, many mediation analysis studies are challenged by missingness in the mediator and outcome. In general, when the mediator and outcome are missing not at random, the direct and indirect effects are not identifiable without further assumptions. We study the identifiability of the direct and indirect effects under some interpretable mechanisms that allow for missing not at random in the mediator and outcome. We evaluate the performance of statistical inference under those mechanisms through simulation studies and illustrate the proposed methods via the National Job Corps Study. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Shuozhi Zuo and Debashis Ghosh and Peng Ding and Fan Yang},
  doi          = {10.1080/01621459.2024.2359132},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {794-804},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Mediation analysis with the mediator and outcome missing not at random},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed heterogeneity learning for generalized partially linear models with spatially varying coefficients. <em>JASA</em>, <em>120</em>(550), 779-793. (<a href='https://doi.org/10.1080/01621459.2024.2359131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial heterogeneity is of great importance in social, economic, and environmental science studies. The spatially varying coefficient model is a popular and effective spatial regression technique to address spatial heterogeneity. However, accounting for heterogeneity comes at the cost of reducing model parsimony. To balance flexibility and parsimony, this article develops a class of generalized partially linear spatially varying coefficient models which allow the inclusion of both constant and spatially varying effects of covariates. Another significant challenge in many applications comes from the enormous size of the spatial datasets collected from modern technologies. To tackle this challenge, we design a novel distributed heterogeneity learning (DHL) method based on bivariate spline smoothing over a triangulation of the domain. The proposed DHL algorithm has a simple, scalable, and communication-efficient implementation scheme that can almost achieve linear speedup. In addition, this article provides rigorous theoretical support for the DHL framework. We prove that the DHL constant coefficient estimators are asymptotic normal and the DHL spline estimators reach the same convergence rate as the global spline estimators obtained using the entire dataset. The proposed DHL method is evaluated through extensive simulation studies and analyses of U.S. loan application data. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Shan Yu and Guannan Wang and Li Wang},
  doi          = {10.1080/01621459.2024.2359131},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {779-793},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Distributed heterogeneity learning for generalized partially linear models with spatially varying coefficients},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Node-level community detection within edge exchangeable models for interaction processes. <em>JASA</em>, <em>120</em>(550), 764-778. (<a href='https://doi.org/10.1080/01621459.2024.2358560'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientists are increasingly interested in discovering community structure from modern relational data arising on large-scale social networks. While many methods have been proposed for learning community structure, few account for the fact that these modern networks arise from processes of interactions in the population. We introduce block edge exchangeable models (BEEM) for the study of interaction networks with latent node-level community structure. The block vertex components model (B-VCM) is derived as a canonical example. Several theoretical and practical advantages over traditional vertex-centric approaches are highlighted. In particular, BEEMs allow for sparse degree structure and power-law degree distributions within communities. Our theoretical analysis bounds the misspecification rate of block assignments while supporting simulations show the properties of the network can be recovered. A computationally tractable Gibbs algorithm is derived. We demonstrate the proposed model using post-comment interaction data from Talklife, a large-scale online peer-to-peer support network, and contrast the learned communities from those using standard algorithms including degree-corrected stochastic block models, popularity-adjusted block models, and weighted stochastic block models. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Yuhua Zhang and Walter Dempsey},
  doi          = {10.1080/01621459.2024.2358560},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {764-778},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Node-level community detection within edge exchangeable models for interaction processes},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Population-level balance in signed networks. <em>JASA</em>, <em>120</em>(550), 751-763. (<a href='https://doi.org/10.1080/01621459.2024.2356894'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistical network models are useful for understanding the underlying formation mechanism and characteristics of complex networks. However, statistical models for signed networks have been largely unexplored. In signed networks, there exist both positive (e.g., like, trust) and negative (e.g., dislike, distrust) edges, which are commonly seen in real-world scenarios. The positive and negative edges in signed networks lead to unique structural patterns, which pose challenges for statistical modeling. In this article, we introduce a statistically principled latent space approach for modeling signed networks and accommodating the well-known balance theory , that is, “the enemy of my enemy is my friend” and “the friend of my friend is my friend.” The proposed approach treats both edges and their signs as random variables, and characterizes the balance theory with a novel and natural notion of population-level balance. This approach guides us towards building a class of balanced inner-product models, and toward developing scalable algorithms via projected gradient descent to estimate the latent variables. We also establish non-asymptotic error rates for the estimates, which are further verified through simulation studies. In addition, we apply the proposed approach to an international relation network, which provides an informative and interpretable model-based visualization of countries during World War II. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Weijing Tang and Ji Zhu},
  doi          = {10.1080/01621459.2024.2356894},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {751-763},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Population-level balance in signed networks},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rate-optimal rank aggregation with private pairwise rankings. <em>JASA</em>, <em>120</em>(550), 737-750. (<a href='https://doi.org/10.1080/01621459.2025.2484843'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In various real-world scenarios, such as recommender systems and political surveys, pairwise rankings are commonly collected and used for rank aggregation to derive an overall ranking of items. However, preference rankings can reveal individuals’ personal preferences, highlighting the need to protect them from exposure in downstream analysis. In this article, we address the challenge of preserving privacy while ensuring the utility of rank aggregation based on pairwise rankings generated from a general comparison model. A common privacy protection strategy in practice is the use of the randomized response mechanism to perturb raw pairwise rankings. However, a critical challenge arises because the privatized rankings no longer adhere to the original model, resulting in significant bias in downstream rank aggregation tasks. To address this, we propose an adaptive debiasing method for rankings from the randomized response mechanism, ensuring consistent estimation of true preferences and enhancing the utility of downstream rank aggregation. Theoretically, we provide insights into the relationship between overall privacy guarantees and estimation errors in private ranking data, and establish minimax rates for estimation errors. This enables the determination of optimal privacy guarantees that balance consistency in rank aggregation with privacy protection. We also investigate convergence rates of expected ranking errors for partial and full ranking recovery, quantifying how privacy protection affects the specification of top- K item sets and complete rankings. Our findings are validated through extensive simulations and a real-world application. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Shirong Xu and Will Wei Sun and Guang Cheng},
  doi          = {10.1080/01621459.2025.2484843},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {737-750},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Rate-optimal rank aggregation with private pairwise rankings},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse bayesian group factor model for feature interactions in multiple count tables data. <em>JASA</em>, <em>120</em>(550), 723-736. (<a href='https://doi.org/10.1080/01621459.2025.2449721'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group factor models have been developed to infer relationships between multiple co-occurring multivariate continuous responses. Motivated by complex count data from multi-domain microbiome studies using next-generation sequencing, we develop a sparse Bayesian group factor model (Sp-BGFM) for multiple count table data that captures the interaction between microorganisms in different domains. Sp-BGFM uses a rounded kernel mixture model using a Dirichlet process (DP) prior with log-normal mixture kernels for count vectors. A group factor model is used to model the covariance matrix of the mixing kernel that describes microorganism interaction. We construct a Dirichlet-Horseshoe (Dir-HS) shrinkage prior and use it as a joint prior for factor loading vectors. Joint sparsity induced by a Dir-HS prior greatly improves the performance in high-dimensional applications. We further model the effects of covariates on microbial abundances using regression. The semiparametric model flexibly accommodates large variability in observed counts and excess zero counts and provides a basis for robust estimation of the interaction and covariate effects. We evaluate Sp-BGFM using simulation studies and real data analysis, comparing it to popular alternatives. Our results highlight the necessity of joint sparsity induced by the Dir-HS prior, and the benefits of a flexible DP model for baseline abundances. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Shuangjie Zhang and Yuning Shen and Irene A. Chen and Juhee Lee},
  doi          = {10.1080/01621459.2025.2449721},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {723-736},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Sparse bayesian group factor model for feature interactions in multiple count tables data},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GeoWarp: Warped spatial processes for inferring subsea sediment properties. <em>JASA</em>, <em>120</em>(550), 710-722. (<a href='https://doi.org/10.1080/01621459.2024.2445874'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For offshore structures like wind turbines, subsea infrastructure, pipelines, and cables, it is crucial to quantify the properties of the seabed sediments at a proposed site. However, data collection offshore is costly, so analysis of the seabed sediments must be made from measurements that are spatially sparse. Adding to this challenge, the structure of the seabed sediments exhibits both nonstationarity and anisotropy. To address these issues, we propose GeoWarp, a hierarchical spatial statistical modeling framework for inferring the 3-D geotechnical properties of subsea sediments. GeoWarp decomposes the seabed properties into a region-wide vertical mean profile (modeled using B-splines), and a nonstationary 3-D spatial Gaussian process. Process nonstationarity and anisotropy are accommodated by warping space in three dimensions and by allowing the process variance to change with depth. We apply GeoWarp to measurements of the seabed made using cone penetrometer tests (CPTs) at six sites on the North West Shelf of Australia. We show that GeoWarp captures the complex spatial distribution of the sediment properties, and produces realistic 3-D simulations suitable for downstream engineering analyses. Through cross-validation, we show that GeoWarp has predictive performance superior to other state-of-the-art methods, demonstrating its value as a tool in offshore geotechnical engineering. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Michael Bertolacci and Andrew Zammit-Mangion and Juan Valderrama Giraldo and Michael O’Neill and Fraser Bransby and Phil Watson},
  doi          = {10.1080/01621459.2024.2445874},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {710-722},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {GeoWarp: Warped spatial processes for inferring subsea sediment properties},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining broad and narrow case definitions in matched case-control studies: Firearms in the home and suicide risk. <em>JASA</em>, <em>120</em>(550), 698-709. (<a href='https://doi.org/10.1080/01621459.2024.2441519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Does having firearms in the home increase suicide risk? To test this hypothesis, a matched case-control study can be performed, in which suicide case subjects are compared to living controls who are similar in observed covariates in terms of their retrospective exposure to firearms at home. In this application, cases can be defined using a broad case definition (suicide) or a narrow case definition (suicide occurred at home). The broad case definition offers a larger number of cases, but the narrow case definition may offer a larger effect size, which can reduce sensitivity to bias from unmeasured confounding. However, when the goal is to test whether there is a treatment effect based on the broad case definition, restricting to the narrow case definition may introduce selection bias (i.e., bias due to selecting samples based on characteristics affected by the treatment) because exposure to firearms in the home may affect the location of suicide and thus the type of a case a subject is. We propose a new sensitivity analysis framework for combining broad and narrow case definitions in matched case-control studies, that considers the unmeasured confounding bias and selection bias simultaneously. We develop a valid randomization-based testing procedure using only the narrow case matched sets when the effect of the unmeasured confounder on receiving treatment and the effect of the treatment on case definition among the always-cases are controlled by sensitivity parameters. We then use the Bonferroni method to combine the testing procedures using the broad and narrow case definitions. With the proposed methods, we find robust evidence that having firearms at home increases suicide risk. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Ting Ye and Kan Chen and Dylan Small},
  doi          = {10.1080/01621459.2024.2441519},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {698-709},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Combining broad and narrow case definitions in matched case-control studies: Firearms in the home and suicide risk},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inferring causal effect of a digital communication strategy under a latent sequential ignorability assumption and treatment noncompliance. <em>JASA</em>, <em>120</em>(550), 685-697. (<a href='https://doi.org/10.1080/01621459.2024.2435655'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Organizations are increasingly relying on digital communications, such as targeted e-mails and mobile notifications, to engage with their audiences. Despite the evident advantages like cost-effectiveness and customization, assessing the effectiveness of such communications from observational data poses various statistical challenges. An immediate challenge is to adjust for targeting rules used in these communications. When digital communications involve a sequence of e-mails or notifications, however, further adjustments are required to correct for selection bias arising from previous communications influencing the subsequent ones and to deal with noncompliance issues, for example, not opening the e-mail. This article addresses these challenges in a study of promotional e-mail sequences sent by a U.S. retailer. We use a Bayesian methodology for causal inference from longitudinal data, considering targeting, noncompliance, and sequential confounding with unmeasured variables. The methodology serves three objectives: to evaluate the average treatment effect of any deterministic e-mailing strategy, to compare the effectiveness of these strategies across varying compliance behaviors, and to infer optimal strategies for distinct customer segments. Our analysis finds, among other things, that certain promotional e-mails effectively maintain engagement among individuals who have regularly received such incentives, and individuals who consistently open their e-mails exhibit reduced sensitivity to promotional content. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Yuki Ohnishi and Bikram Karmakar and Wreetabrata Kar},
  doi          = {10.1080/01621459.2024.2435655},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {685-697},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Inferring causal effect of a digital communication strategy under a latent sequential ignorability assumption and treatment noncompliance},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Immune profiling among colorectal cancer subtypes using dependent mixture models. <em>JASA</em>, <em>120</em>(550), 671-684. (<a href='https://doi.org/10.1080/01621459.2024.2427936'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Comparison of transcriptomic data across different conditions is of interest in many biomedical studies. In this article, we consider comparative immune cell profiling for early-onset (EO) versus late-onset (LO) colorectal cancer (CRC). EOCRC, diagnosed between ages 18–45, is a rising public health concern that needs to be urgently addressed. However, its etiology remains poorly understood. We work toward filling this gap by identifying homogeneous T cell sub-populations that show significantly distinct characteristics across the two tumor types, and identifying others that are shared between EOCRC and LOCRC. We develop dependent finite mixture models where immune subtypes enriched under a specific condition are characterized by terms in the mixture model with common atoms but distinct weights across conditions, whereas common subtypes are characterized by sharing both atoms and relative weights. The proposed model facilitates the desired comparison across conditions by introducing highly structured multi-layer Dirichlet priors. We illustrate inference with simulation studies and data examples. Results identify EO- and LO-enriched T cells subtypes whose biomarkers are found to be linked to mechanisms of tumor progression, and potentially motivate insights into treatment of CRC. Code implementing the proposed method is available at: https://github.com/YunshanDYS/SASCcode . Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Yunshan Duan and Shuai Guo and Wenyi Wang and Peter Müller},
  doi          = {10.1080/01621459.2024.2427936},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {671-684},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Immune profiling among colorectal cancer subtypes using dependent mixture models},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlocking retrospective prevalent information in EHRs—A revisit to the pairwise pseudolikelihood. <em>JASA</em>, <em>120</em>(550), 658-670. (<a href='https://doi.org/10.1080/01621459.2024.2427431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic health records offer abundant data on various diseases and health conditions, enabling researchers to explore the relationship between disease onset age and underlying risk factors. Unlike mortality data, the event of interest is nonterminal, hence, individuals can retrospectively report their disease-onset-age upon recruitment to the study. These individuals, diagnosed with the disease before entering the study, are termed “prevalent.” The ascertainment imposes a left truncation condition, also known as a “delayed entry,” because individuals had to survive a certain period before being eligible for enrollment. The standard method to accommodate delayed entry conditions on the entire history up to recruitment, hence, the retrospective prevalent failure times are conditioned upon and cannot participate in estimating the disease-onset-age distribution. Other methods that condition on less information and allow the incorporation of the prevalent observations either bring about numerical and computational difficulties or require statistical assumptions that are violated by most biobanks. This work presents a novel estimator of the coefficients in a regression model for the age-at-onset, successfully using the prevalent data. Asymptotic results are provided, and simulations are conducted to showcase the substantial efficiency gain. In particular, the method is highly useful in leveraging large-scale repositories for replication analysis of genetic variants. Indeed, analysis of urinary bladder cancer data reveals that the proposed approach yields about twice as many replicated discoveries compared to the popular approach. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Nir Keret and Malka Gorfine},
  doi          = {10.1080/01621459.2024.2427431},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {658-670},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Unlocking retrospective prevalent information in EHRs—A revisit to the pairwise pseudolikelihood},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatio-temporal modeling for record-breaking temperature events in spain. <em>JASA</em>, <em>120</em>(550), 645-657. (<a href='https://doi.org/10.1080/01621459.2024.2427430'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Record-breaking temperature events are now very frequently in the news, viewed as evidence of climate change. With this as motivation, we undertake the first substantial spatial modeling investigation of temperature record-breaking across years for any given day within the year. We work with a dataset consisting of over 60 years (1960–2021) of daily maximum temperatures across peninsular Spain. Formal statistical analysis of record-breaking events is an area that has received attention primarily within the probability community, dominated by results for the stationary record-breaking setting with some additional work addressing trends. Such effort is inadequate for analyzing actual record-breaking data. Resulting from novel and detailed exploratory data analysis, we propose rich hierarchical conditional modeling of the indicator events which define record-breaking sequences. After suitable model selection, we discover explicit trend behavior, necessary autoregression, significance of distance to the coast, useful interactions, helpful spatial random effects, and very strong daily random effects. Illustratively, the model estimates that global warming trends have increased the number of records expected in the past decade almost 2-fold, 1.93 ( 1.89 , 1.98 ) , but also estimates highly differentiated climate warming rates in space and by season. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Jorge Castillo-Mateo and Alan E. Gelfand and Zeus Gracia-Tabuenca and Jesús Asín and Ana C. Cebrián},
  doi          = {10.1080/01621459.2024.2427430},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {645-657},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Spatio-temporal modeling for record-breaking temperature events in spain},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ℓ1-based bayesian ideal point model for multidimensional politics. <em>JASA</em>, <em>120</em>(550), 631-644. (<a href='https://doi.org/10.1080/01621459.2024.2425461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ideal point estimation methods in the social sciences lack a principled approach for identifying multidimensional ideal points. We present a novel method for estimating multidimensional ideal points based on l 1 distance. In the Bayesian framework, the use of l 1 distance transforms the invariance problem of infinite rotational turns into the signed perpendicular problem, yielding posterior estimates that contract around a small area. Our simulation shows that the proposed method successfully recovers planted multidimensional ideal points in a variety of settings including non-partisan, two-party, and multi-party systems. The proposed method is applied to the analysis of roll call data from the United States House of Representatives during the late Gilded Age (1891–1899) when legislative coalitions were distinguished not only by partisan divisions but also by sectional divisions that ran across party lines. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Sooahn Shin and Johan Lim and Jong Hee Park},
  doi          = {10.1080/01621459.2024.2425461},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {631-644},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {ℓ1-based bayesian ideal point model for multidimensional politics},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A physics-informed, deep double reservoir network for forecasting boundary layer velocity. <em>JASA</em>, <em>120</em>(550), 618-630. (<a href='https://doi.org/10.1080/01621459.2024.2422131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When a fluid flows over a solid surface, it creates a thin boundary layer where the flow velocity is influenced by the surface through viscosity, and can transition from laminar to turbulent at sufficiently high speeds. Understanding and forecasting the fluid dynamics under these conditions is one of the most challenging scientific problems in fluid dynamics. It is therefore of high interest to formulate models able to capture the nonlinear spatio-temporal velocity structure as well as produce forecasts in a computationally efficient manner. Traditional statistical approaches are limited in their ability to produce timely forecasts of complex, nonlinear spatio-temporal structures which are at the same time able to incorporate the underlying flow physics. In this work, we propose a model to accurately forecast boundary layer velocities with a deep double reservoir computing network which is capable of capturing the complex, nonlinear dynamics of the boundary layer while at the same time incorporating physical constraints via a penalty obtained by a Partial Differential Equation (PDE). Simulation studies on a one-dimensional viscous fluid demonstrate how the proposed model is able to produce accurate forecasts while simultaneously accounting for energy loss. The application focuses on boundary layer data in a water tunnel with a PDE penalty derived from an appropriate simplification of the Navier-Stokes equations, showing improved forecasting by the proposed approach in terms of mass conservation and variability of velocity fluctuation against non-physics-informed methods. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Matthew Bonas and David H. Richter and Stefano Castruccio},
  doi          = {10.1080/01621459.2024.2422131},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {618-630},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {A physics-informed, deep double reservoir network for forecasting boundary layer velocity},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Testing a large number of composite null hypotheses using conditionally symmetric multidimensional gaussian mixtures in genome-wide studies. <em>JASA</em>, <em>120</em>(550), 605-617. (<a href='https://doi.org/10.1080/01621459.2024.2422124'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal mediation, pleiotropy, and replication analyses are three highly popular genetic study designs. Although these analyses address different scientific questions, the underlying statistical inference problems all involve large-scale testing of composite null hypotheses. The goal is to determine whether all null hypotheses—as opposed to at least one—in a set of individual tests should simultaneously be rejected. Recently, various methods have been proposed for each of these situations, including an appealing two-group empirical Bayes approach that calculates local false discovery rates (lfdr). However, lfdr estimation is difficult due to the need for multivariate density estimation. Furthermore, the multiple testing rules for the empirical Bayes lfdr approach can disagree with conventional frequentist z-statistics, which is troubling for a field that ubiquitously uses summary statistics. This work proposes a framework to unify two-group testing in genetic association composite null settings, the conditionally symmetric multidimensional Gaussian mixture model (csmGmm). The csmGmm is shown to demonstrate more robust operating characteristics than recently-proposed alternatives. Crucially, the csmGmm also offers interpretability guarantees by harmonizing lfdr and z-statistic testing rules. We extend the base csmGmm to cover each of the mediation, pleiotropy, and replication settings, and we prove that the lfdr z-statistic agreement holds in each situation. We apply the model to a collection of translational lung cancer genetic association studies that motivated this work. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Ryan Sun and Zachary R. McCaw and Xihong Lin},
  doi          = {10.1080/01621459.2024.2422124},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {605-617},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Testing a large number of composite null hypotheses using conditionally symmetric multidimensional gaussian mixtures in genome-wide studies},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Space-time extremes of severe U.S. thunderstorm environments. <em>JASA</em>, <em>120</em>(550), 591-604. (<a href='https://doi.org/10.1080/01621459.2024.2421582'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Severe thunderstorms cause substantial economic and human losses in the United States. Simultaneous high values of convective available potential energy (CAPE) and storm relative helicity (SRH) are favorable to severe weather, and both they and the composite variable PROD = CAPE × SRH can be used as indicators of severe thunderstorm activity. Their extremal spatial dependence exhibits temporal non-stationarity due to seasonality and large-scale atmospheric signals such as El Niño-Southern Oscillation (ENSO). In order to investigate this, we introduce a space-time model based on a max-stable, Brown–Resnick, field whose range depends on ENSO and on time through a tensor product spline. We also propose a max-stability test based on empirical likelihood and the bootstrap. The marginal and dependence parameters must be estimated separately owing to the complexity of the model, and we develop a bootstrap-based model selection criterion that accounts for the marginal uncertainty when choosing the dependence model. In the case study, the out-sample performance of our model is good. We find that extremes of PROD, CAPE, and SRH are generally more localized in summer and, in some regions, less localized during El Niño and La Niña events, and give meteorological interpretations of these phenomena. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Jonathan Koh and Erwan Koch and Anthony C. Davison},
  doi          = {10.1080/01621459.2024.2421582},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {591-604},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Space-time extremes of severe U.S. thunderstorm environments},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jbes">JBES - 19</h2>
<ul>
<li><details>
<summary>
(2025). Another look at dependence: The most predictable aspects of time series. <em>JBES</em>, <em>43</em>(3), 723-736. (<a href='https://doi.org/10.1080/07350015.2024.2424345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Serial dependence and predictability are two sides of the same coin. The literature has considered alternative measures of these two fundamental concepts. In this article, we aim to distill the most predictable aspect of a univariate time series, that is, the one for which predictability is optimized. Our target measure is the mutual information between the past and future of a random process, a broad measure of predictability that takes into account all future forecast horizons, rather than focusing on the one-step-ahead prediction error mean square error. The most predictable aspect is defined as the measurable transformation of the series that maximizes the mutual information between past and future. This transformation arises from the linear combination of a set of basis functions localized at the quantiles of the unconditional distribution of the process. The mutual information is estimated as a function of the sample partial autocorrelations, using a semiparametric method that estimates an infinite sum by a regularized finite sum. The second most predictable aspect can also be defined, subject to suitable orthogonality restrictions. Finally, we illustrate the use of the most predictable aspect for testing the null hypothesis of no predictability and for point and interval prediction of the original time series.},
  archive      = {J_JBES},
  author       = {Tommaso Proietti},
  doi          = {10.1080/07350015.2024.2424345},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {723-736},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Another look at dependence: The most predictable aspects of time series},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Calibrated equilibrium estimation and double selection for high-dimensional partially linear measurement error models. <em>JBES</em>, <em>43</em>(3), 710-722. (<a href='https://doi.org/10.1080/07350015.2024.2422982'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practice, measurement error data is frequently encountered and needs to be handled appropriately. As a result of additional bias induced by measurement error, many existing estimation methods fail to achieve satisfactory performances. This article studies high-dimensional partially linear measurement error models. It proposes a calibrated equilibrium (CARE) estimation method to calibrate the bias caused by measurement error and overcomes the technical difficulty of the objective function unbounded from below in high-dimensional cases due to non-convexity. To facilitate the applications of the CARE estimation method, a bootstrap approach for approximating the covariance matrix of measurement errors is introduced. For the high-dimensional or ultra-high dimensional partially linear measurement error models, a novel multiple testing method, the calibrated equilibrium multiple double selection (CARE–MUSE) algorithm, is proposed to control the false discovery rate (FDR). Under certain regularity conditions, we derive the oracle inequalities for estimation error and prediction risk, along with an upper bound on the number of falsely discovered signs for the CARE estimator. We further establish the convergence rate of the nonparametric function estimator. In addition, FDR and power guarantee for the CARE–MUSE algorithm are investigated under a weaker minimum signal condition, which is insufficient for the CARE estimator to achieve sign consistency. Extensive simulation studies and a real data application demonstrate the satisfactory finite sample performance of the proposed methods.},
  archive      = {J_JBES},
  author       = {Jingxuan Luo and Gaorong Li and Heng Peng and Lili Yue},
  doi          = {10.1080/07350015.2024.2422982},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {710-722},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Calibrated equilibrium estimation and double selection for high-dimensional partially linear measurement error models},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive kernel-based structural change test for copulas. <em>JBES</em>, <em>43</em>(3), 696-709. (<a href='https://doi.org/10.1080/07350015.2024.2422980'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a structural change test for copula models based on the kernel smoothing method. The proposed approach enables adaptable estimation of the dynamic marginal distributions, either parametrically or semi-parametrically. The test statistic is formulated via the weighted quadratic distance between the local smoothing copula and the empirical copula function, using pseudo-observations of marginal distributions. The test statistic is pivotal with an asymptotic standard Normal distribution, irrespective of the marginal distributions, parameters, and estimations, and is consistent against a wide range of smoothly transitioning structural changes as well as abrupt structural breaks for copula models. Monte Carlo simulations show that the test performs well in finite samples and outperforms existing tests in the case of periodic changes.},
  archive      = {J_JBES},
  author       = {Xiaohui Lu and Yahong Zhou},
  doi          = {10.1080/07350015.2024.2422980},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {696-709},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {An adaptive kernel-based structural change test for copulas},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining instrumental variable estimators for a panel data model with factors. <em>JBES</em>, <em>43</em>(3), 684-695. (<a href='https://doi.org/10.1080/07350015.2024.2421991'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the estimation of factor-augmented panel data models using observed measurements to proxy for unobserved factors or loadings and explore the use of internal instruments to address the resulting endogeneity. The main challenge consists in that economic theory rarely provides insights into which measurements to choose as proxies when several are available. To overcome this problem, we propose a new class of estimators that are linear combinations of instrumental variable estimators and establish large sample results. We also show that an optimal weighting scheme exists, leading to efficiency gains relative to an instrumental variable estimator. Simulations show that the proposed approach performs better than existing methods. We illustrate the new method using data on test scores across U.S. school districts.},
  archive      = {J_JBES},
  author       = {Matthew Harding and Carlos Lamarche and Chris Muris},
  doi          = {10.1080/07350015.2024.2421991},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {684-695},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Combining instrumental variable estimators for a panel data model with factors},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural phillips curve and a deep output gap. <em>JBES</em>, <em>43</em>(3), 669-683. (<a href='https://doi.org/10.1080/07350015.2024.2421279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many problems plague empirical Phillips curves (PCs). Among them is the hurdle that the two key components, inflation expectations and the output gap, are both unobserved. Traditional remedies include proxying for the absentees or extracting them via assumptions-heavy filtering procedures. I propose an alternative route: a Hemisphere Neural Network (HNN) whose architecture yields a final layer where components can be interpreted as latent states within a Neural PC. First, HNN conducts the supervised estimation of nonlinearities that arise when translating a high-dimensional set of observed regressors into latent states. Second, forecasts are economically interpretable. Among other findings, the contribution of real activity to inflation appears understated in traditional PCs. In contrast, HNN captures the 2021 upswing in inflation and attributes it to a large positive output gap starting from late 2020. The unique path of HNN’s gap comes from dispensing with unemployment and GDP in favor of an amalgam of nonlinearly processed alternative tightness indicators.},
  archive      = {J_JBES},
  author       = {Philippe Goulet Coulombe},
  doi          = {10.1080/07350015.2024.2421279},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {669-683},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A neural phillips curve and a deep output gap},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Group sparse β-model for network. <em>JBES</em>, <em>43</em>(3), 657-668. (<a href='https://doi.org/10.1080/07350015.2024.2418849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparsity, homogeneity, and heterogeneity are three important characteristics of many real-life networks. The recently proposed Sparse β -Model divides nodes into core ones and peripheral ones to accommodate sparsity, but the parameters of core nodes are assumed to be of similar magnitude, which may not be in line with applications. In this article, we propose the Group Sparse β -Model that splits the core nodes into groups and assumes different orders of magnitude of parameters in different groups, accounting for the heterogeneity among core nodes. When the groups are known, we provide consistent and asymptotically normal moment estimators of the parameters that control the global and local density. Based on that, consistency and asymptotic normality of the maximum likelihood estimators of the remaining parameters are derived. We also establish finite-sample error bounds results. When the groups are unknown, a ratio method is proposed to detect groups, which is computationally efficient. Simulations show competitive results and the analysis of a corporate inter-relationships network illustrates the usefulness of the proposed model.},
  archive      = {J_JBES},
  author       = {Zhonghan Wang and Junlong Zhao},
  doi          = {10.1080/07350015.2024.2418849},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {657-668},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Group sparse β-model for network},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Testing for equal average forecast accuracy in possibly unstable environments. <em>JBES</em>, <em>43</em>(3), 643-656. (<a href='https://doi.org/10.1080/07350015.2024.2418835'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the issue of testing the null of equal average forecast accuracy in a model where the forecast error loss differential series has a potentially nonconstant mean function over time. We show that when time variation is present in the loss differential mean, the standard Diebold and Mariano test, which was proposed for evaluating forecasts in a stable environment, has an asymptotic size of zero, and, whilst consistent, can have reduced local power. This arises due to inconsistent estimation of the implicit long run variance estimator, which diverges under a time varying mean. We suggest a modified statistic that replaces the standard long run variance estimator based on full-sample demeaning of the loss differential series with one based on nonparametric local demeaning. The new long run variance estimator is consistent under both the null and alternative when the mean function is time varying or constant, and in both cases, the modified test recovers the asymptotic size and power properties associated with the original test in the constant mean case. The modified test therefore provides a robust method for testing the equal average forecast accuracy null, allowing for instability in the loss differential mean. The benefits of our test are demonstrated via Monte Carlo simulation and two empirical applications.},
  archive      = {J_JBES},
  author       = {David I. Harvey and Stephen J. Leybourne and Yang Zu},
  doi          = {10.1080/07350015.2024.2418835},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {643-656},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Testing for equal average forecast accuracy in possibly unstable environments},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inference in experiments with matched pairs and imperfect compliance. <em>JBES</em>, <em>43</em>(3), 627-642. (<a href='https://doi.org/10.1080/07350015.2024.2416972'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies inference for the local average treatment effect in randomized controlled trials with imperfect compliance where treatment status is determined according to “matched pairs.” By “matched pairs,” we mean that units are sampled iid from the population of interest, paired according to observed, baseline covariates and finally, within each pair, one unit is selected at random for treatment. Under weak assumptions governing the quality of the pairings, we first derive the limit distribution of the usual Wald (i.e., two-stage least squares) estimator of the local average treatment effect. We show further that conventional heteroscedasticity-robust estimators of the Wald estimator’s limiting variance are generally conservative, in that their probability limits are (typically strictly) larger than the limiting variance. We therefore provide an alternative estimator of the limiting variance that is consistent. Finally, we consider the use of additional observed, baseline covariates not used in pairing units to increase the precision with which we can estimate the local average treatment effect. To this end, we derive the limiting behavior of a two-stage least squares estimator of the local average treatment effect which includes both the additional covariates in addition to pair fixed effects, and show that its limiting variance is always less than or equal to that of the Wald estimator. To complete our analysis, we provide a consistent estimator of this limiting variance. A simulation study confirms the practical relevance of our theoretical results. Finally, we apply our results to revisit a prominent experiment studying the effect of macroinsurance on microenterprise in Egypt.},
  archive      = {J_JBES},
  author       = {Yuehao Bai and Hongchang Guo and Azeem M. Shaikh and Max Tabord-Meehan},
  doi          = {10.1080/07350015.2024.2416972},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {627-642},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Inference in experiments with matched pairs and imperfect compliance},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Penalized sparse covariance regression with high dimensional covariates. <em>JBES</em>, <em>43</em>(3), 615-626. (<a href='https://doi.org/10.1080/07350015.2024.2415109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Covariance regression offers an effective way to model the large covariance matrix with the auxiliary similarity matrices. In this work, we propose a sparse covariance regression (SCR) approach to handle the potentially high-dimensional predictors (i.e., similarity matrices). Specifically, we use the penalization method to identify the informative predictors and estimate their associated coefficients simultaneously. We first investigate the Lasso estimator and subsequently consider the folded concave penalized estimation methods (e.g., SCAD and MCP). However, the theoretical analysis of the existing penalization methods is primarily based on iid data, which is not directly applicable to our scenario. To address this difficulty, we establish the non-asymptotic error bounds by exploiting the spectral properties of the covariance matrix and similarity matrices. Then, we derive the estimation error bound for the Lasso estimator and establish the desirable oracle property of the folded concave penalized estimator. Extensive simulation studies are conducted to corroborate our theoretical results. We also illustrate the usefulness of the proposed method by applying it to a Chinese stock market dataset.},
  archive      = {J_JBES},
  author       = {Yuan Gao and Zhiyuan Zhang and Zhanrui Cai and Xuening Zhu and Tao Zou and Hansheng Wang},
  doi          = {10.1080/07350015.2024.2415109},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {615-626},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Penalized sparse covariance regression with high dimensional covariates},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An oracle inequality for multivariate dynamic quantile forecasting. <em>JBES</em>, <em>43</em>(3), 603-614. (<a href='https://doi.org/10.1080/07350015.2024.2415107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I derive an oracle inequality for a family of possibly misspecified multivariate conditional autoregressive quantile models. The family includes standard specifications for (nonlinear) quantile prediction proposed in the literature. This inequality is used to establish that the predictor that minimizes the in-sample average check loss achieves the best out-of-sample performance within its class at a near optimal rate, even when the model is fully misspecified. An empirical application to backtesting global Growth-at-Risk shows that a combination of the generalized autoregressive conditionally heteroscedastic model and the vector autoregression for Value-at-Risk performs best out-of-sample in terms of the check loss.},
  archive      = {J_JBES},
  author       = {Jordi Llorens-Terrazas},
  doi          = {10.1080/07350015.2024.2415107},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {603-614},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {An oracle inequality for multivariate dynamic quantile forecasting},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correcting for misclassified binary regressors using instrumental variables. <em>JBES</em>, <em>43</em>(3), 592-602. (<a href='https://doi.org/10.1080/07350015.2024.2415102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimators that exploit an instrumental variable to correct for misclassification in a binary regressor typically assume that the misclassification rates are invariant across all values of the instrument. We show this assumption is invalid in routine empirical settings. We derive a new estimator which allows misclassification rates to vary across values of the instrumental variable. Our key identifying assumption, that the sum of misclassification rates remains constant across instrument values, follows from the empirical examples we present. We also show this assumption can be relaxed using moment inequalities that arise from our model. We demonstrate the usefulness of our estimator through Monte Carlo simulations and a reanalysis of the extent to which Medicaid eligibility crowds out other forms of health insurance. Correcting for measurement error substantially reduces estimates of crowd out and the extent to which Medicaid eligibility lowers the share of the uninsured.},
  archive      = {J_JBES},
  author       = {Steven J. Haider and Melvin Stephens Jr.},
  doi          = {10.1080/07350015.2024.2415102},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {592-602},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Correcting for misclassified binary regressors using instrumental variables},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust estimation for threshold autoregressive moving-average models. <em>JBES</em>, <em>43</em>(3), 579-591. (<a href='https://doi.org/10.1080/07350015.2024.2412011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Threshold autoregressive moving-average (TARMA) models extend the popular TAR model and are among the few parametric time series specifications to include a moving average in a nonlinear setting. The state dependent reactions to shocks is particularly appealing in Economics and Finance. However, no theory is currently available when the data present heavy tails or anomalous observations. Here we provide the first theoretical framework for robust M -estimation for TARMA models and study its practical relevance. Under mild conditions, we show that the robust estimator for the threshold parameter is super-consistent, while the estimators for autoregressive and moving-average parameters are strongly consistent and asymptotically normal. The Monte Carlo study shows that the M -estimator is superior, in terms of both bias and variance, to the least squares estimator, which can be heavily affected by outliers. The findings suggest that robust M -estimation should be generally preferred to the least squares method. We apply our methodology to a set of commodity price time series; the robust TARMA fit presents smaller standard errors and superior forecasting accuracy. The results support the hypothesis of a two-regime non-linearity characterized by slow expansions and fast contractions.},
  archive      = {J_JBES},
  author       = {Greta Goracci and Davide Ferrari and Simone Giannerini and Francesco Ravazzolo},
  doi          = {10.1080/07350015.2024.2412011},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {579-591},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Robust estimation for threshold autoregressive moving-average models},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revisiting panel data binary choice models with lagged dependent variables. <em>JBES</em>, <em>43</em>(3), 568-578. (<a href='https://doi.org/10.1080/07350015.2024.2412006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article revisits the identification and estimation of a class of semiparametric (distribution-free) panel data binary choice models with lagged dependent variables, exogenous covariates, and entity fixed effects. We provide a novel identification strategy, using an “identification at infinity” argument. In contrast with the celebrated work by Honoré and Kyriazidou published in 2000, our method permits time trends of any form and does not suffer from the “curse of dimensionality”. We propose an easily implementable conditional maximum score estimator. The asymptotic properties of the proposed estimator are fully characterized. A small-scale Monte Carlo study demonstrates that our approach performs satisfactorily in finite samples. We illustrate the usefulness of our method by presenting an empirical application to enrollment in private hospital insurance using the Household, Income and Labor Dynamics in Australia (HILDA) Survey data.},
  archive      = {J_JBES},
  author       = {Christopher R. Dobronyi and Fu Ouyang and Thomas Tao Yang},
  doi          = {10.1080/07350015.2024.2412006},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {568-578},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Revisiting panel data binary choice models with lagged dependent variables},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Endogenous kink threshold regression. <em>JBES</em>, <em>43</em>(3), 556-567. (<a href='https://doi.org/10.1080/07350015.2024.2407634'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers an endogenous kink threshold regression model with an unknown threshold value in a time series as well as a panel data framework, where both the threshold variable and regressors are allowed to be endogenous. We construct our estimators from a nonparametric control function approach and derive the consistency and asymptotic distribution of our proposed estimators. Monte Carlo simulations are used to assess the finite sample performance of our proposed estimators. Finally, we apply our model to analyze the impact of COVID-19 cases on labor markets in the United States and Canada.},
  archive      = {J_JBES},
  author       = {Jianhan Zhang and Chaoyi Chen and Yiguo Sun and Thanasis Stengos},
  doi          = {10.1080/07350015.2024.2407634},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {556-567},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Endogenous kink threshold regression},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design-based theory for lasso adjustment in randomized block experiments and rerandomized experiments. <em>JBES</em>, <em>43</em>(3), 544-555. (<a href='https://doi.org/10.1080/07350015.2024.2403381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blocking, a special case of rerandomization, is routinely implemented in the design stage of randomized experiments to balance the baseline covariates. This study proposes a regression adjustment method based on the least absolute shrinkage and selection operator (Lasso) to efficiently estimate the average treatment effect in randomized block experiments with high-dimensional covariates. We derive the asymptotic properties of the proposed estimator and outline the conditions under which this estimator is more efficient than the unadjusted one. We provide a conservative variance estimator to facilitate valid inferences. Our framework allows one treated or control unit in some blocks and heterogeneous propensity scores across blocks, thus including paired experiments and finely stratified experiments as special cases. We further accommodate rerandomized experiments and a combination of blocking and rerandomization. Moreover, our analysis allows both the number of blocks and block sizes to tend to infinity, as well as heterogeneous treatment effects across blocks without assuming a true outcome data-generating model. Simulation studies and two real-data analyses demonstrate the advantages of the proposed method.},
  archive      = {J_JBES},
  author       = {Ke Zhu and Hanzhong Liu and Yuehan Yang},
  doi          = {10.1080/07350015.2024.2403381},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {544-555},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Design-based theory for lasso adjustment in randomized block experiments and rerandomized experiments},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic quantile factor analysis. <em>JBES</em>, <em>43</em>(3), 530-543. (<a href='https://doi.org/10.1080/07350015.2024.2396956'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article extends quantile factor analysis to a probabilistic variant that incorporates regularization and computationally efficient variational approximations. We establish through synthetic and real data experiments that the proposed estimator can, in many cases, achieve better accuracy than a recently proposed loss-based estimator. We contribute to the factor analysis literature by extracting new indexes of low , medium , and high economic policy uncertainty, as well as loose , median , and tight financial conditions. We show that the high uncertainty and tight financial conditions indexes have superior predictive ability for various measures of economic activity. In a high-dimensional exercise involving about 1000 daily financial series, we find that quantile factors also provide superior out-of-sample information compared to mean or median factors.},
  archive      = {J_JBES},
  author       = {Dimitris Korobilis and Maximilian Schröder},
  doi          = {10.1080/07350015.2024.2396956},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {530-543},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Probabilistic quantile factor analysis},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved divide-and-conquer approach to estimating mean functional, with application to average treatment effect estimation. <em>JBES</em>, <em>43</em>(3), 520-529. (<a href='https://doi.org/10.1080/07350015.2024.2395429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mean estimation is an important issue in statistical inference and machine learning. We are concerned with estimating mean functional that is a function of several nonparametric functions when there is a large amount of observations. Directly estimating such mean functional through nonparametric smoothing has the complexity of at least a quadratic order of the sample size, which is computationally prohibitive for massive data. The divide-and-conquer approach are thus readily used to alleviate the computational complexity issue, which however imposes a stringent condition on the sample size in each local machine if a locally optimal bandwidth is used. To address this issue, we suggest to use a globally optimal bandwidth in each local machine, which alleviates the restriction on the local sample sizes substantially. We show that the divide-and-conquer approach with a globally optimal bandwidth achieves the estimation efficiency bound as if all observations were pooled together. In terms of computational efficiency, our proposal outperforms the pooled algorithm dramatically. We demonstrate these properties through average treatment effect estimation from both the asymptotic and the non-asymptotic perspectives.},
  archive      = {J_JBES},
  author       = {Zhengtian Zhu and Liping Zhu},
  doi          = {10.1080/07350015.2024.2395429},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {520-529},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {An improved divide-and-conquer approach to estimating mean functional, with application to average treatment effect estimation},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distinguishing time-varying factor models. <em>JBES</em>, <em>43</em>(3), 508-519. (<a href='https://doi.org/10.1080/07350015.2024.2395424'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-varying factor models have been widely used to model changing relationships among economic and financial variables. The existing literature usually specifies the time-varying factor loadings as deterministic functions of time or unit root processes. This article proposes two consistent tests to distinguish between these two specifications based on a randomization approach. By setting the null hypothesis as either specification, we show that the proposed test statistics follow an asymptotic Chi-squared distribution under the respective null hypotheses and diverge to infinity in probability under the respective alternatives. Simulation studies reveal that both test statistics perform reasonably well in finite samples. We apply the proposed tests to the U.S. macroeconomic and global macroeconomic and financial datasets. The results suggest that the time-varying factor loadings as deterministic functions of time should be adopted for these two applications.},
  archive      = {J_JBES},
  author       = {Zhonghao Fu and Liangjun Su and Xia Wang},
  doi          = {10.1080/07350015.2024.2395424},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {508-519},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Distinguishing time-varying factor models},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-based co-clustering in customer targeting utilizing large-scale online product rating networks. <em>JBES</em>, <em>43</em>(3), 495-507. (<a href='https://doi.org/10.1080/07350015.2024.2395423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the widely available online customer ratings on products, the individual-level rating prediction and clustering of customers and products are increasingly important for sellers to create targeting strategies for expanding the customer base and improving product ratings. However, the massive missing data problem is a significant challenge for modeling online product ratings. To address this issue, we propose a new co-clustering methodology based on a bipartite network modeling of large-scale ordinal product ratings. Our method extends existing co-clustering methods by incorporating covariates and ordinal ratings in the model-based co-clustering of a weighted bipartite network. We devise an efficient variational EM algorithm for model estimation. A simulation study demonstrates that our methodology is scalable for modeling large datasets and provides accurate estimation and clustering results. We further show that our model can successfully identify different groups of customers and products with meaningful interpretations and achieve promising predictive performance in a real application for customer targeting.},
  archive      = {J_JBES},
  author       = {Qian Chen and Amal Agarwal and Duncan K. H. Fong and Wayne S. DeSarbo and Lingzhou Xue},
  doi          = {10.1080/07350015.2024.2395423},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {495-507},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Model-based co-clustering in customer targeting utilizing large-scale online product rating networks},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jcgs">JCGS - 31</h2>
<ul>
<li><details>
<summary>
(2025). Quantile regression and homogeneity identification of a semiparametric panel data model. <em>JCGS</em>, <em>34</em>(3), 1169-1187. (<a href='https://doi.org/10.1080/10618600.2024.2433672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we delve into the quantile regression and homogeneity detection of a varying index coefficient panel data model, which incorporates fixed individual effects and exhibits nonlinear time trends. Using spline approximation, we obtain estimators for the trend functions, link functions, and index parameters, and subsequently establish the corresponding convergence rates and asymptotic normality. Observing that subjects within a group may share identical trend functions, we are motivated to further explore potential homogeneity in these trends. To this end, we propose a homogeneity identification algorithm based on binary segmentation. For the determination of the thresholding parameter in homogeneity identification, we propose a generalized Bayesian information criterion. Furthermore, we introduce a penalized method to discern the constant and linear structures within the nonparametric functions of our model. By leveraging grouped observations, we achieve more efficient estimation and improve the asymptotic properties of the estimators. To demonstrate the finite sample performance of our proposed approach, we conduct simulation studies and apply our methodology to a real-world dataset comprising Air Pollution Data and Integrated Surface Data (APD&ISD). Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Rui Li and Tao Li and Huacheng Su and Jinhong You},
  doi          = {10.1080/10618600.2024.2433672},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1169-1187},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Quantile regression and homogeneity identification of a semiparametric panel data model},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural bayes estimators for irregular spatial data using graph neural networks. <em>JCGS</em>, <em>34</em>(3), 1153-1168. (<a href='https://doi.org/10.1080/10618600.2024.2433671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Bayes estimators are neural networks that approximate Bayes estimators in a fast and likelihood-free manner. Although they are appealing to use with spatial models, where estimation is often a computational bottleneck, neural Bayes estimators in spatial applications have, to date, been restricted to data collected over a regular grid. These estimators are also currently dependent on a prescribed set of spatial locations, which means that the neural network needs to be retrained for new datasets; this renders them impractical in many applications and impedes their widespread adoption. In this work, we employ graph neural networks (GNNs) to tackle the important problem of parameter point estimation from data collected over arbitrary spatial locations. In addition to extending neural Bayes estimation to irregular spatial data, the use of GNNs leads to substantial computational benefits, since the estimator can be used with any configuration or number of locations and independent replicates, thus, amortizing the cost of training for a given spatial model. We also facilitate fast uncertainty quantification by training an accompanying neural Bayes estimator that approximates a set of marginal posterior quantiles. We illustrate our methodology on Gaussian and max-stable processes. Finally, we showcase our methodology on a dataset of global sea-surface temperature, where we estimate the parameters of a Gaussian process model in 2161 spatial regions, each containing thousands of irregularly-spaced data points, in just a few minutes with a single graphics processing unit. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Matthew Sainsbury-Dale and Andrew Zammit-Mangion and Jordan Richards and Raphaël Huser},
  doi          = {10.1080/10618600.2024.2433671},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1153-1168},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Neural bayes estimators for irregular spatial data using graph neural networks},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visualization and assessment of copula symmetry. <em>JCGS</em>, <em>34</em>(3), 1140-1152. (<a href='https://doi.org/10.1080/10618600.2024.2432978'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visualization and assessment of copula structures are crucial for accurately understanding and modeling the dependencies in multivariate data analysis. In this article, we introduce an innovative method that employs functional boxplots and rank-based testing procedures to evaluate copula symmetries. This approach is specifically designed to assess key characteristics such as reflection symmetry, radial symmetry, and joint symmetry. We first construct test functions for each specific property and then investigate the asymptotic properties of their empirical estimators. We demonstrate that the functional boxplot of these sample test functions serves as an informative visualization tool of a given copula structure, effectively measuring the departure from zero of the test function. Furthermore, we introduce a nonparametric testing procedure to assess the significance of deviations from symmetry, ensuring the accuracy and reliability of our visualization method. Through extensive simulation studies involving various copula models, we demonstrate the effectiveness of our testing approach. Finally, we apply our visualization and testing techniques to three real-world datasets: a nutritional habits survey with five variables, stock price data for the five top companies in the NASDAQ-100 stock index, and two major stock indices, the US S&P500 and German DAX. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Cristian F. Jiménez-Varón and Hao Lee and Marc G. Genton and Ying Sun},
  doi          = {10.1080/10618600.2024.2432978},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1140-1152},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Visualization and assessment of copula symmetry},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable estimation and two-sample testing for large networks via subsampling. <em>JCGS</em>, <em>34</em>(3), 1127-1139. (<a href='https://doi.org/10.1080/10618600.2024.2432974'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, large networks are routinely used to represent data from many scientific fields. Statistical analysis of these networks, such as estimation and hypothesis testing, has received considerable attention. However, most of the methods proposed in the literature are computationally expensive for large networks. In this article, we propose a subsampling-based method to reduce the computational cost of estimation and two-sample hypothesis testing. The idea is to divide the network into smaller subgraphs with an overlap region, then draw inference based on each subgraph, and finally combine the results together. We first develop the subsampling method for random dot product graph models, and establish theoretical consistency of the proposed method. Then we extend the subsampling method to a more general setup and establish similar theoretical properties. We demonstrate the performance of our methods through simulation experiments and real data analysis. Supplemental materials for the article are available online. The code is available in the following GitHub repository: https://github.com/kchak19/SubsampleTestingNetwork . Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Kaustav Chakraborty and Srijan Sengupta and Yuguo Chen},
  doi          = {10.1080/10618600.2024.2432974},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1127-1139},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Scalable estimation and two-sample testing for large networks via subsampling},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FlexBART: Flexible bayesian regression trees with categorical predictors. <em>JCGS</em>, <em>34</em>(3), 1117-1126. (<a href='https://doi.org/10.1080/10618600.2024.2431072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most implementations of Bayesian additive regression trees (BART) one-hot encode categorical predictors, replacing each one with several binary indicators, one for every level or category. Regression trees built with these indicators partition the discrete set of categorical levels by repeatedly removing one level at a time. Unfortunately, the vast majority of partitions cannot be built with this strategy, severely limiting BART’s ability to partially pool data across groups of levels. Motivated by analyses of baseball data and neighborhood-level crime dynamics, we overcame this limitation by re-implementing BART with regression trees that can assign multiple levels to both branches of a decision tree node. To model spatial data aggregated into small regions, we further proposed a new decision rule prior that creates spatially contiguous regions by deleting a random edge from a random spanning tree of a suitably defined network. Our re-implementation, which is available in the flexBART package, often yields improved out-of-sample predictive performance and scales better to larger datasets than existing implementations of BART. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Sameer K. Deshpande},
  doi          = {10.1080/10618600.2024.2431072},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1117-1126},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {FlexBART: Flexible bayesian regression trees with categorical predictors},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monotone cubic B-splines with a neural-network generator. <em>JCGS</em>, <em>34</em>(3), 1102-1116. (<a href='https://doi.org/10.1080/10618600.2024.2431070'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a method for fitting monotone curves using cubic B-splines with a monotonicity constraint on the coefficients. We explore different ways of enforcing this constraint and analyze their theoretical and empirical properties. We propose two algorithms for solving the spline fitting problem: one that uses standard optimization techniques and one that trains a Multi-Layer Perceptrons (MLP) generator to approximate the solutions under various settings and perturbations. The generator approach can speed up the fitting process when we need to solve the problem repeatedly, such as when constructing confidence bands using bootstrap. We evaluate our method against several existing methods, some of which do not use the monotonicity constraint, on some monotone curves with varying noise levels. We demonstrate that our method outperforms the other methods, especially in high-noise scenarios. We also apply our method to analyze the polarization-hole phenomenon during star formation in astrophysics. The source code is accessible at https://github.com/szcf-weiya/MonotoneSplines.jl . Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Lijun Wang and Xiaodan Fan and Huabai Li and Jun S. Liu},
  doi          = {10.1080/10618600.2024.2431070},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1102-1116},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Monotone cubic B-splines with a neural-network generator},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decentralized learning of quantile regression: A smoothing approach. <em>JCGS</em>, <em>34</em>(3), 1091-1101. (<a href='https://doi.org/10.1080/10618600.2024.2431060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed estimation has attracted a significant amount of attention recently due to its advantages in computational efficiency and data privacy preservation. In this article, we focus on quantile regression over a decentralized network. Without a coordinating central node, a decentralized network improves system stability and increases efficiency by communicating with fewer nodes per round. However, existing related works on decentralized quantile regression have slow (sub-linear) convergence speed. We propose a novel method for decentralized quantile regression which is built upon the smoothed quantile loss. However, we argue that the smoothed loss proposed in the existing literature using a single smoothing bandwidth parameter fails to achieve fast convergence and statistical efficiency simultaneously in the decentralized setting. We propose a novel quadratic approximation of the quantile loss using a big bandwidth for the Hessian and a small bandwidth for the gradient. Our method enjoys a linear convergence rate and has optimal statistical efficiency. Numerical experiments and real data analysis are conducted to demonstrate the effectiveness of our method. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Jianwei Shi and Yue Wang and Zhongyi Zhu and Heng Lian},
  doi          = {10.1080/10618600.2024.2431060},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1091-1101},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Decentralized learning of quantile regression: A smoothing approach},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local clustering for functional data. <em>JCGS</em>, <em>34</em>(3), 1075-1090. (<a href='https://doi.org/10.1080/10618600.2024.2431057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In functional data analysis, unsupervised clustering has been extensively conducted and has important implications. In most of the existing functional clustering analyses, it is assumed that there is a single clustering structure across the whole domain of measurement (say, time interval). In some data analyses, for example, the analysis of normalized COVID-19 daily confirmed cases for the U.S. states, it is observed that functions can have different clustering patterns in different time subintervals. To tackle the lack of flexibility of the existing functional clustering techniques, we develop a local clustering approach, which can fully data-dependently identify subintervals, where, in different subintervals, functions have different clustering structures. This approach is built on the basis expansion technique and has a novel penalization form. It simultaneously achieves subinterval identification, clustering, and estimation. Its estimation and clustering consistency properties are rigorously established. In simulation, it significantly outperforms multiple competitors. In the analysis of the COVID-19 case trajectory data, it identifies sensible subintervals and clustering structures. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Yuanxing Chen and Qingzhao Zhang and Shuangge Ma},
  doi          = {10.1080/10618600.2024.2431057},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1075-1090},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Local clustering for functional data},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). No more, no less than sum of its parts: Groups, monoids, and the algebra of graphics, statistics, and interaction. <em>JCGS</em>, <em>34</em>(3), 1063-1074. (<a href='https://doi.org/10.1080/10618600.2024.2429708'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive data visualization has become a staple of modern data presentation. Yet, despite its growing popularity, we still lack a general framework for turning raw data into summary statistics that can be displayed by interactive graphics. This gap may stem from a subtle yet profound issue: while we would often like to treat graphics, statistics, and interaction in our plots as independent, they are in fact deeply connected. This article examines this interdependence in light of two fundamental concepts from category theory: groups and monoids. We argue that the knowledge of these algebraic structures can help us design sensible interactive graphics. Specifically, if we want our graphics to support interactive features which split our data into parts and then combine these parts back together (such as linked selection), then the statistics underlying our plots need to possess certain properties. By grounding our thinking in these algebraic concepts, we may be able to build more flexible and expressive interactive data visualization systems. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Adam Bartonicek and Simon Urbanek and Paul Murrell},
  doi          = {10.1080/10618600.2024.2429708},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1063-1074},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {No more, no less than sum of its parts: Groups, monoids, and the algebra of graphics, statistics, and interaction},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Functional projection K-means. <em>JCGS</em>, <em>34</em>(3), 1051-1062. (<a href='https://doi.org/10.1080/10618600.2024.2429706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new technique for simultaneous clustering and dimensionality reduction of functional data is proposed. The observations are projected into a low-dimensional subspace and clustered by means of a functional K -means. The subspace and the partition are estimated simultaneously by minimizing the within deviance in the reduced space. This allows us to find new dimensions with a very low within deviance, which should correspond to a high level of discriminant power. However, in some cases, the total deviance explained by the new dimensions is so low as to make the subspace, and therefore the partition identified in it, insignificant. To overcome this drawback, we add to the loss a penalty equal to the negative total deviance in the reduced space. In this way, subspaces with a low deviance are avoided. We show how several existing methods are particular cases of our proposal simply by varying the weight of the penalty. The estimation is improved by adding a regularization term to the loss in order to take into account the functional nature of the data by smoothing the centroids. In contrast to existing literature, which largely considers the smoothing as a pre-processing step, in our proposal regularization is integrated with the identification of both subspace and cluster partition. An alternating least squares algorithm is introduced to compute model parameter estimates. The effectiveness of our proposal is demonstrated through its application to both real and simulated data. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Roberto Rocci and Stefano A. Gattone},
  doi          = {10.1080/10618600.2024.2429706},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1051-1062},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Functional projection K-means},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse model-based clustering of three-way data via lasso-type penalties. <em>JCGS</em>, <em>34</em>(3), 1030-1050. (<a href='https://doi.org/10.1080/10618600.2024.2429705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixtures of matrix Gaussian distributions provide a probabilistic framework for clustering continuous matrix-variate data, which are increasingly common in various fields. Despite their widespread use and successful applications, these models suffer from over-parameterization, making them not suitable for even moderately sized matrix-variate data. To address this issue, we introduce a sparse model-based clustering approach for three-way data. Our approach assumes that the matrix mixture parameters are sparse and have different degrees of sparsity across clusters, enabling the induction of parsimony in a flexible manner. Estimation relies on the maximization of a penalized likelihood, with specifically tailored group and graphical lasso penalties. These penalties facilitate the selection of the most informative features for clustering three-way data where variables are recorded over multiple occasions, as well as allowing the identification of cluster-specific association structures. We conduct extensive testing of the proposed methodology on synthetic data and validate its effectiveness through an application to time-dependent crime patterns across multiple U.S. cities. Supplementary files for this article are available online.},
  archive      = {J_JCGS},
  author       = {Andrea Cappozzo and Alessandro Casa and Michael Fop},
  doi          = {10.1080/10618600.2024.2429705},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1030-1050},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Sparse model-based clustering of three-way data via lasso-type penalties},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A majorization-minimization gauss-newton method for 1-bit matrix completion. <em>JCGS</em>, <em>34</em>(3), 1017-1029. (<a href='https://doi.org/10.1080/10618600.2024.2428610'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 1-bit matrix completion, the aim is to estimate an underlying low-rank matrix from a partial set of binary observations. We propose a novel method for 1-bit matrix completion called Majorization-Minimization Gauss-Newton ( MMGN ). Our method is based on the majorization-minimization principle, which converts the original optimization problem into a sequence of standard low-rank matrix completion problems. We solve each of these sub-problems by a factorization approach that explicitly enforces the assumed low-rank structure and then apply a Gauss-Newton method. Using simulations and a real data example, we illustrate that in comparison to existing 1-bit matrix completion methods, MMGN outputs comparable if not more accurate estimates. In addition, it is often significantly faster, and less sensitive to the spikiness of the underlying matrix. In comparison with three standard generic optimization approaches that directly minimize the original objective, MMGN also exhibits a clear computational advantage, especially when the fraction of observed entries is small. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Xiaoqian Liu and Xu Han and Eric C. Chi and Boaz Nadler},
  doi          = {10.1080/10618600.2024.2428610},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1017-1029},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {A majorization-minimization gauss-newton method for 1-bit matrix completion},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-dimensional block diagonal covariance structure detection using singular vectors. <em>JCGS</em>, <em>34</em>(3), 1005-1016. (<a href='https://doi.org/10.1080/10618600.2024.2422985'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The assumption of independent subvectors arises in many aspects of multivariate analysis. In most real-world applications, however, we lack prior knowledge about the number of subvectors and the specific variables within each subvector. Yet, testing all these combinations is not feasible. For example, for a data matrix containing 15 variables, there are already 1 , 382 , 958 , 545 possible combinations. Given that zero correlation is a necessary condition for independence, independent subvectors exhibit a block diagonal covariance matrix. This article focuses on the detection of such block diagonal covariance structures in high-dimensional data and therefore also identifies uncorrelated subvectors. Our approach exploits the fact that the structure of the covariance matrix is mirrored by the structure of its eigenvectors. However, the true block diagonal structure is masked by noise in the sample case. To address this problem, we propose to use sparse approximations of the sample eigenvectors to reveal the sparse structure of the population eigenvectors. Notably, the right singular vectors of a data matrix with an overall mean of zero are identical to the sample eigenvectors of its covariance matrix. Using sparse approximations of these singular vectors instead of the eigenvectors makes the estimation of the covariance matrix obsolete. We demonstrate the performance of our method through simulations and provide real data examples. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Jan O. Bauer},
  doi          = {10.1080/10618600.2024.2422985},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1005-1016},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {High-dimensional block diagonal covariance structure detection using singular vectors},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal subsampling for data streams with measurement constrained categorical responses. <em>JCGS</em>, <em>34</em>(3), 994-1004. (<a href='https://doi.org/10.1080/10618600.2024.2421990'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-velocity, large-scale data streams have become pervasive. Frequently, the associated labels for such data prove costly to measure and are not always available upfront. Consequently, the analysis of such data poses a significant challenge. In this article, we develop a method that addresses this challenge by employing an online subsampling procedure and a multinomial logistic model for efficient analysis of high-velocity, large-scale data streams. Our algorithm is designed to sequentially update parameter estimation based on the A-optimality criterion. Moreover, it significantly increases computational efficiency while imposing minimal storage requirements. Theoretical properties are rigorously established to quantify the asymptotic behavior of the estimator. The method’s efficacy is further demonstrated through comprehensive numerical studies on both simulated and real-world datasets. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Jun Yu and Zhiqiang Ye and Mingyao Ai and Ping Ma},
  doi          = {10.1080/10618600.2024.2421990},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {994-1004},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Optimal subsampling for data streams with measurement constrained categorical responses},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent markov time-interaction processes. <em>JCGS</em>, <em>34</em>(3), 984-993. (<a href='https://doi.org/10.1080/10618600.2024.2421984'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present parametric and semiparametric latent Markov time-interaction processes, that are point processes where the occurrence of an event can increase or reduce the probability of future events. We first present time-interaction processes with parametric and nonparametric baselines, then we let model parameters be modulated by a discrete state continuous time latent Markov process. Posterior inference is based on a novel and efficient data augmentation approach in the Markov chain Monte Carlo framework. We illustrate with a simulation study; and an original application to terrorist attacks in Europe in the period 2001–2017, where we find two distinct latent clusters for the hazard of occurrence of terrorist events, negative association with GDP growth, and self-exciting phenomena. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Rosario Barone and Alessio Farcomeni and Maura Mezzetti},
  doi          = {10.1080/10618600.2024.2421984},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {984-993},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Latent markov time-interaction processes},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label random subspace ensemble classification. <em>JCGS</em>, <em>34</em>(3), 971-983. (<a href='https://doi.org/10.1080/10618600.2024.2421248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we develop a new ensemble learning framework, multi-label Random Subspace Ensemble (mRaSE), for multi-label classification. Given a base classifier (e.g., multinomial logistic regression, classification tree, K -nearest neighbors), mRaSE works by first randomly sampling a collection of subspaces, then choosing the best ones that achieve the minimum cross-validation errors and, finally, aggregating the chosen weak learners. In addition to its superior prediction performance, mRaSE also provides a model-free feature ranking depending on the given base classifier. An iterative version of mRaSE is also developed to further improve the performance. A model-free extension is pursued on the iterative version, leading to the so-called Super mRaSE , which accepts a collection of base classifiers as input to the algorithm. We show the proposed algorithms compared favorably with the state-of-the-art classification algorithm including random forest and deep neural network, via extensive simulation studies and two real data applications. The new algorithms are implemented in an updated version of the R package RaSEn .},
  archive      = {J_JCGS},
  author       = {Fan Bi and Jianan Zhu and Yang Feng},
  doi          = {10.1080/10618600.2024.2421248},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {971-983},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Multi-label random subspace ensemble classification},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-task learning for gaussian graphical regressions with high dimensional covariates. <em>JCGS</em>, <em>34</em>(3), 961-970. (<a href='https://doi.org/10.1080/10618600.2024.2421246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian graphical regression is a powerful approach for regressing the precision matrix of a Gaussian graphical model on covariates, which permits the response variables and covariates to outnumber the sample size. However, traditional approaches of fitting the model via separate node-wise lasso regressions overlook the network-induced structure among these regressions, leading to high error rates, particularly when the number of nodes is large. To address this issue, we propose a multi-task learning estimator for fitting Gaussian graphical regression models, which incorporates a cross-task group sparsity penalty and a within-task element-wise sparsity penalty to govern the sparsity of active covariates and their effects on the graph, respectively. We also develop an efficient augmented Lagrangian algorithm for computation, which solves subproblems with a semi-smooth Newton method. We further prove that our multi-task learning estimator has considerably lower error rates than the separate node-wise regression estimates, as the cross-task penalty enables borrowing information across tasks. We examine the utility of our method through simulations and an application to a gene co-expression network study with brain cancer patients. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Jingfei Zhang and Yi Li},
  doi          = {10.1080/10618600.2024.2421246},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {961-970},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Multi-task learning for gaussian graphical regressions with high dimensional covariates},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Qini curves for multi-armed treatment rules. <em>JCGS</em>, <em>34</em>(3), 948-960. (<a href='https://doi.org/10.1080/10618600.2024.2418820'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Qini curves have emerged as an attractive and popular approach for evaluating the benefit of data-driven targeting rules for treatment allocation. We propose a generalization of the Qini curve to multiple costly treatment arms that quantifies the value of optimally selecting among both units and treatment arms at different budget levels. We develop an efficient algorithm for computing these curves and propose bootstrap-based confidence intervals that are exact in large samples for any point on the curve. These confidence intervals can be used to conduct hypothesis tests comparing the value of treatment targeting using an optimal combination of arms with using just a subset of arms, or with a non-targeting assignment rule ignoring covariates, at different budget levels. We demonstrate the statistical performance in a simulation experiment and an application to treatment targeting for election turnout.},
  archive      = {J_JCGS},
  author       = {Erik Sverdrup and Han Wu and Susan Athey and Stefan Wager},
  doi          = {10.1080/10618600.2024.2418820},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {948-960},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Qini curves for multi-armed treatment rules},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sampling random graphs with specified degree sequences. <em>JCGS</em>, <em>34</em>(3), 934-947. (<a href='https://doi.org/10.1080/10618600.2024.2418817'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The configuration model is a standard tool for uniformly generating random graphs with a specified degree sequence, and is often used as a null model to evaluate how much of an observed network’s structure can be explained by its degree structure alone. A Markov chain Monte Carlo (MCMC) algorithm, based on a degree-preserving double-edge swap, provides an asymptotic solution to sample from the configuration model. However, accurately and efficiently detecting when this Markov chain is sufficiently close to its stationary distribution remains an unsolved problem. Here, we provide a solution to sample from the configuration model using this standard MCMC algorithm. We develop an algorithm, based on the assortativity of the sampled graphs, for estimating the gap between effectively independent MCMC states, and a computationally efficient gap-estimation heuristic derived from analyzing a corpus of 509 empirical networks. We provide a convergence detection method based on the Dickey-Fuller Generalized Least Squares test, which we show is more accurate and efficient than three alternative Markov chain convergence tests. Supplementary materials for the proposed methods can be found here.},
  archive      = {J_JCGS},
  author       = {Upasana Dutta and Bailey K. Fosdick and Aaron Clauset},
  doi          = {10.1080/10618600.2024.2418817},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {934-947},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Sampling random graphs with specified degree sequences},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient sampling from the watson distribution in arbitrary dimensions. <em>JCGS</em>, <em>34</em>(3), 923-933. (<a href='https://doi.org/10.1080/10618600.2024.2416521'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present two efficient methods for sampling from the Watson distribution in arbitrary dimensions. The first method adapts the rejection sampling algorithm from Kent, Ganeiber, and Mardia , originally designed for Bingham distributions, using angular central Gaussian envelopes. For the Watson distribution, we derive a closed-form expression for the parameters that maximize sampling efficiency, which is further investigated and bounded by asymptotic results. This approach avoids the curse of dimensionality through a smart matrix inversion, enabling fast runtimes even in high dimensions. The second method, based on Saw , employs adaptive rejection sampling from a projected distribution. This algorithm is also effective in all dimensions and offers rapid sampling capabilities. Finally, our simulation study compares the two main methods, revealing that each excels under different conditions: the first method is more efficient for small samples or large dimensions, while the second performs better with larger samples and more concentrated distributions. Both algorithms are available in the R package watson on CRAN. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Lukas Sablica and Kurt Hornik and Josef Leydold},
  doi          = {10.1080/10618600.2024.2416521},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {923-933},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Efficient sampling from the watson distribution in arbitrary dimensions},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distortion corrected kernel density estimator on riemannian manifolds. <em>JCGS</em>, <em>34</em>(3), 906-922. (<a href='https://doi.org/10.1080/10618600.2024.2415543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manifold learning obtains a low-dimensional representation of an underlying Riemannian manifold supporting high-dimensional data. Kernel density estimates of the low-dimensional embedding with a fixed bandwidth fail to account for the way manifold learning algorithms distort the geometry of the Riemannian manifold. We propose a novel distortion-corrected kernel density estimator (DC-KDE) for any manifold learning embedding, with a bandwidth that depends on the estimated Riemannian metric at each data point. Exploiting the geometric information of the manifold leads to more accurate density estimation, which subsequently could be used for anomaly detection. To compare our proposed estimator with a fixed-bandwidth kernel density estimator, we run two simulations including one with data lying in a 100 dimensional ambient space. We demonstrate that the proposed DC-KDE improves the density estimates as long as the manifold learning embedding is of sufficient quality, and has higher rank correlations with the true manifold density. Further simulation results are provided via a supplementary R shiny app. The proposed method is applied to density estimation in statistical manifolds of electricity usage with the Irish smart meter data.},
  archive      = {J_JCGS},
  author       = {Fan Cheng and Rob J. Hyndman and Anastasios Panagiotelis},
  doi          = {10.1080/10618600.2024.2415543},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {906-922},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Distortion corrected kernel density estimator on riemannian manifolds},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sample efficient nonparametric regression via low-rank regularization. <em>JCGS</em>, <em>34</em>(3), 896-905. (<a href='https://doi.org/10.1080/10618600.2024.2414891'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonparametric regression suffers from curse of dimensionality, requiring a relatively large sample size for accurate estimation beyond the univariate case. In this article, we consider a simple method of dimension reduction in nonparametric regression via series estimation, based on the concept of low-rankness which was previously studied in parametric multivariate reduced-rank regression and matrix regression. For d > 2 , the low-rank assumption is realized via tensor regression. We establish a faster convergence rate of the estimator in the (approximate) low-rank case. Limitations of the model are also discussed. Through simulation studies and real data analysis, we compare the estimation accuracy of the proposed method with that of existing approaches. The results demonstrate that the proposed method yields estimates with lower RMSE compared to existing methods. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Jiakun Jiang and Jiahao Peng and Heng Lian},
  doi          = {10.1080/10618600.2024.2414891},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {896-905},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Sample efficient nonparametric regression via low-rank regularization},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable clustering: Large scale unsupervised learning of gaussian mixture models with outliers. <em>JCGS</em>, <em>34</em>(3), 884-895. (<a href='https://doi.org/10.1080/10618600.2024.2414889'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a widely used technique with a long and rich history in a variety of areas. However, most existing algorithms do not scale well to large datasets, or are missing theoretical guarantees of convergence. This article introduces a provably robust clustering algorithm based on loss minimization that performs well on Gaussian mixture models with outliers. It provides theoretical guarantees that the algorithm obtains high accuracy with high probability under certain assumptions. Moreover, it can also be used as an initialization strategy for k -means clustering. Experiments on real-world large-scale datasets demonstrate the effectiveness of the algorithm when clustering a large number of clusters, and a k -means algorithm initialized by the algorithm outperforms many of the classic clustering methods in both speed and accuracy, while scaling well to large datasets such as ImageNet. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Yijia Zhou and Kyle A. Gallivan and Adrian Barbu},
  doi          = {10.1080/10618600.2024.2414889},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {884-895},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Scalable clustering: Large scale unsupervised learning of gaussian mixture models with outliers},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous functional regression for subgroup analysis. <em>JCGS</em>, <em>34</em>(3), 872-883. (<a href='https://doi.org/10.1080/10618600.2024.2414113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With ever increasing number of features of modern datasets, data heterogeneity is gradually becoming the norm rather than the exception. Whereas classical regressions usually assume all the samples follow a common model, it becomes imperative to identify the heterogeneous relationship in different subsamples. In this article, we propose a new approach to model heterogeneous functional regression relations. We target at the association between a response and a predictor, whose relationship can vary across underlying subgroups and is modeled as an unknown functional of an auxiliary predictor. We introduce a procedure which performs simultaneous parameter estimation and subgroup identification through a fusion type group-wise penalization. We establish the statistical guarantees in terms of non-asymptotic convergence of the parameter estimation. We also establish the oracle property and asymptotic normality of the estimators. We carry out intensive simulations, and illustrate with a new dataset from an Alzheimer’s disease study. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Yeqing Zhou and Fei Jiang},
  doi          = {10.1080/10618600.2024.2414113},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {872-883},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Heterogeneous functional regression for subgroup analysis},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AddiVortes: (Bayesian) additive voronoi tessellations. <em>JCGS</em>, <em>34</em>(3), 859-871. (<a href='https://doi.org/10.1080/10618600.2024.2414104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Additive Voronoi Tessellations (AddiVortes) model is a multivariate regression model that uses Voronoi tessellations to partition the covariate space in an additive ensemble model. Unlike other partition methods, such as decision trees, this has the benefit of allowing the boundaries of the partitions to be non-orthogonal and nonparallel to the covariate axes. The AddiVortes model uses a similar sum-of-tessellations approach and a Bayesian backfitting MCMC algorithm to the BART model. We use regularization priors to limit the strength of individual tessellations and accepts new models based on a likelihood. The performance of the AddiVortes model is illustrated through testing on several datasets and comparing the performance to other models along with a simulation study to verify some of the properties of the model. In many cases, the AddiVortes model outperforms random forests, BART and other leading black-box regression models when compared using a range of metrics. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Adam J. Stone and John Paul Gosling},
  doi          = {10.1080/10618600.2024.2414104},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {859-871},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {AddiVortes: (Bayesian) additive voronoi tessellations},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differentially private methods for compositional data. <em>JCGS</em>, <em>34</em>(3), 848-858. (<a href='https://doi.org/10.1080/10618600.2024.2412174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Confidential data, such as electronic health records, activity data from wearable devices, and geolocation data, are becoming increasingly prevalent. Differential privacy provides a framework to conduct statistical analyses while mitigating the risk of leaking private information. Compositional data, which consist of vectors with positive components that add up to a constant, have received little attention in the differential privacy literature. This article proposes differentially private approaches for analyzing compositional data based on the Dirichlet distribution. We explore several methods, including Bayesian and bootstrap procedures. For the Bayesian methods, we consider posterior inference techniques based on Markov chain Monte Carlo, Approximate Bayesian Computation, and asymptotic approximations. We conduct an extensive simulation study to compare these approaches and make evidence-based recommendations. Finally, we apply the methodology to a dataset from the American Time Use Survey.},
  archive      = {J_JCGS},
  author       = {Qi Guo and Andrés F. Barrientos and Víctor Peña},
  doi          = {10.1080/10618600.2024.2412174},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {848-858},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Differentially private methods for compositional data},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MCMC for bayesian nonparametric mixture modeling under differential privacy. <em>JCGS</em>, <em>34</em>(3), 837-847. (<a href='https://doi.org/10.1080/10618600.2024.2410911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the probability density of a population while preserving the privacy of individuals in that population is an important and challenging problem that has received considerable attention in recent years. While the previous literature focused on frequentist approaches, in this article, we propose a Bayesian nonparametric mixture model under differential privacy (DP) and present two Markov chain Monte Carlo (MCMC) algorithms for posterior inference. One is a marginal approach, resembling Neal’s algorithm 5 with a pseudo-marginal Metropolis-Hastings move, and the other is a conditional approach. Although our focus is primarily on local DP, we show that our MCMC algorithms can be easily extended to deal with global differential privacy mechanisms. Moreover, for some carefully chosen mechanisms and mixture kernels, we show how auxiliary parameters can be analytically marginalized, allowing standard MCMC algorithms (i.e., non-privatized, such as Neal’s Algorithm 2) to be efficiently employed. Our approach is general and applicable to any mixture model and privacy mechanism. In several simulations and a real case study, we discuss the performance of our algorithms and evaluate different privacy mechanisms proposed in the frequentist literature. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Mario Beraha and Stefano Favaro and Vinayak Rao},
  doi          = {10.1080/10618600.2024.2410911},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {837-847},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {MCMC for bayesian nonparametric mixture modeling under differential privacy},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grid point approximation for distributed nonparametric smoothing and prediction. <em>JCGS</em>, <em>34</em>(3), 824-836. (<a href='https://doi.org/10.1080/10618600.2024.2409817'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel smoothing is a widely used nonparametric method in modern statistical analysis. The problem of efficiently conducting kernel smoothing for a massive dataset on a distributed system is a problem of great importance. In this work, we find that the popularly used one-shot type estimator is highly inefficient for prediction purposes. To this end, we propose a novel grid point approximation (GPA) method, which has the following advantages. First, the resulting GPA estimator is as statistically efficient as the global estimator under mild conditions. Second, it requires no communication and is extremely efficient in terms of computation for prediction. Third, it is applicable to the case where the data are not randomly distributed across different machines. To select a suitable bandwidth, two novel bandwidth selectors are further developed and theoretically supported. Extensive numerical studies are conducted to corroborate our theoretical findings. Two real data examples are also provided to demonstrate the usefulness of our GPA method. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Yuan Gao and Rui Pan and Feng Li and Riquan Zhang and Hansheng Wang},
  doi          = {10.1080/10618600.2024.2409817},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {824-836},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Grid point approximation for distributed nonparametric smoothing and prediction},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Network embedding-based directed community detection with unknown community number. <em>JCGS</em>, <em>34</em>(3), 812-823. (<a href='https://doi.org/10.1080/10618600.2024.2409789'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection of network analysis plays an important role in numerous application areas, in which estimating the number of communities is a fundamental issue. However, many existing methods focus on undirected networks ignoring the directionality of edges or unrealistically assume that the number of communities is known a priori. In this article, we develop a data-dependent community detection method for the directed network to determine the number of communities and recover community structures simultaneously, which absorbs the ideas of network embedding and penalized fusion by embedding the out- and in-nodes into low-dimensional vector space and forcing the embedding vectors toward its center. The asymptotic consistency properties of the proposed method are established in terms of network embedding, directed community detection, and estimation of the number of communities. The proposed method is applied on synthetic networks and real brain functional networks, which demonstrate the superior performance of the proposed method against a number of competitors. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Qingzhao Zhang and Jinlong Zhou and Mingyang Ren},
  doi          = {10.1080/10618600.2024.2409789},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {812-823},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Network embedding-based directed community detection with unknown community number},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient modeling of spatial extremes over large geographical domains. <em>JCGS</em>, <em>34</em>(3), 795-811. (<a href='https://doi.org/10.1080/10618600.2024.2409784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various natural phenomena exhibit spatial extremal dependence at short spatial distances. However, existing models proposed in the spatial extremes literature often assume that extremal dependence persists across the entire domain. This is a strong limitation when modeling extremes over large geographical domains, and yet it has been mostly overlooked in the literature. We here develop a more realistic Bayesian framework based on a novel Gaussian scale mixture model, with the Gaussian process component defined though a stochastic partial differential equation yielding a sparse precision matrix, and the random scale component modeled as a low-rank Pareto-tailed or Weibull-tailed spatial process determined by compactly-supported basis functions. We show that our proposed model is approximately tail-stationary and that it can capture a wide range of extremal dependence structures. Its inherently sparse probabilistic structure allows fast Bayesian computations in high spatial dimensions based on a customized Markov chain Monte Carlo algorithm prioritizing calibration in the tail. We fit our model to analyze heavy monsoon rainfall data in Bangladesh. Our study shows that our model outperforms natural competitors and that it fits precipitation extremes well. We finally use the fitted model to draw inference on long-term return levels for marginal precipitation and spatial aggregates. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Arnab Hazra and Raphaël Huser and David Bolin},
  doi          = {10.1080/10618600.2024.2409784},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {795-811},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Efficient modeling of spatial extremes over large geographical domains},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A latent space model for weighted keyword co-occurrence networks with applications in knowledge discovery in statistics. <em>JCGS</em>, <em>34</em>(3), 779-794. (<a href='https://doi.org/10.1080/10618600.2024.2407465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keywords are widely recognized as pivotal in conveying the central idea of academic articles. In this article, we construct a weighted and dynamic keyword co-occurrence network and propose a latent space model for analyzing it. Our model has two special characteristics. First, it is applicable to weighted networks; however, most previous models were primarily designed for unweighted networks. Simply replacing the frequency of keyword co-occurrence with binary values would result in a significant loss of information. Second, our model can handle the situation where network nodes evolve over time, and assess the effect of new nodes on network connectivity. We use the projected gradient descent algorithm to estimate the latent positions and establish the theoretical properties of the estimators. In the real data application, we study the keyword co-occurrence network within the field of statistics. We identify popular keywords over the whole period as well as within each time period. For keyword pairs, our model provides a new way to assess the association between them. Finally, we observe that the interest of statisticians in emerging research areas has gradually grown in recent years. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Yan Zhang and Rui Pan and Xuening Zhu and Kuangnan Fang and Hansheng Wang},
  doi          = {10.1080/10618600.2024.2407465},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {779-794},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {A latent space model for weighted keyword co-occurrence networks with applications in knowledge discovery in statistics},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jeee">JEEE - 7</h2>
<ul>
<li><details>
<summary>
(2025). Prey profile of jungle cat in human dominated landscape of southern west bengal: Evidence from camera traps. <em>JEEE</em>, <em>37</em>(2), 236-242. (<a href='https://doi.org/10.1080/03949370.2025.2453939'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Jungle cats ( Felis chaus ) are one of the least studied felids with a widespread presence throughout the southern districts of West Bengal. During a survey through camera traps to document fishing cats ( Prionailurus viverrinus ), we recorded bycatch data of camera trap captured images of Jungle cats with their prey. Although the diet of Jungle cats has been extensively studied using genetic methods globally, this paper presents evidence of its prey items through camera trap data. We obtained 196 independent images of Jungle cats, with 31 showing them with prey. Our data indicates that rodents are its primary prey. The images also reveal that Jungle cats’ prey on domestic duck and other birds. We recommend organizing awareness camps among locals to reduce retaliation and ensure the safe coexistence of jungle cats in human settlement areas.},
  archive      = {J_JEEE},
  author       = {Samrat Chakraborty and Paromit Chatterjee and Goutam K. Saha},
  doi          = {10.1080/03949370.2025.2453939},
  journal      = {Ethology Ecology & Evolution},
  month        = {3},
  number       = {2},
  pages        = {236-242},
  shortjournal = {Ethol. Ecol. Evol.},
  title        = {Prey profile of jungle cat in human dominated landscape of southern west bengal: Evidence from camera traps},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Are size-dependent aposematic patterns shaped by evolutionary pressures in “indestructible” velvet ants (Hymenoptera mutillidae)? a case study of neotropical species. <em>JEEE</em>, <em>37</em>(2), 224-235. (<a href='https://doi.org/10.1080/03949370.2025.2453906'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predation is one of the most powerful selective forces driving evolution among animals, and one common form of defense against it is aposematism. The Mutillidae (Hymenoptera Aculeata), commonly known as velvet ants, are solitary parasitoid wasps that exhibit a range of colors, including shades of white, yellow, orange-red, and black. In some Hymenoptera, a distinct color pattern consisting of a black head, an orange or red mesosoma, and a black metasoma – referred to as the Black-Orange-Black (BOB) pattern – may function as an aposematic signal to deter predators, particularly in smaller species. To investigate the presence of this pattern in Mutillidae and its potential association with body size, we tested the hypothesis that the BOB pattern is more prevalent in smaller species. The total body length of the individuals was measured in millimeters (mm), and they were categorized as either displaying the BOB pattern or not (non-BOB, NBOB). A total of 448 individuals from various genera were analyzed, of which 79 exhibited the BOB pattern. The BOB pattern was more frequently observed among individuals measuring between 4.5 and 7.5 mm in body size, indicating that these individuals tended to be smaller compared to those with the NBOB pattern. A significant difference in body size was detected between the two patterns. These findings suggest that aposematism may serve as an effective defensive strategy, particularly concentrated in smaller body sizes, within this group already recognized for its diverse array of anti-predator adaptations.},
  archive      = {J_JEEE},
  author       = {Luana Pereira de Melo and Rodrigo Aranda},
  doi          = {10.1080/03949370.2025.2453906},
  journal      = {Ethology Ecology & Evolution},
  month        = {3},
  number       = {2},
  pages        = {224-235},
  shortjournal = {Ethol. Ecol. Evol.},
  title        = {Are size-dependent aposematic patterns shaped by evolutionary pressures in “indestructible” velvet ants (Hymenoptera mutillidae)? a case study of neotropical species},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Substrate-induced chromatic variations in three species of leaf and stick insects (Insecta phasmatodea). <em>JEEE</em>, <em>37</em>(2), 210-223. (<a href='https://doi.org/10.1080/03949370.2025.2482531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mimicry, particularly chromatic adaptation, is a defining characteristic of leaf and stick insects, which comprise phasmids (Insecta Phasmatodea). This study investigates substrate-induced color changes in three phasmid species: Extatosoma tiaratum, Hesperophasma sp. “La Ciénaga”, and Phyllium gantungense “Rizal”. For each species, two experimental groups were exposed to a grey-green lichen ( Evernia prunastri ) as a substrate, while two cages were set up with an artificial pink material. Control groups were reared on elmleaf blackberry ( Rubus ulmifolius ) alone; all groups were composed of at least 20 individuals. Using digital pictures, the RGB color channels of juveniles and adults were analyzed to quantify color variations. We revealed significant species-specific variations in color development responses related to substrates. In E. tiaratum , we did not observe a significant difference between adults reared over different substrates. However, digital image analyses revealed that E. tiaratum exhibited significant chromatic changes during development, especially among 11 juvenile females, suggesting a potential genetic predisposition for substrate-specific color adaptation. In the species P. gantungense , we did not find color changes during the experiment, indicating a lack of phenotypic plasticity in response to substrate variation. Hesperophasma sp. “La Ciénaga” showed minimal color changes; however, untreated juveniles naturally darkened as they matured, a trend that was inhibited in substrate-treated groups, indicating a potential influence of the substrate on natural color development. These findings highlight the species-specific nature of substrate-induced color variation in stick insects. Investigating the genetic and physiological mechanisms underlying these changes is essential for understanding the evolutionary dynamics and ecological adaptations of these insects. Further research in this area could reveal insights into the broader implications of phenotypic plasticity and environmental adaptation in phasmids.},
  archive      = {J_JEEE},
  author       = {Mattia Ragazzini and Raffaele Gattelli and Federico Plazzi and Marco Passamonti},
  doi          = {10.1080/03949370.2025.2482531},
  journal      = {Ethology Ecology & Evolution},
  month        = {3},
  number       = {2},
  pages        = {210-223},
  shortjournal = {Ethol. Ecol. Evol.},
  title        = {Substrate-induced chromatic variations in three species of leaf and stick insects (Insecta phasmatodea)},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Echoes of adaptation: House sparrows’ ecological response to shifting human disturbances. <em>JEEE</em>, <em>37</em>(2), 188-209. (<a href='https://doi.org/10.1080/03949370.2025.2482523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human disturbances are being increasingly recognized for their impact on the behavior of urban wildlife during the Anthropocene. This study was conducted to gain insights into the changes in population density of House sparrows ( Passer domesticus ) to different degrees of human disturbance during various stages of COVID-19. A “disturbance score” was computed by considering four variables: human movement, number of vehicles plying, number of shops opened, and ambient noise level. Generalized Linear Mixed Model (GLMM) was used to understand the influence of the disturbance variables on the House sparrows’ density among different phases of lockdown and across different sites. Our findings revealed that the second COVID wave exhibited the highest population density (number/ha) at 4.64 ± 0.941, followed by the first wave at 3.73 ± 1.21. In addition, our results suggest that lockdown phases and disturbance variables significantly influenced the sparrow population density. Furthermore, there were notable variations in sparrow population densities across the different lockdown phases. Similarly, the disturbance variables seem to influence the sparrow population density across the lockdown phases, except for the before-lockdown and first-wave lockdowns, possibly indicating a lag in the sparrows’ adaptive response to the changing urban environment. The findings have unveiled a significant pattern in the behavioral responses of sparrows to human disruptions. The decline in the presence of sparrows in areas with higher anthropogenic disturbances, following the relaxation of lockdown regulations indicates a potential shift of these birds to quieter sites. The capacity of sparrows to adjust their behavior has enabled them to take advantage of decreased disruptions, which could impact their documented population density. Thus, this study emphasizes the need to incorporate wildlife behavioral responses to human disturbances into urban planning and management strategies.},
  archive      = {J_JEEE},
  author       = {Sakti P. Pattnayak and Priyanka Jena and B.A.K. Prusty and Arti Saxena},
  doi          = {10.1080/03949370.2025.2482523},
  journal      = {Ethology Ecology & Evolution},
  month        = {3},
  number       = {2},
  pages        = {188-209},
  shortjournal = {Ethol. Ecol. Evol.},
  title        = {Echoes of adaptation: House sparrows’ ecological response to shifting human disturbances},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Behavioral strategies between aphidius platensis and winter cereal aphids with a focus on parasitism. <em>JEEE</em>, <em>37</em>(2), 174-187. (<a href='https://doi.org/10.1080/03949370.2025.2453940'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aphids that infest cereal crops employ diverse survival strategies, including behavioral defenses to avoid parasitism. The Aphidiinae subfamily, particularly Aphidius platensis , plays an important role as a parasitoid in controlling cereal aphids. There is a lack of information on the behavioral aspects associated with aphids and parasitoids, along with their influence on parasitism rates. This study aimed to observe the apterous adult’s behavior of Rhopalosiphum padi , Schizaphis graminum , Metopolophium dirhodum , and Sitobion avenae and its parasitoid ( Aphidius platensis ) when exposed to each other and evaluate how these interactions reflect on parasitism rates. The behaviors were recorded (5 min) and analyzed using BORIS software. Parasitism rates were assessed by examining the presence of larvae and mummies. Schizaphis graminum was the highest recognized and accepted aphid species by A. platensis , with 95% of parasitism, followed by R. padi (68.3%), despite its ability to escape (walking), and S. avenae (13.2%), despite its kick behavior. Metopolophium dirhodum , with minimal kicking, was not parasitized. Our results showed that the parasitoid tends to be more aggressive (mainly probing and parasitizing) toward the host with which it has greatest parasitism ( S. graminum ). Aphid defensive behaviors were not sufficient to defend themselves, as parasitoid attacks were similar in those that walked and kicked more often. We observed that the parasitoid A. platensis behaved similarly on suitable and unsuitable hosts. This finding provides new information that can contribute to a better understanding of host–parasitoid interactions, which has implications for biological control strategies targeting aphids in winter cereals.},
  archive      = {J_JEEE},
  author       = {Carlos D.R. dos Santos and Josué Sant’Ana and Luiza Rodrigues Redaelli and Priscila de Carvalho Engel},
  doi          = {10.1080/03949370.2025.2453940},
  journal      = {Ethology Ecology & Evolution},
  month        = {3},
  number       = {2},
  pages        = {174-187},
  shortjournal = {Ethol. Ecol. Evol.},
  title        = {Behavioral strategies between aphidius platensis and winter cereal aphids with a focus on parasitism},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Permanent conspicuity in an amazonian weakly electric fish subjected to low predation risk. <em>JEEE</em>, <em>37</em>(2), 154-173. (<a href='https://doi.org/10.1080/03949370.2024.2444275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many organisms, changes in environmental conditions trigger modifications in physiology and signaling for reproduction. In males, sexual maturation often prompts signaling that can convey information on fighting ability and mate quality, allowing adaptative sexual selection to act. Because predation can drive the evolution of sexual signals, insights from organisms exposed to low predation pressure will benefit sexual selection theory. Here, we exposed males and females of Microsternarchus sp. nov. “Ducke” (Gymnotiformes Hypopomidae) to simulate environmental conditions of the breeding season to investigate changes in electric signaling in a species that occurs in environments with low or absent predation pressure from electroreceptive predators. We induced sexual maturation, which was confirmed by visual inspection of female gonads. After sexual maturation, both sexes underwent major changes in Electric Organ Discharges (EOD), suggesting mutual signaling in electric communication before breeding pair formation. EOD parameters related to body length were intensified in sexually mature males and, as such, changes in male electric discharges observed after gonadal maturation exaggerate information on fighting ability and mate quality, as suggested for other electric fishes. Because polarity imbalance was high in both sexes and reproductive stages, our results support the hypothesis that predation pressure did not constrain the evolution of conspicuous EODs in this species, in favor of other adaptive mechanisms of mate choice.},
  archive      = {J_JEEE},
  author       = {Carine M. Cola and Tiago H.S. Pires and Marina Anciães and José A. Alves-Gomes},
  doi          = {10.1080/03949370.2024.2444275},
  journal      = {Ethology Ecology & Evolution},
  month        = {3},
  number       = {2},
  pages        = {154-173},
  shortjournal = {Ethol. Ecol. Evol.},
  title        = {Permanent conspicuity in an amazonian weakly electric fish subjected to low predation risk},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Behavioral strategies of the freshwater crab sylviocarcinus pictus (Crustacea brachyura trichodactylidae) in severe aquatic environments in the brazilian semiarid region. <em>JEEE</em>, <em>37</em>(2), 139-153. (<a href='https://doi.org/10.1080/03949370.2025.2482533'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Severe environments, characterized by high temperatures and scarce rainfall, challenge organisms and may lead them to display behavioral adaptations to live in such areas. While there is a significant amount of research on behavioral adaptations to severe environments on land, aquatic habitats remain relatively understudied. In this study, we selected a population of Sylviocarcinus pictus crabs from the semiarid region of Brazil to investigate, describe, and quantify the behavioral repertoire of adult crabs in a laboratory setting. In the laboratory, we filmed ( n = 10) adult crabs individually (five males and five females), for 72 consecutive hours. Subsequently, we analyzed and recorded their behaviors every 20 min, totaling ( n = 240) videos analyzed. Based on the observations, we then constructed an ethogram with nine behaviors grouped into four categories: quiescence, environmental exploration, feeding, and self-cleaning. Our results indicate that, regardless of sex ( P = 0.39), S. pictus individuals remained more quiescent during the light period ( P < 0.05), with males spending 82.71% of the time quiescent and females spending 91.96% of their time quiescent. Additionally, individuals showed a substantial increase in the frequencies of activity-related behaviors during the dark period ( P < 0.05), with no significant differences between sexes. Compared to other species, S. pictus proved to be even more quiescent, especially during the day, possibly in response to the harsh environmental conditions. In the natural environment, we observed crabs seeking shelter under rocks during the day, possibly as a response to high temperatures. These findings suggest that the crabs have developed behavioral strategies to optimize energy use in severe aquatic environments.},
  archive      = {J_JEEE},
  author       = {Paulo H.P. Nobre and Alexandre V. Palaoro and Carlito A. Nascimento and Juliana G. Araújo and Carlos A.M. Martins and Whandenson M. Nascimento and Allysson P. Pinheiro},
  doi          = {10.1080/03949370.2025.2482533},
  journal      = {Ethology Ecology & Evolution},
  month        = {3},
  number       = {2},
  pages        = {139-153},
  shortjournal = {Ethol. Ecol. Evol.},
  title        = {Behavioral strategies of the freshwater crab sylviocarcinus pictus (Crustacea brachyura trichodactylidae) in severe aquatic environments in the brazilian semiarid region},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jetai">JETAI - 8</h2>
<ul>
<li><details>
<summary>
(2025). Correction. <em>JETAI</em>, <em>37</em>(6), i. (<a href='https://doi.org/10.1080/0952813X.2024.2417493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JETAI},
  doi          = {10.1080/0952813X.2024.2417493},
  journal      = {Journal of Experimental & Theoretical Artificial Intelligence},
  month        = {8},
  number       = {6},
  pages        = {i},
  shortjournal = {J. Exp. Theor. Artif. Intell.},
  title        = {Correction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized correlation coefficients of intuitionistic multiplicative sets and their applications to pattern recognition and clustering analysis. <em>JETAI</em>, <em>37</em>(6), 1013-1044. (<a href='https://doi.org/10.1080/0952813X.2024.2323039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic multiplicative preference relations (IMPRs) and intuitionistic multiplicative sets (IMSs) play a significant role in real-life problems that contain unsymmetrical and nonuniform information. Correlation coefficients are critical tools for evaluating such information, especially in medical areas and clustering analysis, where the relationship between objects in the given data is required. Despite the importance of this subject, there is only one approach in the literature regarding the correlation coefficients of IMSs and existing coefficients have certain disadvantages. In this paper, we propose a parametric generalisation of these correlation coefficients on IMSs and apply them to medical diagnosis, taxonomy, and clustering. To that end, some disadvantages of existing correlation coefficients are listed first. Then, with some theoretical work, we derive a parametric generalisation of these coefficients and their weighted forms. To better illustrate how the parametric generalisation of correlation coefficients improves the results, numerical parametric solutions of existing examples are presented with detailed comparisons. Moreover, a novel algorithm is introduced for clustering using proposed correlation coefficients in IMSs. Finally, three real-life examples are provided to demonstrate the superiority of the proposed generalised correlation coefficients and the clustering algorithm in specific applications.},
  archive      = {J_JETAI},
  author       = {Ali Köseoğlu},
  doi          = {10.1080/0952813X.2024.2323039},
  journal      = {Journal of Experimental & Theoretical Artificial Intelligence},
  month        = {8},
  number       = {6},
  pages        = {1013-1044},
  shortjournal = {J. Exp. Theor. Artif. Intell.},
  title        = {Generalized correlation coefficients of intuitionistic multiplicative sets and their applications to pattern recognition and clustering analysis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Satellite fault tolerant attitude control based on expert guided exploration of reinforcement learning agent. <em>JETAI</em>, <em>37</em>(6), 987-1011. (<a href='https://doi.org/10.1080/0952813X.2024.2321152'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research provides a method that accelerates learning and avoids local minima to improve the policy gradient algorithm’s learning process. Reinforcement learning has the advantage of not requiring a model. Consequently, it can improve control performance, mainly when a model is generally unavailable, such as when an error occurs. The proposed method efficiently and expeditiously investigates the action space. First, it quantifies the resemblance between agents’ and traditional controllers’ actions. Then, the principal reward function is modified to reflect this similarity. This reward-shaping mechanism guides the agent to maximize its return via an attractive force during the gradient ascent. To validate our concept, we establish a satellite attitude control environment with a similarity subsystem. The outcomes demonstrate the effectiveness and robustness of our method.},
  archive      = {J_JETAI},
  author       = {Hicham Henna and Houari Toubakh and Mohamed Redouane Kafi and Ömer Gürsoy and Moamar Sayed-Mouchaweh and Mohamed Djemai},
  doi          = {10.1080/0952813X.2024.2321152},
  journal      = {Journal of Experimental & Theoretical Artificial Intelligence},
  month        = {8},
  number       = {6},
  pages        = {987-1011},
  shortjournal = {J. Exp. Theor. Artif. Intell.},
  title        = {Satellite fault tolerant attitude control based on expert guided exploration of reinforcement learning agent},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-invasive anaemia detection based on palm pallor video using tree-structured 3D CNN and vision transformer models. <em>JETAI</em>, <em>37</em>(6), 957-985. (<a href='https://doi.org/10.1080/0952813X.2023.2301401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anaemia is a common disease that affects billions of people worldwide and is caused due to low blood haemoglobin level. According to WHO statistics, anaemia is the most prevalent in developing and underdeveloped countries. Conventional invasive methods are prohibitively expensive and difficult to administer globally, necessitating a non-invasive, low-cost, and user-friendly solution. This study aims to develop a non-invasive anaemia detection system by combining cutting-edge computational approaches with the age-old practice of estimating blood haemoglobin levels by observing pallor in the palm. The proposed system operates on the basis of inducing changes in palm pallor with appropriate pressure application and release, measuring the rate of colour changes, and performing time-domain analysis to correlate with blood haemoglobin concentration. The video of colour changes in the palm caused by a customised device is captured using a smartphone camera and processed and analysed using deep learning models based on tree-structured 3-Dimensional Convolutional Neural Network (3D CNN) and Vision Transformer (ViT) for accurate estimation of haemoglobin levels. The proposed system ensures a sensitivity, specificity, accuracy and RMSE of 96.87%, 90.90%, 94.44% and 0.495, respectively, while run on a dataset consisting of palm pallor video samples of 531 individuals.},
  archive      = {J_JETAI},
  author       = {Abhishek Kesarwani and Sunanda Das and Dakshina Ranjan Kisku and Mamata Dalui},
  doi          = {10.1080/0952813X.2023.2301401},
  journal      = {Journal of Experimental & Theoretical Artificial Intelligence},
  month        = {8},
  number       = {6},
  pages        = {957-985},
  shortjournal = {J. Exp. Theor. Artif. Intell.},
  title        = {Non-invasive anaemia detection based on palm pallor video using tree-structured 3D CNN and vision transformer models},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy logic in association rule mining: Limited effectiveness analysis. <em>JETAI</em>, <em>37</em>(6), 941-955. (<a href='https://doi.org/10.1080/0952813X.2023.2301377'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a comparative effectiveness analysis of fuzzy and non-fuzzy association rule mining (ARM). The corresponding motivation is the lack of relevant papers devoted to the effectiveness comparison between fuzzy and non-fuzzy ARM. The current research applies the results of fuzzy/non-fuzzy ARM to associative classification and uses the classification accuracy of the corresponding classifiers as the effectiveness measure. The research demonstrates that basic effectiveness comparison between fuzzy and non-fuzzy ARM does not necessarily speak in favour of fuzzy ARM. However, then the research demonstrates that fuzzy ARM has a distinctive ability to handle data inconsistencies, which results in the ability of corresponding fuzzy classifiers to not only provide class predictions but also indicate their certainty in the provided output. The research reveals some distinct correlation between classification accuracy and the degree of certainty in fuzzy associative classification: the greater certainty nearly always results in the better classification accuracy. This ability of fuzzy associative classifiers to indicate their certainty in the performed classification and the corresponding ability of fuzzy ARM to handle data inconsistencies are not applicable in non-fuzzy associative classifiers and ARM. Therefore, these abilities are used in the paper to substantiate the relevance of applying fuzzy logic in ARM.},
  archive      = {J_JETAI},
  author       = {Vugar E. Mirzakhanov},
  doi          = {10.1080/0952813X.2023.2301377},
  journal      = {Journal of Experimental & Theoretical Artificial Intelligence},
  month        = {8},
  number       = {6},
  pages        = {941-955},
  shortjournal = {J. Exp. Theor. Artif. Intell.},
  title        = {Fuzzy logic in association rule mining: Limited effectiveness analysis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LBO-MPAM: Ladybug beetle optimization-based multilayer perceptron attention module for segmenting the skin lesion and automatic localization. <em>JETAI</em>, <em>37</em>(6), 915-940. (<a href='https://doi.org/10.1080/0952813X.2023.2301374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, skin cancer has been the most dangerous disease noticed among people worldwide. Skin cancer should be identified earlier to reduce the rate of mortality. Employing dermoscopic images can identify and categorise skin cancer effectively. But, the visual evaluation is a complex procedure to be done in the dermoscopic image. However, Deep learning (DL) is an efficient method for skin cancer detection; however, segmenting the skin lesion and automatic localisation in an earlier stage is complicated. In this paper, a novel Ladybug Beetle Optimization-Double Attention Based Multilevel 1-D CNN (LBO-DAM 1-D CNN) technique is proposed to detect and classify skin cancer. To improve skin lesion type discriminability, the two types of attention modules are introduced. The Ultra-Lightweight Subspace Attention Module (ULSAM) is utilised for classifying the feature maps into different stages to validate the frequency from different image samples. However, the multilayer perceptron attention module (MLPAM) is determined to provide information regarding skin cancer classification and diminish the noise and unwanted data. To minimise data loss, it is then combined with hierarchical complementarity during classification. Second, a modified MLPAM is used to extract significant feature spaces for network learning, select the most important information, and reduce feature space redundancy. The Ladybug Beetle Optimization (LBO) algorithm provides the optimal classification solution by minimising the loss rate of DAM 1-D CNN architecture. The experimentation is conducted on three different datasets such as ISIC2020, HAM10000, and the melanoma detection dataset. The experimental results revealed that the proposed method is compared with different existing methods such as IMFO-KELM, Mask RCNN, M-SVM, DCNN-9, and TL-CNN with different datasets. These methods attained 94.56, 92.65, 90.56, 88.65, and 95.5 for the ISIC2020 dataset but the proposed method enhanced the classification performance by attaining 97.02. Also, the validation is based on metrics, namely, accuracy, precision, sensitivity, and F1-score of 97.03%, 97.05%, 97.58%, and 97.27% for a total of 500 epochs.},
  archive      = {J_JETAI},
  author       = {Sellam V and Kannan Natrajan and Senthil Pandi S and Sathish Kumar K},
  doi          = {10.1080/0952813X.2023.2301374},
  journal      = {Journal of Experimental & Theoretical Artificial Intelligence},
  month        = {8},
  number       = {6},
  pages        = {915-940},
  shortjournal = {J. Exp. Theor. Artif. Intell.},
  title        = {LBO-MPAM: Ladybug beetle optimization-based multilayer perceptron attention module for segmenting the skin lesion and automatic localization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gastric cancer classification in saliva data samples using levy search updated rainfall hybrid deep dual-stage BILSTM. <em>JETAI</em>, <em>37</em>(6), 897-913. (<a href='https://doi.org/10.1080/0952813X.2023.2301371'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An innovative approach is needed for the early identification of GC (Gastric cancer) to improve the prediction of GC patients. This work presents a GC prediction system to identify GC depending on saliva data samples. The diagnosis of GC at an early stage will improve the survival rate. At first, Raman data of saliva samples are collected and pre-processed. Afterwards, efficient Raman spectral features are extracted from the pre-processed data. Then, the feature selection process is performed with a Levy search updated rainfall (LURF) optimisation approach. This optimisation scheme decreases the dimensionality of the features by integrating Levy’s flight and rainfall optimisation. Finally, the hybrid deep dual-stage bidirectional long short-term memory (Hybrid LURF) framework effectively classifies the data as normal or abnormal. This model efficiently addresses the issues of insufficient long-term dependency in GC prediction and also enhances the classification performance. The validation of the proposed approach is examined with various existing schemes and achieved better accuracy (98.5%), specificity (97%), sensitivity (96.5%), F1-score (93%), detection rate (98.4%) and ROC curve. Further, the accuracy is 0.06% better than multi-layer ANN and 10% better than SVM-polynomial and KNN models.},
  archive      = {J_JETAI},
  author       = {M. Kalimuthu and M. Ramya and S. Sreethar and N. Nandhagopal},
  doi          = {10.1080/0952813X.2023.2301371},
  journal      = {Journal of Experimental & Theoretical Artificial Intelligence},
  month        = {8},
  number       = {6},
  pages        = {897-913},
  shortjournal = {J. Exp. Theor. Artif. Intell.},
  title        = {Gastric cancer classification in saliva data samples using levy search updated rainfall hybrid deep dual-stage BILSTM},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid sequential forward channel selection method for enhancing EEG-based emotion recognition. <em>JETAI</em>, <em>37</em>(6), 871-895. (<a href='https://doi.org/10.1080/0952813X.2023.2301367'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, EEG-based emotion recognition has gained significant attention in affective computing. One of the major challenges in designing an efficient EEG-based emotion-recognition framework lies in handling the high dimensionality of the data recorded from a large number of EEG electrodes. This paper develops a hybrid sequential forward channel selection (HSFCSER) based emotion-recognition method, which aims to identify the most relevant subset of EEG channels and thus reduces the dimensionality of data. In HSFCSER, the Fisher score is used as the filter method, and the wrapper method includes Support Vector Machine (SVM). Wavelet-based features are extracted from the selected optimal EEG channels, followed by the feature selection using a multi-objective genetic algorithm. The proposed method is evaluated on the DEAP database. The methodology identifies 1) two classes of emotions viz. Low/High Valence with an average accuracy of 91.25 ± 5.48% for subject-dependent and 89.38 ± 4.76% for subject-independent, and Low/High Arousal with an average accuracy of 89.92 ± 5.81% for subject-dependent and 86.32 ± 5.34% for subject-independent, and 2) four classes of emotions viz. High Valence-Low Arousal (HVLA), High Valence-High Arousal, Low Valence-Low Arousal, and Low Valence-High Arousal with 75.94 ± 11.07% for subject-dependent and 73.13 ± 8.17% for subject-independent. The efficient electrode positions for emotion recognition are also depicted. The reported results are better compared to the existing results in the literature. The source code of the proposed work is made available at https://github.com/shyammarjit/HSFCS .},
  archive      = {J_JETAI},
  author       = {Shyam Marjit and Parag Jyoti Das and Upasana Talukdar and Shyamanta M Hazarika},
  doi          = {10.1080/0952813X.2023.2301367},
  journal      = {Journal of Experimental & Theoretical Artificial Intelligence},
  month        = {8},
  number       = {6},
  pages        = {871-895},
  shortjournal = {J. Exp. Theor. Artif. Intell.},
  title        = {A hybrid sequential forward channel selection method for enhancing EEG-based emotion recognition},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="joas">JOAS - 8</h2>
<ul>
<li><details>
<summary>
(2025). Statistical methods for dynamic disease screening and spatio-temporal disease surveillance. <em>JOAS</em>, <em>52</em>(12), 2354-2355. (<a href='https://doi.org/10.1080/02664763.2025.2458134'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JOAS},
  author       = {Jong-Min Kim},
  doi          = {10.1080/02664763.2025.2458134},
  journal      = {Journal of Applied Statistics},
  month        = {9},
  number       = {12},
  pages        = {2354-2355},
  shortjournal = {J. Appl. Stat.},
  title        = {Statistical methods for dynamic disease screening and spatio-temporal disease surveillance},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gene mutation estimations via mutual information and ewens sampling based CNN & machine learning algorithms. <em>JOAS</em>, <em>52</em>(12), 2321-2353. (<a href='https://doi.org/10.1080/02664763.2025.2460076'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We conduct gene mutation rate estimations via developing mutual information and Ewens sampling based convolutional neural network (CNN) and machine learning algorithms. More precisely, we develop a systematic methodology through constructing a CNN. Meanwhile, we develop two machine learning algorithms to study protein production with target gene sequences and protein structures. The core of the CNN and machine learning approach is to address a two-stage optimization problem to balance gene mutation rates during protein production. To wit, we try to optimally coordinate the consistency between the given input DNA sequences and the given (or optimally computed) target ones through controlling their intermediate gene mutation rates. The purposes in doing so are aimed to conduct gene editing and protein structure prediction. For example, after the gene mutation rates are estimated, the computing complexity of protein structure prediction will be reduced to a reasonable degree. Our developed CNN numerical optimization scheme consists of two newly designed machine learning algorithms. The stochastic gradients for the two algorithms are designed according to the Kuhn-Tucker conditions with boundary constraints and with the support of Ewens sampling, multi-input multi-output (MIMO) mutual information, and codon optimization techniques. The associated learning rate bounds are explicitly derived from the method and the two algorithms are numerically implemented. The convergence and optimality of the algorithms are mathematically proved. To illustrate the usage of our study, we also conduct a real-world data implementation.},
  archive      = {J_JOAS},
  author       = {Wanyang Dai},
  doi          = {10.1080/02664763.2025.2460076},
  journal      = {Journal of Applied Statistics},
  month        = {9},
  number       = {12},
  pages        = {2321-2353},
  shortjournal = {J. Appl. Stat.},
  title        = {Gene mutation estimations via mutual information and ewens sampling based CNN & machine learning algorithms},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pathway-based genetic association analysis for overdispersed count data. <em>JOAS</em>, <em>52</em>(12), 2306-2320. (<a href='https://doi.org/10.1080/02664763.2025.2460073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Overdispersion is a common phenomenon in genetic data, such as gene expression count data. In genetic association studies, it is important to investigate the association between a gene expression and a set of genetic variants from a pathway. However, existing approaches for pathway analysis are primarily designed for continuous and binary outcomes and are not applicable to overdispersed count data. In this paper, we propose a hierarchical approach to analyze the association between an overdispersed count response and a set of low-frequency genetic variants in negative binomial regression. We derive score-type test statistics for both fixed and random effects of genetic variants, and further introduce a novel procedure for efficiently combining these two statistics for global testing. Through simulation studies, we demonstrate that the proposed method tends to be more powerful than existing methods under a wide range of scenarios. Additionally, we apply the proposed method to a colorectal cancer study, demonstrating its power in identifying associations between gene expression and somatic mutations.},
  archive      = {J_JOAS},
  author       = {Yang Liu},
  doi          = {10.1080/02664763.2025.2460073},
  journal      = {Journal of Applied Statistics},
  month        = {9},
  number       = {12},
  pages        = {2306-2320},
  shortjournal = {J. Appl. Stat.},
  title        = {Pathway-based genetic association analysis for overdispersed count data},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On use of adaptive cluster sampling for variance estimation. <em>JOAS</em>, <em>52</em>(12), 2291-2305. (<a href='https://doi.org/10.1080/02664763.2025.2460072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive cluster sampling is particularly helpful whenever the target population is unique, dispersed unevenly, concealed or difficult to find. In the current investigation, under an adaptive cluster sampling approach, we propose a ratio-product-logarithmic type estimator employing a single auxiliary variable for the estimation of finite population variance. The bias and mean square error of the proposed estimator are developed by using simulation as well as real data sets. The study results show that for estimating the finite population variance, the proposed estimator outperforms the competing estimators.},
  archive      = {J_JOAS},
  author       = {Shameem Alam and Javid Shabbir and Malaika Nadeem},
  doi          = {10.1080/02664763.2025.2460072},
  journal      = {Journal of Applied Statistics},
  month        = {9},
  number       = {12},
  pages        = {2291-2305},
  shortjournal = {J. Appl. Stat.},
  title        = {On use of adaptive cluster sampling for variance estimation},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the improved estimation of the normal mixture components for longitudinal data. <em>JOAS</em>, <em>52</em>(12), 2271-2290. (<a href='https://doi.org/10.1080/02664763.2025.2459293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When analyzing real data sets, statisticians often face the question that the data are heterogeneous and it may not necessarily be possible to model this heterogeneity directly. One natural option in this case is to use the methods based on finite mixtures. The key question in these techniques often is what is the best number of mixtures or, depending on the focus of the analysis, the best number of sub-populations when the model is otherwise fixed. Moreover, when the distribution of the response variable deviates from meeting the assumptions, it's common to employ an appropriate transformation to align the distribution with the model's requirements. To solve the problem in the mixture regression context we propose a technique based on the scaled Box-Cox transformation for normal mixtures. The specific focus here is on mixture regression for longitudinal data, the so-called trajectory analysis. We present interesting practical results as well as simulation experiments to demonstrate that our method yields reasonable results. Associated R-programs are also provided.},
  archive      = {J_JOAS},
  author       = {Tapio Nummi and Jyrki Möttönen and Pasi Väkeväinen and Janne Salonen and Timothy E. O'Brien},
  doi          = {10.1080/02664763.2025.2459293},
  journal      = {Journal of Applied Statistics},
  month        = {9},
  number       = {12},
  pages        = {2271-2290},
  shortjournal = {J. Appl. Stat.},
  title        = {On the improved estimation of the normal mixture components for longitudinal data},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the use and misuse of time-rescaling to assess the goodness-of-fit of self-exciting temporal point processes. <em>JOAS</em>, <em>52</em>(12), 2247-2270. (<a href='https://doi.org/10.1080/02664763.2025.2459245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper first highlights important drawbacks and biases related to the common use of time-rescaling to assess the goodness-of-fit (Gof) of self-exciting temporal point process (SETPP) models. Then it presents a new predictive time-rescaling approach leading to an asymptotically unbiased Gof framework for general SETPPs in the case of single observed trajectories. The predictive approach focuses on forecasting accuracy and addresses the bias problem resulting from the plugged-in estimated parameters. Dawid's prequential approach is used and the models' checking is mainly based on the forecasting accuracy of arrival times. These times are transformed, using sequentially estimated parameters, into random vectors which are proved to converge in probability under the null hypothesis and standard regulatory conditions to vectors of iid Exponential(1) rv's. Numerical experiments are used to compare the performances of the standard and predictive time-rescaling for Gof assessment of non-homogeneous Poisson and Hawkes self-exciting temporal processes. Data of Japanese seismic events are also used to illustrate the dynamic aspect of the proposed model-checking approach.},
  archive      = {J_JOAS},
  author       = {M.-A. El-Aroui},
  doi          = {10.1080/02664763.2025.2459245},
  journal      = {Journal of Applied Statistics},
  month        = {9},
  number       = {12},
  pages        = {2247-2270},
  shortjournal = {J. Appl. Stat.},
  title        = {On the use and misuse of time-rescaling to assess the goodness-of-fit of self-exciting temporal point processes},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parametric estimation of quantile versions of zenga and d inequality curves: Methodology and application to weibull distribution. <em>JOAS</em>, <em>52</em>(12), 2226-2246. (<a href='https://doi.org/10.1080/02664763.2025.2458126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inequality (concentration) curves such as Lorenz, Bonferroni, Zenga curves, as well as a new inequality curve – the D curve, are broadly used to analyse inequalities in wealth and income distribution in certain populations. Quantile versions of these inequality curves are more robust to outliers. We discuss several parametric estimators of quantile versions of the Zenga and D curves. A minimum distance (MD) estimator is proposed for these two curves and the indices related to them. The consistency and asymptotic normality of the MD estimator is proved. The MD estimator can also be used to estimate the inequality measures corresponding to the quantile versions of the inequality curves. The estimation methods considered are illustrated in the case of the Weibull model, which has many applications in life sciences, for example, to fit the precipitation data. In econometrics it is also considered to fit incomes, especially in the case when a significant share of population have low incomes, for example, in less developed countries or among low-paid jobs.},
  archive      = {J_JOAS},
  author       = {Sylwester Pia̧tek},
  doi          = {10.1080/02664763.2025.2458126},
  journal      = {Journal of Applied Statistics},
  month        = {9},
  number       = {12},
  pages        = {2226-2246},
  shortjournal = {J. Appl. Stat.},
  title        = {Parametric estimation of quantile versions of zenga and d inequality curves: Methodology and application to weibull distribution},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Derivation of a multivariate longitudinal causal effects model. <em>JOAS</em>, <em>52</em>(12), 2207-2225. (<a href='https://doi.org/10.1080/02664763.2025.2457013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a causal inference estimation method for longitudinal observational studies with multiple outcomes. The method uses marginal structural models with inverse probability treatment weights (MSM-IPTWs). In developing the proposed method, we re-define the weights as a product of inverse weights at each time point, accounting for time-varying confounders and treatment exposures and possible correlation between and within (serial) the multiple outcomes. The proposed method is evaluated by simulation studies and with an application to estimate the effect of HIV positivity awareness on condom use and multiple sexual partners using the Malawi Longitudinal Study of Families and Health (MLSFH) data. The simulation study shows that the joint MSM-IPTW performs well with coverage within the expected 95% level for a large sample size ( n = 1000) and moderate to strong between and within outcome correlation strength ( ρ j = 0.3 , 0.75, ρ k = 0.4 , 0.8) when the effects are similar. The joint MSM-IPTW performed relatively the same as the adjusted standard joint model when the treatment effect estimate was the same for the outcomes. In the application, HIV positivity awareness increased the usage of condoms and did not affect the number of sexual partners. We recommend using the proposed MSM-IPTWs to correctly control for time-varying treatment and confounders when estimating causal effects for longitudinal observational studies with multiple outcomes.},
  archive      = {J_JOAS},
  author       = {Halima S. Twabi and Samuel O. M. Manda and Dylan S. Small and Hans-Peter Kohler},
  doi          = {10.1080/02664763.2025.2457013},
  journal      = {Journal of Applied Statistics},
  month        = {9},
  number       = {12},
  pages        = {2207-2225},
  shortjournal = {J. Appl. Stat.},
  title        = {Derivation of a multivariate longitudinal causal effects model},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="oms">OMS - 11</h2>
<ul>
<li><details>
<summary>
(2025). Correction. <em>OMS</em>, <em>40</em>(4), 1014. (<a href='https://doi.org/10.1080/10556788.2025.2516933'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_OMS},
  doi          = {10.1080/10556788.2025.2516933},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {1014},
  shortjournal = {Optim. Methods Softw.},
  title        = {Correction},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exponential convergence rates of a second-order dynamic system and algorithm for a linear equality constrained optimization problem. <em>OMS</em>, <em>40</em>(4), 977-1013. (<a href='https://doi.org/10.1080/10556788.2025.2517174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The O ( 1 / t 2 ) convergence rate of second-order dynamical systems with asymptotic vanishing viscous damping is faster than the O ( 1 / t ) rate of systems with fixed viscous damping in unconstrained and linear equality constrained optimization problems. We explore whether the performance of systems with vanishing viscous damping remains superior when both use time scaling. We compare the best polynomial convergence rates of vanishing damping systems with the best exponential convergence rates of a fixed damping system with time scaling for linear equality constrained problems. We prove that the primal-dual trajectory weakly converges to an optimal solution. Additionally, we present an inertial algorithm derived from the implicit discretization of the dynamical system, establishing exponential convergence rates for the primal-dual gap, feasibility measure, and objective value without assuming strong convexity. The sequence of iterates generated by the inertial algorithm weakly converges to an optimal solution when the objective function is proper, convex, and lower semicontinuous. These results align with those in the continuous setting.},
  archive      = {J_OMS},
  author       = {Ke-wei Ding and Lingling Liu and Phan Tu Vuong},
  doi          = {10.1080/10556788.2025.2517174},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {977-1013},
  shortjournal = {Optim. Methods Softw.},
  title        = {Exponential convergence rates of a second-order dynamic system and algorithm for a linear equality constrained optimization problem},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A proximal-gradient inertial algorithm with tikhonov regularization: Strong convergence to the minimal norm solution. <em>OMS</em>, <em>40</em>(4), 947-976. (<a href='https://doi.org/10.1080/10556788.2025.2517172'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the strong convergence properties of a proximal-gradient inertial algorithm with two Tikhonov regularization terms in connection with the minimization problem of the sum of a convex lower semi-continuous function f and a smooth convex function g . For the appropriate setting of the parameters, we provide the strong convergence of the generated sequence ( x k ) k ≥ 0 to the minimum norm minimizer of our objective function f + g . Further, we obtain fast convergence to zero of the objective function values in a generated sequence but also for the discrete velocity and the sub-gradient of the objective function. We also show that for another setting of the parameters the optimal rate of order O ( k − 2 ) for the potential energy ( f + g ) ( x k ) − min ( f + g ) can be obtained.},
  archive      = {J_OMS},
  author       = {Szilárd Csaba László},
  doi          = {10.1080/10556788.2025.2517172},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {947-976},
  shortjournal = {Optim. Methods Softw.},
  title        = {A proximal-gradient inertial algorithm with tikhonov regularization: Strong convergence to the minimal norm solution},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel approach for solving a class of diffusion identification problems. <em>OMS</em>, <em>40</em>(4), 920-946. (<a href='https://doi.org/10.1080/10556788.2025.2506176'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel approach to the formulation and solution of a class of elliptic diffusion identification problems in the framework of the Pontryagin maximum principle (PMP) is investigated. The proposed approach considers twice continuously differentiable diffusion coefficients defined as the convolution with a square-integrable optimization function, which allows to prove the PMP by spike variation and to construct and analyze an efficient PMP-based iterative algorithm that efficiently solves diffusion identification problems approximated by finite elements.},
  archive      = {J_OMS},
  author       = {Ştefana-Lucia Aniţa and Alfio Borzì},
  doi          = {10.1080/10556788.2025.2506176},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {920-946},
  shortjournal = {Optim. Methods Softw.},
  title        = {A novel approach for solving a class of diffusion identification problems},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). One-point feedback for composite optimization with applications to distributed and federated learning. <em>OMS</em>, <em>40</em>(4), 904-919. (<a href='https://doi.org/10.1080/10556788.2025.2502829'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work is devoted to solving the composite optimization problem with the mixture oracle: for the smooth part of the problem, we have access to the gradient, and for the non-smooth part, only the one-point zero-order oracle is available. For such a setup, we present a new method based on the sliding algorithm. Our method allows to separate the oracle complexities and to compute the gradient for one of the functions as rarely as possible. This paper also presents the applicability of our new method to the problems of distributed optimization and federated learning. Experimental results confirm the theory.},
  archive      = {J_OMS},
  author       = {Aleksandr Beznosikov and Ivan Stepanov and Artyom Voronov and Alexander Gasnikov},
  doi          = {10.1080/10556788.2025.2502829},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {904-919},
  shortjournal = {Optim. Methods Softw.},
  title        = {One-point feedback for composite optimization with applications to distributed and federated learning},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). S2MPJ and CUTEst optimization problems for matlab, python and julia. <em>OMS</em>, <em>40</em>(4), 871-903. (<a href='https://doi.org/10.1080/10556788.2025.2490640'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new suite of test problems for optimization is presented, which contains a large fraction of the problems in the CUTEst collection. The problems are supplied in the form of Matlab, Python and Julia files allowing the computation of values and derivatives of the objective function and constraints directly within ‘native’ Matlab, Python or Julia, without any additional installation or interfacing with MEX files or Fortran programs. These files are produced by a new decoder (written in Matlab) for the original SIF descriptions in the CUTEst collection. When used within Matlab, the new problem files optionally support reduced-precision computations.},
  archive      = {J_OMS},
  author       = {S. Gratton and Ph. L. Toint},
  doi          = {10.1080/10556788.2025.2490640},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {871-903},
  shortjournal = {Optim. Methods Softw.},
  title        = {S2MPJ and CUTEst optimization problems for matlab, python and julia},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum computing and the stable set problem. <em>OMS</em>, <em>40</em>(4), 837-870. (<a href='https://doi.org/10.1080/10556788.2025.2490639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an undirected graph, the stable set problem asks to determine the cardinality of the largest subset of pairwise non-adjacent vertices. This value is called the stability number of the graph, and its computation is an NP-hard problem. In this paper, we solve the stable set problem using the D-Wave quantum annealer. By formulating the problem as a quadratic unconstrained binary optimization problem with the penalty method, we show its optimal value equals the graph's stability number for specific penalty values. However, D-Wave's quantum annealer is a heuristic, so the solutions may be far from the optimum and may not represent stable sets. To address these, we introduce a post-processing procedure that identifies samples that could lead to improved solutions. Additionally, we propose a partitioning method to handle larger instances that cannot be embedded on D-Wave's quantum processing unit. Finally, we investigate how different penalty parameter values affect the solutions' quality. Extensive computational results show that the post-processing procedure significantly improves the solution quality, while the partitioning method successfully extends our approach to medium-size instances.},
  archive      = {J_OMS},
  author       = {Aljaž Krpan and Janez Povh and Dunja Pucher},
  doi          = {10.1080/10556788.2025.2490639},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {837-870},
  shortjournal = {Optim. Methods Softw.},
  title        = {Quantum computing and the stable set problem},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bundle trust-region algorithm for nonsmooth nonconvex constrained optimization. <em>OMS</em>, <em>40</em>(4), 813-836. (<a href='https://doi.org/10.1080/10556788.2025.2475518'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop an algorithm based on the idea of the bundle trust-region method to solve nonsmooth nonconvex constrained optimization problems. The resulting algorithm inherits some attractive features from both bundle and trust-region methods. Moreover, it allows effective control of the size of trust-region subproblems via the compression and aggregation techniques of bundle methods. On the other hand, the trust-region strategy is used to manage the search region and accept a candidate point as a new successful iterate. Global convergence of the developed algorithm is studied under some mild assumptions and its encouraging preliminary computational results are reported.},
  archive      = {J_OMS},
  author       = {N. Hoseini Monjezi and S. Nobakhtian},
  doi          = {10.1080/10556788.2025.2475518},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {813-836},
  shortjournal = {Optim. Methods Softw.},
  title        = {A bundle trust-region algorithm for nonsmooth nonconvex constrained optimization},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Soft quasi-newton: Guaranteed positive definiteness by relaxing the secant constraint. <em>OMS</em>, <em>40</em>(4), 783-812. (<a href='https://doi.org/10.1080/10556788.2025.2475406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel algorithm, termed soft quasi-Newton (soft QN), for optimization in the presence of bounded noise. Traditional quasi-Newton algorithms are vulnerable to such noise-induced perturbations. To develop a more robust quasi-Newton method, we replace the secant condition in the matrix optimization problem for the Hessian update with a penalty term in its objective and derive a closed-form update formula. A key feature of our approach is its ability to maintain positive definiteness of the Hessian inverse approximation throughout the iterations. Furthermore, we establish the following properties of soft QN: it recovers the BFGS method under specific limits, it treats positive and negative curvature equally, and it is scale invariant. Collectively, these features enhance the efficacy of soft QN in noisy environments. For strongly convex objective functions and Hessian approximations obtained using soft QN, we develop an algorithm that exhibits linear convergence toward a neighborhood of the optimal solution even when gradient and function evaluations are subject to bounded perturbations. Through numerical experiments, we demonstrate that soft QN consistently outperforms state-of-the-art methods across a range of scenarios.},
  archive      = {J_OMS},
  author       = {Erik Berglund and Jiaojiao Zhang and Mikael Johansson},
  doi          = {10.1080/10556788.2025.2475406},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {783-812},
  shortjournal = {Optim. Methods Softw.},
  title        = {Soft quasi-newton: Guaranteed positive definiteness by relaxing the secant constraint},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proximal subgradient method for non-lipschitz objective functions. <em>OMS</em>, <em>40</em>(4), 755-782. (<a href='https://doi.org/10.1080/10556788.2025.2475405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a convergence analysis framework of the proximal subgradient method for optimization problems involving non-Lipschitz continuous objective functions. In the conventional analysis of the various subgradient methods, including the proximal subgradient method, the Lipschitz continuity assumption has been placed to guarantee the boundedness of the subgradient and derive the convergence rate. However, the Lipschitz continuity does not hold in practical problems, including the sum-of- ℓ 2 -norms (SO ℓ 2 N) optimal control problem, which is examined in the numerical experiments of this paper. Without the Lipschitz continuity assumption, this paper provides the convergence analysis for strongly convex and non-strongly convex objective functions under mild assumptions. Suitable stepsize rules and resulting convergence rates are established; non-strongly convex cases result in a rate close to the rate of the existing subgradient method, and strongly convex cases achieve the same rate as the existing convergence analysis.},
  archive      = {J_OMS},
  author       = {Mitsuru Toyoda and Mirai Tanaka},
  doi          = {10.1080/10556788.2025.2475405},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {755-782},
  shortjournal = {Optim. Methods Softw.},
  title        = {Proximal subgradient method for non-lipschitz objective functions},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A modified polak-ribière-polyak type conjugate gradient method for vector optimization. <em>OMS</em>, <em>40</em>(4), 725-754. (<a href='https://doi.org/10.1080/10556788.2025.2475402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a modified Polak-Ribière-Polyak conjugate gradient method for solving vector optimization problems. Unlike the existing methods, it is not necessary to use the inner loop with sufficient accurate line search to generate the descent direction at each iteration. Moreover, it does not ignore the fact that the proposed algorithm may still generate the descent direction when the conjugate parameter is negative. We prove that the generated direction is sufficiently descent independent of any line search or convexity. Under the standard Wolfe line search, we also prove the global convergence of the modified Polak-Ribière-Polyak conjugate gradient method without restart or convexity assumption. Finally, through numerical experiments and comparative analysis with the existing methods, we validate the numerical performance of the proposed algorithm.},
  archive      = {J_OMS},
  author       = {Qingjie Hu and Yanyan Zhang and Ruyun Li and Zhibin Zhu},
  doi          = {10.1080/10556788.2025.2475402},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {725-754},
  shortjournal = {Optim. Methods Softw.},
  title        = {A modified polak-ribière-polyak type conjugate gradient method for vector optimization},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="optim">OPTIM - 11</h2>
<ul>
<li><details>
<summary>
(2025). On the complexity of inverse bivariate multi-unit assignment valuation problems. <em>OPTIM</em>, <em>74</em>(12), 2991-3006. (<a href='https://doi.org/10.1080/02331934.2024.2374945'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse and bilevel optimization problems play a central role in both theory and applications. These two classes are known to be closely related due to the pioneering work of Dempe and Lohse (2006), and thus have often been discussed together ever since. In this paper, we consider inverse problems for multi-unit assignment valuations. Multi-unit assignment valuations form a subclass of strong-substitutes valuations that can be represented by edge-weighted complete bipartite graphs. These valuations play a key role in auction theory as the strong substitutes condition implies the existence of a Walrasian equilibrium. A recent line of research concentrated on the problem of deciding whether a bivariate valuation function is an assignment valuation or not. In this paper, we consider an inverse variant of the problem: we are given a bivariate function g , and our goal is to find a bivariate multi-unit assignment valuation function f that is as close to g as possible. The difference between f and g can be measured either in ℓ 1 - or ℓ ∞ -norm. Using tools from discrete convex analysis, we show that the problem is strongly NP -hard. On the other hand, we derive linear programming formulations that solve relaxed versions of the problem.},
  archive      = {J_OPTIM},
  author       = {Kristóf Bérczi and Lydia Mirabel Mendoza-Cadena},
  doi          = {10.1080/02331934.2024.2374945},
  journal      = {Optimization},
  month        = {9},
  number       = {12},
  pages        = {2991-3006},
  shortjournal = {Optim.},
  title        = {On the complexity of inverse bivariate multi-unit assignment valuation problems},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust bilevel optimization: Algorithms, complexity and application. <em>OPTIM</em>, <em>74</em>(12), 2951-2990. (<a href='https://doi.org/10.1080/02331934.2025.2468405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper addresses robust bilevel optimization with polyhedral uncertainty in the followers' objective function coefficients. It is assumed that both the leader's and the followers' models are linear, yet, bilinear terms in the followers' objective function are allowed. An efficient algorithm is introduced that finds a bounded-error solution in a finite number of steps. This model captures typical price setting applications, such as network toll setting or electricity tariff optimization for demand response management. The efficiency of the general method is illustrated on demand response management in smart grids. Our computational experiments show that the method solves instances with hundreds of decision variables. The significance of these results is underlined by a proof that the above demand response management problem, and hence, the generic robust bilevel problem as well, are Σ 2 p -complete. Finally, the infinitely robust variant of the problem is discussed, and it is shown to be tractable in polynomial time.},
  archive      = {J_OPTIM},
  author       = {Tamás Kis and András Kovács and Csaba Mészáros},
  doi          = {10.1080/02331934.2025.2468405},
  journal      = {Optimization},
  month        = {9},
  number       = {12},
  pages        = {2951-2990},
  shortjournal = {Optim.},
  title        = {Robust bilevel optimization: Algorithms, complexity and application},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quasi-variational inequalities on product spaces and its applications to stochastic equilibrium problems. <em>OPTIM</em>, <em>74</em>(12), 2931-2950. (<a href='https://doi.org/10.1080/02331934.2025.2505463'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a class of quasi-variational inequalities defined on the product of Banach spaces. An operator formed by the product of generalized monotone and locally upper sign-continuous operators need not preserve the same properties. Under these assumptions on the component operators, we ensure the solutions to the proposed product-type quasi-variational inequalities by applying a preliminary existence result on variational inequalities. As an application, we study the multi-stage stochastic economic equilibrium problems, in which uncertainty is characterized by an uncountable set of scenarios at each stage and the expected utility functions of agents are quasiconcave.},
  archive      = {J_OPTIM},
  author       = {Shivani Valecha and Asrifa Sultana},
  doi          = {10.1080/02331934.2025.2505463},
  journal      = {Optimization},
  month        = {9},
  number       = {12},
  pages        = {2931-2950},
  shortjournal = {Optim.},
  title        = {Quasi-variational inequalities on product spaces and its applications to stochastic equilibrium problems},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence of inertial prox-penalization and inertial forward–backward algorithms for solving monotone bilevel equilibrium problems. <em>OPTIM</em>, <em>74</em>(12), 2885-2929. (<a href='https://doi.org/10.1080/02331934.2024.2341934'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main focus of this paper is on bilevel optimization on Hilbert spaces involving two monotone equilibrium bifunctions. We present a new achievement consisting on the introduction of inertial methods for solving these types of problems. Indeed, two several inertial type methods are suggested: a proximal algorithm and a forward–backward one. Under suitable conditions and without any restrictive assumption on the trajectories, the weak and strong convergence of the sequence generated by the both iterative methods are established. Two particular cases illustrating the proposed methods are thereafter discussed with respect to hierarchical minimization problems and equilibrium problems under a saddle point constraint. Furthermore, numerical examples are given to demonstrate the implementability of our algorithms. The algorithms and their convergence results improve and develop previous results in the field.},
  archive      = {J_OPTIM},
  author       = {A. Balhag and Z. Mazgouri and M. Théra},
  doi          = {10.1080/02331934.2024.2341934},
  journal      = {Optimization},
  month        = {9},
  number       = {12},
  pages        = {2885-2929},
  shortjournal = {Optim.},
  title        = {Convergence of inertial prox-penalization and inertial forward–backward algorithms for solving monotone bilevel equilibrium problems},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lower stackelberg equilibria: From bilevel optimization to stackelberg games. <em>OPTIM</em>, <em>74</em>(12), 2857-2883. (<a href='https://doi.org/10.1080/02331934.2024.2422020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Both pessimistic and optimistic bilevel optimization problems may be not stable under perturbation when the lower-level problem has not a unique solution, meaning that the limit of sequences of solutions (resp. equilibria) to perturbed bilevel problems is not necessarily a solution (resp. an equilibrium) to the original problem. In this paper, we investigate the notion of lower Stackelberg equilibrium, an equilibrium concept arising as a limit point of pessimistic equilibria and of optimistic equilibria of perturbed bilevel problems. First, connections with pessimistic equilibria and optimistic equilibria are obtained in a general setting, together with existence and closure results. Secondly, the problem of finding a lower Stackelberg equilibrium is shown to be stable under general perturbation, differently from what happens for pessimistic and optimistic bilevel problems. Then, moving to the game theory viewpoint, the set of lower Stackelberg equilibria is proved to coincide with the set of subgame perfect Nash equilibrium outcomes of the associated Stackelberg game. These results allow to achieve a comprehensive look on various equilibrium concepts in bilevel optimization and in Stackelberg games as well as to add a new interpretation in terms of game theory to the previous limit results on pessimistic equilibria and optimistic equilibria under perturbation.},
  archive      = {J_OPTIM},
  author       = {F. Caruso and M. C. Ceparano and J. Morgan},
  doi          = {10.1080/02331934.2024.2422020},
  journal      = {Optimization},
  month        = {9},
  number       = {12},
  pages        = {2857-2883},
  shortjournal = {Optim.},
  title        = {Lower stackelberg equilibria: From bilevel optimization to stackelberg games},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel approach to pessimistic bilevel problems. an application to the rank pricing problem with ties. <em>OPTIM</em>, <em>74</em>(12), 2823-2856. (<a href='https://doi.org/10.1080/02331934.2024.2388204'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel method to address the pessimistic approach to the bilevel problem. It consists of considering a lexicographic biobjective optimization problem at the lower level. To emphasize the significance of this approach, we implement it in the context of the Rank Pricing Problem with Ties. This problem can be formulated as a bilevel problem that inherently demands the use of the pessimistic approach. Considering the properties of the lexicographic biobjective problem involved, we formulate this problem as a single level mixed integer optimization problem, deriving also valid values for the big- M s involved and valid inequalities for this formulation. The computational experiment carried out confirms the relevance of the proposed method.},
  archive      = {J_OPTIM},
  author       = {Herminia I. Calvete and Carmen Galé and Aitor Hernández and José A. Iranzo},
  doi          = {10.1080/02331934.2024.2388204},
  journal      = {Optimization},
  month        = {9},
  number       = {12},
  pages        = {2823-2856},
  shortjournal = {Optim.},
  title        = {A novel approach to pessimistic bilevel problems. an application to the rank pricing problem with ties},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast smoothing newton method for bilevel hyperparameter optimization for SVC with logistic loss. <em>OPTIM</em>, <em>74</em>(12), 2793-2822. (<a href='https://doi.org/10.1080/02331934.2024.2394612'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector classification (SVC) with logistic loss has excellent theoretical properties in classification problems where the label values are not continuous. In this paper, we reformulate the hyperparameter selection for SVC with logistic loss as a bilevel optimization problem in which the upper-level problem and the lower-level problem are both based on logistic loss. The resulting bilevel optimization model is converted to a single-level nonlinear programming (NLP) based on the KKT conditions of the lower-level problem. Such NLP contains a set of nonlinear equality constraints and a simple lower-bound constraint. The second-order sufficient condition is characterized, which guarantees that the strict local optimizers are obtained. To solve such NLP, we apply the smoothing Newton method proposed in [Liang L, Sun D., Toh KC. A squared smoothing Newton method for semidefinite programming, 2023] to solve the KKT conditions, which contain one pair of complementarity constraints. We show that the smoothing Newton method has a superlinear convergence rate. Extensive numerical results verify the efficiency of the proposed approach and strict local minimizers can be achieved both numerically and theoretically. In particular, compared with other methods, our algorithm can achieve competitive results while consuming less time than other methods.},
  archive      = {J_OPTIM},
  author       = {Yixin Wang and Qingna Li},
  doi          = {10.1080/02331934.2024.2394612},
  journal      = {Optimization},
  month        = {9},
  number       = {12},
  pages        = {2793-2822},
  shortjournal = {Optim.},
  title        = {A fast smoothing newton method for bilevel hyperparameter optimization for SVC with logistic loss},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fresh look at nonsmooth Levenberg–Marquardt methods with applications to bilevel optimization. <em>OPTIM</em>, <em>74</em>(12), 2745-2792. (<a href='https://doi.org/10.1080/02331934.2024.2313688'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we revisit the classical problem of solving over-determined systems of nonsmooth equations numerically. We suggest a nonsmooth Levenberg–Marquardt method for its solution which, in contrast to the existing literature, does not require local Lipschitzness of the data functions. This is possible when using Newton-differentiability instead of semismoothness as the underlying tool of generalized differentiation. Conditions for local fast convergence of the method are given. Afterwards, in the context of over-determined mixed nonlinear complementarity systems, our findings are applied, and globalized solution methods, based on a residual induced by the maximum and the Fischer–Burmeister function, respectively, are constructed. The assumptions for local fast convergence are worked out and compared. Finally, these methods are applied for the numerical solution of bilevel optimization problems. We recall the derivation of a stationarity condition taking the shape of an over-determined mixed nonlinear complementarity system involving a penalty parameter, formulate assumptions for local fast convergence of our solution methods explicitly, and present results of numerical experiments. Particularly, we investigate whether the treatment of the appearing penalty parameter as an additional variable is beneficial or not.},
  archive      = {J_OPTIM},
  author       = {Lateef O. Jolaoso and Patrick Mehlitz and Alain B. Zemkoho},
  doi          = {10.1080/02331934.2024.2313688},
  journal      = {Optimization},
  month        = {9},
  number       = {12},
  pages        = {2745-2792},
  shortjournal = {Optim.},
  title        = {A fresh look at nonsmooth Levenberg–Marquardt methods with applications to bilevel optimization},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Second-order optimality conditions for bi-local solutions of bilevel programs. <em>OPTIM</em>, <em>74</em>(12), 2721-2743. (<a href='https://doi.org/10.1080/02331934.2025.2468412'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A popular way for developing optimality conditions of bilevel programs is to express them as (single-level) constrained optimization problems involving optimal value functions of lower programs, in which the computation of first/second-order directional derivatives for the value functions or solution mappings of the lower level problems is a challenging task. This type of directional derivatives based optimality conditions are not suitable for analysing theoretical properties of numerical algorithms for bilevel programs, especially when lower programs are non-convex optimization problems. This paper focuses on bilevel programs whose lower level optimization problems are non-convex. We introduce the concept of bi-local solutions and prove that, under the Jacobian uniqueness conditions on the lower level problem, the bi-local solutions are just the local solutions of the optimization problem constrained by Karush–Kuhn–Tucker (KKT) conditions of the lower level problem. Importantly, under suitable conditions, we prove that the KKT constrained optimization problem satisfies the Mangasarian–Fromovitz constraint qualification (MFCQ). Based on the equivalence of bi-local solutions and local solutions of the KKT constrained optimization problem, we establish the second-order necessary and sufficient optimality conditions for the bi-local optimal solutions. Different from second-order optimality conditions in terms of second-order directional derivatives of value functions, the second-order optimality conditions in this paper rely only on the second-order derivatives of the problem functions of the bilevel program. Moreover, the second-order sufficient optimality conditions can be applied for analysing convergence properties of numerical algorithms for the bilevel program.},
  archive      = {J_OPTIM},
  author       = {Xiang Liu and Mengwei Xu and Liwei Zhang},
  doi          = {10.1080/02331934.2025.2468412},
  journal      = {Optimization},
  month        = {9},
  number       = {12},
  pages        = {2721-2743},
  shortjournal = {Optim.},
  title        = {Second-order optimality conditions for bi-local solutions of bilevel programs},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimality conditions for bilevel programmes via moreau envelope reformulation*. <em>OPTIM</em>, <em>74</em>(12), 2685-2719. (<a href='https://doi.org/10.1080/02331934.2024.2358086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For bilevel programmes with a convex lower-level programme, the classical approach replaces the lower-level programme with its Karush-Kuhn-Tucker condition and solve the resulting mathematical programme with complementarity constraint (MPCC). It is known that when the set of lower-level multipliers is not unique, MPCC may not be equivalent to the original bilevel problem, and many MPCC-tailored constraint qualifications do not hold. In this paper, we study bilevel programmes where the lower level is generalized convex. Applying the equivalent reformulation via Moreau envelope, we derive new directional optimality conditions. Even in the nondirectional case, the new optimality condition is stronger than the strong stationarity for the corresponding MPCC.},
  archive      = {J_OPTIM},
  author       = {Kuang Bai and Jane J. Ye and Shangzhi Zeng},
  doi          = {10.1080/02331934.2024.2358086},
  journal      = {Optimization},
  month        = {9},
  number       = {12},
  pages        = {2685-2719},
  shortjournal = {Optim.},
  title        = {Optimality conditions for bilevel programmes via moreau envelope reformulation*},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Special issue to celebrate the scientific career of stephan dempe. <em>OPTIM</em>, <em>74</em>(12), 2677-2683. (<a href='https://doi.org/10.1080/02331934.2025.2548732'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_OPTIM},
  author       = {Patrick Mehlitz and Jacqueline Morgan and Christiane Tammer and Jane J. Ye and Alain B. Zemkoho},
  doi          = {10.1080/02331934.2025.2548732},
  journal      = {Optimization},
  month        = {9},
  number       = {12},
  pages        = {2677-2683},
  shortjournal = {Optim.},
  title        = {Special issue to celebrate the scientific career of stephan dempe},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="tas">TAS - 14</h2>
<ul>
<li><details>
<summary>
(2025). Learn r: As a language, 2nd ed.. <em>TAS</em>, <em>79</em>(3), 417-419. (<a href='https://doi.org/10.1080/00031305.2025.2490305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TAS},
  author       = {Haihan Yu},
  doi          = {10.1080/00031305.2025.2490305},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {417-419},
  shortjournal = {Am. Stat.},
  title        = {Learn r: As a language, 2nd ed.},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonparametric statistical methods using r, 2nd ed.. <em>TAS</em>, <em>79</em>(3), 416. (<a href='https://doi.org/10.1080/00031305.2025.2484865'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TAS},
  author       = {Bojana Milošević},
  doi          = {10.1080/00031305.2025.2484865},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {416},
  shortjournal = {Am. Stat.},
  title        = {Nonparametric statistical methods using r, 2nd ed.},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data science in practice. <em>TAS</em>, <em>79</em>(3), 416-417. (<a href='https://doi.org/10.1080/00031305.2025.2490304'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TAS},
  author       = {Xiao Hui Tai},
  doi          = {10.1080/00031305.2025.2490304},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {416-417},
  shortjournal = {Am. Stat.},
  title        = {Data science in practice},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Connections between statistics and Mathematics/Probability. <em>TAS</em>, <em>79</em>(3), 410-415. (<a href='https://doi.org/10.1080/00031305.2025.2453230'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are many connections between probability, other mathematics courses, and statistics. Understanding these connections provides insights that might not be fully appreciated when considering each discipline in isolation. While the typical instruction of statistics courses relies on elucidating its foundational principles from mathematical and probability theory, it is generally less appreciated that statistics can in turn provide a deeper understanding of results in mathematics and probability. We offer several examples for which knowledge of statistics can shed new light on probability and other mathematics results. Examples span both undergraduate and graduate level material. In today’s data driven-world, many students are naturally curious about statistics and are exposed to this field early in their undergraduate curriculum. Leveraging connections between statistics and mathematics and probability makes theoretical concepts more intuitive and relevant, fostering a better understanding.},
  archive      = {J_TAS},
  author       = {Michael A. Proschan and Pamela A. Shaw},
  doi          = {10.1080/00031305.2025.2453230},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {410-415},
  shortjournal = {Am. Stat.},
  title        = {Connections between statistics and Mathematics/Probability},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analytics, have some humility: A statistical view of fourth-down decision making. <em>TAS</em>, <em>79</em>(3), 393-409. (<a href='https://doi.org/10.1080/00031305.2025.2475801'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The standard mathematical approach to fourth-down decision-making in American football is to make the decision that maximizes estimated win probability. Win probability estimates arise from machine learning models fit from historical data. These models attempt to capture a nuanced relationship between a noisy binary outcome variable and game-state variables replete with interactions and non-linearities from a finite dataset of just a few thousand games. Thus, it is imperative to knit uncertainty quantification into the fourth-down decision procedure; we do so using bootstrapping. We find that uncertainty in the estimated optimal fourth-down decision is far greater than that currently expressed by sports analysts in popular sports media.},
  archive      = {J_TAS},
  author       = {Ryan S. Brill and Ronald Yurko and Abraham J. Wyner},
  doi          = {10.1080/00031305.2025.2475801},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {393-409},
  shortjournal = {Am. Stat.},
  title        = {Analytics, have some humility: A statistical view of fourth-down decision making},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An example to illustrate randomized trial estimands and estimators. <em>TAS</em>, <em>79</em>(3), 383-392. (<a href='https://doi.org/10.1080/00031305.2025.2468399'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the International Conference on Harmonisation finalized an estimand framework for randomized trials that was adopted by regulatory bodies worldwide. The framework introduced five strategies for handling post-randomization events; namely the treatment policy, composite variable, while on treatment, hypothetical and principal stratum estimands. We describe an illustrative example to elucidate the difference between these five strategies for handling intercurrent events and provide an estimation technique for each. Specifically, we consider the intercurrent event of treatment discontinuation and introduce potential outcome notation to describe five estimands and corresponding estimators: (1) an intention-to-treat estimator of the total effect of a treatment policy; (2) an intention-to-treat estimator of a composite of the outcome and remaining on treatment; (3) a per-protocol estimator of the outcome in individuals observed to remain on treatment; (4) a g-computation estimator of a hypothetical scenario that all individuals remain on treatment; and (5) a principal stratum estimator of the treatment effect in individuals who would remain on treatment under the experimental condition. Additional insight is provided by defining situations where certain estimands are equal, and by studying the while on treatment strategy under repeated outcome measures. We highlight relevant causal inference literature to enable adoption in practice.},
  archive      = {J_TAS},
  author       = {Linda J. Harrison and Sean S. Brummel},
  doi          = {10.1080/00031305.2025.2468399},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {383-392},
  shortjournal = {Am. Stat.},
  title        = {An example to illustrate randomized trial estimands and estimators},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flexible distributed lag models for count data using mgcv. <em>TAS</em>, <em>79</em>(3), 371-382. (<a href='https://doi.org/10.1080/00031305.2025.2505514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this tutorial we present the use of R package mgcv to implement Distributed Lag Non-Linear Models (DLNMs) in a flexible way. Interpretation of smoothing splines as random quantities enables approximate Bayesian inference, which in turn allows uncertainty quantification and comprehensive model checking. We illustrate various modeling situations using open-access epidemiological data in conjunction with simulation experiments. We demonstrate the inclusion of temporal structures and the use of mixture distributions to allow for extreme outliers. Moreover, we demonstrate interactions of the temporal lagged structures with other covariates with different lagged periods for different covariates. Spatial structures are also demonstrated, including smooth spatial variability and Markov random fields, in addition to hierarchical formulations to allow for non-structured dependency. Posterior predictive simulation is used to ensure models verify well against the data.},
  archive      = {J_TAS},
  author       = {Theo Economou and Daphne Parliari and Aurelio Tobias and Laura Dawkins and Hamish Steptoe and Christophe Sarran and Oliver Stoner and Rachel Lowe and Jos Lelieveld},
  doi          = {10.1080/00031305.2025.2505514},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {371-382},
  shortjournal = {Am. Stat.},
  title        = {Flexible distributed lag models for count data using mgcv},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analyzing spatial point patterns in digital pathology: Immune cells in high-grade serous ovarian carcinomas. <em>TAS</em>, <em>79</em>(3), 355-370. (<a href='https://doi.org/10.1080/00031305.2025.2459280'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiplex immunofluorescence (mIF) imaging technology facilitates the study of the tumor microenvironment in cancer patients. Due to the capabilities of this emerging bioimaging technique, it is possible to statistically analyze, for example, the co-varying location and functions of multiple different types of immune cells. Complex spatial relationships between different immune cells have been shown to correlate with patient outcomes and may reveal new pathways for targeted immunotherapy treatments. This tutorial reviews methods and procedures relating to spatial point patterns for complex data analysis. We consider tissue cells as a realization of a spatial point process for each patient. We focus on proper functional descriptors for each observation and techniques that allow us to obtain information about inter-patient variation. Ovarian cancer is the deadliest gynaecological malignancy and can resist chemotherapy treatment effective in cancers. We use a dataset of high-grade serous ovarian cancer samples from 51 patients. We examine the immune cell composition (T cells, B cells, macrophages) within tumors and additional information such as cell classification (tumor or stroma) and other patient clinical characteristics. Our analyses, supported by reproducible software, apply to other digital pathology datasets.},
  archive      = {J_TAS},
  author       = {Jonatan A. González and Julia Wrobel and Simon Vandekar and Paula Moraga},
  doi          = {10.1080/00031305.2025.2459280},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {355-370},
  shortjournal = {Am. Stat.},
  title        = {Analyzing spatial point patterns in digital pathology: Immune cells in high-grade serous ovarian carcinomas},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Play-by-play volleyball win probability model. <em>TAS</em>, <em>79</em>(3), 345-354. (<a href='https://doi.org/10.1080/00031305.2025.2490786'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a volleyball point-by-point win probability model that updates the probability of winning a set after each play in the set. The covariate informed product partition model (PPMx) is well suited to flexibly include in-set team performance information when making predictions. However, making predictions in real time would be too expensive computationally as it would require refitting the PPMx after each play. Instead, we develop a predictive procedure based on a single training of the PPMx that predicts in real-time. We deploy this procedure using data from the 2018 Men’s World Volleyball Championship. The procedure first trains a PPMx model using end-of-set team performance statistics from the round robin stage of the tournament. Then based on the PPMx predictive distribution, we predict the win probability after every play of every match in the knockout stages. Finally, we show how the prediction procedure can be enhanced by including pre-set information toward the beginning of the set and set score toward the end.},
  archive      = {J_TAS},
  author       = {Nathan Hawkins and Gilbert W. Fellingham and Garritt L. Page},
  doi          = {10.1080/00031305.2025.2490786},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {345-354},
  shortjournal = {Am. Stat.},
  title        = {Play-by-play volleyball win probability model},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Closed-form power and sample size calculations for bayes factors. <em>TAS</em>, <em>79</em>(3), 330-344. (<a href='https://doi.org/10.1080/00031305.2025.2467919'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining an appropriate sample size is a critical element of study design, and the method used to determine it should be consistent with the planned analysis. When the planned analysis involves Bayes factor hypothesis testing, the sample size is usually desired to ensure a sufficiently high probability of obtaining a Bayes factor indicating compelling evidence for a hypothesis, given that the hypothesis is true. In practice, Bayes factor sample size determination is typically performed using computationally intensive Monte Carlo simulation. Here, we summarize alternative approaches that enable sample size determination without simulation. We show how, under approximate normality assumptions, sample sizes can be determined numerically, and provide the R package bfpwr for this purpose. Additionally, we identify conditions under which sample sizes can even be determined in closed-form, resulting in novel, easy-to-use formulas that also help foster intuition, enable asymptotic analysis, and can also be used for hybrid Bayesian/likelihoodist design. Furthermore, we show how power and sample size can be computed without simulation for more complex analysis priors, such as Jeffreys-Zellner-Siow priors or non-local normal moment priors. Case studies from medicine and psychology illustrate how researchers can use our methods to design informative yet cost-efficient studies.},
  archive      = {J_TAS},
  author       = {Samuel Pawel and Leonhard Held},
  doi          = {10.1080/00031305.2025.2467919},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {330-344},
  shortjournal = {Am. Stat.},
  title        = {Closed-form power and sample size calculations for bayes factors},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A class of regression association measures based on concordance. <em>TAS</em>, <em>79</em>(3), 320-329. (<a href='https://doi.org/10.1080/00031305.2024.2448431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measures of regression association aiming at predictability of a dependent variable Y from an independent variable X have received considerable attention recently. In this article, we provide a unified discussion of some existing measures, including their rationale, properties, and estimation. Motivated by these measures, we consider a general class of regression association measures which views the regression association of Y from X as the association of two independent replications from the conditional distribution of Y given X . We illustrate that the so-called Markov product copulas can be employed as a neat and convenient building block for this class of measures, and the measures so constructed can be expressed as a common form of the proportion of the variance of some function of Y that can be explained by X , rendering the measures a direct interpretation in terms of predictability. Also, the notion of two independent replications from the conditional distribution leads to a simple nonparametric estimation method based on the induced order statistics, hence, no smoothing techniques are required. Under the considered general framework, the performances and utilities of the regression association measures are examined through simulations and real data applications.},
  archive      = {J_TAS},
  author       = {Jia-Han Shih and Yi-Hau Chen},
  doi          = {10.1080/00031305.2024.2448431},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {320-329},
  shortjournal = {Am. Stat.},
  title        = {A class of regression association measures based on concordance},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Laplace’s law of succession estimator and M-statistics. <em>TAS</em>, <em>79</em>(3), 311-319. (<a href='https://doi.org/10.1080/00031305.2024.2448430'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classic formula for estimating the binomial probability as the proportion of successes contradicts common sense for extreme probabilities when the event never occurs or occurs every time. Laplace’s law of succession estimator, one of the first applications of Bayesian statistics, has been around for over 250 years and resolves the paradoxes, although rarely discussed in modern statistics texts. This work aims to introduce a new theory for exact optimal statistical inference using Laplace’s law of succession estimator as a motivating example. We prove that this estimator may be viewed from a different theoretical perspective as the limit point of the short confidence interval on the double-log scale when the confidence level approaches zero. This motivating example paves the road to the definition of an estimator as the inflection point on the cumulative distribution function as a function of the parameter given the observed statistic. This estimator has the maximum infinitesimal probability of the coverage of the unknown parameter and, therefore, is called the maximum concentration (MC) estimator as a part of a more general M-statistics theory. The new theory is illustrated with exact optimal confidence intervals for the normal standard deviation and the respective MC estimators.},
  archive      = {J_TAS},
  author       = {Eugene Demidenko},
  doi          = {10.1080/00031305.2024.2448430},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {311-319},
  shortjournal = {Am. Stat.},
  title        = {Laplace’s law of succession estimator and M-statistics},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient computation strategy for generalized single-index models and their variants by integrating with GAM. <em>TAS</em>, <em>79</em>(3), 302-310. (<a href='https://doi.org/10.1080/00031305.2025.2464854'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various generalizations of single-index models and associated estimation methods have been developed. However, implementing these developed methods requires much effort to program, case by case, due to the lack of a common and flexible vehicle to cover them. We suggest an efficient computation strategy for easily estimating parameters and nonparametric functions in generalized single-index models and generalized partially linear single-index models by integrating with well-developed algorithms and packages for estimating the generalized additive models (Wood; Hastie and Tibshirani, GAM). Such an integration makes estimation in these index-type models much easier, expedient, and flexible and brings a lot of convenience. We briefly introduce the principle and extensively examine numerical performance for various scenarios. Numerical experiments indicate that the proposed strategy works well with finite sample sizes and is especially flexible to model structures. Finally, we analyze two real-data examples as an illustration.},
  archive      = {J_TAS},
  author       = {Ximin Li and Haozhe Liang and Hua Liang},
  doi          = {10.1080/00031305.2025.2464854},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {302-310},
  shortjournal = {Am. Stat.},
  title        = {An efficient computation strategy for generalized single-index models and their variants by integrating with GAM},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiple imputation approach for the cumulative incidence, with implications for variance estimation. <em>TAS</em>, <em>79</em>(3), 291-301. (<a href='https://doi.org/10.1080/00031305.2025.2453674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an alternative approach to estimating the cumulative incidence function that uses nonparametric multiple imputation to reduce the problem to that of estimating a binomial proportion. In the standard competing risks setting, we show mathematically and empirically that our imputation-based estimator is equivalent to the Aalen-Johansen estimator of the cumulative incidence given a sufficient number of imputations. However, our approach allows for the use of a wider variety of methods for the analysis of binary outcomes, including preferred options for uncertainty estimation. While we focus on the cumulative incidence function, the multiple imputation approach likely extends to more complex problems in competing risks.},
  archive      = {J_TAS},
  author       = {Elizabeth C. Chase and Philip S. Boonstra and Jeremy M. G. Taylor},
  doi          = {10.1080/00031305.2025.2453674},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {291-301},
  shortjournal = {Am. Stat.},
  title        = {A multiple imputation approach for the cumulative incidence, with implications for variance estimation},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
