<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>taylor</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aai">AAI - 58</h2>
<ul>
<li><details>
<summary>
(2025). Assessing the performance of pretrained models for accurate and consistent classification of argument structure constructions. <em>AAI</em>, <em>39</em>(1), Article: 2566798. (<a href='https://doi.org/10.1080/08839514.2025.2566798'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the growing body of (applied) linguistic research on argument structure constructions (e.g. ditransitive: He gave me a ball ), few studies have attempted to develop a classification model for these constructions. Furthermore, existing models struggle with inconsistent performance across different constructions and datasets, highlighting the need for improvement. The current study explores whether broadening and improving the quality of training data can enhance the performance of deep learning models in classifying constructions. Specifically, the study fine-tunes two pre-trained models, BERT and RoBERTa, and examines the errors they produce. The results show that using a high-quality dataset that includes diverse genres/modalities improves performance accuracy and consistency, and RoBERTa (F1 = 0.925) outperforms BERT (F1 = 0.916) in this context. The error analysis further reveals that the two models exhibit similar error patterns, but with distinct strengths: The BERT-based model outperforms in intransitive resultatives, while the RoBERTa-based model outperforms in caused motions and intransitive motions. Overall, these findings highlight the importance of using diverse, high-quality datasets and selecting the optimal model architecture to maximize performance, while also revealing areas for future improvement. Additionally, the high accuracy of our systems suggests their potential to make a meaningful impact in educational and assessment settings.},
  archive      = {J_AAI},
  author       = {Haerim Hwang},
  doi          = {10.1080/08839514.2025.2566798},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2566798},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Assessing the performance of pretrained models for accurate and consistent classification of argument structure constructions},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sentiment analysis of conversational implicature: A computational pragmatics approach. <em>AAI</em>, <em>39</em>(1), Article: 2565173. (<a href='https://doi.org/10.1080/08839514.2025.2565173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process of inferring the intention of conversational implicatures involves the interpretation of the speaker’s sentiment. However, the relationship between implicatures and sentiments has not been clear enough, and there is no research explaining the relationship between the response orientation of conversational implicature and sentiment score. Therefore, based on the dialogue snippets of conversational implicature, this paper uses automatic sentiment analysis, statistical testing and other methods to identify the statistical dependencies between implicatures and sentiments, and compare the sentiment scores of implicatures and literal meanings. The results show that the response orientation of implicature has a significant impact on the sentiment score, and its source only contains response utterance. In addition, within the response utterance, whether there is a significant difference between the sentiment scores of implicature and literal meaning is related to the selected algorithms of sentiment analysis. The sentiment lexicon-based method like Pattern cannot distinguish the sentimental difference between implicature and literal meaning, but the sentiment score obtained by the VADER-based method that considers grammatical and syntactical heuristics has significant differences in implicatures and literal meanings. Finally, the methodological implications of the experiments and results for the development of computational pragmatics are provided in this paper.},
  archive      = {J_AAI},
  author       = {Xianbo Li and Kunpei Xu},
  doi          = {10.1080/08839514.2025.2565173},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2565173},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Sentiment analysis of conversational implicature: A computational pragmatics approach},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing wheat single-nucleotide polymorphism data analysis with explainable deep learning models. <em>AAI</em>, <em>39</em>(1), Article: 2565169. (<a href='https://doi.org/10.1080/08839514.2025.2565169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of machine learning (ML) and deep learning (DL) is transforming scientific fields, including foodomics. This study advances the application of artificial neural networks (ANNs) for analyzing single-nucleotide polymorphism (SNP) data in foodomics. We introduce underutilized mechanisms in fields, such as data augmentation, dropout, batch normalization, learning rate scheduling, and Bayesian optimization for hyper-parameter optimization (HPO), enabling more robust and generalizable models. Our ANN achieves state-of-the-art performance on a publicly available dataset from prior work, with an average RMSE reduction of 0.017 (10.5%) over the previous ANN model and statistically significant improvements on strong traditional baselines, including Random Forest, XGBoost, LASSO, and Ridge regression. To enhance interpretability, we integrate SHAP (SHapley Additive exPlanations), which highlights the most influential SNP markers contributing to predictions, potentially identifying novel genomic markers. We also emphasize reproducibility, following best practices in code and data sharing. By making both our code and preprocessed dataset publicly available, we aim to support transparency and foster further research. Our results show that ANNs can serve not only as high-performing predictive models but also as explainable tools for SNP analysis in foodomics, contributing to the foundation of explainable artificial intelligence in this emerging field.},
  archive      = {J_AAI},
  author       = {Dario Ruggeri and László Vidács},
  doi          = {10.1080/08839514.2025.2565169},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2565169},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Advancing wheat single-nucleotide polymorphism data analysis with explainable deep learning models},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural ensemble architecture with pseudo-random input sequence for classifying LADA diabetes. <em>AAI</em>, <em>39</em>(1), Article: 2565168. (<a href='https://doi.org/10.1080/08839514.2025.2565168'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Latent Autoimmune Diabetes of Adult-onset (LADA) is a complex disease characterized by the attributes of both Type 1 and Type 2 diabetes, which makes distinguishing LADA challenging, particularly from Type 2 diabetes. Existing approaches for analyzing LADA utilize stand-alone statistical and/or machine learning algorithms, which have proven to be insignificant in capturing fine details pertinent to LADA. This study proposes a novel Neural Ensemble Model (NEM) to independently analyze LADA variables: first, conventional variables alone, then conventional variables in combination with five genetic variables above Genome Wide Association Studies (GWAS) levels, and finally conventional variables in combination with 11 genetic variables below GWAS levels. An ensemble carefully orchestrated with Radial Bias Function Feed Forward Neural Network (RBF-FFNN), a Multi-Layer Perceptron (MLP) with Feature Extraction and an MLP was developed to accurately classify LADA from Type 1 and Type 2 diabetes. The proposed NEM benefits from a pseudo-random input sequence from each genre of analysis to determine the most reliable identification of case, control, precision, recall, and variable importance, for maximum prediction accuracy. The proposed NEM achieves a greater prediction accuracy when utilizing a combination of conventional and genetic variables below GWAS levels, with 97.45% accurate identification of positive LADA diabetes.},
  archive      = {J_AAI},
  author       = {Anthony Miller and John Panneerselvam and Lu Liu and V. Vijaya Baskar and Lauren Miller},
  doi          = {10.1080/08839514.2025.2565168},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2565168},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A neural ensemble architecture with pseudo-random input sequence for classifying LADA diabetes},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting cycling performance before and after training: Insights from machine learning using small samples. <em>AAI</em>, <em>39</em>(1), Article: 2565167. (<a href='https://doi.org/10.1080/08839514.2025.2565167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on optimizing sports performance is challenging due to large individual variability and small sample sizes. Machine learning (ML) is underexplored in predicting performance changes following training interventions. This study aimed to predict 4-km cycling performance before and after a 12-week intervention using ML models, incorporating physiological, training load, and well-being data while identifying key predictors. Twenty-seven recreational cyclists completed baseline tests, including 4-km time-trial, V . O 2max , pulmonary V . O 2-kinetics , Wingate, squat jump, ultrasound imaging, and anthropometry. They were randomly assigned to one of four training programs. ML models (generalized linear models ( glm ), random forest ( rf ), and principal component regression ( pcr )) were used to predict performance pre- and post-training, as well as performance changes. Models were evaluated using R 2 and mean absolute error (MAE). Cyclists produced 4.1 ± 0.7 W/kg during the time-trial. Change in cycling performance showed substantial individual variability and did not differ between training programs ( p > .05). ML models accurately predicted performance pre-training (R 2 = 0.875, MAE = 0.260 W/kg) and post-training (R 2 = 0.792, MAE = 0.266 W/kg) using glm , but changes in performance were less predictable. Key predictors included power at V . O 2max , ventilatory thresholds, body composition, deoxygenation, sleep, and sickness. Findings highlight ML’s potential for predicting endurance performance but indicate difficulty in forecasting individual adaptations to training.},
  archive      = {J_AAI},
  author       = {Luuk Vos and Renske N. Vergeer and Richie P. Goulding and Guido Weide and Jos J. de Koning and Richard T. Jaspers and Stephan van der Zwaard},
  doi          = {10.1080/08839514.2025.2565167},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2565167},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Predicting cycling performance before and after training: Insights from machine learning using small samples},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated machine learning approach (AutoML) to alzheimer’s disease diagnosis and prognosis. <em>AAI</em>, <em>39</em>(1), Article: 2565166. (<a href='https://doi.org/10.1080/08839514.2025.2565166'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is a neurodegenerative disorder characterized by memory loss. While applying Machine Learning (ML) demands a certain level of expertise, which is often a barrier for healthcare professionals, automated machine learning (AutoML) significantly lowers this barrier. This study analyzes an AutoML tool (PyCaret) for AD classification and prediction. Two experiments were designed to evaluate its diagnostic and prognostic capabilities with AD, Mild cognitive impairment (MCI), and Normal Controls (NC). SHapley Additive exPlanations (SHAP) was used to explain the ML models. For diagnosis, it had an accuracy of 98.6% for NC vs AD, 91.3%, for NC vs MCI, 92.5% for MCI vs AD, and 89.5% for the multiclass NC vs MCI vs AD. Regarding the prognosis capabilities, prediction of future cognitive states four years after their initial visit produced an accuracy of 92.8% for NC vs AD, 82.7% for NC vs MCI, 90.2% for MCI vs AD, and 81.4% for NC vs MCI vs AD. These results are in range and, in some cases, improve the state of the art even when compared to deep learning solutions. They confirm the potential of AutoML tools to automate ML algorithm selection and tuning for a specific medical application.},
  archive      = {J_AAI},
  author       = {Pablo Guillén and Enrique Frias-Martinez},
  doi          = {10.1080/08839514.2025.2565166},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2565166},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Automated machine learning approach (AutoML) to alzheimer’s disease diagnosis and prognosis},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining stochastic defenses to resist gradient inversion: An ablation study. <em>AAI</em>, <em>39</em>(1), Article: 2565165. (<a href='https://doi.org/10.1080/08839514.2025.2565165'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient Inversion (GI) attacks are a ubiquitous threat in Federated Learning (FL) as they exploit gradient leakage to reconstruct supposedly private training data. Common defense mechanisms such as Differential Privacy (DP) or stochastic Privacy Modules (PMs) introduce randomness during gradient computation to prevent such attacks. However, we pose that if an attacker effectively mimics a client’s stochastic gradient computation, the attacker can circumvent the defense and reconstruct clients’ private training data. This paper introduces several targeted GI attacks that leverage this principle to bypass common defense mechanisms. As a result, we demonstrate that no individual defense provides sufficient privacy protection. To address this issue, we propose to combine multiple defenses. We conduct an extensive ablation study to evaluate the influence of various combinations of defenses on privacy protection and model utility. We observe that only the combination of DP and a stochastic PM was sufficient to decrease the Attack Success Rate (ASR) from 100% to 0%, thus preserving privacy. Moreover, we found that this combination of defenses consistently achieves the best trade-off between privacy and model utility.},
  archive      = {J_AAI},
  author       = {Daniel Scheliga and Patrick Mäder and Marco Seeland},
  doi          = {10.1080/08839514.2025.2565165},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2565165},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Combining stochastic defenses to resist gradient inversion: An ablation study},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting inland waterway container on barge volume: A machine learning approach using economic features. <em>AAI</em>, <em>39</em>(1), Article: 2550462. (<a href='https://doi.org/10.1080/08839514.2025.2550462'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a machine learning approach to predict Container-on-Barge (COB) volume in Inland Waterway Transportation (IWT) systems, focusing exclusively on using economic features as predictors. Five machine learning models were trained using European economic features to forecast COB volume, while historical COB volume was used solely for validation and hyperparameter tuning. Among these models, the convolutional neural network combined with long short-term memory (CNN-LSTM) exhibited superior performance, achieving a mean absolute percentage error (MAPE) of 1.08% when forecasting eight consecutive quarters of COB volume in Europe. The results demonstrate the feasibility of accurately forecasting COB volume using economic features. This research develops an alternative method to forecast COB volume and provides a foundation for developing transfer learning models to predict COB volume in other emerging markets where historical COB volume data is limited. The findings are expected to assist in strategic planning and infrastructure investment for efficient and sustainable COB IWT systems.},
  archive      = {J_AAI},
  author       = {Fan Bu and Heather Nachtmann},
  doi          = {10.1080/08839514.2025.2550462},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2550462},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Forecasting inland waterway container on barge volume: A machine learning approach using economic features},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-based framework for automated symbol recognition and wiring design in electrical diagrams. <em>AAI</em>, <em>39</em>(1), Article: 2548834. (<a href='https://doi.org/10.1080/08839514.2025.2548834'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The digitization of electrical diagrams plays a crucial role in modern construction industries, enabling efficient reuse, seamless distribution, and accurate archiving. Despite technological advances, many of these diagrams remain in undigitized formats, leading to labor-intensive manual analysis for tasks such as cost estimation and wiring design. These challenges are aggravated by the diversity of symbols, high inter-class similarities, and the inherent complexities of wiring layouts, which require advanced recognition and efficient wiring design. This paper presents a deep learning framework that integrates an attention mechanism for symbol recognition, followed by a graph-based algorithm for fully automated wiring design. Through comparative evaluation, Efficient Channel Attention emerged as the most effective attention module, improving the mean average precision by 3.2%. The wiring algorithm leverages an improved pathfinding approach that reduces bends and total wiring length by 43% while adhering to boundary constraints and electrical rules. Extensive experiments on proprietary and public datasets demonstrate that the proposed framework significantly improves the recognition of complex electrical symbols, outperforming the baseline model. This research sets a new benchmark for automating electrical diagram analysis, offering substantial cost savings while reducing the manual effort associated with large-scale construction projects.},
  archive      = {J_AAI},
  author       = {Ikenna Ekeke and Carlos Francisco Moreno-García and Eyad Elyan},
  doi          = {10.1080/08839514.2025.2548834},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2548834},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Attention-based framework for automated symbol recognition and wiring design in electrical diagrams},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-phase feature selection framework for intrusion detection system: Balancing relevance and computational efficiency (2P-FSID). <em>AAI</em>, <em>39</em>(1), Article: 2539396. (<a href='https://doi.org/10.1080/08839514.2025.2539396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of data demands robust security mechanisms to prevent unauthorized access, making ML-based intrusion detection systems essential. However, high-dimensional data necessitates the need for effective feature selection. This study proposes the Two-Phase Feature Selection framework for Intrusion Detection (2P-FSID) to enhance model performance and interpretability. In Phase 1, a filter-based approach is employed to select a relevant subset of features, yielding an initial subset S1. These features are further assessed using Mutual Information (MI), Correlation (Corr), and Feature Importance (FI) as part of the Feature Relevance Estimation (FRE) process. A hybrid pruning strategy, comprising dynamic pruning and static pruning, is employed to refine the subset into S3. In Phase 2, Shapley Additive Explanations (SHAP) values are computed to quantify each feature’s influence on classification performance. Features are categorized into either positively or negatively influential. The model is initially trained using positively influential features, and then negatively influential features are iteratively added and evaluated for potential performance improvement, resulting in the final optimized subset S4. Experimental results on the NSL-KDD and UNSW-NB15 datasets demonstrate a reduction in feature space from 41 to 19 and 44 to 17 features, respectively, while achieving high detection accuracies of 95.18% and 92.79%.},
  archive      = {J_AAI},
  author       = {C. Rajathi and Rukmani Panjanathan},
  doi          = {10.1080/08839514.2025.2539396},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2539396},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A two-phase feature selection framework for intrusion detection system: Balancing relevance and computational efficiency (2P-FSID)},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel univariate feature selection with ANOVA F-test-based machine learning model for intrusion detection framework of robotics system. <em>AAI</em>, <em>39</em>(1), Article: 2539395. (<a href='https://doi.org/10.1080/08839514.2025.2539395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic systems have become popular across various industries, ranging from manufacturing and healthcare to logistics and space exploration. However, increasing the integration of robotic systems into critical infrastructures exposes devices to cybersecurity threats. The intrusion detection system (IDS) plays a vital role in safeguarding the systems from malicious activities and unauthorized access. This paper presents a novel, robotics-aware IDS framework incorporating hybrid feature selection and tailored classification strategies for robotic system. To evaluate the efficacy of the presented framework, an algorithm is also designed and tested using multiple machine-learning techniques. The NSL-KDD dataset is utilized for training and evaluating machine learning models due to the inclusion of a wide range of attack scenarios and normal instances. The results demonstrate that the proposed IDS effectively classifies cyberattacks relevant to robotic systems. The presented framework is also evaluated against existing IDS approaches in robotic systems. The results demonstrate that the proposed approach exhibits better results in terms of accuracy, robustness, and adaptability to emerging cyber threats.},
  archive      = {J_AAI},
  author       = {Narinder Verma and Neerendra Kumar and Kuljeet Singh and Abeer Aljohani and Anurag Sinha and Syed Abid Hussain},
  doi          = {10.1080/08839514.2025.2539395},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2539395},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A novel univariate feature selection with ANOVA F-test-based machine learning model for intrusion detection framework of robotics system},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multivariate time series anomaly detection using directed hypergraph neural networks. <em>AAI</em>, <em>39</em>(1), Article: 2538519. (<a href='https://doi.org/10.1080/08839514.2025.2538519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series anomaly detection is a challenging problem because there can be a number of complex relationships between variables in multivariate time series. Although graph neural networks have been shown to be effective in capturing variable-variable relationships (i.e. relationships between two variables), they are hard to capture variable-group relationships (i.e. relationships between variables and groups of variables). To overcome this limitation, we propose a novel method called DHG-AD for multivariate time series anomaly detection. DHG-AD employs directed hypergraphs to model variable-group relationships within multivariate time series. For each time window, DHG-AD constructs two different directed hypergraphs to represent relationships between variables and groups of positively and negatively correlated variables, enabling the model to capture both types of relationships effectively. The directed hypergraph neural networks learn node representations from these hypergraphs, allowing comprehensive multivariate interaction modeling for anomaly detection. We show through experiments using various evaluation metrics that our proposed method achieves the best scores among the compared methods on two real-world datasets.},
  archive      = {J_AAI},
  author       = {Tae Wook Ha and Myoung Ho Kim},
  doi          = {10.1080/08839514.2025.2538519},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2538519},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Multivariate time series anomaly detection using directed hypergraph neural networks},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting software anomalies in robots by means of one-class classifiers. <em>AAI</em>, <em>39</em>(1), Article: 2538459. (<a href='https://doi.org/10.1080/08839514.2025.2538459'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing dependence on collaborative robots in essential industrial and service sectors raises urgent concerns regarding their reliability and ability to handle faults. Undetected software issues can degrade performance, jeopardize safety, and result in expensive downtimes. Incorporating collaborative robots into daily life and industrial settings requires strong and dependable systems, especially concerning software. While most anomaly detection research has focused on hardware anomalies, this study addresses the underexplored challenge of software anomaly detection in component-based robotic systems. Leveraging a publicly available dataset with labeled software-induced anomalies, six one-class classification techniques were evaluated: Approximate Convex Hull, Autoencoder Neural Networks, K-Means, K-Nearest Neighbors, Principal Component Analysis, and Support Vector Data Description. Each classifier was assessed across preprocessing methods and hyperparameter configurations, using the Area Under the Curve (AUC) as the primary performance metric. The results show that Principal Component Analysis outperforms other methods in most scenarios, although the optimal performance varies depending on the anomaly type. The results confirm that the suggested one-class classification method is an efficient means of early identification of software anomalies in robotic systems, potentially improving operational reliability and reducing downtime.},
  archive      = {J_AAI},
  author       = {Héctor Quintián and Esteban Jove and Francisco Zayas-Gato and Nuño Basurto and Carlos Cambra and Álvaro Herrero},
  doi          = {10.1080/08839514.2025.2538459},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2538459},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Detecting software anomalies in robots by means of one-class classifiers},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Context-aware intrusion detection in vehicular communication networks: Enhanced attack modeling and dataset. <em>AAI</em>, <em>39</em>(1), Article: 2538453. (<a href='https://doi.org/10.1080/08839514.2025.2538453'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular Communication Networks (VCNs) are essential for autonomous vehicles and Intelligent Transportation Systems but face challenges in security vulnerabilities and data sparsity. Traditional attack models inadequately represent VCN dynamics, weakening threat detection, while existing datasets lack real-world mobility and spatiotemporal details. This study addresses these gaps by developing a comprehensive attack simulation framework, enhancing critical network attacks i.e. position spoofing, Sybil, and wormhole through realistic mobility patterns, positional dynamics, and temporal interactions. The resulting dataset contains legitimate and malicious instances: Spoofing (45,975 legitimate, 589 malicious), Wormhole (52,237 legitimate, 5,219 malicious), and Sybil (14,829 legitimate, 1,753 malicious). It includes essential vehicular-specific features such as mobility dynamics, inter-vehicle distances, and end-to-end communication patterns. For validation, machine learning algorithms, including Random Forest, K-Nearest Neighbors, and Logistic Regression were employed. Detection performance was evaluated using accuracy, precision, recall, and two F1-score variants (standard and macro). Results indicate high detection efficacy, with Random Forest achieving accuracy between 93.6% and 99.8% and F1-macro scores from 88.5% to 97.7%. Compared to previous studies lacking spatiotemporal considerations, our dataset’s enhanced realism demonstrates significant potential in advancing data-driven anomaly detection and real-world threat mitigation in dynamic vehicular environments.},
  archive      = {J_AAI},
  author       = {Muhammad Danish Khan and Vinh-Thong Ta and Husnain Rafiq and Nonso Nnamoko},
  doi          = {10.1080/08839514.2025.2538453},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2538453},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Context-aware intrusion detection in vehicular communication networks: Enhanced attack modeling and dataset},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting chinese disinformation with Fine–Tuned BERT and contextual techniques. <em>AAI</em>, <em>39</em>(1), Article: 2525127. (<a href='https://doi.org/10.1080/08839514.2025.2525127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the digital age, misinformation poses a significant threat to social cohesion, digital platform integrity, and political stability, particularly in countries with large online populations like China. Objectives – We examine how model architecture (BERT versus RoBERTa) and advanced strategies influence accuracy, precision, and recall on the multi – source MCFEND corpus. Building on large language models (LLMs) like BERT (Bidirectional Encoder Representations from Transformers) provides a promising avenue for addressing this challenge. This study presents a novel approach to specifically detecting Chinese misinformation using fine-tuned BERT models, incorporating techniques such as Contextual Unit Obscuration, Multi-span Concealment, and Adaptive Concealment. These methods enhance the models’ ability to capture linguistic nuances and contextual cues specific to Chinese text. Our BERT-based and RoBERTa-based fine-tuned models demonstrate superior performance compared to traditional fine-tuning methods and other state-of-the-art approaches, achieving an accuracy of 83.1% —surpassing state-of-the-art approaches – and achieve notable precision and recall scores over 0.73, marks a significant improvement over many existing detection frameworks. This research supports global efforts to combat misinformation by providing a robust framework across linguistic and cultural contexts. Integrating these models with media literacy and policy initiatives is vital to enhancing digital platform integrity, building a resilient information ecosystem, and promoting informed public discourse.},
  archive      = {J_AAI},
  author       = {Lixin Yun and Sheng Yun and Haoran Xue},
  doi          = {10.1080/08839514.2025.2525127},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2525127},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Detecting chinese disinformation with Fine–Tuned BERT and contextual techniques},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A pipeline for automating emergency medicine documentation using LLMs with retrieval-augmented text generation. <em>AAI</em>, <em>39</em>(1), Article: 2519169. (<a href='https://doi.org/10.1080/08839514.2025.2519169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and efficient documentation of patient information is vital in emergency healthcare settings. Traditional manual documentation methods are often time-consuming and prone to errors, potentially affecting patient outcomes. Large Language Models (LLMs) offer a promising solution to enhance medical communication systems; however, their clinical deployment, particularly in non-English languages such as German, presents challenges related to content accuracy, clinical relevance, and data privacy. This study addresses these challenges by developing and evaluating an automated pipeline for emergency medical documentation in German. The research objectives include (1) generating synthetic dialogues with known ground truth data to create controlled datasets for evaluating NLP performance and (2) designing an innovative pipeline to retrieve essential clinical information from these dialogues. A subset of 100 anonymized patient records from the MIMIC-IV-ED dataset was selected, ensuring diversity in demographics, chief complaints, and conditions. A Retrieval-Augmented Generation (RAG) system extracted key nominal and numerical features using chunking, embedding, and dynamic prompts. Evaluation metrics included precision, recall, F1-score, and sentiment analysis. Initial results demonstrated high extraction accuracy, particularly in medication data (F1-scores: 86.21%–100%), though performance declined in nuanced clinical language, requiring further refinement for real-world emergency settings.},
  archive      = {J_AAI},
  author       = {Denis Moser and Matthias Bender and Murat Sariyar},
  doi          = {10.1080/08839514.2025.2519169},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2519169},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A pipeline for automating emergency medicine documentation using LLMs with retrieval-augmented text generation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting and explaining postpartum depression in real-time with generative artificial intelligence. <em>AAI</em>, <em>39</em>(1), Article: 2515063. (<a href='https://doi.org/10.1080/08839514.2025.2515063'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among the many challenges mothers undergo after childbirth, postpartum depression (PPD) is a severe condition that significantly impacts their mental and physical well-being. Consequently, the rapid detection of PPD and their associated risk factors is critical for in-time assessment and intervention through specialized prevention procedures. Accordingly, this work addresses the need to help practitioners make decisions with the latest technological advancements to enable real-time screening and treatment recommendations. Mainly, our work contributes to an intelligent PPD screening system that combines Natural Language Processing, Machine Learning (ML), and Large Language Models (LLMS) toward an affordable, real-time, and noninvasive free speech analysis. Moreover, it addresses the black box problem since the predictions are described to the end users thanks to the combination of LLMS with interpretable ML models ( i.e . tree-based algorithms) using feature importance and natural language. The results obtained are 90 on PPD detection for all evaluation metrics, outperforming the competing solutions in the literature. Ultimately, our solution contributes to the rapid detection of PPD and their associated risk factors, critical for in-time and proper assessment and intervention.},
  archive      = {J_AAI},
  author       = {Silvia García-Méndez and Francisco de Arriba-Pérez},
  doi          = {10.1080/08839514.2025.2515063},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2515063},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Detecting and explaining postpartum depression in real-time with generative artificial intelligence},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing robustness in feature importance methods with NAFIC and CESHAP for improved interpretability. <em>AAI</em>, <em>39</em>(1), Article: 2515062. (<a href='https://doi.org/10.1080/08839514.2025.2515062'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding and interpreting machine learning models is crucial in high-stakes industries like steel manufacturing, where decisions impact energy efficiency and environmental sustainability. Traditional feature importance methods often struggle with robustness under noisy conditions, leading to unreliable insights. To address this problem, we introduce the Complexity and Interaction Enhanced SHAP (CESHAP), a novel feature importance method that incorporates model complexity and feature interactions. Alongside, we propose the Noise-Adjusted Feature Importance Change (NAFIC) metric to assess the robustness of feature importance methods against varying levels of noise. Experiments conducted on an energy consumption dataset from the steel industry, with systematically introduced Gaussian noise levels (5%, 10%, 15%, 20%), demonstrate that CESHAP offers superior robustness in tree-based models compared to SHapley Additive exPlanations (SHAP) and Permutation Feature Importance (PFI). Our findings underscore the effectiveness of CESHAP in enhancing interpretability and reliability in complex, non-linear models, ultimately supporting more informed decision-making in energy-intensive industries.},
  archive      = {J_AAI},
  author       = {Grigorios Tzionis and Georgia Kougka and Ilias Gialampoukidis and Stefanos Vrochidis and Ioannis Kompatsiaris and Maro Vlachopoulou},
  doi          = {10.1080/08839514.2025.2515062},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2515062},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Enhancing robustness in feature importance methods with NAFIC and CESHAP for improved interpretability},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSFE-net: Multi-scale feature enhancement network for remote sensing object detection. <em>AAI</em>, <em>39</em>(1), Article: 2514324. (<a href='https://doi.org/10.1080/08839514.2025.2514324'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense objects detection in remote sensing is challenging due to similar neighboring features, causing redundant boxes and positioning errors. To address this, we propose MSFE-Net, a multi-scale feature enhancement network designed to effectively suppress background interference and detect adjacent similar targets. Our Cascading Feature Fusion Module (CFFM) and Weighted Dilated Convolutional Pyramid (WDCP) enhance shallow texture and deep semantic features, respectively. To further reduce redundant target boxes, the Weighted Feature Fusion Enhancement Module (WFFEM) learns differential and fused features across multiple branches, thereby enriching target contextual features and suppressing background noise. Ultimately, the Multi-scale Feature Stairstep-upsampling Fusion Module (MFSFM) refines high-resolution texture and semantic features for targets across scales, using a stairstep-upsampling fusion strategy with outputs from the CFFM, WDCP, and WFFEM. Experimental results on the NWPU VHR-10 dataset show that MSFE-Net achieves 92.8% in mAP50 and 62.6% in mAP75, outperforming state-of-the-art methods such as YOLOv6 and YOLOv7. Compared to other models, MSFE-Net balances between parameter counts and computational demand, with Params slightly higher than YOLOv5s and YOLOv7-tiny and GFLOPs in a moderately high range. These results underscore MSFE-Net’s efficacy in balancing accuracy with computational demands, rendering it a highly practical option for dense object detection in remote sensing.},
  archive      = {J_AAI},
  author       = {Kai Yuan and Xing Li and Yaoyao Ren and Lianpeng Zhang and Wei Liu and Erzhu Li},
  doi          = {10.1080/08839514.2025.2514324},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2514324},
  shortjournal = {Appl. Artif. Intell.},
  title        = {MSFE-net: Multi-scale feature enhancement network for remote sensing object detection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Augmentation of semantic processes for deep learning applications. <em>AAI</em>, <em>39</em>(1), Article: 2506788. (<a href='https://doi.org/10.1080/08839514.2025.2506788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The popularity of Deep Learning (DL) methods used in business process management research and practice is constantly increasing. One important factor that hinders the adoption of DL in certain areas is the availability of sufficiently large training datasets, particularly affecting domains where process models are mainly defined manually with a high knowledge-acquisition effort. In this paper, we examine process model augmentation in combination with semi-supervised transfer learning to enlarge existing datasets and train DL models effectively. The use case of similarity learning between manufacturing process models is discussed. Based on a literature study of existing augmentation techniques, a concept is presented with different categories of augmentation from knowledge-light approaches to knowledge-intensive ones, e. g. based on automated planning. Specifically, the impacts of augmentation approaches on the syntactic and semantic correctness of the augmented process models are considered. The concept also proposes a semi-supervised transfer learning approach to integrate augmented and non-augmented process model datasets in a two-phased training procedure. The experimental evaluation investigates augmented process model datasets regarding their quality for model training in the context of similarity learning between manufacturing process models. The results indicate a large potential with a reduction of the prediction error of up to 53%.},
  archive      = {J_AAI},
  author       = {Maximilian Hoffmann and Lukas Malburg and Ralph Bergmann},
  doi          = {10.1080/08839514.2025.2506788},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2506788},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Augmentation of semantic processes for deep learning applications},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EXplainable artificial intelligence for hip fracture recognition. <em>AAI</em>, <em>39</em>(1), Article: 2502568. (<a href='https://doi.org/10.1080/08839514.2025.2502568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting hip fractures from X-rays is a critical area where artificial intelligence can significantly reduce diagnostic errors, minimize reliance on advanced imaging techniques, and expedite the diagnostic process and subsequent surgical interventions. In this paper, we present an approach of eXplainable Artificial Intelligence, which focuses not only on the accuracy of models but also on their interpretability and the ability of users to understand and trust the decisions made by the automatic system. We present a model for the automatic classification of hip fractures in radiographs based on Convolutional Neural Networks, which is enhanced by a twin Case-Based Reasoning methodology for acquiring explanatory experiences and learning how to generate textual explanations. These findings underscore the practical benefits of incorporating explanations into medical diagnostics, paving the way for improved patient outcomes and more reliable diagnostic processes.},
  archive      = {J_AAI},
  author       = {Enrique Queipo-de-Llano and Marius Ciurcau and Alejandro Paz-Olalla and Belén Díaz-Agudo and Juan A. Recio-García},
  doi          = {10.1080/08839514.2025.2502568},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2502568},
  shortjournal = {Appl. Artif. Intell.},
  title        = {EXplainable artificial intelligence for hip fracture recognition},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time series forecasting using recurrent neural networks based on recurrent sigmoid piecewise linear neurons. <em>AAI</em>, <em>39</em>(1), Article: 2490057. (<a href='https://doi.org/10.1080/08839514.2025.2490057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new recurrent sigmoid piecewise linear neuron that can be used in neural networks to perform time series forecasting. The neuron model guarantees its dynamical stability for any sequence of input values and any number of recurrent steps and provides an upper bound for the variance of context vector elements. The neuron can be used as a drop-in replacement for the popular long short-term memory and gated recurrent unit neurons. In addition to theoretical analysis experiments on real-world time series were performed to evaluate networks with different structures and neuron types. Experiments show that networks with the new neuron achieve better test accuracy while using a considerably smaller number of trainable parameters.},
  archive      = {J_AAI},
  author       = {Victor Sineglazov and Vladyslav Horbatiuk},
  doi          = {10.1080/08839514.2025.2490057},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2490057},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Time series forecasting using recurrent neural networks based on recurrent sigmoid piecewise linear neurons},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized recommendation system of E-commerce in the digital economy era: Enhancing social connections with graph attention networks. <em>AAI</em>, <em>39</em>(1), Article: 2487417. (<a href='https://doi.org/10.1080/08839514.2025.2487417'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of digital economy, e-commerce platforms face significant challenges in providing personalized recommendations due to data sparsity, a result of limited user-product interactions. This research introduces a model that enhances e-commerce personalization by leveraging graph attention networks to mine and integrate information from user-item (U-I) score graphs and user-user (U-U) social graphs. The U-U social graph captures user relationships, providing supplementary information to uncover social connections and preferences, especially among users with sparse interactions, thereby alleviating data sparsity concerns. Additionally, the model incorporates graph contrastive learning to extract universal features of users and items, further mitigating the sparse data challenge. Our approach, when applied to the CiaoDVD and Epinions datasets, demonstrated a 1.21% improvement in Mean Absolute Error (MAE) and a 2.22% improvement in Root Mean Square Error (RMSE) on the CiaoDVD dataset, and a 1.71% improvement in MAE and a 2.11% improvement in RMSE on the Epinions dataset, outperforming all baseline methods.},
  archive      = {J_AAI},
  author       = {Yuan He and Yonghong Du and Xiaofei Pu},
  doi          = {10.1080/08839514.2025.2487417},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2487417},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Personalized recommendation system of E-commerce in the digital economy era: Enhancing social connections with graph attention networks},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image logic and semantics of user motion interaction language based on deep learning. <em>AAI</em>, <em>39</em>(1), Article: 2482989. (<a href='https://doi.org/10.1080/08839514.2025.2482989'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of science and technology, exploring the image logic semantics of users’ Chinese language using deep learning is crucial for understanding users’ interactions in virtual space. To address the challenges of recognizing existential sentences in Chinese language images, this research introduces a Tree-LSTM encoder, combined with an improved Transformer attention mechanism, to construct a logical semantic recognition model. The model was validated using a dataset from the Modern Dictionary database. Results showed that the proposed model achieved a recognition accuracy of 90.01%, surpassing other models by at least 2.99%. After incorporating Wikipedia data, the model’s performance in handling complex sentence structures and technical terminology was particularly outstanding. When all the extended data sources were integrated, the model’s accuracy reached 92.31%, representing a 2.3% improvement over the original dataset. This success is due to the Tree-LSTM’s ability to capture hierarchical and logical relationships within sentences. The model also effectively learns and recognizes low-frequency new words, enhancing overall performance.},
  archive      = {J_AAI},
  author       = {Yanlan Liu and Yixi Zhai and Liqing Chu and Dandan Wang and Yufei Wu},
  doi          = {10.1080/08839514.2025.2482989},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2482989},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Image logic and semantics of user motion interaction language based on deep learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards automated frequency response analysis of power transformers with deep learning. <em>AAI</em>, <em>39</em>(1), Article: 2479223. (<a href='https://doi.org/10.1080/08839514.2025.2479223'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequency response analysis (FRA) has emerged as one of the standard techniques for monitoring the integrity of the mechanical structure of power transformer windings. Interpreting FRA test results, though, is still largely dependent on expert identification of graphical features. Machine learning, however, presents an opportunity to automate and improve this feature identification process. In this study, FRA measurements were simulated and then image and series data representations were used to train three neural networks. The Xception network, trained with image magnitude data, obtained the best performance, with an F1 score of 98.6%. The ResNet and Fully Connected Neural Network, trained with series magnitude data, obtained F1 scores of 94.6% and 91.4%, respectively. Results revealed that networks trained using image-encoded FRA data outperformed those trained using series FRA data.},
  archive      = {J_AAI},
  author       = {Micah Phillip and Arvind Singh and Craig J. Ramlal},
  doi          = {10.1080/08839514.2025.2479223},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2479223},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Towards automated frequency response analysis of power transformers with deep learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring healthcare and public health implications via temporal analysis of Human–Virus interactions leveraging adversarial networks and saliency maps. <em>AAI</em>, <em>39</em>(1), Article: 2476237. (<a href='https://doi.org/10.1080/08839514.2025.2476237'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Viruses are prone to rapid mutations that enhance traits like transmissibility and resistance to treatments. The adaptability complicates the development of effective vaccines. The study investigates the dynamic interactions between humans and COVID-19 virus through time-series analysis, focusing on how these interactions evolve over time. A novel approach was introduced using adversarial networks to model the relationship between human and viral entities, capturing their temporal dynamics. Two interdependent models are trained within a framework, allowing us to forecast interactions and identify influential features. Saliency maps were utilized to visualize the factors affecting these interactions over time. The technique helps reveal how specific viral properties shift in response to human factors. The findings of the study aim to enhance the understanding of human-virus dynamics, particularly for COVID-19, offering potential insights for public health strategies and interventions. By combining adversarial networks with saliency visualization, the study provides an intensive study for analyzing and interpreting complex temporal interactions between humans and viruses.},
  archive      = {J_AAI},
  author       = {Nihal Srivastava and Logesh Ravi and Malathi Devarajan and Amal John Kachapilly and Jaisuraj Bantupalli and Sanjukta Roy},
  doi          = {10.1080/08839514.2025.2476237},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2476237},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Exploring healthcare and public health implications via temporal analysis of Human–Virus interactions leveraging adversarial networks and saliency maps},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting trip duration and distance in bike-sharing systems using dynamic time warping. <em>AAI</em>, <em>39</em>(1), Article: 2474786. (<a href='https://doi.org/10.1080/08839514.2025.2474786'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bike-sharing systems (BSSs) have recently become important in urban transportation due to several factors, such as their cost-effectiveness and environmental considerations. The BSS provides an enormous amount of data that is recorded regarding trips. This huge volume of bike sharing data raises various challenges and opportunities. Many research studies have used bike sharing datasets to understand the geographical, social, financial, and behavioral aspects of bike user behaviors. While existing literature primarily focuses on predicting the number of rentals and returns per station, this study addresses the complementary aspect of predicting the trip duration and distance of the trip. Accurate prediction of ride duration allows a better estimate of bike availability at stations, while distance predictions assist in maintenance planning based on bike usage patterns. The contribution of this work is twofold. First, the proposed work clusters the BSS dataset into k sub-datasets based on similarity of dataset instances. Then, the predictive model is trained to predict the data of each sub-dataset separately. Thus, there will be k models for the k sub-dataset. Next, the performance of the proposed method, the average score of the k models, will be compared to the performance of a model trained on the complete dataset on predicting BSSs ride duration and distance of the trip. The rationale for splitting the dataset into k sub-datasets is to separate similar patterns in one sub-dataset. Second, the utilization of the dynamic time warping (DTW) algorithm on the BSSs data was proposed for the clustering purpose, as the DTW usage is very limited in the current literature of BSSs. The dataset clustering is based on the similarity of the curves representing the number of trips between each pair of bike stations throughout the day hours. Then, the DTW algorithm is used to measure the curve similarity between these bike station pairs’ curves. These two contributions of the proposed approach complement existing prediction models for rentals and returns, providing a comprehensive solution for BSS optimization. The proposed method was thoroughly evaluated on two real datasets of different sizes. For the two datasets, the obtained results show that the best improvements of the predictive model’s accuracy are 30% and 42% on average for predicting trip duration and distance of the trip, respectively.},
  archive      = {J_AAI},
  author       = {Ahmed Ali and Ahmad Salah and Mahmoud Bekhit and Ahmed Fathalla},
  doi          = {10.1080/08839514.2025.2474786},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2474786},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Predicting trip duration and distance in bike-sharing systems using dynamic time warping},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot learning for triplet-based EV energy consumption estimation. <em>AAI</em>, <em>39</em>(1), Article: 2474785. (<a href='https://doi.org/10.1080/08839514.2025.2474785'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the energy consumption of an electric vehicle (EV) is often relevant when planning and managing electric mobility. The prediction is challenging as EV energy consumption is highly variable and dependent on context . First, this paper proposes an integrated framework for the collection of online telematic data, processing of this data, online maintenance of statistics, and machine-learning-based prediction of travel time and energy consumption. A key feature of the proposed framework is the preprocessing of the trajectory data into triplets , a convenient data unit that captures the relevant context necessary for effective energ y prediction. The second contribution of the paper addresses the effective management of drastic change in context through robust energy prediction models. In particular, using few-shot learning techniques, we tackle the problem of the need to create different energy prediction models for different EV types, from small EVs to electric buses. Experimental results on three different data sets demonstrate how energy prediction models adapt to different EV types.},
  archive      = {J_AAI},
  author       = {Alminas Čivilis and Linas Petkevičius and Simonas Šaltenis and Kristian Torp and Ieva Markucevičiūtė-Vinckė},
  doi          = {10.1080/08839514.2025.2474785},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2474785},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Few-shot learning for triplet-based EV energy consumption estimation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MagneticPillars++: Efficient LiDAR odometry via deep frame-to-keyframe point cloud registration. <em>AAI</em>, <em>39</em>(1), Article: 2472105. (<a href='https://doi.org/10.1080/08839514.2025.2472105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Downstream applications for point cloud registration, like LiDAR Odometry, often conduct Iterative Closest Points (ICP) in the initial frame-to-frame matching and/or subsequent map refinement. However, due to its distance-based processing nature, ICP relies on an accurate pose initialization while implicating increased computational complexity with a growing number of points. To meet specific runtime requirements, methods often apply the extensive mapping step at low frequencies, e.g. every 10 frames, which in turn leads to increased noise on the calculated trajectory. To tackle the discrepancy between runtime and accuracy, we present MagneticPillars++, an extension of our previous point cloud registration approach optimized for LiDAR Odometry, introducing novel intermediate cell correspondence filtering and accelerated match normalization. Furthermore, we propose a frame-to-keyframe matching technique replacing the simple frame-to-frame matching within a LiDAR Odometry pipeline. This can tremendously reduce noise without the need for expensive ICP corrections. We conduct extensive experiments for various tasks like point cloud registration, LiDAR Odometry, and loop closure estimation, demonstrating the versatility of our approach, where we are able to outperform state-of-the-art approaches in terms of accuracy and runtime, resulting in residual translation and rotation errors of up to 4.7 cm and 0.231 with an average runtime of.},
  archive      = {J_AAI},
  author       = {Kai Fischer and Martin Simon and Stefan Milz and Patrick Mäder},
  doi          = {10.1080/08839514.2025.2472105},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2472105},
  shortjournal = {Appl. Artif. Intell.},
  title        = {MagneticPillars++: Efficient LiDAR odometry via deep frame-to-keyframe point cloud registration},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSNet: A novel deep learning framework for efficient missing seedling detection in maize fields. <em>AAI</em>, <em>39</em>(1), Article: 2469372. (<a href='https://doi.org/10.1080/08839514.2025.2469372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine vision application in agriculture has spurred significant interest in crop-missing detection. This study targets critical challenges, such as comprehensive aerial imagery coverage, tiny seedlings easily mistaken for weeds, and the absence of adaptive learning in traditional row classification. We propose a novel methodology for missing seedling detection, which comprises three essential stages: seedling localization, row classification, and missing region prediction. We present SeedNet, a detector that leverages row direction information to enhance small seedling detection performance. By incorporating this information, SeedNet improves recall by 25.3 % and AP by 15.4 % compared to the baseline. Additionally, we introduce PeakNet, a deep learning-based classifier for row segmentation that efficiently adapts to row spacing without any prior assumptions, achieving an accuracy of 99.69 % . Finally, missing areas are predicted by analyzing the relative distances between adjacent seedlings within the same row. Under challenging outdoor conditions, this method achieves a missing detection accuracy of 98 % , meeting practical requirements for field testing. SeedNet and PeakNet demonstrate exceptional performance in real-time processing, achieving inference speeds of 105 FPS and 2295 FPS, respectively. These results indicate strong potential for practical applications in real-time agricultural systems. The proposed approach provides a high-performance, low-cost solution for crop missing detection.},
  archive      = {J_AAI},
  author       = {Yong Shi and Ruijie Xu and Zhiquan Qi},
  doi          = {10.1080/08839514.2025.2469372},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2469372},
  shortjournal = {Appl. Artif. Intell.},
  title        = {MSNet: A novel deep learning framework for efficient missing seedling detection in maize fields},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Handling class imbalanced data in sarcasm detection with ensemble oversampling techniques. <em>AAI</em>, <em>39</em>(1), Article: 2468534. (<a href='https://doi.org/10.1080/08839514.2025.2468534'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of social media has amplified online sharing, necessitating businesses to comprehend public sentiment. Traditional sentiment analysis struggles with sarcasm detection and class imbalance. To address this, we introduce Synthetic Ensemble Oversampling methods (SEO) that effectively leverage the strengths of various oversampling algorithms. By incorporating ensemble learning principles into oversampling techniques, our proposed methods offer distinct strategies for selecting newly generated sarcastic data. In this study, we employ five oversampling algorithms: Synthetic Minority Oversampling TEchnique (SMOTE), Adaptive Synthetic Sampling (ADASYN), polynom-fit-SMOTE, Proximity Weighted Synthetic Sampling (ProWSyn), and SMOTE with Instance Prioritization and Filtering (SMOTE_IPF). We work with two imbalanced sarcasm detection datasets, iSarcasmEval and SARC-reduced, collected from Twitter and Reddit. After extracting features from using Word2Vec, Global Vectors (GloVe), and FastText, we apply oversampling and ensemble techniques. Evaluated across six classifiers – Support Vector Machine, Decision Tree, Random Forest, Extreme Gradient Boosting, Logistic Regression, and BERT – the results demonstrate that the SEO2 framework consistently enhances classifier performance compared to single oversampling techniques. Notably, the Cluster Uncentered method frequently provides the best improvements across datasets, achieving significant gains in both AUC and F1 scores. These findings highlight the potential of ensemble-based oversampling in addressing class imbalance for sarcasm detection.},
  archive      = {J_AAI},
  author       = {Ya-Han Hu and Ting-Hsuan Liu and Chih-Fong Tsai and Yu-Jung Lin},
  doi          = {10.1080/08839514.2025.2468534},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2468534},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Handling class imbalanced data in sarcasm detection with ensemble oversampling techniques},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prior waveform guided network (PWGN) for laser detection in fog. <em>AAI</em>, <em>39</em>(1), Article: 2463725. (<a href='https://doi.org/10.1080/08839514.2025.2463725'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of autonomous vehicles and mobile robotics, lidar has been one of the most popular researches in the world. But the poor ranging accuracy and detection range in the foggy situation have limited the application of lidar. In this paper, the detection of pulsed lidar in fog is investigated. The transmission model in the fog of the laser signal is established by considering laser backscattering in the fog. A Prior Waveform Guided Network (PWGN) based on the Convolutional Neural Network (CNN) is proposed. The results of simulation and experiments show that the PWGN can effectively remove the interference of fog in the detection of pulsed laser signal. The mean of absolute errors(MAE) of the detection achieves 3.13 cm at the range of 10 m at the scattering rate of 30%. The MAE may be half or 1/3 of the MAEs of other approaches at the detection range of 42 m.},
  archive      = {J_AAI},
  author       = {Haowei Zhu and Long Wu and Xu Yang and Lu Xu and Shuyu Chen and Yong Zhang and Jianlong Zhang and Chenghua Yang and Wei Zhang},
  doi          = {10.1080/08839514.2025.2463725},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2463725},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Prior waveform guided network (PWGN) for laser detection in fog},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Establishing a dynamic recommendation system for E-commerce by integrating online reviews, product feature expansion, and deep learning. <em>AAI</em>, <em>39</em>(1), Article: 2463723. (<a href='https://doi.org/10.1080/08839514.2025.2463723'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing fragmentation of the consumer journey complicates understanding consumer behavior and tracking digital footprints. Product feature tags should dynamically adapt to consumer preferences, marketing campaigns, and trending internet topics, leveraging crawler technology to address this. However, many e-commerce platforms still rely on manual tagging or static product attribute classification, with limited adoption of machine learning approaches. This study proposes a dynamic tagging and recommendation system using deep learning for product image recognition and similarity comparison. By integrating crawler technology, internet trends can serve as dynamic product tags. These tags, combined with consumer behavior data, enable the creation of a recommendation system capable of automatically generating relevant tags. Sales data from 3,132 cartoon products on a Taiwanese e-commerce platform were analyzed. A convolutional neural network was employed to establish a tagging and image recognition model, and it was trialed over 24 weeks. Results showed significant improvements in consumer engagement: average clicks per product increased by 36.1%, views by 22.9%, products added to carts by 32.3%, orders by 28.3%, and payment transactions by 30.4%. Aligning recommendation systems with consumer expectations enhances their ability to identify preferences and drive purchasing behavior.},
  archive      = {J_AAI},
  author       = {Tsung-Yin Ou and Chun-Hung Chen and Wen-Lung Tsai},
  doi          = {10.1080/08839514.2025.2463723},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2463723},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Establishing a dynamic recommendation system for E-commerce by integrating online reviews, product feature expansion, and deep learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI ethics: Integrating transparency, fairness, and privacy in AI development. <em>AAI</em>, <em>39</em>(1), Article: 2463722. (<a href='https://doi.org/10.1080/08839514.2025.2463722'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expansion of Artificial Intelligence in sectors such as healthcare, finance, and communication has raised critical ethical concerns surrounding transparency, fairness, and privacy. Addressing these issues is essential for the responsible development and deployment of AI systems. This research establishes a comprehensive ethical framework that mitigates biases and promotes accountability in AI technologies. A comparative analysis of international AI policy frameworks from regions including the European Union, United States, and China is conducted using analytical tools such as Venn diagrams and Cartesian graphs. These tools allow for a visual and systematic evaluation of the ethical principles guiding AI development across different jurisdictions. The results reveal significant variations in how global regions prioritize transparency, fairness, and privacy, with challenges in creating a unified ethical standard. To address these challenges, we propose technical strategies, including fairness-aware algorithms, routine audits, and the establishment of diverse development teams to ensure ethical AI practices. This paper provides actionable recommendations for integrating ethical oversight into the AI lifecycle, advocating for the creation of AI systems that are both technically sophisticated and aligned with societal values. The findings underscore the necessity of global collaboration in fostering ethical AI development.},
  archive      = {J_AAI},
  author       = {Petar Radanliev},
  doi          = {10.1080/08839514.2025.2463722},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2463722},
  shortjournal = {Appl. Artif. Intell.},
  title        = {AI ethics: Integrating transparency, fairness, and privacy in AI development},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metadata enriched multi-instance contrastive learning for high-quality facial skin visual representations. <em>AAI</em>, <em>39</em>(1), Article: 2462389. (<a href='https://doi.org/10.1080/08839514.2025.2462389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Utilizing self-supervised learning to learn meaningful representations from unlabeled data can be a cost-effective strategy, particularly in medical domains where expert labeling incurs high costs. Contrastive learning typically employs a single contrastive relationship based on individual instances. However, depending on the task-related characteristics, such as facial skin images, this approach may be unsuitable for learning useful representations. In this work, we propose an advanced contrastive learning method to learn high-quality facial skin representations that are useful for various downstream applications related to skin disorders, such as wrinkles and pigmentation. Our method leverages metadata to establish effective multi-instance contrastive relationships specifically for facial skin images. To this end, we employ mini-batches, constructed through the integration of multiple contrastive relationships, to enable a model to learn the multifaceted features of facial skin. Using a facial skin image dataset, we demonstrate that the proposed method is effective in classifying facial wrinkles and pigmentation severity compared to conventional contrastive learning. The features learned by the proposed method adapt well to other skin lesion datasets from different sources, demonstrating the transferability of the learned skin representations. Our study highlights the potential of application-specific batch configurations leveraging metadata to enhance the effectiveness of self-supervised learning.},
  archive      = {J_AAI},
  author       = {Jihyo Kim and Sungchul Kim and Seungwon Seo and Bumsoo Kim and Daejeong Mun and Hoonjae Lee and Sangheum Hwang},
  doi          = {10.1080/08839514.2025.2462389},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2462389},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Metadata enriched multi-instance contrastive learning for high-quality facial skin visual representations},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DHMDL: Dynamically hashed multimodal deep learning framework for racket video summarization using audio and visual markers. <em>AAI</em>, <em>39</em>(1), Article: 2462382. (<a href='https://doi.org/10.1080/08839514.2025.2462382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sports videos are being streamed over a large range of social media platforms, and they always have a huge audience base and viewer history. In order to provide more excitement for the users in watching a completed game, automatic video summarization is an inevitable solution. While sports like soccer, cricket have been the main focus of the video summarization research, little attention has been centered over racket sports. Our proposed dynamically hashed multimodal deep learning (DHMDL) sports video summarization framework fuses excitement scores by utilizing deep learning architectures to extract cues from multi modalities namely commentator voice, spectators’ cheers and player’s expression and then leverages to generate video segment as highlight by using hash codes mapped to weighted sum of excitement score. Also, the proposed synchronized parallel processing ranking based hash map framed using the merge sorting technique for categorizing the excitement scores is applied in video summarization. The framework is tested on U.S. Open and Wimbledon match videos and the results show superior results against state-of-art techniques with normalized discounted cumulative gain (nDCG) score improved by 2%, positive matching highlight segment identification increased by 20% on YouTube Videos.},
  archive      = {J_AAI},
  author       = {G. Priyanka and J. Senthil Kumar and M. Prasha Meena},
  doi          = {10.1080/08839514.2025.2462382},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2462382},
  shortjournal = {Appl. Artif. Intell.},
  title        = {DHMDL: Dynamically hashed multimodal deep learning framework for racket video summarization using audio and visual markers},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-based energy consumption prediction model for green industrial parks. <em>AAI</em>, <em>39</em>(1), Article: 2462375. (<a href='https://doi.org/10.1080/08839514.2025.2462375'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancing the accuracy of industrial building energy consumption forecasts is beneficial for improving energy management and addressing the imbalance between supply and demand in building electricity use. To overcome the limitations of existing energy consumption forecasting methods, which inadequately consider the specific energy usage characteristics and user behaviors in parks and often perform poorly at predicting extreme values, this study proposes a hybrid energy consumption forecasting model combines Singular Spectrum Analysis (SSA) and Long Short-Term Memory (LSTM) neural networks. Initially, SSA is used to extract the autocorrelation of the electricity consumption series and eliminate the mutual interference caused by component mixing. Then, fuzzy entropy values are utilized to differentiate the complexity of various components, reconstructing them into high-frequency and low-frequency components. These components are then predicted using a multi-factor LSTM model optimized by improved particle swarm optimization, with the results aggregated for the final forecast. The results indicate that the model’s root mean square error is only 12.116 kWh, which is lower compared to the LSTM multi-factor model, the EMD-LSTM model, and the SSA-LSTM model. The model shows a closer fit to the original series trend and more accurate predictions at extreme points, aligning more closely with actual values.},
  archive      = {J_AAI},
  author       = {Chaoan Lai and Yina Wang and Jianhua Zhu and Xuequan Zhou},
  doi          = {10.1080/08839514.2025.2462375},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2462375},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Deep learning-based energy consumption prediction model for green industrial parks},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variable selection algorithm for explaining anomalies in real-world regenerative thermal oxidizers. <em>AAI</em>, <em>39</em>(1), Article: 2462374. (<a href='https://doi.org/10.1080/08839514.2025.2462374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of regenerative thermal oxidizers (RTOs), which reduce hazardous air pollution and save energy, has increased with the rapid growth of industrial technology. Therefore, detecting and explaining anomalies in RTOs have become important. To accurately detect anomalies in RTOs, it is required to apply reconstruction-based anomaly detection (AD) models, which is currently proposed as a main AD research area. However, traditional explainable artificial intelligence (XAI) cannot explain reconstruction-based AD models to identify main facilities in RTOs. To address this problem, we developed a method to improve the accuracy of XAI in explaining reconstruction-based AD models. Specifically, we first grouped the variables based on correlation and the clustering analysis. We then calculated the impact of each group on normal/abnormal events in terms of the maximum mean discrepancy and cosine similarity. Using the most influencing variables based on our method, XAI correctly identified the main variables without considering unnecessary variables. Experimental results on a real-world RTO dataset showed that our method improve the accuracy of XAI that determine the main variables compared to the traditional XAI.},
  archive      = {J_AAI},
  author       = {Min-Ji Seo and Myung-Ho Kim},
  doi          = {10.1080/08839514.2025.2462374},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2462374},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Variable selection algorithm for explaining anomalies in real-world regenerative thermal oxidizers},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A composite recognition method based on multimode mutual attention fusion network. <em>AAI</em>, <em>39</em>(1), Article: 2462371. (<a href='https://doi.org/10.1080/08839514.2025.2462371'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the problem of single-mode vulnerability to complex environments, a multimode fusion network with mutual attention is proposed. This network combines the use of laser, infrared and millimeter wave modalities to leverage the advantages of each mode in different environments, increasing the network’s resilience to interference. The study begins with the construction of pixel-level fusion networks, feature-weighted fusion networks and the multimode mutual attention fusion network. A comprehensive introduction to the multimode mutual attention fusion network is given, as well as a comparison with the other two networks. The model is then trained and evaluated using data from glide rocket and drone experiments. Finally, an analysis of the anti-outlier interference capability of the multimode fusion network with mutual attention is carried out. The test results show that the multimode mutual attention fusion network containing a feature fusion attention mechanism has the highest detection performance and anti-interference ability. Without interference, the network achieves a remarkable accuracy of 0.98 for multi-target recognition. In addition, with an accuracy of 0.96, it ensures a high level of stability in various interference environments. In addition, the introduction of multi-scale fusion has improved the rocket’s speed adaptability by about 75%.},
  archive      = {J_AAI},
  author       = {Xing Ding and Xiangrong Zhang and Chao Liang and Bo Liu and Lanjie Niu},
  doi          = {10.1080/08839514.2025.2462371},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2462371},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A composite recognition method based on multimode mutual attention fusion network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DC-BiLSTM-CNN algorithm for sentiment analysis of chinese product reviews. <em>AAI</em>, <em>39</em>(1), Article: 2461809. (<a href='https://doi.org/10.1080/08839514.2025.2461809'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of e-commerce has led to a significant increase in user feedback, especially in the form of post-purchase comments on online platforms. These reviews not only reflect customer sentiments but also crucially influence other users’ purchasing decisions due to their public accessibility. The sheer volume and complexity of product reviews make manual sorting challenging, necessitating businesses to autonomously process and discern customer sentiments. Chinese, a predominant language on e-commerce platforms, presents unique challenges in sentiment analysis due to its character-based nature. This paper introduces an innovative Dual-Channel BiLSTM-CNN (DC-BiLSTM-CNN) algorithm. Based on the language characteristics of Chinese product reviews, a sentiment analysis algorithm, dual channel BiLSTM-CNN (DC-BiLSTM-CNN), is proposed. The algorithm constructs two channels, transforming text into both character and word vectors and inputting them into Bidirectional Long Short-Term Memory (BiLSTM), and Convolutional Neural Network (CNN) models. The combination of these channels facilitates a more comprehensive feature extraction from reviews. Comparative analysis revealed that DC-BiLSTM-CNN significantly outperforms baseline models, substantially enhancing the classification of product reviews. We conclude that the proposed DC-BiLSTM-CNN algorithm offers an effective solution for handling Chinese product reviews, carrying positive implications for businesses seeking to enhance product and service quality, ultimately resulting in heightened user satisfaction.},
  archive      = {J_AAI},
  author       = {Yuanfang Dong and Xiaofei Li and Meiling He and Jun Li},
  doi          = {10.1080/08839514.2025.2461809},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2461809},
  shortjournal = {Appl. Artif. Intell.},
  title        = {DC-BiLSTM-CNN algorithm for sentiment analysis of chinese product reviews},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Torque prediction in deep hole drilling: Artificial neural networks versus nonlinear regression model. <em>AAI</em>, <em>39</em>(1), Article: 2459482. (<a href='https://doi.org/10.1080/08839514.2025.2459482'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main challenges when drilling small and deep holes is the difficulty of chip evacuation. As the hole depth increases, chips tend to become tightly compressed, causing chip jamming. It leads to a rapid increase in cutting forces and strong random fluctuations. The discontinuous chip evacuation process makes the cutting force signal strongly nonlinear and random, making it difficult to predict accurately. In this paper, we have developed a two-layer artificial neural network (ANN) model for training using the Levenberg-Marquardt algorithm to predict torque during deep drilling. Unlike many previous studies, this model uses hole depth as an input vector element instead of hole diameter. The model has been validated through experiments drilling AISI-304 stainless steel with hole depth-to-diameter ratios of 8 under continuous drilling conditions with ultrasonic-assisted vibration. The performance of the ANN model was compared with the exponential model and evaluated by the MAPE index. Results show that the ANN model has better predictive capability, the average MAPE value approximately four times smaller and higher reliability with a standard deviation approximately 3.5 times smaller than the exponential function model. This model can be further refined to predict torque for drilling deep holes for future studies.},
  archive      = {J_AAI},
  author       = {Ngoc Hung- Chu and Hoai Nam- Nguyen and Van Du- Nguyen and Dang Binh- Nguyen},
  doi          = {10.1080/08839514.2025.2459482},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2459482},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Torque prediction in deep hole drilling: Artificial neural networks versus nonlinear regression model},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spectrogram features-based automatic speaker identification for smart services. <em>AAI</em>, <em>39</em>(1), Article: 2459476. (<a href='https://doi.org/10.1080/08839514.2025.2459476'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic speaker identification (ASI) is an exciting area of research with numerous applications such as surveillance, voice authentication, identity verification, and electronic voice eavesdropping. This study investigates ASI based on features derived from spectrogram images through a convolution neural network (CNN) with rectangular-shaped kernels. Traditionally, CNN employs square-shaped kernel and max-pooling operations at different layers, a design optimized to handle 2D data. Nevertheless, encoding of information differs slightly to deal with spectrograms. The frequency is displayed along the y-axis, and the x-axis presents the time of the audio. Amplitude is denoted by intensity within the spectrogram image at certain point. The main contributions of this study are 1: To analyze audio signals effectively using spectrograms, this study proposed the utilization of spectrogram features with different sizes and shapes of rectangular kernels to derive distinctive features by improving the recognition accuracy of the speaker identification system. 2. The extracted spectrogram-based features and models are evaluated on the ELSDSR, TSP, and LibriSpeech datasets and achieved the weighted accuracy of 96.0%, 99.2%, and 97.6%, respectively. 3. The proposed rectangular-shaped CNN approach effectively derives suitable features from spectrogram images and outperformed several baseline techniques when performance was assessed on ELSDSR, TSP, and LibriSpeech datasets.},
  archive      = {J_AAI},
  author       = {Rashid Jahangir and Mohammed Alreshoodi and Fawaz Khaled Alarfaj},
  doi          = {10.1080/08839514.2025.2459476},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2459476},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Spectrogram features-based automatic speaker identification for smart services},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ergonomic road sign evaluation and multi-criteria sorting based on q-rung orthopair fuzzy information embedded in CRITIC and TOPSIS-sort. <em>AAI</em>, <em>39</em>(1), Article: 2459470. (<a href='https://doi.org/10.1080/08839514.2025.2459470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a novel multi-criteria sorting approach for evaluating the compliance of road signs based on ergonomic principles and sign comprehension using an integrated Criteria Importance Through Intercriteria Correlation (CRITIC) and Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) sorting (TOPSIS-Sort) under an environment that handles uncertainty via q -rung orthopair fuzzy sets ( q -ROFS). The q -ROF-CRITIC assigns the priority weights of the attributes (i.e. comprehension and ergonomic principles), whereas the q -ROF-TOPSIS-Sort evaluates and classifies the compliance levels of road signs in view of a set of pre-defined categories, consequently bridging the limitations of the TOPSIS-Sort in handling imprecise evaluations. Demonstrated in an actual case study of evaluating 83 road signs in the Philippines, results show that prohibitive signs have the highest comprehension levels, while parking and stop signs, together with road obstacle signs, belong to the medium compliance level. Low-level compliance is observed for supplementary and intersection road signs due to unfamiliarity, while horizontal signs are ergonomically low on spatial and physical attributes. The proposed approach is supported by sensitivity analysis of q values and comparative assessments with other methods. The findings encourage further investigation into comprehensibility evaluations and open avenues for exploring the factors that influence road sign comprehension.},
  archive      = {J_AAI},
  author       = {Maria Gemel Palconit and Dyonne Bernadine Mirasol and Dyanne Brendalyn Mirasol-Cavero and Ferdinand Batayola and Hana Astrid Canseco-Tuñacao and Charldy Wenceslao and Nadine May Atibing and Lanndon Ocampo},
  doi          = {10.1080/08839514.2025.2459470},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2459470},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Ergonomic road sign evaluation and multi-criteria sorting based on q-rung orthopair fuzzy information embedded in CRITIC and TOPSIS-sort},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel RNN architecture to improve the precision of ship trajectory predictions. <em>AAI</em>, <em>39</em>(1), Article: 2459465. (<a href='https://doi.org/10.1080/08839514.2025.2459465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring maritime transport activities is crucial for ensuring the security and safety of people and goods. This type of monitoring often relies on the use of navigation systems such as the Automatic Identification System (AIS). AIS data has been used to support the defense teams when identifying equipment defects, locating suspicious activity, ensuring ship collision avoidance, and detecting hazardous events. In this context, Ship Trajectory Prediction (STP) has been conducted using AIS data to support the estimation of vessel routes and locations, contributing to maritime safety and situational awareness. Currently, the Ornstein-Uhlenbeck (OU) model is considered the state-of-the-art for STP. However, this model can be time-consuming and can only represent a single vessel track. To solve these challenges, Recurrent Neural Network (RNN) models have been applied to STP to allow scalability for large data sets and to capture larger regions or anomalous vessels behavior. This research proposes a new RNN architecture that decreases the prediction error up to 50% for cargo vessels when compared to the OU model. Results also confirm that the proposed Decimal Preservation layer can benefit other RNN architectures developed in the literature by reducing their prediction errors for complex data sets.},
  archive      = {J_AAI},
  author       = {Martha Dais Ferreira and Jessica N. A. Campbell},
  doi          = {10.1080/08839514.2025.2459465},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2459465},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A novel RNN architecture to improve the precision of ship trajectory predictions},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trust-based consensus and ABAC for blockchain using deep learning to secure internet of things. <em>AAI</em>, <em>39</em>(1), Article: 2459461. (<a href='https://doi.org/10.1080/08839514.2025.2459461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid increase in Internet of Things (IoT) applications has exposed critical security vulnerabilities, particularly concerning user privacy and identity forgery. To address these concerns, Blockchain technology offers a promising solution by providing strong security and ensuring data integrity through its transparent ledger system. By leveraging blockchain, IoT systems can enhance their security protocols, making it more difficult for attackers to exploit vulnerabilities and access sensitive data. We proposed Attribute-Based Access Control (ABAC) integrated with trust-based delegated consensus blockchain (TDCB) technology. The ABAC scheme employs Fully Homomorphic Encryption (FHE) processes to encrypt attributes and access regulations, enabling analytical operations directly on encrypted data. Dueling Double Deep Q-Networks with Prioritized Experience Replay (D3P) with Deep Reinforcement Learning (DRL) collaborate with Multiple blockchain nodes to decode the ABAC system’s data and optimize the performances of the blockchain. Our proposed scheme ABAC-TDBC-D3P enhances throughput and security and reduces total computing costs. The simulation results demonstrate that the suggested ABAC-TDCB-D3P scheme has a percentage of 86% for Collusive Rumour Attack (CRA) and 91% for Naive Malicious Attack (NMA). Significant improvements in blockchain security, particularly in mitigating the impact of malicious nodes, were compared to previous schemes.},
  archive      = {J_AAI},
  author       = {Arunkumar Muniswamy and R. Rathi},
  doi          = {10.1080/08839514.2025.2459461},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2459461},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Trust-based consensus and ABAC for blockchain using deep learning to secure internet of things},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PegasosQSVM: A quantum machine learning approach for accurate fake news detection. <em>AAI</em>, <em>39</em>(1), Article: 2457207. (<a href='https://doi.org/10.1080/08839514.2025.2457207'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid spread of fake news on social media poses a significant threat to modern societies. Traditional machine learning approaches have limitations in handling the ever-increasing volume and complexity of data. This research explores quantum machine learning for fake news classification by proposing Pegasos Quantum Support Vector Machines, a novel algorithm combining Pegasos Support Vector Machines with quantum kernels, and advanced data encoding. Through experimentation on the IBM Qasm Simulator, Pegasos Quantum Support Vector Machines scored 90.67% in accuracy. This study is primarily focused on local simulation, where the proposed algorithm scored as high as 95.63%, with 95.44% precision, 99.52% recall, and 96.76% f1-score. The achieved results outperform other machine learning methods on the BUZZFEED dataset, including Quantum Neural Networks and Quantum K-Nearest Neighbors. Its successful implementation paves the way for further refinement of quantum machine learning techniques in fake news classification. The PegasosQSVM algorithm encounters, however, some implementation issues on real world Quantum Processing Units(QPU). Noisy Intermediate-Scale Quantum era QPU are prone to noise effects that affect the computations negatively, and by extension, the results of quantum machine learning algorithms. Further implementation on real QPU and use of error mitigation techniques, are needed for optimal results on quantum hardware.},
  archive      = {J_AAI},
  author       = {Mehdi Khalil and Chi Zhang and Zhiwei Ye and Peng Zhang},
  doi          = {10.1080/08839514.2025.2457207},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2457207},
  shortjournal = {Appl. Artif. Intell.},
  title        = {PegasosQSVM: A quantum machine learning approach for accurate fake news detection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence in design process: An analysis using text mining. <em>AAI</em>, <em>39</em>(1), Article: 2453782. (<a href='https://doi.org/10.1080/08839514.2025.2453782'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The progress of Artificial Intelligence (AI) offers modern designers opportunities to explore innovative design processes. Particularly, generative AI that creates images and other content through text can contribute to the creative processes in various design fields such as graphics, industrial design, UX, and fashion. However, there is a lack of comprehensive research on AI’s role and applications throughout the entire design process, and current papers often employ qualitative methods such as interviews and case studies. Therefore, this paper aims to quantitatively analyze experts’ views on AI’s utilization in the whole design process through text mining of literature. The researchers selected 126 papers through scientific databases such as ScienceDirect, Web of Science, and utilized the keyword matching method to extract the frequency of keywords for each stage of the design process – Research, Ideation, Mock-up, Production, and Evaluation. Through text mining, research findings indicate that AI is predominantly discussed in the later stages of design, particularly in the production process, while its use in the mock-up stage is perceived to be low. Additionally, distinct differences in AI use across design disciplines were identified: graphics focusing on ideation; UX on evaluation; and fashion on production.},
  archive      = {J_AAI},
  author       = {Younjung Hwang and Seokjun Jeong and Yi Wu},
  doi          = {10.1080/08839514.2025.2453782},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2453782},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Artificial intelligence in design process: An analysis using text mining},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From baseline to best practice: An advanced feature selection, feature resampling and grid search techniques to improve injury severity prediction. <em>AAI</em>, <em>39</em>(1), Article: 2452675. (<a href='https://doi.org/10.1080/08839514.2025.2452675'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses the need for precise prediction models that predict the severity of injuries sustained in traffic crashes as a regression task. To this end, we thoroughly analyzed traffic crashes in Rome between 2016 and 2019, gathering data on vehicle attributes and environmental factors. Fourth predictive systems are employed to investigate the intricate problem of predicting the severity of injuries sustained in traffic crashes using different regression algorithms, such as Random Forest, Decision Trees, XGBoost, and Artificial Neural Networks. Compared to comparable systems without feature selection, feature resampling, and optimization methods, the results demonstrate that employing optimized XGBoost along with grid search in conjunction with SelectKBest and SMOTE strategy has resulted in greater performance, with an 89% R2 score. Our findings provide insight into the requirement for accurate forecasting models in optimization and balanced approaches to enhancing traffic safety. These findings offer a viable way to improve traffic safety tactics. As far as we know and as of right now, there hasn’t been much interest in supporting a fusion-based system that critically reviews machine learning techniques using grid search optimization, feature selection, and smote technique and examines how injury severity prediction is affected by road crashes.},
  archive      = {J_AAI},
  author       = {Soukaina EL Ferouali and Zouhair Elamrani Abou Elassad and Sara Qassimi and Abdelmounaîm Abdali},
  doi          = {10.1080/08839514.2025.2452675},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2452675},
  shortjournal = {Appl. Artif. Intell.},
  title        = {From baseline to best practice: An advanced feature selection, feature resampling and grid search techniques to improve injury severity prediction},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalised affective classification through enhanced EEG signal analysis. <em>AAI</em>, <em>39</em>(1), Article: 2450568. (<a href='https://doi.org/10.1080/08839514.2025.2450568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AAI},
  author       = {Joseph Barrowclough and Nonso Nnamoko and Ioannis Korkontzelos},
  doi          = {10.1080/08839514.2025.2450568},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2450568},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Personalised affective classification through enhanced EEG signal analysis},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Encrypted search method for cloud computing data under attack based on TF-IDF and apriori algorithm. <em>AAI</em>, <em>39</em>(1), Article: 2449303. (<a href='https://doi.org/10.1080/08839514.2024.2449303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper designs the MKSE and SEMSS methods. Among them, MKSE uses an improved TF-IDF weight calculation method to extract keywords and applies virtual keywords to construct inverted indexes, making it difficult for malicious attackers to infer the index content easily. SEMSS uses the Apriori algorithm to mine the co-occurrence relationship between words and find the keyword set that meets the minimum support threshold to improve the recall rate of search results. Finally, the security of the scheme is verified from the aspects of semantic security, effici this paper designsency, data integrity, etc. The results showed that the data encryption time of MKSE and TRSE methods increased gradually with the increase in document collection storage. The index build time was increased as the document set grew. The accuracy of the improved TF-IDF method was 63.8%. The running time of Apriori decreased with the increase of minimum support. When the minimum support was 12.0%, the Apriori algorithm ran for 211 seconds. The MKSE method was more efficient than the TRSE method in searching documents by query keywords. When the document set size was 3000, the SEMSS method had a full search rate of 81.09%. This research realizes the semantic security of outsourced data, which can efficiently and comprehensively carry out cryptographic retrieval based on keyword sorting.},
  archive      = {J_AAI},
  author       = {Demei Mao and Mingzhu Wang},
  doi          = {10.1080/08839514.2024.2449303},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2449303},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Encrypted search method for cloud computing data under attack based on TF-IDF and apriori algorithm},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discrete wavelet transform sampling for image super resolution. <em>AAI</em>, <em>39</em>(1), Article: 2449296. (<a href='https://doi.org/10.1080/08839514.2024.2449296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In battlefield environments, drones depend on high-resolution imagery for critical tasks such as target identification and situational awareness. However, acquiring clear images of distant targets presents a significant challenge. To address this, we propose a supervised learning approach for image super-resolution. Our network architecture builds upon the U-Net framework, incorporating enhancements to the encoder and decoder through techniques such as Discrete Wavelet Transform, Channel Attention Residual Modules, Selective Kernel Feature Fusion, Weight Normalization, and Dropout. We evaluate our model on a super-resolution dataset and compare its performance against other networks, highlighting the importance of minimizing trainable parameters for real-time deployment on resource-constrained drone platforms. The effWicacy of our proposed network is further validated through image recognition tasks and real-world scenario testing. By enhancing image clarity at extended ranges, our approach enables drones to detect adversaries earlier, facilitating proactive countermeasures and improving mission success rates},
  archive      = {J_AAI},
  author       = {Chieh-Li Chen and Heng-Lin Yao and Bo-Lin Jian},
  doi          = {10.1080/08839514.2024.2449296},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2449296},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Discrete wavelet transform sampling for image super resolution},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A blockchain-integrated federated learning approach for secure data sharing and privacy protection in multi-device communication. <em>AAI</em>, <em>39</em>(1), Article: 2442770. (<a href='https://doi.org/10.1080/08839514.2024.2442770'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The secure transmission of communication data between different devices still faces numerous potential challenges, such as data tampering, data integrity, network attacks, and the risks of information leakage or forgery. This approach aims to handle the distributed trust issues of federated learning users and update data states rapidly. By modeling multi-source devices through federated learning, the model parameters and reputation values of participating devices are stored on the blockchain. This method incorporates factors such as experience, familiarity, and timeliness to more quickly gather reliable information about nodes to assess their behavior. Simulation results on the MNIST dataset show that when the proportion of selfish nodes is below 50%, the convergence time increases with the proportion of selfish nodes. Compared to advanced algorithms, the proposed model saves approximately 6% of interaction time. As the number of transactions significantly increases, the system’s TPS (Transactions Per Second) decreases, with an average TPS of only 3079.35 when the maximum number of transactions is 4000. The proposed scheme can filter out high-quality data sources during real-time dynamic data exchange, enhancing the accuracy of federated learning training and ensuring privacy security.},
  archive      = {J_AAI},
  author       = {Kejun Li},
  doi          = {10.1080/08839514.2024.2442770},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2442770},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A blockchain-integrated federated learning approach for secure data sharing and privacy protection in multi-device communication},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fractal neural network approach for analyzing satellite images. <em>AAI</em>, <em>39</em>(1), Article: 2440839. (<a href='https://doi.org/10.1080/08839514.2024.2440839'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Satellites play a critical role in modern technology by providing images for various applications, such as detecting infrastructure and assessing environmental impacts. The author’s work investigates the application of Fractal Neural Networks (FractalNet) for automating the detection of specific objects in satellite images. The study aims to improve processing speed and accuracy compared to traditional Convolutional Neural Networks (CNNs). The research involves developing and comparing FractalNet with CNNs, focusing on their effectiveness in image classification. The architecture of FractalNet, characterized by recursive structures and deep layers, is evaluated against CNNs like VGG16 and ResNet50. Data collection included manually gathering high-resolution satellite images of specific objects from Google Earth. The neural network models were trained and tested with varying hyperparameters, including learning rates and batch sizes. FractalNet demonstrated superior performance over CNNs, particularly in deep network configurations. The results improved significantly with data augmentation and optimized hyperparameters, achieving a test accuracy of up to 93.26% with a 32-layer model. Fractal neural networks offer a promising approach for automating satellite image analysis, providing better accuracy and robustness compared to traditional CNNs architectures.},
  archive      = {J_AAI},
  author       = {Volodymyr Shymanskyi and Oleh Ratinskiy and Nataliya Shakhovska},
  doi          = {10.1080/08839514.2024.2440839},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2440839},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Fractal neural network approach for analyzing satellite images},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image segmentation deep learning model for early detection of banana diseases. <em>AAI</em>, <em>39</em>(1), Article: 2440837. (<a href='https://doi.org/10.1080/08839514.2024.2440837'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bananas are among the most widely produced perennial fruits and staple food crops that are highly affected by numerous diseases. When not managed early, Fusarium Wilt and Black Sigatoka are two of the most detrimental banana diseases in East Africa, resulting in production losses of 30% to 100%. Early detection of these banana diseases is necessary for designing proper management practices to avoid further yields and financial losses. The recent advances and successes of deep learning in detecting plant diseases have inspired this study. This study assessed a U-Net semantic segmentation deep learning model for the early detection and segmentation of Fusarium Wilt and Black Sigatoka banana diseases. This model was trained using 18,240 banana leaf and stalk images affected by these two banana diseases. The dataset was collected from the farms using mobile phone cameras with the guidance of agricultural experts and was annotated to label the images. The results showed that the U-Net model achieved a Dice Coefficient of 96.45% and an Intersection over Union (IoU) of 93.23%. The model accurately segmented areas where the banana leaves and stalks were damaged by Fusarium Wilt and Black Sigatoka diseases.},
  archive      = {J_AAI},
  author       = {Christian A. Elinisa and Ciira Wa Maina and Anthony Vodacek and Neema Mduma},
  doi          = {10.1080/08839514.2024.2440837},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2440837},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Image segmentation deep learning model for early detection of banana diseases},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application of immunological and swarm intelligence learning-based algorithm for industrial grade computer sales prediction. <em>AAI</em>, <em>39</em>(1), Article: 2440836. (<a href='https://doi.org/10.1080/08839514.2024.2440836'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper strives to raise the imitating effectiveness of radial basis function-based neural network (RNNet) through biological learning (BL) and swarm intelligence (SI) optimization algorithms. Latter, the artificial immune system (AIS) and particle swarm optimization (PSO) algorithms are utilized for RNNet to regulate. The proposed synthesis of AIS-inspired and PSO-inspired (SAIPS) algorithm incorporates the complementary development and prospecting abilities to realize optimized resolution. The attribute of population variation has shown high frequency to meet the global optimum to replace local optimum being restricted and outperforms in five standard nonlinear trial functions. The experimental results have represented that the consolidation of AIS-inspired and PSO-inspired algorithms is an outstanding approach and therefore a hybrid algorithm is proposed, which aims to obtain an expression that can cultivate optimum precision among related algorithms in this research. The algorithm then evaluates results from five standard inspections and an empirical industrial grade computer (IgC) sales prediction instance in Taiwan, which reveals that the proposed SAIPS algorithm exceeds the performance among related algorithms as well as the relevant auto-regressive integrated moving average (ARIMA) models in terms of accuracy and time spent.},
  archive      = {J_AAI},
  author       = {Zhen-Yao Chen},
  doi          = {10.1080/08839514.2024.2440836},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2440836},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Application of immunological and swarm intelligence learning-based algorithm for industrial grade computer sales prediction},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). System logs anomaly detection. are we on the right path?. <em>AAI</em>, <em>39</em>(1), Article: 2440692. (<a href='https://doi.org/10.1080/08839514.2024.2440692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {System logs are universally used for monitoring user access, performance, and behavior in software applications. Large-scale industrial systems generate an immense volume of logs, which are difficult to handle with human capabilities. Therefore, an automated method is essential for filtering vast amounts of data. System log anomaly detection is crucial in the security field for identifying system failures, sophisticated internal attacks, and other deviations from the norm. This research area requires further development, as most Deep Learning solutions in the literature are semi-supervised. This poses a significant limitation since these solutions are impractical for large-scale ecosystems due to the high cost of labeling data. This paper introduces a method that replaces the supervised phase of semi-supervised methods with fully unsupervised heuristics, utilizing the elbow method, interquartile range, and Simulated Annealing. The unsupervised results are comparable to the semi-supervised State of the Art while demonstrating greater applicability in real-world applications. This work proposes a more suitable benchmark for the log anomaly outlier detection problem, where the training data include both normal and abnormal sequences and precede the test sessions in time. Additionally, it presents metrics on distinct log sequences to mitigate the impact of unbalanced anomaly types.},
  archive      = {J_AAI},
  author       = {Ramona-Georgiana Albert},
  doi          = {10.1080/08839514.2024.2440692},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2440692},
  shortjournal = {Appl. Artif. Intell.},
  title        = {System logs anomaly detection. are we on the right path?},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating LLMs for code generation in HRI: A comparative study of ChatGPT, gemini, and claude. <em>AAI</em>, <em>39</em>(1), Article: 2439610. (<a href='https://doi.org/10.1080/08839514.2024.2439610'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the effectiveness of Large Language Models (LLMs) in generating code for Human-Robot Interaction (HRI) applications. We present the first direct comparison of ChatGPT 3.5, Gemini 1.5 Pro, and Claude 3.5 Sonnet in the specific context of generating code for Human-Robot Interaction applications. Through a series of 20 carefully designed prompts, ranging from simple movement commands to complex object manipulation scenarios, we evaluate the models’ ability to generate accurate and context-aware code. Our findings reveal significant variations in performance, with Claude 3.5 Sonnet achieving a 95% success rate, Gemini 1.5 Pro at 60%, and ChatGPT 3.5 at 20%. The study highlights the rapid advancement in LLM capabilities for specialized programming tasks while also identifying persistent challenges in spatial reasoning and adherence to specific constraints. These results suggest promising applications for LLMs in robotics development and education while emphasizing the continued need for human oversight and specialized training in AI-assisted programming for HRI.},
  archive      = {J_AAI},
  author       = {Andrei Sobo and Awes Mubarak and Almas Baimagambetov and Nikolaos Polatidis},
  doi          = {10.1080/08839514.2024.2439610},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2439610},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Evaluating LLMs for code generation in HRI: A comparative study of ChatGPT, gemini, and claude},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Friend link prediction method based on heterogeneous multigraph and hierarchical attention. <em>AAI</em>, <em>39</em>(1), Article: 2427545. (<a href='https://doi.org/10.1080/08839514.2024.2427545'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of location-based social network (LBSN), rich data comprising social behaviors and location information among users has emerged. Predicting potential friendships accurately from abundant information has become a pivotal research area. While graph neural network (GNN) have shown significant promise in prediction, existing approaches often fail to fully exploit the heterogeneous data characteristics in LBSN. Key challenges include inadequate modeling of the intricate relationships between users and points of interest (POI), overlooking the significance of spatial-temporal information in user trajectories, and underutilizing rich edge features. To address these challenges, we design a novel GRU-enhanced Heterogeneous Multigraph Attention Network (GEHMAN), which is a GNN model enhanced by GRU. We construct a heterogeneous multigraph to comprehensively capture user-POI relationships. We then employ a skip-gram model to embed POI nodes from user sub-trajectories and use RNN with GRU units to embed user nodes. GEHMAN utilize hierarchical attention mechanism to consolidate node information by aggregating diverse types of neighboring nodes and connecting edges. Experiments on six real city datasets show that compared with the best performance of six benchmark methods including LBSN2vec++, Metapath2vec and HAN, the average improvement percentages of GEHMAN in AUC, AP, and Top@K are 2.225%, 1.948%, and 6.353%, respectively.},
  archive      = {J_AAI},
  author       = {Aoxue Liu and Boyu Li and Yong Wang and Ziteng Yang},
  doi          = {10.1080/08839514.2024.2427545},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2427545},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Friend link prediction method based on heterogeneous multigraph and hierarchical attention},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="csci">CSCI - 35</h2>
<ul>
<li><details>
<summary>
(2025). Innovative synthetic EHR data generation: Diffusion models for enhanced privacy and clinical utility in multimorbidity clustering. <em>CSCI</em>, <em>37</em>(1), Article: 2565163. (<a href='https://doi.org/10.1080/09540091.2025.2565163'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing use of electronic health records (EHRs) in medical research and AI-driven healthcare necessitates high-fidelity synthetic data that balances patient privacy with statistical and clinical utility. Traditional generative models, such as generative adversarial networks (GANs) and variational autoencoders (VAEs), struggle with mode collapse, limited sample diversity, and difficulties in modelling complex dependencies in high-dimensional tabular data. This study introduces a diffusion model-based approach for generating synthetic EHR data and evaluates its utility in clustering multimorbidity patterns using Dirichlet process mixture models (DPMMs). Denoising diffusion probabilistic models (DDPMs) iteratively refine noise through a structured denoising process, producing diverse, high-fidelity synthetic records. The DPMM framework, a Bayesian nonparametric clustering method, dynamically determines the number of clusters, effectively handling heterogeneous, imbalanced datasets. Model evaluation incorporates statistical similarity measures, feature correlation analysis, privacy risk assessments, and predictive performance metrics. Results demonstrate that DDPM-generated data surpasses GANs and VAEs in fidelity (Jensen–Shannon divergence (JSD) = 0.020, Pearson pairwise correlation (PPC) = 0.94), and privacy preservation (membership inference attack (MIA) Risk = 0.25). DPMM clustering reveals clinically meaningful disease patterns, outperforming traditional clustering models. These findings highlight the potential of diffusion models for privacy-preserving synthetic EHR generation and robust multimorbidity clustering in healthcare analytics.},
  archive      = {J_CSCI},
  author       = {Francis John Kita and Gadde Srinivasa Rao and Peter Josephat Kirigiti},
  doi          = {10.1080/09540091.2025.2565163},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2565163},
  shortjournal = {Connect. Sci.},
  title        = {Innovative synthetic EHR data generation: Diffusion models for enhanced privacy and clinical utility in multimorbidity clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid CNN XGBoost intrusion detection approach tuned by modified sine cosine algorithm towards better cloud security. <em>CSCI</em>, <em>37</em>(1), Article: 2549581. (<a href='https://doi.org/10.1080/09540091.2025.2549581'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing (CC) delivers processing power and data storage on demand. It is one of the most significant computer science technologies, contributing to healthcare, industry, and the Internet of Things. One of CC's biggest security concerns are intrusion detection and separating harmful from legitimate communication, similar to computer networks. Although a wide range of intrusion detection systems is available today, they often suffer from misclassification issues, where the system can fail to recognize an attack as a threat or to mark normal traffic as malicious. This research proposes classifying network traffic using a convolutional neural network and extreme gradient boosting model. Additionally, a modified sine cosine algorithm is used to tune model hyperparameters for optimal performance. The presented framework was tested on major real-world TON IoT intrusion detection datasets. The proposed optimizer is compared to many recent metaheuristics in a matched experimental setting. The simulation results show that the suggested technique is superior to other methods for both datasets, with the best-performing optimized models achieving an accuracy of 96.667 on Windows 10 and 98.6731 on Windows 7 simulation.},
  archive      = {J_CSCI},
  author       = {Nikola Savanovic and Aleksandra Bozovic and Milos Antonijevic and Goran Kvascev and Bosko Nikolic and K. Venkatachalam and Nebojsa Bacanin and Miodrag Zivkovic},
  doi          = {10.1080/09540091.2025.2549581},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2549581},
  shortjournal = {Connect. Sci.},
  title        = {Hybrid CNN XGBoost intrusion detection approach tuned by modified sine cosine algorithm towards better cloud security},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A homotopy-CNN framework for continuous deformation in low-light image enhancement. <em>CSCI</em>, <em>37</em>(1), Article: 2546911. (<a href='https://doi.org/10.1080/09540091.2025.2546911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a homotopy-guided image enhancement framework for Low-Light Image Enhancement (LLIE), where a low-light image is progressively transformed into a well-lit version using a parametric deformation model. The enhancement pipeline incorporates a convolutional neural network that predicts structure-aware filtering parameters, which are applied via a 12-directional convolution kernel fusion, followed by adaptive gamma, contrast, and saturation refinements. Instead of relying solely on reference-free or black-box learning, the model leverages perceptual quality metrics such as SSIM and PSNR during training to optimise enhancement along the homotopy path. Notably, we explore the modulation of brightness across the range b ∈ [ − 2.0 , 2.0 ] , observing that b ≤ 0 yields outputs closer to ground-truth references, while b ≥ 0 enhances perceptual vividness. Experiments on the LOL dataset show that the method produces superior visual quality and strong quantitative performance, all while remaining efficient on standard CPUs without the need for GPU acceleration.},
  archive      = {J_CSCI},
  author       = {S. Shivam Kumar Jha and N. Mohana},
  doi          = {10.1080/09540091.2025.2546911},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2546911},
  shortjournal = {Connect. Sci.},
  title        = {A homotopy-CNN framework for continuous deformation in low-light image enhancement},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-constraints active learning assisted deep-ensemble spatio-textural feature learning model for violence detection in surveillance dataset. <em>CSCI</em>, <em>37</em>(1), Article: 2544539. (<a href='https://doi.org/10.1080/09540091.2025.2544539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents Vi-mCALNET, a multi-constraint active learning-assisted deep-ensemble spatio-textural feature learning model for violence detection in surveillance videos. Unlike traditional approaches, Vi-mCALNET integrates active learning-driven frame selection with deep ensemble learning to enhance classification accuracy while reducing computational complexity. Traditional deep learning vision models for violent crime detection face limitations including inability to use contextual details, long-term dependency issues, gradient vanishing, and accuracy degradation. Vi-mCALNET addresses these challenges through a comprehensive approach. The model employs GLCM, ResNet101, and DenseNet121 for feature extraction, followed by a heterogeneous ensemble classifier comprising SVM, DT, k-NN, NB, and RF. Extracted features are fused into a composite feature vector, processed through PCA and z-score normalization to prevent local minima, convergence issues, and overfitting.The heterogeneous ensemble classifier uses maximum voting to classify videos as violent or non-violent. Vi-mCALNET achieved superior performance with 99.51% accuracy, 99.32% precision, 99.36% recall, and 0.994 F-measure on publicly available datasets.Ablation studies and statistical significance analysis confirmed Vi-mCALNET's robust performance with lower variance, making it suitable for real-time, scalable surveillance applications while reducing annotation costs and computational demands.},
  archive      = {J_CSCI},
  author       = {Duba Sriveni and Loganathan R},
  doi          = {10.1080/09540091.2025.2544539},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2544539},
  shortjournal = {Connect. Sci.},
  title        = {Multi-constraints active learning assisted deep-ensemble spatio-textural feature learning model for violence detection in surveillance dataset},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An experimental evaluation of deep learning-based models for acne severity classification in humans. <em>CSCI</em>, <em>37</em>(1), Article: 2533867. (<a href='https://doi.org/10.1080/09540091.2025.2533867'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the context of acne severity, this paper presents a novel comparison between three convolutional neural network models: SqueezeNet, CenterNet and VGG-16 for the evaluation of acne severity on a custom-annotated dataset through Hayashi Grading Criterion. Unlike previous works, which mainly focus on single-model performance, this paper systematically presents the classification abilities of these three distinct architectures. The models were compared against real labels by the predictions for every group of images used in training that have been graded 0 through 3 in terms of acne severity. According to the results, CenterNet has the highest accuracy of 79.45%, followed by VGG-16 with 78.08% and then SqueezeNet having 76.71%. These findings add to the literature on AI models in acne classification and suggest that CenterNet is the most accurate model which can be incorporated into clinical practice for the management of acne vulgaris. The ACNE04 dataset contains both local lesion number and global acne severity have been utilised to assess the effectiveness of acne classification of the listed deep learning models.},
  archive      = {J_CSCI},
  author       = {Ayesha Shaik and Jincy Jis Kanichai and Aleena Bosco Kurumthottam and Vidul Garg and Balasundaram Ananthakrishnan},
  doi          = {10.1080/09540091.2025.2533867},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2533867},
  shortjournal = {Connect. Sci.},
  title        = {An experimental evaluation of deep learning-based models for acne severity classification in humans},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel architecture for efficient pedestrian detection in autonomous vehicles. <em>CSCI</em>, <em>37</em>(1), Article: 2529261. (<a href='https://doi.org/10.1080/09540091.2025.2529261'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public safety and intelligent surveillance systems rely heavily on accurate pedestrian detection to ensure effective monitoring and response. However, real-world challenges such as complex backgrounds, occlusions, and small target sizes significantly impact detection performance. To address these issues, this study proposes YOLO-SPD, an optimised YOLOv8-based architecture specifically designed for pedestrian detection. The model enhances multi-scale feature fusion by integrating a Bi-directional Feature Pyramid Network (BiFPN) in the neck structure, reducing computational complexity while preserving fine-grained details. Additionally, the Coordinate Attention (CA) mechanism is embedded within the Spatial Pyramid Pooling Fast (SPPF) module to improve localisation by effectively capturing both local and global spatial dependencies. Furthermore, pedestrian-specific bounding box regression is refined using the Complete Intersection over Union (CIoU) loss function, ensuring precise localisation and better edge positioning. The proposed approach is evaluated on the Caltech Pedestrian and KITTI datasets. Extensive experiments demonstrate its effectiveness, achieving 97.85% precision on the KITTI dataset and 96.18% precision on the Caltech Pedestrian dataset. These results highlight the robustness and reliability of YOLO-SPD in detecting pedestrians across diverse environments, making it a promising solution for real-time autonomous driving and intelligent surveillance applications.},
  archive      = {J_CSCI},
  author       = {Wajdi Farhat and Olfa Ben Rhaiem and Hassene Faiedh and Chokri Souani},
  doi          = {10.1080/09540091.2025.2529261},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2529261},
  shortjournal = {Connect. Sci.},
  title        = {A novel architecture for efficient pedestrian detection in autonomous vehicles},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SMARDY: The CORE of zero-trust FAIR marketplace for research data. <em>CSCI</em>, <em>37</em>(1), Article: 2523965. (<a href='https://doi.org/10.1080/09540091.2025.2523965'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supporting discovery through good and open management of existing datasets is the core of progress in data-rich research environments. Open Data and FAIR (Findable, Accessible, Interoperable, and Reusable) principles drive the exploitation of current results to a better and more trustworthy scientific era, but the wide adoption in Science is hindered by concerns regarding the proper handling of sensitive or extra-valuable copyrighted datasets. We present Smardy, our proposal for extending Open Data Repositories for research datasets with components meant to protect data sovereignty and trust in transfer. Our implementation of a cross-platform is the core of a FAIR Dataset Marketplace, which allows the authors to trade their datasets with the unconditional security of a Zero-Trust environment, and helps them to protect their IP over data using undisputable, Blockchain-based proofs of their authorship. The depicted aspects include application-code design, functional schemes, fingerprinting, and encryption steps for properly handling datasets and generating authorship proofs.},
  archive      = {J_CSCI},
  author       = {Cosmin-Andrei Ioniţe and Ion-Dorinel Filip and Alba González–Cebrián and Ciprian Dobre},
  doi          = {10.1080/09540091.2025.2523965},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2523965},
  shortjournal = {Connect. Sci.},
  title        = {SMARDY: The CORE of zero-trust FAIR marketplace for research data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differential privacy in statistical queries for synthetic trajectories generated by generative adversarial networks. <em>CSCI</em>, <em>37</em>(1), Article: 2523964. (<a href='https://doi.org/10.1080/09540091.2025.2523964'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread adoption of smartphones and the rapid advancement of information and communication technologies, the use of Location-Based Services (LBS) has significantly increased across various domains. Consequently, the collection and utilisation of user trajectory data are also growing rapidly. While such data can provide valuable insights for personalised services and other analyses, it inherently contains sensitive location information, posing serious privacy risks if used without proper anonymization. Previous studies have attempted to mitigate privacy concerns by applying Differential Privacy (DP) to prefix tree structures for statistical analysis. However, these approaches often suffer from diminished data utility due to the excessive noise required by DP mechanisms. To address this issue, we propose a two-stage trajectory privacy framework. In the first stage, we employ a Category Auxiliary Classifier-Generative Adversarial Network (CAC-GAN) to generate synthetic trajectory data that preserves the statistical characteristics of the original data, thereby providing primary privacy protection. In the second stage, we apply a prefix tree-based DP algorithm to the synthetic data, offering enhanced privacy during statistical analysis and query processing. Experimental results demonstrate that the proposed CAC-GAN method achieves approximately 53% improvement in both data utility and anonymity compared to existing methods. Furthermore, relative error analysis across various ϵ values confirms that our two-stage protection scheme maintains superior statistical accuracy. This study presents a novel methodology that effectively balances trajectory data privacy and utility.},
  archive      = {J_CSCI},
  author       = {Jihwan Shin and Yeji Song and Minsoo Jang and Jinhyun Ahn and Taewhi Lee and Dong-Hyuk Im},
  doi          = {10.1080/09540091.2025.2523964},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2523964},
  shortjournal = {Connect. Sci.},
  title        = {Differential privacy in statistical queries for synthetic trajectories generated by generative adversarial networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ReinforceAdapt: Multi-objective approach for environmental adaptation method. <em>CSCI</em>, <em>37</em>(1), Article: 2523960. (<a href='https://doi.org/10.1080/09540091.2025.2523960'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective optimization (MOO) underpins numerous real-world applications requiring the simultaneous optimization of conflicting objectives. Evolutionary Algorithms (EAs), particularly Multi-Objective Evolutionary Algorithms (MOEAs), have demonstrated exceptional capabilities in approximating Pareto-optimal solutions. However, their reliance on static operator configurations often results in suboptimal performance in dynamic and high-dimensional search spaces. To address this limitation, we propose a novel framework that integrates Deep Reinforcement Learning (DRL) with MOEAs, enabling adaptive and context-aware operator selection. Our methodology formulates operators as actions and solution states within a reinforcement learning paradigm. By leveraging Q -learning, the framework dynamically evaluates and selects operators that balances exploration and exploitation to optimise convergence and diversity. The implementation incorporates modular optimization, adaptive credit assignment, and decomposition-based subproblem partitioning which ensures scalability across diverse problem domains. Experimental evaluations on benchmark suites reveal that the proposed DRL-MOEA framework achieves superior performance, significantly improving Inverted Generational Distance (IGD) metrics while enhancing Pareto front diversity compared to state-of-the-art approaches. The results shows the framework's robustness and adaptability, establishing it as a powerful tool for addressing the challenges of multi-objective optimization in complex and dynamic environments.},
  archive      = {J_CSCI},
  author       = {Ravi Prakash and Brajesh Kumar Umrao and Ranvijay},
  doi          = {10.1080/09540091.2025.2523960},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2523960},
  shortjournal = {Connect. Sci.},
  title        = {ReinforceAdapt: Multi-objective approach for environmental adaptation method},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detection and classification of enhanced periapical lesion images with YOLO algorithms. <em>CSCI</em>, <em>37</em>(1), Article: 2522706. (<a href='https://doi.org/10.1080/09540091.2025.2522706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, artificial intelligence has become a reliable technology in clinical decision support systems with the solutions it offers in the dental field. This success also indicates a significant potential in detecting five different types of lesions on the tooth root through radiographic images. Because the periapical X-ray-taking process may vary depending on the individual's physical, psychological, and mental conditions. Also, environmental parameters may negatively affect the image acquisition process. It is possible to tolerate these disadvantageous situations with artificial intelligence-based algorithms and image processing approaches. In this study, it was planned to in-depth analysis of the periapical lesion data types in the original dataset called Periapical X-rays provided from the Kaggle public database. For this, the original adaptive image processing approach developed by integrating the ABC optimisation algorithm was applied to the dataset for five different lesion types. Then, the enhanced images enriched with the data augmentation approach were trained with YOLOv7, YOLOv8, YOLOv9 and YOLOv10 algorithms. As a result of the training, the enhanced images compared to the original images reached 96% F Criterion thanks to the network architecture of YOLOv8 algorithm. This shows that the YOLOv8 network architecture in enhanced lesion images is more successful.},
  archive      = {J_CSCI},
  author       = {Fatma Akalin and Tuğçenur Yildiz},
  doi          = {10.1080/09540091.2025.2522706},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2522706},
  shortjournal = {Connect. Sci.},
  title        = {Detection and classification of enhanced periapical lesion images with YOLO algorithms},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An NLP-driven e-learning platform with LLMs and graph databases for personalised guidance. <em>CSCI</em>, <em>37</em>(1), Article: 2518991. (<a href='https://doi.org/10.1080/09540091.2025.2518991'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information is ubiquitously available at our fingertips, transforming the way we learn, work and engage with the world around us. The challenge is not just accessing data but discerning its relevance and utility. This constant flow of information demands selective attention and strategic thinking about how we integrate new findings for professional growth. In this context, we propose an e-learning platform that recommends career paths based on user-uploaded PDFs. Our solution extracts keywords with Natural Language Processing (NLP). Using OpenAI, we enable interaction with the PDF files, allowing the user to ask questions and receive summaries. Then, we generate embeddings and index them with Facebook AI Similarity Search (FAISS). Next, we use a dataset of job listings and, with BERT, skills and technologies are extracted. An interconnected graph using a graph database system (Neo4j) based on these skills and technologies is built. Keywords from the uploaded documents are analyzed and matched to skills, leading to job recommendations or guidance on additional skills needed to secure employment. Mean Reciprocal Rank (MRR) is calculated to compare the results of different job recommendation systems.},
  archive      = {J_CSCI},
  author       = {Gabriela Dobriţa and Simona-Vasilica Oprea and Adela Bâra},
  doi          = {10.1080/09540091.2025.2518991},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2518991},
  shortjournal = {Connect. Sci.},
  title        = {An NLP-driven e-learning platform with LLMs and graph databases for personalised guidance},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSLWNet: A dual-stream lightweight deep learning network for the detection of epileptic seizures using EEG signals. <em>CSCI</em>, <em>37</em>(1), Article: 2518985. (<a href='https://doi.org/10.1080/09540091.2025.2518985'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is one of the most prevalent neurological disorders, and the accurate detection of epileptic seizures is challenging. Therefore, a dual-stream deep learning network is proposed in this research to extract the deep features by utilising the scalograms and time-series EEG signals. In this, first, the convolutional neural network (CNN) extracts the spatial dimensional features from the scalogram images, and then the squeeze and excitation (SE) technique enhances the relevant informative features by adjusting the channel weights. Correspondingly, the gated recurrent unit (GRU) extracts the temporal characteristics from the time-series EEG signal, and then for assigning more weights to the significant features the confined attention (CA) mechanism is included. Next, the extracted features are fused to form a deep feature set for the accurate detection of seizures using the support vector machine (SVM) classifier. Further, to improve the seizure detection rate, the regression at the end of variational mode extraction techniques (VME) is employed in the preprocessing stage. In addition, the performance of the proposed dual-stream lightweight seizure network (DSLWNet) is evaluated using the CHB-MIT and Bonn datasets. The experimental outcomes show the superiority of the proposed work in seizure detection by achieving an accuracy of 98.67% and 99.5%, respectively.},
  archive      = {J_CSCI},
  author       = {Bommala Silpa and Malaya Kumar Hota},
  doi          = {10.1080/09540091.2025.2518985},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2518985},
  shortjournal = {Connect. Sci.},
  title        = {DSLWNet: A dual-stream lightweight deep learning network for the detection of epileptic seizures using EEG signals},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LPIF-based image enhancement and hybrid ensemble models for brain tumor detection. <em>CSCI</em>, <em>37</em>(1), Article: 2518983. (<a href='https://doi.org/10.1080/09540091.2025.2518983'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumors represent one of the most critical neurological disorders where early and accurate diagnosis significantly impacts treatment outcomes. This paper presents a comprehensive deep learning framework for automated brain tumor classification using MRI scans, validated across both binary (DS1) and multi-class (DS2) datasets. Our approach introduces three key innovations: (1) a novel Local Pixel Inhomogeneity Factor (LPIF) based preprocessing pipeline that enhances tumor visibility while suppressing noise through adaptive local intensity processing, (2) AugmentFusion – a hybrid data augmentation strategy combining CLAHE with geometric transformations and noise injection to improve model generalisation, and (3) a hybrid ensemble model integrating DenseNet121 and VGG16 through majority voting, optimised using Adaptive Lookahead-AdamW with Cyclic Learning (ALACL). Extensive experiments demonstrate state-of-the-art performance, with our ensemble achieving 99.46% accuracy (AUC: 0.995, F1-score: 0.992) on the DS1 dataset (normal vs. tumor classification) and 98.63% accuracy (AUC: 0.986, F1-score: 0.99) on the more challenging DS2 dataset (multi-class tumor classification). These results significantly outperform existing approaches including transformer-based methods (98.6% accuracy) and 3D CNN architectures (98.4% accuracy). The framework maintains robust performance across all evaluation metrics while demonstrating computational efficiency suitable for clinical deployment. Our solution provides radiologists with a reliable decision support tool that combines high diagnostic accuracy with interpretability, potentially improving early detection and treatment planning for brain tumor patients.},
  archive      = {J_CSCI},
  author       = {Prabhat Kumar Sahu},
  doi          = {10.1080/09540091.2025.2518983},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2518983},
  shortjournal = {Connect. Sci.},
  title        = {LPIF-based image enhancement and hybrid ensemble models for brain tumor detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PSPNet EPO-SEB: A novel attention-enhanced hybrid model for accurate histopathological image segmentation. <em>CSCI</em>, <em>37</em>(1), Article: 2508357. (<a href='https://doi.org/10.1080/09540091.2025.2508357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise histopathological image segmentation is vital for accurate diagnosis and treatment planning. This manuscript proposes a hybrid framework, PSPNet EPO-SEB, combining PSPNet with an emperor penguin optimizer and an attention-enhanced module for improved segmentation performance. The model was rigorously evaluated on two prominent datasets, BACH and Camelyon17, encompassing high-resolution and whole-slide histopathological images, respectively. Experimental results demonstrate that PSPNet EPO-SEB outperforms conventional segmentation models, achieving dice coefficients (DC) of 0.9237 and 0.9186, and intersection over union (IoU) values of 0.8629 and 0.8622 on the BACH and Camelyon17 datasets, respectively. These metrics surpass those of competing models such as U-Net, V-Net, PA-Net, FANet18, Mask R-CNN, R2UNet, with PSPNet EPO-SEB showing enhanced boundary accuracy, True positive rates (TPR) above 0.93, and minimized false positive rates (FPR) at 0.1211 on BACH and 0.1108 on Camelyon17. Furthermore, the proposed model maintains low average error rates (AER) and achieves boundary precision with Hausdorff distances (HD) as low as 12.68 on BACH and 13.04 on Camelyon17, underscoring its accuracy in delineating complex tissue structures. Despite a slight increase in computational time due to optimization and attention mechanisms, the enhanced segmentation precision and boundary adherence make PSPNet EPO-SEB a highly effective solution for complex histopathological image analysis.},
  archive      = {J_CSCI},
  author       = {Prem Purusottam Jena and Debahuti Mishra and Kaberi Das and Sashikala Mishra and Mandakini Priyadarshani Behera},
  doi          = {10.1080/09540091.2025.2508357},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2508357},
  shortjournal = {Connect. Sci.},
  title        = {PSPNet EPO-SEB: A novel attention-enhanced hybrid model for accurate histopathological image segmentation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QIR: A novel quaternion-based image representation for reversible image steganography. <em>CSCI</em>, <em>37</em>(1), Article: 2507830. (<a href='https://doi.org/10.1080/09540091.2025.2507830'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image steganography involves concealing data within a digital image. Reversible steganography is considered as the complete restoration of the original image after the embedded secret data have been extracted. In this research work, a novel quaternion-based image representation technique is proposed for effective representation of images for processing it in quantum computational units. The proposed model is evaluated by implementing the representation of images for reversible image steganography where the images that are represented should be decrypted without loss. The images that were used in this study involve three different sizes 256 × 256 , 512 × 512 , 1024 × 1024 . Here the numerical results of the proposed work shows that the average PSNR value of the original image to the stego image is 44 dB and the average PSNR value to the original image and quantum decrypted image using quaternion function is 74 dB approximately which is 40% greater than the previous quantum representation and the SSIM and MSE values obtained are 95% similar to the previous works. The importance of our contribution is the stego image which is represented using 3-D quaternion rotation undergoes a decryption using LSB–MSB technique which then recovers the original secret and cover image with minimum loss. This shows that the stego image is not affected by the proposed quantum representation.},
  archive      = {J_CSCI},
  author       = {R. Deepika and Kalaipriyan Thirugnanasambandam and K. Muthunagai},
  doi          = {10.1080/09540091.2025.2507830},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2507830},
  shortjournal = {Connect. Sci.},
  title        = {QIR: A novel quaternion-based image representation for reversible image steganography},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparative linguistic analysis framework of human-written vs. machine-generated text. <em>CSCI</em>, <em>37</em>(1), Article: 2507183. (<a href='https://doi.org/10.1080/09540091.2025.2507183'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Writing content with the assistance of artificial intelligence has increased in popularity and influenced every domain, yet the challenge of understanding the differences between machine-generated and human-authored writing remains. To address this issue, our research aims to propose a detailed framework for deciphering the characteristics of machine-written language by identifying distinct linguistic features, analyzing stylistic differences, evaluating sentiment consistency, and validating the performance of selected generative models in replicating human writing across different types of writing. Using free resources from Hugging Face, we selected three models: GPT-Neo 1.3B, Qwen2.5-1.5B-Instruct, and BloomZ-560M, and employed them without fine-tuning in a Google Colab environment using a consistent prompt. These models were used to generate introductions for corresponding human-authored texts. We compared the extracted features of 2,121 texts, using visualisation methods such as histograms, boxplots and Q-Q plots, alongside the Shapiro–Wilk test and the non-parametric Kruskal – Wallis test and Dunn’s post-hoc test. Our findings highlight both the advancements of open-source text-generating models and the persistent gaps in replicating the depth and richness of human writing, providing and contributing to the knowledge about artificial intelligence and its progress in the generative field, supporting the validation of open-source text-generative models through statistical comparisons.},
  archive      = {J_CSCI},
  author       = {Lia Cornelia Culda and Raluca Andreea Nerişanu and Marian Pompiliu Cristescu and Dumitru Alexandru Mara and Adela Bâra and Simona-Vasilica Oprea},
  doi          = {10.1080/09540091.2025.2507183},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2507183},
  shortjournal = {Connect. Sci.},
  title        = {Comparative linguistic analysis framework of human-written vs. machine-generated text},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-stage deep learning based method for diabetic retinopathy classification. <em>CSCI</em>, <em>37</em>(1), Article: 2507182. (<a href='https://doi.org/10.1080/09540091.2025.2507182'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR) is a major cause of blindness, but current classification models suffer from low interpretability and difficulty in adjustment. To address these issues, a two-stage deep learning method for DR classification has been proposed, featuring lesion-sliced detection and DR classification stages. In the lesion-sliced detection stage, an improved neural process model extracts information from fundus images by fusing lesion details from various image locations, significantly enhancing accuracy. In the DR classification stage, an enhanced deep forest model was used to identify critical features influencing DR grades, boosting the credibility of the grading outcomes. Tests on the IDRiD and E-ophtha datasets demonstrated superior performance and generalisation ability of the lesion-sliced detection model compared to mainstream neural networks. Meanwhile, experiments on the Kaggle dataset confirmed that the deep forest-based DR classification model outperformed both traditional forest models and residual networks, marking its first application in DR classification. This approach achieves high accuracy and reliability, with improvements in both detection efficiency and generalisation.},
  archive      = {J_CSCI},
  author       = {Chen Zhang and Shaoqi Dong and Ziyun Song and Liming Liu and Jiaxu Ning and Bin Zhang and Changsheng Zhang},
  doi          = {10.1080/09540091.2025.2507182},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2507182},
  shortjournal = {Connect. Sci.},
  title        = {A two-stage deep learning based method for diabetic retinopathy classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EXING-IoT conceptual framework for explainability integration in next generation-IoT. <em>CSCI</em>, <em>37</em>(1), Article: 2507180. (<a href='https://doi.org/10.1080/09540091.2025.2507180'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) paradigm is evolving and the Next-Generation IoT (NG-IoT) ecosystem will incorporate distributed ledger and blockchain technology, AI-adapted components, and intelligent edge solutions that take advantage of edge computing, Artificial Intelligence (AI), networks, and communications. In addition to the low integration of eXplainable Artificial Intelligence (XAI) in the IoT or NG-IoT contexts, the explainability of these systems is rarely evaluated. Due to these limitations, we thoroughly examined the current state of XAI integration with IoT services. We propose a new conceptual framework called eXING-IoT (eXplainability Integrated in the Next Generation IoT) for better NG-IoT systems' explainability integration and evaluation. This includes a list of qualities that future NG-IoT environments should have, thus paving the way for the advancement of NG-IoT beyond the state of the art.},
  archive      = {J_CSCI},
  author       = {Alexandra Vultureanu-Albişi and Costin Bădică and Mirjana Ivanović},
  doi          = {10.1080/09540091.2025.2507180},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2507180},
  shortjournal = {Connect. Sci.},
  title        = {EXING-IoT conceptual framework for explainability integration in next generation-IoT},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ensuring unbiasedness: Foundational insights into integrating GSTARIMA and DNN models for rainfall prediction. <em>CSCI</em>, <em>37</em>(1), Article: 2507179. (<a href='https://doi.org/10.1080/09540091.2025.2507179'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The GSTARIMA (Generalied Space–Time Autoregressive Integrated Moving Average) model is commonly used to analyse time series and spatial data with temporal and spatial dependencies. This paper focuses on estimating the autoregressive and moving average parameters of the GSTARIMA model using Maximum Likelihood Estimation (MLE). We theoretically demonstrate the unbiasedness of these estimates, proving that the expected values of the estimates match the true parameters. Empirical experiments further verify this property, both before and after applying Deep Neural Network (DNN) interventions to correct model errors. The results show that the parameter estimates remain unbiased, and error properties (zero mean and constant variance) are preserved even after DNN processing. This study highlights the robustness of MLE in providing unbiased estimates within the GSTARIMA framework, even when integrated with machine learning techniques.},
  archive      = {J_CSCI},
  author       = {Devi Munandar and Budi Nurani Ruchjana and Atje Setiawan Abdullah and Hilman Ferdinandus Pardede},
  doi          = {10.1080/09540091.2025.2507179},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2507179},
  shortjournal = {Connect. Sci.},
  title        = {Ensuring unbiasedness: Foundational insights into integrating GSTARIMA and DNN models for rainfall prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning computer vision system for estimating sheep age using teeth images. <em>CSCI</em>, <em>37</em>(1), Article: 2506456. (<a href='https://doi.org/10.1080/09540091.2025.2506456'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the use of deep learning neural networks and transfer learning to estimate the age of sheep from their dental images. This is an important aspect of agriculture for meat quality, animal welfare, breeding, and health management. Using cutting-edge techniques, MobileNet, ResNet50, and ResNet102, we compare two deep learning approaches: fine-tuning and feature extraction using the pre-trained version of these models as part of our investigation. We collected 540 images of sheep from nearby farms, concentrating on three age groups: young, middle-aged, and elderly, for the purpose of our study. With an interesting recognition accuracy of 96.9%, the experimental results demonstrate that ResNet102 is the best performer both when fine-tuned and when employing its deep features that are retrieved from its pre-trained version. These findings highlight how cutting-edge machine learning techniques have the potential to completely transform long-standing methods in the sheep sector and pave the way for developing a novel mobile application that improves economic outcomes and cultural conformity concerning sheep age recognition.},
  archive      = {J_CSCI},
  author       = {Ahmad B. Hassanat and Mohammad A. Al-Sarayreh and Ahmad S. Tarawneh and Mohammad A. Abbadi and Khalid Almohammadi and Mansoor Alghamdi and Maha Alamri and Abdulkareem Alzahrani and Ghada A. Altarawneh},
  doi          = {10.1080/09540091.2025.2506456},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2506456},
  shortjournal = {Connect. Sci.},
  title        = {Deep learning computer vision system for estimating sheep age using teeth images},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visual data security in healthcare and cloud applications using a novel 2D-HCFCM, polynomial chains and NLDSR. <em>CSCI</em>, <em>37</em>(1), Article: 2491340. (<a href='https://doi.org/10.1080/09540091.2025.2491340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past two decades, numerous encryption schemes leveraging chaotic systems have been developed to ensure data integrity in healthcare and cloud environments. In this paper, we first assess the performance of a two-dimensional Higher Complexity Folium Chaotic Map (2D-HCFCM) and then introduce a robust encryption algorithm for 8-bit and 24-bit images. The algorithm constructs polynomials of 0 ≤ d ≤ 7 with 2D-HCFCM, followed by polynomial chaining and 8-bit conditional logical operation ( CL O 8 bit ), driven by ζ ( υ ) = ( ⌊ csin ⁡ ( x 2 + y 2 ) ⌋ + x y ) mod 2 to introduce additional dynamic control. Furthermore, the Nested Layered with Diagonal Swapping and Relocation (NLDSR) technique introduces nonlinearity and resistance to chosen plaintext attacks. In summary, the algorithm offers an encryption key of 800 bits and demonstrates satisfactory security performance, with a χ 2 of 236.0598, an NBCR of 49.7%, and an NPCR value of 99.6389, with optimal computational efficiency. The security analysis confirms that the algorithm is effective in preserving the integrity of visual data.},
  archive      = {J_CSCI},
  author       = {Sajid Khan and Hao Peng and Abdul Haseeb and Sardar Usman},
  doi          = {10.1080/09540091.2025.2491340},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2491340},
  shortjournal = {Connect. Sci.},
  title        = {Visual data security in healthcare and cloud applications using a novel 2D-HCFCM, polynomial chains and NLDSR},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel classification of meditation techniques via optimised chi-squared 1D-CNN method based on complexity, continuity and connectivity features. <em>CSCI</em>, <em>37</em>(1), Article: 2467387. (<a href='https://doi.org/10.1080/09540091.2025.2467387'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intricate world of human–computer interaction deeply explores how people gain knowledge and blend technology into daily life. Electroencephalography (EEG) is one of several methods for measuring brain activity, it is non-invasive, portable, inexpensive and time-sensitive. Research shows a strong link between meditation and changes in EEG patterns, spanning various techniques. With machine learning playing a major role, EEG datasets have made comprehensive study possible. This paper investigates the efficacy of 1D-CNN (One-Dimensional Convolutional Neural Network) classification, using complexity, continuity and connectivity features. It remarkably outperforms and achieves 60% training accuracy, showcasing model robustness in meditation classification. This novel methodology enables to differentiates neural oscillations in type of meditator and control. Prior research used power spectrum density, entropy, and connectivity for meditation distinctions. EEG data from practitioners of Himalayan Yoga (HYT), Isha Shoonya (SYN) and Vipassana (VIP) as well as untrained controls (CTR) are examined in this research. Employing chi-square, CNN and hyperparameter models, outcomes reveal distinctive cognitive aspects among meditation styles, allowing effective differentiation.},
  archive      = {J_CSCI},
  author       = {Abhishek Jain and Rohit Raja and Manoj Kumar and Pawan Kumar Verma},
  doi          = {10.1080/09540091.2025.2467387},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2467387},
  shortjournal = {Connect. Sci.},
  title        = {A novel classification of meditation techniques via optimised chi-squared 1D-CNN method based on complexity, continuity and connectivity features},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel CNN architecture for image restoration with implicit frequency selection. <em>CSCI</em>, <em>37</em>(1), Article: 2465448. (<a href='https://doi.org/10.1080/09540091.2025.2465448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration aims to recover clear images from degraded ones, with deep neural networks becoming the dominant approach. While earlier methods focused on spatial-domain information, recent models have explored frequency-domain data to improve performance. However, explicit frequency-domain processing introduces significant computational overhead. To address this, we propose the Implicit Frequency Selective Image Restoration Network (IFSR-Net), which implicitly captures frequency information without explicit transformations, achieving high performance with reduced computational cost. Our analysis indicates that the main spectral variations between the clear and degraded images are centred on the high-frequency components in the feature maps; the convolution operator tends to amplify the amplitude and variance of these components. Building on this observation, we designed an Implicit Frequency Selection Module (IFSM) to enrich high-frequency components and an Implicit Frequency Selection Attention (IFSA) mechanism to emphasize and integrate beneficial frequency features. We integrated and optimized design elements from existing image restoration models to further refine the overall architecture of IFSR-Net. Extensive experiments across seven datasets and three tasks demonstrate the effectiveness of our approach. Ablation studies confirm the validity of our design choices, offering insights for future research in image restoration.},
  archive      = {J_CSCI},
  author       = {Jiaxing Hu and Zhibo Wang},
  doi          = {10.1080/09540091.2025.2465448},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2465448},
  shortjournal = {Connect. Sci.},
  title        = {A novel CNN architecture for image restoration with implicit frequency selection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Password region attribute classification based on multi-granularity cascade fusion. <em>CSCI</em>, <em>37</em>(1), Article: 2461092. (<a href='https://doi.org/10.1080/09540091.2025.2461092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The composition of the password is markedly disparate contingent on the configuration strategy and the individual user's predilections. The objective of this paper is to mine the region attribute information behind the password text through text classification. In contrast to the traditional text classification approach, the classification of password region attribution represents a distinct challenge namely ultra-short text classification. The issue of password regional attribute classification is particularly tricky due to its inherent lexical polysemy, the scarcity of text features, the lack of context and the difficulty in explicitly identifying semantics. To address the aforementioned issues, we propose a multi-granularity cascade fusion approach for password region attribution classification. Firstly, the model employs series of segmentation techniques to split password into multi-dimensional fine-grained subword representations. Subsequently, multiple segmented representations of the same password are fed into a localised feature encoder to mine the private local features. Finally, a multi-level cascade fusion method is designed to integrate different granularity of password features into a unified representation to classification. Our approach can effectively addresses the limitations of scarce information and the challenge of integrating multiple representations for password text. Experiments on a large amount of real password data demonstrate that, our model can converge rapidly and achieve an accuracy of 88.18%, a precision of 88.31%, a recall of 87.73%, and an F1-score of 88.02%, significantly outperforming traditional models.},
  archive      = {J_CSCI},
  author       = {Wei Yu and Cheng Liu and Lvlin Ni and Yu Shi and Qingbing Ji},
  doi          = {10.1080/09540091.2025.2461092},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2461092},
  shortjournal = {Connect. Sci.},
  title        = {Password region attribute classification based on multi-granularity cascade fusion},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved data labelling method for news headlines classification in cloud environment. <em>CSCI</em>, <em>37</em>(1), Article: 2461088. (<a href='https://doi.org/10.1080/09540091.2025.2461088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In several domains, such as computer vision, natural language processing, and speech recognition, automatic data labelling is a critical task. Automatic data labelling is the process of utilising machine learning techniques to automatically label substantial amounts of data. Two largest news datasets like, the Kaggle dataset and the AG News dataset are used as benchmark for the performance analysis of the proposed algorithms. A novel four-dimensional matrix-based input representation that depicts the intra – and inter-word associations is used to obtain the feature vectors. Density-Based Spatial Clustering of Applications with Noise (DBSCAN) helps to remove the outliers which improves the overall accuracy of Convolutional Neural Networks (CNN). The proposed approach also reduces the dependency on human annotators. The DBSCAN algorithm is utilised o automatically cluster similar data points, thereby reducing the need for manual labelling. These clusters are then fed into a CNN with a rethinking mechanism, which allows the network to revise its initial predictions based on additional context. This integration of clustering and deep learning techniques aims to improve the accuracy and efficiency. The cloud computing method is used to achieve high-throughput news headlines classification in order to achieve accurate and efficient data labelling.},
  archive      = {J_CSCI},
  author       = {A. Sherly Alphonse and S. Abinaya and Nirvik Verma},
  doi          = {10.1080/09540091.2025.2461088},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2461088},
  shortjournal = {Connect. Sci.},
  title        = {Improved data labelling method for news headlines classification in cloud environment},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Software defect prediction using wrapper-based dynamic arithmetic optimization for feature selection. <em>CSCI</em>, <em>37</em>(1), Article: 2461080. (<a href='https://doi.org/10.1080/09540091.2025.2461080'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software Defect Prediction (SDP) empowers the creators to diagnose and unscramble defects in the introductory legs of the software evolution process to reduce the effort and cost invested in creating high-quality software. Feature Selection (FS) is critical to pinpoint the most pertinent features for defect prediction. This paper intends to employ a peculiar wrapper-based FS mode, dubbed DAOAFS, rooted on the dynamic arithmetic optimization algorithm (DAOA). Subsequently, this work evaluates the competence of the proposed FS mode using ten benchmark NASA datasets on four supervised learning classifiers, namely NB, DT, SVM, and KNN using accuracy and error curve as the standard performance measure metrics. This paper also correlates the proposed FS mode's conduct with existing FS techniques based on widely utilized meta-heuristic approaches such as GA, PSO, DE, ACO, FA, and SWO. This work employed Friedman and Holm test to ratify the proposed FS mode's statistical connotation. The investigatory outcomes supported the assertion that the recommended DAOAFS mode was effective in enhancing the efficacy of the defect forecasting model by achieving the highest mean accuracy of 94.76%. The findings also revealed that the proposed approach established its supremacy over the other studied FS techniques with bettered veracity in most instances.},
  archive      = {J_CSCI},
  author       = {Kunal Anand and Ajay Kumar Jena and Himansu Das and S. S. Askar and Mohamed Abouhawwash},
  doi          = {10.1080/09540091.2025.2461080},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2461080},
  shortjournal = {Connect. Sci.},
  title        = {Software defect prediction using wrapper-based dynamic arithmetic optimization for feature selection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative adversarial deep learning model for producing location-based synthetic trajectory data. <em>CSCI</em>, <em>37</em>(1), Article: 2458502. (<a href='https://doi.org/10.1080/09540091.2025.2458502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid expansion of location-based services has triggered the acquisition and analysis of various types of individual trajectory recordings. However, the sensitive nature of such kind of data inevitably leads to privacy constraints and regulations on its use and sharing. This paper addresses the problem in a distinctive perspective. Instead of blurring or modifying original trajectory samples, we aim to generate a completely synthetic dataset, whose samples are singularly different from the original ones, but whose collective sets share similar global characteristics and performances. We propose a generative deep learning solution for location-based trajectory formats, with the goal of producing realistic synthetic location sequences: the process relies on a generative adversarial network (GAN) framework, involving long short-term memory (LSTM) recurrent layers to capture trajectory characteristics, and neural embeddings to model mobility relations between places. We leverage multiple metrics to assess the realistic character of synthetic data and their similarity with the original source; moreover, we evaluate downstream performance differences with regard to the next place prediction problem. Tested on a real-world large-scale dataset of long-distance trips, and compared with baselines and traditional geomasking techniques, our approach presents better characteristics, providing novel insights into GeoAI solutions for human mobility analysis.},
  archive      = {J_CSCI},
  author       = {Alessandro Crivellari and Yuhui Shi},
  doi          = {10.1080/09540091.2025.2458502},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2458502},
  shortjournal = {Connect. Sci.},
  title        = {Generative adversarial deep learning model for producing location-based synthetic trajectory data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incremental learning based two-level multimodal data fusion model for alzheimer disease prediction on different data modalities. <em>CSCI</em>, <em>37</em>(1), Article: 2458501. (<a href='https://doi.org/10.1080/09540091.2025.2458501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer's disease (AD) is a complex neurodegenerative condition that affects millions of people worldwide, necessitating early and accurate diagnosis for optimal patient care. This study presents a novel Two-Level Multimodal Data Fusion Integrated Incremental Learner Ensemble Classifier (TMDFILE) for Alzheimer's detection. This method integrates temporal, spatial, spectral, audio, and text data modalities, utilising a gating mechanism to optimise the contribution of each modality. Incremental learning is employed to adjust evolving data patterns and, enhance long-term performance. The proposed TMDFILE was evaluated across five diverse datasets: achieving an accuracy of 94.5%, precision of 93.5%, recall of 95.1%, and F-measure of 94.1% on the ADNI dataset; an accuracy of 94.9%, with precision, recall, and F-measure values of 94.5%, 94.1%, and 94.3%, respectively, on the OASIS dataset; an accuracy of 93.5%, precision of 95.1%, and recall of 94.1% on the EEG Emotion Recognition dataset; an accuracy of 94.5%, precision of 93.5%, and recall of 95.1% on the Aberystwyth Dementia dataset, providing reliable classifications that contribute to early cognitive decline detection; and showed robust performance with an accuracy of 94.5%, precision of 93.5%, and recall of 95.1% on the BRATS dataset, relevant to brain imaging analysis for Alzheimer's detection. TMDFILE consistently outperformed traditional classifiers, including Support Vector Machines, Random Forest, and Convolutional Neural Networks, achieving an average precision of 93.5%, recall of 95.1%, F-measure of 94.1%, and accuracy of 94.5%. These findings underscore TMDFILE's effectiveness in diagnostic accuracy and reliability, establishing it as a promising tool for Alzheimer's disease detection across clinical and research applications.},
  archive      = {J_CSCI},
  author       = {M. Leela and K. Helenprabha},
  doi          = {10.1080/09540091.2025.2458501},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2458501},
  shortjournal = {Connect. Sci.},
  title        = {Incremental learning based two-level multimodal data fusion model for alzheimer disease prediction on different data modalities},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel deep learning model for stock market prediction using a sentiment analysis system from authoritative financial website’s data. <em>CSCI</em>, <em>37</em>(1), Article: 2455070. (<a href='https://doi.org/10.1080/09540091.2025.2455070'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of deep learning, specifically time series neural networks, in predicting stock market trends has emerged as a significant use case in financial analysis. However, the complex interrelationships and instability of the stock market have made the timely and accurate prediction of its behaviour as a confronting endeavour. To address this difficulty, in this research work a stock market index prediction model called SenT-In, which combines the with a sentiment awareness model. A sentiment awareness model using Convolutional Neural Networks (CNN) and Gated Recurrent Unit (GRU) is proposed to calculate the sentiment index of a large volume of news articles collected from reputable financial websites. In addition, a sentiment attention method is developed to combine stock data and news sentiment index as the input for training and predicting using the SenT-In network, which is both simple and efficient. The proposed model is evaluated in four different stock market datasets which include FSTE, SSE, Nifty 50 and S&P 500. On comparing the results with conventional deep learning algorithms such as GRU, LSTM, CNN and SVM, proposed SenT-In outperforms existing methods in accuracy with 9%, F1-Score with 7%, AUC-ROC curve with 13% and PR-AUC curve with 9% efficiency (on average).},
  archive      = {J_CSCI},
  author       = {Jitendra Kumar Chauhan and Tanveer Ahmed and Amit Sinha},
  doi          = {10.1080/09540091.2025.2455070},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2455070},
  shortjournal = {Connect. Sci.},
  title        = {A novel deep learning model for stock market prediction using a sentiment analysis system from authoritative financial website’s data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Classification of heart sound signals with whisper model. <em>CSCI</em>, <em>37</em>(1), Article: 2449943. (<a href='https://doi.org/10.1080/09540091.2025.2449943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart sounds, or phonocardiograms (PCG), are important for diagnosing cardiovascular conditions, providing a non-invasive means to assess heart function through auscultation. Accurate classification of PCG signals can facilitate early detection of cardiac abnormalities, significantly improving patient outcomes. However, the complexity and variability of heart sound recordings present significant challenges for traditional classification methods, necessitating advanced approaches that can effectively handle the nuances of cardiac acoustics. This paper introduces a novel transfer learning approach that adapts OpenAI's Whisper model, originally designed for robust speech recognition, to the task of heart sound classification. In particular, we employ Whisper's encoder architecture to effectively capture acoustic features that generalize to cardiac auscultation, making it a promising candidate for PCG analysis. To tailor the model for this specialized task, we implement a modified encoder architecture optimized for heart sound characteristics. We process the input to the model using a Log-Mel spectrogram pipeline specifically designed to highlight the unique acoustic properties of PCG signals. Experimental results demonstrate that the adapted Whisper model achieves state-of-the-art performance, surpassing existing methods in both accuracy and robustness.},
  archive      = {J_CSCI},
  author       = {Maryam Alotaibi and Yakoub Bazi and Mohamad Mahmoud Al Rahhal and Nassim Ammour and Mansour Zuair},
  doi          = {10.1080/09540091.2025.2449943},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2449943},
  shortjournal = {Connect. Sci.},
  title        = {Classification of heart sound signals with whisper model},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimising source code vulnerability detection using deep learning and deep graph network. <em>CSCI</em>, <em>37</em>(1), Article: 2447373. (<a href='https://doi.org/10.1080/09540091.2024.2447373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enhance the effectiveness of vulnerability detection in software developed using C and C++ programming languages, our study introduces a novel correlation calculation method for analyzing and evaluating Code Property Graphs (CPG). The intelligent computation method proposed in this study comprises three key stages. In the first stage, we present a method for extracting features from the CPG source code. To accomplish this, we integrate three distinct data exploration methods: employing Graph Convolutional Neural (GCN) to extract node features from CPG, utilizing Convolutional Neural Network (CNN) to extract edge features from CPG, and finally employing the Doc2vec natural language processing algorithm to extract source code from CPG nodes. The second stage involves proposing a method for synthesizing CPG source code features. Building on the features acquired in the first stage, our paper introduces a synthesis and construction method to generate feature vectors for the source code. The final stage, stage three, executes the detection of source code vulnerabilities. The experimental results demonstrate that our proposed model in this study achieves higher efficiency compared to other studies, with an improvement ranging from 3% to 4%.},
  archive      = {J_CSCI},
  author       = {Cho Do Xuan and Tran Thi Luong and Ma Cong Thanh},
  doi          = {10.1080/09540091.2024.2447373},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2447373},
  shortjournal = {Connect. Sci.},
  title        = {Optimising source code vulnerability detection using deep learning and deep graph network},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selecting hybrids of metaheuristics for resource-constraint project scheduling problems with discounted cashflows. <em>CSCI</em>, <em>37</em>(1), Article: 2447365. (<a href='https://doi.org/10.1080/09540091.2024.2447365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving resource-constrained project scheduling problems with discounted cash flows (RCPSP-DC) is a critical challenge for project and finance managers, as efficient resource allocation can significantly impact a company’s financial success. While prior research addresses this NP-hard problem, most approaches depend on hybrid metaheuristics requiring expertise in hybridisation and lack systematic methods for architecture selection, often relying on a single criterion with trial-and-error parameter tuning. In this paper, we propose a novel collaborative parallel hybridisation framework that integrates Thompson sampling and multicriteria decision analysis (MCDA) to holistically evaluate and identify the best hybrid architecture from a diverse set of options. Unlike conventional approaches, our method employs onboard Taguchi design of experiments (DOE) for structured and efficient parameter tuning. Additionally, Thompson sampling, applied in the form of Bayesian learning, mitigates the stochastic nature of metaheuristics through multiple experiments. This framework was used to select the best architecture from 57 hybrid combinations of six metaheuristics for solving RCPSP-DC. Extensive experiments using standard datasets demonstrate that the proposed framework achieves statistically significant performance improvements, selecting a hybrid architecture that outperforms state-of-the-art methods. The selected architecture’s competitiveness is validated through a Z-test of proportions, underscoring its effectiveness in solving RCPSP-DC problems.},
  archive      = {J_CSCI},
  author       = {Tshewang Phuntsho and Tad Gonsalves},
  doi          = {10.1080/09540091.2024.2447365},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2447365},
  shortjournal = {Connect. Sci.},
  title        = {Selecting hybrids of metaheuristics for resource-constraint project scheduling problems with discounted cashflows},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human body contour extraction method based on human skeleton key point guidance. <em>CSCI</em>, <em>37</em>(1), Article: 2445805. (<a href='https://doi.org/10.1080/09540091.2024.2445805'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By extracting human contours from 2D images captured by the camera and then obtaining human size data, the cost of garment custom measurement can be effectively reduced and the efficiency of custom measurement can be improved. The extraction of human contours plays an important role in the collection of online human size data. We propose a method to extract human contours by fusing the prior information of human skeleton key points into the salience target detection network. Specifically, the skeleton key point information extracted based on OpenPose is fused into the encoder-decoder network for rough detection of the human body target, and the residual refinement network is used to fine-adjust the human body matting, so as to achieve accurate human contour extraction. In this paper, the accuracy and superiority of the algorithm are verified in the public data set P3M-10K of human body matting and applied to the 2D body measurement WeChat applet on mobile phone and computer website.},
  archive      = {J_CSCI},
  author       = {Zhongwei Hua and Yong Ren and Yulu Wang and Zhuriyao Jin},
  doi          = {10.1080/09540091.2024.2445805},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2445805},
  shortjournal = {Connect. Sci.},
  title        = {Human body contour extraction method based on human skeleton key point guidance},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards enhanced assessment question classification: A study using machine learning, deep learning, and generative AI. <em>CSCI</em>, <em>37</em>(1), Article: 2445249. (<a href='https://doi.org/10.1080/09540091.2024.2445249'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to benchmark the performance of machine learning (ML), deep learning (DL), and generative AI (GenAI) models in categorising assessment questions based on Bloom’s Taxonomy. Previous studies have lacked comprehensive investigations into the performance of these approaches. Further, the GenAI remains unexplored, offering a promising avenue for groundbreaking explorations. Therefore, we explore the effectiveness of various ML models by incorporating domain-specific term weighting and utilising word embeddings. The study also analyses the performance of Recurrent Neural Networks (RNNs) and Convolutional Neural Network (CNN) with and without bidirectional connections, as well as an approach that combines RNNs and CNN. Furthermore, we evaluate several transformer-based models by fine-tuning them alongside GenAI models text-davinci-003, gpt-3.5-turbo, PaLM2, and Gemini Pro in zero-shot classification settings. The results demonstrate that ML models outperformed DL models, achieving a best accuracy of 0.871 and F1 score of 0.872. Additionally, domain-specific term weighting is found to be superior to word embeddings. Furthermore, most ML and DL models performed better than GenAI models, with GenAI models achieving a best accuracy of 0.618 and a best F1 score of 0.627. Therefore, the outcome suggests considering the ML models with domain-specific term weighting as benchmark models in future research.},
  archive      = {J_CSCI},
  author       = {Mohammed Osman Gani and Ramesh Kumar Ayyasamy and Saadat M. Alhashmi and Khondaker Sajid Alam and Anbuselvan Sangodiah and Khondaker Khaleduzzman and Chinnasamy Ponnusamy},
  doi          = {10.1080/09540091.2024.2445249},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2445249},
  shortjournal = {Connect. Sci.},
  title        = {Towards enhanced assessment question classification: A study using machine learning, deep learning, and generative AI},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating robustness dynamics of shallow machine learning techniques: Beyond basic natural variations in image classification. <em>CSCI</em>, <em>37</em>(1), Article: 2435654. (<a href='https://doi.org/10.1080/09540091.2024.2435654'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the widespread adoption of deep learning models, shallow machine learning (SML) algorithms are still used for image classification due to simplicity, interpretability and efficiency. This study aims to bridge this gap by investigating the robustness dynamics of SML techniques under more complex scenarios, such as adversarial perturbations and geometric transformation. Five popular classification algorithms, including k-nearest neighbour and support vector machines, were employed to build classification models. Methodology involves investigating the robustness of proposed  methods, first, on original and corrupted data by utilising benchmark datasets across several image domains. To strengthen the investigation, the models were trained using a new low-rank representation (LRR) strategy. This hybrid model simultaneously addresses two key limitations in classical LRR models: overcoming the sequential learning process and effectively capturing both local and global data structures. By introducing a dual regularisation mechanism, it integrates a k-nearest neighbour graph to preserve local consistency, while a global low-rank constraint ensures coherent data representation. Experimental results reveal significant drops in accuracy of most SML methods, especially under adversarial attacks and geometric transformations, but LRR approach mitigates these effects to a notable extent, boosting performance across data variations. The results also show that the proposed  method outperforms state-of-the-art LRR techniques in most experiments.},
  archive      = {J_CSCI},
  author       = {Mengtong Li},
  doi          = {10.1080/09540091.2024.2435654},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2435654},
  shortjournal = {Connect. Sci.},
  title        = {Investigating robustness dynamics of shallow machine learning techniques: Beyond basic natural variations in image classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="cybs">CYBS - 4</h2>
<ul>
<li><details>
<summary>
(2025). Deriving a multi-objective function using hybrid meta-heuristic approach for optimal CH selection and optimal routing in WSN. <em>CYBS</em>, <em>56</em>(7), 1085-1126. (<a href='https://doi.org/10.1080/01969722.2025.2468191'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to advent of sensors with less in weight, tiny in size and low power, it designates as Wireless Sensor Networks (WSNs). However in recent times, the key issue is noted in WSN is reducing the lifetime of the system. Hence in this paper, an advanced selection of Cluster Head (CH) and optimal routing is implemented by utilizing the improved heuristic algorithm. The developed Hybrid Walrus and Chameleon Swarm Algorithm (HWCSA) is performed by optimally select the CH and the multi-objective functions with constraints like residual energy, distance, and delay are derived in the CH selection approach. Moreover, the same HWCSA is used for performing the routing process to provide better communication between Base Station (BS) and sensor nodes. Here, multi-objective function with constraints like throughput, distance, packet delivery ratio, and hop count are optimally derived by optimizing the shortest path. In the end, the designed HWCSA approach is estimated with several performance metrics. Validating cost function analysis, the proposed model achieves 4%, 7.6%, 9.4%, and 8.5% better than BMO, OOA, WOA, and CSA algorithms. Throughout the empirical analysis, the designed model attains effective performance than state-of-the-art-methods.},
  archive      = {J_CYBS},
  author       = {M. Raghupathy and Chukka Rajasekhar},
  doi          = {10.1080/01969722.2025.2468191},
  journal      = {Cybernetics and Systems},
  month        = {10},
  number       = {7},
  pages        = {1085-1126},
  shortjournal = {Cybern. Sci.},
  title        = {Deriving a multi-objective function using hybrid meta-heuristic approach for optimal CH selection and optimal routing in WSN},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Failure mode and effects analysis method on the air system of an aircraft turbofan engine in multi-criteria open group decision-making environment. <em>CYBS</em>, <em>56</em>(7), 1053-1084. (<a href='https://doi.org/10.1080/01969722.2025.2468189'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failure mode and effects analysis (FMEA), an proactive risk management approach, has been widely applied in a variety of industries, especially in aircraft industry. In the process of implementation, the influence and uncertainty among different experts is inevitable. In order to handle the uncertainty in the assessments of FMEA experts, Dempster-Shafer evidence theory was introduced to FMEA for its flexibility and superiority in coping with uncertain and subjective assessments. However, traditional Dempster combination rule have difficulty in dealing with highly conflicting evidence that given from FMEA experts’ assessments. Moreover, experts themselves may influence each other though process such as chatting, judging, decision-making and voting. In this paper, we explore the problem of conflict evidence fusion from a correlation perspective among FMEA experts. We use ambiguity measure and Gaussian distribution to deal with the highly conflicting evidence. We use ambiguity measure to calculate the variance of Gaussian distribution. Then, we use Gaussian model to generalize expert assessments. After that, we use Dempster combination rule to fuze assessments from different experts. Finally, we calculate the risk priority number to rank the risk level of the FMEA items. The experiment results in the air system of an aircraft turbofan engine shows the efficiency and accuracy of the proposed method.},
  archive      = {J_CYBS},
  author       = {Yongchuan Tang and Zixi Fei and Lei Huang and Wenyi Zhang and Bingying Zhao and He Guan and Yubo Huang},
  doi          = {10.1080/01969722.2025.2468189},
  journal      = {Cybernetics and Systems},
  month        = {10},
  number       = {7},
  pages        = {1053-1084},
  shortjournal = {Cybern. Sci.},
  title        = {Failure mode and effects analysis method on the air system of an aircraft turbofan engine in multi-criteria open group decision-making environment},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heart disease detection and prognosis using IoT-based ECG sensor data with hybrid deep learning architecture and optimal resource allocation. <em>CYBS</em>, <em>56</em>(7), 1002-1052. (<a href='https://doi.org/10.1080/01969722.2025.2459959'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart disease remains a major global cause of mortality, underscoring the need for advancements in early detection and prognosis to enhance patient recovery. This study proposes an innovative framework integrating deep learning (DL) models and optimal resource allocation strategies to improve heart disease detection and prognosis. The framework begins with rigorous preprocessing of the Internet of Things (IoT) captured Electrocardiogram (ECG) data, employing min–max normalization, and advanced median filtering techniques for noise reduction and baseline wander correction. Statistical features are extracted from the preprocessed data, while features such Improved Empirical Mode Decomposition (EMD), RR interval, R peak, and PR interval are derived from ECG signals. These features are then augmented using a min–max technique to enhance dataset diversity and model robustness. Furthermore, the study introduces a hybrid model combining a Deep Residual Network (DRN) and an Improved Bidirectional Gated Recurrent Unit for severity classification heart disease detection, leveraging augmented features. Optimal resource allocation is facilitated by the Improved Walrus Optimization Algorithm (WaOA), optimizing ventilator, Intensive Care Unit (ICU) bed, medical staff, and medication allocation based on predicted disease severity. Evaluation with real-world datasets demonstrates superior diagnostic accuracy and resource utilization efficiency, highlighting the transformative potential of IoT and AI-driven approaches in cardiovascular healthcare.},
  archive      = {J_CYBS},
  author       = {Pranali P. Lokhande and Kotadi Chinnaiah},
  doi          = {10.1080/01969722.2025.2459959},
  journal      = {Cybernetics and Systems},
  month        = {10},
  number       = {7},
  pages        = {1002-1052},
  shortjournal = {Cybern. Sci.},
  title        = {Heart disease detection and prognosis using IoT-based ECG sensor data with hybrid deep learning architecture and optimal resource allocation},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of modified ECC-based secured FoG-assisted healthcare data management system in IoT-enabled WSN. <em>CYBS</em>, <em>56</em>(7), 971-1001. (<a href='https://doi.org/10.1080/01969722.2024.2343985'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) consists of a massive count of connected devices with different sensing support, particularly in medical health constraints sensing. In these summaries, secure communication and data collection to centralized servers is rather difficult for preventing the occurrence of diverse attacks for illegal data access. To tackle these problems, this task plans to design and implement the FoG-based secure data management system in IoT-WSN using adaptive encryption and decryption processes. As the FoG server is away from the corresponding aggregator node, it is transmitted via the other nodes using the proposed modified Elliptic Curve Cryptography (ECC)-based encryption process. For secured data transmission the designed method undergoes two main stages as message receiving stage, and the message-extraction stage. The hybridized meta-heuristic algorithm termed Jaya-Galactic Swarm Optimization (J-GSO) is used for modifying the ECC with an optimized key. From the simulation findings, the performance of the suggested scheme at the data size of three bytes is 3.08%, 3.22%, 3.65%, and 3.33% better than the MFO-m-ECC, PSO-m-ECC, GSO-m-ECC, and JA-m-ECC at the ECC curve variation of “secp192r1”. Experimental results reveal the superiority of the designed method when tested with baseline schemes regarding time complexity, space complexity, and cost function.},
  archive      = {J_CYBS},
  author       = {A. Tina Victoria and M. Kowsigan},
  doi          = {10.1080/01969722.2024.2343985},
  journal      = {Cybernetics and Systems},
  month        = {10},
  number       = {7},
  pages        = {971-1001},
  shortjournal = {Cybern. Sci.},
  title        = {Development of modified ECC-based secured FoG-assisted healthcare data management system in IoT-enabled WSN},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="engo">ENGO - 12</h2>
<ul>
<li><details>
<summary>
(2025). A novel reinforcement learning-based method for structure optimization. <em>ENGO</em>, <em>57</em>(9), 2629-2648. (<a href='https://doi.org/10.1080/0305215X.2024.2411412'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of deep learning technology, Reinforcement Learning (RL) has garnered considerable acclaim within the realm of structural optimization owing to its excellent exploration mechanism. However, the widespread application of RL in this field is limited owing to the excessive number of iterations required to converge and the expensive computational cost it brings. To address these challenges, this article presents a novel RL framework for structural optimization, combining Monte Carlo tree search with the proximal policy optimization method, called LMPOM. The key contributions of LMPOM encompass: (1) an enhanced Monte Carlo tree search strategy for partitioning the hybrid design space; (2) a strategy for adaptively updating surrogate models to reduce simulation costs; and (3) the introduction of a novel termination condition for the RL algorithms. Through tests on three benchmark problems, compared with previous RL algorithms, LMPOM consistently shows fewer iterations and better optimization results.},
  archive      = {J_ENGO},
  author       = {Zijian Mei and Zhouwang Yang and Jingrun Chen},
  doi          = {10.1080/0305215X.2024.2411412},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2629-2648},
  shortjournal = {Eng. Optim.},
  title        = {A novel reinforcement learning-based method for structure optimization},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A Q-learning multi-objective grey wolf optimizer for the distributed hybrid flowshop scheduling problem. <em>ENGO</em>, <em>57</em>(9), 2609-2628. (<a href='https://doi.org/10.1080/0305215X.2024.2410844'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing research focuses on a single objective for the distributed hybrid flowshop scheduling problem (DHFSP). This article focuses on a multi-objective DHFSP with sequence-dependent set-up time (DHFSP-SDST). A Q-learning multi-objective grey wolf optimizer (QMOGWO) is designed to optimize the makespan, total energy consumption and total tardiness. A mathematical model for DHFSP-SDST is established. Several initialization strategies and a random method are introduced to improve the quality of the initial population. The new individual is developed by the discrete solution updating mechanism of QMOGWO. Based on the Q-learning, local search strategies are designed to avoid local optima. To verify the performance of the proposed QMOGWO, different scales of instances are tested in various factories and at different stages, and the simulation results show that the QMOGWO outperforms the comparison methods.},
  archive      = {J_ENGO},
  author       = {Jianguo Zheng and Shuilin Chen},
  doi          = {10.1080/0305215X.2024.2410844},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2609-2628},
  shortjournal = {Eng. Optim.},
  title        = {A Q-learning multi-objective grey wolf optimizer for the distributed hybrid flowshop scheduling problem},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal box contraction for solving linear systems via simulated and quantum annealing. <em>ENGO</em>, <em>57</em>(9), 2597-2608. (<a href='https://doi.org/10.1080/0305215X.2024.2408686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving linear systems of equations is an important problem in engineering. Many quantum algorithms, such as the Harrow–Hassidim–Lloyd algorithm and the box algorithm, have been proposed for solving such systems. The focus of this article is on improving the efficiency of the box algorithm. The basic principle behind this algorithm is to transform the linear system into a series of quadratic unconstrained binary optimization (QUBO) problems, which are then solved on annealing machines. The computational efficiency of the box algorithm is entirely determined by the number of iterations, which, in turn, depends on the box contraction ratio, typically set to 0.5. Here, it is shown through theoretical analysis that a contraction ratio of 0.5 is sub-optimal and that a computational speed-up can be achieved with a contraction ratio of 0.2. This is confirmed through numerical experiments where a computational speed-up between 20 % to 60 % is observed when the optimal contraction ratio is used.},
  archive      = {J_ENGO},
  author       = {Sanjay Suresh and Krishnan Suresh},
  doi          = {10.1080/0305215X.2024.2408686},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2597-2608},
  shortjournal = {Eng. Optim.},
  title        = {Optimal box contraction for solving linear systems via simulated and quantum annealing},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Employing an optimal control strategy for systems with measurement and actuation faults: A swarm optimization approach. <em>ENGO</em>, <em>57</em>(9), 2560-2596. (<a href='https://doi.org/10.1080/0305215X.2024.2408491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various industries involve interconnected coupled tank systems to control fluid level, which poses significant challenge for traditional controllers. A tilt-integral-derivative controller offers enhanced adaptability for such systems. However, tuning of these controllers is highly challenging. This work focuses on enhancing the liquid level control in coupled tank systems using a tilt-integral-derivative controller. Tuning for the control algorithm is achieved through the application of Harris's hawks optimization. An objective function is designed by imposing constraints on performance metrics such as integral square error, integral absolute error, integral time absolute error, and closed-loop gain, which are then solved using Harris's hawks optimization. Further, the robust behaviour of the system is exhibited using μ -analysis to assess its stability. Simulation studies confirm the control algorithm's effectiveness, showing superior performance in reducing settling-time and minimizing overshoot. Additionally, the robustness of the controller in handling sensor and actuator faults under varying operating conditions is demonstrated.},
  archive      = {J_ENGO},
  author       = {Achu Govind K. R. and Subhasish Mahapatra and Atanu Panda},
  doi          = {10.1080/0305215X.2024.2408491},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2560-2596},
  shortjournal = {Eng. Optim.},
  title        = {Employing an optimal control strategy for systems with measurement and actuation faults: A swarm optimization approach},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization of a roller coaster bogie considering fatigue life. <em>ENGO</em>, <em>57</em>(9), 2529-2559. (<a href='https://doi.org/10.1080/0305215X.2024.2408479'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the effectiveness of fatigue-life constrained topology optimization in roller coaster engineering, a previously unexplored field. Emphasizing the importance of fatigue life considerations, the research focuses on key components of roller coasters: the wheel assemblies. By integrating stress–life fatigue constraints, such an approach can lead to longer lasting and more efficiently designed roller coaster components. Multiaxial fatigue topology optimization using the method of moving asymptotes gradient-based optimization is examined to address the complex loading experienced by these bogies given a substantial load-time history in the high-cycle fatigue region. Using a validated optimization methodology, this study aims to reduce the bogie volume in selected domains while ensuring structural integrity and potentially extending service life. The optimization process successfully reduces the number of designable elements, resulting in decreased global volume and mass, and the results quantifiably demonstrate the impact of applying high-cycle fatigue constraints on the bogie’s performance.},
  archive      = {J_ENGO},
  author       = {Dylan Eisen and Il Yong Kim},
  doi          = {10.1080/0305215X.2024.2408479},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2529-2559},
  shortjournal = {Eng. Optim.},
  title        = {Optimization of a roller coaster bogie considering fatigue life},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A sustainable network design for municipal solid waste management considering waste-to-energy conversion under uncertainty. <em>ENGO</em>, <em>57</em>(9), 2505-2528. (<a href='https://doi.org/10.1080/0305215X.2024.2408478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research proposes a sustainable municipal solid waste management (MSWM) system to address population growth, consumerism, and resource scarcity. It introduces a two-phase decision structure combining multi-attribute decision-making (MADM) tools. Phase one develops a hybrid risk-oriented fuzzy MADM tool for selecting optimal waste-to-energy technologies, considering environmental and technological factors. Phase two uses a fuzzy bi-objective multi-period mixed-integer linear programming model to design the MSWM supply chain efficiently under uncertainty. A case study in North Tehran demonstrates the framework’s practical applicability and effectiveness in real-world scenarios, highlighting that effective source separation boosts recycling, reduces costs, and provides social benefits. Sensitivity analyses offer insights to enhance waste segregation practices. The study emphasizes integrating economic, environmental, and social sustainability in waste management decision-making. By offering a novel, holistic approach, this research addresses existing gaps in systematic decision-making processes and provides a robust tool for municipalities to optimize strategies under uncertainty.},
  archive      = {J_ENGO},
  author       = {Pantea Saatchi and Farima Salamian and Neda Manavizadeh and Masoud Rabbani},
  doi          = {10.1080/0305215X.2024.2408478},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2505-2528},
  shortjournal = {Eng. Optim.},
  title        = {A sustainable network design for municipal solid waste management considering waste-to-energy conversion under uncertainty},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid simulated annealing–slime mould algorithm for the non-permutation flow-shop scheduling problem. <em>ENGO</em>, <em>57</em>(9), 2492-2504. (<a href='https://doi.org/10.1080/0305215X.2024.2408477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The non-permutation flow-shop scheduling problem (NPFSP) is a more general type of flow-shop scheduling problem than the permutation flow-shop scheduling problem (PFSP). It features a large solution space and is highly complex. In this study, a novel metaheuristic algorithm is proposed for the NPFSP, where makespan is the scheduling objective. The specific implementation process is as follows. First, a mathematical model of the NPFSP is constructed. Secondly, the encoding and decoding rules are designed to establish the association between the solutions for PFSP and NPFSP. Subsequently, a metaheuristic hybrid simulated annealing–slime mould algorithm is proposed. Finally, a series of control experiments is conducted based on the Demirkol benchmark. The statistical results show the effectiveness of the proposed algorithm in solving the NPFSP.},
  archive      = {J_ENGO},
  author       = {Anran Zhao and Peng Liu and Xiyu Gao and Denghang Ding and Guotai Huang},
  doi          = {10.1080/0305215X.2024.2408477},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2492-2504},
  shortjournal = {Eng. Optim.},
  title        = {Hybrid simulated annealing–slime mould algorithm for the non-permutation flow-shop scheduling problem},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bi-level optimization and integrated multiple-criteria decision making under uncertainty for structural design of insulated bearings. <em>ENGO</em>, <em>57</em>(9), 2467-2491. (<a href='https://doi.org/10.1080/0305215X.2024.2402467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the premature failure of insulated bearings, this article proposes a design method for the structure of bearings to prolong their service life. First, a bi-level optimization model is established to determine the structural parameters of bearings considering their insulating and mechanical properties. Upper-level problems include bearing voltage ratio, porosity of insulating coatings, minimum thickness of oil film and Hertz contact area. Lower-level problems include fatigue life of bearings and adhesion of insulating coatings. Second, a non-dominated sorting genetic algorithm-III based on space decomposition and penalty-based boundary intersection (NSGA-III-SD-PBI) is designed to solve the optimization model. Third, the integrated multiple-criteria decision-making (MCDM) using the fuzzy best–worst method (BWM) and fuzzy technique for order preference by similarity to an ideal solution (TOPSIS) is developed to determine the best structural parameters of bearings. A case study demonstrates the effectiveness and superiority of the proposed method, with fatigue life increased by 20%.},
  archive      = {J_ENGO},
  author       = {Ruosong Ji and Yixiong Feng and Zhaoxi Hong and Jiugen Wang and Junjie Song and Yong Wang and Xu Hao and Lianbin Gao and Jianrong Tan},
  doi          = {10.1080/0305215X.2024.2402467},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2467-2491},
  shortjournal = {Eng. Optim.},
  title        = {Bi-level optimization and integrated multiple-criteria decision making under uncertainty for structural design of insulated bearings},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An integrated optimization method for the damper placements, shape and size of truss structures. <em>ENGO</em>, <em>57</em>(9), 2446-2466. (<a href='https://doi.org/10.1080/0305215X.2024.2401557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work extends the application of the approximation concept in dynamic topology optimization for truss structures. The corresponding problem contains both continuous and discrete variables, encompassing damper placements, truss shape and cross-sectional area. First, the utilization of a branched multipoint approximation (BMA) function establishes sequential approximation problems that also involve such mixed variables, marking its innovative application in dynamic optimization. Then, a modified genetic algorithm (GA) is used to optimize discrete variables. To enhance convergence stationarity, the concept of ‘adjacent individuals’ is proposed to control the degree of difference in topology configuration between initial population members and the current optimal. Additionally, adjustments to the sequence-based crossover process ensure compliance with damper quantity constraints. Examples demonstrate that the introduction of adjacent individuals is beneficial to convergence stationarity, and the shape change of the truss increases the mode damping ratio by more than 20%. The created optimization platform can also tackle other mixed variables optimization problems.},
  archive      = {J_ENGO},
  author       = {Shuanjun Liu and Hai Huang and Shenyan Chen and Ziqi Dai and Weipeng Li},
  doi          = {10.1080/0305215X.2024.2401557},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2446-2466},
  shortjournal = {Eng. Optim.},
  title        = {An integrated optimization method for the damper placements, shape and size of truss structures},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differential evolution-based topology optimization using karhunen-loève expansion. <em>ENGO</em>, <em>57</em>(9), 2419-2445. (<a href='https://doi.org/10.1080/0305215X.2024.2400558'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topology optimization is a widely adopted structural optimization approach that aims to maximize desired performance based on mathematical and physical principles. Gradient-based methods are common for obtaining optimal configurations; however, they struggle with problems involving numerous local optima and non-differentiable problems, which prevent the derivation of design sensitivity. To address these issues, this study explores the application of the Success History-Based Differential Evolution with Linear Population Size Reduction and Semi-Parameter Adaptation, which is regarded as LSHADE-SPA algorithm, known for its strong search capabilities. Nevertheless, its computational cost makes it impractical for topology optimization, especially as the number of design variables increases. To overcome this challenge, a novel structure representation method utilizing the Karhunen-Loève (KL) expansion is constructed. Applying truncated KL expansion instead of conventional density methods to represent structural configurations reduces the number of design variables. This article introduces a differential evolution-based topology optimization method utilizing truncated KL expansion and validates its effectiveness through applications in various structural and fluid problems. The method is particularly suited to highly nonlinear problems, such as negative Poisson's ratio structures and micro-mixer designs. The findings here indicate that differential evolution with truncated KL expansion can serve as an efficient and robust topology optimization method, proving particularly effective for solving optimization problems that are challenging for conventional gradient-based approaches. Notably, the proposed methodology not only delivers superior results but also alleviates computational burdens, thereby advancing the prospects of topology optimization in various engineering applications.},
  archive      = {J_ENGO},
  author       = {Kozo Furuta and Yasutoshi Tsukuda and Takamitsu Sasaki and Naoyuki Ishida and Kazuhiro Izui and Shinji Nishiwaki and Shinya Watanabe},
  doi          = {10.1080/0305215X.2024.2400558},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2419-2445},
  shortjournal = {Eng. Optim.},
  title        = {Differential evolution-based topology optimization using karhunen-loève expansion},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective-derived efficient energy saving in multipath routing for mobile ad hoc networks with the modified aquila–firefly heuristic strategy. <em>ENGO</em>, <em>57</em>(9), 2383-2418. (<a href='https://doi.org/10.1080/0305215X.2024.2399656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile ad hoc networks (MANETs) suffer from a major problem with the energy drainage of network nodes, as the mobile nodes rely on batteries and do not have a permanent power supply. Therefore, a new multipath routing technique, using a novel hybrid heuristic algorithm, is designed to solve the diverse metrics of a multi-objective function, including energy consumption, distance, routing overhead ratio, throughput, end-to-end delay and packet delivery ratio. This approach implements a new hybrid algorithm termed the modified aquila–firefly heuristic strategy (MA-FHS), which integrates the aquila optimizer and the firefly algorithm. This derived fitness function is applied to achieve optimal paths in multipath routing with minimization of the multi-objective function. The simulation demonstrates that the developed routing protocols outperformed traditional protocols under several network constraints.},
  archive      = {J_ENGO},
  author       = {P. Satyanarayana and G. Diwakar and V. Priyanka Brahmaiah and S. Marlin and N. V. Phani Sai Kumar and S. Gopalakrishnan},
  doi          = {10.1080/0305215X.2024.2399656},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2383-2418},
  shortjournal = {Eng. Optim.},
  title        = {Multi-objective-derived efficient energy saving in multipath routing for mobile ad hoc networks with the modified aquila–firefly heuristic strategy},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal product pricing and lot sizing decisions for an omni-channel supply chain. <em>ENGO</em>, <em>57</em>(9), 2349-2382. (<a href='https://doi.org/10.1080/0305215X.2024.2399642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an omni-channel supply chain, companies offer customers multiple channels to interact with their brand. This allows for greater outreach and sales, resulting in increased customer loyalty and trust. Furthermore, there has been little discussion on the simultaneous consideration of strategic and tactical decisions under return policies in omni-channel supply chains. To maximize total profit, this research proposes a two-echelon supply chain, comprising a manufacturer and multiple retailers, including traditional, electronic and omni-channels. The non-deterministic demand function takes into account the sales price, refund price, delivery time and order quantities. A heuristic algorithm based on analysis of Karush–Kuhn–Tucker optimality conditions used to solve a nonlinear programming model. This research presents an analysis of the factors influencing the decision variables and profit of the entire supply chain and offers retailers a unique way to evaluate their performance and make operational decisions regarding price, delivery time and order quantities.},
  archive      = {J_ENGO},
  author       = {Ghazaleh Saboori and G. Reza Nasiri and Hossein Salehi},
  doi          = {10.1080/0305215X.2024.2399642},
  journal      = {Engineering Optimization},
  month        = {9},
  number       = {9},
  pages        = {2349-2382},
  shortjournal = {Eng. Optim.},
  title        = {Optimal product pricing and lot sizing decisions for an omni-channel supply chain},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijcon">IJCON - 20</h2>
<ul>
<li><details>
<summary>
(2025). Harmonics estimation of power signals in presence of non-gaussian and non-stationary noise. <em>IJCON</em>, <em>98</em>(10), 2516-2527. (<a href='https://doi.org/10.1080/00207179.2025.2464222'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel R-adaptive sigma point filter entitled variational Bayesian Gaussian sum cubature Kalman filter (VB-GSCKF) for joint estimation of harmonic amplitude, phase, and frequencies along with the noise parameters. Since Gaussian filters may not guarantee good estimates in real-time applications involving non-stationary and non-Gaussian noise, alternative techniques are required. The proposed algorithm contributes to this gap as it automatically tunes the noise covariance matrix using the variational Bayesian approach and its Gaussian sum framework effectively models the non-Gaussian noise. The proposed VB-GSCKF algorithm demonstrates its superiority over other competing adaptive Gaussian filters and new hybrid based estimation approach where the signal is first denoised using Deep Learning (DL) algorithms and then the estimation is done using GSCKF in the presence of non-Gaussian and non-stationary measurement noise. Finally, real harmonic data produced by a grid-connected inverter hardware configuration is used to demonstrate the effectiveness of the proposed VB-GSCKF.},
  archive      = {J_IJCON},
  author       = {Pravir Yadav and Jayanta Piri and Aparajita Sengupta and Mainak Sengupta},
  doi          = {10.1080/00207179.2025.2464222},
  journal      = {International Journal of Control},
  month        = {10},
  number       = {10},
  pages        = {2516-2527},
  shortjournal = {Int. J. Control},
  title        = {Harmonics estimation of power signals in presence of non-gaussian and non-stationary noise},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance recovery for a class of nonlinear systems by a parametric lyapunov equation based observer. <em>IJCON</em>, <em>98</em>(10), 2506-2515. (<a href='https://doi.org/10.1080/00207179.2025.2463573'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A parametric Lyapunov equation (PLE) based observer is designed to achieve semi-global output feedback stabilisation for lower-triangular nonlinear systems, even when the control input is discontinuous and any global growth conditions, such as the globally Lipschitz condition, are not imposed. Meanwhile, the output estimation error achieves perfect regulation and remains nonpeaking. The recovery of asymptotic stability, the region of attraction, and the plant state trajectory is captured by the developed observer. The designed observer serves as a neat and effective form of high-gain observers, inheriting nearly all their characteristics, such as the fast time-scale transformation and the separate design of observer and state feedback.},
  archive      = {J_IJCON},
  author       = {Shunli Li and Bin Zhou and Guangren Duan},
  doi          = {10.1080/00207179.2025.2463573},
  journal      = {International Journal of Control},
  month        = {10},
  number       = {10},
  pages        = {2506-2515},
  shortjournal = {Int. J. Control},
  title        = {Performance recovery for a class of nonlinear systems by a parametric lyapunov equation based observer},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assignment and distributed control of laplacian null space in multiagent systems. <em>IJCON</em>, <em>98</em>(10), 2491-2505. (<a href='https://doi.org/10.1080/00207179.2025.2463568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The benchmark consensus protocol is used by the most notable distributed algorithms for controlling multiagent systems through local interaction rules, where it yields to the well-known Laplacian matrix whose null space is fixed and is spanned by the vector of ones provided that the underlying graph is connected. Since this protocol is the key building block for a wide range of other existing distributed algorithms, its extensions are likewise based on this Laplacian matrix. However, the fixed nature of the null space of this Laplacian matrix limits the composition of complex (i.e. reconfigurable) cooperative behaviours for multiagent systems. Motivated by this standpoint, the contribution of this paper is threefold: (i) For undirected and connected graphs, we introduce a new Laplacian matrix, whose null space is spanned by a user-assigned vector composed of nonzero elements. We give its mathematical definition and show that it inherits key properties of the aforementioned well-known Laplacian matrix. (ii) We next present distributed control architectures for convergence to the desired null space as well as for convergence to a specific vector within that null space. (iii) We finally multiplex information networks to distributively control the null space of this new Laplacian matrix, where this is the most important contribution of this paper. We specifically show that the resulting null space can vary through local interaction rules as desired between the spans of two or more user-assigned vectors to pave the way for composing complex cooperative behaviours for multiagent systems.},
  archive      = {J_IJCON},
  author       = {Dzung Tran and Tansel Yucelen and Deniz Kurtoglu and S. Burak Sarsılmaz},
  doi          = {10.1080/00207179.2025.2463568},
  journal      = {International Journal of Control},
  month        = {10},
  number       = {10},
  pages        = {2491-2505},
  shortjournal = {Int. J. Control},
  title        = {Assignment and distributed control of laplacian null space in multiagent systems},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic event-triggered fixed-time secondary control of islanded microgrids. <em>IJCON</em>, <em>98</em>(10), 2481-2490. (<a href='https://doi.org/10.1080/00207179.2025.2463559'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional microgrids that employ droop control may experience challenges related to frequency and voltage offsets, which can pose risks to power system safety. Furthermore, the use of continuous communication in traditional control systems can result in technical and financial challenges. This paper introduces a fixed-time dynamic event-triggered secondary control for islanded microgrids, designed to achieve frequency restoration, voltage regulation and active power sharing within a specified timeframe. This distributed control approach relies solely on information from each distributed generator(DG) and its neighbours. Each DG receives communication from its neighbours and concurrently broadcasts its own information only when certain deviation were reached, thereby minimising communication costs. Several simulated instances illustrate the usefulness and robustness of this control method, including scenarios involving load changes, time delay and topology switching.},
  archive      = {J_IJCON},
  author       = {Wenchao Huang and Yuhan Tu and Shaobin Chen and Yanwei Huang},
  doi          = {10.1080/00207179.2025.2463559},
  journal      = {International Journal of Control},
  month        = {10},
  number       = {10},
  pages        = {2481-2490},
  shortjournal = {Int. J. Control},
  title        = {Dynamic event-triggered fixed-time secondary control of islanded microgrids},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feedback stabilisation of tank-liquid system with robustness to surface tension. <em>IJCON</em>, <em>98</em>(10), 2469-2480. (<a href='https://doi.org/10.1080/00207179.2025.2462241'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We construct a robust stabilising feedback law for the viscous Saint-Venant system of Partial Differential Equations with surface tension and without wall friction. The Saint-Venant system describes the movement of a tank which contains a viscous liquid. We assume constant contact angles between the liquid and the walls of the tank and we achieve a spill-free exponential stabilisation with robustness to surface tension by using a Control Lyapunov Functional. The proposed Control Lyapunov Functional provides a parameterised family of sets which approximate the state space from the interior. Based on the Control Lyapunov Functional, we construct a nonlinear stabilising feedback law which ensures that the closed-loop system converges exponentially to the desired equilibrium point in the sense of an appropriate norm.},
  archive      = {J_IJCON},
  author       = {Iasson Karafyllis and Filippos Vokos and Miroslav Krstic},
  doi          = {10.1080/00207179.2025.2462241},
  journal      = {International Journal of Control},
  month        = {10},
  number       = {10},
  pages        = {2469-2480},
  shortjournal = {Int. J. Control},
  title        = {Feedback stabilisation of tank-liquid system with robustness to surface tension},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stabilization of the wave equation with internal damping and numerical simulations. <em>IJCON</em>, <em>98</em>(10), 2456-2468. (<a href='https://doi.org/10.1080/00207179.2025.2461595'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we investigate the exponential stabilisation problem of a wave equation incorporating Wentzell static boundary conditions. Using the Lumer-Philips theorem, we confirm the existence of a solution. We derive an acceptable exponential decay rate by following Nakao's criterion. Additionally, we conduct one-dimensional numerical experiments to verify the preservation of the energetic properties of the wave equation under interior viscoelastic damping.},
  archive      = {J_IJCON},
  author       = {Kalifa Lassana Barry and Karima Laoubi},
  doi          = {10.1080/00207179.2025.2461595},
  journal      = {International Journal of Control},
  month        = {10},
  number       = {10},
  pages        = {2456-2468},
  shortjournal = {Int. J. Control},
  title        = {Stabilization of the wave equation with internal damping and numerical simulations},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Input-to-state stability of switched systems incorporating unstabilisable modes via an enhanced event-triggered control scheme. <em>IJCON</em>, <em>98</em>(10), 2441-2455. (<a href='https://doi.org/10.1080/00207179.2025.2461592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the input-to-state stability (ISS) of switched systems with unstabilizable modes using an enhanced event-triggered control (ETC) scheme. Unlike the traditional results, the switched system with unstabilisable modes is explored and the fixed constraints on the trade-off are relaxed to be greater than the reciprocal of the average time of any given varying period. The interleaving of system switching and event-triggered behaviour causes asynchronous phenomena and additional triggers. To address the two disadvantages, an improved mode-dependent event-triggered with periodic sampling is put forward by the aid of a relative threshold function combined with an asynchronous associated jumping function. A global gain norm term is introduced to relax the existing relative threshold function, which increases the degree of freedom in designing event-triggered mechanism (ETM). By adding a compensation term to the controller design, asynchronous behaviour is addressed without strict assumptions. Based on the proposed ETM and the admissible edge-dependent average dwell time (AED-ADT) switching signal, an improved and less restrictive sufficient criterion has been formulated to ensure the ISS of the system. Finally, a booster converter example is used to show the applicability and another numerical example is used to testify the availability and the advantages of the derived conclusions.},
  archive      = {J_IJCON},
  author       = {Jinxin Song and Lijun Gao and Xiangning Li and Zhenyue Wang},
  doi          = {10.1080/00207179.2025.2461592},
  journal      = {International Journal of Control},
  month        = {10},
  number       = {10},
  pages        = {2441-2455},
  shortjournal = {Int. J. Control},
  title        = {Input-to-state stability of switched systems incorporating unstabilisable modes via an enhanced event-triggered control scheme},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design of event-triggered adaptive finite-time controller for full-state constrained stochastic nonlinear systems with unknown control directions. <em>IJCON</em>, <em>98</em>(10), 2429-2440. (<a href='https://doi.org/10.1080/00207179.2025.2461591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the problem of event-triggered (ET) adaptive finite-time tracking control is investigated for full-state constrained stochastic nonlinear systems with unknown control directions. In the backstepping, multi-dimensional Taylor networks are employed to estimate the unknown nonlinearities and the command filter is used to overcome the problem of explosion of complexity. Subsequently, a novel adaptive updated law is created for co-designing the controller and the switching threshold-based ET mechanism by introducing the Nussbaum-type functions, which effectively handles the effects of the measurement errors due to the ET mechanism, and the challenges of controller design because of the presence of unknown control directions. The proposed control strategy can achieve that the closed-loop system is semi-global finite-time stable in probability, the system states are maintained in the predefined compact sets in a finite time and the system output tracking expectation signal is commendable while easing the communications burden. Finally, two examples are employed to illustrate the validity of the proposed control strategy.},
  archive      = {J_IJCON},
  author       = {Dong-Mei Wang and Yu-Qun Han and Li-Ting Lu and Shan-Liang Zhu},
  doi          = {10.1080/00207179.2025.2461591},
  journal      = {International Journal of Control},
  month        = {10},
  number       = {10},
  pages        = {2429-2440},
  shortjournal = {Int. J. Control},
  title        = {Design of event-triggered adaptive finite-time controller for full-state constrained stochastic nonlinear systems with unknown control directions},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive disturbance observers-based fixed-time prescribed performance optimisation control for a class of uncertain nonlinear systems. <em>IJCON</em>, <em>98</em>(10), 2410-2428. (<a href='https://doi.org/10.1080/00207179.2025.2460042'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the trajectory tracking optimisation control problem of a class of uncertain nonlinear systems with external disturbances, and an adaptive disturbance observers-based fixed-time prescribed performance optimisation control strategy is introduced. First, the adaptive disturbance observers are designed to observe the external disturbances in fixed time without the previous knowledge. Then, an adaptive fixed-time prescribed performance controller is designed to enhance the transient and steady-state performances of the system. Meanwhile, the command filters with a fractional-order error compensation system are introduced to solve the issue of differential explosion. Further, an adaptive mutation-sparrow search algorithm (AM-SSA) is constructed to optimise the controller parameters to improve the system's convergence speed and steady-state accuracy. Theoretical analysis demonstrates that the system tracking error can converge to the zero region within a fixed time. Finally, the effectiveness and practicality of the proposed method are proved through the comparative analysis involving simulations and experiments.},
  archive      = {J_IJCON},
  author       = {Le Liu and Lei Zhang and Shanghua Wu and Yiming Fang},
  doi          = {10.1080/00207179.2025.2460042},
  journal      = {International Journal of Control},
  month        = {10},
  number       = {10},
  pages        = {2410-2428},
  shortjournal = {Int. J. Control},
  title        = {Adaptive disturbance observers-based fixed-time prescribed performance optimisation control for a class of uncertain nonlinear systems},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite-dimensional adaptive observer design for linear parabolic systems with delayed measurements. <em>IJCON</em>, <em>98</em>(10), 2401-2409. (<a href='https://doi.org/10.1080/00207179.2025.2460035'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New finite-dimensional adaptive observers are proposed for uncertain heat equation and a class of linear Kuramoto–Sivashinsky equation (KSE) with local output. The observers are based on the modal decomposition approach and use a classical persistent excitation condition to ensure practical exponential convergence of both states and parameters estimation. An important challenge of this work is that it treats the case when the function ϕ 1 ( ⋅ , t ) of the unknown part in the PDE model depends on the spatial variable and ϕ 1 ( ⋅ , t ) ∈ L 2 ( 0 , 1 ) .},
  archive      = {J_IJCON},
  author       = {Tarek Ahmed-Ali and Emilia Fridman and Francoise Lamnabhi-Lagarrigue},
  doi          = {10.1080/00207179.2025.2460035},
  journal      = {International Journal of Control},
  month        = {10},
  number       = {10},
  pages        = {2401-2409},
  shortjournal = {Int. J. Control},
  title        = {Finite-dimensional adaptive observer design for linear parabolic systems with delayed measurements},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling and adaptive NN control for SMA flexible actuating systems with modified GPI hysteresis model. <em>IJCON</em>, <em>98</em>(10), 2390-2400. (<a href='https://doi.org/10.1080/00207179.2025.2458138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a shape memory alloy (SMA) actuating system is constructed to achieve flexible actuation ability. To improve the actuating performance, an effective control scheme needs to be developed to address the negative effects caused by the nonlinear nature of the internal SMA material and accommodate complex operating conditions. A modified generalised Prandtl-Ishlinskii (MGPI) hysteresis model is proposed to accurately characterise the strong saturated asymmetric hysteresis nonlinearity in the SMA wires. The modification of the input shape function allows for greater flexibility in controller design. Using this hysteresis modelling approach, an adaptive neural network (NN) control with a command filter is designed to achieve superior control performance. Experimental results validate the effectiveness of the proposed controller strategy.},
  archive      = {J_IJCON},
  author       = {Ying Feng and Wei Xiao and Mingwei Liang and Chenxing Sun},
  doi          = {10.1080/00207179.2025.2458138},
  journal      = {International Journal of Control},
  month        = {10},
  number       = {10},
  pages        = {2390-2400},
  shortjournal = {Int. J. Control},
  title        = {Modeling and adaptive NN control for SMA flexible actuating systems with modified GPI hysteresis model},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed exploration algorithm for GPS-denied areas based on flocking rules. <em>IJCON</em>, <em>98</em>(10), 2380-2389. (<a href='https://doi.org/10.1080/00207179.2025.2458135'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of having a multi-agent system (MAS) search for areas of higher relative importance as measured by an unknown utility function. In the envisioned scenario, there are inexpensive agents without localisation sensors and limited communication capabilities. More expensive nodes serve as fixed towers and forward noisy position and velocity measurements using directional antennae. There is no assumptions on initial network connectivity. By proposing a set of flocking rules and set-membership estimation, the formation drives to a vicinity of nearby local maximum of the function while having theoretical guarantees of no collisions. The performance of the method is evaluated both in Matlab simulations and using the Crazyswarm package under the robot operating system (ROS) environment, including cases of moving destinations, obstacles, undesirable zones, and different number of nodes and sizes of the mission plane.},
  archive      = {J_IJCON},
  author       = {Rafael Ribeiro and Francisco Santos and Daniel Silvestre and Carlos Silvestre},
  doi          = {10.1080/00207179.2025.2458135},
  journal      = {International Journal of Control},
  month        = {10},
  number       = {10},
  pages        = {2380-2389},
  shortjournal = {Int. J. Control},
  title        = {Distributed exploration algorithm for GPS-denied areas based on flocking rules},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). General maximum principle for optimal control problems of stochastic systems with delay: An ekeland's variational principle method. <em>IJCON</em>, <em>98</em>(10), 2369-2379. (<a href='https://doi.org/10.1080/00207179.2025.2457104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider optimal control problems of stochastic systems with delay. The control domains are not necessarily convex and the diffusion coefficients explicitly depend on control variables. The delay term of the state is regarded as a control process and then the Ekeland's variational principle is applied to obtain a general maximum principle for the optimal control problems. As applications, we use the theoretical results to a delayed stochastic linear quadratic (LQ) optimal control problem with a non-convex control domain.},
  archive      = {J_IJCON},
  author       = {Qixia Zhang},
  doi          = {10.1080/00207179.2025.2457104},
  journal      = {International Journal of Control},
  month        = {10},
  number       = {10},
  pages        = {2369-2379},
  shortjournal = {Int. J. Control},
  title        = {General maximum principle for optimal control problems of stochastic systems with delay: An ekeland's variational principle method},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linear cluster consensus algorithms for signed delayed networks. <em>IJCON</em>, <em>98</em>(10), 2351-2368. (<a href='https://doi.org/10.1080/00207179.2025.2457097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we investigate the cluster consensus problem for higher-order integrator networks modelled via signed digraphs with delayed dynamics. Contrary to the related studies in the existing literature, systems do not have to contain any special graph structures. By utilising an extended digraph approach, the trajectories of a signed delayed network are recovered from its corresponding extended unsigned digraph. For higher-order integrator systems with fixed input or communication delay under continuous-time topology, the stability properties are investigated and the upper bounds are determined so that the systems achieve cluster consensus without any change in cluster members. Furthermore, we show that the discrete-time higher-order integrator systems with nonuniform delay reach cluster consensus and are stable under bounded delay provided that the undelayed system is stable. At the end, numerical examples are provided to illustrate theoretical results.},
  archive      = {J_IJCON},
  author       = {Ümit Develer and Onur Cihan and Mehmet Akar},
  doi          = {10.1080/00207179.2025.2457097},
  journal      = {International Journal of Control},
  month        = {10},
  number       = {10},
  pages        = {2351-2368},
  shortjournal = {Int. J. Control},
  title        = {Linear cluster consensus algorithms for signed delayed networks},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Regional control strategies for a spatiotemporal SQEIAR epidemic model: Application to COVID-19. <em>IJCON</em>, <em>98</em>(10), 2332-2350. (<a href='https://doi.org/10.1080/00207179.2025.2456036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we develop a spatial SEIAR-type epidemic model considering a quarantined population (denoted as Q), which we call the SQEIAR model. The dynamics of the SQEIAR model are described by six Partial Differential Equations (PDEs) that represent the changes in the susceptible, quarantined, exposed, asymptomatic, infected, and recovered populations. Our goal is to reduce the number of susceptible, exposed, asymptomatic, and infected individuals while accounting for the environment, which plays a critical role in the spread of epidemics. We then propose a novel strategy for epidemic control, incorporating two key control measures: regional quarantine for the susceptible population and treatment for the infected. This approach serves as an alternative to widespread quarantine, minimising the economic, social, and other potential impacts. Additionally, we consider the possibility of reinfection among recovered individuals, a common occurrence in many diseases. To demonstrate the practical utility of our results, a numerical example centred on COVID-19 is presented.},
  archive      = {J_IJCON},
  author       = {Mohammed Elghandouri and Khalil Ezzinbi and Youness Mezzan},
  doi          = {10.1080/00207179.2025.2456036},
  journal      = {International Journal of Control},
  month        = {10},
  number       = {10},
  pages        = {2332-2350},
  shortjournal = {Int. J. Control},
  title        = {Regional control strategies for a spatiotemporal SQEIAR epidemic model: Application to COVID-19},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-player nonzero-sum and zero-sum games subject to stochastic noncausal systems. <em>IJCON</em>, <em>98</em>(10), 2315-2331. (<a href='https://doi.org/10.1080/00207179.2025.2456025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies two-player nonzero-sum and zero-sum games within the context of stochastic noncausal systems (SNSs). These SNSs are transformed into subsystems consisting of forward and backward stochastic difference equations through an equivalent conversion. Subsequently, recurrence equations are introduced to convert stochastic two-player nonzero-sum games into deterministic difference equation solving problems. These recurrence equations are then utilised to derive the relevant equations needed to deduce the saddle-point equilibrium solutions for two-player zero-sum games embedded within linear and nonlinear SNSs. The resolution of these equations yields analytical expressions that encapsulate the saddle-point equilibrium solutions for such types of two-player zero-sum games. To illustrate these findings, an illustrative example is provided.},
  archive      = {J_IJCON},
  author       = {Xin Chen and Zeyu Zhang and Yijia Zhang and Dongmei Yuan},
  doi          = {10.1080/00207179.2025.2456025},
  journal      = {International Journal of Control},
  month        = {10},
  number       = {10},
  pages        = {2315-2331},
  shortjournal = {Int. J. Control},
  title        = {Two-player nonzero-sum and zero-sum games subject to stochastic noncausal systems},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Longitudinal robust dynamic programming control for driving robot vehicles with performance self-learning. <em>IJCON</em>, <em>98</em>(10), 2304-2314. (<a href='https://doi.org/10.1080/00207179.2024.2403507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To realise the accurate and stable longitudinal control of the vehicle manipulated by the driving robot (DRV) under different test conditions, a longitudinal robust dynamic programming (RDP) control method for the DRV based on performance self-learning is proposed. Firstly, the dynamics of the driving robot and the vehicle are analysed. Then, the adjoint sensitivity method is used for the DRV to train the neural ordinary differential equation (NODE). The performance of the vehicle under different pedal openings is learned. A RDP controller is designed to solve the nominal target acceleration. Moreover, the unscented Kalman filtering (UKF) method is used to estimate the uncertain external disturbance of the DRV. Furthermore, dynamic compensation is used for the driving robot to track the vehicle's speed. Finally, the stability of the controller is proved. Compared with MPC, LQR, and PID methods, test results show the effectiveness of the proposed method.},
  archive      = {J_IJCON},
  author       = {Gang Chen and Weihong Lu and Jiaqi Mei and Liangmo Wang and Weigong Zhang},
  doi          = {10.1080/00207179.2024.2403507},
  journal      = {International Journal of Control},
  month        = {10},
  number       = {10},
  pages        = {2304-2314},
  shortjournal = {Int. J. Control},
  title        = {Longitudinal robust dynamic programming control for driving robot vehicles with performance self-learning},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximate controllability of second-order neutral measure driven systems with state-dependent delay. <em>IJCON</em>, <em>98</em>(10), 2294-2303. (<a href='https://doi.org/10.1080/00207179.2024.2403483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the solvability and approximate controllability of a new class of measure driven control systems with state-dependent delay, which can deal with hybrid system without any restriction Zeno behaviour. By applying fixed point technology and Lebesgue Stieltjes integral, a new set of sufficient conditions is constructed that ensures the existence of mild solution and approximate controllability of the considered system. Lastly, an example is formulated to demonstrate the effectiveness of obtained results.},
  archive      = {J_IJCON},
  author       = {Hongxia Fan and Chengju Qiang},
  doi          = {10.1080/00207179.2024.2403483},
  journal      = {International Journal of Control},
  month        = {10},
  number       = {10},
  pages        = {2294-2303},
  shortjournal = {Int. J. Control},
  title        = {Approximate controllability of second-order neutral measure driven systems with state-dependent delay},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partially observable optimal control using exponential cost criterion. <em>IJCON</em>, <em>98</em>(10), 2275-2293. (<a href='https://doi.org/10.1080/00207179.2024.2403479'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a partially observable optimal control model in which the system and observation noises are correlated, and the cost criterion is in the form of an exponential of an integral. A new minimum principle criterion is derived and applied to compute the explicit solution of linear exponential Gaussian optimisation problem with correlated noises.},
  archive      = {J_IJCON},
  author       = {Zhipeng Li and Minyue Fu and Huanshui Zhang},
  doi          = {10.1080/00207179.2024.2403479},
  journal      = {International Journal of Control},
  month        = {10},
  number       = {10},
  pages        = {2275-2293},
  shortjournal = {Int. J. Control},
  title        = {Partially observable optimal control using exponential cost criterion},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global output feedback control for uncertain nonlinear systems with input quantisation and sensor gain perturbation. <em>IJCON</em>, <em>98</em>(10), 2265-2274. (<a href='https://doi.org/10.1080/00207179.2024.2403474'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new quantised control method via output feedback is proposed by establishing two pairs of time-varying coupled matrix inequalities. Compared to relevant quantised control results, our control method has the novelty: (i) the sensor gain perturbation is allowed to be large and nondifferentiable; (ii) the growth constraint of system nonlinearities is relaxed to depend on unmeasured states and x 1 -polynomial function; (iii) a dynamic scaling technique, instead of backstepping design, is introduced to reduce the computational complexity of controller design. In particular, by using a symbolic function (or hyperbolic tangent function), global asymptotic stability is achieved under any hysteresis quantiser.},
  archive      = {J_IJCON},
  author       = {Hongyu Chen and Xianglei Jia and Chengdi Xiang},
  doi          = {10.1080/00207179.2024.2403474},
  journal      = {International Journal of Control},
  month        = {10},
  number       = {10},
  pages        = {2265-2274},
  shortjournal = {Int. J. Control},
  title        = {Global output feedback control for uncertain nonlinear systems with input quantisation and sensor gain perturbation},
  volume       = {98},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijss">IJSS - 18</h2>
<ul>
<li><details>
<summary>
(2025). Finite-time bumpless transfer synchronisation of discrete-time delayed positive neural networks under dual-channel false data inject attacks. <em>IJSS</em>, <em>56</em>(15), 3848-3862. (<a href='https://doi.org/10.1080/00207721.2025.2479767'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the finite-time synchronisation problem of discrete-time delayed positive neural networks under false data injection attacks. A master–slave networked control framework is constructed which is under dual-channel attacks, that is, the channel from sensor to controller and the channel from controller to actuator. False data injection attacks can destroy easily the positivity of positive neural networks, by injecting large negative data into the sampled signals, for instance. In this case, assuming a non-negative synchronisation error, as in previous work, to maintain the positivity of the slave system is inadequate. A newly designed regulator-based switching control method is proposed to synchronise the master–slave system decreasing the influence of dual-channel attacks. The positivity constraint in synchronisation error system is removed. To further reduce the turbulence caused by the switching of variable control inputs, a bumpless transfer strategy is considered. By using the Lyapunov theorem, some sufficient delay-dependent conditions for finite-time synchronisation of master–slave positive neural networks are proposed in the form of linear matrix inequalities. A numerical example and a water management system are presented to verify the effectiveness of the proposed methods.},
  archive      = {J_IJSS},
  author       = {Kun Ma and Yijun Zhang and Kai Zhou and Xiahedan Haliding},
  doi          = {10.1080/00207721.2025.2479767},
  journal      = {International Journal of Systems Science},
  month        = {11},
  number       = {15},
  pages        = {3848-3862},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Finite-time bumpless transfer synchronisation of discrete-time delayed positive neural networks under dual-channel false data inject attacks},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sampled-data output regulation for a class of linear time-delay systems. <em>IJSS</em>, <em>56</em>(15), 3828-3847. (<a href='https://doi.org/10.1080/00207721.2025.2474133'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an aperiodic sampled-data control scheme to address the output regulation problem for a class of linear time-delay systems. First, we demonstrate that the problem can be solved exactly by the sampled-data dynamic output feedback control law equipped with sequential predictors under a constant exogenous signal. Second, we demonstrate that the problem can be solved practically by the same control law under a time-varying exogenous signal with bounded first derivative. Also, we consider that delay occurs during the transmission of signals from predictors in both scenarios. Finally, we substantiate the effectiveness of our proposed control approach with the aid of two illustrative examples.},
  archive      = {J_IJSS},
  author       = {Mengqi Jia and Wei Liu},
  doi          = {10.1080/00207721.2025.2474133},
  journal      = {International Journal of Systems Science},
  month        = {11},
  number       = {15},
  pages        = {3828-3847},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Sampled-data output regulation for a class of linear time-delay systems},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Secure control for simplicial complexes under hybrid cyber attacks–an event-triggered impulsive approach. <em>IJSS</em>, <em>56</em>(15), 3804-3827. (<a href='https://doi.org/10.1080/00207721.2025.2479756'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates delayed event-triggered impulsive control for simplicial complexes under stochastic hybrid cyber attacks, such as denial-of-service (DoS) and deception attacks. Firstly, leveraging the properties of d -simplices and link-dependent topology, an equivalent adjacency matrix is introduced to model D -simplicial complexes as a linear system. Secondly, a delayed event-triggered mechanism is developed to ensure efficient resource utilisation while preventing the Zeno phenomenon through a delayed waiting time. The proposed control strategy framework combines an event-triggered mechanism with topology-dependent impulsive control, where impulsive instants are dynamically determined. Additionally, the impact of hybrid attacks is modelled by incorporating DoS and deception attacks that follow a Bernoulli distribution. Thirdly, sufficient conditions for mean-square exponential synchronisation of simplicial complexes under attacks are derived using Lyapunov functions and inequality recursion techniques. Finally, numerical simulations and examples are presented to validate the effectiveness and robustness of the proposed approach.},
  archive      = {J_IJSS},
  author       = {Wenying Yuan and Tianchi Tong and Qian Dong and Jinsheng Sun},
  doi          = {10.1080/00207721.2025.2479756},
  journal      = {International Journal of Systems Science},
  month        = {11},
  number       = {15},
  pages        = {3804-3827},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Secure control for simplicial complexes under hybrid cyber attacks–an event-triggered impulsive approach},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predictor-based observer and resilient controller design for aperiodic sampled-data systems with disturbance and output delay. <em>IJSS</em>, <em>56</em>(15), 3784-3803. (<a href='https://doi.org/10.1080/00207721.2025.2477798'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the control problem based on state/disturbance observers is studied for a class of networked aperiodic sampled-data systems with unknown disturbances and output delays. A novel observer structure is devised to estimate states and disturbances by predicting the actual output of the system. Moreover, the disturbance constraint is broadened to encompass wider types such as unbounded finite derivatives. Based on the obtained estimation of disturbance and state, a resilient controller is proposed to compensate for the impact caused by controller parameter perturbations. In particular, a new class of Lyapunov-like functionals is constructed to extend the sampling interval associated with exponential convergence. By employing matrix analysis and integration techniques, sufficient criteria are established to guarantee the exponential convergence of the networked aperiodic sampled-data closed-loop dynamics. The obtained criteria reveal that the estimation error of the disturbance depends only on the errors of the predictor and state observation, benefiting from the novel structure of the devised observer. The parameter gains of the observer and controller are readily determined by solving a set of convex optimisation constraints. The effectiveness and superiority of the proposed observer-based control algorithm are confirmed through developed examples.},
  archive      = {J_IJSS},
  author       = {Mingzhi Die and Zidong Wang and Yuqiang Luo and Fan Wang and Shuxin Du},
  doi          = {10.1080/00207721.2025.2477798},
  journal      = {International Journal of Systems Science},
  month        = {11},
  number       = {15},
  pages        = {3784-3803},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Predictor-based observer and resilient controller design for aperiodic sampled-data systems with disturbance and output delay},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Impulsive secure consensus control of nonlinear multi-agent systems with actuation delays under sequential scaling attacks. <em>IJSS</em>, <em>56</em>(15), 3771-3783. (<a href='https://doi.org/10.1080/00207721.2025.2477216'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the mean-square exponential consensus problem of nonlinear multi-agent systems in the presence of actuation delays under sequential scaling attacks. Given the limited energy of the attacker, specific attack characteristics such as attack duration and attack frequency are introduced to characterise the sequential scaling attacks. Firstly, an event-triggering mechanism is proposed to reduce the communication resource consumption by determining when agents need to communicate with their neighbours, thereby avoiding continuous information transmission. Considering the effect of actuation delays, a distributed delayed impulsive controller is designed. An impulse-switching error system is then constructed, which transforms the original system with time delays into one without. Furthermore, sufficient consensus criteria is derived, imposing constraints on event-triggering parameters. The design of impulsive gain matrix is also presented. Finally, the obtained results are demonstrated to be effective through an example.},
  archive      = {J_IJSS},
  author       = {Anguo Zhang and Wangli He and Feng Qian},
  doi          = {10.1080/00207721.2025.2477216},
  journal      = {International Journal of Systems Science},
  month        = {11},
  number       = {15},
  pages        = {3771-3783},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Impulsive secure consensus control of nonlinear multi-agent systems with actuation delays under sequential scaling attacks},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable control for large-scale networked systems with input saturation constraint using chordal decomposition. <em>IJSS</em>, <em>56</em>(15), 3758-3770. (<a href='https://doi.org/10.1080/00207721.2025.2477203'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the scalable control of large-scale networked systems(LSNSs) with input saturation constraints is studied using choral decomposition. Firstly, in order to more effectively address the control requirements of complex systems and reduce the communication load, the modeling of LSNSs with different plant and communication topologies is constructed on an undirected graph. Subsequently, the chordal decomposition theorem was employed to establish a set of linear matrix inequalities (LMIs) over maximal cliques, with the objective of ensuring the mean-square asymptotic stability of LSNSs with input saturation constraints. Additionally, a design methodology was proposed for the design of the H ∞ scalable controllers, which ensures that the controllers of the maximal clique to which it belongs and the controllers of neighbouring maximal cliques are updated only when plugging-in or plugging-out subsystems. Furthermore, the proposed approach offers significant advantages in terms of reduced computational complexity and increased privacy. Finally, the effecyiveness of the proposed scalable control approach is validated by analyzing microgrids.},
  archive      = {J_IJSS},
  author       = {An Lin and Chen Peng and Jun Cheng and Engang Tian},
  doi          = {10.1080/00207721.2025.2477203},
  journal      = {International Journal of Systems Science},
  month        = {11},
  number       = {15},
  pages        = {3758-3770},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Scalable control for large-scale networked systems with input saturation constraint using chordal decomposition},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed h∞ moving horizon estimation over energy harvesting sensor networks. <em>IJSS</em>, <em>56</em>(15), 3743-3757. (<a href='https://doi.org/10.1080/00207721.2025.2476173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the distributed 𝐻 ∞ moving horizon estimation problem for nonlinear systems over energy harvesting sensor networks in a deterministic framework, where each sensor is able to gather energy from the surrounding environment. A transformed Poisson process model is introduced to describe the energy collected by each sensor, with particular consideration given to the minimum energy collected. In contrast to previous research on distributed state estimation over energy harvesting sensor networks, which solely considered the energy costs associated with transmission and assumed knowledge of the statistical properties of harvested energy, we consider a more comprehensive scenario. Specifically, we account for the energy costs associated with both sensor sensing and data transmission to neighbouring sensors, while only the parameters of the minimum harvested energy are known. Subsequently, a novel energy allocation strategy is proposed to provide energy for each sensor sensing and transmission based on a predetermined fixed circular order, which determines a maximum time interval for each sensor sensing and transmission. Then, local measurement output predictors and prior state predictors are constructed to handle interruptions in sensor sensing and communication caused by the energy harvesting mechanism. Furthermore, we derive sufficient conditions for the existence of a distributed moving horizon estimator, ensuring H ∞ consensus. To illustrate the proposed method's effectiveness, a single-machine infinite-bus power system is presented.},
  archive      = {J_IJSS},
  author       = {Chaoyang Liang and Defeng He and Chenhui Xu},
  doi          = {10.1080/00207721.2025.2476173},
  journal      = {International Journal of Systems Science},
  month        = {11},
  number       = {15},
  pages        = {3743-3757},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Distributed h∞ moving horizon estimation over energy harvesting sensor networks},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Experimental results of model predictive control of a coupled tank system using interior-point barrier algorithm. <em>IJSS</em>, <em>56</em>(15), 3730-3742. (<a href='https://doi.org/10.1080/00207721.2025.2475361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In model predictive control (MPC), the control input is determined at each instance by formulating and solving an optimisation problem that incorporates real-time measurement updates. Applications characterised by rapid process dynamics often necessitate shorter sampling intervals, which impose stringent requirements on computational consistency. Also, implementing MPC on hardware with constrained computational resources remains a significant challenge. Consequently, the realisation of MPC for such scenarios mandates an appropriate choice of an optimisation algorithm that exhibits consistency in terms of iteration numbers, ensuring optimised solutions within a sampling period in real-time environments. This study introduces the application of an infeasible interior-point barrier algorithm tailored for MPC. The MPC is formulated for linear systems in the condensed framework so that the number of decision variables in the optimisation problem is reduced. The solution algorithm of the optimisation problem is formulated on primal-dual conditions. The proposed algorithm is evaluated in real-time on a coupled tank system. Both the state and output feedback MPC are implemented that demonstrate consistent iteration count throughout its runtime. Comparative performance analyses with other methodologies are conducted elucidating the trade-offs inherent in different approaches.},
  archive      = {J_IJSS},
  author       = {Rangoli Singh and Sandip Ghosh and Debdas Ghosh and Devender Singh and Pawel Dworak},
  doi          = {10.1080/00207721.2025.2475361},
  journal      = {International Journal of Systems Science},
  month        = {11},
  number       = {15},
  pages        = {3730-3742},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Experimental results of model predictive control of a coupled tank system using interior-point barrier algorithm},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-free finite-time H2/H∞ predictive control for discrete-time systems via Q-learning. <em>IJSS</em>, <em>56</em>(15), 3718-3729. (<a href='https://doi.org/10.1080/00207721.2025.2475360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a model-free finite-time 𝐻 2 / 𝐻 ∞ predictive control strategy for linear discrete-time systems with unknown parameters. The method employs Q-learning to learn the optimal control policy directly from measured input-output data, eliminating the need for an explicit system model. The developed control strategy aims to achieve a finite-time H 2 / H ∞ performance index, balancing robustness and the energy consumption of the control input in a given intervals, thereby enhancing the overall system performance. The algorithm incorporates receding horizon optimisation to dynamically adjust the control strategy the evolving disturbances. Therefore, the robustness of the considered system is further improved. Simulation results demonstrate the effectiveness of the proposed method, showcasing its potential for practical applications in various control systems, particularly those with limited model information or model uncertainties.},
  archive      = {J_IJSS},
  author       = {Yihong Lin and Haiying Wan and Peng He and Xiaoli Luan and Fei Liu},
  doi          = {10.1080/00207721.2025.2475360},
  journal      = {International Journal of Systems Science},
  month        = {11},
  number       = {15},
  pages        = {3718-3729},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Model-free finite-time H2/H∞ predictive control for discrete-time systems via Q-learning},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boundedness theorems of discrete-time stochastic delay systems and applications to neural networks. <em>IJSS</em>, <em>56</em>(15), 3702-3717. (<a href='https://doi.org/10.1080/00207721.2025.2474717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on investigating the p th exponential ultimate boundedness of a class of discrete-time stochastic delay systems and its application in neural networks. By employing a novel method that combines inequality techniques and reductio ad absurdum, several sufficient conditions for the p th exponential ultimate boundedness of the addressed systems are derived. This method not only circumvents the hardship of constructing Lyapunov functional but also yields simpler criteria for exponential ultimate boundedness criteria. As applications, the criteria for boundedness are utilised in neural networks. Finally, the validity of the theoretical results is verified by numerical examples.},
  archive      = {J_IJSS},
  author       = {Danhua He and Liguang Xu},
  doi          = {10.1080/00207721.2025.2474717},
  journal      = {International Journal of Systems Science},
  month        = {11},
  number       = {15},
  pages        = {3702-3717},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Boundedness theorems of discrete-time stochastic delay systems and applications to neural networks},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fully distributed event-triggered containment control for complex networks. <em>IJSS</em>, <em>56</em>(15), 3689-3701. (<a href='https://doi.org/10.1080/00207721.2025.2474715'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the fully distributed containment control problem of complex networks (CNs) with the event-triggered coupling. Firstly, to achieve the considered containment control without requiring any global information, the suitable adaptive laws for coupling strengths between neighbouring nodes are designed. Then, a fully distributed event-triggered scheme is introduced, under which the coupling communication resources can be effectively saved. In this scheme, continuous coupling communication will be avoided in the updating of control laws and the monitoring of triggering function. Besides, the Zeno behaviour is excluded by showing that the interval between any two triggering events is lower-bounded by a strictly positive value. Finally, a simulation example is presented to verify the effectiveness of our obtained results.},
  archive      = {J_IJSS},
  author       = {Bin Zhang and Dan Liu and Binrui Wang},
  doi          = {10.1080/00207721.2025.2474715},
  journal      = {International Journal of Systems Science},
  month        = {11},
  number       = {15},
  pages        = {3689-3701},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Fully distributed event-triggered containment control for complex networks},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sliding mode preview control for nonlinear discrete-time fuzzy systems with hybrid cyber-attacks and its applications. <em>IJSS</em>, <em>56</em>(15), 3669-3688. (<a href='https://doi.org/10.1080/00207721.2025.2474144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a preview mechanism is employed to investigate the sliding mode tracking control for nonlinear discrete-time fuzzy systems under randomly occurring uncertainties (ROUs) and hybrid cyber-attacks (HCAs). HCAs are modelled by random variables obeying the Bernoulli distribution, and preview information is introduced to construct the augmented error system (AES). A sliding mode control (SMC) method with preview action is designed. In scenarios with ROUs and HCAs, some sufficient conditions are derived to ensure both stochastic stability of the system and the reachability of specified sliding regions. Finally, two examples are provided to illustrate the effectiveness of the proposed control strategy.},
  archive      = {J_IJSS},
  author       = {Yuxin Chen and Junchao Ren},
  doi          = {10.1080/00207721.2025.2474144},
  journal      = {International Journal of Systems Science},
  month        = {11},
  number       = {15},
  pages        = {3669-3688},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Sliding mode preview control for nonlinear discrete-time fuzzy systems with hybrid cyber-attacks and its applications},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven control for stochastic linear-quadratic optimal problem with completely unknown dynamics. <em>IJSS</em>, <em>56</em>(15), 3657-3668. (<a href='https://doi.org/10.1080/00207721.2025.2474137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents an off-policy iteration approach for finding adaptive optimal control policies online for continuous-time stochastic linear systems with completely unknown system dynamics. The proposed approach employs the approximate/adaptive dynamic programming technique to iteratively solve the stochastic algebraic Riccati equation using the online information of state and input, without requiring the priori knowledge of the system matrices. In addition, all iterations can be conducted by repeatedly using the same state and input information in some fixed time intervals. Theoretical guarantees are given for the stability of the closed-loop system and the convergence of the algorithm. Finally, the application of the proposed algorithm for two examples validates its feasibility and effectiveness.},
  archive      = {J_IJSS},
  author       = {Yanlin Chen and Weiyao Lan},
  doi          = {10.1080/00207721.2025.2474137},
  journal      = {International Journal of Systems Science},
  month        = {11},
  number       = {15},
  pages        = {3657-3668},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Data-driven control for stochastic linear-quadratic optimal problem with completely unknown dynamics},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel noise-robust method for efficient online data decomposition. <em>IJSS</em>, <em>56</em>(15), 3637-3656. (<a href='https://doi.org/10.1080/00207721.2025.2474135'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the critical role of data decomposition in managing complex datasets across various fields, addressing the challenge of noise is essential, as it can significantly degrade decomposition performance. This study emphasises the importance of noise-robust data decomposition and proposes a novel online method designed for efficient and reliable decomposition under noisy conditions. To address this challenge, we define an optimisation objective that simultaneously suppresses noise while satisfying physical constraints. To mitigate the sensitivity of gradient descent-based methods to initial conditions, which can often lead to local optima, we simplify the optimisation objective propose and advanced techniques. This approach eliminates irrelevant variables, fully exploits the efficiency of sparse matrices, and quickly solves for both spatial and temporal modes, significantly improving overall performance. Theoretical derivations and analyses are provided to elucidate the optimisation process and its impact on noise robustness. Numerical experiments demonstrate that the proposed method effectively avoids local optima and outperforms traditional methods in terms of noise robustness. Specifically, in real-world data experiments, the proposed method achieves an 89.6% reduction in the root mean square error of reconstructed data, compared to a 68.06% reduction achieved by existing methods, representing a 31.6% relative improvement. These results highlight the superior reliability and robustness of the proposed method in practical applications.},
  archive      = {J_IJSS},
  author       = {Yiguo Yang and Shuai Li and Pin Wu and Weibing Feng},
  doi          = {10.1080/00207721.2025.2474135},
  journal      = {International Journal of Systems Science},
  month        = {11},
  number       = {15},
  pages        = {3637-3656},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {A novel noise-robust method for efficient online data decomposition},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-level anti-windup fast control of disturbed multi-agents with application to vehicles formation. <em>IJSS</em>, <em>56</em>(15), 3618-3636. (<a href='https://doi.org/10.1080/00207721.2025.2473488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the fast formation control problem of the multi-agent system (MAS) subject to practical input constraints and mismatched disturbances. An improved terminal sliding mode (TSM) control scheme, which incorporates finite-time disturbance observers (FTDOs) and a saturation level detecting system (SLDS), is proposed for a class of second-order MAS. More specifically, FTDOs effectively estimate both matched and mismatched disturbances in the motion equation of each agent, while the novel SLDS analyses the effect of input saturations and makes different dynamic modifications on both TSM surface and control law with respect to two (light or deep) saturation levels. The proposed two-level anti-windup TSM control theoretically guarantees the finite-time stability of MAS despite the presence of unknown mismatched disturbances and deep input saturations, which is practically applied to the formation control of unmanned ground vehicles with numerical simulations and physical experiments.},
  archive      = {J_IJSS},
  author       = {Zhimin Xu and Hao An and Yinghui Li and Changhong Wang},
  doi          = {10.1080/00207721.2025.2473488},
  journal      = {International Journal of Systems Science},
  month        = {11},
  number       = {15},
  pages        = {3618-3636},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Two-level anti-windup fast control of disturbed multi-agents with application to vehicles formation},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stabilisation of stochastic systems driven by poisson process. <em>IJSS</em>, <em>56</em>(15), 3603-3617. (<a href='https://doi.org/10.1080/00207721.2025.2473481'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates control design for a class of strict-feedback nonlinear continuous-time stochastic differential system (SDS) driven by the Poisson process. The method of backstepping is employed in designing the stabilising control function together with the Lyapunov stability theory. The control function guarantees global asymptotic stability at the origin in probability. Further, fourth-moment exponential stability conditions for the system are derived and the proposed results are validated by a numerical example along with its application to a physical system.},
  archive      = {J_IJSS},
  author       = {K. Mathiyalagan and T. Elizabeth Jeyanthi},
  doi          = {10.1080/00207721.2025.2473481},
  journal      = {International Journal of Systems Science},
  month        = {11},
  number       = {15},
  pages        = {3603-3617},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {Stabilisation of stochastic systems driven by poisson process},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified criterion for semiglobal and global finite/fixed-time stability of stochastic systems. <em>IJSS</em>, <em>56</em>(15), 3587-3602. (<a href='https://doi.org/10.1080/00207721.2025.2471570'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, semiglobal and global finite/fixed-time stability of a class of semilinear stochastic systems in Hilbert spaces are studied. By employing the stopping time technique and applying the infinite-dimensional Itô formula, a unified Lyapunov criterion is established under which global finite-time, global fixed-time, semiglobal finite-time and semiglobal fixed-time stability can all be obtained. This fills the research gaps in the finite/fixed-time stability of stochastic distributed parameter systems and the semiglobal finite/fixed-time stability of stochastic systems. Moreover, compared to existing results on finite/fixed-time stability for stochastic systems, our Lyapunov criterion can still work well under more stringent conditions. This is done by adding a term which can reflect the stabilising effect of the diffusion term and replacing original fractional power functions with a class of piecewise continuous fractional power functions that are no longer required to be increasing. Finally, illustrative examples are given and the obtained theoretical results are verified by numerical simulations.},
  archive      = {J_IJSS},
  author       = {Lin Fu and Shiguo Peng and Quanxin Zhu and Jiawei Zhuang},
  doi          = {10.1080/00207721.2025.2471570},
  journal      = {International Journal of Systems Science},
  month        = {11},
  number       = {15},
  pages        = {3587-3602},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {A unified criterion for semiglobal and global finite/fixed-time stability of stochastic systems},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved adaptive neural asymptotic tracking control for pure-feedback nonlinear systems with disturbances. <em>IJSS</em>, <em>56</em>(15), 3571-3586. (<a href='https://doi.org/10.1080/00207721.2025.2471025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This note considers the issue of the asymptotic tracking control for a class of pure-feedback systems (PFSs) with disturbances. During the controller construction, the mean value theorem (MVT) is utilised to tackle the non-affine structure of the original systems. Then, we employ radial basis function neural networks (RBFNNs) to dispose the difficulty of the uncertain nonlinear functions. An improved Lyapunov function which relaxes the restrictions on design parameters is designed through introducing the lower bounds. By utilising the backstepping algorithm and the stability theory of Lyapunov function, an adaptive neural asymptotic tracking control strategy is designed. The control scheme can ensure all the states in the considered system are bounded and the tracking error inclines to zero asymptotically. Finally, simulation examples verify the validity of the designed strategy.},
  archive      = {J_IJSS},
  author       = {Huanqing Wang and Lingjia Zhao},
  doi          = {10.1080/00207721.2025.2471025},
  journal      = {International Journal of Systems Science},
  month        = {11},
  number       = {15},
  pages        = {3571-3586},
  shortjournal = {Int. J. Syst. Sci.},
  title        = {An improved adaptive neural asymptotic tracking control for pure-feedback nonlinear systems with disturbances},
  volume       = {56},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jasa">JASA - 59</h2>
<ul>
<li><details>
<summary>
(2025). Objective bayesian inference. <em>JASA</em>, <em>120</em>(550), 1321-1322. (<a href='https://doi.org/10.1080/01621459.2025.2454051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JASA},
  author       = {Jaeyong Lee},
  doi          = {10.1080/01621459.2025.2454051},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1321-1322},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Objective bayesian inference},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Soccer analytics: An introduction using r. <em>JASA</em>, <em>120</em>(550), 1320-1321. (<a href='https://doi.org/10.1080/01621459.2024.2435110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JASA},
  author       = {Alexander Aue},
  doi          = {10.1080/01621459.2024.2435110},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1320-1321},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Soccer analytics: An introduction using r},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Handbook of bayesian, fiducial, and frequentist inference. <em>JASA</em>, <em>120</em>(550), 1318-1320. (<a href='https://doi.org/10.1080/01621459.2025.2454048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JASA},
  author       = {Mengyang Gu},
  doi          = {10.1080/01621459.2025.2454048},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1318-1320},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Handbook of bayesian, fiducial, and frequentist inference},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep regression learning with optimal loss function. <em>JASA</em>, <em>120</em>(550), 1305-1317. (<a href='https://doi.org/10.1080/01621459.2024.2412364'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we develop a novel efficient and robust nonparametric regression estimator under a framework of a feedforward neural network (FNN). There are several interesting characteristics for the proposed estimator. First, the loss function is built upon an estimated maximum likelihood function, which integrates the information from observed data as well as the information from the data distribution. Consequently, the resulting estimator has desirable optimal properties, such as efficiency. Second, different from the traditional maximum likelihood estimation (MLE), the proposed method avoids the specification of the distribution, making it adaptable to various distributions such as heavy tails and multimodal or heterogeneous distributions. Third, the proposed loss function relies on probabilities rather than direct observations as in least square loss, contributing to the robustness of the proposed estimator. Finally, the proposed loss function involves a nonparametric regression function only. This enables the direct application of the existing packages, simplifying the computational and programming requirements. We establish the large sample property of the proposed estimator in terms of its excess risk and minimax near-optimal rate. The theoretical results demonstrate that the proposed estimator is equivalent to the true MLE where the density function is known in terms of excess risk. Our simulation studies show that the proposed estimator outperforms the existing methods based on prediction accuracy, efficiency and robustness. Particularly, it is comparable to the MLE with the known density and even gets slightly better as the sample size increases. This implies that the adaptive and data-driven loss function from the estimated density may offer an additional avenue for capturing valuable information. We further apply the proposed method to four real data examples, resulting in significantly reduced out-of-sample prediction errors compared to existing methods. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Xuancheng Wang and Ling Zhou and Huazhen Lin},
  doi          = {10.1080/01621459.2024.2412364},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1305-1317},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Deep regression learning with optimal loss function},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust permutation tests in linear instrumental variables regression. <em>JASA</em>, <em>120</em>(550), 1294-1304. (<a href='https://doi.org/10.1080/01621459.2024.2412363'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article develops permutation versions of identification-robust tests in linear instrumental variables regression. Unlike the existing randomization and rank-based tests in which independence between the instruments and the error terms is assumed, the permutation Anderson-Rubin (AR), Lagrange Multiplier (LM) and Conditional Likelihood Ratio (CLR) tests are asymptotically similar and robust to conditional heteroscedasticity under standard exclusion restriction, that is, the orthogonality between the instruments and the error terms. Moreover, when the instruments are independent of the structural error term, the permutation AR tests are exact, hence, robust to heavy tails. As such, these tests share the strengths of the rank-based tests and the wild bootstrap AR tests. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Purevdorj Tuvaandorj},
  doi          = {10.1080/01621459.2024.2412363},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1294-1304},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Robust permutation tests in linear instrumental variables regression},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A sparse beta regression model for network analysis. <em>JASA</em>, <em>120</em>(550), 1281-1293. (<a href='https://doi.org/10.1080/01621459.2024.2411073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For statistical analysis of network data, the 𝛽 -model has emerged as a useful tool, thanks to its flexibility in incorporating nodewise heterogeneity and theoretical tractability. To generalize the β -model, this article proposes the Sparse β -Regression Model (S β RM) that unites two research themes developed recently in modeling homophily and sparsity. In particular, we employ differential heterogeneity that assigns weights only to important nodes and propose penalized likelihood with an l 1 penalty for parameter estimation. While our estimation method is closely related to the LASSO method for logistic regression, we develop a new theory emphasizing the use of our model for dealing with a parameter regime that can handle sparse networks usually seen in practice. More interestingly, the resulting inference on the homophily parameter demands no debiasing normally employed in LASSO type estimation. We provide extensive simulation and data analysis to illustrate the use of the model. As a special case of our model, we extend the Erdős-Rényi model by including covariates and develop the associated statistical inference for sparse networks, which may be of independent interest. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Stefan Stein and Rui Feng and Chenlei Leng},
  doi          = {10.1080/01621459.2024.2411073},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1281-1293},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {A sparse beta regression model for network analysis},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Iterative methods for vecchia-laplace approximations for latent gaussian process models. <em>JASA</em>, <em>120</em>(550), 1267-1280. (<a href='https://doi.org/10.1080/01621459.2024.2410004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Latent Gaussian process (GP) models are flexible probabilistic nonparametric function models. Vecchia approximations are accurate approximations for GPs to overcome computational bottlenecks for large data, and the Laplace approximation is a fast method with asymptotic convergence guarantees to approximate marginal likelihoods and posterior predictive distributions for non-Gaussian likelihoods. Unfortunately, the computational complexity of combined Vecchia-Laplace approximations grows faster than linearly in the sample size when used in combination with direct solver methods such as the Cholesky decomposition. Computations with Vecchia-Laplace approximations can thus become prohibitively slow precisely when the approximations are usually the most accurate, that is, on large datasets. In this article, we present iterative methods to overcome this drawback. Among other things, we introduce and analyze several preconditioners, derive new convergence results, and propose novel methods for accurately approximating predictive variances. We analyze our proposed methods theoretically and in experiments with simulated and real-world data. In particular, we obtain a speed-up of an order of magnitude compared to Cholesky-based calculations and a 3-fold increase in prediction accuracy in terms of the continuous ranked probability score compared to a state-of-the-art method on a large satellite dataset. All methods are implemented in a free C++ software library with high-level Python and R packages. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Pascal Kündig and Fabio Sigrist},
  doi          = {10.1080/01621459.2024.2410004},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1267-1280},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Iterative methods for vecchia-laplace approximations for latent gaussian process models},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive learning of the latent space of wasserstein generative adversarial networks. <em>JASA</em>, <em>120</em>(550), 1254-1266. (<a href='https://doi.org/10.1080/01621459.2024.2408778'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative models based on latent variables, such as generative adversarial networks (GANs) and variational auto-encoders (VAEs), have gained lots of interests due to their impressive performance in many fields. However, many data such as natural images usually do not populate the ambient Euclidean space but instead reside in a lower-dimensional manifold. Thus an inappropriate choice of the latent dimension fails to uncover the structure of the data, possibly resulting in mismatch of latent representations and poor generative qualities. Toward addressing these problems, we propose a novel framework called the latent Wasserstein GAN (LWGAN) that fuses the Wasserstein auto-encoder and the Wasserstein GAN so that the intrinsic dimension of the data manifold can be adaptively learned by a modified informative latent distribution. We prove that there exist an encoder network and a generator network in such a way that the intrinsic dimension of the learned encoding distribution is equal to the dimension of the data manifold. We theoretically establish that our estimated intrinsic dimension is a consistent estimate of the true dimension of the data manifold. Meanwhile, we provide an upper bound on the generalization error of LWGAN, implying that we force the synthetic data distribution to be similar to the real data distribution from a population perspective. Comprehensive empirical experiments verify our framework and show that LWGAN is able to identify the correct intrinsic dimension under several scenarios, and simultaneously generate high-quality synthetic data by sampling from the learned latent distribution. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Yixuan Qiu and Qingyi Gao and Xiao Wang},
  doi          = {10.1080/01621459.2024.2408778},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1254-1266},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Adaptive learning of the latent space of wasserstein generative adversarial networks},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inferring covariance structure from multiple data sources via subspace factor analysis. <em>JASA</em>, <em>120</em>(550), 1239-1253. (<a href='https://doi.org/10.1080/01621459.2024.2408777'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Factor analysis provides a canonical framework for imposing lower-dimensional structure such as sparse covariance in high-dimensional data. High-dimensional data on the same set of variables are often collected under different conditions, for instance in reproducing studies across research groups. In such cases, it is natural to seek to learn the shared versus condition-specific structure. Existing hierarchical extensions of factor analysis have been proposed, but face practical issues including identifiability problems. To address these shortcomings, we propose a class of SUbspace Factor Analysis (SUFA) models, which characterize variation across groups at the level of a lower-dimensional subspace. We prove that the proposed class of SUFA models lead to identifiability of the shared versus group-specific components of the covariance, and study their posterior contraction properties. Taking a Bayesian approach, these contributions are developed alongside efficient posterior computation algorithms. Our sampler fully integrates out latent variables, is easily parallelizable and has complexity that does not depend on sample size. We illustrate the methods through application to integration of multiple gene expression datasets relevant to immunology. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Noirrit Kiran Chandra and David B. Dunson and Jason Xu},
  doi          = {10.1080/01621459.2024.2408777},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1239-1253},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Inferring covariance structure from multiple data sources via subspace factor analysis},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A model-agnostic graph neural network for integrating local and global information. <em>JASA</em>, <em>120</em>(550), 1225-1238. (<a href='https://doi.org/10.1080/01621459.2024.2404668'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have achieved promising performance in a variety of graph-focused tasks. Despite their success, however, existing GNNs suffer from two significant limitations: a lack of interpretability in their results due to their black-box nature, and an inability to learn representations of varying orders. To tackle these issues, we propose a novel Model-agnostic Graph Neural Network (MaGNet) framework, which is able to effectively integrate information of various orders, extract knowledge from high-order neighbors, and provide meaningful and interpretable results by identifying influential compact graph structures. In particular, MaGNet consists of two components: an estimation model for the latent representation of complex relationships under graph topology, and an interpretation model that identifies influential nodes, edges, and node features. Theoretically, we establish the generalization error bound for MaGNet via empirical Rademacher complexity, and demonstrate its power to represent layer-wise neighborhood mixing. We conduct comprehensive numerical studies using simulated data to demonstrate the superior performance of MaGNet in comparison to several state-of-the-art alternatives. Furthermore, we apply MaGNet to a real-world case study aimed at extracting task-critical information from brain activity data, thereby highlighting its effectiveness in advancing scientific research. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Wenzhuo Zhou and Annie Qu and Keiland W. Cooper and Norbert Fortin and Babak Shahbaba},
  doi          = {10.1080/01621459.2024.2404668},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1225-1238},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {A model-agnostic graph neural network for integrating local and global information},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimating higher-order mixed memberships via the l2,∞ tensor perturbation bound. <em>JASA</em>, <em>120</em>(550), 1214-1224. (<a href='https://doi.org/10.1080/01621459.2024.2404265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Higher-order multiway data is ubiquitous in machine learning and statistics and often exhibits community-like structures, where each component (node) along each different mode has a community membership associated with it. In this article we propose the sub-Gaussian) tensor mixed-membership blockmodel , a generalization of the tensor blockmodel positing that memberships need not be discrete, but instead are convex combinations of latent communities. We establish the identifiability of our model and propose a computationally efficient estimation procedure based on the higher-order orthogonal iteration algorithm (HOOI) for tensor SVD composed with a simplex corner-finding algorithm. We then demonstrate the consistency of our estimation procedure by providing a per-node error bound under sub-Gaussian noise, which showcases the effect of higher-order structures on estimation accuracy. To prove our consistency result, we develop the l 2 , ∞ tensor perturbation bound for HOOI under independent, heteroscedastic, sub-Gaussian noise that may be of independent interest. Our analysis uses a novel leave-one-out construction for the iterates, and our bounds depend only on spectral properties of the underlying low-rank tensor under nearly optimal signal-to-noise ratio conditions such that tensor SVD is computationally feasible. Finally, we apply our methodology to real and simulated data, demonstrating some effects not identifiable from the model with discrete community memberships. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Joshua Agterberg and Anru R. Zhang},
  doi          = {10.1080/01621459.2024.2404265},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1214-1224},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Estimating higher-order mixed memberships via the l2,∞ tensor perturbation bound},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive transfer learning framework for functional classification. <em>JASA</em>, <em>120</em>(550), 1201-1213. (<a href='https://doi.org/10.1080/01621459.2024.2403788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we study the transfer learning problem in functional classification, aiming to improve the classification accuracy of the target data by leveraging information from related source datasets. To facilitate transfer learning, we propose a novel transferability function tailored for classification problems, enabling a more accurate evaluation of the similarity between source and target dataset distributions. Interestingly, we find that a source dataset can offer more substantial benefits under certain conditions than another dataset with an identical distribution to the target dataset. This observation renders the commonly-used debiasing step in the parameter-based transfer learning algorithm unnecessary under some circumstances to the classification problem. In particular, we propose two adaptive transfer learning algorithms based on the functional Distance Weighted Discrimination (DWD) classifier for scenarios with and without prior knowledge regarding informative sources. Furthermore, we establish the upper bound on the excess risk of the proposed classifiers, providing the statistical gain via transfer learning mathematically provable. Simulation studies are conducted to thoroughly examine the finite-sample performance of the proposed algorithms. Finally, we implement the proposed method to Beijing air-quality data, and significantly improve the prediction of the PM 2.5 level of a target station by effectively incorporating information from source datasets. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Caihong Qin and Jinhan Xie and Ting Li and Yang Bai},
  doi          = {10.1080/01621459.2024.2403788},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1201-1213},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {An adaptive transfer learning framework for functional classification},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large-scale low-rank gaussian process prediction with support points. <em>JASA</em>, <em>120</em>(550), 1189-1200. (<a href='https://doi.org/10.1080/01621459.2024.2403188'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-rank approximation is a popular strategy to tackle the “big n problem” associated with large-scale Gaussian process regressions. Basis functions for developing low-rank structures are crucial and should be carefully specified. Predictive processes simplify the problem by inducing basis functions with a covariance function and a set of knots. The existing literature suggests certain practical implementations of knot selection and covariance estimation; however, theoretical foundations explaining the influence of these two factors on predictive processes are lacking. In this article, the asymptotic prediction performance of the predictive process and Gaussian process predictions are derived and the impacts of the selected knots and estimated covariance are studied. The use of support points as knots, which best represent data locations, is advocated. Extensive simulation studies demonstrate the superiority of support points and verify our theoretical results. Real data of precipitation and ozone are used as examples, and the efficiency of our method over other widely used low-rank approximation methods is verified. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Yan Song and Wenlin Dai and Marc G. Genton},
  doi          = {10.1080/01621459.2024.2403188},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1189-1200},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Large-scale low-rank gaussian process prediction with support points},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-based clustering of categorical data based on the hamming distance. <em>JASA</em>, <em>120</em>(550), 1178-1188. (<a href='https://doi.org/10.1080/01621459.2024.2402568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A model-based approach is developed for clustering categorical data with no natural ordering. The proposed method exploits the Hamming distance to define a family of probability mass functions to model the data. The elements of this family are then considered as kernels of a finite mixture model with an unknown number of components. Conjugate Bayesian inference has been derived for the parameters of the Hamming distribution model. The mixture is framed in a Bayesian nonparametric setting, and a transdimensional blocked Gibbs sampler is developed to provide full Bayesian inference on the number of clusters, their structure, and the group-specific parameters, facilitating the computation with respect to customary reversible jump algorithms. The proposed model encompasses a parsimonious latent class model as a special case when the number of components is fixed. Model performances are assessed via a simulation study and reference datasets, showing improvements in clustering recovery over existing approaches. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Raffaele Argiento and Edoardo Filippi-Mazzola and Lucia Paci},
  doi          = {10.1080/01621459.2024.2402568},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1178-1188},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Model-based clustering of categorical data based on the hamming distance},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neyman-pearson multi-class classification via cost-sensitive learning. <em>JASA</em>, <em>120</em>(550), 1164-1177. (<a href='https://doi.org/10.1080/01621459.2024.2402567'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing classification methods aim to minimize the overall misclassification error rate. However, in applications such as loan default prediction, different types of errors can have varying consequences. To address this asymmetry issue, two popular paradigms have been developed: the Neyman-Pearson (NP) paradigm and the cost-sensitive (CS) paradigm. Previous studies on the NP paradigm have primarily focused on the binary case, while the multi-class NP problem poses a greater challenge due to its unknown feasibility. In this work, we tackle the multi-class NP problem by establishing a connection with the CS problem via strong duality and propose two algorithms. We extend the concept of NP oracle inequalities, crucial in binary classifications, to NP oracle properties in the multi-class context. Our algorithms satisfy these NP oracle properties under certain conditions. Furthermore, we develop practical algorithms to assess the feasibility and strong duality in multi-class NP problems, which can offer practitioners the landscape of a multi-class NP problem with various target error levels. Simulations and real data studies validate the effectiveness of our algorithms. To our knowledge, this is the first study to address the multi-class NP problem with theoretical guarantees. The proposed algorithms have been implemented in the R package npcs , which is available on CRAN. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Ye Tian and Yang Feng},
  doi          = {10.1080/01621459.2024.2402567},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1164-1177},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Neyman-pearson multi-class classification via cost-sensitive learning},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On optimality of mallows model averaging. <em>JASA</em>, <em>120</em>(550), 1152-1163. (<a href='https://doi.org/10.1080/01621459.2024.2402566'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past decades, model averaging (MA) has attracted much attention as it has emerged as an alternative tool to the model selection (MS) statistical approach. Hansen introduced a Mallows model averaging (MMA) method with model weights selected by minimizing a Mallows’ C p criterion. The main theoretical justification for MMA is an asymptotic optimality (AOP), which states that the risk/loss of the resulting MA estimator is asymptotically equivalent to that of the best but infeasible averaged model. MMA’s AOP is proved in the literature by either constraining weights in a special discrete weight set or limiting the number of candidate models. In this work, it is first shown that under these restrictions, however, the optimal risk of MA becomes an unreachable target, and MMA may converge more slowly than MS. In this background, a foundational issue that has not been addressed is: When a suitably large set of candidate models is considered, and the model weights are not harmfully constrained, can the MMA estimator perform asymptotically as well as the optimal convex combination of the candidate models? We answer this question in both nested and non-nested settings. In the nested setting, we provide finite sample inequalities for the risk of MMA and show that without unnatural restrictions on the candidate models, MMA’s AOP holds in a general continuous weight set under certain mild conditions. In the non-nested setting, a sufficient condition and a negative result are established for the achievability of the optimal MA risk. Implications on minimax adaptivity are given as well. The results from simulations and real data analysis back up our theoretical findings. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Jingfu Peng and Yang Li and Yuhong Yang},
  doi          = {10.1080/01621459.2024.2402566},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1152-1163},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {On optimality of mallows model averaging},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust estimation for number of factors in high dimensional factor modeling via spearman correlation matrix. <em>JASA</em>, <em>120</em>(550), 1139-1151. (<a href='https://doi.org/10.1080/01621459.2024.2402565'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining the number of factors in high-dimensional factor modeling is essential but challenging, especially when the data are heavy-tailed. In this article, we introduce a new estimator based on the spectral properties of Spearman sample correlation matrix under the high-dimensional setting, where both dimension and sample size tend to infinity proportionally. Our estimator is robust against heavy tails in either the common factors or idiosyncratic errors. The consistency of our estimator is established under mild conditions. Numerical experiments demonstrate the superiority of our estimator compared to existing methods. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Jiaxin Qiu and Zeng Li and Jianfeng Yao},
  doi          = {10.1080/01621459.2024.2402565},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1139-1151},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Robust estimation for number of factors in high dimensional factor modeling via spearman correlation matrix},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Valid inference after causal discovery. <em>JASA</em>, <em>120</em>(550), 1127-1138. (<a href='https://doi.org/10.1080/01621459.2024.2402089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal discovery and causal effect estimation are two fundamental tasks in causal inference. While many methods have been developed for each task individually, statistical challenges arise when applying these methods jointly: estimating causal effects after running causal discovery algorithms on the same data leads to “double dipping,” invalidating the coverage guarantees of classical confidence intervals. To this end, we develop tools for valid post-causal-discovery inference. Across empirical studies, we show that a naive combination of causal discovery and subsequent inference algorithms leads to highly inflated miscoverage rates; on the other hand, applying our method provides reliable coverage while allowing for a trade-off between causal discovery accuracy and confidence interval width. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Paula Gradu and Tijana Zrnic and Yixin Wang and Michael I. Jordan},
  doi          = {10.1080/01621459.2024.2402089},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1127-1138},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Valid inference after causal discovery},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving tensor regression by optimal model averaging. <em>JASA</em>, <em>120</em>(550), 1115-1126. (<a href='https://doi.org/10.1080/01621459.2024.2398164'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensors have broad applications in neuroimaging, data mining, digital marketing, etc. CANDECOMP/PARAFAC (CP) tensor decomposition can effectively reduce the number of parameters to gain dimensionality-reduction and thus plays a key role in tensor regression. However, in CP decomposition, there is uncertainty about which rank to use. In this article, we develop a model averaging method to handle this uncertainty by weighting the estimators from candidate tensor regression models with different ranks. When all candidate models are misspecified, we prove that the model averaging estimator is asymptotically optimal. When correct models are included in the set of candidate models, we prove the consistency of parameters and the convergence of the model averaging weight. Simulations and empirical studies illustrate that the proposed method has superiority over the competition methods and has promising applications. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Qiushi Bu and Hua Liang and Xinyu Zhang and Jiahui Zou},
  doi          = {10.1080/01621459.2024.2398164},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1115-1126},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Improving tensor regression by optimal model averaging},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Off-policy evaluation in doubly inhomogeneous environments. <em>JASA</em>, <em>120</em>(550), 1102-1114. (<a href='https://doi.org/10.1080/01621459.2024.2395593'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work aims to study off-policy evaluation (OPE) under scenarios where two key reinforcement learning (RL) assumptions—temporal stationarity and individual homogeneity are both violated. To handle the “double inhomogeneities”, we propose a class of latent factor models for the reward and transition functions, under which we develop a general OPE framework that consists of both model-based and model-free approaches. To our knowledge, this is the first article that develops statistically sound OPE methods in offline RL with double inhomogeneities. It contributes to a deeper understanding of OPE in environments, where standard RL assumptions are not met, and provides several practical approaches in these settings. We establish the theoretical properties of the proposed value estimators and empirically show that our approach outperforms state-of-the-art methods. Finally, we illustrate our method on a dataset from the Medical Information Mart for Intensive Care. An R implementation of the proposed procedure is available at https://github.com/ZeyuBian/2FEOPE . Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Zeyu Bian and Chengchun Shi and Zhengling Qi and Lan Wang},
  doi          = {10.1080/01621459.2024.2395593},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1102-1114},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Off-policy evaluation in doubly inhomogeneous environments},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-based causal feature selection for general response types. <em>JASA</em>, <em>120</em>(550), 1090-1101. (<a href='https://doi.org/10.1080/01621459.2024.2395588'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discovering causal relationships from observational data is a fundamental yet challenging task. Invariant causal prediction (ICP, Peters, Bühlmann, and Meinshausen) is a method for causal feature selection which requires data from heterogeneous settings and exploits that causal models are invariant. ICP has been extended to general additive noise models and to nonparametric settings using conditional independence tests. However, the latter often suffer from low power (or poor Type I error control) and additive noise models are not suitable for applications in which the response is not measured on a continuous scale, but reflects categories or counts. Here, we develop transformation-model ( tram ) based ICP, allowing for continuous, categorical, count-type, and uninformatively censored responses (these model classes, generally, do not allow for identifiability when there is no exogenous heterogeneity). As an invariance test, we propose tram -GCM based on the expected conditional covariance between environments and score residuals with uniform asymptotic level guarantees. For the special case of linear shift tram s, we also consider tram -Wald, which tests invariance based on the Wald statistic. We provide an open-source R package tramicp and evaluate our approach on simulated data and in a case study investigating causal features of survival in critically ill patients. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Lucas Kook and Sorawit Saengkyongam and Anton Rask Lundborg and Torsten Hothorn and Jonas Peters},
  doi          = {10.1080/01621459.2024.2395588},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1090-1101},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Model-based causal feature selection for general response types},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zigzag path connects two monte carlo samplers: Hamiltonian counterpart to a piecewise deterministic markov process. <em>JASA</em>, <em>120</em>(550), 1077-1089. (<a href='https://doi.org/10.1080/01621459.2024.2395587'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zigzag and other piecewise deterministic Markov process samplers have attracted significant interest for their non-reversibility and other appealing properties for Bayesian posterior computation. Hamiltonian Monte Carlo is another state-of-the-art sampler, exploiting fictitious momentum to guide Markov chains through complex target distributions. We establish an important connection between the zigzag sampler and a variant of Hamiltonian Monte Carlo based on Laplace-distributed momentum. The position and velocity component of the corresponding Hamiltonian dynamics travels along a zigzag path paralleling the Markovian zigzag process; however, the dynamics is non-Markovian in this position-velocity space as the momentum component encodes non-immediate pasts. This information is partially lost during a momentum refreshment step, in which we preserve its direction but resample magnitude. In the limit of increasingly frequent momentum refreshments, we prove that Hamiltonian zigzag converges strongly to its Markovian counterpart. This theoretical insight suggests that, when retaining full momentum information, Hamiltonian zigzag can better explore target distributions with highly correlated parameters by suppressing the diffusive behavior of Markovian zigzag. We corroborate this intuition by comparing performance of the two zigzag cousins on high-dimensional truncated multivariate Gaussians, including a 11,235-dimensional target arising from a Bayesian phylogenetic multivariate probit modeling of HIV virus data. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Akihiko Nishimura and Zhenyu Zhang and Marc A. Suchard},
  doi          = {10.1080/01621459.2024.2395587},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1077-1089},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Zigzag path connects two monte carlo samplers: Hamiltonian counterpart to a piecewise deterministic markov process},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monte carlo inference for semiparametric bayesian regression. <em>JASA</em>, <em>120</em>(550), 1063-1076. (<a href='https://doi.org/10.1080/01621459.2024.2395586'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data transformations are essential for broad applicability of parametric regression models. However, for Bayesian analysis, joint inference of the transformation and model parameters typically involves restrictive parametric transformations or nonparametric representations that are computationally inefficient and cumbersome for implementation and theoretical analysis, which limits their usability in practice. This article introduces a simple, general, and efficient strategy for joint posterior inference of an unknown transformation and all regression model parameters. The proposed approach directly targets the posterior distribution of the transformation by linking it with the marginal distributions of the independent and dependent variables, and then deploys a Bayesian nonparametric model via the Bayesian bootstrap. Crucially, this approach delivers (a) joint posterior consistency under general conditions, including multiple model misspecifications, and (b) efficient Monte Carlo (not Markov chain Monte Carlo) inference for the transformation and all parameters for important special cases. These tools apply across a variety of data domains, including real-valued, positive, and compactly-supported data. Simulation studies and an empirical application demonstrate the effectiveness and efficiency of this strategy for semiparametric Bayesian analysis with linear models, quantile regression, and Gaussian processes. The R package SeBR is available on CRAN. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Daniel R. Kowal and Bohan Wu},
  doi          = {10.1080/01621459.2024.2395586},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1063-1076},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Monte carlo inference for semiparametric bayesian regression},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal network pairwise comparison. <em>JASA</em>, <em>120</em>(550), 1048-1062. (<a href='https://doi.org/10.1080/01621459.2024.2393471'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are interested in the problem of two-sample network hypothesis testing: given two networks with the same set of nodes, we wish to test whether the underlying Bernoulli probability matrices of the two networks are the same or not. We propose Interlacing Balance Measure (IBM) as a new two-sample testing approach. We consider the Degree-Corrected Mixed-Membership (DCMM) model for undirected networks, where we allow severe degree heterogeneity, mixed-memberships, flexible sparsity levels, and weak signals. In such a broad setting, how to find a test that has a tractable limiting null and optimal testing performances is a challenging problem. We show that IBM is such a test: in a broad DCMM setting with only mild regularity conditions, IBM has N ( 0 , 1 ) as the limiting null and achieves the optimal phase transition. While the above is for undirected networks, IBM is a unified approach and is directly implementable for directed networks. For a broad directed-DCMM (extension of DCMM for directed networks) setting, we show that IBM has N ( 0 , 1 / 2 ) as the limiting null and continues to achieve the optimal phase transition. We have also applied IBM to the Enron email network and a gene co-expression network, with interesting results. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Jiashun Jin and Zheng Tracy Ke and Shengming Luo and Yucong Ma},
  doi          = {10.1080/01621459.2024.2393471},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1048-1062},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Optimal network pairwise comparison},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised triply robust inductive transfer learning. <em>JASA</em>, <em>120</em>(550), 1037-1047. (<a href='https://doi.org/10.1080/01621459.2024.2393463'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a Semi-supervised Triply Robust Inductive transFer LEarning (STRIFLE) approach, which integrates heterogeneous data from a label-rich source population and a label-scarce target population and uses a large amount of unlabeled data simultaneously to improve the learning accuracy in the target population. Specifically, we consider a high dimensional covariate shift setting and employ two nuisance models, a density ratio model and an imputation model, to combine transfer learning and surrogate-assisted semi-supervised learning strategies effectively and achieve triple robustness. While the STRIFLE approach assumes the target and source populations to share the same conditional distribution of outcome Y given both the surrogate features S and predictors X , it allows the true underlying model of Y⏧ X to differ between the two populations due to the potential covariate shift in S and X . Different from double robustness, even if both nuisance models are misspecified or the distribution of Y⏧ S , X is not the same between the two populations when the shifted source population and the target population share enough similarities, the triply robust STRIFLE estimator can still partially use the source population when the shifted source population and the target population share enough similarities. Moreover, it is guaranteed to be no worse than the target-only surrogate-assisted semi-supervised estimator with an additional error term from transferability detection. These desirable properties of our estimator are established theoretically and verified in finite samples via extensive simulation studies. We use the STRIFLE estimator to train a Type II diabetes polygenic risk prediction model for the African American target population by transferring knowledge from electronic health records linked genomic data observed in a larger European source population. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Tianxi Cai and Mengyan Li and Molei Liu},
  doi          = {10.1080/01621459.2024.2393463},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1037-1047},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Semi-supervised triply robust inductive transfer learning},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Euclidean mirrors and dynamics in network time series. <em>JASA</em>, <em>120</em>(550), 1025-1036. (<a href='https://doi.org/10.1080/01621459.2024.2392912'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing changes in network evolution is central to statistical network inference. We consider a dynamic network model in which each node has an associated time-varying low-dimensional latent vector of feature data, and connection probabilities are functions of these vectors. Under mild assumptions, the evolution of latent vectors exhibits low-dimensional manifold structure under a suitable distance. This distance can be approximated by a measure of separation between the observed networks themselves, and there exist Euclidean representations for underlying network structure, as characterized by this distance. These Euclidean representations, called Euclidean mirrors, permit the visualization of network dynamics and lead to methods for change point and anomaly detection in networks. We illustrate our methodology with real and synthetic data, and identify change points corresponding to massive shifts in pandemic policies in a communication network of a large organization. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Avanti Athreya and Zachary Lubberts and Youngser Park and Carey Priebe},
  doi          = {10.1080/01621459.2024.2392912},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1025-1036},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Euclidean mirrors and dynamics in network time series},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Statistical inference for networks of high-dimensional point processes. <em>JASA</em>, <em>120</em>(550), 1014-1024. (<a href='https://doi.org/10.1080/01621459.2024.2392907'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fueled in part by recent applications in neuroscience, the multivariate Hawkes process has become a popular tool for modeling the network of interactions among high-dimensional point process data. While evaluating the uncertainty of the network estimates is critical in scientific applications, existing methodological and theoretical work has primarily addressed estimation. To bridge this gap, we develop a new statistical inference procedure for high-dimensional Hawkes processes. The key ingredient for the inference procedure is a new concentration inequality on the first- and second-order statistics for integrated stochastic processes, which summarize the entire history of the process. Combining recent martingale central limit theorem with the new concentration inequality, we then characterize the convergence rate of the test statistics in a continuous time domain. Finally, to account for potential non-stationarity of the process in practice, we extend our statistical inference procedure to a flexible class of Hawkes processes with time-varying background intensities and unknown transition functions. The finite sample validity of the inferential tools is illustrated via extensive simulations and further applied to a neuron spike train dataset. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Xu Wang and Mladen Kolar and Ali Shojaie},
  doi          = {10.1080/01621459.2024.2392907},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1014-1024},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Statistical inference for networks of high-dimensional point processes},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust regression with covariate filtering: Heavy tails and adversarial contamination. <em>JASA</em>, <em>120</em>(550), 1002-1013. (<a href='https://doi.org/10.1080/01621459.2024.2392906'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of linear regression where both covariates and responses are potentially (i) heavy-tailed and (ii) adversarially contaminated. Several computationally efficient estimators have been proposed for the simpler setting where the covariates are sub-Gaussian and uncontaminated; however, these estimators may fail when the covariates are either heavy-tailed or contain outliers. In this work, we show how to modify the Huber regression, least trimmed squares, and least absolute deviation estimators to obtain estimators which are simultaneously computationally and statistically efficient in the stronger contamination model. Our approach is quite simple, and consists of applying a filtering algorithm to the covariates, and then applying the classical robust regression estimators to the remaining data. We show that the Huber regression estimator achieves near-optimal error rates in this setting, whereas the least trimmed squares and least absolute deviation estimators can be made to achieve near-optimal error after applying a postprocessing step. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Ankit Pensia and Varun Jog and Po-Ling Loh},
  doi          = {10.1080/01621459.2024.2392906},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {1002-1013},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Robust regression with covariate filtering: Heavy tails and adversarial contamination},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Natural gradient variational bayes without fisher matrix analytic calculation and its inversion. <em>JASA</em>, <em>120</em>(550), 990-1001. (<a href='https://doi.org/10.1080/01621459.2024.2392904'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a method for efficiently approximating the inverse of the Fisher information matrix, a crucial step in achieving effective variational Bayes inference. A notable aspect of our approach is the avoidance of analytically computing the Fisher information matrix and its explicit inversion. Instead, we introduce an iterative procedure for generating a sequence of matrices that converge to the inverse of Fisher information. The natural gradient variational Bayes algorithm without analytic expression of the Fisher matrix and its inversion is provably convergent and achieves a convergence rate of order O ( log s / s ) , with s the number of iterations. We also obtain a central limit theorem for the iterates. Implementation of our method does not require storage of large matrices, and achieves a linear complexity in the number of variational parameters. Our algorithm exhibits versatility, making it applicable across a diverse array of variational Bayes domains, including Gaussian approximation and normalizing flow Variational Bayes. We offer a range of numerical examples to demonstrate the efficiency and reliability of the proposed variational Bayes method. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {A. Godichon-Baggioni and D. Nguyen and M.-N. Tran},
  doi          = {10.1080/01621459.2024.2392904},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {990-1001},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Natural gradient variational bayes without fisher matrix analytic calculation and its inversion},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient multiple change point detection and localization for high-dimensional quantile regression with heteroscedasticity. <em>JASA</em>, <em>120</em>(550), 976-989. (<a href='https://doi.org/10.1080/01621459.2024.2392903'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data heterogeneity is a challenging issue for modern statistical data analysis. There are different types of data heterogeneity in practice. In this article, we consider potential structural changes and complicated tail distributions. There are various existing methods proposed to handle either structural changes or heteroscedasticity. However, it is difficult to handle them simultaneously. To overcome this limitation, we consider statistically and computationally efficient change point detection and localization in high-dimensional quantile regression models. Our proposed framework is general and flexible since the change points and the underlying regression coefficients are allowed to vary across different quantile levels. The model parameters, including the data dimension, the number of change points, and the signal jump size, can be scaled with the sample size. Under this framework, we construct a novel two-step estimation of the number and locations of the change points as well as the underlying regression coefficients. Without any moment constraints on the error term, we present theoretical results, including consistency of the change point number, oracle estimation of change point locations, and estimation for the underlying regression coefficients with the optimal convergence rate. Finally, we present simulation results and an application to the S&P 100 dataset to demonstrate the advantage of the proposed method. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Xianru Wang and Bin Liu and Xinsheng Zhang and Yufeng Liu},
  doi          = {10.1080/01621459.2024.2392903},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {976-989},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Efficient multiple change point detection and localization for high-dimensional quantile regression with heteroscedasticity},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parallel sampling of decomposable graphs using markov chains on junction trees. <em>JASA</em>, <em>120</em>(550), 963-975. (<a href='https://doi.org/10.1080/01621459.2024.2388908'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian inference for undirected graphical models is mostly restricted to the class of decomposable graphs, as they enjoy a rich set of properties making them amenable to high-dimensional problems. While parameter inference is straightforward in this setup, inferring the underlying graph is a challenge driven by the computational difficulty in exploring the space of decomposable graphs. This work makes two contributions to address this problem. First, we provide sufficient and necessary conditions for when multi-edge perturbations maintain decomposability of the graph. Using these, we characterize a simple class of partitions that efficiently classify all edge perturbations by whether they maintain decomposability. Second, we propose a novel parallel nonreversible Markov chain Monte Carlo sampler for distributions over junction tree representations of the graph. At every step, the parallel sampler executes simultaneously all edge perturbations within a partition. Through simulations, we demonstrate the efficiency of our new edge perturbation conditions and class of partitions. We find that our parallel sampler yields improved mixing properties in comparison to the single-move variate, and outperforms current state-of-the-art methods in terms of accuracy and computational efficiency. The implementation of our work is available in the Python package parallelDG. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Mohamad Elmasri},
  doi          = {10.1080/01621459.2024.2388908},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {963-975},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Parallel sampling of decomposable graphs using markov chains on junction trees},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal network membership estimation under severe degree heterogeneity. <em>JASA</em>, <em>120</em>(550), 948-962. (<a href='https://doi.org/10.1080/01621459.2024.2388903'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real networks often have severe degree heterogeneity, with maximum, average, and minimum node degrees differing significantly. This article examines the impact of degree heterogeneity on statistical limits of network data analysis. Introducing the heterogeneity distribution (HD) under a degree-corrected mixed membership model, we show that the optimal rate of mixed membership estimation is an explicit functional of the HD. This result confirms that severe degree heterogeneity decelerates the error rate, even when the overall sparsity remains unchanged. To obtain a rate-optimal method, we modify an existing spectral algorithm, Mixed-SCORE, by adding a pre-PCA normalization step. This step normalizes the adjacency matrix by a diagonal matrix consisting of the b th power of node degrees, for some b ∈ R . We discover that b = 1/2 is universally favorable. The resulting spectral algorithm is rate-optimal for networks with arbitrary degree heterogeneity. A technical component in our proofs is entry-wise eigenvector analysis of the normalized graph Laplacian. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Zheng Tracy Ke and Jingming Wang},
  doi          = {10.1080/01621459.2024.2388903},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {948-962},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Optimal network membership estimation under severe degree heterogeneity},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Controlling the false split rate in tree-based aggregation. <em>JASA</em>, <em>120</em>(550), 935-947. (<a href='https://doi.org/10.1080/01621459.2024.2376285'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many domains, data measurements can naturally be associated with the leaves of a tree, expressing the relationships among these measurements. For example, companies belong to industries, which in turn belong to ever coarser divisions such as sectors; microbes are commonly arranged in a taxonomic hierarchy from species to kingdoms; street blocks belong to neighborhoods, which in turn belong to larger-scale regions. The problem of tree-based aggregation that we consider in this article asks which of these tree-defined subgroups of leaves should really be treated as a single entity and which of these entities should be distinguished from each other. We introduce the false split rate , an error measure that describes the degree to which subgroups have been split when they should not have been. While expressible as the false discovery rate in a special case, we show that these measures can be quite different for the general tree structures common in our setting. We then propose a multiple hypothesis testing algorithm for tree-based aggregation, which we prove controls this error measure. We focus on two main examples of tree-based aggregation, one which involves aggregating means and the other hich involves aggregating regression coefficients. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Simeng Shao and Jacob Bien and Adel Javanmard},
  doi          = {10.1080/01621459.2024.2376285},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {935-947},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Controlling the false split rate in tree-based aggregation},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust matrix completion with heavy-tailed noise. <em>JASA</em>, <em>120</em>(550), 922-934. (<a href='https://doi.org/10.1080/01621459.2024.2375037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies noisy low-rank matrix completion in the presence of heavy-tailed and possibly asymmetric noise, where we aim to estimate an underlying low-rank matrix given a set of highly incomplete noisy entries. Though the matrix completion problem has attracted much attention in the past decade, there is still lack of theoretical understanding when the observations are contaminated by heavy-tailed noises. Prior theory falls short of explaining the empirical results and is unable to capture the optimal dependence of the estimation error on the noise level. In this article, we adopt an adaptive Huber loss to accommodate heavy-tailed noise, which is robust against large and possibly asymmetric errors when the parameter in the Huber loss function is carefully designed to balance the Huberization biases and robustness to outliers. Then, we propose an efficient nonconvex algorithm via a balanced low-rank Burer-Monteiro matrix factorization and gradient descent with robust spectral initialization. We prove that under merely a bounded second-moment condition on the error distributions, rather than the sub-Gaussian assumption, the Euclidean errors of the iterates generated by the proposed algorithm decrease geometrically fast until achieving a minimax-optimal statistical estimation error, which has the same order as that in the sub-Gaussian case. The key technique behind this significant advancement is a powerful leave-one-out analysis framework. The theoretical results are corroborated by our numerical studies. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Bingyan Wang and Jianqing Fan},
  doi          = {10.1080/01621459.2024.2375037},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {922-934},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Robust matrix completion with heavy-tailed noise},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Statistical inference for Hüsler–Reiss graphical models through matrix completions. <em>JASA</em>, <em>120</em>(550), 909-921. (<a href='https://doi.org/10.1080/01621459.2024.2371978'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The severity of multivariate extreme events is driven by the dependence between the largest marginal observations. The Hüsler–Reiss distribution is a versatile model for this extremal dependence, and it is usually parameterized by a variogram matrix. In order to represent conditional independence relations and obtain sparse parameterizations, we introduce the novel Hüsler–Reiss precision matrix. Similarly to the Gaussian case, this matrix appears naturally in density representations of the Hüsler–Reiss Pareto distribution and encodes the extremal graphical structure through its zero pattern. For a given, arbitrary graph we prove the existence and uniqueness of the completion of a partially specified Hüsler–Reiss variogram matrix so that its precision matrix has zeros on non-edges in the graph. Using suitable estimators for the parameters on the edges, our theory provides the first consistent estimator of graph structured Hüsler–Reiss distributions. If the graph is unknown, our method can be combined with recent structure learning algorithms to jointly infer the graph and the corresponding parameter matrix. Based on our methodology, we propose new tools for statistical inference of sparse Hüsler–Reiss models and illustrate them on large flight delay data in the United States, as well as Danube river flow data. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Manuel Hentschel and Sebastian Engelke and Johan Segers},
  doi          = {10.1080/01621459.2024.2371978},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {909-921},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Statistical inference for Hüsler–Reiss graphical models through matrix completions},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contextual dynamic pricing with strategic buyers. <em>JASA</em>, <em>120</em>(550), 896-908. (<a href='https://doi.org/10.1080/01621459.2024.2370613'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized pricing, which involves tailoring prices based on individual characteristics, is commonly used by firms to implement a consumer-specific pricing policy. In this process, buyers can also strategically manipulate their feature data to obtain a lower price, incurring certain manipulation costs. Such strategic behavior can hinder firms from maximizing their profits. In this article, we study the contextual dynamic pricing problem with strategic buyers. The seller does not observe the buyer’s true feature, but a manipulated feature according to buyers’ strategic behavior. In addition, the seller does not observe the buyers’ valuation of the product, but only a binary response indicating whether a sale happens or not. Recognizing these challenges, we propose a strategic dynamic pricing policy that incorporates the buyers’ strategic behavior into the online learning to maximize the seller’s cumulative revenue. We first prove that existing nonstrategic pricing policies that neglect the buyers’ strategic behavior result in a linear Ω ( T ) regret with T the total time horizon, indicating that these policies are not better than a random pricing policy. We then establish an O ( T ) regret upper bound of our proposed policy and an Ω ( T ) regret lower bound for any pricing policy within our problem setting. This underscores the rate optimality of our policy. Importantly, our policy is not a mere amalgamation of existing dynamic pricing policies and strategic behavior handling algorithms. Our policy can also accommodate the scenario when the marginal cost of manipulation is unknown in advance. To account for it, we simultaneously estimate the valuation parameter and the cost parameter in the online pricing policy, which is shown to also achieve an O ( T ) regret bound. Extensive experiments support our theoretical developments and demonstrate the superior performance of our policy compared to other pricing policies that are unaware of the strategic behaviors. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Pangpang Liu and Zhuoran Yang and Zhaoran Wang and Will Wei Sun},
  doi          = {10.1080/01621459.2024.2370613},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {896-908},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Contextual dynamic pricing with strategic buyers},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synthetic likelihood in misspecified models. <em>JASA</em>, <em>120</em>(550), 884-895. (<a href='https://doi.org/10.1080/01621459.2024.2370594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian synthetic likelihood is a widely used approach for conducting Bayesian analysis in complex models where evaluation of the likelihood is infeasible but simulation from the assumed model is tractable. We analyze the behavior of the Bayesian synthetic likelihood posterior when the assumed model differs from the actual data generating process. We demonstrate that the Bayesian synthetic likelihood posterior can display a wide range of nonstandard behaviors depending on the level of model misspecification, including multimodality and asymptotic non-Gaussianity. Our results suggest that likelihood tempering, a common approach for robust Bayesian inference, fails for synthetic likelihood whilst recently proposed robust synthetic likelihood approaches can ameliorate this behavior and deliver reliable posterior inference under model misspecification. All results are illustrated using a simple running example. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {David T. Frazier and David J. Nott and Christopher Drovandi},
  doi          = {10.1080/01621459.2024.2370594},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {884-895},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Synthetic likelihood in misspecified models},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Supervised dynamic PCA: Linear dynamic forecasting with many predictors. <em>JASA</em>, <em>120</em>(550), 869-883. (<a href='https://doi.org/10.1080/01621459.2024.2370592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel dynamic forecasting method using a new supervised Principal Component Analysis (PCA) when a large number of predictors are available. The new supervised PCA provides an effective way to bridge the gap between predictors and the target variable of interest by scaling and combining the predictors and their lagged values, resulting in an effective dynamic forecasting. Unlike the traditional diffusion-index approach, which does not learn the relationships between the predictors and the target variable before conducting PCA, we first rescale each predictor according to their significance in forecasting the targeted variable in a dynamic fashion, and a PCA is then applied to a rescaled and additive panel, which establishes a connection between the predictability of the PCA factors and the target variable. We also propose to use penalized methods such as the LASSO to select the significant factors that have superior predictive power over the others. Theoretically, we show that our estimators are consistent and outperform the traditional methods in prediction under some mild conditions. We conduct extensive simulations to verify that the proposed method produces satisfactory forecasting results and outperforms most of the existing methods using the traditional PCA. An example of predicting U.S. macroeconomic variables using a large number of predictors showcases that our method fares better than most of the existing ones in applications. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Zhaoxing Gao and Ruey S. Tsay},
  doi          = {10.1080/01621459.2024.2370592},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {869-883},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Supervised dynamic PCA: Linear dynamic forecasting with many predictors},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced response envelope via envelope regularization. <em>JASA</em>, <em>120</em>(550), 859-868. (<a href='https://doi.org/10.1080/01621459.2024.2368844'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The response envelope model provides substantial efficiency gains over the standard multivariate linear regression by identifying the material part of the response to the model and by excluding the immaterial part. In this article, we propose the enhanced response envelope by incorporating a novel envelope regularization term based on a nonconvex manifold formulation. It is shown that the enhanced response envelope can yield better prediction risk than the original envelope estimator. The enhanced response envelope naturally handles high-dimensional data for which the original response envelope is not serviceable without necessary remedies. In an asymptotic high-dimensional regime where the ratio of the number of predictors over the number of samples converges to a nonzero constant, we characterize the risk function and reveal an interesting double descent phenomenon for the envelope model. A simulation study confirms our main theoretical findings. Simulations and real data applications demonstrate that the enhanced response envelope does have significantly improved prediction performance over the original envelope method, especially when the number of predictors is close to or moderately larger than the number of samples. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Oh-Ran Kwon and Hui Zou},
  doi          = {10.1080/01621459.2024.2368844},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {859-868},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Enhanced response envelope via envelope regularization},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tyranny-of-the-minority regression adjustment in randomized experiments. <em>JASA</em>, <em>120</em>(550), 846-858. (<a href='https://doi.org/10.1080/01621459.2024.2366043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regression adjustment is widely used in the analysis of randomized experiments to improve the estimation efficiency of the treatment effect. This article reexamines a weighted regression adjustment method termed t yranny- o f-the- m inority (ToM), wherein units in the minority group are given greater weights. We demonstrate that ToM regression adjustment is more robust than Lin ’s regression adjustment with treatment-covariate interactions, even though these two regression adjustment methods are asymptotically equivalent in completely randomized experiments. Moreover, ToM regression adjustment can be easily extended to stratified randomized experiments and completely randomized survey experiments. We obtain the design-based properties of the ToM regression-adjusted average treatment effect estimator under such designs. In particular, we show that the ToM regression-adjusted estimator improves the asymptotic estimation efficiency compared to the unadjusted estimator, even when the regression model is misspecified, and is optimal in the class of linearly adjusted estimators. We also study the asymptotic properties of various heteroscedasticity-robust standard errors and provide recommendations for practitioners. Simulation studies and real data analysis demonstrate ToM regression adjustment’s superiority over existing methods. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Xin Lu and Hanzhong Liu},
  doi          = {10.1080/01621459.2024.2366043},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {846-858},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Tyranny-of-the-minority regression adjustment in randomized experiments},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Test and measure for partial mean dependence based on machine learning methods. <em>JASA</em>, <em>120</em>(550), 833-845. (<a href='https://doi.org/10.1080/01621459.2024.2366030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is of importance to investigate the significance of a subset of covariates W for the response Y given covariates Z in regression modeling. To this end, we propose a significance test for the partial mean independence problem based on machine learning methods and data splitting. The test statistic converges to the standard Chi-squared distribution under the null hypothesis while it converges to a normal distribution under the fixed alternative hypothesis. Power enhancement and algorithm stability are also discussed. If the null hypothesis is rejected, we propose a partial Generalized Measure of Correlation (pGMC) to measure the partial mean dependence of Y given W after controlling for the nonlinear effect of Z . We present the appealing theoretical properties of the pGMC and establish the asymptotic normality of its estimator with the optimal root- N convergence rate. Furthermore, the valid confidence interval for the pGMC is also derived. As an important special case when there are no conditional covariates Z , we introduce a new test of overall significance of covariates for the response in a model-free setting. Numerical studies and real data analysis are also conducted to compare with existing approaches and to demonstrate the validity and flexibility of our proposed procedures. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Leheng Cai and Xu Guo and Wei Zhong},
  doi          = {10.1080/01621459.2024.2366030},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {833-845},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Test and measure for partial mean dependence based on machine learning methods},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonparametric multiple-output center-outward quantile regression. <em>JASA</em>, <em>120</em>(550), 818-832. (<a href='https://doi.org/10.1080/01621459.2024.2366029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building on recent measure-transportation-based concepts of multivariate quantiles, we are considering the problem of nonparametric multiple-output quantile regression. Our approach defines nested conditional center-outward quantile regression contours and regions with given conditional probability content, the graphs of which constitute nested center-outward quantile regression tubes with given unconditional probability content; these (conditional and unconditional) probability contents do not depend on the underlying distribution—an essential property of quantile concepts. Empirical counterparts of these concepts are constructed, yielding interpretable empirical contours, regions, and tubes which are shown to consistently reconstruct (in the Pompeiu-Hausdorff topology) their population versions. Our method is entirely nonparametric and performs well in simulations—with possible heteroscedasticity and nonlinear trends. Its potential as a data-analytic tool is illustrated on some real datasets. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Eustasio del Barrio and Alberto González Sanz and Marc Hallin},
  doi          = {10.1080/01621459.2024.2366029},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {818-832},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Nonparametric multiple-output center-outward quantile regression},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). False discovery rate control for structured multiple testing: Asymmetric rules and conformal Q-values. <em>JASA</em>, <em>120</em>(550), 805-817. (<a href='https://doi.org/10.1080/01621459.2024.2359739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effective utilization of structural information in data while ensuring statistical validity poses a significant challenge in false discovery rate (FDR) analyses. Conformal inference provides rigorous theory for grounding complex machine learning methods without relying on strong assumptions or highly idealized models. However, existing conformal methods have limitations in handling structured multiple testing, as their validity often requires the deployment of symmetric decision rules, which assume the exchangeability of data points and permutation-invariance of fitting algorithms. To overcome these limitations, we introduce the pseudo local index of significance (PLIS) procedure, which is capable of accommodating asymmetric rules and requires only pairwise exchangeability between the null conformity scores. We demonstrate that PLIS offers finite-sample guarantees in FDR control and the ability to assign higher weights to relevant data points. Numerical results confirm the effectiveness and robustness of PLIS and demonstrate improvements in power compared to existing model-free methods in various scenarios. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Zinan Zhao and Wenguang Sun},
  doi          = {10.1080/01621459.2024.2359739},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {805-817},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {False discovery rate control for structured multiple testing: Asymmetric rules and conformal Q-values},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mediation analysis with the mediator and outcome missing not at random. <em>JASA</em>, <em>120</em>(550), 794-804. (<a href='https://doi.org/10.1080/01621459.2024.2359132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mediation analysis is widely used for investigating direct and indirect causal pathways through which an effect arises. However, many mediation analysis studies are challenged by missingness in the mediator and outcome. In general, when the mediator and outcome are missing not at random, the direct and indirect effects are not identifiable without further assumptions. We study the identifiability of the direct and indirect effects under some interpretable mechanisms that allow for missing not at random in the mediator and outcome. We evaluate the performance of statistical inference under those mechanisms through simulation studies and illustrate the proposed methods via the National Job Corps Study. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Shuozhi Zuo and Debashis Ghosh and Peng Ding and Fan Yang},
  doi          = {10.1080/01621459.2024.2359132},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {794-804},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Mediation analysis with the mediator and outcome missing not at random},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed heterogeneity learning for generalized partially linear models with spatially varying coefficients. <em>JASA</em>, <em>120</em>(550), 779-793. (<a href='https://doi.org/10.1080/01621459.2024.2359131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial heterogeneity is of great importance in social, economic, and environmental science studies. The spatially varying coefficient model is a popular and effective spatial regression technique to address spatial heterogeneity. However, accounting for heterogeneity comes at the cost of reducing model parsimony. To balance flexibility and parsimony, this article develops a class of generalized partially linear spatially varying coefficient models which allow the inclusion of both constant and spatially varying effects of covariates. Another significant challenge in many applications comes from the enormous size of the spatial datasets collected from modern technologies. To tackle this challenge, we design a novel distributed heterogeneity learning (DHL) method based on bivariate spline smoothing over a triangulation of the domain. The proposed DHL algorithm has a simple, scalable, and communication-efficient implementation scheme that can almost achieve linear speedup. In addition, this article provides rigorous theoretical support for the DHL framework. We prove that the DHL constant coefficient estimators are asymptotic normal and the DHL spline estimators reach the same convergence rate as the global spline estimators obtained using the entire dataset. The proposed DHL method is evaluated through extensive simulation studies and analyses of U.S. loan application data. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Shan Yu and Guannan Wang and Li Wang},
  doi          = {10.1080/01621459.2024.2359131},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {779-793},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Distributed heterogeneity learning for generalized partially linear models with spatially varying coefficients},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Node-level community detection within edge exchangeable models for interaction processes. <em>JASA</em>, <em>120</em>(550), 764-778. (<a href='https://doi.org/10.1080/01621459.2024.2358560'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientists are increasingly interested in discovering community structure from modern relational data arising on large-scale social networks. While many methods have been proposed for learning community structure, few account for the fact that these modern networks arise from processes of interactions in the population. We introduce block edge exchangeable models (BEEM) for the study of interaction networks with latent node-level community structure. The block vertex components model (B-VCM) is derived as a canonical example. Several theoretical and practical advantages over traditional vertex-centric approaches are highlighted. In particular, BEEMs allow for sparse degree structure and power-law degree distributions within communities. Our theoretical analysis bounds the misspecification rate of block assignments while supporting simulations show the properties of the network can be recovered. A computationally tractable Gibbs algorithm is derived. We demonstrate the proposed model using post-comment interaction data from Talklife, a large-scale online peer-to-peer support network, and contrast the learned communities from those using standard algorithms including degree-corrected stochastic block models, popularity-adjusted block models, and weighted stochastic block models. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Yuhua Zhang and Walter Dempsey},
  doi          = {10.1080/01621459.2024.2358560},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {764-778},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Node-level community detection within edge exchangeable models for interaction processes},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Population-level balance in signed networks. <em>JASA</em>, <em>120</em>(550), 751-763. (<a href='https://doi.org/10.1080/01621459.2024.2356894'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistical network models are useful for understanding the underlying formation mechanism and characteristics of complex networks. However, statistical models for signed networks have been largely unexplored. In signed networks, there exist both positive (e.g., like, trust) and negative (e.g., dislike, distrust) edges, which are commonly seen in real-world scenarios. The positive and negative edges in signed networks lead to unique structural patterns, which pose challenges for statistical modeling. In this article, we introduce a statistically principled latent space approach for modeling signed networks and accommodating the well-known balance theory , that is, “the enemy of my enemy is my friend” and “the friend of my friend is my friend.” The proposed approach treats both edges and their signs as random variables, and characterizes the balance theory with a novel and natural notion of population-level balance. This approach guides us towards building a class of balanced inner-product models, and toward developing scalable algorithms via projected gradient descent to estimate the latent variables. We also establish non-asymptotic error rates for the estimates, which are further verified through simulation studies. In addition, we apply the proposed approach to an international relation network, which provides an informative and interpretable model-based visualization of countries during World War II. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Weijing Tang and Ji Zhu},
  doi          = {10.1080/01621459.2024.2356894},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {751-763},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Population-level balance in signed networks},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rate-optimal rank aggregation with private pairwise rankings. <em>JASA</em>, <em>120</em>(550), 737-750. (<a href='https://doi.org/10.1080/01621459.2025.2484843'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In various real-world scenarios, such as recommender systems and political surveys, pairwise rankings are commonly collected and used for rank aggregation to derive an overall ranking of items. However, preference rankings can reveal individuals’ personal preferences, highlighting the need to protect them from exposure in downstream analysis. In this article, we address the challenge of preserving privacy while ensuring the utility of rank aggregation based on pairwise rankings generated from a general comparison model. A common privacy protection strategy in practice is the use of the randomized response mechanism to perturb raw pairwise rankings. However, a critical challenge arises because the privatized rankings no longer adhere to the original model, resulting in significant bias in downstream rank aggregation tasks. To address this, we propose an adaptive debiasing method for rankings from the randomized response mechanism, ensuring consistent estimation of true preferences and enhancing the utility of downstream rank aggregation. Theoretically, we provide insights into the relationship between overall privacy guarantees and estimation errors in private ranking data, and establish minimax rates for estimation errors. This enables the determination of optimal privacy guarantees that balance consistency in rank aggregation with privacy protection. We also investigate convergence rates of expected ranking errors for partial and full ranking recovery, quantifying how privacy protection affects the specification of top- K item sets and complete rankings. Our findings are validated through extensive simulations and a real-world application. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Shirong Xu and Will Wei Sun and Guang Cheng},
  doi          = {10.1080/01621459.2025.2484843},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {737-750},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Rate-optimal rank aggregation with private pairwise rankings},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse bayesian group factor model for feature interactions in multiple count tables data. <em>JASA</em>, <em>120</em>(550), 723-736. (<a href='https://doi.org/10.1080/01621459.2025.2449721'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group factor models have been developed to infer relationships between multiple co-occurring multivariate continuous responses. Motivated by complex count data from multi-domain microbiome studies using next-generation sequencing, we develop a sparse Bayesian group factor model (Sp-BGFM) for multiple count table data that captures the interaction between microorganisms in different domains. Sp-BGFM uses a rounded kernel mixture model using a Dirichlet process (DP) prior with log-normal mixture kernels for count vectors. A group factor model is used to model the covariance matrix of the mixing kernel that describes microorganism interaction. We construct a Dirichlet-Horseshoe (Dir-HS) shrinkage prior and use it as a joint prior for factor loading vectors. Joint sparsity induced by a Dir-HS prior greatly improves the performance in high-dimensional applications. We further model the effects of covariates on microbial abundances using regression. The semiparametric model flexibly accommodates large variability in observed counts and excess zero counts and provides a basis for robust estimation of the interaction and covariate effects. We evaluate Sp-BGFM using simulation studies and real data analysis, comparing it to popular alternatives. Our results highlight the necessity of joint sparsity induced by the Dir-HS prior, and the benefits of a flexible DP model for baseline abundances. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Shuangjie Zhang and Yuning Shen and Irene A. Chen and Juhee Lee},
  doi          = {10.1080/01621459.2025.2449721},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {723-736},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Sparse bayesian group factor model for feature interactions in multiple count tables data},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GeoWarp: Warped spatial processes for inferring subsea sediment properties. <em>JASA</em>, <em>120</em>(550), 710-722. (<a href='https://doi.org/10.1080/01621459.2024.2445874'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For offshore structures like wind turbines, subsea infrastructure, pipelines, and cables, it is crucial to quantify the properties of the seabed sediments at a proposed site. However, data collection offshore is costly, so analysis of the seabed sediments must be made from measurements that are spatially sparse. Adding to this challenge, the structure of the seabed sediments exhibits both nonstationarity and anisotropy. To address these issues, we propose GeoWarp, a hierarchical spatial statistical modeling framework for inferring the 3-D geotechnical properties of subsea sediments. GeoWarp decomposes the seabed properties into a region-wide vertical mean profile (modeled using B-splines), and a nonstationary 3-D spatial Gaussian process. Process nonstationarity and anisotropy are accommodated by warping space in three dimensions and by allowing the process variance to change with depth. We apply GeoWarp to measurements of the seabed made using cone penetrometer tests (CPTs) at six sites on the North West Shelf of Australia. We show that GeoWarp captures the complex spatial distribution of the sediment properties, and produces realistic 3-D simulations suitable for downstream engineering analyses. Through cross-validation, we show that GeoWarp has predictive performance superior to other state-of-the-art methods, demonstrating its value as a tool in offshore geotechnical engineering. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Michael Bertolacci and Andrew Zammit-Mangion and Juan Valderrama Giraldo and Michael O’Neill and Fraser Bransby and Phil Watson},
  doi          = {10.1080/01621459.2024.2445874},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {710-722},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {GeoWarp: Warped spatial processes for inferring subsea sediment properties},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining broad and narrow case definitions in matched case-control studies: Firearms in the home and suicide risk. <em>JASA</em>, <em>120</em>(550), 698-709. (<a href='https://doi.org/10.1080/01621459.2024.2441519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Does having firearms in the home increase suicide risk? To test this hypothesis, a matched case-control study can be performed, in which suicide case subjects are compared to living controls who are similar in observed covariates in terms of their retrospective exposure to firearms at home. In this application, cases can be defined using a broad case definition (suicide) or a narrow case definition (suicide occurred at home). The broad case definition offers a larger number of cases, but the narrow case definition may offer a larger effect size, which can reduce sensitivity to bias from unmeasured confounding. However, when the goal is to test whether there is a treatment effect based on the broad case definition, restricting to the narrow case definition may introduce selection bias (i.e., bias due to selecting samples based on characteristics affected by the treatment) because exposure to firearms in the home may affect the location of suicide and thus the type of a case a subject is. We propose a new sensitivity analysis framework for combining broad and narrow case definitions in matched case-control studies, that considers the unmeasured confounding bias and selection bias simultaneously. We develop a valid randomization-based testing procedure using only the narrow case matched sets when the effect of the unmeasured confounder on receiving treatment and the effect of the treatment on case definition among the always-cases are controlled by sensitivity parameters. We then use the Bonferroni method to combine the testing procedures using the broad and narrow case definitions. With the proposed methods, we find robust evidence that having firearms at home increases suicide risk. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Ting Ye and Kan Chen and Dylan Small},
  doi          = {10.1080/01621459.2024.2441519},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {698-709},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Combining broad and narrow case definitions in matched case-control studies: Firearms in the home and suicide risk},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inferring causal effect of a digital communication strategy under a latent sequential ignorability assumption and treatment noncompliance. <em>JASA</em>, <em>120</em>(550), 685-697. (<a href='https://doi.org/10.1080/01621459.2024.2435655'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Organizations are increasingly relying on digital communications, such as targeted e-mails and mobile notifications, to engage with their audiences. Despite the evident advantages like cost-effectiveness and customization, assessing the effectiveness of such communications from observational data poses various statistical challenges. An immediate challenge is to adjust for targeting rules used in these communications. When digital communications involve a sequence of e-mails or notifications, however, further adjustments are required to correct for selection bias arising from previous communications influencing the subsequent ones and to deal with noncompliance issues, for example, not opening the e-mail. This article addresses these challenges in a study of promotional e-mail sequences sent by a U.S. retailer. We use a Bayesian methodology for causal inference from longitudinal data, considering targeting, noncompliance, and sequential confounding with unmeasured variables. The methodology serves three objectives: to evaluate the average treatment effect of any deterministic e-mailing strategy, to compare the effectiveness of these strategies across varying compliance behaviors, and to infer optimal strategies for distinct customer segments. Our analysis finds, among other things, that certain promotional e-mails effectively maintain engagement among individuals who have regularly received such incentives, and individuals who consistently open their e-mails exhibit reduced sensitivity to promotional content. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Yuki Ohnishi and Bikram Karmakar and Wreetabrata Kar},
  doi          = {10.1080/01621459.2024.2435655},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {685-697},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Inferring causal effect of a digital communication strategy under a latent sequential ignorability assumption and treatment noncompliance},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Immune profiling among colorectal cancer subtypes using dependent mixture models. <em>JASA</em>, <em>120</em>(550), 671-684. (<a href='https://doi.org/10.1080/01621459.2024.2427936'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Comparison of transcriptomic data across different conditions is of interest in many biomedical studies. In this article, we consider comparative immune cell profiling for early-onset (EO) versus late-onset (LO) colorectal cancer (CRC). EOCRC, diagnosed between ages 18–45, is a rising public health concern that needs to be urgently addressed. However, its etiology remains poorly understood. We work toward filling this gap by identifying homogeneous T cell sub-populations that show significantly distinct characteristics across the two tumor types, and identifying others that are shared between EOCRC and LOCRC. We develop dependent finite mixture models where immune subtypes enriched under a specific condition are characterized by terms in the mixture model with common atoms but distinct weights across conditions, whereas common subtypes are characterized by sharing both atoms and relative weights. The proposed model facilitates the desired comparison across conditions by introducing highly structured multi-layer Dirichlet priors. We illustrate inference with simulation studies and data examples. Results identify EO- and LO-enriched T cells subtypes whose biomarkers are found to be linked to mechanisms of tumor progression, and potentially motivate insights into treatment of CRC. Code implementing the proposed method is available at: https://github.com/YunshanDYS/SASCcode . Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Yunshan Duan and Shuai Guo and Wenyi Wang and Peter Müller},
  doi          = {10.1080/01621459.2024.2427936},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {671-684},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Immune profiling among colorectal cancer subtypes using dependent mixture models},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlocking retrospective prevalent information in EHRs—A revisit to the pairwise pseudolikelihood. <em>JASA</em>, <em>120</em>(550), 658-670. (<a href='https://doi.org/10.1080/01621459.2024.2427431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic health records offer abundant data on various diseases and health conditions, enabling researchers to explore the relationship between disease onset age and underlying risk factors. Unlike mortality data, the event of interest is nonterminal, hence, individuals can retrospectively report their disease-onset-age upon recruitment to the study. These individuals, diagnosed with the disease before entering the study, are termed “prevalent.” The ascertainment imposes a left truncation condition, also known as a “delayed entry,” because individuals had to survive a certain period before being eligible for enrollment. The standard method to accommodate delayed entry conditions on the entire history up to recruitment, hence, the retrospective prevalent failure times are conditioned upon and cannot participate in estimating the disease-onset-age distribution. Other methods that condition on less information and allow the incorporation of the prevalent observations either bring about numerical and computational difficulties or require statistical assumptions that are violated by most biobanks. This work presents a novel estimator of the coefficients in a regression model for the age-at-onset, successfully using the prevalent data. Asymptotic results are provided, and simulations are conducted to showcase the substantial efficiency gain. In particular, the method is highly useful in leveraging large-scale repositories for replication analysis of genetic variants. Indeed, analysis of urinary bladder cancer data reveals that the proposed approach yields about twice as many replicated discoveries compared to the popular approach. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Nir Keret and Malka Gorfine},
  doi          = {10.1080/01621459.2024.2427431},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {658-670},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Unlocking retrospective prevalent information in EHRs—A revisit to the pairwise pseudolikelihood},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatio-temporal modeling for record-breaking temperature events in spain. <em>JASA</em>, <em>120</em>(550), 645-657. (<a href='https://doi.org/10.1080/01621459.2024.2427430'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Record-breaking temperature events are now very frequently in the news, viewed as evidence of climate change. With this as motivation, we undertake the first substantial spatial modeling investigation of temperature record-breaking across years for any given day within the year. We work with a dataset consisting of over 60 years (1960–2021) of daily maximum temperatures across peninsular Spain. Formal statistical analysis of record-breaking events is an area that has received attention primarily within the probability community, dominated by results for the stationary record-breaking setting with some additional work addressing trends. Such effort is inadequate for analyzing actual record-breaking data. Resulting from novel and detailed exploratory data analysis, we propose rich hierarchical conditional modeling of the indicator events which define record-breaking sequences. After suitable model selection, we discover explicit trend behavior, necessary autoregression, significance of distance to the coast, useful interactions, helpful spatial random effects, and very strong daily random effects. Illustratively, the model estimates that global warming trends have increased the number of records expected in the past decade almost 2-fold, 1.93 ( 1.89 , 1.98 ) , but also estimates highly differentiated climate warming rates in space and by season. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Jorge Castillo-Mateo and Alan E. Gelfand and Zeus Gracia-Tabuenca and Jesús Asín and Ana C. Cebrián},
  doi          = {10.1080/01621459.2024.2427430},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {645-657},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Spatio-temporal modeling for record-breaking temperature events in spain},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ℓ1-based bayesian ideal point model for multidimensional politics. <em>JASA</em>, <em>120</em>(550), 631-644. (<a href='https://doi.org/10.1080/01621459.2024.2425461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ideal point estimation methods in the social sciences lack a principled approach for identifying multidimensional ideal points. We present a novel method for estimating multidimensional ideal points based on l 1 distance. In the Bayesian framework, the use of l 1 distance transforms the invariance problem of infinite rotational turns into the signed perpendicular problem, yielding posterior estimates that contract around a small area. Our simulation shows that the proposed method successfully recovers planted multidimensional ideal points in a variety of settings including non-partisan, two-party, and multi-party systems. The proposed method is applied to the analysis of roll call data from the United States House of Representatives during the late Gilded Age (1891–1899) when legislative coalitions were distinguished not only by partisan divisions but also by sectional divisions that ran across party lines. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Sooahn Shin and Johan Lim and Jong Hee Park},
  doi          = {10.1080/01621459.2024.2425461},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {631-644},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {ℓ1-based bayesian ideal point model for multidimensional politics},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A physics-informed, deep double reservoir network for forecasting boundary layer velocity. <em>JASA</em>, <em>120</em>(550), 618-630. (<a href='https://doi.org/10.1080/01621459.2024.2422131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When a fluid flows over a solid surface, it creates a thin boundary layer where the flow velocity is influenced by the surface through viscosity, and can transition from laminar to turbulent at sufficiently high speeds. Understanding and forecasting the fluid dynamics under these conditions is one of the most challenging scientific problems in fluid dynamics. It is therefore of high interest to formulate models able to capture the nonlinear spatio-temporal velocity structure as well as produce forecasts in a computationally efficient manner. Traditional statistical approaches are limited in their ability to produce timely forecasts of complex, nonlinear spatio-temporal structures which are at the same time able to incorporate the underlying flow physics. In this work, we propose a model to accurately forecast boundary layer velocities with a deep double reservoir computing network which is capable of capturing the complex, nonlinear dynamics of the boundary layer while at the same time incorporating physical constraints via a penalty obtained by a Partial Differential Equation (PDE). Simulation studies on a one-dimensional viscous fluid demonstrate how the proposed model is able to produce accurate forecasts while simultaneously accounting for energy loss. The application focuses on boundary layer data in a water tunnel with a PDE penalty derived from an appropriate simplification of the Navier-Stokes equations, showing improved forecasting by the proposed approach in terms of mass conservation and variability of velocity fluctuation against non-physics-informed methods. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Matthew Bonas and David H. Richter and Stefano Castruccio},
  doi          = {10.1080/01621459.2024.2422131},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {618-630},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {A physics-informed, deep double reservoir network for forecasting boundary layer velocity},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Testing a large number of composite null hypotheses using conditionally symmetric multidimensional gaussian mixtures in genome-wide studies. <em>JASA</em>, <em>120</em>(550), 605-617. (<a href='https://doi.org/10.1080/01621459.2024.2422124'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal mediation, pleiotropy, and replication analyses are three highly popular genetic study designs. Although these analyses address different scientific questions, the underlying statistical inference problems all involve large-scale testing of composite null hypotheses. The goal is to determine whether all null hypotheses—as opposed to at least one—in a set of individual tests should simultaneously be rejected. Recently, various methods have been proposed for each of these situations, including an appealing two-group empirical Bayes approach that calculates local false discovery rates (lfdr). However, lfdr estimation is difficult due to the need for multivariate density estimation. Furthermore, the multiple testing rules for the empirical Bayes lfdr approach can disagree with conventional frequentist z-statistics, which is troubling for a field that ubiquitously uses summary statistics. This work proposes a framework to unify two-group testing in genetic association composite null settings, the conditionally symmetric multidimensional Gaussian mixture model (csmGmm). The csmGmm is shown to demonstrate more robust operating characteristics than recently-proposed alternatives. Crucially, the csmGmm also offers interpretability guarantees by harmonizing lfdr and z-statistic testing rules. We extend the base csmGmm to cover each of the mediation, pleiotropy, and replication settings, and we prove that the lfdr z-statistic agreement holds in each situation. We apply the model to a collection of translational lung cancer genetic association studies that motivated this work. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Ryan Sun and Zachary R. McCaw and Xihong Lin},
  doi          = {10.1080/01621459.2024.2422124},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {605-617},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Testing a large number of composite null hypotheses using conditionally symmetric multidimensional gaussian mixtures in genome-wide studies},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Space-time extremes of severe U.S. thunderstorm environments. <em>JASA</em>, <em>120</em>(550), 591-604. (<a href='https://doi.org/10.1080/01621459.2024.2421582'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Severe thunderstorms cause substantial economic and human losses in the United States. Simultaneous high values of convective available potential energy (CAPE) and storm relative helicity (SRH) are favorable to severe weather, and both they and the composite variable PROD = CAPE × SRH can be used as indicators of severe thunderstorm activity. Their extremal spatial dependence exhibits temporal non-stationarity due to seasonality and large-scale atmospheric signals such as El Niño-Southern Oscillation (ENSO). In order to investigate this, we introduce a space-time model based on a max-stable, Brown–Resnick, field whose range depends on ENSO and on time through a tensor product spline. We also propose a max-stability test based on empirical likelihood and the bootstrap. The marginal and dependence parameters must be estimated separately owing to the complexity of the model, and we develop a bootstrap-based model selection criterion that accounts for the marginal uncertainty when choosing the dependence model. In the case study, the out-sample performance of our model is good. We find that extremes of PROD, CAPE, and SRH are generally more localized in summer and, in some regions, less localized during El Niño and La Niña events, and give meteorological interpretations of these phenomena. Supplementary materials for this article are available online, including a standardized description of the materials available for reproducing the work.},
  archive      = {J_JASA},
  author       = {Jonathan Koh and Erwan Koch and Anthony C. Davison},
  doi          = {10.1080/01621459.2024.2421582},
  journal      = {Journal of the American Statistical Association},
  month        = {4},
  number       = {550},
  pages        = {591-604},
  shortjournal = {J. Am. Stat. Assoc.},
  title        = {Space-time extremes of severe U.S. thunderstorm environments},
  volume       = {120},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jbes">JBES - 19</h2>
<ul>
<li><details>
<summary>
(2025). Another look at dependence: The most predictable aspects of time series. <em>JBES</em>, <em>43</em>(3), 723-736. (<a href='https://doi.org/10.1080/07350015.2024.2424345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Serial dependence and predictability are two sides of the same coin. The literature has considered alternative measures of these two fundamental concepts. In this article, we aim to distill the most predictable aspect of a univariate time series, that is, the one for which predictability is optimized. Our target measure is the mutual information between the past and future of a random process, a broad measure of predictability that takes into account all future forecast horizons, rather than focusing on the one-step-ahead prediction error mean square error. The most predictable aspect is defined as the measurable transformation of the series that maximizes the mutual information between past and future. This transformation arises from the linear combination of a set of basis functions localized at the quantiles of the unconditional distribution of the process. The mutual information is estimated as a function of the sample partial autocorrelations, using a semiparametric method that estimates an infinite sum by a regularized finite sum. The second most predictable aspect can also be defined, subject to suitable orthogonality restrictions. Finally, we illustrate the use of the most predictable aspect for testing the null hypothesis of no predictability and for point and interval prediction of the original time series.},
  archive      = {J_JBES},
  author       = {Tommaso Proietti},
  doi          = {10.1080/07350015.2024.2424345},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {723-736},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Another look at dependence: The most predictable aspects of time series},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Calibrated equilibrium estimation and double selection for high-dimensional partially linear measurement error models. <em>JBES</em>, <em>43</em>(3), 710-722. (<a href='https://doi.org/10.1080/07350015.2024.2422982'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practice, measurement error data is frequently encountered and needs to be handled appropriately. As a result of additional bias induced by measurement error, many existing estimation methods fail to achieve satisfactory performances. This article studies high-dimensional partially linear measurement error models. It proposes a calibrated equilibrium (CARE) estimation method to calibrate the bias caused by measurement error and overcomes the technical difficulty of the objective function unbounded from below in high-dimensional cases due to non-convexity. To facilitate the applications of the CARE estimation method, a bootstrap approach for approximating the covariance matrix of measurement errors is introduced. For the high-dimensional or ultra-high dimensional partially linear measurement error models, a novel multiple testing method, the calibrated equilibrium multiple double selection (CARE–MUSE) algorithm, is proposed to control the false discovery rate (FDR). Under certain regularity conditions, we derive the oracle inequalities for estimation error and prediction risk, along with an upper bound on the number of falsely discovered signs for the CARE estimator. We further establish the convergence rate of the nonparametric function estimator. In addition, FDR and power guarantee for the CARE–MUSE algorithm are investigated under a weaker minimum signal condition, which is insufficient for the CARE estimator to achieve sign consistency. Extensive simulation studies and a real data application demonstrate the satisfactory finite sample performance of the proposed methods.},
  archive      = {J_JBES},
  author       = {Jingxuan Luo and Gaorong Li and Heng Peng and Lili Yue},
  doi          = {10.1080/07350015.2024.2422982},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {710-722},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Calibrated equilibrium estimation and double selection for high-dimensional partially linear measurement error models},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive kernel-based structural change test for copulas. <em>JBES</em>, <em>43</em>(3), 696-709. (<a href='https://doi.org/10.1080/07350015.2024.2422980'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a structural change test for copula models based on the kernel smoothing method. The proposed approach enables adaptable estimation of the dynamic marginal distributions, either parametrically or semi-parametrically. The test statistic is formulated via the weighted quadratic distance between the local smoothing copula and the empirical copula function, using pseudo-observations of marginal distributions. The test statistic is pivotal with an asymptotic standard Normal distribution, irrespective of the marginal distributions, parameters, and estimations, and is consistent against a wide range of smoothly transitioning structural changes as well as abrupt structural breaks for copula models. Monte Carlo simulations show that the test performs well in finite samples and outperforms existing tests in the case of periodic changes.},
  archive      = {J_JBES},
  author       = {Xiaohui Lu and Yahong Zhou},
  doi          = {10.1080/07350015.2024.2422980},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {696-709},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {An adaptive kernel-based structural change test for copulas},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining instrumental variable estimators for a panel data model with factors. <em>JBES</em>, <em>43</em>(3), 684-695. (<a href='https://doi.org/10.1080/07350015.2024.2421991'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the estimation of factor-augmented panel data models using observed measurements to proxy for unobserved factors or loadings and explore the use of internal instruments to address the resulting endogeneity. The main challenge consists in that economic theory rarely provides insights into which measurements to choose as proxies when several are available. To overcome this problem, we propose a new class of estimators that are linear combinations of instrumental variable estimators and establish large sample results. We also show that an optimal weighting scheme exists, leading to efficiency gains relative to an instrumental variable estimator. Simulations show that the proposed approach performs better than existing methods. We illustrate the new method using data on test scores across U.S. school districts.},
  archive      = {J_JBES},
  author       = {Matthew Harding and Carlos Lamarche and Chris Muris},
  doi          = {10.1080/07350015.2024.2421991},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {684-695},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Combining instrumental variable estimators for a panel data model with factors},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural phillips curve and a deep output gap. <em>JBES</em>, <em>43</em>(3), 669-683. (<a href='https://doi.org/10.1080/07350015.2024.2421279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many problems plague empirical Phillips curves (PCs). Among them is the hurdle that the two key components, inflation expectations and the output gap, are both unobserved. Traditional remedies include proxying for the absentees or extracting them via assumptions-heavy filtering procedures. I propose an alternative route: a Hemisphere Neural Network (HNN) whose architecture yields a final layer where components can be interpreted as latent states within a Neural PC. First, HNN conducts the supervised estimation of nonlinearities that arise when translating a high-dimensional set of observed regressors into latent states. Second, forecasts are economically interpretable. Among other findings, the contribution of real activity to inflation appears understated in traditional PCs. In contrast, HNN captures the 2021 upswing in inflation and attributes it to a large positive output gap starting from late 2020. The unique path of HNN’s gap comes from dispensing with unemployment and GDP in favor of an amalgam of nonlinearly processed alternative tightness indicators.},
  archive      = {J_JBES},
  author       = {Philippe Goulet Coulombe},
  doi          = {10.1080/07350015.2024.2421279},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {669-683},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A neural phillips curve and a deep output gap},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Group sparse β-model for network. <em>JBES</em>, <em>43</em>(3), 657-668. (<a href='https://doi.org/10.1080/07350015.2024.2418849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparsity, homogeneity, and heterogeneity are three important characteristics of many real-life networks. The recently proposed Sparse β -Model divides nodes into core ones and peripheral ones to accommodate sparsity, but the parameters of core nodes are assumed to be of similar magnitude, which may not be in line with applications. In this article, we propose the Group Sparse β -Model that splits the core nodes into groups and assumes different orders of magnitude of parameters in different groups, accounting for the heterogeneity among core nodes. When the groups are known, we provide consistent and asymptotically normal moment estimators of the parameters that control the global and local density. Based on that, consistency and asymptotic normality of the maximum likelihood estimators of the remaining parameters are derived. We also establish finite-sample error bounds results. When the groups are unknown, a ratio method is proposed to detect groups, which is computationally efficient. Simulations show competitive results and the analysis of a corporate inter-relationships network illustrates the usefulness of the proposed model.},
  archive      = {J_JBES},
  author       = {Zhonghan Wang and Junlong Zhao},
  doi          = {10.1080/07350015.2024.2418849},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {657-668},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Group sparse β-model for network},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Testing for equal average forecast accuracy in possibly unstable environments. <em>JBES</em>, <em>43</em>(3), 643-656. (<a href='https://doi.org/10.1080/07350015.2024.2418835'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the issue of testing the null of equal average forecast accuracy in a model where the forecast error loss differential series has a potentially nonconstant mean function over time. We show that when time variation is present in the loss differential mean, the standard Diebold and Mariano test, which was proposed for evaluating forecasts in a stable environment, has an asymptotic size of zero, and, whilst consistent, can have reduced local power. This arises due to inconsistent estimation of the implicit long run variance estimator, which diverges under a time varying mean. We suggest a modified statistic that replaces the standard long run variance estimator based on full-sample demeaning of the loss differential series with one based on nonparametric local demeaning. The new long run variance estimator is consistent under both the null and alternative when the mean function is time varying or constant, and in both cases, the modified test recovers the asymptotic size and power properties associated with the original test in the constant mean case. The modified test therefore provides a robust method for testing the equal average forecast accuracy null, allowing for instability in the loss differential mean. The benefits of our test are demonstrated via Monte Carlo simulation and two empirical applications.},
  archive      = {J_JBES},
  author       = {David I. Harvey and Stephen J. Leybourne and Yang Zu},
  doi          = {10.1080/07350015.2024.2418835},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {643-656},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Testing for equal average forecast accuracy in possibly unstable environments},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inference in experiments with matched pairs and imperfect compliance. <em>JBES</em>, <em>43</em>(3), 627-642. (<a href='https://doi.org/10.1080/07350015.2024.2416972'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies inference for the local average treatment effect in randomized controlled trials with imperfect compliance where treatment status is determined according to “matched pairs.” By “matched pairs,” we mean that units are sampled iid from the population of interest, paired according to observed, baseline covariates and finally, within each pair, one unit is selected at random for treatment. Under weak assumptions governing the quality of the pairings, we first derive the limit distribution of the usual Wald (i.e., two-stage least squares) estimator of the local average treatment effect. We show further that conventional heteroscedasticity-robust estimators of the Wald estimator’s limiting variance are generally conservative, in that their probability limits are (typically strictly) larger than the limiting variance. We therefore provide an alternative estimator of the limiting variance that is consistent. Finally, we consider the use of additional observed, baseline covariates not used in pairing units to increase the precision with which we can estimate the local average treatment effect. To this end, we derive the limiting behavior of a two-stage least squares estimator of the local average treatment effect which includes both the additional covariates in addition to pair fixed effects, and show that its limiting variance is always less than or equal to that of the Wald estimator. To complete our analysis, we provide a consistent estimator of this limiting variance. A simulation study confirms the practical relevance of our theoretical results. Finally, we apply our results to revisit a prominent experiment studying the effect of macroinsurance on microenterprise in Egypt.},
  archive      = {J_JBES},
  author       = {Yuehao Bai and Hongchang Guo and Azeem M. Shaikh and Max Tabord-Meehan},
  doi          = {10.1080/07350015.2024.2416972},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {627-642},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Inference in experiments with matched pairs and imperfect compliance},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Penalized sparse covariance regression with high dimensional covariates. <em>JBES</em>, <em>43</em>(3), 615-626. (<a href='https://doi.org/10.1080/07350015.2024.2415109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Covariance regression offers an effective way to model the large covariance matrix with the auxiliary similarity matrices. In this work, we propose a sparse covariance regression (SCR) approach to handle the potentially high-dimensional predictors (i.e., similarity matrices). Specifically, we use the penalization method to identify the informative predictors and estimate their associated coefficients simultaneously. We first investigate the Lasso estimator and subsequently consider the folded concave penalized estimation methods (e.g., SCAD and MCP). However, the theoretical analysis of the existing penalization methods is primarily based on iid data, which is not directly applicable to our scenario. To address this difficulty, we establish the non-asymptotic error bounds by exploiting the spectral properties of the covariance matrix and similarity matrices. Then, we derive the estimation error bound for the Lasso estimator and establish the desirable oracle property of the folded concave penalized estimator. Extensive simulation studies are conducted to corroborate our theoretical results. We also illustrate the usefulness of the proposed method by applying it to a Chinese stock market dataset.},
  archive      = {J_JBES},
  author       = {Yuan Gao and Zhiyuan Zhang and Zhanrui Cai and Xuening Zhu and Tao Zou and Hansheng Wang},
  doi          = {10.1080/07350015.2024.2415109},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {615-626},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Penalized sparse covariance regression with high dimensional covariates},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An oracle inequality for multivariate dynamic quantile forecasting. <em>JBES</em>, <em>43</em>(3), 603-614. (<a href='https://doi.org/10.1080/07350015.2024.2415107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I derive an oracle inequality for a family of possibly misspecified multivariate conditional autoregressive quantile models. The family includes standard specifications for (nonlinear) quantile prediction proposed in the literature. This inequality is used to establish that the predictor that minimizes the in-sample average check loss achieves the best out-of-sample performance within its class at a near optimal rate, even when the model is fully misspecified. An empirical application to backtesting global Growth-at-Risk shows that a combination of the generalized autoregressive conditionally heteroscedastic model and the vector autoregression for Value-at-Risk performs best out-of-sample in terms of the check loss.},
  archive      = {J_JBES},
  author       = {Jordi Llorens-Terrazas},
  doi          = {10.1080/07350015.2024.2415107},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {603-614},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {An oracle inequality for multivariate dynamic quantile forecasting},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correcting for misclassified binary regressors using instrumental variables. <em>JBES</em>, <em>43</em>(3), 592-602. (<a href='https://doi.org/10.1080/07350015.2024.2415102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimators that exploit an instrumental variable to correct for misclassification in a binary regressor typically assume that the misclassification rates are invariant across all values of the instrument. We show this assumption is invalid in routine empirical settings. We derive a new estimator which allows misclassification rates to vary across values of the instrumental variable. Our key identifying assumption, that the sum of misclassification rates remains constant across instrument values, follows from the empirical examples we present. We also show this assumption can be relaxed using moment inequalities that arise from our model. We demonstrate the usefulness of our estimator through Monte Carlo simulations and a reanalysis of the extent to which Medicaid eligibility crowds out other forms of health insurance. Correcting for measurement error substantially reduces estimates of crowd out and the extent to which Medicaid eligibility lowers the share of the uninsured.},
  archive      = {J_JBES},
  author       = {Steven J. Haider and Melvin Stephens Jr.},
  doi          = {10.1080/07350015.2024.2415102},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {592-602},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Correcting for misclassified binary regressors using instrumental variables},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust estimation for threshold autoregressive moving-average models. <em>JBES</em>, <em>43</em>(3), 579-591. (<a href='https://doi.org/10.1080/07350015.2024.2412011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Threshold autoregressive moving-average (TARMA) models extend the popular TAR model and are among the few parametric time series specifications to include a moving average in a nonlinear setting. The state dependent reactions to shocks is particularly appealing in Economics and Finance. However, no theory is currently available when the data present heavy tails or anomalous observations. Here we provide the first theoretical framework for robust M -estimation for TARMA models and study its practical relevance. Under mild conditions, we show that the robust estimator for the threshold parameter is super-consistent, while the estimators for autoregressive and moving-average parameters are strongly consistent and asymptotically normal. The Monte Carlo study shows that the M -estimator is superior, in terms of both bias and variance, to the least squares estimator, which can be heavily affected by outliers. The findings suggest that robust M -estimation should be generally preferred to the least squares method. We apply our methodology to a set of commodity price time series; the robust TARMA fit presents smaller standard errors and superior forecasting accuracy. The results support the hypothesis of a two-regime non-linearity characterized by slow expansions and fast contractions.},
  archive      = {J_JBES},
  author       = {Greta Goracci and Davide Ferrari and Simone Giannerini and Francesco Ravazzolo},
  doi          = {10.1080/07350015.2024.2412011},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {579-591},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Robust estimation for threshold autoregressive moving-average models},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revisiting panel data binary choice models with lagged dependent variables. <em>JBES</em>, <em>43</em>(3), 568-578. (<a href='https://doi.org/10.1080/07350015.2024.2412006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article revisits the identification and estimation of a class of semiparametric (distribution-free) panel data binary choice models with lagged dependent variables, exogenous covariates, and entity fixed effects. We provide a novel identification strategy, using an “identification at infinity” argument. In contrast with the celebrated work by Honoré and Kyriazidou published in 2000, our method permits time trends of any form and does not suffer from the “curse of dimensionality”. We propose an easily implementable conditional maximum score estimator. The asymptotic properties of the proposed estimator are fully characterized. A small-scale Monte Carlo study demonstrates that our approach performs satisfactorily in finite samples. We illustrate the usefulness of our method by presenting an empirical application to enrollment in private hospital insurance using the Household, Income and Labor Dynamics in Australia (HILDA) Survey data.},
  archive      = {J_JBES},
  author       = {Christopher R. Dobronyi and Fu Ouyang and Thomas Tao Yang},
  doi          = {10.1080/07350015.2024.2412006},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {568-578},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Revisiting panel data binary choice models with lagged dependent variables},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Endogenous kink threshold regression. <em>JBES</em>, <em>43</em>(3), 556-567. (<a href='https://doi.org/10.1080/07350015.2024.2407634'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers an endogenous kink threshold regression model with an unknown threshold value in a time series as well as a panel data framework, where both the threshold variable and regressors are allowed to be endogenous. We construct our estimators from a nonparametric control function approach and derive the consistency and asymptotic distribution of our proposed estimators. Monte Carlo simulations are used to assess the finite sample performance of our proposed estimators. Finally, we apply our model to analyze the impact of COVID-19 cases on labor markets in the United States and Canada.},
  archive      = {J_JBES},
  author       = {Jianhan Zhang and Chaoyi Chen and Yiguo Sun and Thanasis Stengos},
  doi          = {10.1080/07350015.2024.2407634},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {556-567},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Endogenous kink threshold regression},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design-based theory for lasso adjustment in randomized block experiments and rerandomized experiments. <em>JBES</em>, <em>43</em>(3), 544-555. (<a href='https://doi.org/10.1080/07350015.2024.2403381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blocking, a special case of rerandomization, is routinely implemented in the design stage of randomized experiments to balance the baseline covariates. This study proposes a regression adjustment method based on the least absolute shrinkage and selection operator (Lasso) to efficiently estimate the average treatment effect in randomized block experiments with high-dimensional covariates. We derive the asymptotic properties of the proposed estimator and outline the conditions under which this estimator is more efficient than the unadjusted one. We provide a conservative variance estimator to facilitate valid inferences. Our framework allows one treated or control unit in some blocks and heterogeneous propensity scores across blocks, thus including paired experiments and finely stratified experiments as special cases. We further accommodate rerandomized experiments and a combination of blocking and rerandomization. Moreover, our analysis allows both the number of blocks and block sizes to tend to infinity, as well as heterogeneous treatment effects across blocks without assuming a true outcome data-generating model. Simulation studies and two real-data analyses demonstrate the advantages of the proposed method.},
  archive      = {J_JBES},
  author       = {Ke Zhu and Hanzhong Liu and Yuehan Yang},
  doi          = {10.1080/07350015.2024.2403381},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {544-555},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Design-based theory for lasso adjustment in randomized block experiments and rerandomized experiments},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic quantile factor analysis. <em>JBES</em>, <em>43</em>(3), 530-543. (<a href='https://doi.org/10.1080/07350015.2024.2396956'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article extends quantile factor analysis to a probabilistic variant that incorporates regularization and computationally efficient variational approximations. We establish through synthetic and real data experiments that the proposed estimator can, in many cases, achieve better accuracy than a recently proposed loss-based estimator. We contribute to the factor analysis literature by extracting new indexes of low , medium , and high economic policy uncertainty, as well as loose , median , and tight financial conditions. We show that the high uncertainty and tight financial conditions indexes have superior predictive ability for various measures of economic activity. In a high-dimensional exercise involving about 1000 daily financial series, we find that quantile factors also provide superior out-of-sample information compared to mean or median factors.},
  archive      = {J_JBES},
  author       = {Dimitris Korobilis and Maximilian Schröder},
  doi          = {10.1080/07350015.2024.2396956},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {530-543},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Probabilistic quantile factor analysis},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved divide-and-conquer approach to estimating mean functional, with application to average treatment effect estimation. <em>JBES</em>, <em>43</em>(3), 520-529. (<a href='https://doi.org/10.1080/07350015.2024.2395429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mean estimation is an important issue in statistical inference and machine learning. We are concerned with estimating mean functional that is a function of several nonparametric functions when there is a large amount of observations. Directly estimating such mean functional through nonparametric smoothing has the complexity of at least a quadratic order of the sample size, which is computationally prohibitive for massive data. The divide-and-conquer approach are thus readily used to alleviate the computational complexity issue, which however imposes a stringent condition on the sample size in each local machine if a locally optimal bandwidth is used. To address this issue, we suggest to use a globally optimal bandwidth in each local machine, which alleviates the restriction on the local sample sizes substantially. We show that the divide-and-conquer approach with a globally optimal bandwidth achieves the estimation efficiency bound as if all observations were pooled together. In terms of computational efficiency, our proposal outperforms the pooled algorithm dramatically. We demonstrate these properties through average treatment effect estimation from both the asymptotic and the non-asymptotic perspectives.},
  archive      = {J_JBES},
  author       = {Zhengtian Zhu and Liping Zhu},
  doi          = {10.1080/07350015.2024.2395429},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {520-529},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {An improved divide-and-conquer approach to estimating mean functional, with application to average treatment effect estimation},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distinguishing time-varying factor models. <em>JBES</em>, <em>43</em>(3), 508-519. (<a href='https://doi.org/10.1080/07350015.2024.2395424'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-varying factor models have been widely used to model changing relationships among economic and financial variables. The existing literature usually specifies the time-varying factor loadings as deterministic functions of time or unit root processes. This article proposes two consistent tests to distinguish between these two specifications based on a randomization approach. By setting the null hypothesis as either specification, we show that the proposed test statistics follow an asymptotic Chi-squared distribution under the respective null hypotheses and diverge to infinity in probability under the respective alternatives. Simulation studies reveal that both test statistics perform reasonably well in finite samples. We apply the proposed tests to the U.S. macroeconomic and global macroeconomic and financial datasets. The results suggest that the time-varying factor loadings as deterministic functions of time should be adopted for these two applications.},
  archive      = {J_JBES},
  author       = {Zhonghao Fu and Liangjun Su and Xia Wang},
  doi          = {10.1080/07350015.2024.2395424},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {508-519},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Distinguishing time-varying factor models},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-based co-clustering in customer targeting utilizing large-scale online product rating networks. <em>JBES</em>, <em>43</em>(3), 495-507. (<a href='https://doi.org/10.1080/07350015.2024.2395423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the widely available online customer ratings on products, the individual-level rating prediction and clustering of customers and products are increasingly important for sellers to create targeting strategies for expanding the customer base and improving product ratings. However, the massive missing data problem is a significant challenge for modeling online product ratings. To address this issue, we propose a new co-clustering methodology based on a bipartite network modeling of large-scale ordinal product ratings. Our method extends existing co-clustering methods by incorporating covariates and ordinal ratings in the model-based co-clustering of a weighted bipartite network. We devise an efficient variational EM algorithm for model estimation. A simulation study demonstrates that our methodology is scalable for modeling large datasets and provides accurate estimation and clustering results. We further show that our model can successfully identify different groups of customers and products with meaningful interpretations and achieve promising predictive performance in a real application for customer targeting.},
  archive      = {J_JBES},
  author       = {Qian Chen and Amal Agarwal and Duncan K. H. Fong and Wayne S. DeSarbo and Lingzhou Xue},
  doi          = {10.1080/07350015.2024.2395423},
  journal      = {Journal of Business & Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {495-507},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Model-based co-clustering in customer targeting utilizing large-scale online product rating networks},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jcgs">JCGS - 31</h2>
<ul>
<li><details>
<summary>
(2025). Quantile regression and homogeneity identification of a semiparametric panel data model. <em>JCGS</em>, <em>34</em>(3), 1169-1187. (<a href='https://doi.org/10.1080/10618600.2024.2433672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we delve into the quantile regression and homogeneity detection of a varying index coefficient panel data model, which incorporates fixed individual effects and exhibits nonlinear time trends. Using spline approximation, we obtain estimators for the trend functions, link functions, and index parameters, and subsequently establish the corresponding convergence rates and asymptotic normality. Observing that subjects within a group may share identical trend functions, we are motivated to further explore potential homogeneity in these trends. To this end, we propose a homogeneity identification algorithm based on binary segmentation. For the determination of the thresholding parameter in homogeneity identification, we propose a generalized Bayesian information criterion. Furthermore, we introduce a penalized method to discern the constant and linear structures within the nonparametric functions of our model. By leveraging grouped observations, we achieve more efficient estimation and improve the asymptotic properties of the estimators. To demonstrate the finite sample performance of our proposed approach, we conduct simulation studies and apply our methodology to a real-world dataset comprising Air Pollution Data and Integrated Surface Data (APD&ISD). Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Rui Li and Tao Li and Huacheng Su and Jinhong You},
  doi          = {10.1080/10618600.2024.2433672},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1169-1187},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Quantile regression and homogeneity identification of a semiparametric panel data model},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural bayes estimators for irregular spatial data using graph neural networks. <em>JCGS</em>, <em>34</em>(3), 1153-1168. (<a href='https://doi.org/10.1080/10618600.2024.2433671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Bayes estimators are neural networks that approximate Bayes estimators in a fast and likelihood-free manner. Although they are appealing to use with spatial models, where estimation is often a computational bottleneck, neural Bayes estimators in spatial applications have, to date, been restricted to data collected over a regular grid. These estimators are also currently dependent on a prescribed set of spatial locations, which means that the neural network needs to be retrained for new datasets; this renders them impractical in many applications and impedes their widespread adoption. In this work, we employ graph neural networks (GNNs) to tackle the important problem of parameter point estimation from data collected over arbitrary spatial locations. In addition to extending neural Bayes estimation to irregular spatial data, the use of GNNs leads to substantial computational benefits, since the estimator can be used with any configuration or number of locations and independent replicates, thus, amortizing the cost of training for a given spatial model. We also facilitate fast uncertainty quantification by training an accompanying neural Bayes estimator that approximates a set of marginal posterior quantiles. We illustrate our methodology on Gaussian and max-stable processes. Finally, we showcase our methodology on a dataset of global sea-surface temperature, where we estimate the parameters of a Gaussian process model in 2161 spatial regions, each containing thousands of irregularly-spaced data points, in just a few minutes with a single graphics processing unit. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Matthew Sainsbury-Dale and Andrew Zammit-Mangion and Jordan Richards and Raphaël Huser},
  doi          = {10.1080/10618600.2024.2433671},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1153-1168},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Neural bayes estimators for irregular spatial data using graph neural networks},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visualization and assessment of copula symmetry. <em>JCGS</em>, <em>34</em>(3), 1140-1152. (<a href='https://doi.org/10.1080/10618600.2024.2432978'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visualization and assessment of copula structures are crucial for accurately understanding and modeling the dependencies in multivariate data analysis. In this article, we introduce an innovative method that employs functional boxplots and rank-based testing procedures to evaluate copula symmetries. This approach is specifically designed to assess key characteristics such as reflection symmetry, radial symmetry, and joint symmetry. We first construct test functions for each specific property and then investigate the asymptotic properties of their empirical estimators. We demonstrate that the functional boxplot of these sample test functions serves as an informative visualization tool of a given copula structure, effectively measuring the departure from zero of the test function. Furthermore, we introduce a nonparametric testing procedure to assess the significance of deviations from symmetry, ensuring the accuracy and reliability of our visualization method. Through extensive simulation studies involving various copula models, we demonstrate the effectiveness of our testing approach. Finally, we apply our visualization and testing techniques to three real-world datasets: a nutritional habits survey with five variables, stock price data for the five top companies in the NASDAQ-100 stock index, and two major stock indices, the US S&P500 and German DAX. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Cristian F. Jiménez-Varón and Hao Lee and Marc G. Genton and Ying Sun},
  doi          = {10.1080/10618600.2024.2432978},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1140-1152},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Visualization and assessment of copula symmetry},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable estimation and two-sample testing for large networks via subsampling. <em>JCGS</em>, <em>34</em>(3), 1127-1139. (<a href='https://doi.org/10.1080/10618600.2024.2432974'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, large networks are routinely used to represent data from many scientific fields. Statistical analysis of these networks, such as estimation and hypothesis testing, has received considerable attention. However, most of the methods proposed in the literature are computationally expensive for large networks. In this article, we propose a subsampling-based method to reduce the computational cost of estimation and two-sample hypothesis testing. The idea is to divide the network into smaller subgraphs with an overlap region, then draw inference based on each subgraph, and finally combine the results together. We first develop the subsampling method for random dot product graph models, and establish theoretical consistency of the proposed method. Then we extend the subsampling method to a more general setup and establish similar theoretical properties. We demonstrate the performance of our methods through simulation experiments and real data analysis. Supplemental materials for the article are available online. The code is available in the following GitHub repository: https://github.com/kchak19/SubsampleTestingNetwork . Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Kaustav Chakraborty and Srijan Sengupta and Yuguo Chen},
  doi          = {10.1080/10618600.2024.2432974},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1127-1139},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Scalable estimation and two-sample testing for large networks via subsampling},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FlexBART: Flexible bayesian regression trees with categorical predictors. <em>JCGS</em>, <em>34</em>(3), 1117-1126. (<a href='https://doi.org/10.1080/10618600.2024.2431072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most implementations of Bayesian additive regression trees (BART) one-hot encode categorical predictors, replacing each one with several binary indicators, one for every level or category. Regression trees built with these indicators partition the discrete set of categorical levels by repeatedly removing one level at a time. Unfortunately, the vast majority of partitions cannot be built with this strategy, severely limiting BART’s ability to partially pool data across groups of levels. Motivated by analyses of baseball data and neighborhood-level crime dynamics, we overcame this limitation by re-implementing BART with regression trees that can assign multiple levels to both branches of a decision tree node. To model spatial data aggregated into small regions, we further proposed a new decision rule prior that creates spatially contiguous regions by deleting a random edge from a random spanning tree of a suitably defined network. Our re-implementation, which is available in the flexBART package, often yields improved out-of-sample predictive performance and scales better to larger datasets than existing implementations of BART. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Sameer K. Deshpande},
  doi          = {10.1080/10618600.2024.2431072},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1117-1126},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {FlexBART: Flexible bayesian regression trees with categorical predictors},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monotone cubic B-splines with a neural-network generator. <em>JCGS</em>, <em>34</em>(3), 1102-1116. (<a href='https://doi.org/10.1080/10618600.2024.2431070'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a method for fitting monotone curves using cubic B-splines with a monotonicity constraint on the coefficients. We explore different ways of enforcing this constraint and analyze their theoretical and empirical properties. We propose two algorithms for solving the spline fitting problem: one that uses standard optimization techniques and one that trains a Multi-Layer Perceptrons (MLP) generator to approximate the solutions under various settings and perturbations. The generator approach can speed up the fitting process when we need to solve the problem repeatedly, such as when constructing confidence bands using bootstrap. We evaluate our method against several existing methods, some of which do not use the monotonicity constraint, on some monotone curves with varying noise levels. We demonstrate that our method outperforms the other methods, especially in high-noise scenarios. We also apply our method to analyze the polarization-hole phenomenon during star formation in astrophysics. The source code is accessible at https://github.com/szcf-weiya/MonotoneSplines.jl . Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Lijun Wang and Xiaodan Fan and Huabai Li and Jun S. Liu},
  doi          = {10.1080/10618600.2024.2431070},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1102-1116},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Monotone cubic B-splines with a neural-network generator},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decentralized learning of quantile regression: A smoothing approach. <em>JCGS</em>, <em>34</em>(3), 1091-1101. (<a href='https://doi.org/10.1080/10618600.2024.2431060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed estimation has attracted a significant amount of attention recently due to its advantages in computational efficiency and data privacy preservation. In this article, we focus on quantile regression over a decentralized network. Without a coordinating central node, a decentralized network improves system stability and increases efficiency by communicating with fewer nodes per round. However, existing related works on decentralized quantile regression have slow (sub-linear) convergence speed. We propose a novel method for decentralized quantile regression which is built upon the smoothed quantile loss. However, we argue that the smoothed loss proposed in the existing literature using a single smoothing bandwidth parameter fails to achieve fast convergence and statistical efficiency simultaneously in the decentralized setting. We propose a novel quadratic approximation of the quantile loss using a big bandwidth for the Hessian and a small bandwidth for the gradient. Our method enjoys a linear convergence rate and has optimal statistical efficiency. Numerical experiments and real data analysis are conducted to demonstrate the effectiveness of our method. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Jianwei Shi and Yue Wang and Zhongyi Zhu and Heng Lian},
  doi          = {10.1080/10618600.2024.2431060},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1091-1101},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Decentralized learning of quantile regression: A smoothing approach},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local clustering for functional data. <em>JCGS</em>, <em>34</em>(3), 1075-1090. (<a href='https://doi.org/10.1080/10618600.2024.2431057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In functional data analysis, unsupervised clustering has been extensively conducted and has important implications. In most of the existing functional clustering analyses, it is assumed that there is a single clustering structure across the whole domain of measurement (say, time interval). In some data analyses, for example, the analysis of normalized COVID-19 daily confirmed cases for the U.S. states, it is observed that functions can have different clustering patterns in different time subintervals. To tackle the lack of flexibility of the existing functional clustering techniques, we develop a local clustering approach, which can fully data-dependently identify subintervals, where, in different subintervals, functions have different clustering structures. This approach is built on the basis expansion technique and has a novel penalization form. It simultaneously achieves subinterval identification, clustering, and estimation. Its estimation and clustering consistency properties are rigorously established. In simulation, it significantly outperforms multiple competitors. In the analysis of the COVID-19 case trajectory data, it identifies sensible subintervals and clustering structures. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Yuanxing Chen and Qingzhao Zhang and Shuangge Ma},
  doi          = {10.1080/10618600.2024.2431057},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1075-1090},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Local clustering for functional data},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). No more, no less than sum of its parts: Groups, monoids, and the algebra of graphics, statistics, and interaction. <em>JCGS</em>, <em>34</em>(3), 1063-1074. (<a href='https://doi.org/10.1080/10618600.2024.2429708'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive data visualization has become a staple of modern data presentation. Yet, despite its growing popularity, we still lack a general framework for turning raw data into summary statistics that can be displayed by interactive graphics. This gap may stem from a subtle yet profound issue: while we would often like to treat graphics, statistics, and interaction in our plots as independent, they are in fact deeply connected. This article examines this interdependence in light of two fundamental concepts from category theory: groups and monoids. We argue that the knowledge of these algebraic structures can help us design sensible interactive graphics. Specifically, if we want our graphics to support interactive features which split our data into parts and then combine these parts back together (such as linked selection), then the statistics underlying our plots need to possess certain properties. By grounding our thinking in these algebraic concepts, we may be able to build more flexible and expressive interactive data visualization systems. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Adam Bartonicek and Simon Urbanek and Paul Murrell},
  doi          = {10.1080/10618600.2024.2429708},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1063-1074},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {No more, no less than sum of its parts: Groups, monoids, and the algebra of graphics, statistics, and interaction},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Functional projection K-means. <em>JCGS</em>, <em>34</em>(3), 1051-1062. (<a href='https://doi.org/10.1080/10618600.2024.2429706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new technique for simultaneous clustering and dimensionality reduction of functional data is proposed. The observations are projected into a low-dimensional subspace and clustered by means of a functional K -means. The subspace and the partition are estimated simultaneously by minimizing the within deviance in the reduced space. This allows us to find new dimensions with a very low within deviance, which should correspond to a high level of discriminant power. However, in some cases, the total deviance explained by the new dimensions is so low as to make the subspace, and therefore the partition identified in it, insignificant. To overcome this drawback, we add to the loss a penalty equal to the negative total deviance in the reduced space. In this way, subspaces with a low deviance are avoided. We show how several existing methods are particular cases of our proposal simply by varying the weight of the penalty. The estimation is improved by adding a regularization term to the loss in order to take into account the functional nature of the data by smoothing the centroids. In contrast to existing literature, which largely considers the smoothing as a pre-processing step, in our proposal regularization is integrated with the identification of both subspace and cluster partition. An alternating least squares algorithm is introduced to compute model parameter estimates. The effectiveness of our proposal is demonstrated through its application to both real and simulated data. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Roberto Rocci and Stefano A. Gattone},
  doi          = {10.1080/10618600.2024.2429706},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1051-1062},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Functional projection K-means},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse model-based clustering of three-way data via lasso-type penalties. <em>JCGS</em>, <em>34</em>(3), 1030-1050. (<a href='https://doi.org/10.1080/10618600.2024.2429705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixtures of matrix Gaussian distributions provide a probabilistic framework for clustering continuous matrix-variate data, which are increasingly common in various fields. Despite their widespread use and successful applications, these models suffer from over-parameterization, making them not suitable for even moderately sized matrix-variate data. To address this issue, we introduce a sparse model-based clustering approach for three-way data. Our approach assumes that the matrix mixture parameters are sparse and have different degrees of sparsity across clusters, enabling the induction of parsimony in a flexible manner. Estimation relies on the maximization of a penalized likelihood, with specifically tailored group and graphical lasso penalties. These penalties facilitate the selection of the most informative features for clustering three-way data where variables are recorded over multiple occasions, as well as allowing the identification of cluster-specific association structures. We conduct extensive testing of the proposed methodology on synthetic data and validate its effectiveness through an application to time-dependent crime patterns across multiple U.S. cities. Supplementary files for this article are available online.},
  archive      = {J_JCGS},
  author       = {Andrea Cappozzo and Alessandro Casa and Michael Fop},
  doi          = {10.1080/10618600.2024.2429705},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1030-1050},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Sparse model-based clustering of three-way data via lasso-type penalties},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A majorization-minimization gauss-newton method for 1-bit matrix completion. <em>JCGS</em>, <em>34</em>(3), 1017-1029. (<a href='https://doi.org/10.1080/10618600.2024.2428610'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 1-bit matrix completion, the aim is to estimate an underlying low-rank matrix from a partial set of binary observations. We propose a novel method for 1-bit matrix completion called Majorization-Minimization Gauss-Newton ( MMGN ). Our method is based on the majorization-minimization principle, which converts the original optimization problem into a sequence of standard low-rank matrix completion problems. We solve each of these sub-problems by a factorization approach that explicitly enforces the assumed low-rank structure and then apply a Gauss-Newton method. Using simulations and a real data example, we illustrate that in comparison to existing 1-bit matrix completion methods, MMGN outputs comparable if not more accurate estimates. In addition, it is often significantly faster, and less sensitive to the spikiness of the underlying matrix. In comparison with three standard generic optimization approaches that directly minimize the original objective, MMGN also exhibits a clear computational advantage, especially when the fraction of observed entries is small. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Xiaoqian Liu and Xu Han and Eric C. Chi and Boaz Nadler},
  doi          = {10.1080/10618600.2024.2428610},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1017-1029},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {A majorization-minimization gauss-newton method for 1-bit matrix completion},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-dimensional block diagonal covariance structure detection using singular vectors. <em>JCGS</em>, <em>34</em>(3), 1005-1016. (<a href='https://doi.org/10.1080/10618600.2024.2422985'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The assumption of independent subvectors arises in many aspects of multivariate analysis. In most real-world applications, however, we lack prior knowledge about the number of subvectors and the specific variables within each subvector. Yet, testing all these combinations is not feasible. For example, for a data matrix containing 15 variables, there are already 1 , 382 , 958 , 545 possible combinations. Given that zero correlation is a necessary condition for independence, independent subvectors exhibit a block diagonal covariance matrix. This article focuses on the detection of such block diagonal covariance structures in high-dimensional data and therefore also identifies uncorrelated subvectors. Our approach exploits the fact that the structure of the covariance matrix is mirrored by the structure of its eigenvectors. However, the true block diagonal structure is masked by noise in the sample case. To address this problem, we propose to use sparse approximations of the sample eigenvectors to reveal the sparse structure of the population eigenvectors. Notably, the right singular vectors of a data matrix with an overall mean of zero are identical to the sample eigenvectors of its covariance matrix. Using sparse approximations of these singular vectors instead of the eigenvectors makes the estimation of the covariance matrix obsolete. We demonstrate the performance of our method through simulations and provide real data examples. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Jan O. Bauer},
  doi          = {10.1080/10618600.2024.2422985},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {1005-1016},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {High-dimensional block diagonal covariance structure detection using singular vectors},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal subsampling for data streams with measurement constrained categorical responses. <em>JCGS</em>, <em>34</em>(3), 994-1004. (<a href='https://doi.org/10.1080/10618600.2024.2421990'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-velocity, large-scale data streams have become pervasive. Frequently, the associated labels for such data prove costly to measure and are not always available upfront. Consequently, the analysis of such data poses a significant challenge. In this article, we develop a method that addresses this challenge by employing an online subsampling procedure and a multinomial logistic model for efficient analysis of high-velocity, large-scale data streams. Our algorithm is designed to sequentially update parameter estimation based on the A-optimality criterion. Moreover, it significantly increases computational efficiency while imposing minimal storage requirements. Theoretical properties are rigorously established to quantify the asymptotic behavior of the estimator. The method’s efficacy is further demonstrated through comprehensive numerical studies on both simulated and real-world datasets. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Jun Yu and Zhiqiang Ye and Mingyao Ai and Ping Ma},
  doi          = {10.1080/10618600.2024.2421990},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {994-1004},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Optimal subsampling for data streams with measurement constrained categorical responses},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent markov time-interaction processes. <em>JCGS</em>, <em>34</em>(3), 984-993. (<a href='https://doi.org/10.1080/10618600.2024.2421984'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present parametric and semiparametric latent Markov time-interaction processes, that are point processes where the occurrence of an event can increase or reduce the probability of future events. We first present time-interaction processes with parametric and nonparametric baselines, then we let model parameters be modulated by a discrete state continuous time latent Markov process. Posterior inference is based on a novel and efficient data augmentation approach in the Markov chain Monte Carlo framework. We illustrate with a simulation study; and an original application to terrorist attacks in Europe in the period 2001–2017, where we find two distinct latent clusters for the hazard of occurrence of terrorist events, negative association with GDP growth, and self-exciting phenomena. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Rosario Barone and Alessio Farcomeni and Maura Mezzetti},
  doi          = {10.1080/10618600.2024.2421984},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {984-993},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Latent markov time-interaction processes},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label random subspace ensemble classification. <em>JCGS</em>, <em>34</em>(3), 971-983. (<a href='https://doi.org/10.1080/10618600.2024.2421248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we develop a new ensemble learning framework, multi-label Random Subspace Ensemble (mRaSE), for multi-label classification. Given a base classifier (e.g., multinomial logistic regression, classification tree, K -nearest neighbors), mRaSE works by first randomly sampling a collection of subspaces, then choosing the best ones that achieve the minimum cross-validation errors and, finally, aggregating the chosen weak learners. In addition to its superior prediction performance, mRaSE also provides a model-free feature ranking depending on the given base classifier. An iterative version of mRaSE is also developed to further improve the performance. A model-free extension is pursued on the iterative version, leading to the so-called Super mRaSE , which accepts a collection of base classifiers as input to the algorithm. We show the proposed algorithms compared favorably with the state-of-the-art classification algorithm including random forest and deep neural network, via extensive simulation studies and two real data applications. The new algorithms are implemented in an updated version of the R package RaSEn .},
  archive      = {J_JCGS},
  author       = {Fan Bi and Jianan Zhu and Yang Feng},
  doi          = {10.1080/10618600.2024.2421248},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {971-983},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Multi-label random subspace ensemble classification},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-task learning for gaussian graphical regressions with high dimensional covariates. <em>JCGS</em>, <em>34</em>(3), 961-970. (<a href='https://doi.org/10.1080/10618600.2024.2421246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian graphical regression is a powerful approach for regressing the precision matrix of a Gaussian graphical model on covariates, which permits the response variables and covariates to outnumber the sample size. However, traditional approaches of fitting the model via separate node-wise lasso regressions overlook the network-induced structure among these regressions, leading to high error rates, particularly when the number of nodes is large. To address this issue, we propose a multi-task learning estimator for fitting Gaussian graphical regression models, which incorporates a cross-task group sparsity penalty and a within-task element-wise sparsity penalty to govern the sparsity of active covariates and their effects on the graph, respectively. We also develop an efficient augmented Lagrangian algorithm for computation, which solves subproblems with a semi-smooth Newton method. We further prove that our multi-task learning estimator has considerably lower error rates than the separate node-wise regression estimates, as the cross-task penalty enables borrowing information across tasks. We examine the utility of our method through simulations and an application to a gene co-expression network study with brain cancer patients. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Jingfei Zhang and Yi Li},
  doi          = {10.1080/10618600.2024.2421246},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {961-970},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Multi-task learning for gaussian graphical regressions with high dimensional covariates},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Qini curves for multi-armed treatment rules. <em>JCGS</em>, <em>34</em>(3), 948-960. (<a href='https://doi.org/10.1080/10618600.2024.2418820'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Qini curves have emerged as an attractive and popular approach for evaluating the benefit of data-driven targeting rules for treatment allocation. We propose a generalization of the Qini curve to multiple costly treatment arms that quantifies the value of optimally selecting among both units and treatment arms at different budget levels. We develop an efficient algorithm for computing these curves and propose bootstrap-based confidence intervals that are exact in large samples for any point on the curve. These confidence intervals can be used to conduct hypothesis tests comparing the value of treatment targeting using an optimal combination of arms with using just a subset of arms, or with a non-targeting assignment rule ignoring covariates, at different budget levels. We demonstrate the statistical performance in a simulation experiment and an application to treatment targeting for election turnout.},
  archive      = {J_JCGS},
  author       = {Erik Sverdrup and Han Wu and Susan Athey and Stefan Wager},
  doi          = {10.1080/10618600.2024.2418820},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {948-960},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Qini curves for multi-armed treatment rules},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sampling random graphs with specified degree sequences. <em>JCGS</em>, <em>34</em>(3), 934-947. (<a href='https://doi.org/10.1080/10618600.2024.2418817'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The configuration model is a standard tool for uniformly generating random graphs with a specified degree sequence, and is often used as a null model to evaluate how much of an observed network’s structure can be explained by its degree structure alone. A Markov chain Monte Carlo (MCMC) algorithm, based on a degree-preserving double-edge swap, provides an asymptotic solution to sample from the configuration model. However, accurately and efficiently detecting when this Markov chain is sufficiently close to its stationary distribution remains an unsolved problem. Here, we provide a solution to sample from the configuration model using this standard MCMC algorithm. We develop an algorithm, based on the assortativity of the sampled graphs, for estimating the gap between effectively independent MCMC states, and a computationally efficient gap-estimation heuristic derived from analyzing a corpus of 509 empirical networks. We provide a convergence detection method based on the Dickey-Fuller Generalized Least Squares test, which we show is more accurate and efficient than three alternative Markov chain convergence tests. Supplementary materials for the proposed methods can be found here.},
  archive      = {J_JCGS},
  author       = {Upasana Dutta and Bailey K. Fosdick and Aaron Clauset},
  doi          = {10.1080/10618600.2024.2418817},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {934-947},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Sampling random graphs with specified degree sequences},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient sampling from the watson distribution in arbitrary dimensions. <em>JCGS</em>, <em>34</em>(3), 923-933. (<a href='https://doi.org/10.1080/10618600.2024.2416521'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present two efficient methods for sampling from the Watson distribution in arbitrary dimensions. The first method adapts the rejection sampling algorithm from Kent, Ganeiber, and Mardia , originally designed for Bingham distributions, using angular central Gaussian envelopes. For the Watson distribution, we derive a closed-form expression for the parameters that maximize sampling efficiency, which is further investigated and bounded by asymptotic results. This approach avoids the curse of dimensionality through a smart matrix inversion, enabling fast runtimes even in high dimensions. The second method, based on Saw , employs adaptive rejection sampling from a projected distribution. This algorithm is also effective in all dimensions and offers rapid sampling capabilities. Finally, our simulation study compares the two main methods, revealing that each excels under different conditions: the first method is more efficient for small samples or large dimensions, while the second performs better with larger samples and more concentrated distributions. Both algorithms are available in the R package watson on CRAN. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Lukas Sablica and Kurt Hornik and Josef Leydold},
  doi          = {10.1080/10618600.2024.2416521},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {923-933},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Efficient sampling from the watson distribution in arbitrary dimensions},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distortion corrected kernel density estimator on riemannian manifolds. <em>JCGS</em>, <em>34</em>(3), 906-922. (<a href='https://doi.org/10.1080/10618600.2024.2415543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manifold learning obtains a low-dimensional representation of an underlying Riemannian manifold supporting high-dimensional data. Kernel density estimates of the low-dimensional embedding with a fixed bandwidth fail to account for the way manifold learning algorithms distort the geometry of the Riemannian manifold. We propose a novel distortion-corrected kernel density estimator (DC-KDE) for any manifold learning embedding, with a bandwidth that depends on the estimated Riemannian metric at each data point. Exploiting the geometric information of the manifold leads to more accurate density estimation, which subsequently could be used for anomaly detection. To compare our proposed estimator with a fixed-bandwidth kernel density estimator, we run two simulations including one with data lying in a 100 dimensional ambient space. We demonstrate that the proposed DC-KDE improves the density estimates as long as the manifold learning embedding is of sufficient quality, and has higher rank correlations with the true manifold density. Further simulation results are provided via a supplementary R shiny app. The proposed method is applied to density estimation in statistical manifolds of electricity usage with the Irish smart meter data.},
  archive      = {J_JCGS},
  author       = {Fan Cheng and Rob J. Hyndman and Anastasios Panagiotelis},
  doi          = {10.1080/10618600.2024.2415543},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {906-922},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Distortion corrected kernel density estimator on riemannian manifolds},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sample efficient nonparametric regression via low-rank regularization. <em>JCGS</em>, <em>34</em>(3), 896-905. (<a href='https://doi.org/10.1080/10618600.2024.2414891'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonparametric regression suffers from curse of dimensionality, requiring a relatively large sample size for accurate estimation beyond the univariate case. In this article, we consider a simple method of dimension reduction in nonparametric regression via series estimation, based on the concept of low-rankness which was previously studied in parametric multivariate reduced-rank regression and matrix regression. For d > 2 , the low-rank assumption is realized via tensor regression. We establish a faster convergence rate of the estimator in the (approximate) low-rank case. Limitations of the model are also discussed. Through simulation studies and real data analysis, we compare the estimation accuracy of the proposed method with that of existing approaches. The results demonstrate that the proposed method yields estimates with lower RMSE compared to existing methods. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Jiakun Jiang and Jiahao Peng and Heng Lian},
  doi          = {10.1080/10618600.2024.2414891},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {896-905},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Sample efficient nonparametric regression via low-rank regularization},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable clustering: Large scale unsupervised learning of gaussian mixture models with outliers. <em>JCGS</em>, <em>34</em>(3), 884-895. (<a href='https://doi.org/10.1080/10618600.2024.2414889'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a widely used technique with a long and rich history in a variety of areas. However, most existing algorithms do not scale well to large datasets, or are missing theoretical guarantees of convergence. This article introduces a provably robust clustering algorithm based on loss minimization that performs well on Gaussian mixture models with outliers. It provides theoretical guarantees that the algorithm obtains high accuracy with high probability under certain assumptions. Moreover, it can also be used as an initialization strategy for k -means clustering. Experiments on real-world large-scale datasets demonstrate the effectiveness of the algorithm when clustering a large number of clusters, and a k -means algorithm initialized by the algorithm outperforms many of the classic clustering methods in both speed and accuracy, while scaling well to large datasets such as ImageNet. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Yijia Zhou and Kyle A. Gallivan and Adrian Barbu},
  doi          = {10.1080/10618600.2024.2414889},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {884-895},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Scalable clustering: Large scale unsupervised learning of gaussian mixture models with outliers},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous functional regression for subgroup analysis. <em>JCGS</em>, <em>34</em>(3), 872-883. (<a href='https://doi.org/10.1080/10618600.2024.2414113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With ever increasing number of features of modern datasets, data heterogeneity is gradually becoming the norm rather than the exception. Whereas classical regressions usually assume all the samples follow a common model, it becomes imperative to identify the heterogeneous relationship in different subsamples. In this article, we propose a new approach to model heterogeneous functional regression relations. We target at the association between a response and a predictor, whose relationship can vary across underlying subgroups and is modeled as an unknown functional of an auxiliary predictor. We introduce a procedure which performs simultaneous parameter estimation and subgroup identification through a fusion type group-wise penalization. We establish the statistical guarantees in terms of non-asymptotic convergence of the parameter estimation. We also establish the oracle property and asymptotic normality of the estimators. We carry out intensive simulations, and illustrate with a new dataset from an Alzheimer’s disease study. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Yeqing Zhou and Fei Jiang},
  doi          = {10.1080/10618600.2024.2414113},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {872-883},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Heterogeneous functional regression for subgroup analysis},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AddiVortes: (Bayesian) additive voronoi tessellations. <em>JCGS</em>, <em>34</em>(3), 859-871. (<a href='https://doi.org/10.1080/10618600.2024.2414104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Additive Voronoi Tessellations (AddiVortes) model is a multivariate regression model that uses Voronoi tessellations to partition the covariate space in an additive ensemble model. Unlike other partition methods, such as decision trees, this has the benefit of allowing the boundaries of the partitions to be non-orthogonal and nonparallel to the covariate axes. The AddiVortes model uses a similar sum-of-tessellations approach and a Bayesian backfitting MCMC algorithm to the BART model. We use regularization priors to limit the strength of individual tessellations and accepts new models based on a likelihood. The performance of the AddiVortes model is illustrated through testing on several datasets and comparing the performance to other models along with a simulation study to verify some of the properties of the model. In many cases, the AddiVortes model outperforms random forests, BART and other leading black-box regression models when compared using a range of metrics. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Adam J. Stone and John Paul Gosling},
  doi          = {10.1080/10618600.2024.2414104},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {859-871},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {AddiVortes: (Bayesian) additive voronoi tessellations},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differentially private methods for compositional data. <em>JCGS</em>, <em>34</em>(3), 848-858. (<a href='https://doi.org/10.1080/10618600.2024.2412174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Confidential data, such as electronic health records, activity data from wearable devices, and geolocation data, are becoming increasingly prevalent. Differential privacy provides a framework to conduct statistical analyses while mitigating the risk of leaking private information. Compositional data, which consist of vectors with positive components that add up to a constant, have received little attention in the differential privacy literature. This article proposes differentially private approaches for analyzing compositional data based on the Dirichlet distribution. We explore several methods, including Bayesian and bootstrap procedures. For the Bayesian methods, we consider posterior inference techniques based on Markov chain Monte Carlo, Approximate Bayesian Computation, and asymptotic approximations. We conduct an extensive simulation study to compare these approaches and make evidence-based recommendations. Finally, we apply the methodology to a dataset from the American Time Use Survey.},
  archive      = {J_JCGS},
  author       = {Qi Guo and Andrés F. Barrientos and Víctor Peña},
  doi          = {10.1080/10618600.2024.2412174},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {848-858},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Differentially private methods for compositional data},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MCMC for bayesian nonparametric mixture modeling under differential privacy. <em>JCGS</em>, <em>34</em>(3), 837-847. (<a href='https://doi.org/10.1080/10618600.2024.2410911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the probability density of a population while preserving the privacy of individuals in that population is an important and challenging problem that has received considerable attention in recent years. While the previous literature focused on frequentist approaches, in this article, we propose a Bayesian nonparametric mixture model under differential privacy (DP) and present two Markov chain Monte Carlo (MCMC) algorithms for posterior inference. One is a marginal approach, resembling Neal’s algorithm 5 with a pseudo-marginal Metropolis-Hastings move, and the other is a conditional approach. Although our focus is primarily on local DP, we show that our MCMC algorithms can be easily extended to deal with global differential privacy mechanisms. Moreover, for some carefully chosen mechanisms and mixture kernels, we show how auxiliary parameters can be analytically marginalized, allowing standard MCMC algorithms (i.e., non-privatized, such as Neal’s Algorithm 2) to be efficiently employed. Our approach is general and applicable to any mixture model and privacy mechanism. In several simulations and a real case study, we discuss the performance of our algorithms and evaluate different privacy mechanisms proposed in the frequentist literature. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Mario Beraha and Stefano Favaro and Vinayak Rao},
  doi          = {10.1080/10618600.2024.2410911},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {837-847},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {MCMC for bayesian nonparametric mixture modeling under differential privacy},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grid point approximation for distributed nonparametric smoothing and prediction. <em>JCGS</em>, <em>34</em>(3), 824-836. (<a href='https://doi.org/10.1080/10618600.2024.2409817'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel smoothing is a widely used nonparametric method in modern statistical analysis. The problem of efficiently conducting kernel smoothing for a massive dataset on a distributed system is a problem of great importance. In this work, we find that the popularly used one-shot type estimator is highly inefficient for prediction purposes. To this end, we propose a novel grid point approximation (GPA) method, which has the following advantages. First, the resulting GPA estimator is as statistically efficient as the global estimator under mild conditions. Second, it requires no communication and is extremely efficient in terms of computation for prediction. Third, it is applicable to the case where the data are not randomly distributed across different machines. To select a suitable bandwidth, two novel bandwidth selectors are further developed and theoretically supported. Extensive numerical studies are conducted to corroborate our theoretical findings. Two real data examples are also provided to demonstrate the usefulness of our GPA method. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Yuan Gao and Rui Pan and Feng Li and Riquan Zhang and Hansheng Wang},
  doi          = {10.1080/10618600.2024.2409817},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {824-836},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Grid point approximation for distributed nonparametric smoothing and prediction},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Network embedding-based directed community detection with unknown community number. <em>JCGS</em>, <em>34</em>(3), 812-823. (<a href='https://doi.org/10.1080/10618600.2024.2409789'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection of network analysis plays an important role in numerous application areas, in which estimating the number of communities is a fundamental issue. However, many existing methods focus on undirected networks ignoring the directionality of edges or unrealistically assume that the number of communities is known a priori. In this article, we develop a data-dependent community detection method for the directed network to determine the number of communities and recover community structures simultaneously, which absorbs the ideas of network embedding and penalized fusion by embedding the out- and in-nodes into low-dimensional vector space and forcing the embedding vectors toward its center. The asymptotic consistency properties of the proposed method are established in terms of network embedding, directed community detection, and estimation of the number of communities. The proposed method is applied on synthetic networks and real brain functional networks, which demonstrate the superior performance of the proposed method against a number of competitors. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Qingzhao Zhang and Jinlong Zhou and Mingyang Ren},
  doi          = {10.1080/10618600.2024.2409789},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {812-823},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Network embedding-based directed community detection with unknown community number},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient modeling of spatial extremes over large geographical domains. <em>JCGS</em>, <em>34</em>(3), 795-811. (<a href='https://doi.org/10.1080/10618600.2024.2409784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various natural phenomena exhibit spatial extremal dependence at short spatial distances. However, existing models proposed in the spatial extremes literature often assume that extremal dependence persists across the entire domain. This is a strong limitation when modeling extremes over large geographical domains, and yet it has been mostly overlooked in the literature. We here develop a more realistic Bayesian framework based on a novel Gaussian scale mixture model, with the Gaussian process component defined though a stochastic partial differential equation yielding a sparse precision matrix, and the random scale component modeled as a low-rank Pareto-tailed or Weibull-tailed spatial process determined by compactly-supported basis functions. We show that our proposed model is approximately tail-stationary and that it can capture a wide range of extremal dependence structures. Its inherently sparse probabilistic structure allows fast Bayesian computations in high spatial dimensions based on a customized Markov chain Monte Carlo algorithm prioritizing calibration in the tail. We fit our model to analyze heavy monsoon rainfall data in Bangladesh. Our study shows that our model outperforms natural competitors and that it fits precipitation extremes well. We finally use the fitted model to draw inference on long-term return levels for marginal precipitation and spatial aggregates. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Arnab Hazra and Raphaël Huser and David Bolin},
  doi          = {10.1080/10618600.2024.2409784},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {795-811},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {Efficient modeling of spatial extremes over large geographical domains},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A latent space model for weighted keyword co-occurrence networks with applications in knowledge discovery in statistics. <em>JCGS</em>, <em>34</em>(3), 779-794. (<a href='https://doi.org/10.1080/10618600.2024.2407465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keywords are widely recognized as pivotal in conveying the central idea of academic articles. In this article, we construct a weighted and dynamic keyword co-occurrence network and propose a latent space model for analyzing it. Our model has two special characteristics. First, it is applicable to weighted networks; however, most previous models were primarily designed for unweighted networks. Simply replacing the frequency of keyword co-occurrence with binary values would result in a significant loss of information. Second, our model can handle the situation where network nodes evolve over time, and assess the effect of new nodes on network connectivity. We use the projected gradient descent algorithm to estimate the latent positions and establish the theoretical properties of the estimators. In the real data application, we study the keyword co-occurrence network within the field of statistics. We identify popular keywords over the whole period as well as within each time period. For keyword pairs, our model provides a new way to assess the association between them. Finally, we observe that the interest of statisticians in emerging research areas has gradually grown in recent years. Supplementary materials for this article are available online.},
  archive      = {J_JCGS},
  author       = {Yan Zhang and Rui Pan and Xuening Zhu and Kuangnan Fang and Hansheng Wang},
  doi          = {10.1080/10618600.2024.2407465},
  journal      = {Journal of Computational and Graphical Statistics},
  month        = {7},
  number       = {3},
  pages        = {779-794},
  shortjournal = {J. Comput. Graph. Stat.},
  title        = {A latent space model for weighted keyword co-occurrence networks with applications in knowledge discovery in statistics},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jeee">JEEE - 7</h2>
<ul>
<li><details>
<summary>
(2025). Prey profile of jungle cat in human dominated landscape of southern west bengal: Evidence from camera traps. <em>JEEE</em>, <em>37</em>(2), 236-242. (<a href='https://doi.org/10.1080/03949370.2025.2453939'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Jungle cats ( Felis chaus ) are one of the least studied felids with a widespread presence throughout the southern districts of West Bengal. During a survey through camera traps to document fishing cats ( Prionailurus viverrinus ), we recorded bycatch data of camera trap captured images of Jungle cats with their prey. Although the diet of Jungle cats has been extensively studied using genetic methods globally, this paper presents evidence of its prey items through camera trap data. We obtained 196 independent images of Jungle cats, with 31 showing them with prey. Our data indicates that rodents are its primary prey. The images also reveal that Jungle cats’ prey on domestic duck and other birds. We recommend organizing awareness camps among locals to reduce retaliation and ensure the safe coexistence of jungle cats in human settlement areas.},
  archive      = {J_JEEE},
  author       = {Samrat Chakraborty and Paromit Chatterjee and Goutam K. Saha},
  doi          = {10.1080/03949370.2025.2453939},
  journal      = {Ethology Ecology & Evolution},
  month        = {3},
  number       = {2},
  pages        = {236-242},
  shortjournal = {Ethol. Ecol. Evol.},
  title        = {Prey profile of jungle cat in human dominated landscape of southern west bengal: Evidence from camera traps},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Are size-dependent aposematic patterns shaped by evolutionary pressures in “indestructible” velvet ants (Hymenoptera mutillidae)? a case study of neotropical species. <em>JEEE</em>, <em>37</em>(2), 224-235. (<a href='https://doi.org/10.1080/03949370.2025.2453906'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predation is one of the most powerful selective forces driving evolution among animals, and one common form of defense against it is aposematism. The Mutillidae (Hymenoptera Aculeata), commonly known as velvet ants, are solitary parasitoid wasps that exhibit a range of colors, including shades of white, yellow, orange-red, and black. In some Hymenoptera, a distinct color pattern consisting of a black head, an orange or red mesosoma, and a black metasoma – referred to as the Black-Orange-Black (BOB) pattern – may function as an aposematic signal to deter predators, particularly in smaller species. To investigate the presence of this pattern in Mutillidae and its potential association with body size, we tested the hypothesis that the BOB pattern is more prevalent in smaller species. The total body length of the individuals was measured in millimeters (mm), and they were categorized as either displaying the BOB pattern or not (non-BOB, NBOB). A total of 448 individuals from various genera were analyzed, of which 79 exhibited the BOB pattern. The BOB pattern was more frequently observed among individuals measuring between 4.5 and 7.5 mm in body size, indicating that these individuals tended to be smaller compared to those with the NBOB pattern. A significant difference in body size was detected between the two patterns. These findings suggest that aposematism may serve as an effective defensive strategy, particularly concentrated in smaller body sizes, within this group already recognized for its diverse array of anti-predator adaptations.},
  archive      = {J_JEEE},
  author       = {Luana Pereira de Melo and Rodrigo Aranda},
  doi          = {10.1080/03949370.2025.2453906},
  journal      = {Ethology Ecology & Evolution},
  month        = {3},
  number       = {2},
  pages        = {224-235},
  shortjournal = {Ethol. Ecol. Evol.},
  title        = {Are size-dependent aposematic patterns shaped by evolutionary pressures in “indestructible” velvet ants (Hymenoptera mutillidae)? a case study of neotropical species},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Substrate-induced chromatic variations in three species of leaf and stick insects (Insecta phasmatodea). <em>JEEE</em>, <em>37</em>(2), 210-223. (<a href='https://doi.org/10.1080/03949370.2025.2482531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mimicry, particularly chromatic adaptation, is a defining characteristic of leaf and stick insects, which comprise phasmids (Insecta Phasmatodea). This study investigates substrate-induced color changes in three phasmid species: Extatosoma tiaratum, Hesperophasma sp. “La Ciénaga”, and Phyllium gantungense “Rizal”. For each species, two experimental groups were exposed to a grey-green lichen ( Evernia prunastri ) as a substrate, while two cages were set up with an artificial pink material. Control groups were reared on elmleaf blackberry ( Rubus ulmifolius ) alone; all groups were composed of at least 20 individuals. Using digital pictures, the RGB color channels of juveniles and adults were analyzed to quantify color variations. We revealed significant species-specific variations in color development responses related to substrates. In E. tiaratum , we did not observe a significant difference between adults reared over different substrates. However, digital image analyses revealed that E. tiaratum exhibited significant chromatic changes during development, especially among 11 juvenile females, suggesting a potential genetic predisposition for substrate-specific color adaptation. In the species P. gantungense , we did not find color changes during the experiment, indicating a lack of phenotypic plasticity in response to substrate variation. Hesperophasma sp. “La Ciénaga” showed minimal color changes; however, untreated juveniles naturally darkened as they matured, a trend that was inhibited in substrate-treated groups, indicating a potential influence of the substrate on natural color development. These findings highlight the species-specific nature of substrate-induced color variation in stick insects. Investigating the genetic and physiological mechanisms underlying these changes is essential for understanding the evolutionary dynamics and ecological adaptations of these insects. Further research in this area could reveal insights into the broader implications of phenotypic plasticity and environmental adaptation in phasmids.},
  archive      = {J_JEEE},
  author       = {Mattia Ragazzini and Raffaele Gattelli and Federico Plazzi and Marco Passamonti},
  doi          = {10.1080/03949370.2025.2482531},
  journal      = {Ethology Ecology & Evolution},
  month        = {3},
  number       = {2},
  pages        = {210-223},
  shortjournal = {Ethol. Ecol. Evol.},
  title        = {Substrate-induced chromatic variations in three species of leaf and stick insects (Insecta phasmatodea)},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Echoes of adaptation: House sparrows’ ecological response to shifting human disturbances. <em>JEEE</em>, <em>37</em>(2), 188-209. (<a href='https://doi.org/10.1080/03949370.2025.2482523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human disturbances are being increasingly recognized for their impact on the behavior of urban wildlife during the Anthropocene. This study was conducted to gain insights into the changes in population density of House sparrows ( Passer domesticus ) to different degrees of human disturbance during various stages of COVID-19. A “disturbance score” was computed by considering four variables: human movement, number of vehicles plying, number of shops opened, and ambient noise level. Generalized Linear Mixed Model (GLMM) was used to understand the influence of the disturbance variables on the House sparrows’ density among different phases of lockdown and across different sites. Our findings revealed that the second COVID wave exhibited the highest population density (number/ha) at 4.64 ± 0.941, followed by the first wave at 3.73 ± 1.21. In addition, our results suggest that lockdown phases and disturbance variables significantly influenced the sparrow population density. Furthermore, there were notable variations in sparrow population densities across the different lockdown phases. Similarly, the disturbance variables seem to influence the sparrow population density across the lockdown phases, except for the before-lockdown and first-wave lockdowns, possibly indicating a lag in the sparrows’ adaptive response to the changing urban environment. The findings have unveiled a significant pattern in the behavioral responses of sparrows to human disruptions. The decline in the presence of sparrows in areas with higher anthropogenic disturbances, following the relaxation of lockdown regulations indicates a potential shift of these birds to quieter sites. The capacity of sparrows to adjust their behavior has enabled them to take advantage of decreased disruptions, which could impact their documented population density. Thus, this study emphasizes the need to incorporate wildlife behavioral responses to human disturbances into urban planning and management strategies.},
  archive      = {J_JEEE},
  author       = {Sakti P. Pattnayak and Priyanka Jena and B.A.K. Prusty and Arti Saxena},
  doi          = {10.1080/03949370.2025.2482523},
  journal      = {Ethology Ecology & Evolution},
  month        = {3},
  number       = {2},
  pages        = {188-209},
  shortjournal = {Ethol. Ecol. Evol.},
  title        = {Echoes of adaptation: House sparrows’ ecological response to shifting human disturbances},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Behavioral strategies between aphidius platensis and winter cereal aphids with a focus on parasitism. <em>JEEE</em>, <em>37</em>(2), 174-187. (<a href='https://doi.org/10.1080/03949370.2025.2453940'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aphids that infest cereal crops employ diverse survival strategies, including behavioral defenses to avoid parasitism. The Aphidiinae subfamily, particularly Aphidius platensis , plays an important role as a parasitoid in controlling cereal aphids. There is a lack of information on the behavioral aspects associated with aphids and parasitoids, along with their influence on parasitism rates. This study aimed to observe the apterous adult’s behavior of Rhopalosiphum padi , Schizaphis graminum , Metopolophium dirhodum , and Sitobion avenae and its parasitoid ( Aphidius platensis ) when exposed to each other and evaluate how these interactions reflect on parasitism rates. The behaviors were recorded (5 min) and analyzed using BORIS software. Parasitism rates were assessed by examining the presence of larvae and mummies. Schizaphis graminum was the highest recognized and accepted aphid species by A. platensis , with 95% of parasitism, followed by R. padi (68.3%), despite its ability to escape (walking), and S. avenae (13.2%), despite its kick behavior. Metopolophium dirhodum , with minimal kicking, was not parasitized. Our results showed that the parasitoid tends to be more aggressive (mainly probing and parasitizing) toward the host with which it has greatest parasitism ( S. graminum ). Aphid defensive behaviors were not sufficient to defend themselves, as parasitoid attacks were similar in those that walked and kicked more often. We observed that the parasitoid A. platensis behaved similarly on suitable and unsuitable hosts. This finding provides new information that can contribute to a better understanding of host–parasitoid interactions, which has implications for biological control strategies targeting aphids in winter cereals.},
  archive      = {J_JEEE},
  author       = {Carlos D.R. dos Santos and Josué Sant’Ana and Luiza Rodrigues Redaelli and Priscila de Carvalho Engel},
  doi          = {10.1080/03949370.2025.2453940},
  journal      = {Ethology Ecology & Evolution},
  month        = {3},
  number       = {2},
  pages        = {174-187},
  shortjournal = {Ethol. Ecol. Evol.},
  title        = {Behavioral strategies between aphidius platensis and winter cereal aphids with a focus on parasitism},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Permanent conspicuity in an amazonian weakly electric fish subjected to low predation risk. <em>JEEE</em>, <em>37</em>(2), 154-173. (<a href='https://doi.org/10.1080/03949370.2024.2444275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many organisms, changes in environmental conditions trigger modifications in physiology and signaling for reproduction. In males, sexual maturation often prompts signaling that can convey information on fighting ability and mate quality, allowing adaptative sexual selection to act. Because predation can drive the evolution of sexual signals, insights from organisms exposed to low predation pressure will benefit sexual selection theory. Here, we exposed males and females of Microsternarchus sp. nov. “Ducke” (Gymnotiformes Hypopomidae) to simulate environmental conditions of the breeding season to investigate changes in electric signaling in a species that occurs in environments with low or absent predation pressure from electroreceptive predators. We induced sexual maturation, which was confirmed by visual inspection of female gonads. After sexual maturation, both sexes underwent major changes in Electric Organ Discharges (EOD), suggesting mutual signaling in electric communication before breeding pair formation. EOD parameters related to body length were intensified in sexually mature males and, as such, changes in male electric discharges observed after gonadal maturation exaggerate information on fighting ability and mate quality, as suggested for other electric fishes. Because polarity imbalance was high in both sexes and reproductive stages, our results support the hypothesis that predation pressure did not constrain the evolution of conspicuous EODs in this species, in favor of other adaptive mechanisms of mate choice.},
  archive      = {J_JEEE},
  author       = {Carine M. Cola and Tiago H.S. Pires and Marina Anciães and José A. Alves-Gomes},
  doi          = {10.1080/03949370.2024.2444275},
  journal      = {Ethology Ecology & Evolution},
  month        = {3},
  number       = {2},
  pages        = {154-173},
  shortjournal = {Ethol. Ecol. Evol.},
  title        = {Permanent conspicuity in an amazonian weakly electric fish subjected to low predation risk},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Behavioral strategies of the freshwater crab sylviocarcinus pictus (Crustacea brachyura trichodactylidae) in severe aquatic environments in the brazilian semiarid region. <em>JEEE</em>, <em>37</em>(2), 139-153. (<a href='https://doi.org/10.1080/03949370.2025.2482533'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Severe environments, characterized by high temperatures and scarce rainfall, challenge organisms and may lead them to display behavioral adaptations to live in such areas. While there is a significant amount of research on behavioral adaptations to severe environments on land, aquatic habitats remain relatively understudied. In this study, we selected a population of Sylviocarcinus pictus crabs from the semiarid region of Brazil to investigate, describe, and quantify the behavioral repertoire of adult crabs in a laboratory setting. In the laboratory, we filmed ( n = 10) adult crabs individually (five males and five females), for 72 consecutive hours. Subsequently, we analyzed and recorded their behaviors every 20 min, totaling ( n = 240) videos analyzed. Based on the observations, we then constructed an ethogram with nine behaviors grouped into four categories: quiescence, environmental exploration, feeding, and self-cleaning. Our results indicate that, regardless of sex ( P = 0.39), S. pictus individuals remained more quiescent during the light period ( P < 0.05), with males spending 82.71% of the time quiescent and females spending 91.96% of their time quiescent. Additionally, individuals showed a substantial increase in the frequencies of activity-related behaviors during the dark period ( P < 0.05), with no significant differences between sexes. Compared to other species, S. pictus proved to be even more quiescent, especially during the day, possibly in response to the harsh environmental conditions. In the natural environment, we observed crabs seeking shelter under rocks during the day, possibly as a response to high temperatures. These findings suggest that the crabs have developed behavioral strategies to optimize energy use in severe aquatic environments.},
  archive      = {J_JEEE},
  author       = {Paulo H.P. Nobre and Alexandre V. Palaoro and Carlito A. Nascimento and Juliana G. Araújo and Carlos A.M. Martins and Whandenson M. Nascimento and Allysson P. Pinheiro},
  doi          = {10.1080/03949370.2025.2482533},
  journal      = {Ethology Ecology & Evolution},
  month        = {3},
  number       = {2},
  pages        = {139-153},
  shortjournal = {Ethol. Ecol. Evol.},
  title        = {Behavioral strategies of the freshwater crab sylviocarcinus pictus (Crustacea brachyura trichodactylidae) in severe aquatic environments in the brazilian semiarid region},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jetai">JETAI - 10</h2>
<ul>
<li><details>
<summary>
(2025). An effectual underwater image enhancement framework using adaptive trans-resunet ++ with attention mechanism. <em>JETAI</em>, <em>37</em>(7), 1217-1245. (<a href='https://doi.org/10.1080/0952813X.2024.2383659'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intricacy of the underwater setting makes it difficult for optical lenses to capture clear underwater photos without haze and colour distortion. Some studies use domain adaptation and transfer learning to address this issue, they aim to reduce the latent mismatch between composition and real-world data, making the space of latent data difficult to read and impractical to control. The background light is a crucial component of the decaying paradigm that directly impacts how well images are enhanced. Thus, to improve the quality of the images over the underwater, new deep-learning techniques are being designed in this paper. Here, the Adaptive Trans-ResUnet++ with Attention Mechanism-based model performs the real-time underwater image enhancement process. In addition, a novel Random Enhanced Artificial Gorilla Troops Optimizer algorithm model is used for optimising the parameters over the given model to further enhance the given model’s performance. A diverse quantitative and qualitative validation is also carried out to learn the enhancement of underwater image quality. The enhanced underwater image may be also useful in the underwater object detection process. Thus, the enhanced images obtained from the developed model are compared with the existing techniques to confirm the efficacy of the suggested underwater image enhancement process.},
  archive      = {J_JETAI},
  author       = {Ajanya P and S. Meera},
  doi          = {10.1080/0952813X.2024.2383659},
  journal      = {Journal of Experimental & Theoretical Artificial Intelligence},
  month        = {10},
  number       = {7},
  pages        = {1217-1245},
  shortjournal = {J. Exp. Theor. Artif. Intell.},
  title        = {An effectual underwater image enhancement framework using adaptive trans-resunet ++ with attention mechanism},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Content-based image retrieval by classification with reinforcement optimisation evolutionary machine learning with applications. <em>JETAI</em>, <em>37</em>(7), 1195-1215. (<a href='https://doi.org/10.1080/0952813X.2024.2383652'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Content Based Image Retrieval (CBIR) plays a significant role in identifying the similarity of images with large datasets. It is identified based on the size, colour, and texture features of the image. But in such conditions, it is complex to determine the features of query images in large datasets and does not show accurate similarity when compared with every image in the retrieval process. In order to perform an efficient similarity of images, a novel Machine Learning (ML) approach Kernelized Radial Basis Auto-Encoder Function Neural Network (Ker_RadBAEFNN) technique is proposed that performs the individual image classification in the retrieval process. Moreover, the neural networks are optimised based on the reinforcement process and perform the extraction process regarding individual images. Further,reinforcement-based optimisation estimates the images in neural networks for undertaking an automatic feature extraction of query images. The performance of the classification process is validated based on MNIST, METU, and COCO datasets that determined the efficiency of the recognition and classification process of image retrieval. The experimental analysis is carried out based on various measures such as accuracy, precision, recall, F1-score, RMSE, and MAPE for the proposed and existing GLCM-ABC, PSO-ANN, IRB-CNN, FAGWO, and OCAM methods. The analysis shows that the performance of the proposed attained better effectiveness with attained accuracy by 98% and diminished for state-of-the-art techniques as 92%, 95%, 94%, 96.8%, as well as 96%, respectively. Compared to existing methods, the accuracy rate of the proposed method is maximised by 1.3%.},
  archive      = {J_JETAI},
  author       = {Anandh Sam Chandra Bose and Laxman Singh and Shamimul Qamar and S. Uma and L. Sherly Puspha Annabel and Sanjay Singla},
  doi          = {10.1080/0952813X.2024.2383652},
  journal      = {Journal of Experimental & Theoretical Artificial Intelligence},
  month        = {10},
  number       = {7},
  pages        = {1195-1215},
  shortjournal = {J. Exp. Theor. Artif. Intell.},
  title        = {Content-based image retrieval by classification with reinforcement optimisation evolutionary machine learning with applications},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature selection on real-time application using hybrid of flamingo search algorithm and improved non-dominated sorting genetic algorithm III. <em>JETAI</em>, <em>37</em>(7), 1175-1193. (<a href='https://doi.org/10.1080/0952813X.2024.2383649'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection plays an essential role in enhancing the efficiency and effectiveness of machine learning models, particularly in the context of large-scale datasets where the dimensionality of features presents significant challenges. This research presents a novel approach to feature selection, a critical aspect of enhancing machine learning model efficiency, particularly in the context of large-scale datasets. By integrating the Flamingo Search Algorithm (FSA), Non-dominated Sorting Genetic Algorithm III (NSGA-III), and Regularised Extreme Learning Machine (RELM), the proposed method addresses limitations in existing feature selection and multi-objective optimisation algorithms. Leveraging FSA’s emulation of flamingo behaviours, the approach achieves a balance between global exploration and local exploitation, mitigating issues like premature convergence and local optima. Integration with NSGA-III enhances multi-objective optimisation capabilities, maintaining a delicate equilibrium between convergence and diversity. FSA-RELM is employed for accurate feature assessment, given its rapid learning and suitability for large datasets with multiple labels. Experimental evaluations demonstrate the proposed method’s superiority in feature selection accuracy, classification performance, and computational efficiency compared to existing approaches. This research contributes to advancing feature selection methodologies, offering a comprehensive solution for high-dimensional datasets in machine learning and data mining applications.},
  archive      = {J_JETAI},
  author       = {C. Gnana Kousalya and V. Senthil kumar and P. M. Diaz and M. Julie Emerald Jiju},
  doi          = {10.1080/0952813X.2024.2383649},
  journal      = {Journal of Experimental & Theoretical Artificial Intelligence},
  month        = {10},
  number       = {7},
  pages        = {1175-1193},
  shortjournal = {J. Exp. Theor. Artif. Intell.},
  title        = {Feature selection on real-time application using hybrid of flamingo search algorithm and improved non-dominated sorting genetic algorithm III},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The impact of sociality regimes on heterogeneous cooperative-competitive multi-agent reinforcement learning: A study with the predator-prey game. <em>JETAI</em>, <em>37</em>(7), 1159-1174. (<a href='https://doi.org/10.1080/0952813X.2024.2361408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance in multi-agent reinforcement learning (MARL) scenarios has usually been analysed in homogeneous teams with a few choices for the sociality regime (selfish, egalitarian, or altruistic). In this paper we analyse both homogeneous and heterogeneous teams in a variation of sociality regimes in the predator-prey game, using a novel normalisation of the weights so that the sum of all rewards is independent of the sociality regime. We find that the selfish regime is advantageous for both predator and prey teams, and for both homogeneous and heterogeneous teams. In particular, rewards are about 100% higher for the predator team when switching from the egalitarian to selfish regime and more than 400% higher from the altruistic regime. For the prey, the increase is around 40% and 100% respectively. The results are similar for homogeneous and heterogeneous situations. The takeaway message is that any study of homogeneous and heterogeneous cooperative-competitive multi-agent reinforcement learning teams should also take into account the sociality regimes before making conclusions on the preference of any algorithm.},
  archive      = {J_JETAI},
  author       = {Yue Zhao and José Hernández-Orallo},
  doi          = {10.1080/0952813X.2024.2361408},
  journal      = {Journal of Experimental & Theoretical Artificial Intelligence},
  month        = {10},
  number       = {7},
  pages        = {1159-1174},
  shortjournal = {J. Exp. Theor. Artif. Intell.},
  title        = {The impact of sociality regimes on heterogeneous cooperative-competitive multi-agent reinforcement learning: A study with the predator-prey game},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient safest route prediction-based route discovery mechanism for drivers using improved golden tortoise beetle optimizer. <em>JETAI</em>, <em>37</em>(7), 1135-1157. (<a href='https://doi.org/10.1080/0952813X.2024.2343736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several commercialised route recommendation systems only consider the metrics like cost, time, and distance. The essential metric ‘safety’ is neglected by the existent systems. It suggests only the short way and doesn’t include any safety information, such as crime awareness, road availability. This paper describes an inventive ideology to discover the safest route with minimal risk score for security of the road travellers. Hence, a new safety route navigation mechanism is developed to solve the challenges in the traditional route discovery approaches using deep learning. In the developed route discovery mechanism, the examination of the safest roads is done by the developed deep learning network, where the network is trained with the inputs obtained from the roads, such as road surface conditions, Road users, weather conditions, traffic conditions, accidental cases, and crime areas. The availability of the safest route will be determined by the ‘Long Short-Term Memory with Attention Mechanism’ (LSTM-AM). The route discovery is done with the help of a developed ‘Fitness-based Golden Tortoise Beetle Optimizer’ (FGTBO) with multi-objective constraints like distance, time, and road availability. The implementation outcome of the developed route discovery scheme will be validated with the traditional route discovery approaches concerning various measures.},
  archive      = {J_JETAI},
  author       = {A. Vijaya Lakshmi and A. Parthiban and K. Suresh Joseph},
  doi          = {10.1080/0952813X.2024.2343736},
  journal      = {Journal of Experimental & Theoretical Artificial Intelligence},
  month        = {10},
  number       = {7},
  pages        = {1135-1157},
  shortjournal = {J. Exp. Theor. Artif. Intell.},
  title        = {An efficient safest route prediction-based route discovery mechanism for drivers using improved golden tortoise beetle optimizer},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Securing IoT network with hybrid evolutionary lion intrusion detection system: A composite motion optimisation algorithm for feature selection and ensemble classification. <em>JETAI</em>, <em>37</em>(7), 1111-1133. (<a href='https://doi.org/10.1080/0952813X.2024.2342858'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Networks connected to the Internet of Things (IoT) are often vulnerable to attacks. Several existing methods in the intrusion detection system for securing IoT have been presented with ensemble classifier, but it does not accurately classify attack, and also it takes high computation time. With intention of solving the security issues, Intrusion Detection System using Hybrid Evolutionary Lion and Balancing Composite Motion Optimisation Algorithm espoused feature selection with Ensemble Classifier (IDS-IoT-Hybrid ELOA-BCMOA-Ensemble-DT-LSVM-RF-XGBoost) is proposed for Securing IoT Network. At first, data were accumulated from the NSL-KDD data set. Afterward, data is fed to pre-processing, where it restored missing value using mean curvature flow method. At feature selection, optimum features are compiled under Hybrid Evolutionary Lion and Balancing Composite Motion Optimisation Algorithm. Based upon the optimum features, intruders of IoT data are categorised as denial-of-service (DoS), probe, remote to local attack (R2L), user to root attack (U2R), normal (no attack) with the help of Ensemble classifier. Proposed IDS-IoT-Hybrid ELOA-BCMOA-Ensemble-DT-LSVM-RF-XGBoost approach is constructed utilising Python. Then, proposed IDS-IoT-Hybrid ELOA-BCMOA-Ensemble-DT-LSVM-RF-XGBoost approach attains 21.11%, 19.58%, 24.61% and 9.52% higher accuracy; 94.47%, 93.95%, 93.08% and 90.59% lower error rate, and 62.94%, 36.69%, 64.17% and 50.97% less computation time analysed with existing models.},
  archive      = {J_JETAI},
  author       = {Anuvelavan Subramaniam and Sureshkumar Chelladurai and Stanly Kumar Ande and Sathiyandrakumar Srinivasan},
  doi          = {10.1080/0952813X.2024.2342858},
  journal      = {Journal of Experimental & Theoretical Artificial Intelligence},
  month        = {10},
  number       = {7},
  pages        = {1111-1133},
  shortjournal = {J. Exp. Theor. Artif. Intell.},
  title        = {Securing IoT network with hybrid evolutionary lion intrusion detection system: A composite motion optimisation algorithm for feature selection and ensemble classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced health monitoring in IoT with auto-metric graph neural networks and archimedes optimisation. <em>JETAI</em>, <em>37</em>(7), 1093-1109. (<a href='https://doi.org/10.1080/0952813X.2024.2338495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IoT-based healthcare monitoring systems often lack context-awareness, hindering their ability to provide personalised and accurate healthcare services. The proposed architecture addresses this challenge by incorporating auto-metric graph neural network with Archimedes optimisation algorithm is proposed in this paper for Health Care Monitoring in IoT-based Context-Aware Architecture (ANGNN-AOA-IoT-CA). The proposed work contains four phases: IoT phase, data preprocessing phase, context-aware phase and decision-making phase. In internet of things (IoT) phase, the sensor nodes are used for identifying the health status. Then, the amassed data are stored in storage layer. Hence, in the data preprocessing phase, the data redundancy, recurrence/repetition data are deleted. In context-aware phase, the preprocessed information is presented in the cloud and fog layer. As a result, the context-aware phase minimises the search space activities. In decision-making phase, the data are extracted and given to the ANGNN for classifying as normal and critical condition. Then Archimedes optimisation algorithm is utilised to acquire the better solution. The acquired outcomes of the proposed technique are analysed with existing models. Finally, the proposed method attains 2.37%, 2.95% and 1.17% higher accuracy, 1.09%, 1.47% and 1.53% higher sensitivity, 1.17%, 0.73% and 1.22% higher specificity compared with existing methods.},
  archive      = {J_JETAI},
  author       = {S.S. Arumugam and T. Sripriya and A. Mudassar Ali and Francis H Shajin},
  doi          = {10.1080/0952813X.2024.2338495},
  journal      = {Journal of Experimental & Theoretical Artificial Intelligence},
  month        = {10},
  number       = {7},
  pages        = {1093-1109},
  shortjournal = {J. Exp. Theor. Artif. Intell.},
  title        = {Enhanced health monitoring in IoT with auto-metric graph neural networks and archimedes optimisation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Student’s performance prediction based on an improved multi-view hypergraph neural network. <em>JETAI</em>, <em>37</em>(7), 1075-1091. (<a href='https://doi.org/10.1080/0952813X.2024.2328234'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting students’ academic performance is a crucial area of research in Educational Data Mining. Efficient performance prediction can significantly improve instructional effectiveness, facilitate personalised learning, and identify at-risk students. While researchers have analysed the complex relationships between students’ daily behaviours and their academic performance, most studies focus solely on individual student models and disregard potential relationships among students. To address these issues, we propose an improved multi-view hypergraph neural network (IMHNN). IMHNN employs hypergraphs to establish high-order relationships between student behaviours and introduces an attentional convolutional network to adaptively obtain weights for different behaviours. Additionally, a residual network is introduced to mitigate transition smoothing and improve the generalisation performance of the model. Using a genuine education dataset, we compare the performance of various approaches, demonstrating that our method outperforms other existing methods.},
  archive      = {J_JETAI},
  author       = {Xuefen Lin and Yada Guo},
  doi          = {10.1080/0952813X.2024.2328234},
  journal      = {Journal of Experimental & Theoretical Artificial Intelligence},
  month        = {10},
  number       = {7},
  pages        = {1075-1091},
  shortjournal = {J. Exp. Theor. Artif. Intell.},
  title        = {Student’s performance prediction based on an improved multi-view hypergraph neural network},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent system for solid waste classification using combination of image processing and machine learning models. <em>JETAI</em>, <em>37</em>(7), 1063-1074. (<a href='https://doi.org/10.1080/0952813X.2024.2323043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solid waste is a major issue in all cities around the world. Classification and segregation of solid waste prior to reuse, recycle or recover is an important step towards sustainable waste management. Traditional manual sorting of solid waste is a labour-intensive process that may pose health risks to the workers. Currently, automated classification of solid waste using machine learning techniques is widely applied. This study aims to develop an automated waste classification model by testing traditional and deep machine learning models. To achieve that, both open and generated datasets were used in the model training and testing. The study results showed relatively low prediction capability of the traditional machine learning models like Random Forest (RF) and Support Vector Machine (SVM) as compared to the deep machine learning Convolutional Neural Network (CNN). The testing of the three models on a combined data set of Trashnet with local garbage data set resulted in accuracy of 62.5% for SVM, 72.0% for RF and 92.7% for CNN. JONET deep learning model has been developed using a combination of pre-trained base model (DenseNet 201) with a new architicture that contains a fully connected layer in the classification stage with 1024 neurons. The model is capable to identify six classes of solid waste items with various accuracies. When tested on the Trashnet dataset, the accuracy was 96.06%, while testing on the local garbage dataset gave an accuracy of 94.40%. JONET has been tested also on multi object images which gave an acceptable prediction accuracy.},
  archive      = {J_JETAI},
  author       = {Hani Abu-Qdais and Nawras Shatnawi and Esra’a AL-Alamie},
  doi          = {10.1080/0952813X.2024.2323043},
  journal      = {Journal of Experimental & Theoretical Artificial Intelligence},
  month        = {10},
  number       = {7},
  pages        = {1063-1074},
  shortjournal = {J. Exp. Theor. Artif. Intell.},
  title        = {Intelligent system for solid waste classification using combination of image processing and machine learning models},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence: Reflecting on the past and looking towards the next paradigm shift. <em>JETAI</em>, <em>37</em>(7), 1045-1062. (<a href='https://doi.org/10.1080/0952813X.2024.2323042'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) has undergone major advances over the past decades, propelled by key innovations in machine learning and the availability of big data and computing power. This paper surveys the historical progress of AI from its origins in logic-based systems like the Logic Theorist to recent deep learning breakthroughs like Bidirectional Encoder Representations from Transformers (BERT), Generative Pretrained Transformer 3 (GPT-3) and Large Language Model Meta AI (LLaMA). The early rule-based systems using handcrafted expertise gave way to statistical learning techniques and neural networks trained on large datasets. Milestones like AlexNet and AlphaGo established deep learning as a dominant AI approach. Transfer learning enabled models pre-trained on diverse corpora to excel at specialised downstream tasks. The scope of AI expanded from niche applications like playing chess to multifaceted capabilities in computer vision, natural language processing and dialogue agents. However, current AI still needs to catch up to human intelligence in aspects like reasoning, creativity, and empathy. Addressing limitations around real-world knowledge, biases, and transparency remains vital for further progress and aligning AI with human values. This survey provides a comprehensive overview of the evolution of AI and documents innovations that shaped its advancement over the past six decades.},
  archive      = {J_JETAI},
  author       = {Petar Radanliev},
  doi          = {10.1080/0952813X.2024.2323042},
  journal      = {Journal of Experimental & Theoretical Artificial Intelligence},
  month        = {10},
  number       = {7},
  pages        = {1045-1062},
  shortjournal = {J. Exp. Theor. Artif. Intell.},
  title        = {Artificial intelligence: Reflecting on the past and looking towards the next paradigm shift},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="joas">JOAS - 9</h2>
<ul>
<li><details>
<summary>
(2025). Improving the within-node estimation of survival trees while retaining interpretability. <em>JOAS</em>, <em>52</em>(13), 2544-2558. (<a href='https://doi.org/10.1080/02664763.2025.2473535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In statistical learning for survival data, survival trees are favored for their capacity to detect complex relationships beyond parametric and semiparametric models. Despite this, their prediction accuracy is often suboptimal. In this paper, we propose a new method based on super learning to improve the within-node estimation and overall survival prediction accuracy, while preserving the interpretability of the survival tree. Simulation studies reveal the proposed method's superior finite sample performance compared to conventional approaches for within-node estimation in survival trees. Furthermore, we apply this method to analyze the North Central Cancer Treatment Group Lung Cancer Data, cardiovascular medical records from the Faisalabad Institute of Cardiology, and the integrated genomic data of ovarian carcinoma with The Cancer Genome Atlas project.},
  archive      = {J_JOAS},
  author       = {Haolin Li and Yiyang Fan and Jianwen Cai},
  doi          = {10.1080/02664763.2025.2473535},
  journal      = {Journal of Applied Statistics},
  month        = {10},
  number       = {13},
  pages        = {2544-2558},
  shortjournal = {J. Appl. Stat.},
  title        = {Improving the within-node estimation of survival trees while retaining interpretability},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BSTPP: A python package for bayesian spatiotemporal point processes. <em>JOAS</em>, <em>52</em>(13), 2524-2543. (<a href='https://doi.org/10.1080/02664763.2025.2462969'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatiotemporal point process models have a rich history of effectively modeling event data in space and time. However, they are sometimes neglected due to the difficulty of implementing them. There is a lack of packages with the ability to perform inference for these models, particularly in python. Thus we present BSTPP a python package for Bayesian inference on spatiotemporal point processes. It offers three different kinds of models: space-time separable Log Gaussian Cox, Hawkes, and Cox Hawkes. Users may employ the predefined trigger parameterizations for the Hawkes models, or they may implement their own trigger functions with the extendable Trigger module. For the Cox models, posterior inference on the Gaussian processes is sped up with a pre-trained Variational Auto Encoder (VAE). The package includes a new flexible pre-trained VAE. We validate the model through simulation studies and then explore it by applying it to shooting data in Chicago.},
  archive      = {J_JOAS},
  author       = {Isaac Manring and Honglang Wang and George Mohler and Xenia Miscouridou},
  doi          = {10.1080/02664763.2025.2462969},
  journal      = {Journal of Applied Statistics},
  month        = {10},
  number       = {13},
  pages        = {2524-2543},
  shortjournal = {J. Appl. Stat.},
  title        = {BSTPP: A python package for bayesian spatiotemporal point processes},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diagnostic analytics for the mixed poisson INGARCH model with applications. <em>JOAS</em>, <em>52</em>(13), 2495-2523. (<a href='https://doi.org/10.1080/02664763.2025.2476658'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In statistical diagnosis and sensitivity analysis, the local influence method plays a crucial role and is sometimes more advantageous than other methods. The mixed Poisson integer-valued generalized autoregressive conditional heteroscedastic (INGARCH) model is built on a flexible family of mixed Poisson distributions. It not only encompasses the negative binomial INGARCH model but also allows for the introduction of the Poisson-inverse Gaussian INGARCH model and the Poisson generalized hyperbolic secant INGARCH model. This paper applies the local influence analysis method to count time series data within the framework of the mixed Poisson INGARCH model. For parameter estimation, the Expectation-Maximization algorithm is utilized. In the context of local influence analysis, two global influence methods (generalized Cook distance and Q-distance) and four perturbations–case weights perturbation, data perturbation, additive perturbation, and scale perturbation–are considered to identify influential points. Finally, the feasibility and effectiveness of the proposed methods are demonstrated through simulations and analysis of a real data set.},
  archive      = {J_JOAS},
  author       = {Wenjie Dang and Fukang Zhu and Nuo Xu and Shuangzhe Liu},
  doi          = {10.1080/02664763.2025.2476658},
  journal      = {Journal of Applied Statistics},
  month        = {10},
  number       = {13},
  pages        = {2495-2523},
  shortjournal = {J. Appl. Stat.},
  title        = {Diagnostic analytics for the mixed poisson INGARCH model with applications},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimating an executive summary of a time series: The tendency. <em>JOAS</em>, <em>52</em>(13), 2478-2494. (<a href='https://doi.org/10.1080/02664763.2025.2475351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we revisit the problem of decomposing a signal into a tendency and a residual. The tendency describes an executive summary of a signal that encapsulates its notable characteristics while disregarding seemingly random, less interesting aspects. Building upon the Intrinsic Time Decomposition (ITD) and information-theoretical analysis, we introduce two alternative procedures for selecting the tendency from the ITD baselines. The first is based on the maximum extrema prominence, namely the maximum difference between extrema within each baseline. Specifically this method selects the tendency as the baseline from which an ITD step would produce the largest decline of the maximum prominence. The second method uses the rotations from the ITD and selects the tendency as the last baseline for which the associated rotation is statistically stationary. We delve into a comparative analysis of the information content and interpretability of the tendencies obtained by our proposed methods and those obtained through conventional low-pass filtering schemes, particularly the Hodrik–Prescott (HP) filter. Our findings underscore a fundamental distinction in the nature and interpretability of these tendencies, highlighting their context-dependent utility with emphasis in multi-scale signals. Through a series of real-world applications, we demonstrate the computational robustness and practical utility of our proposed tendencies, emphasizing their adaptability and relevance in diverse time series contexts.},
  archive      = {J_JOAS},
  author       = {Caio Alves and Juan M. Restrepo and Jorge M. Ramirez},
  doi          = {10.1080/02664763.2025.2475351},
  journal      = {Journal of Applied Statistics},
  month        = {10},
  number       = {13},
  pages        = {2478-2494},
  shortjournal = {J. Appl. Stat.},
  title        = {Estimating an executive summary of a time series: The tendency},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical bayesian models for small area estimation with GB2 distribution. <em>JOAS</em>, <em>52</em>(13), 2448-2477. (<a href='https://doi.org/10.1080/02664763.2025.2475349'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present predictive hierarchical Bayesian models to fit continuous, and positively skewed size data from small areas with the generalized beta of the second kind (GB2) distribution. We discuss three different GB2 mixture models. In the models, we have implemented the technique of small areas estimation. The posterior distributions of these models are complex. We have used Taylor series approximations, grid sampling and Metropolis samplers to fit the models. We have applied our models to the per-capita consumption size data from the second Nepal Living Standards Survey. We choose the best fitted model from the three GB2 mixture models. With the best fitted model, we provide small area estimation of poverty indicators by linking the survey data with the census data. A simulation study is provided.},
  archive      = {J_JOAS},
  author       = {Binod Manandhar and Balgobin Nandram},
  doi          = {10.1080/02664763.2025.2475349},
  journal      = {Journal of Applied Statistics},
  month        = {10},
  number       = {13},
  pages        = {2448-2477},
  shortjournal = {J. Appl. Stat.},
  title        = {Hierarchical bayesian models for small area estimation with GB2 distribution},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantile regression model for interval-censored data with competing risks. <em>JOAS</em>, <em>52</em>(13), 2438-2447. (<a href='https://doi.org/10.1080/02664763.2025.2474627'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our interest is to provide the methodology for estimating quantile regression model for interval-censored competing risk data. Lee and Kim [ Analysis of interval censored competing risk data via nonparametric multiple imputation . Stat. Biopharm. Res. 13 (2020), pp. 367–374.] applied a censoring complete data concept suggested by Ruan and Gray [ Analyses of cumulative incidence function via non-parametric multiple imputation . Sta. Med. 27 (2008), pp. 5709–5724.] to recover a missing information related with competing events. In this paper, we also applied it to a quantile regression model. The simulated censoring times of the competing events are generated with a multiple imputation technique and the survival function of right censoring times. The performance of suggested methods is evaluated by comparing with the result of a simple imputation method under several distributions and sample sizes. The AIDS dataset is analyzed to estimate the effect of several covariates on the quantiles of cause-specific CIF as a real data analysis.},
  archive      = {J_JOAS},
  author       = {Amirah Afiqah binti Che Ramli and Yang-Jin Kim},
  doi          = {10.1080/02664763.2025.2474627},
  journal      = {Journal of Applied Statistics},
  month        = {10},
  number       = {13},
  pages        = {2438-2447},
  shortjournal = {J. Appl. Stat.},
  title        = {Quantile regression model for interval-censored data with competing risks},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayes factors for two-group comparisons in cox regression with an application for reverse-engineering raw data from summary statistics. <em>JOAS</em>, <em>52</em>(13), 2413-2437. (<a href='https://doi.org/10.1080/02664763.2025.2472150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of Cox proportional hazards regression to analyze time-to-event data is ubiquitous in biomedical research. Typically, the frequentist framework is used to draw conclusions about whether hazards are different between patients in an experimental and a control condition. We offer a procedure to compute Bayes factors for simple Cox models, both for the scenario where the full data are available and for the scenario where only summary statistics are available. The procedure is implemented in our ‘baymedr’ R package. The usage of Bayes factors remedies some shortcomings of frequentist inference and has the potential to save scarce resources.},
  archive      = {J_JOAS},
  author       = {Maximilian Linde and Jorge N. Tendeiro and Don van Ravenzwaaij},
  doi          = {10.1080/02664763.2025.2472150},
  journal      = {Journal of Applied Statistics},
  month        = {10},
  number       = {13},
  pages        = {2413-2437},
  shortjournal = {J. Appl. Stat.},
  title        = {Bayes factors for two-group comparisons in cox regression with an application for reverse-engineering raw data from summary statistics},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence diagnostics in the heckman selection models based on EM algorithms. <em>JOAS</em>, <em>52</em>(13), 2384-2412. (<a href='https://doi.org/10.1080/02664763.2025.2461715'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents diagnostic techniques for Heckman selection models estimated using the EM algorithm. The focus is on the selection t and normal models, based on the bivariate Student's- t and bivariate normal distributions, respectively. The Heckman selection model is a key econometric tool for estimating relationships while addressing selection bias. Relying on the EM-type algorithm, we develop global and local influence analyses based on the conditional expectation of the complete-data log-likelihood function, exploring four perturbation schemes for local influence analysis. To assess the effectiveness of the proposed diagnostic measures in identifying influential observations, we conducted a simulation study, complemented by two real-data applications that demonstrate how these techniques can effectively identify influential points. The proposed algorithms and methodologies are incorporated into the R package HeckmanEM .},
  archive      = {J_JOAS},
  author       = {Marcos S. Oliveira and Marcos O. Prates and Christian E. Galarza and Victor H. Lachos},
  doi          = {10.1080/02664763.2025.2461715},
  journal      = {Journal of Applied Statistics},
  month        = {10},
  number       = {13},
  pages        = {2384-2412},
  shortjournal = {J. Appl. Stat.},
  title        = {Influence diagnostics in the heckman selection models based on EM algorithms},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Objective bayesian trend filtering via adaptive piecewise polynomial regression. <em>JOAS</em>, <em>52</em>(13), 2357-2383. (<a href='https://doi.org/10.1080/02664763.2025.2461186'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several methods have been developed for nonparametric regression problems, including classical approaches such as kernels, local polynomials, smoothing splines, sieves, and wavelets, as well as relatively new methods such as lasso, generalized lasso, and trend filtering. This study proposes an objective Bayesian trend filtering method based on model selection. The procedure followed in this study estimates the functions based on adaptive piecewise polynomial regression models with two components. First, we determine the intervals with varying trends using Bayesian binary segmentation and then evaluate the most reasonable trend via Bayesian model selection at these intervals. This trend filtering procedure follows Bayesian model selection that uses intrinsic priors, which eliminated any subjective input. Additionally, we prove that the proposed method using these intrinsic priors was consistent when applied to large sample sizes. The behavior of the proposed Bayesian trend filtering procedure is compared with the trend filtering using a simulation study and real examples. Finally, we apply the proposed method to detect the variance change points under mean changes, whereas the existing methods yielded inaccurate estimates of the variance change points when the mean varied smoothly, as the sudden-change assumption was violated in such cases.},
  archive      = {J_JOAS},
  author       = {Sang Gil Kang and Yongku Kim},
  doi          = {10.1080/02664763.2025.2461186},
  journal      = {Journal of Applied Statistics},
  month        = {10},
  number       = {13},
  pages        = {2357-2383},
  shortjournal = {J. Appl. Stat.},
  title        = {Objective bayesian trend filtering via adaptive piecewise polynomial regression},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="oms">OMS - 11</h2>
<ul>
<li><details>
<summary>
(2025). Correction. <em>OMS</em>, <em>40</em>(4), 1014. (<a href='https://doi.org/10.1080/10556788.2025.2516933'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_OMS},
  doi          = {10.1080/10556788.2025.2516933},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {1014},
  shortjournal = {Optim. Methods Softw.},
  title        = {Correction},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exponential convergence rates of a second-order dynamic system and algorithm for a linear equality constrained optimization problem. <em>OMS</em>, <em>40</em>(4), 977-1013. (<a href='https://doi.org/10.1080/10556788.2025.2517174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The O ( 1 / t 2 ) convergence rate of second-order dynamical systems with asymptotic vanishing viscous damping is faster than the O ( 1 / t ) rate of systems with fixed viscous damping in unconstrained and linear equality constrained optimization problems. We explore whether the performance of systems with vanishing viscous damping remains superior when both use time scaling. We compare the best polynomial convergence rates of vanishing damping systems with the best exponential convergence rates of a fixed damping system with time scaling for linear equality constrained problems. We prove that the primal-dual trajectory weakly converges to an optimal solution. Additionally, we present an inertial algorithm derived from the implicit discretization of the dynamical system, establishing exponential convergence rates for the primal-dual gap, feasibility measure, and objective value without assuming strong convexity. The sequence of iterates generated by the inertial algorithm weakly converges to an optimal solution when the objective function is proper, convex, and lower semicontinuous. These results align with those in the continuous setting.},
  archive      = {J_OMS},
  author       = {Ke-wei Ding and Lingling Liu and Phan Tu Vuong},
  doi          = {10.1080/10556788.2025.2517174},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {977-1013},
  shortjournal = {Optim. Methods Softw.},
  title        = {Exponential convergence rates of a second-order dynamic system and algorithm for a linear equality constrained optimization problem},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A proximal-gradient inertial algorithm with tikhonov regularization: Strong convergence to the minimal norm solution. <em>OMS</em>, <em>40</em>(4), 947-976. (<a href='https://doi.org/10.1080/10556788.2025.2517172'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the strong convergence properties of a proximal-gradient inertial algorithm with two Tikhonov regularization terms in connection with the minimization problem of the sum of a convex lower semi-continuous function f and a smooth convex function g . For the appropriate setting of the parameters, we provide the strong convergence of the generated sequence ( x k ) k ≥ 0 to the minimum norm minimizer of our objective function f + g . Further, we obtain fast convergence to zero of the objective function values in a generated sequence but also for the discrete velocity and the sub-gradient of the objective function. We also show that for another setting of the parameters the optimal rate of order O ( k − 2 ) for the potential energy ( f + g ) ( x k ) − min ( f + g ) can be obtained.},
  archive      = {J_OMS},
  author       = {Szilárd Csaba László},
  doi          = {10.1080/10556788.2025.2517172},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {947-976},
  shortjournal = {Optim. Methods Softw.},
  title        = {A proximal-gradient inertial algorithm with tikhonov regularization: Strong convergence to the minimal norm solution},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel approach for solving a class of diffusion identification problems. <em>OMS</em>, <em>40</em>(4), 920-946. (<a href='https://doi.org/10.1080/10556788.2025.2506176'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel approach to the formulation and solution of a class of elliptic diffusion identification problems in the framework of the Pontryagin maximum principle (PMP) is investigated. The proposed approach considers twice continuously differentiable diffusion coefficients defined as the convolution with a square-integrable optimization function, which allows to prove the PMP by spike variation and to construct and analyze an efficient PMP-based iterative algorithm that efficiently solves diffusion identification problems approximated by finite elements.},
  archive      = {J_OMS},
  author       = {Ştefana-Lucia Aniţa and Alfio Borzì},
  doi          = {10.1080/10556788.2025.2506176},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {920-946},
  shortjournal = {Optim. Methods Softw.},
  title        = {A novel approach for solving a class of diffusion identification problems},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). One-point feedback for composite optimization with applications to distributed and federated learning. <em>OMS</em>, <em>40</em>(4), 904-919. (<a href='https://doi.org/10.1080/10556788.2025.2502829'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work is devoted to solving the composite optimization problem with the mixture oracle: for the smooth part of the problem, we have access to the gradient, and for the non-smooth part, only the one-point zero-order oracle is available. For such a setup, we present a new method based on the sliding algorithm. Our method allows to separate the oracle complexities and to compute the gradient for one of the functions as rarely as possible. This paper also presents the applicability of our new method to the problems of distributed optimization and federated learning. Experimental results confirm the theory.},
  archive      = {J_OMS},
  author       = {Aleksandr Beznosikov and Ivan Stepanov and Artyom Voronov and Alexander Gasnikov},
  doi          = {10.1080/10556788.2025.2502829},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {904-919},
  shortjournal = {Optim. Methods Softw.},
  title        = {One-point feedback for composite optimization with applications to distributed and federated learning},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). S2MPJ and CUTEst optimization problems for matlab, python and julia. <em>OMS</em>, <em>40</em>(4), 871-903. (<a href='https://doi.org/10.1080/10556788.2025.2490640'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new suite of test problems for optimization is presented, which contains a large fraction of the problems in the CUTEst collection. The problems are supplied in the form of Matlab, Python and Julia files allowing the computation of values and derivatives of the objective function and constraints directly within ‘native’ Matlab, Python or Julia, without any additional installation or interfacing with MEX files or Fortran programs. These files are produced by a new decoder (written in Matlab) for the original SIF descriptions in the CUTEst collection. When used within Matlab, the new problem files optionally support reduced-precision computations.},
  archive      = {J_OMS},
  author       = {S. Gratton and Ph. L. Toint},
  doi          = {10.1080/10556788.2025.2490640},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {871-903},
  shortjournal = {Optim. Methods Softw.},
  title        = {S2MPJ and CUTEst optimization problems for matlab, python and julia},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum computing and the stable set problem. <em>OMS</em>, <em>40</em>(4), 837-870. (<a href='https://doi.org/10.1080/10556788.2025.2490639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an undirected graph, the stable set problem asks to determine the cardinality of the largest subset of pairwise non-adjacent vertices. This value is called the stability number of the graph, and its computation is an NP-hard problem. In this paper, we solve the stable set problem using the D-Wave quantum annealer. By formulating the problem as a quadratic unconstrained binary optimization problem with the penalty method, we show its optimal value equals the graph's stability number for specific penalty values. However, D-Wave's quantum annealer is a heuristic, so the solutions may be far from the optimum and may not represent stable sets. To address these, we introduce a post-processing procedure that identifies samples that could lead to improved solutions. Additionally, we propose a partitioning method to handle larger instances that cannot be embedded on D-Wave's quantum processing unit. Finally, we investigate how different penalty parameter values affect the solutions' quality. Extensive computational results show that the post-processing procedure significantly improves the solution quality, while the partitioning method successfully extends our approach to medium-size instances.},
  archive      = {J_OMS},
  author       = {Aljaž Krpan and Janez Povh and Dunja Pucher},
  doi          = {10.1080/10556788.2025.2490639},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {837-870},
  shortjournal = {Optim. Methods Softw.},
  title        = {Quantum computing and the stable set problem},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bundle trust-region algorithm for nonsmooth nonconvex constrained optimization. <em>OMS</em>, <em>40</em>(4), 813-836. (<a href='https://doi.org/10.1080/10556788.2025.2475518'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop an algorithm based on the idea of the bundle trust-region method to solve nonsmooth nonconvex constrained optimization problems. The resulting algorithm inherits some attractive features from both bundle and trust-region methods. Moreover, it allows effective control of the size of trust-region subproblems via the compression and aggregation techniques of bundle methods. On the other hand, the trust-region strategy is used to manage the search region and accept a candidate point as a new successful iterate. Global convergence of the developed algorithm is studied under some mild assumptions and its encouraging preliminary computational results are reported.},
  archive      = {J_OMS},
  author       = {N. Hoseini Monjezi and S. Nobakhtian},
  doi          = {10.1080/10556788.2025.2475518},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {813-836},
  shortjournal = {Optim. Methods Softw.},
  title        = {A bundle trust-region algorithm for nonsmooth nonconvex constrained optimization},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Soft quasi-newton: Guaranteed positive definiteness by relaxing the secant constraint. <em>OMS</em>, <em>40</em>(4), 783-812. (<a href='https://doi.org/10.1080/10556788.2025.2475406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel algorithm, termed soft quasi-Newton (soft QN), for optimization in the presence of bounded noise. Traditional quasi-Newton algorithms are vulnerable to such noise-induced perturbations. To develop a more robust quasi-Newton method, we replace the secant condition in the matrix optimization problem for the Hessian update with a penalty term in its objective and derive a closed-form update formula. A key feature of our approach is its ability to maintain positive definiteness of the Hessian inverse approximation throughout the iterations. Furthermore, we establish the following properties of soft QN: it recovers the BFGS method under specific limits, it treats positive and negative curvature equally, and it is scale invariant. Collectively, these features enhance the efficacy of soft QN in noisy environments. For strongly convex objective functions and Hessian approximations obtained using soft QN, we develop an algorithm that exhibits linear convergence toward a neighborhood of the optimal solution even when gradient and function evaluations are subject to bounded perturbations. Through numerical experiments, we demonstrate that soft QN consistently outperforms state-of-the-art methods across a range of scenarios.},
  archive      = {J_OMS},
  author       = {Erik Berglund and Jiaojiao Zhang and Mikael Johansson},
  doi          = {10.1080/10556788.2025.2475406},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {783-812},
  shortjournal = {Optim. Methods Softw.},
  title        = {Soft quasi-newton: Guaranteed positive definiteness by relaxing the secant constraint},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proximal subgradient method for non-lipschitz objective functions. <em>OMS</em>, <em>40</em>(4), 755-782. (<a href='https://doi.org/10.1080/10556788.2025.2475405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a convergence analysis framework of the proximal subgradient method for optimization problems involving non-Lipschitz continuous objective functions. In the conventional analysis of the various subgradient methods, including the proximal subgradient method, the Lipschitz continuity assumption has been placed to guarantee the boundedness of the subgradient and derive the convergence rate. However, the Lipschitz continuity does not hold in practical problems, including the sum-of- ℓ 2 -norms (SO ℓ 2 N) optimal control problem, which is examined in the numerical experiments of this paper. Without the Lipschitz continuity assumption, this paper provides the convergence analysis for strongly convex and non-strongly convex objective functions under mild assumptions. Suitable stepsize rules and resulting convergence rates are established; non-strongly convex cases result in a rate close to the rate of the existing subgradient method, and strongly convex cases achieve the same rate as the existing convergence analysis.},
  archive      = {J_OMS},
  author       = {Mitsuru Toyoda and Mirai Tanaka},
  doi          = {10.1080/10556788.2025.2475405},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {755-782},
  shortjournal = {Optim. Methods Softw.},
  title        = {Proximal subgradient method for non-lipschitz objective functions},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A modified polak-ribière-polyak type conjugate gradient method for vector optimization. <em>OMS</em>, <em>40</em>(4), 725-754. (<a href='https://doi.org/10.1080/10556788.2025.2475402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a modified Polak-Ribière-Polyak conjugate gradient method for solving vector optimization problems. Unlike the existing methods, it is not necessary to use the inner loop with sufficient accurate line search to generate the descent direction at each iteration. Moreover, it does not ignore the fact that the proposed algorithm may still generate the descent direction when the conjugate parameter is negative. We prove that the generated direction is sufficiently descent independent of any line search or convexity. Under the standard Wolfe line search, we also prove the global convergence of the modified Polak-Ribière-Polyak conjugate gradient method without restart or convexity assumption. Finally, through numerical experiments and comparative analysis with the existing methods, we validate the numerical performance of the proposed algorithm.},
  archive      = {J_OMS},
  author       = {Qingjie Hu and Yanyan Zhang and Ruyun Li and Zhibin Zhu},
  doi          = {10.1080/10556788.2025.2475402},
  journal      = {Optimization Methods and Software},
  month        = {7},
  number       = {4},
  pages        = {725-754},
  shortjournal = {Optim. Methods Softw.},
  title        = {A modified polak-ribière-polyak type conjugate gradient method for vector optimization},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="optim">OPTIM - 15</h2>
<ul>
<li><details>
<summary>
(2025). Split common null point problem for generalized monotone operators. <em>OPTIM</em>, <em>74</em>(13), 3401-3417. (<a href='https://doi.org/10.1080/02331934.2024.2371048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present some properties of the resolvent of maximally comonotone (generalized monotone) operators in Hilbert spaces. Also, we study the split common null point problem for a finite family of maximally comonotone operators in Hilbert spaces. For solving this split common null point problem, we propose an inertial algorithm with the step size independent on the prior estimate of the norm of the bounded linear operators and prove strong convergence theorem for this inertial algorithm. The obtained result of this article complements many recent results in this direction.},
  archive      = {J_OPTIM},
  author       = {Mohammad Eslamian},
  doi          = {10.1080/02331934.2024.2371048},
  journal      = {Optimization},
  month        = {10},
  number       = {13},
  pages        = {3401-3417},
  shortjournal = {Optim.},
  title        = {Split common null point problem for generalized monotone operators},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A class modified projection algorithms for nonmonotone variational inequalities with continuity. <em>OPTIM</em>, <em>74</em>(13), 3379-3400. (<a href='https://doi.org/10.1080/02331934.2024.2371041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many well-known projection algorithms may have no convergence results when the mapping lacks generalized monotonicity. This paper proposes a modified projection contraction algorithm and a modified Tseng-type extragradient algorithm for solving nonmonotone variational inequalities. To ensure global convergence of the two new algorithms, we assume only that the mapping is continuous and the solution set of its dual variational inequality is nonempty. In particular, we do not need to assume any generalized monotonicity of the mapping. Numerical experiments are provided to illustrate the efficiency of the proposed algorithms.},
  archive      = {J_OPTIM},
  author       = {Zunjie Huang and Yongle Zhang and Yiran He},
  doi          = {10.1080/02331934.2024.2371041},
  journal      = {Optimization},
  month        = {10},
  number       = {13},
  pages        = {3379-3400},
  shortjournal = {Optim.},
  title        = {A class modified projection algorithms for nonmonotone variational inequalities with continuity},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Necessary optimality conditions for strictly robust bilevel optimization problems. <em>OPTIM</em>, <em>74</em>(13), 3355-3377. (<a href='https://doi.org/10.1080/02331934.2024.2370428'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of robust bilevel programming problems is a relatively new area of optimization theory. In this work, we investigate a bilevel optimization problem where the upper-level and the lower-level constraints incorporate uncertainty. Reducing the problem into a single-level nonlinear and nonsmooth program, necessary optimality conditions are then developed in terms of Clarke subdifferentials. Our approach consists of using the optimal value reformulation together with a partial calmness condition for the robust counterpart of the initial problem. To aid in the detection of Karush-Kuhn-Tucker (KKT) multipliers, an appropriate nonsmooth Mangasarian-Fromovitz constraint qualification is introduced. There are examples highlighting both our results and the limits of certain past studies.},
  archive      = {J_OPTIM},
  author       = {Nazih Abderrazzak Gadhi and Mohamed Ohda},
  doi          = {10.1080/02331934.2024.2370428},
  journal      = {Optimization},
  month        = {10},
  number       = {13},
  pages        = {3355-3377},
  shortjournal = {Optim.},
  title        = {Necessary optimality conditions for strictly robust bilevel optimization problems},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mordukhovich derivatives of the set-valued metric projection operator in general banach spaces. <em>OPTIM</em>, <em>74</em>(13), 3309-3353. (<a href='https://doi.org/10.1080/02331934.2024.2370427'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the properties and the precise solutions of the Mordukhovich derivatives of the set-valued metric projection operator onto some closed balls in some general Banach spaces. In the Banach space c , we find the properties of Mordukhovich derivatives of the set-valued metric projection operator onto the closed subspace c 0 . We show that the metric projection from C [0, 1] to polynomial with degree less than or equal to n is a single-valued mapping. We investigate its Mordukhovich derivatives and G a ˆ teaux directional derivatives.},
  archive      = {J_OPTIM},
  author       = {Jinlu Li},
  doi          = {10.1080/02331934.2024.2370427},
  journal      = {Optimization},
  month        = {10},
  number       = {13},
  pages        = {3309-3353},
  shortjournal = {Optim.},
  title        = {Mordukhovich derivatives of the set-valued metric projection operator in general banach spaces},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Augmented lagrangian method for nonlinear circular conic programs: A local convergence analysis. <em>OPTIM</em>, <em>74</em>(13), 3275-3307. (<a href='https://doi.org/10.1080/02331934.2024.2370426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we analyse a local convergence of augmented Lagrangian method (ALM) for a class of nonlinear circular conic optimization problems. In light of the singular value decomposition, the Debreu theorem and the implicit function theorem, we prove that the sequence generated by ALM converges to a local minimizer in the linear convergence rate under the constraint nondegeneracy condition and the strong second-order sufficient condition, in which the ratio constant is proportional to 1 / τ , where τ is the associated penalty parameter with a given lower threshold. As a byproduct, we also derive explicit expressions of critical cone and its affine hull for the given nonlinear circular conic program.},
  archive      = {J_OPTIM},
  author       = {Yue Lu and Hong-Min Ma and Dong-Yang Xue and Jein-Shan Chen},
  doi          = {10.1080/02331934.2024.2370426},
  journal      = {Optimization},
  month        = {10},
  number       = {13},
  pages        = {3275-3307},
  shortjournal = {Optim.},
  title        = {Augmented lagrangian method for nonlinear circular conic programs: A local convergence analysis},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparative study of different algorithms and scalarization techniques for constructing the pareto front of multiobjective optimization problems. <em>OPTIM</em>, <em>74</em>(13), 3237-3274. (<a href='https://doi.org/10.1080/02331934.2024.2369605'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an analysis and comparison of various algorithms applied to different scalarization methods for multiobjective optimization problems (MOPs). At first, some theoretical results are provided on the relation between (weakly) efficient solutions of an MOP and optimal solutions of the related numerical method. Moreover, we consider some deficiencies in different scalarization approaches given in the literature and try to fill some gaps in these works. Hence, by considering appropriate limitations, we provide sufficient conditions for ( ε -)properly efficient and ( ε -)efficient solutions of an MOP via scalarization techniques. Then, an algorithm for approximating the Pareto front of MOPs is presented. The main purpose of this algorithm is to generate efficient points on the Pareto front with a uniform distribution. One advantage of this algorithm, compared to some other algorithms, is that in each iteration of the algorithm, more than one efficient point located on the Pareto border can be generated. The new algorithm is implemented by applying the modified Pascoletti–Serafini, the unified direction, and the modified normal boundary intersection scalarization techniques, and then the procedures are considered on different test problems including (non-)convex and discrete Pareto fronts. The capability of the numerical method is shown by comparing the results with the algorithms in the literature. To compare the algorithms, measures of coverage and spacing metric indicators are used.},
  archive      = {J_OPTIM},
  author       = {F. Akbari and E. Khorram and M. Ghaznavi},
  doi          = {10.1080/02331934.2024.2369605},
  journal      = {Optimization},
  month        = {10},
  number       = {13},
  pages        = {3237-3274},
  shortjournal = {Optim.},
  title        = {A comparative study of different algorithms and scalarization techniques for constructing the pareto front of multiobjective optimization problems},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantitative stability for stochastic tensor variational inequalities. <em>OPTIM</em>, <em>74</em>(13), 3221-3236. (<a href='https://doi.org/10.1080/02331934.2024.2367679'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of this article is to investigate a class of stochastic tensor variational inequalities (denoted by STVI), which is a generalization of the stochastic linear variational inequalities (denoted by SLVI) and a subclass of stochastic variational inequalities (denoted by SVI). The quantitative stability of the expected residual minimization (ERM) problem for the STVI is analysed. Firstly, the existence of solutions of the ERM problem and its perturbed problem are considered. Then, the quantitative stability of the ERM problem is derived under suitable probability metrics. Finally, under some suitable assumptions, the rates of convergence of the sample average approximation (SAA) method for the optimal solution sets of the perturbed problems are discussed.},
  archive      = {J_OPTIM},
  author       = {Tong-tong Shang and Guo-ji Tang},
  doi          = {10.1080/02331934.2024.2367679},
  journal      = {Optimization},
  month        = {10},
  number       = {13},
  pages        = {3221-3236},
  shortjournal = {Optim.},
  title        = {Quantitative stability for stochastic tensor variational inequalities},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel single-parameter continuously differentiable filled function for global optimization. <em>OPTIM</em>, <em>74</em>(13), 3203-3220. (<a href='https://doi.org/10.1080/02331934.2024.2367642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The filled function approach is an effective global optimization method. The properties of the filled function directly affect the efficiency of the algorithm and have been discussed by many scholars, resulting in various new forms of filled functions. However, most of existing filled functions are not continuously differentiable and have parameters that are difficult to adjust. To remedy this problem, a new continuously differentiable filled function with an easily adjustable parameter is constructed. According to the theoretical analysis of the filled function, a new easy-to-implement filled function algorithm is designed utilizing the efficient local search algorithm based on gradient information. Numerical experiments show that the proposed filled function algorithm is a feasible and effective global optimization algorithm with less computational cost.},
  archive      = {J_OPTIM},
  author       = {Yan Xu and Deqiang Qu},
  doi          = {10.1080/02331934.2024.2367642},
  journal      = {Optimization},
  month        = {10},
  number       = {13},
  pages        = {3203-3220},
  shortjournal = {Optim.},
  title        = {A novel single-parameter continuously differentiable filled function for global optimization},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantitative stability for a class of stochastic vector linear variational inequalities. <em>OPTIM</em>, <em>74</em>(13), 3179-3201. (<a href='https://doi.org/10.1080/02331934.2024.2367637'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the expected value (for short, EV) formulation for a class of stochastic vector linear variational inequalities (for short, SVLVI). We first discuss the existence of solutions to both the original problem and its perturbed problem. Then, under suitable probability metrics, we derive the quantitative stability of SVLVI. Finally, we study the discrete approximation problem, and obtain the rates of convergence of optimal solution sets under different assumptions.},
  archive      = {J_OPTIM},
  author       = {Jianxun Liu and Liqin Lin and Yong Zhao and Changcheng Gong},
  doi          = {10.1080/02331934.2024.2367637},
  journal      = {Optimization},
  month        = {10},
  number       = {13},
  pages        = {3179-3201},
  shortjournal = {Optim.},
  title        = {Quantitative stability for a class of stochastic vector linear variational inequalities},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modified subgradient extragradient method for solution of split variational inequality problem with application to generalized nash equilibrium problem. <em>OPTIM</em>, <em>74</em>(13), 3143-3177. (<a href='https://doi.org/10.1080/02331934.2024.2358413'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, we propose modified subgradient extragradient method to find the common solution of split variational inequality problem and common fixed point problem of a finite family of demicontractive mappings without knowing norm of bounded linear operator and Lipschitz constants of the associated pseudomonotone operators. We obtain the strong convergence result for the proposed method under certain mild conditions. This result extends and generalizes many recent results in this direction. Furthermore, we demonstrate how our findings may be used to solve a generalized Nash equilibrium problem and LASSO problem. Finally, we give numerical experiments to validate the performance of our algorithm and compare it with other existing methods.},
  archive      = {J_OPTIM},
  author       = {Renu Chugh and Nishu Gupta and Charu Batra},
  doi          = {10.1080/02331934.2024.2358413},
  journal      = {Optimization},
  month        = {10},
  number       = {13},
  pages        = {3143-3177},
  shortjournal = {Optim.},
  title        = {Modified subgradient extragradient method for solution of split variational inequality problem with application to generalized nash equilibrium problem},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pre-conditioning CQ algorithm for solving the split feasibility problem and its application to image restoration problem. <em>OPTIM</em>, <em>74</em>(13), 3123-3141. (<a href='https://doi.org/10.1080/02331934.2024.2358412'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we define two pre-conditioning CQ algorithms for the split feasibility problem by using self-adaptive and line-search techniques in the real Hilbert space. One of the self-adaptive techniques is used to obtain optimal step size. These techniques do not require prior knowledge of the operator norm or estimation of the matrix norm. We also establish weak convergence theorems with respect to particular norms. As an application, numerical experiments show that the proposed algorithm is effective in image restoration problem.},
  archive      = {J_OPTIM},
  author       = {Ebru Altıparmak and Lateef Olakunle Jolaoso and Ibrahim Karahan and Habib ur Rehman},
  doi          = {10.1080/02331934.2024.2358412},
  journal      = {Optimization},
  month        = {10},
  number       = {13},
  pages        = {3123-3141},
  shortjournal = {Optim.},
  title        = {Pre-conditioning CQ algorithm for solving the split feasibility problem and its application to image restoration problem},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A minimax approach to duality for linear distributional sensitivity testing. <em>OPTIM</em>, <em>74</em>(13), 3113-3121. (<a href='https://doi.org/10.1080/02331934.2024.2358410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the dual formulation of the problem of finding the maximum of 𝔼 𝜈 ⁡ [ 𝑓 ⁡ ( 𝑋 ) ] , where ν is allowed to vary over all the probability measures on a Polish space X for which d c ( μ , ν ) ≤ r , with d c an optimal transport distance, f a real-valued function on X satisfying some regularity, μ a ‘baseline’ measure and r ≥ 0 . Whereas some derivations of the dual rely on Fenchel duality, applied on a vector space of functions in duality with a vector space of measures, we impose compactness on X to allow the use of the minimax theorem of Ky Fan, which does not require vector space structure.},
  archive      = {J_OPTIM},
  author       = {Gusti van Zyl},
  doi          = {10.1080/02331934.2024.2358410},
  journal      = {Optimization},
  month        = {10},
  number       = {13},
  pages        = {3113-3121},
  shortjournal = {Optim.},
  title        = {A minimax approach to duality for linear distributional sensitivity testing},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Levitin–Polyak well-posedness of split multivalued variational inequalities. <em>OPTIM</em>, <em>74</em>(13), 3081-3111. (<a href='https://doi.org/10.1080/02331934.2024.2358408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce and study the split multivalued variational inequality problem (SMVIP) and the parametric SMVIP. We examine, in particular, Levitin–Polyak well-posedness of SMVIPs and parametric SMVIPs in Hilbert spaces. We provide several examples to illustrate our theoretical results. We also discuss several important special cases.},
  archive      = {J_OPTIM},
  author       = {Soumitra Dey and Simeon Reich},
  doi          = {10.1080/02331934.2024.2358408},
  journal      = {Optimization},
  month        = {10},
  number       = {13},
  pages        = {3081-3111},
  shortjournal = {Optim.},
  title        = {Levitin–Polyak well-posedness of split multivalued variational inequalities},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). First- and second-order optimality conditions for the control of infinite horizon Navier–Stokes equations. <em>OPTIM</em>, <em>74</em>(13), 3037-3080. (<a href='https://doi.org/10.1080/02331934.2024.2358406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {First and second-order optimality conditions for optimal control problems over the infinite time horizon subject to the Navier–Stokes equations are derived. The cost functional enhances temporal sparsity of the controls, which implies that the optimal controls shut down in finite time. The problem formulation also includes explicit constraints on the control which may be non-smooth and non-affine.},
  archive      = {J_OPTIM},
  author       = {Eduardo Casas and Karl Kunisch},
  doi          = {10.1080/02331934.2024.2358406},
  journal      = {Optimization},
  month        = {10},
  number       = {13},
  pages        = {3037-3080},
  shortjournal = {Optim.},
  title        = {First- and second-order optimality conditions for the control of infinite horizon Navier–Stokes equations},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual kuhn-tucker necessary conditions for strict minima of order two for nonsmooth vector optimization problems with inequality and equality constraints. <em>OPTIM</em>, <em>74</em>(13), 3007-3035. (<a href='https://doi.org/10.1080/02331934.2024.2358403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we give primal and dual Kuhn-Tucker necessary conditions for the existence of a strict local minimum of order two for vector optimization problems with equality and inequality constraints under some new regularity conditions. First, we improve the existing primal necessary conditions for such minima. Then, we apply an alternative theorem to derive dual Kuhn-Tucker necessary conditions of second and higher-order. To compare our results to the ones in the literature, we provide some examples.},
  archive      = {J_OPTIM},
  author       = {Elena Constantin},
  doi          = {10.1080/02331934.2024.2358403},
  journal      = {Optimization},
  month        = {10},
  number       = {13},
  pages        = {3007-3035},
  shortjournal = {Optim.},
  title        = {Dual kuhn-tucker necessary conditions for strict minima of order two for nonsmooth vector optimization problems with inequality and equality constraints},
  volume       = {74},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="tas">TAS - 14</h2>
<ul>
<li><details>
<summary>
(2025). Learn r: As a language, 2nd ed.. <em>TAS</em>, <em>79</em>(3), 417-419. (<a href='https://doi.org/10.1080/00031305.2025.2490305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TAS},
  author       = {Haihan Yu},
  doi          = {10.1080/00031305.2025.2490305},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {417-419},
  shortjournal = {Am. Stat.},
  title        = {Learn r: As a language, 2nd ed.},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonparametric statistical methods using r, 2nd ed.. <em>TAS</em>, <em>79</em>(3), 416. (<a href='https://doi.org/10.1080/00031305.2025.2484865'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TAS},
  author       = {Bojana Milošević},
  doi          = {10.1080/00031305.2025.2484865},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {416},
  shortjournal = {Am. Stat.},
  title        = {Nonparametric statistical methods using r, 2nd ed.},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data science in practice. <em>TAS</em>, <em>79</em>(3), 416-417. (<a href='https://doi.org/10.1080/00031305.2025.2490304'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TAS},
  author       = {Xiao Hui Tai},
  doi          = {10.1080/00031305.2025.2490304},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {416-417},
  shortjournal = {Am. Stat.},
  title        = {Data science in practice},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Connections between statistics and Mathematics/Probability. <em>TAS</em>, <em>79</em>(3), 410-415. (<a href='https://doi.org/10.1080/00031305.2025.2453230'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are many connections between probability, other mathematics courses, and statistics. Understanding these connections provides insights that might not be fully appreciated when considering each discipline in isolation. While the typical instruction of statistics courses relies on elucidating its foundational principles from mathematical and probability theory, it is generally less appreciated that statistics can in turn provide a deeper understanding of results in mathematics and probability. We offer several examples for which knowledge of statistics can shed new light on probability and other mathematics results. Examples span both undergraduate and graduate level material. In today’s data driven-world, many students are naturally curious about statistics and are exposed to this field early in their undergraduate curriculum. Leveraging connections between statistics and mathematics and probability makes theoretical concepts more intuitive and relevant, fostering a better understanding.},
  archive      = {J_TAS},
  author       = {Michael A. Proschan and Pamela A. Shaw},
  doi          = {10.1080/00031305.2025.2453230},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {410-415},
  shortjournal = {Am. Stat.},
  title        = {Connections between statistics and Mathematics/Probability},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analytics, have some humility: A statistical view of fourth-down decision making. <em>TAS</em>, <em>79</em>(3), 393-409. (<a href='https://doi.org/10.1080/00031305.2025.2475801'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The standard mathematical approach to fourth-down decision-making in American football is to make the decision that maximizes estimated win probability. Win probability estimates arise from machine learning models fit from historical data. These models attempt to capture a nuanced relationship between a noisy binary outcome variable and game-state variables replete with interactions and non-linearities from a finite dataset of just a few thousand games. Thus, it is imperative to knit uncertainty quantification into the fourth-down decision procedure; we do so using bootstrapping. We find that uncertainty in the estimated optimal fourth-down decision is far greater than that currently expressed by sports analysts in popular sports media.},
  archive      = {J_TAS},
  author       = {Ryan S. Brill and Ronald Yurko and Abraham J. Wyner},
  doi          = {10.1080/00031305.2025.2475801},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {393-409},
  shortjournal = {Am. Stat.},
  title        = {Analytics, have some humility: A statistical view of fourth-down decision making},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An example to illustrate randomized trial estimands and estimators. <em>TAS</em>, <em>79</em>(3), 383-392. (<a href='https://doi.org/10.1080/00031305.2025.2468399'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the International Conference on Harmonisation finalized an estimand framework for randomized trials that was adopted by regulatory bodies worldwide. The framework introduced five strategies for handling post-randomization events; namely the treatment policy, composite variable, while on treatment, hypothetical and principal stratum estimands. We describe an illustrative example to elucidate the difference between these five strategies for handling intercurrent events and provide an estimation technique for each. Specifically, we consider the intercurrent event of treatment discontinuation and introduce potential outcome notation to describe five estimands and corresponding estimators: (1) an intention-to-treat estimator of the total effect of a treatment policy; (2) an intention-to-treat estimator of a composite of the outcome and remaining on treatment; (3) a per-protocol estimator of the outcome in individuals observed to remain on treatment; (4) a g-computation estimator of a hypothetical scenario that all individuals remain on treatment; and (5) a principal stratum estimator of the treatment effect in individuals who would remain on treatment under the experimental condition. Additional insight is provided by defining situations where certain estimands are equal, and by studying the while on treatment strategy under repeated outcome measures. We highlight relevant causal inference literature to enable adoption in practice.},
  archive      = {J_TAS},
  author       = {Linda J. Harrison and Sean S. Brummel},
  doi          = {10.1080/00031305.2025.2468399},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {383-392},
  shortjournal = {Am. Stat.},
  title        = {An example to illustrate randomized trial estimands and estimators},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flexible distributed lag models for count data using mgcv. <em>TAS</em>, <em>79</em>(3), 371-382. (<a href='https://doi.org/10.1080/00031305.2025.2505514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this tutorial we present the use of R package mgcv to implement Distributed Lag Non-Linear Models (DLNMs) in a flexible way. Interpretation of smoothing splines as random quantities enables approximate Bayesian inference, which in turn allows uncertainty quantification and comprehensive model checking. We illustrate various modeling situations using open-access epidemiological data in conjunction with simulation experiments. We demonstrate the inclusion of temporal structures and the use of mixture distributions to allow for extreme outliers. Moreover, we demonstrate interactions of the temporal lagged structures with other covariates with different lagged periods for different covariates. Spatial structures are also demonstrated, including smooth spatial variability and Markov random fields, in addition to hierarchical formulations to allow for non-structured dependency. Posterior predictive simulation is used to ensure models verify well against the data.},
  archive      = {J_TAS},
  author       = {Theo Economou and Daphne Parliari and Aurelio Tobias and Laura Dawkins and Hamish Steptoe and Christophe Sarran and Oliver Stoner and Rachel Lowe and Jos Lelieveld},
  doi          = {10.1080/00031305.2025.2505514},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {371-382},
  shortjournal = {Am. Stat.},
  title        = {Flexible distributed lag models for count data using mgcv},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analyzing spatial point patterns in digital pathology: Immune cells in high-grade serous ovarian carcinomas. <em>TAS</em>, <em>79</em>(3), 355-370. (<a href='https://doi.org/10.1080/00031305.2025.2459280'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiplex immunofluorescence (mIF) imaging technology facilitates the study of the tumor microenvironment in cancer patients. Due to the capabilities of this emerging bioimaging technique, it is possible to statistically analyze, for example, the co-varying location and functions of multiple different types of immune cells. Complex spatial relationships between different immune cells have been shown to correlate with patient outcomes and may reveal new pathways for targeted immunotherapy treatments. This tutorial reviews methods and procedures relating to spatial point patterns for complex data analysis. We consider tissue cells as a realization of a spatial point process for each patient. We focus on proper functional descriptors for each observation and techniques that allow us to obtain information about inter-patient variation. Ovarian cancer is the deadliest gynaecological malignancy and can resist chemotherapy treatment effective in cancers. We use a dataset of high-grade serous ovarian cancer samples from 51 patients. We examine the immune cell composition (T cells, B cells, macrophages) within tumors and additional information such as cell classification (tumor or stroma) and other patient clinical characteristics. Our analyses, supported by reproducible software, apply to other digital pathology datasets.},
  archive      = {J_TAS},
  author       = {Jonatan A. González and Julia Wrobel and Simon Vandekar and Paula Moraga},
  doi          = {10.1080/00031305.2025.2459280},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {355-370},
  shortjournal = {Am. Stat.},
  title        = {Analyzing spatial point patterns in digital pathology: Immune cells in high-grade serous ovarian carcinomas},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Play-by-play volleyball win probability model. <em>TAS</em>, <em>79</em>(3), 345-354. (<a href='https://doi.org/10.1080/00031305.2025.2490786'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a volleyball point-by-point win probability model that updates the probability of winning a set after each play in the set. The covariate informed product partition model (PPMx) is well suited to flexibly include in-set team performance information when making predictions. However, making predictions in real time would be too expensive computationally as it would require refitting the PPMx after each play. Instead, we develop a predictive procedure based on a single training of the PPMx that predicts in real-time. We deploy this procedure using data from the 2018 Men’s World Volleyball Championship. The procedure first trains a PPMx model using end-of-set team performance statistics from the round robin stage of the tournament. Then based on the PPMx predictive distribution, we predict the win probability after every play of every match in the knockout stages. Finally, we show how the prediction procedure can be enhanced by including pre-set information toward the beginning of the set and set score toward the end.},
  archive      = {J_TAS},
  author       = {Nathan Hawkins and Gilbert W. Fellingham and Garritt L. Page},
  doi          = {10.1080/00031305.2025.2490786},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {345-354},
  shortjournal = {Am. Stat.},
  title        = {Play-by-play volleyball win probability model},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Closed-form power and sample size calculations for bayes factors. <em>TAS</em>, <em>79</em>(3), 330-344. (<a href='https://doi.org/10.1080/00031305.2025.2467919'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining an appropriate sample size is a critical element of study design, and the method used to determine it should be consistent with the planned analysis. When the planned analysis involves Bayes factor hypothesis testing, the sample size is usually desired to ensure a sufficiently high probability of obtaining a Bayes factor indicating compelling evidence for a hypothesis, given that the hypothesis is true. In practice, Bayes factor sample size determination is typically performed using computationally intensive Monte Carlo simulation. Here, we summarize alternative approaches that enable sample size determination without simulation. We show how, under approximate normality assumptions, sample sizes can be determined numerically, and provide the R package bfpwr for this purpose. Additionally, we identify conditions under which sample sizes can even be determined in closed-form, resulting in novel, easy-to-use formulas that also help foster intuition, enable asymptotic analysis, and can also be used for hybrid Bayesian/likelihoodist design. Furthermore, we show how power and sample size can be computed without simulation for more complex analysis priors, such as Jeffreys-Zellner-Siow priors or non-local normal moment priors. Case studies from medicine and psychology illustrate how researchers can use our methods to design informative yet cost-efficient studies.},
  archive      = {J_TAS},
  author       = {Samuel Pawel and Leonhard Held},
  doi          = {10.1080/00031305.2025.2467919},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {330-344},
  shortjournal = {Am. Stat.},
  title        = {Closed-form power and sample size calculations for bayes factors},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A class of regression association measures based on concordance. <em>TAS</em>, <em>79</em>(3), 320-329. (<a href='https://doi.org/10.1080/00031305.2024.2448431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measures of regression association aiming at predictability of a dependent variable Y from an independent variable X have received considerable attention recently. In this article, we provide a unified discussion of some existing measures, including their rationale, properties, and estimation. Motivated by these measures, we consider a general class of regression association measures which views the regression association of Y from X as the association of two independent replications from the conditional distribution of Y given X . We illustrate that the so-called Markov product copulas can be employed as a neat and convenient building block for this class of measures, and the measures so constructed can be expressed as a common form of the proportion of the variance of some function of Y that can be explained by X , rendering the measures a direct interpretation in terms of predictability. Also, the notion of two independent replications from the conditional distribution leads to a simple nonparametric estimation method based on the induced order statistics, hence, no smoothing techniques are required. Under the considered general framework, the performances and utilities of the regression association measures are examined through simulations and real data applications.},
  archive      = {J_TAS},
  author       = {Jia-Han Shih and Yi-Hau Chen},
  doi          = {10.1080/00031305.2024.2448431},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {320-329},
  shortjournal = {Am. Stat.},
  title        = {A class of regression association measures based on concordance},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Laplace’s law of succession estimator and M-statistics. <em>TAS</em>, <em>79</em>(3), 311-319. (<a href='https://doi.org/10.1080/00031305.2024.2448430'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classic formula for estimating the binomial probability as the proportion of successes contradicts common sense for extreme probabilities when the event never occurs or occurs every time. Laplace’s law of succession estimator, one of the first applications of Bayesian statistics, has been around for over 250 years and resolves the paradoxes, although rarely discussed in modern statistics texts. This work aims to introduce a new theory for exact optimal statistical inference using Laplace’s law of succession estimator as a motivating example. We prove that this estimator may be viewed from a different theoretical perspective as the limit point of the short confidence interval on the double-log scale when the confidence level approaches zero. This motivating example paves the road to the definition of an estimator as the inflection point on the cumulative distribution function as a function of the parameter given the observed statistic. This estimator has the maximum infinitesimal probability of the coverage of the unknown parameter and, therefore, is called the maximum concentration (MC) estimator as a part of a more general M-statistics theory. The new theory is illustrated with exact optimal confidence intervals for the normal standard deviation and the respective MC estimators.},
  archive      = {J_TAS},
  author       = {Eugene Demidenko},
  doi          = {10.1080/00031305.2024.2448430},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {311-319},
  shortjournal = {Am. Stat.},
  title        = {Laplace’s law of succession estimator and M-statistics},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient computation strategy for generalized single-index models and their variants by integrating with GAM. <em>TAS</em>, <em>79</em>(3), 302-310. (<a href='https://doi.org/10.1080/00031305.2025.2464854'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various generalizations of single-index models and associated estimation methods have been developed. However, implementing these developed methods requires much effort to program, case by case, due to the lack of a common and flexible vehicle to cover them. We suggest an efficient computation strategy for easily estimating parameters and nonparametric functions in generalized single-index models and generalized partially linear single-index models by integrating with well-developed algorithms and packages for estimating the generalized additive models (Wood; Hastie and Tibshirani, GAM). Such an integration makes estimation in these index-type models much easier, expedient, and flexible and brings a lot of convenience. We briefly introduce the principle and extensively examine numerical performance for various scenarios. Numerical experiments indicate that the proposed strategy works well with finite sample sizes and is especially flexible to model structures. Finally, we analyze two real-data examples as an illustration.},
  archive      = {J_TAS},
  author       = {Ximin Li and Haozhe Liang and Hua Liang},
  doi          = {10.1080/00031305.2025.2464854},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {302-310},
  shortjournal = {Am. Stat.},
  title        = {An efficient computation strategy for generalized single-index models and their variants by integrating with GAM},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiple imputation approach for the cumulative incidence, with implications for variance estimation. <em>TAS</em>, <em>79</em>(3), 291-301. (<a href='https://doi.org/10.1080/00031305.2025.2453674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an alternative approach to estimating the cumulative incidence function that uses nonparametric multiple imputation to reduce the problem to that of estimating a binomial proportion. In the standard competing risks setting, we show mathematically and empirically that our imputation-based estimator is equivalent to the Aalen-Johansen estimator of the cumulative incidence given a sufficient number of imputations. However, our approach allows for the use of a wider variety of methods for the analysis of binary outcomes, including preferred options for uncertainty estimation. While we focus on the cumulative incidence function, the multiple imputation approach likely extends to more complex problems in competing risks.},
  archive      = {J_TAS},
  author       = {Elizabeth C. Chase and Philip S. Boonstra and Jeremy M. G. Taylor},
  doi          = {10.1080/00031305.2025.2453674},
  journal      = {The American Statistician},
  month        = {7},
  number       = {3},
  pages        = {291-301},
  shortjournal = {Am. Stat.},
  title        = {A multiple imputation approach for the cumulative incidence, with implications for variance estimation},
  volume       = {79},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
