<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>INSR</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="insr">INSR - 7</h2>
<ul>
<li><details>
<summary>
(2025). Statistical depth meets machine learning: Kernel mean embeddings and depth in functional data analysis. <em>INSR</em>, <em>93</em>(2), 317-348. (<a href='https://doi.org/10.1111/insr.12611'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistical depth is the act of gauging how representative a point is compared with a reference probability measure. The depth allows introducing rankings and orderings to data living in multivariate, or function spaces. Though widely applied and with much experimental success, little theoretical progress has been made in analysing functional depths. This article highlights how the common h -depth and related depths from functional data analysis can be viewed as a kernel mean embedding, widely used in statistical machine learning. This facilitates answers to several open questions regarding the statistical properties of functional depths. We show that (i) h -depth has the interpretation of a kernel-based method; (ii) several h -depths possess explicit expressions, without the need to estimate them using Monte Carlo procedures; (iii) under minimal assumptions, -depths and their maximisers are uniformly strongly consistent and asymptotically Gaussian (also in infinite-dimensional spaces and for imperfectly observed functional data); and (iv) several -depths uniquely characterise probability distributions in separable Hilbert spaces. In addition, we also provide a link between the depth and empirical characteristic function based procedures for functional data. Finally, the unveiled connections enable to design an extension of the -depth towards regression problems.},
  archive      = {J_INSR},
  author       = {George Wynne and Stanislav Nagy},
  doi          = {10.1111/insr.12611},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {317-348},
  shortjournal = {Int. Stat. Rev.},
  title        = {Statistical depth meets machine learning: Kernel mean embeddings and depth in functional data analysis},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How do applied researchers use the causal forest? a methodological review. <em>INSR</em>, <em>93</em>(2), 288-316. (<a href='https://doi.org/10.1111/insr.12610'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This methodological review examines the use of the causal forest method by applied researchers across 133 peer-reviewed papers. It shows that the emerging best practice relies heavily on the approach and tools created by the original authors of the causal forest such as their grf package and the approaches given by them in examples. Generally, researchers use the causal forest on a relatively low-dimensional dataset relying on observed controls or in some cases experiments to identify effects. There are several common ways to then communicate results–by mapping out the univariate distribution of individual-level treatment effect estimates, displaying variable importance results for the forest and graphing the distribution of treatment effects across covariates that are important either for theoretical reasons or because they have high variable importance. Some deviations from this common practice are interesting and deserve further development and use. Others are unnecessary or even harmful. The paper concludes by reflecting on the emerging best practice for causal forest use and paths for future research.},
  archive      = {J_INSR},
  author       = {Patrick Rehill},
  doi          = {10.1111/insr.12610},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {288-316},
  shortjournal = {Int. Stat. Rev.},
  title        = {How do applied researchers use the causal forest? a methodological review},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature screening for ultrahigh dimensional mixed data via wasserstein distance. <em>INSR</em>, <em>93</em>(2), 267-287. (<a href='https://doi.org/10.1111/insr.12609'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article develops a novel feature screening procedure for ultrahigh dimensional mixed data based on Wasserstein distance, termed as Wasserstein-SIS. To handle the mixture of continuous and discrete data, we use Wasserstein distance as a new marginal utility to measure the difference between the joint distribution and the product of marginal distributions. In theory, we establish the sure screening property under less restrictive assumptions on data types. The proposed procedure does not require model specification, gives a more effective geometric measure to compare the discrepancy between distributions and avoids introducing biases caused by the choice of slicing rules for continuous data. Numerical comparison indicates that the proposed Wasserstein-SIS method performs better than existing methods in various models. A real data application also validates the better practicability of Wasserstein-SIS.},
  archive      = {J_INSR},
  author       = {Bing Tian and Hong Wang},
  doi          = {10.1111/insr.12609},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {267-287},
  shortjournal = {Int. Stat. Rev.},
  title        = {Feature screening for ultrahigh dimensional mixed data via wasserstein distance},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revisiting estimation of number of trials in binomial distribution. <em>INSR</em>, <em>93</em>(2), 246-266. (<a href='https://doi.org/10.1111/insr.12608'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the parameter n when p is known or simultaneous estimation of n and p of the binomial distribution based on k ≥ 1 independent observations has been considered by many authors over the last several decades. A range of estimators have been proposed, and questions regarding asymptotic and small sample properties received adequate treatment. In this paper, we provide an extensive review and a comprehensive performance comparison of the estimators from the literature. We propose a conceptually simple estimator of n that uses the marginal likelihood when p is integrated out by simultaneous optimisation w.r.t. n and the hyperparameters. We compare the proposed estimator with various existing estimators and find its performance competitive and, in some scenarios, superior.},
  archive      = {J_INSR},
  author       = {Mina Georgieva and Brani Vidakovic},
  doi          = {10.1111/insr.12608},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {246-266},
  shortjournal = {Int. Stat. Rev.},
  title        = {Revisiting estimation of number of trials in binomial distribution},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the number of components for matrix-variate mixtures: A comparison among information criteria. <em>INSR</em>, <em>93</em>(2), 222-245. (<a href='https://doi.org/10.1111/insr.12607'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the crucial task of determining the optimal number of components in mixture models, known as mixture order, when considering matrix-variate data. Despite the growing interest in this data type among practitioners and researchers, the effectiveness of information criteria in selecting the mixture order remains largely unexplored in this branch of the literature. Although the Bayesian information criterion (BIC) is commonly utilised, its effectiveness is only marginally tested in this context, and several other potentially valuable criteria exist. An extensive simulation study evaluates the performance of 10 information criteria across various data structures, specifically focusing on matrix-variate normal mixtures.},
  archive      = {J_INSR},
  author       = {Salvatore D. Tomarchio and Antonio Punzo},
  doi          = {10.1111/insr.12607},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {222-245},
  shortjournal = {Int. Stat. Rev.},
  title        = {On the number of components for matrix-variate mixtures: A comparison among information criteria},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chance-corrected interrater agreement statistics for two-rater dichotomous responses: A method review with comparative assessment under possibly correlated decisions. <em>INSR</em>, <em>93</em>(2), 199-221. (<a href='https://doi.org/10.1111/insr.12606'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measurement of the interrater agreement (IRA) is critical for assessing the reliability and validity of ratings in various disciplines. While numerous IRA statistics have been developed, there is a lack of guidance on selecting appropriate measures especially when raters' decisions could be correlated. To address this gap, we review a family of chance-corrected IRA statistics for two-rater dichotomous-response cases, a fundamental setting that not only serves as the theoretical foundation for categorical-response or multirater IRA methods but is also practically dominant in most empirical studies, and we propose a novel data-generating framework to simulate correlated decision processes between raters. Subsequently, a new estimand, which calibrates the ‘true’ chance-corrected IRA, is introduced while accounting for the potential ‘probabilistic certainty’. Extensive simulations were conducted to evaluate the performance of the reviewed IRA methods under various practical scenarios and were summarised by an agglomerative hierarchical clustering analysis. Finally, we provide recommendations for selecting appropriate IRA statistics based on outcome prevalence and rater characteristics and highlight the need for further advancements in IRA estimation methodologies.},
  archive      = {J_INSR},
  author       = {Zizhong Tian and Vernon M. Chinchilli and Chan Shen and Shouhao Zhou},
  doi          = {10.1111/insr.12606},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {199-221},
  shortjournal = {Int. Stat. Rev.},
  title        = {Chance-corrected interrater agreement statistics for two-rater dichotomous responses: A method review with comparative assessment under possibly correlated decisions},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A conversation with amy racine-poon. <em>INSR</em>, <em>93</em>(2), 183-198. (<a href='https://doi.org/10.1111/insr.12605'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Professor Dr. Amy Racine-Poon is best known for her interdisciplinary contributions as an applied Bayesian statistician in the pharmaceutical industry and healthcare. She was born in Hong Kong and obtained a BA with upper honors in Mathematics (1970) from the Chinese University of Hong Kong. She earned a PhD in statistics from the University of California, Berkeley, under the supervision of Erich L. Lehmann. She worked as a Lecturer at the Department of Statistics at UC Berkeley (1975–1977) and as a Statistician at the Biometry Branch of the National Institute of Environmental Health in Research Triangle Park, North Carolina (1977–1980). Amy moved to Basel, Switzerland, in 1981 to join Ciba-Geiby/Novartis AG, where she worked for 42 years (1981–2023) across different therapeutic areas and stages of drug development, applying her skills in advanced statistical and pharmacometric methodologies that led to the development of large number of new drugs. During her career, she was also a Visiting Professor at the Department of Mathematics, Imperial College London (1995–1997) and a Volunteer Statistical Expert at Bill & Melinda Gates Foundation, Seattle, Washington (2015–2019). Amy Racine-Poon's numerous honors include the Royal Statistical Society Greenfield Industrial Medal for Innovative Use of Statistics in the Industries (1995), Fellow of the American Statistical Association (1997), Novartis Distinguished Scientist Award (1999), American Statistical Association Youden Interlaboratory Research Award (2020) and the Sheiner-Beal Pharmacometrics Award (2024) from the American Society of Clinical Pharmacology and Therapeutics. The following conversation took place between Oleksandr Sverdlov (Alex) and Amy Racine-Poon (Amy) in October 2024.},
  archive      = {J_INSR},
  author       = {Oleksandr Sverdlov},
  doi          = {10.1111/insr.12605},
  journal      = {International Statistical Review},
  month        = {8},
  number       = {2},
  pages        = {183-198},
  shortjournal = {Int. Stat. Rev.},
  title        = {A conversation with amy racine-poon},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
