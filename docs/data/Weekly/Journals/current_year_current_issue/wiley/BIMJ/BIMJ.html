<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>BIMJ</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="bimj">BIMJ - 11</h2>
<ul>
<li><details>
<summary>
(2025). Weibull regression with both measurement error and misclassification in covariates. <em>BIMJ</em>, <em>67</em>(5), e70083. (<a href='https://doi.org/10.1002/bimj.70083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of measurement error and misclassification in covariates is ubiquitous in nutritional epidemiology and some other research areas, which often leads to biased estimate and loss of power. However, addressing both measurement error and misclassification simultaneously in a single analysis is challenged and less actively studied, especially in regression model for survival data with censoring. The approximate maximum likelihood estimation (AMLE) has been proved to be an effective method to correct both measurement error and misclassification simultaneously in a logistic regression model. However, its impact on survival analysis models has not been studied. In this paper, we study biases caused by both measurement error and misclassification in covariates from a Weibull accelerated failure time model, and explore the use of AMLE and its asymptotic properties to correct these biases. Extensive simulation studies are conducted to evaluate the finite-sample performance of the resulting estimator. The proposed method is then applied to deal with measurement error and misclassification in some nutrients of interest from the EPIC-InterAct Study.},
  archive      = {J_BIMJ},
  author       = {Zhiqiang Cao and Man Yu Wong},
  doi          = {10.1002/bimj.70083},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {5},
  pages        = {e70083},
  shortjournal = {Bio. J.},
  title        = {Weibull regression with both measurement error and misclassification in covariates},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving genomic prediction using high-dimensional secondary phenotypes: The genetic latent factor approach. <em>BIMJ</em>, <em>67</em>(5), e70081. (<a href='https://doi.org/10.1002/bimj.70081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decreasing costs and new technologies have led to an increase in the amount of data available to plant breeding programs. High-throughput phenotyping (HTP) platforms routinely generate high-dimensional datasets of secondary features that may be used to improve genomic prediction accuracy. However, integration of these data comes with challenges such as multicollinearity, parameter estimation in settings, and the computational complexity of many standard approaches. Several methods have emerged to analyze such data, but interpretation of model parameters often remains challenging. We propose genetic latent factor best linear unbiased prediction (glfBLUP), a prediction pipeline that reduces the dimensionality of the original secondary HTP data using generative factor analysis. In short, glfBLUP uses redundancy filtered and regularized genetic and residual correlation matrices to fit a maximum likelihood factor model and estimate genetic latent factor scores. These latent factors are subsequently used in multitrait genomic prediction. Our approach performs better than alternatives in extensive simulations and a real-world application, while producing easily interpretable and biologically relevant parameters. We discuss several possible extensions and highlight glfBLUP as the basis for a flexible and modular multitrait genomic prediction framework.},
  archive      = {J_BIMJ},
  author       = {Killian A. C. Melsen and Jonathan F. Kunst and José Crossa and Margaret R. Krause and Fred A. van Eeuwijk and Willem Kruijer and Carel F. W. Peeters},
  doi          = {10.1002/bimj.70081},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {5},
  pages        = {e70081},
  shortjournal = {Bio. J.},
  title        = {Improving genomic prediction using high-dimensional secondary phenotypes: The genetic latent factor approach},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated mixed effects logistic regression based on one-time shared summary statistics. <em>BIMJ</em>, <em>67</em>(5), e70080. (<a href='https://doi.org/10.1002/bimj.70080'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Upholding data privacy, especially in medical research, has become tantamount to facing difficulties in accessing individual-level patient data. Estimating mixed effects binary logistic regression models involving data from multiple data providers, like hospitals, thus becomes more challenging. Federated learning has emerged as an option to preserve the privacy of individual observations while still estimating a global model that can be interpreted on the individual level, but it usually involves iterative communication between the data providers and the data analyst. In this paper, we present a strategy to estimate a mixed effects binary logistic regression model that requires data providers to share summary statistics only once. It involves generating pseudo-data whose summary statistics match those of the actual data and using these in the model estimation process instead of the actual unavailable data. Our strategy is able to include multiple predictors, which can be a combination of continuous and categorical variables. Through simulation, we show that our approach estimates the true model at least as good as the one that requires the pooled individual observations. An illustrative example using real data is provided. Unlike typical federated learning algorithms, our approach eliminates infrastructure requirements and security issues while being communication efficient and while accounting for heterogeneity.},
  archive      = {J_BIMJ},
  author       = {Marie Analiz April Limpoco and Christel Faes and Niel Hens},
  doi          = {10.1002/bimj.70080},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {5},
  pages        = {e70080},
  shortjournal = {Bio. J.},
  title        = {Federated mixed effects logistic regression based on one-time shared summary statistics},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multivariate bayesian dynamic borrowing for repeated measures data with application to external control arms in open-label extension studies. <em>BIMJ</em>, <em>67</em>(5), e70079. (<a href='https://doi.org/10.1002/bimj.70079'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Borrowing analyses are increasingly important in clinical trials. We develop a method for using robust mixture priors in multivariate dynamic borrowing. The method was motivated by a desire to produce causally valid, long-term treatment effect estimates of a continuous endpoint from a single active-arm open-label extension study following a randomized clinical trial by dynamically incorporating prior beliefs from a long-term external control arm. The proposed method is a generally applicable Bayesian dynamic borrowing analysis for estimates of multivariate summary metrics based on a multivariate normal likelihood function for various parameter models, some of which we describe. There are important connections to estimation incorporating a prior belief for a hypothetical estimand strategy, that is, had the event not occurred, for intercurrent events which lead to missing data.},
  archive      = {J_BIMJ},
  author       = {Benjamin F. Hartley and Matthew A. Psioda and Adrian P. Mander},
  doi          = {10.1002/bimj.70079},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {5},
  pages        = {e70079},
  shortjournal = {Bio. J.},
  title        = {Multivariate bayesian dynamic borrowing for repeated measures data with application to external control arms in open-label extension studies},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new logistic model with subject-specific and serially correlated time-specific distribution-free random effects on the unit interval for longitudinal binary data. <em>BIMJ</em>, <em>67</em>(5), e70078. (<a href='https://doi.org/10.1002/bimj.70078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various beta-binomial mixed effects models have been developed in recent years for longitudinal binary data; however, these approaches rely heavily on the parametric specification of beta and normal random effects. Furthermore, their incorporation of normal random effects into beta-binomial models has been done at the sacrifice of certain computational convenience and clear interpretation with beta-binomial models. In this paper, we introduce a new model that incorporates subject-specific and serially correlated time-specific distribution-free random effects on the unit interval into logistic regression multiplicatively with fixed effects. This new multiplicative model facilitates the interpretation of random effects on the unit interval as risk modifiers. This multiplicative model setup also eases the model derivation and random effects prediction. A quasi-likelihood approach has been developed in the estimation of our model. Our results are robust against random effects distributions. Our method is illustrated through the analysis of multiple sclerosis trial data.},
  archive      = {J_BIMJ},
  author       = {Lulu Zhang and Renjun Ma and Guohua Yan and Xifen Huang},
  doi          = {10.1002/bimj.70078},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {5},
  pages        = {e70078},
  shortjournal = {Bio. J.},
  title        = {A new logistic model with subject-specific and serially correlated time-specific distribution-free random effects on the unit interval for longitudinal binary data},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inference under covariate-adaptive randomization using random center-effect. <em>BIMJ</em>, <em>67</em>(5), e70076. (<a href='https://doi.org/10.1002/bimj.70076'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimization method is a popular choice for covariate-adaptive randomization in multicenter trials. Existing literature suggests that the type-I error is controlled if minimization variables are included in the statistical analysis. However, in practice, minimization variables with many categories, such as the recruitment center, are often not included in the model. In this paper, we propose including the minimization variable “center” as a random effect and assess its performance using simulations for Gaussian, binary, and Poisson endpoint variables. Our simulation study suggests that the random-effect model controls type-I error and preserves maximum power for all three endpoints under varied clinical trial settings. This approach offers an alternative to the re-randomization test, which regulatory authorities often suggest for sensitivity analysis.},
  archive      = {J_BIMJ},
  author       = {Anjali Pandey and Harsha Shree BS and Andrea Callegaro},
  doi          = {10.1002/bimj.70076},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {5},
  pages        = {e70076},
  shortjournal = {Bio. J.},
  title        = {Inference under covariate-adaptive randomization using random center-effect},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ADDIS-graphs for online error control with application to platform trials. <em>BIMJ</em>, <em>67</em>(5), e70075. (<a href='https://doi.org/10.1002/bimj.70075'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In contemporary research, online error control is often required, where an error criterion, such as familywise error rate (FWER) or false discovery rate (FDR), shall remain under control while testing an a priori unbounded sequence of hypotheses. The existing online literature mainly considered large-scale studies and constructed powerful but rigid algorithms for these. However, smaller studies, such as platform trials, require high flexibility and easy interpretability to take study objectives into account and facilitate the communication. Another challenge in platform trials is that due to the shared control arm some of the -values are dependent and significance levels need to be prespecified before the decisions for all the past treatments are available. We propose adaptive-discarding-Graphs (ADDIS-Graphs) with FWER control that due to their graphical structure perfectly adapt to such settings and provably uniformly improve the state-of-the-art method. We introduce several extensions of these ADDIS-Graphs, including the incorporation of information about the joint distribution of the -values and a version for FDR control.},
  archive      = {J_BIMJ},
  author       = {Lasse Fischer and Marta Bofill Roig and Werner Brannath},
  doi          = {10.1002/bimj.70075},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {5},
  pages        = {e70075},
  shortjournal = {Bio. J.},
  title        = {ADDIS-graphs for online error control with application to platform trials},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flexible parametric accelerated failure time models with cure. <em>BIMJ</em>, <em>67</em>(5), e70074. (<a href='https://doi.org/10.1002/bimj.70074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accelerated failure time (AFT) models offer an attractive alternative to Cox proportional hazards models. AFT models are collapsible and, unlike hazard ratios in proportional hazards models, the acceleration factor—a key effect measure in AFT models—is collapsible, meaning its value remains unchanged when adjusting for additional covariates. In addition, AFT models provide an intuitive interpretation directly on the survival time scale. From the recent development of smooth parametric AFT models, we identify potential issues with their applications and note several desired extensions that have not yet been implemented. To enrich this tool and its application in clinical research, we improve the AFT models within a flexible parametric framework in several ways: we adopt monotone natural splines to constrain the log cumulative hazard to be a monotonic function across its support; allow for time-varying acceleration factors, possibly include cure and accommodating more than one time-varying effect; and implement both mixture and nonmixture cure models. We implement all of these extensions in the rstpm2 package, which is publicly available on CRAN. Simulations highlight a varying success in estimating cure fractions. However, in terms of covariate-effect estimation, flexible AFT models appear to be more robust than the Cox model even when there is a high proportion of cured individuals in the data, regardless of whether cure is reached within the observed data. We also apply some of our extensions of AFT models to real-world survival data.},
  archive      = {J_BIMJ},
  author       = {Birzhan Akynkozhayev and Benjamin Christoffersen and Xingrong Liu and Keith Humphreys and Mark Clements},
  doi          = {10.1002/bimj.70074},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {5},
  pages        = {e70074},
  shortjournal = {Bio. J.},
  title        = {Flexible parametric accelerated failure time models with cure},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimands for early-phase dose optimization trials in oncology. <em>BIMJ</em>, <em>67</em>(5), e70072. (<a href='https://doi.org/10.1002/bimj.70072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phase I dose escalation trials in oncology generally aim to find the maximum tolerated dose. However, with the advent of molecular-targeted therapies and antibody drug conjugates, dose-limiting toxicities are less frequently observed, giving rise to the concept of optimal biological dose (OBD), which considers both efficacy and toxicity. The estimand framework presented in the addendum of the ICH E9(R1) guidelines strengthens the dialogue between different stakeholders by bringing in greater clarity in the clinical trial objectives and by providing alignment between the targeted estimand under consideration and the statistical analysis methods. However, there is a lack of clarity in implementing this framework in early-phase dose optimization studies. This paper aims to discuss the estimand framework for dose optimization trials in oncology, considering efficacy and toxicity through utility functions. Such trials should include pharmacokinetics data, toxicity data, and efficacy data. Based on these data, the analysis methods used to identify the optimized dose/s are also described. Focusing on optimizing the utility function to estimate the OBD, the population-level summary measure should reflect only the properties used for estimating this utility function. A detailed strategy recommendation for intercurrent events has been provided using a real-life oncology case study. Key recommendations regarding the estimand attributes include that in a seamless phase I/II dose optimization trial, the treatment attribute should start when the subject receives the first dose. We argue that such a framework brings in additional clarity to dose optimization trial objectives and strengthens the understanding of the drug under consideration, which would enable the correct dose to move to phase II of clinical development.},
  archive      = {J_BIMJ},
  author       = {Ayon Mukherjee and Jonathan L. Moscovici and Zheng Liu},
  doi          = {10.1002/bimj.70072},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {5},
  pages        = {e70072},
  shortjournal = {Bio. J.},
  title        = {Estimands for early-phase dose optimization trials in oncology},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hazards, causality, and practical relevance of collider effects – Comment on beyersmann et al. “Hazards constitute key quantities for analyzing, interpreting and understanding time-to-event data”. <em>BIMJ</em>, <em>67</em>(5), e70071. (<a href='https://doi.org/10.1002/bimj.70071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hazards constitute key quantities for analyzing, interpreting, and understanding time-to-event data. Hazards and corresponding effect measures, such as the hazard ratio from the Cox proportional hazards model, have a valid causal interpretation if the hazard function is considered as a function in time rather than hazards at specific time points. In this comment, we would like to add two points: (1) The hazard ratio is also a useful population-level estimand with a valid causal interpretation. (2) Empirical evidence shows that problematic situations, which could occur in theory due to strong heterogeneity, are usually avoided in typical randomized controlled trials.},
  archive      = {J_BIMJ},
  author       = {Ralf Bender and Lars Beckmann},
  doi          = {10.1002/bimj.70071},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {5},
  pages        = {e70071},
  shortjournal = {Bio. J.},
  title        = {Hazards, causality, and practical relevance of collider effects – Comment on beyersmann et al. “Hazards constitute key quantities for analyzing, interpreting and understanding time-to-event data”},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unified estimation method for partially linear models with nonmonotone missing at random data. <em>BIMJ</em>, <em>67</em>(5), e70070. (<a href='https://doi.org/10.1002/bimj.70070'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partially linear models are commonly used in observational studies of the causal effect of treatment and/or exposure when there are observed confounding variables. The models are robust and asymptotically distribution-free for testing the causal null hypothesis. In this research, we investigate methods for estimating the partially linear models with data missing at random in all the variables, including the response, the treatment, and the confounding variables. We develop a general estimation method for inference in partially linear models with nonmonotone missing at random data. It proposes using partially linear working models to improve the estimation efficiency of the standard complete case method. It can be shown that the new estimator is consistent, which does not depend on the correctness of the working models. In addition, we recommend bootstrap estimates for the asymptotic variances and semiparametric models for the missing data probabilities. It is computationally simple and can be directly implemented in standard software. Simulation studies are provided to examine its performance. A real data example with sparsely observed missingness patterns is used to illustrate the method.},
  archive      = {J_BIMJ},
  author       = {Yang Zhao},
  doi          = {10.1002/bimj.70070},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {5},
  pages        = {e70070},
  shortjournal = {Bio. J.},
  title        = {Unified estimation method for partially linear models with nonmonotone missing at random data},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
