<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SJOS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="sjos">SJOS - 12</h2>
<ul>
<li><details>
<summary>
(2025). Corrigendum to “Statistical inference for generative adversarial networks and other minimax problems”. <em>SJOS</em>, <em>52</em>(3), 1477-1478. (<a href='https://doi.org/10.1111/sjos.12793'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SJOS},
  doi          = {10.1111/sjos.12793},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1477-1478},
  shortjournal = {Scand. J. Stat.},
  title        = {Corrigendum to “Statistical inference for generative adversarial networks and other minimax problems”},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dimension reduction for the estimation of the conditional tail index. <em>SJOS</em>, <em>52</em>(3), 1444-1476. (<a href='https://doi.org/10.1111/sjos.12792'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are interested in the relationship between the large values of a real random variable and its associated multidimensional covariate, in the context where the conditional distribution is heavy-tailed. Estimating the positive conditional tail index of a heavy-tailed conditional distribution is a crucial step for statistical inference, but the task becomes increasingly challenging as the covariate dimension increases. In this work, we assume the existence of a lower-dimensional linear subspace such that the conditional tail index depends on the covariate only through its projection onto this subspace. We propose a method to estimate this dimension reduction subspace and establish its consistency. Additionally, we introduce an estimator of the conditional tail index that leverages this dimension reduction and prove its consistency. We illustrate the benefits of this dimension reduction approach for estimating the conditional tail index through simulations and an application to real-world data.},
  archive      = {J_SJOS},
  author       = {Laurent Gardes and Alexandre Podgorny},
  doi          = {10.1111/sjos.12792},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1444-1476},
  shortjournal = {Scand. J. Stat.},
  title        = {Dimension reduction for the estimation of the conditional tail index},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse fréchet sufficient dimension reduction with graphical structure among predictors. <em>SJOS</em>, <em>52</em>(3), 1422-1443. (<a href='https://doi.org/10.1111/sjos.12791'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fréchet regression has received considerable attention to model metric-space valued responses that are complex and non-Euclidean data, such as probability distributions and vectors on the unit sphere. However, existing Fréchet regression literature focuses on the classical setting where the predictor dimension is fixed, and the sample size goes to infinity. This paper proposes sparse Fréchet sufficient dimension reduction with graphical structure among high-dimensional Euclidean predictors. In particular, we propose a convex optimization problem that leverages the graphical information among predictors and avoids inverting the high-dimensional covariance matrix. We also provide the Alternating Direction Method of Multipliers (ADMM) algorithm to solve the optimization problem. Theoretically, the proposed method achieves subspace estimation and variable selection consistency under suitable conditions. Extensive simulations and a real data analysis are carried out to illustrate the finite-sample performance of the proposed method.},
  archive      = {J_SJOS},
  author       = {Jiaying Weng and Kai Tan and Cheng Wang and Zhou Yu},
  doi          = {10.1111/sjos.12791},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1422-1443},
  shortjournal = {Scand. J. Stat.},
  title        = {Sparse fréchet sufficient dimension reduction with graphical structure among predictors},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Statistical disaggregation—A monte carlo approach for imputation under constraints. <em>SJOS</em>, <em>52</em>(3), 1376-1421. (<a href='https://doi.org/10.1111/sjos.12790'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Equality-constrained models naturally arise in problems in which the measurements are taken at different levels of resolution. The challenge in this setting is that the models usually induce a joint distribution which is intractable. Resorting to instead sampling from the joint distribution by means of a Monte Carlo approach is also challenging. For example, a naive rejection sampler does not work when the probability mass of the constraint is zero. A typical example of such constrained problems is to learn energy consumption for a higher resolution level based on data at a lower resolution, for example, to decompose a daily reading into readings at a finer level. We introduce a novel Monte Carlo sampling algorithm based on Langevin diffusions and rejection sampling to solve the problem of sampling from equality-constrained models. Our method has the advantage of being exact for linear constraints and naturally deals with multimodal distributions on arbitrary constraints. We test our method on statistical disaggregation problems for electricity consumption datasets, and our approach provides better uncertainty estimation and accuracy in data imputation compared with other naive/unconstrained methods.},
  archive      = {J_SJOS},
  author       = {Shenggang Hu and Hongsheng Dai and Fanlin Meng and Louis Aslett and Murray Pollock and Gareth O. Roberts},
  doi          = {10.1111/sjos.12790},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1376-1421},
  shortjournal = {Scand. J. Stat.},
  title        = {Statistical disaggregation—A monte carlo approach for imputation under constraints},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semiparametric regression with localized bregman divergence. <em>SJOS</em>, <em>52</em>(3), 1330-1375. (<a href='https://doi.org/10.1111/sjos.12789'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on semiparametric regression based on minimizing the localized Bregman divergence. A local parametric model derived from the framework of the generalized linear model with multiple covariates and a linear predictor is utilized. The parameter vector included in the model is estimated under localization. The asymptotic behavior of both the locally estimated parameter vector and the induced regression estimator is investigated. Theoretical comparisons of estimators by using the divergence risk measure are also addressed. Further generalization, including a multivariate polynomial predictor, is explored, where Faa di Bruno's theorem concerning the derivative of a composition of multivariate functions is efficiently utilized. Simulations and application to a real dataset demonstrate that the proposed regression estimator works efficiently.},
  archive      = {J_SJOS},
  author       = {Hiroki Kosugi and Kanta Naito and Spiridon Penev},
  doi          = {10.1111/sjos.12789},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1330-1375},
  shortjournal = {Scand. J. Stat.},
  title        = {Semiparametric regression with localized bregman divergence},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Testing relevant hypotheses in functional variance function via self-normalization. <em>SJOS</em>, <em>52</em>(3), 1301-1329. (<a href='https://doi.org/10.1111/sjos.12788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel methodology for testing relevant hypotheses in the functional variance functions of contaminated functional data via spline-backfitted kernel smoothing and self-normalization. Our approach focuses on testing the null hypothesis of no relevant deviation instead of exact equality, such as the equality of two variance functions from two independent measurement errors. The proposed statistics enable testing of relevant hypotheses in one-sample, two-sample, and single or multiple change points problems, and exhibit oracle efficiency, meaning that developed procedures are asymptotically indistinguishable from those with true trajectories. Additionally, we demonstrate the finite sample properties of our proposed tests using a simulation study and electroencephalogram (EEG) data.},
  archive      = {J_SJOS},
  author       = {Qirui Hu},
  doi          = {10.1111/sjos.12788},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1301-1329},
  shortjournal = {Scand. J. Stat.},
  title        = {Testing relevant hypotheses in functional variance function via self-normalization},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A minimum wasserstein distance approach to fisher's combination of independent, discrete p-values. <em>SJOS</em>, <em>52</em>(3), 1281-1300. (<a href='https://doi.org/10.1111/sjos.12787'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a comprehensive framework to adjust a discrete test statistic for improving its hypothesis testing procedure. The adjustment minimizes the Wasserstein distance to a null-approximating continuous distribution, tackling some fundamental challenges inherent in combining statistical significances derived from discrete distributions. The related theory justifies Lancaster's mid-p and mean-value chi-squared statistics for Fisher's combination as special cases. To counter the conservative nature of Lancaster's testing procedures, we propose an updated null-approximating distribution. It is achieved by further minimizing the Wasserstein distance to the adjusted statistics within an appropriate distribution family. Specifically, in the context of Fisher's combination, we propose an optimal gamma distribution as a substitute for the traditionally used chi-squared distribution. This new approach yields an asymptotically consistent test that significantly improves Type I error control and enhances statistical power.},
  archive      = {J_SJOS},
  author       = {Gonzalo Contador and Zheyang Wu},
  doi          = {10.1111/sjos.12787},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1281-1300},
  shortjournal = {Scand. J. Stat.},
  title        = {A minimum wasserstein distance approach to fisher's combination of independent, discrete p-values},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced branching latin hypercube design and its application in automatic algorithm configuration. <em>SJOS</em>, <em>52</em>(3), 1239-1280. (<a href='https://doi.org/10.1111/sjos.12786'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing experiments that involve branching and nested factors is challenging due to the complex relationships between these factors. Identification of optimal settings requires designs with good stratification properties for both nested and shared factors. To meet this requirement, we defined a type of enhanced branching Latin hypercube designs and developed several novel construction methods by integrating orthogonal arrays and sliced Latin hypercube designs. These designs exhibit attractive low-dimensional stratification properties and perform well in terms of column correlation. Additionally, the size of each design can be flexibly chosen based on the trade-off between the experimental budget and estimation accuracy. The simulation results demonstrate that the proposed design method exhibits significant superiority in terms of design metrics and estimation accuracy. Furthermore, we showcase the application of these designs in initializing automatic algorithm configuration. The proofs and additional design tables are provided in the Appendix.},
  archive      = {J_SJOS},
  author       = {Bing Wen and Sumin Wang and Fasheng Sun},
  doi          = {10.1111/sjos.12786},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1239-1280},
  shortjournal = {Scand. J. Stat.},
  title        = {Enhanced branching latin hypercube design and its application in automatic algorithm configuration},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mode-adaptive factor models. <em>SJOS</em>, <em>52</em>(3), 1206-1238. (<a href='https://doi.org/10.1111/sjos.12785'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Factor models are indispensable tools in economics and finance, providing valuable insights into the latent structures underlying complex datasets. Nevertheless, the prevalence of heavy-tailed macroeconomic and financial data, often characterized by extreme values and greater skewness than that found in a normal distribution, presents significant analytical challenges. This article introduces mode-adaptive factor models (MAFM) for robust factor analysis in high-dimensional panel data, inspired by the equivalence between conventional principal component analysis and the constrained least squares method in factor models. Unlike traditional factor models that concentrate on mean estimation, MAFM leverage the mode to capture central tendencies more effectively, particularly in the presence of skewed and heavy-tailed distributions. To facilitate MAFM for factor analysis, we develop an iterative mode regression algorithm that integrates the expectation-maximization procedure, ensuring convergence to a stationary solution. We establish the theoretical properties of the MAFM estimators without imposing moment constraints on idiosyncratic errors and propose a mode information criterion for consistent factor number selection. We also suggest a data-dependent bandwidth selection procedure to enhance the flexibility of MAFM. The simulation studies demonstrate the effectiveness of MAFM across diverse distributional settings. An empirical application to macroeconomic forecasting further highlights the practical advantages of MAFM, showcasing their robustness and efficacy in real-world analyses.},
  archive      = {J_SJOS},
  author       = {Tao Wang},
  doi          = {10.1111/sjos.12785},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1206-1238},
  shortjournal = {Scand. J. Stat.},
  title        = {Mode-adaptive factor models},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unifying class of compound poisson integer-valued ARMA and GARCH models. <em>SJOS</em>, <em>52</em>(3), 1176-1205. (<a href='https://doi.org/10.1111/sjos.12784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {INAR (integer-valued autoregressive) and INGARCH (integer-valued GARCH) models are among the most commonly employed approaches for count time series modeling, but have been studied in largely distinct strands of literature. In this paper, a new class of generalized integer-valued ARMA (GINARMA) models is introduced which unifies a large number of compound Poisson INAR and INGARCH processes. Its stochastic properties, including stationarity and geometric ergodicity, are studied. Particular attention is given to a generalization of the INAR( p ) model which parallels the extension of the INARCH( p ) to the INGARCH( p , q ) model. For inference, we consider maximum likelihood, Gaussian quasi-likelihood, and moment-based approaches, along with likelihood ratio tests to distinguish between selected instances of our class. Models from the proposed class have a natural interpretation as stochastic epidemic processes, which throughout the article is used to illustrate our arguments. In a case study, different instances, including both established and newly introduced models, are applied to weekly case numbers of measles and mumps in Bavaria, Germany.},
  archive      = {J_SJOS},
  author       = {Johannes Bracher and Barbora Němcová},
  doi          = {10.1111/sjos.12784},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1176-1205},
  shortjournal = {Scand. J. Stat.},
  title        = {A unifying class of compound poisson integer-valued ARMA and GARCH models},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining stochastic tendency and distribution overlap towards improved nonparametric effect measures and inference. <em>SJOS</em>, <em>52</em>(3), 1138-1175. (<a href='https://doi.org/10.1111/sjos.12783'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fundamental functional in nonparametric statistics is the Mann-Whitney functional θ = P ⁡ ( X < Y ) , which constitutes the basis for the most popular nonparametric procedures. The functional θ measures a location or stochastic tendency effect between two distributions. A limitation of is its inability to capture scale differences. If differences of this nature are to be detected, specific tests for scale or omnibus tests need to be employed. However, the latter often suffer from low power, and they do not yield interpretable effect measures. In this article, we extend by additionally incorporating the recently introduced distribution overlap index (nonparametric dispersion measure) that can be expressed in terms of the quantile process. We derive the joint asymptotic distribution of the respective estimators of and and construct confidence regions. Extending the Wilcoxon–Mann–Whitney test, we introduce a new test based on the joint use of these functionals. It results in much larger consistency regions while maintaining competitive power to the rank sum test for situations in which alone would suffice. Compared with classical omnibus tests, the simulated power is much improved. Additionally, the newly proposed inference method yields effect measures whose interpretation is surprisingly straightforward.},
  archive      = {J_SJOS},
  author       = {Jonas Beck and Patrick B. Langthaler and Arne C. Bathke},
  doi          = {10.1111/sjos.12783},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1138-1175},
  shortjournal = {Scand. J. Stat.},
  title        = {Combining stochastic tendency and distribution overlap towards improved nonparametric effect measures and inference},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bandwidth selection for kernel intensity estimators for spatial point processes. <em>SJOS</em>, <em>52</em>(3), 1111-1137. (<a href='https://doi.org/10.1111/sjos.12782'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intensity estimation through kernel smoothing is a popular non-parametric method of describing the characteristics of an underlying spatial point process. Key to the accuracy of this estimate is the choice of bandwidth. Too large or small a bandwidth can lead to features in the intensity being lost or to the introduction of artefacts. There are many available methods of bandwidth selection for spatial point patterns, but no consensus on the best option. Popular methods and software default options lead to very different intensity estimates and contrasting conclusions about the data that can be difficult to reconcile. In response, we propose new bandwidth selectors with more stable and consistent performance. These are adapted from popular plug-in and cross-validation techniques developed for general multivariate density estimation. The theoretical and practical performance of these proposed methods is explored and compared with other available methods in both simulated and real-data scenarios. We find that our proposed methods perform consistently well across a range of different intensity patterns. We end with a discussion on the implications of edge effects when applying these methods, given the constrained windows in which spatial point patterns are often observed.},
  archive      = {J_SJOS},
  author       = {Bethany J. Macdonald and Tilman M. Davies and Martin L. Hazelton},
  doi          = {10.1111/sjos.12782},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1111-1137},
  shortjournal = {Scand. J. Stat.},
  title        = {Bandwidth selection for kernel intensity estimators for spatial point processes},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
