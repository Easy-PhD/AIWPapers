<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>CAAITIT</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="caaitit">CAAITIT - 20</h2>
<ul>
<li><details>
<summary>
(2025). Unified neural lexical analysis via two-stage span tagging. <em>CAAITIT</em>, <em>10</em>(4), 1254-1267. (<a href='https://doi.org/10.1049/cit2.70015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lexical analysis is a fundamental task in natural language processing, which involves several subtasks, such as word segmentation (WS), part-of-speech (POS) tagging, and named entity recognition (NER). Recent works have shown that taking advantage of relatedness between these subtasks can be beneficial. This paper proposes a unified neural framework to address these subtasks simultaneously. Apart from the sequence tagging paradigm, the proposed method tackles the multitask lexical analysis via two-stage sequence span classification. Firstly, the model detects the word and named entity boundaries by multi-label classification over character spans in a sentence. Then, the authors assign POS labels and entity labels for words and named entities by multi-class classification, respectively. Furthermore, a Gated Task Transformation (GTT) is proposed to encourage the model to share valuable features between tasks. The performance of the proposed model was evaluated on Chinese and Thai public datasets, demonstrating state-of-the-art results.},
  archive      = {J_CAAITIT},
  author       = {Yantuan Xian and Yefen Zhu and Zhentao Yu and Yuxin Huang and Junjun Guo and Yan Xiang},
  doi          = {10.1049/cit2.70015},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1254-1267},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Unified neural lexical analysis via two-stage span tagging},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring high dimensional feature space with channel-spatial nonlinear transforms for learned image compression. <em>CAAITIT</em>, <em>10</em>(4), 1235-1253. (<a href='https://doi.org/10.1049/cit2.70025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear transforms have significantly advanced learned image compression (LIC), particularly using residual blocks. This transform enhances the nonlinear expression ability and obtain compact feature representation by enlarging the receptive field, which indicates how the convolution process extracts features in a high dimensional feature space. However, its functionality is restricted to the spatial dimension and network depth, limiting further improvements in network performance due to insufficient information interaction and representation. Crucially, the potential of high dimensional feature space in the channel dimension and the exploration of network width/resolution remain largely untapped. In this paper, we consider nonlinear transforms from the perspective of feature space, defining high-dimensional feature spaces in different dimensions and investigating the specific effects. Firstly, we introduce the dimension increasing and decreasing transforms in both channel and spatial dimensions to obtain high dimensional feature space and achieve better feature extraction. Secondly, we design a channel-spatial fusion residual transform (CSR), which incorporates multi-dimensional transforms for a more effective representation. Furthermore, we simplify the proposed fusion transform to obtain a slim architecture (CSR-sm), balancing network complexity and compression performance. Finally, we build the overall network with stacked CSR transforms to achieve better compression and reconstruction. Experimental results demonstrate that the proposed method can achieve superior rate-distortion performance compared to the existing LIC methods and traditional codecs. Specifically, our proposed method achieves 9.38% BD-rate reduction over VVC on Kodak dataset.},
  archive      = {J_CAAITIT},
  author       = {Wen Tan and Fanyang Meng and Chao Li and Youneng Bao and Yongsheng Liang},
  doi          = {10.1049/cit2.70025},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1235-1253},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Exploring high dimensional feature space with channel-spatial nonlinear transforms for learned image compression},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy efficient VM selection using CSOA-VM model in cloud data centers. <em>CAAITIT</em>, <em>10</em>(4), 1217-1234. (<a href='https://doi.org/10.1049/cit2.70018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cloud data centres evolved with an issue of energy management due to the constant increase in size, complexity and enormous consumption of energy. Energy management is a challenging issue that is critical in cloud data centres and an important concern of research for many researchers. In this paper, we proposed a cuckoo search (CS)-based optimisation technique for the virtual machine (VM) selection and a novel placement algorithm considering the different constraints. The energy consumption model and the simulation model have been implemented for the efficient selection of VM. The proposed model CSOA-VM not only lessens the violations at the service level agreement (SLA) level but also minimises the VM migrations. The proposed model also saves energy and the performance analysis shows that energy consumption obtained is 1.35 kWh, SLA violation is 9.2 and VM migration is about 268. Thus, there is an improvement in energy consumption of about 1.8% and a 2.1% improvement (reduction) in violations of SLA in comparison to existing techniques.},
  archive      = {J_CAAITIT},
  author       = {Mandeep Singh Devgan and Tajinder Kumar and Purushottam Sharma and Xiaochun Cheng and Shashi Bhushan and Vishal Garg},
  doi          = {10.1049/cit2.70018},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1217-1234},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Energy efficient VM selection using CSOA-VM model in cloud data centers},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent medical diagnosis model based on graph neural networks for medical images. <em>CAAITIT</em>, <em>10</em>(4), 1201-1216. (<a href='https://doi.org/10.1049/cit2.70020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, numerous estimation issues have been solved due to the developments in data-driven artificial neural networks (ANN) and graph neural networks (GNN). The primary limitation of previous methodologies has been the dependence on data that can be structured in a grid format. However, physiological recordings often exhibit irregular and unordered patterns, posing a significant challenge in conceptualising them as matrices. As a result, GNNs which comprise interactive nodes connected by edges whose weights are defined by anatomical junctions or temporal relationships have received a lot of consideration by leveraging implicit data that exists in a biological system. Additionally, our study incorporates a structural GNN to effectively differentiate between different degrees of infection in both the left and right hemispheres of the brain. Subsequently, demographic data are included, and a multi-task learning architecture is devised, integrating classification and regression tasks. The trials used an authentic dataset, including 800 brain x-ray pictures, consisting of 560 instances classified as moderate cases and 240 instances classified as severe cases. Based on empirical evidence, our methodology demonstrates superior performance in classification, surpassing other comparison methods with a notable achievement of 92.27% in terms of area under the curve as well as a correlation coefficient of 0.62.},
  archive      = {J_CAAITIT},
  author       = {Ashutosh Sharma and Amit Sharma and Kai Guo},
  doi          = {10.1049/cit2.70020},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1201-1216},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Intelligent medical diagnosis model based on graph neural networks for medical images},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bat algorithm based on kinetic adaptation and elite communication for engineering problems. <em>CAAITIT</em>, <em>10</em>(4), 1174-1200. (<a href='https://doi.org/10.1049/cit2.12345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Bat algorithm, a metaheuristic optimization technique inspired by the foraging behaviour of bats, has been employed to tackle optimization problems. Known for its ease of implementation, parameter tunability, and strong global search capabilities, this algorithm finds application across diverse optimization problem domains. However, in the face of increasingly complex optimization challenges, the Bat algorithm encounters certain limitations, such as slow convergence and sensitivity to initial solutions. In order to tackle these challenges, the present study incorporates a range of optimization components into the Bat algorithm, thereby proposing a variant called PKEBA. A projection screening strategy is implemented to mitigate its sensitivity to initial solutions, thereby enhancing the quality of the initial solution set. A kinetic adaptation strategy reforms exploration patterns, while an elite communication strategy enhances group interaction, to avoid algorithm from local optima. Subsequently, the effectiveness of the proposed PKEBA is rigorously evaluated. Testing encompasses 30 benchmark functions from IEEE CEC2014, featuring ablation experiments and comparative assessments against classical algorithms and their variants. Moreover, real-world engineering problems are employed as further validation. The results conclusively demonstrate that PKEBA exhibits superior convergence and precision compared to existing algorithms.},
  archive      = {J_CAAITIT},
  author       = {Chong Yuan and Dong Zhao and Ali Asghar Heidari and Lei Liu and Shuihua Wang and Huiling Chen and Yudong Zhang},
  doi          = {10.1049/cit2.12345},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1174-1200},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Bat algorithm based on kinetic adaptation and elite communication for engineering problems},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sophisticated ensemble deep learning approaches for multilabel retinal disease classification in medical imaging. <em>CAAITIT</em>, <em>10</em>(4), 1159-1173. (<a href='https://doi.org/10.1049/cit2.70012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel ensemble Deep learning (DL)-based Multi-Label Retinal Disease Classification (MLRDC) system, known for its high accuracy and efficiency. Utilising a stacking ensemble approach, and integrating DenseNet201, EfficientNetB4, EfficientNetB3 and EfficientNetV2S models, exceptional performance in retinal disease classification is achieved. The proposed MLRDC model, leveraging DL as the meta-model, outperforms individual base detectors, with DenseNet201 and EfficientNetV2S achieving an accuracy of 96.5%, precision of 98.6%, recall of 97.1%, and F1 score of 97.8%. Weighted multilabel classifiers in the ensemble exhibit an average accuracy of 90.6%, precision of 98.3%, recall of 91.2%, and F1 score of 94.6%, whereas unweighted models achieve an average accuracy of 90%, precision of 98.6%, recall of 93.1%, and F1 score of 95.7%. Employing Logistic Regression (LR) as the meta-model, the proposed MLRDC system achieves an accuracy of 93.5%, precision of 98.2%, recall of 93.9%, and F1 score of 96%, with a minimal loss of 0.029. These results highlight the superiority of the proposed model over benchmark state-of-the-art ensembles, emphasising its practical applicability in medical image classification.},
  archive      = {J_CAAITIT},
  author       = {Asghar Amir and Tariqullah Jan and Mohammad Haseeb Zafar and Shadan Khan Khattak},
  doi          = {10.1049/cit2.70012},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1159-1173},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Sophisticated ensemble deep learning approaches for multilabel retinal disease classification in medical imaging},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tibetan medical named entity recognition based on syllable-word-sentence embedding transformer. <em>CAAITIT</em>, <em>10</em>(4), 1148-1158. (<a href='https://doi.org/10.1049/cit2.70029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tibetan medical named entity recognition (Tibetan MNER) involves extracting specific types of medical entities from unstructured Tibetan medical texts. Tibetan MNER provide important data support for the work related to Tibetan medicine. However, existing Tibetan MNER methods often struggle to comprehensively capture multi-level semantic information, failing to sufficiently extract multi-granularity features and effectively filter out irrelevant information, which ultimately impacts the accuracy of entity recognition. This paper proposes an improved embedding representation method called syllable–word–sentence embedding. By leveraging features at different granularities and using un-scaled dot-product attention to focus on key features for feature fusion, the syllable–word–sentence embedding is integrated into the transformer, enhancing the specificity and diversity of feature representations. The model leverages multi-level and multi-granularity semantic information, thereby improving the performance of Tibetan MNER. We evaluate our proposed model on datasets from various domains. The results indicate that the model effectively identified three types of entities in the Tibetan news dataset we constructed, achieving an F1 score of 93.59%, which represents an improvement of 1.24% compared to the vanilla FLAT. Additionally, results from the Tibetan medical dataset we developed show that it is effective in identifying five kinds of medical entities, with an F1 score of 71.39%, which is a 1.34% improvement over the vanilla FLAT.},
  archive      = {J_CAAITIT},
  author       = {Jin Zhang and Ziyue Zhang and Lobsang Yeshi and Dorje Tashi and Xiangshi Wang and Yuqing Cai and Yongbin Yu and Xiangxiang Wang and Nyima Tashi and Gadeng Luosang},
  doi          = {10.1049/cit2.70029},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1148-1158},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Tibetan medical named entity recognition based on syllable-word-sentence embedding transformer},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimising PID controllers for multi-area automatic generation control with improved NSGA-II. <em>CAAITIT</em>, <em>10</em>(4), 1135-1147. (<a href='https://doi.org/10.1049/cit2.70024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern automated generation control (AGC) is increasingly complex, requiring precise frequency control for stability and operational accuracy. Traditional PID controller optimisation methods often struggle to handle nonlinearities and meet robustness requirements across diverse operational scenarios. This paper introduces an enhanced strategy using a multi-objective optimisation framework and a modified non-dominated sorting genetic algorithm II (SNSGA). The proposed model optimises the PID controller by minimising key performance metrics: integration time squared error (ITSE), integration time absolute error (ITAE), and rate of change of deviation (J). This approach balances convergence rate, overshoot, and oscillation dynamics effectively. A fuzzy-based method is employed to select the most suitable solution from the Pareto set. The comparative analysis demonstrates that the SNSGA-based approach offers superior tuning capabilities over traditional NSGA-II and other advanced control methods. In a two-area thermal power system without reheat, the SNSGA significantly reduces settling times for frequency deviations: 2.94s for and 4.98s for , marking improvements of 31.6% and 13.4% over NSGA-II, respectively.},
  archive      = {J_CAAITIT},
  author       = {Yang Yang and Yuchao Gao and Shangce Gao and Jinran Wu},
  doi          = {10.1049/cit2.70024},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1135-1147},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Optimising PID controllers for multi-area automatic generation control with improved NSGA-II},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Co-DeepNet: A cooperative convolutional neural network for DNA methylation-based age prediction. <em>CAAITIT</em>, <em>10</em>(4), 1118-1134. (<a href='https://doi.org/10.1049/cit2.70026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction of the age of each individual is possible using the changing pattern of DNA methylation with age. In this paper an age prediction approach to work out multivariate regression problems using DNA methylation data is developed. In this research study a convolutional neural network (CNN)-based model optimised by the genetic algorithm (GA) is addressed. This paper contributes to enhancing age prediction as a regression problem using a union of two CNNs and exchanging knowledge between them. This specifically re-starts the training process from a possibly higher-quality point in different iterations and, consequently, causes potentially yeilds better results at each iteration. The method proposed, which is called cooperative deep neural network (Co-DeepNet), is tested on two types of age prediction problems. Sixteen datasets containing 1899 healthy blood samples and nine datasets containing 2395 diseased blood samples are employed to examine the method's efficiency. As a result, the mean absolute deviation (MAD) is 1.49 and 3.61 years for training and testing data, respectively, when the healthy data is tested. The diseased blood data show MAD results of 3.81 and 5.43 years for training and testing data, respectively. The results of the Co-DeepNet are compared with six other methods proposed in previous studies and a single CNN using four prediction accuracy measurements ( R 2 , MAD, MSE and RMSE). The effectiveness of the Co-DeepNet and superiority of its results is proved through the statistical analysis.},
  archive      = {J_CAAITIT},
  author       = {Najmeh Sadat Jaddi and Mohammad Saniee Abadeh and Niousha Bagheri Khoulenjani and Salwani Abdullah and MohammadMahdi Ariannejad and Mohd Zakree Ahmad Nazri and Fatemeh Alvankarian},
  doi          = {10.1049/cit2.70026},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1118-1134},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Co-DeepNet: A cooperative convolutional neural network for DNA methylation-based age prediction},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models with contrastive decoding algorithm for hallucination mitigation in low-resource languages. <em>CAAITIT</em>, <em>10</em>(4), 1104-1117. (<a href='https://doi.org/10.1049/cit2.70004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural machine translation (NMT) has advanced with deep learning and large-scale multilingual models, yet translating low-resource languages often lacks sufficient training data and leads to hallucinations. This often results in translated content that diverges significantly from the source text. This research proposes a refined Contrastive Decoding (CD) algorithm that dynamically adjusts weights of log probabilities from strong expert and weak amateur models to mitigate hallucinations in low-resource NMT and improve translation quality. Advanced large language NMT models, including ChatGLM and LLaMA, are fine-tuned and implemented for their superior contextual understanding and cross-lingual capabilities. The refined CD algorithm evaluates multiple candidate translations using BLEU score, semantic similarity, and Named Entity Recognition accuracy. Extensive experimental results show substantial improvements in translation quality and a significant reduction in hallucination rates. Fine-tuned models achieve higher evaluation metrics compared to baseline models and state-of-the-art models. An ablation study confirms the contributions of each methodological component and highlights the effectiveness of the refined CD algorithm and advanced models in mitigating hallucinations. Notably, the refined methodology increased the BLEU score by approximately 30% compared to baseline models.},
  archive      = {J_CAAITIT},
  author       = {Zan Hongying and Arifa Javed and Muhammad Abdullah and Javed Rashid and Muhammad Faheem},
  doi          = {10.1049/cit2.70004},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1104-1117},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Large language models with contrastive decoding algorithm for hallucination mitigation in low-resource languages},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-domain graph anomaly detection via graph transfer and graph decouple. <em>CAAITIT</em>, <em>10</em>(4), 1089-1103. (<a href='https://doi.org/10.1049/cit2.70014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain graph anomaly detection (CD-GAD) is a promising task that leverages knowledge from a labelled source graph to guide anomaly detection on an unlabelled target graph. CD-GAD classifies anomalies as unique or common based on their presence in both the source and target graphs. However, existing models often fail to fully explore domain-unique knowledge of the target graph for detecting unique anomalies. Additionally, they tend to focus solely on node-level differences, overlooking structural-level differences that provide complementary information for common anomaly detection. To address these issues, we propose a novel method, Synthetic Graph Anomaly Detection via Graph Transfer and Graph Decouple (GTGD), which effectively detects common and unique anomalies in the target graph. Specifically, our approach ensures deeper learning of domain-unique knowledge by decoupling the reconstruction graphs of common and unique features. Moreover, we simultaneously consider node-level and structural-level differences by transferring node and edge information from the source graph to the target graph, enabling comprehensive domain-common knowledge representation. Anomalies are detected using both common and unique features, with their synthetic score serving as the final result. Extensive experiments demonstrate the effectiveness of our approach, improving an average performance by 12.6 on the AUC-PR compared to state-of-the-art methods.},
  archive      = {J_CAAITIT},
  author       = {Changqin Huang and Xinxing Shi and Chengling Gao and Qintai Hu and Xiaodi Huang and Qionghao Huang and Ali Anaissi},
  doi          = {10.1049/cit2.70014},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1089-1103},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Cross-domain graph anomaly detection via graph transfer and graph decouple},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RNN-based sequence-aware recommenders for tourist attractions. <em>CAAITIT</em>, <em>10</em>(4), 1077-1088. (<a href='https://doi.org/10.1049/cit2.70027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selecting appropriate tourist attractions to visit in real time is an important problem for travellers. Since recommenders proactively suggest items based on user preference, they are a promising solution for this problem. Travellers visit tourist attractions sequentially by considering multiple attributes at the same time. Therefore, it is desirable to consider this when developing recommenders for tourist attractions. Using GRU4REC, we proposed RNN-based sequence-aware recommenders (RNN-SARs) that use multiple sequence datasets for training the recommended model, named multi-RNN-SARs. We proposed two types of multi-RNN-SARs—concatenate-RNN-SARs and parallel-RNN-SARs. In order to evaluate multi-RNN-SARs, we compared hit rate (HR) and mean reciprocal rank (MRR) of the item-based collaborative filtering recommender (item-CFR), RNN-SAR with the single-sequence dataset (basic-RNN-SAR), multi-RNN-SARs and the state-of-the-art SARs using a real-world travel dataset. Our research shows that multi-RNN-SARs have significantly higher performances compared to item-CFR. Not all multi-RNN-SARs outperform basic-RNN-SAR but the best multi-RNN-SAR achieves comparable performance to that of the state-of-the-art algorithms. These results highlight the importance of using multiple sequence datasets in RNN-SARs and the importance of choosing appropriate sequence datasets and learning methods for implementing multi-RNN-SARs in practice.},
  archive      = {J_CAAITIT},
  author       = {Hee Jun Lee and Yang Sok Kim and Won Seok Lee and In Hyeok Choi and Choong Kwon Lee},
  doi          = {10.1049/cit2.70027},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1077-1088},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {RNN-based sequence-aware recommenders for tourist attractions},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph neural networks empowered origin-destination learning for urban traffic prediction. <em>CAAITIT</em>, <em>10</em>(4), 1062-1076. (<a href='https://doi.org/10.1049/cit2.70021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban traffic prediction with high precision is always the unremitting pursuit of intelligent transportation systems and is instrumental in bringing smart cities into reality. The fundamental challenges for traffic prediction lie in the accurate modelling of spatial and temporal traffic dynamics. Existing approaches mainly focus on modelling the traffic data itself, but do not explore the traffic correlations implicit in origin-destination (OD) data. In this paper, we propose STOD-Net, a dynamic spatial-temporal OD feature-enhanced deep network, to simultaneously predict the in-traffic and out-traffic for each and every region of a city. We model the OD data as dynamic graphs and adopt graph neural networks in STOD-Net to learn a low-dimensional representation for each region. As per the region feature, we design a gating mechanism and operate it on the traffic feature learning to explicitly capture spatial correlations. To further capture the complicated spatial and temporal dependencies among different regions, we propose a novel joint feature, learning block in STOD-Net and transfer the hybrid OD features to each block to make the learning process spatiotemporal-aware. We evaluate the effectiveness of STOD-Net on two benchmark datasets, and experimental results demonstrate that it outperforms the state-of-the-art by approximately 5% in terms of prediction accuracy and considerably improves prediction stability up to 80% in terms of standard deviation.},
  archive      = {J_CAAITIT},
  author       = {Chuanting Zhang and Guoqing Ma and Liang Zhang and Basem Shihada},
  doi          = {10.1049/cit2.70021},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1062-1076},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Graph neural networks empowered origin-destination learning for urban traffic prediction},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sep-NMS: Unlocking the aptitude of two-stage referring expression comprehension. <em>CAAITIT</em>, <em>10</em>(4), 1049-1061. (<a href='https://doi.org/10.1049/cit2.70007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Referring expression comprehension (REC) aims to locate a specific region in an image described by a natural language. Existing two-stage methods generate multiple candidate proposals in the first stage, followed by selecting one of these proposals as the grounding result in the second stage. Nevertheless, the number of candidate proposals generated in the first stage significantly exceeds ground truth and the recall of critical objects is inadequate, thereby enormously limiting the overall network performance. To address the above issues, the authors propose an innovative method termed Separate Non-Maximum Suppression (Sep-NMS) for two-stage REC. Particularly, Sep-NMS models information from the two stages independently and collaboratively, ultimately achieving an overall improvement in comprehension and identification of the target objects. Specifically, the authors propose a Ref-Relatedness module for filtering referent proposals rigorously, decreasing the redundancy of referent proposals. A Relatedness module based on robust multimodal pre-trained encoders is built to precisely assess the relevance between language and proposals to improve the recall of critical objects. It is worth mentioning that the authors are the pioneers in utilising a multimodal pre-training model for proposal filtering in the first stage. Moreover, an Information Fusion module is designed to effectively amalgamate the multimodal information across two stages, ensuring maximum utilisation of the available information. Extensive experiments demonstrate that the approach achieves competitive performance with previous state-of-the-art methods. The datasets used are publicly available: RefCOCO, RefCOCO+: https://doi.org/10.1007/978-3-319-46475-6_5 and RefCOCOg: https://doi.org/10.1109/CVPR.2016.9 .},
  archive      = {J_CAAITIT},
  author       = {Jing Wang and Zhikang Wang and Xiaojie Wang and Fangxiang Feng and Bo Yang},
  doi          = {10.1049/cit2.70007},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1049-1061},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Sep-NMS: Unlocking the aptitude of two-stage referring expression comprehension},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WaveLiteDehaze-network: A low-parameter wavelet-based method for real-time dehazing. <em>CAAITIT</em>, <em>10</em>(4), 1033-1048. (<a href='https://doi.org/10.1049/cit2.70011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the image dehazing problem has received considerable attention over recent years, the existing models often prioritise performance at the expense of complexity, making them unsuitable for real-world applications, which require algorithms to be deployed on resource constrained-devices. To address this challenge, we propose WaveLiteDehaze-Network (WLD-Net), an end-to-end dehazing model that delivers performance comparable to complex models while operating in real time and using significantly fewer parameters. This approach capitalises on the insight that haze predominantly affects low-frequency information. By exclusively processing the image in the frequency domain using discrete wavelet transform (DWT), we segregate the image into high and low frequencies and process them separately. This allows us to preserve high-frequency details and recover low-frequency components affected by haze, distinguishing our method from existing approaches that use spatial domain processing as the backbone, with DWT serving as an auxiliary component. DWT is applied at multiple levels for better information retention while also accelerating computation by downsampling feature maps. Subsequently, a learning-based fusion mechanism reintegrates the processed frequencies to reconstruct the dehazed image. Experiments show that WLD-Net outperforms other low-parameter models on real-world hazy images and rivals much larger models, achieving the highest PSNR and SSIM scores on the O-Haze dataset. Qualitatively, the proposed method demonstrates its effectiveness in handling a diverse range of haze types, delivering visually pleasing results and robust performance, while also generalising well across different scenarios. With only 0.385 million parameters (more than 100 times smaller than comparable dehazing methods), WLD-Net processes 1024 × 1024 images in just 0.045 s, highlighting its applicability across various real-world scenarios. The code is available at https://github.com/AliMurtaza29/WLD-Net .},
  archive      = {J_CAAITIT},
  author       = {Ali Murtaza and Uswah Khairuddin and Ahmad ’Athif Mohd Faudzi and Kazuhiko Hamamoto and Yang Fang and Zaid Omar},
  doi          = {10.1049/cit2.70011},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1033-1048},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {WaveLiteDehaze-network: A low-parameter wavelet-based method for real-time dehazing},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stage early exiting from globality towards reliability. <em>CAAITIT</em>, <em>10</em>(4), 1019-1032. (<a href='https://doi.org/10.1049/cit2.70010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early exiting has shown significant potential in accelerating the inference of pre-trained language models (PLMs) by allowing easy samples to exit from shallow layers. However, existing early exiting methods primarily rely on local information from individual samples to estimate prediction uncertainty for making exiting decisions, overlooking the global information provided by the sample population. This impacts the estimation of prediction uncertainty, compromising the reliability of exiting decisions. To remedy this, inspired by principal component analysis (PCA), the authors define a residual score to capture the deviation of features from the principal space of the sample population, providing a global perspective for estimating prediction uncertainty. Building on this, a two-stage exiting strategy is proposed that integrates global information from residual scores with local information from energy scores at both the decision and feature levels. This strategy incorporates three-way decisions to enable more reliable exiting decisions for boundary region samples by delaying judgement. Extensive experiments on the GLUE benchmark validate that the method achieves an average speed-up ratio of 2.17× across all tasks with minimal performance degradation. Additionally, it surpasses the state-of-the-art E-LANG by in model acceleration, along with a performance improvement of 0.6 points, demonstrating a better performance-efficiency trade-off.},
  archive      = {J_CAAITIT},
  author       = {Jianing He and Qi Zhang and Hongyun Zhang and Duoqian Miao},
  doi          = {10.1049/cit2.70010},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1019-1032},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Two-stage early exiting from globality towards reliability},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Point-PC: Point cloud completion guided by prior knowledge via causal inference. <em>CAAITIT</em>, <em>10</em>(4), 1007-1018. (<a href='https://doi.org/10.1049/cit2.12379'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of point cloud completion is to reconstruct raw scanned point clouds acquired from incomplete observations due to occlusion and restricted viewpoints. Numerous methods use a partial-to-complete framework, directly predicting missing components via global characteristics extracted from incomplete inputs. However, this makes detail recovery challenging, as global characteristics fail to provide complete missing component specifics. A new point cloud completion method named Point-PC is proposed. A memory network and a causal inference model are separately designed to introduce shape priors and select absent shape information as supplementary geometric factors for aiding completion. Concretely, a memory mechanism is proposed to store complete shape features and their associated shapes in a key-value format. The authors design a pre-training strategy that uses contrastive learning to map incomplete shape features into the complete shape feature domain, enabling retrieval of analogous shapes from incomplete inputs. In addition, the authors employ backdoor adjustment to eliminate confounders, which are shape prior components sharing identical semantic structures with incomplete inputs. Experiments conducted on three datasets show that our method achieves superior performance compared to state-of-the-art approaches. The code for Point-PC can be accessed by https://github.com/bizbard/Point-PC.git .},
  archive      = {J_CAAITIT},
  author       = {Xuesong Gao and Chuanqi Jiao and Ruidong Chen and Weijie Wang and Weizhi Nie},
  doi          = {10.1049/cit2.12379},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1007-1018},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Point-PC: Point cloud completion guided by prior knowledge via causal inference},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing patient rehabilitation predictions with a hybrid anomaly detection model: Density-based clustering and interquartile range methods. <em>CAAITIT</em>, <em>10</em>(4), 983-1006. (<a href='https://doi.org/10.1049/cit2.70000'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been a concerted effort to improve anomaly detection techniques, particularly in the context of high-dimensional, distributed clinical data. Analysing patient data within clinical settings reveals a pronounced focus on refining diagnostic accuracy, personalising treatment plans, and optimising resource allocation to enhance clinical outcomes. Nonetheless, this domain faces unique challenges, such as irregular data collection, inconsistent data quality, and patient-specific structural variations. This paper proposed a novel hybrid approach that integrates heuristic and stochastic methods for anomaly detection in patient clinical data to address these challenges. The strategy combines HPO-based optimal Density-Based Spatial Clustering of Applications with Noise for clustering patient exercise data, facilitating efficient anomaly identification. Subsequently, a stochastic method based on the Interquartile Range filters unreliable data points, ensuring that medical tools and professionals receive only the most pertinent and accurate information. The primary objective of this study is to equip healthcare professionals and researchers with a robust tool for managing extensive, high-dimensional clinical datasets, enabling effective isolation and removal of aberrant data points. Furthermore, a sophisticated regression model has been developed using Automated Machine Learning (AutoML) to assess the impact of the ensemble abnormal pattern detection approach. Various statistical error estimation techniques validate the efficacy of the hybrid approach alongside AutoML. Experimental results show that implementing this innovative hybrid model on patient rehabilitation data leads to a notable enhancement in AutoML performance, with an average improvement of 0.041 in the score, surpassing the effectiveness of traditional regression models.},
  archive      = {J_CAAITIT},
  author       = {Murad Ali Khan and Jong-Hyun Jang and Naeem Iqbal and Harun Jamil and Syed Shehryar Ali Naqvi and Salabat Khan and Jae-Chul Kim and Do-Hyeun Kim},
  doi          = {10.1049/cit2.70000},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {983-1006},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Enhancing patient rehabilitation predictions with a hybrid anomaly detection model: Density-based clustering and interquartile range methods},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diverse models, united goal: A comprehensive survey of ensemble learning. <em>CAAITIT</em>, <em>10</em>(4), 959-982. (<a href='https://doi.org/10.1049/cit2.70030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble learning, a pivotal branch of machine learning, amalgamates multiple base models to enhance the overarching performance of predictive models, capitalising on the diversity and collective wisdom of the ensemble to surpass individual models and mitigate overfitting. In this review, a four-layer research framework is established for the research of ensemble learning, which can offer a comprehensive and structured review of ensemble learning from bottom to top. Firstly, this survey commences by introducing fundamental ensemble learning techniques, including bagging, boosting, and stacking, while also exploring the ensemble's diversity. Then, deep ensemble learning and semi-supervised ensemble learning are studied in detail. Furthermore, the utilisation of ensemble learning techniques to navigate challenging datasets, such as imbalanced and high-dimensional data, is discussed. The application of ensemble learning techniques across various research domains, including healthcare, transportation, finance, manufacturing, and the Internet, is also examined. The survey concludes by discussing challenges intrinsic to ensemble learning.},
  archive      = {J_CAAITIT},
  author       = {Ziwei Fan and Zhiwen Yu and Kaixiang Yang and Wuxing Chen and Xiaoqing Liu and Guojie Li and Xianling Yang and C. L. Philip Chen},
  doi          = {10.1049/cit2.70030},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {959-982},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Diverse models, united goal: A comprehensive survey of ensemble learning},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robot manipulation based on embodied visual perception: A survey. <em>CAAITIT</em>, <em>10</em>(4), 945-958. (<a href='https://doi.org/10.1049/cit2.70022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual perception is critical in robotic operations, particularly in collaborative and autonomous robot systems. Through efficient visual systems, robots can acquire and process environmental information in real-time, recognise objects, assess spatial relationships, and make adaptive decisions. This review aims to provide a comprehensive overview of the latest advancements in the field of vision as applied to robotic perception, focusing primarily on visual applications in the areas of object perception, self-perception, human–robot collaboration, and multi-robot collaboration. By summarising the current state of development and analysing the challenges and opportunities that remain in these areas, this paper offers a thorough examination of the integration of visual perception with operational robotics. It further inspires future research and drives the application and development of visual perception across various robotic domains, enabling operational robots to better adapt to complex environments and reliably accomplish tasks.},
  archive      = {J_CAAITIT},
  author       = {Sicheng Wang and Milutin N. Nikolić and Tin Lun Lam and Qing Gao and Runwei Ding and Tianwei Zhang},
  doi          = {10.1049/cit2.70022},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {945-958},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Robot manipulation based on embodied visual perception: A survey},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
