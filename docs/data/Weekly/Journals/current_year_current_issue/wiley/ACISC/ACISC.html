<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ACISC</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="acisc">ACISC - 52</h2>
<ul>
<li><details>
<summary>
(2025). Improved deviation sparse fuzzy C-means-2D cumulative sum average filter and modified sine cosine crow search algorithm-wavelet extreme learning machine for brain tumor detection and classification. <em>ACISC</em>, <em>2025</em>(1), 9991264. (<a href='https://doi.org/10.1155/acis/9991264'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The brain tumor grows abnormally in the human brain, which causes brain cancer. Death rates have been rising annually for the past few decades due to negligence of early treatment of brain tumors. To reduce the death rate, early identification of tumors is crucial. Early brain tumor detection may potentially lower the risk of life. Manual tumor diagnosis is complex, challenging, and time-consuming for medical professionals. Therefore, automatic detection and segmentation methods simplify the diagnosing procedure. Thus, automatic segmentation and classification methods are taken up to make the diagnosis process easy. This research proposes a two-dimensional cumulative sum average filter (2D-CSAF) for preprocessing images and an improved deviation sparse fuzzy C-means (IDSFCM) with neighbor information for segmenting brain tumors from magnetic resonance images. The novel IDSFCM segmentation increases the noise reduction capability and enhances segmentation accuracies. The hybrid modified sine cosine algorithm-crow search algorithm (MSCA-CSA)–based WELM model is proposed to classify the brain tumor. The MSCA-CSA algorithm optimizes the weights of the WELM model to increase the classification capability. The gray level co-occurrence matrix (GLCM) feature extraction technique is employed to extract the features from the segmented images, and extracted features are given as input to the MSCA-CSA-WELM model for classification. The brain tumor dataset from Harvard Medical School is considered for this research. The proposed IDSFCM segmentation achieved 99.53% segmentation accuracy. The accuracy, specificity, and sensitivity performance measures are considered for the classification. The classification performance was evaluated using accuracy, sensitivity, and specificity metrics. The proposed MSCA-CSA–based WELM model outperformed feature extraction–based classifiers, achieving 99.37% accuracy, 99.87% sensitivity, and 99.44% specificity during training.},
  archive      = {J_ACISC},
  author       = {Suvashisa Dash and Satyasis Mishra and Mohammed Siddique and Demissie J. Gelmecha and Ram Sewak Singh},
  doi          = {10.1155/acis/9991264},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {9991264},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Improved deviation sparse fuzzy C-means-2D cumulative sum average filter and modified sine cosine crow search algorithm-wavelet extreme learning machine for brain tumor detection and classification},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine Learning–Based approach for early screening of autism spectrum disorders. <em>ACISC</em>, <em>2025</em>(1), 9975499. (<a href='https://doi.org/10.1155/acis/9975499'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A neurodevelopmental illness called autism spectrum disorder (ASD) is frequently associated with sensory problems including an excessive or insufficient sensitivity to noises, scents, or touch. Children with autism typically do not talk much and keep to themselves, but they can imitate certain actions from cartoons and movies. They may exhibit unsafe or unexpected behavior as a result. Early detection and therapy can assist in improving the diseases. In this study, we suggested a data-driven machine learning (ML) model for examining the autism dataset of diverse age groups (toddlers, children, and adults) to classify autism in the initial stage. The proposed ML model can efficiently analyze autism patients’ datasets and correctly classify and detect ASD features. We utilized a data preprocessing technique followed by feature selection methods using information gain and Pearson correlation. Then, we employed five different ML classifiers (KNN, RF, SVM, NB, and MLP) together with a hyperparameter optimization strategy. We assess their work using performance metrics such as prediction accuracy and the F1-measure. After comparing the accuracy between different classifiers, SVM produced the highest accuracies of 98%, 99%, and 100% for the toddler, child, and adult datasets while MLP produced an accuracy of 0.94 for the Pakistani child dataset, respectively. These thorough experimental assessments suggest that correct fine-tuning of the ML techniques can be crucial in the classification of autism in individuals of various ages. We believe that the thorough feature significance analysis presented in this study can guide medical professionals’ judgment when screening ASD individuals. In comparison with other methods currently used for the timely identification of ASD, the suggested framework has shown encouraging results.},
  archive      = {J_ACISC},
  author       = {Usama Jabbar and Muhammad Waseem Iqbal and Abdullah Alourani and Khlood Shinan and Fatmah Alanazi and Nadeem Sarwar and M. Usman Ashraf},
  doi          = {10.1155/acis/9975499},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {9975499},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Machine Learning–Based approach for early screening of autism spectrum disorders},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel method of data protection through DNA chromosome databases. <em>ACISC</em>, <em>2025</em>(1), 9966476. (<a href='https://doi.org/10.1155/acis/9966476'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of the digital age, data have become insecure, which requires techniques to secure data. Deoxyribonucleic acid (DNA) has become an increasingly secure technology for storing next-generation digital data. DNA provides superior capabilities due to its high and efficient storage capacity and long lifespan. Protecting these data is of utmost importance, especially data with sensitive content. In this study, the proposed encryption algorithm is a new and novel contribution; a new cryptographic methodology is presented that leverages the National Center for Biotechnology Information (NCBI) GenBank to create cryptographic keys. This key dictionary is created by nucleotide sequences created from the GenBank database. The proposed methodology uses databases such as the National Center GenBank, which contains huge repositories of genetic information, to improve the effectiveness of data security. By converting traditional digital data into DNA sequences, this methodology provides new features of cryptographic protection. The security and reliability of the proposed methodology were thoroughly tested through simulation and data analysis. The results indicate that the proposed encryption methodology has a superior ability to withstand many types of cryptographic attacks, which confirms its effectiveness and strength in data protection. The paper also presented several findings, including a low encryption time of 250 ms and decryption time of 230 ms, as well as a memory usage of 50 MB for large datasets. Furthermore, the proposed method demonstrated exceptionally high stability. Across all these metrics, the proposed approach outperformed other existing methods. The proposed methodology is applicable to ensure the security and integrity of DNA-based digital storage systems. This methodology was developed independently and has not been previously studied. This modern methodology represents an advance in digital data security and protection, providing an advanced solution in the digital age of cybersecurity.},
  archive      = {J_ACISC},
  author       = {Sadoon Hussein and Ahmed Sami},
  doi          = {10.1155/acis/9966476},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {9966476},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {A novel method of data protection through DNA chromosome databases},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing concrete mix designs with synthetic data generation and machine learning prediction models. <em>ACISC</em>, <em>2025</em>(1), 9961816. (<a href='https://doi.org/10.1155/acis/9961816'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The focus of this paper is on the use of machine learning for the prediction of the strength outcomes of basalt fiber-reinforced concrete (BFRC), based on its mechanical properties. These target properties are compressive, flexural, and tensile strengths, estimated with knowledge of 10 variables, including cement and aggregate content, among other fiber characteristics. Models explored for regression in this paper include linear regression, K-nearest neighbors (KNN), random forest (RF), XGBoost (Extreme Gradient Boosting), support vector machine (SVM), and artificial neural networks (ANN). The highest performance among these was observed for the KNN at flexural strength with a R 2 score of 0.8737, XGBoost for compressive strength with a R 2 score of 0.8963, and RF for tensile strength with a R 2 score of 0.9420. Bayesian optimization was employed to tune hyperparameters to enhance the accuracy of the model. This study also applied Synthetic Minority Oversampling Technique (SMOTE) to generate 1000 synthetic concrete mix designs for the data to increase its diversity and allow the investigation on optimal performances regarding strength. The findings of this study contribute to advancing sustainable manufacturing practices by leveraging machine learning techniques to optimize material properties, thereby supporting the development of resilient infrastructure and enhancing industrial innovation.},
  archive      = {J_ACISC},
  author       = {Mohanad A. Deif and Hani Attar and Waleed Alomoush and Mohamed A. Hafez},
  doi          = {10.1155/acis/9961816},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {9961816},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Optimizing concrete mix designs with synthetic data generation and machine learning prediction models},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural network method for assessing the nutritional requirements of a patient with type 2 diabetes. <em>ACISC</em>, <em>2025</em>(1), 9955073. (<a href='https://doi.org/10.1155/acis/9955073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diet change is a crucial lifestyle management recommendation for diabetic patients as it affects plasma glucose concentrations. However, the optimal macronutrient composition for plasma glucose control in Type 2 diabetes remains unclear, with researchers still using generic diabetes guidelines. This study developed a neural network classifier to determine the nutritional requirements for four types of Type 2 diabetic patients: those with chronic hyperglycemia, hypertension, obesity, or all three conditions. The classifier was trained using Kenya Food Composition Tables data on food nutrients and processing techniques. The neural network had five layers, including three hidden layers with 10 neurons each, using tanh and sigmoid activation functions, gradient descent optimization, cross-entropy loss function, and 0.1 learning rate. Training used 40 hidden neurons per layer, 60,000 epochs and 0.2 learning rate. The neural network was evaluated against random forest, decision tree, and logistic regression models using accuracy, precision, recall, F1-score, and Matthews correlation coefficient (MCC). The neural network achieved high performance with 91.4% accuracy, 88% recall, 86.8% precision, and 87.3% F1-score. For the imbalanced dataset, the MCC score for the neural network was 0.808, indicating promising results for diabetes nutritional management.},
  archive      = {J_ACISC},
  author       = {Sidi M. Mwakalu and Vincent O. Omwenga and Patrick J. Ogao},
  doi          = {10.1155/acis/9955073},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {9955073},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {A neural network method for assessing the nutritional requirements of a patient with type 2 diabetes},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum to “Increment of academic performance prediction of at-risk student by dealing with data imbalance problem”. <em>ACISC</em>, <em>2025</em>(1), 9784853. (<a href='https://doi.org/10.1155/acis/9784853'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ACISC},
  doi          = {10.1155/acis/9784853},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {9784853},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Corrigendum to “Increment of academic performance prediction of at-risk student by dealing with data imbalance problem”},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated learning for grading oil palm fruit ripeness in the oil palm industry. <em>ACISC</em>, <em>2025</em>(1), 9241523. (<a href='https://doi.org/10.1155/acis/9241523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevailing method for grading oil palm fruit bunches in mills relies on human graders conducting visual inspections, resulting in frequent errors and inconsistent assessments. This is a significant open problem when developing a detector for oil palm fruit ripeness and oil content, which are related factors. Current trends focus on computer vision techniques based on image processing and machine learning to improve grading of oil palm fruit bunches at an individual factory, resulting in limited diversity of the data used for evaluation. Collecting data from all factories offers informational advantages but raises privacy concerns. Addressing these challenges, this study proposes federated learning (FL) to develop local and global prediction models for grading oil palm fruit ripeness while preserving data privacy. FL facilitates collaborative model training across factories, mitigating privacy risks and enhancing model development efficiency. The proposed model uses the color of palm husks to determine the ripeness stage, which is used as a factor in predicting the yield of oil from the crop. A predictive model was created using FL principles with a training dataset of 5209 images, which was divided into two subsets: single-palm (2571 images) and multipalm (2638 images). The classification accuracy of a global model was 90.0%, while the local models were expanded to include private data for each of 4 testing clients. The predictive global and local models from FL were used to implement the system in a web application form and to validate its performance in calling the oil palm ripeness stage.},
  archive      = {J_ACISC},
  author       = {Patchanee Laddawong and Yutthapong Pianroj and Piyanart Chotikawanid and Teerasak Punvichai and Saysunee Jumrat and Atitaya Kham-Ouam and Jirapond Muangprathub},
  doi          = {10.1155/acis/9241523},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {9241523},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Federated learning for grading oil palm fruit ripeness in the oil palm industry},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning enabled garbage classification and detection by visual context for aerial images. <em>ACISC</em>, <em>2025</em>(1), 9106130. (<a href='https://doi.org/10.1155/acis/9106130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Environmental pollution caused by garbage is a significant problem in most developing countries. Proper garbage waste processing, management, and recycling are crucial for both ecological and economic reasons. Computer vision techniques have shown advanced capabilities in various applications, including object detection and classification. In this study, we conducted an extensive review of the use of artificial intelligence for garbage processing and management. However, a major limitation in this field is the lack of datasets containing top-view images of garbage. We introduce a new dataset named “KACHARA,” containing 4727 images categorized into seven classes: clothes, decomposable (organic waste), glass, metal, paper, plastic, and wood. Importantly, the dataset exhibits a moderate imbalance, mirroring the distribution of real-world garbage, which is crucial for training accurate classification models. For classification, we utilize transfer learning with the well-known deep learning model MobileNetV3-Large, where the top layers are fine-tuned to enhance performance. We achieved a classification accuracy of 94.37% and also evaluated performance using precision, recall, F1-score, and confusion matrix. These results demonstrate the model’s strong generalization in aerial/top-view garbage classification.},
  archive      = {J_ACISC},
  author       = {Agnivesh Pandey and Rohit Raja and Manoj Gupta and Farhan A. Alenizi and Pannee Suanpang and Aziz Nanthaamornphong},
  doi          = {10.1155/acis/9106130},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {9106130},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Deep learning enabled garbage classification and detection by visual context for aerial images},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AutoGluon, SHAP, and GUI: A groundbreaking framework for concrete mechanical strength modeling, explainability, and accessibility. <em>ACISC</em>, <em>2025</em>(1), 9100809. (<a href='https://doi.org/10.1155/acis/9100809'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of concrete mechanical strength is crucial for ensuring safe and dependable infrastructure design and construction. However, traditional empirical models often face challenges in precisely predicting mechanical strength due to the complex nonlinear relationship between concrete properties and strength. This study proposes an AutoGluon–Shapley additive explanations (AutoGluon-SHAP) approach, which automatically predicts concrete mechanical strength while providing insightful interpretations of the results. Additionally, a graphical user interface (GUI) was developed to enhance global accessibility to the model. AutoGluon leverages powerful algorithms such as LightGBM, CatBoost, XGBoost, random forest, ensembles, and neural networks within its TabularPredictor to automate model selection. The models were trained and tested using a comprehensive dataset of 1760 concrete samples sourced from the published literature, encompassing diverse concrete types, cement brands, additives, target compressive strengths, and curing periods. Results show that the WeightedEnsemble_L2 predictive model demonstrated robust performance in estimating flexural, tensile, and compressive strengths. All the predictive models achieved high performance with R 2 of more than 0.98 for all the strengths’ properties. SHAP offered both global insights into the influence of the predictors on mechanical strength and local explanations for individual predictions, ensuring transparency and reliability. The developed GUI resulted in a globally accessible and reliable estimation of concrete mechanical strength.},
  archive      = {J_ACISC},
  author       = {Chukwuemeka Daniel and Edith K. Neufville},
  doi          = {10.1155/acis/9100809},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {9100809},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {AutoGluon, SHAP, and GUI: A groundbreaking framework for concrete mechanical strength modeling, explainability, and accessibility},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting oil price trends during conflict with hybrid machine learning techniques. <em>ACISC</em>, <em>2025</em>(1), 8867520. (<a href='https://doi.org/10.1155/acis/8867520'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ongoing conflict between Russia and Ukraine has introduced significant volatility into the global oil markets, highlighting the need for robust forecasting models to understand and anticipate price fluctuations during such geopolitical events. This study presents a comprehensive hybrid modeling approach to predict oil prices in the context of Russia and Ukraine across three distinct periods: before the war, during the war, and the immediate aftermath of the conflict. Using advanced machine learning techniques, we developed a hybrid system combining Random Forest, ElasticNet, K-Nearest Neighbors, Gradient Boosting, and Support Vector Regressor models. These models were integrated through a Voting Regressor to enhance prediction accuracy. Our analysis revealed varying levels of predictive performance across the different periods. Prior to the war, the models showed strong predictive capabilities, evidenced by low mean-squared error (MSE) values and high coefficients of determination ( R 2 ). However, during the war, the models struggled to capture extreme volatility, resulting in significantly increased MSE and negative R 2 values. Predictions for the immediate aftermath of the conflict demonstrated improvements, with a reduction in MSE and positive R 2 values, indicating a return to relatively more stable market conditions. Notably, combining data from both before the war and war periods could further improve predictive accuracy, as it would reduce the impact of the conflict’s volatility on model performance. These results emphasize the challenges of forecasting oil prices in periods of geopolitical instability and underscore the importance of hybrid modeling approaches to adapt to rapidly changing market dynamics.},
  archive      = {J_ACISC},
  author       = {Hicham Boussatta and Marouane Chihab and Mohamed Chiny and Younes Chihab},
  doi          = {10.1155/acis/8867520},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {8867520},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Predicting oil price trends during conflict with hybrid machine learning techniques},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced retinal vessel segmentation using dynamic contrast stretching and mathematical morphology on fundus images. <em>ACISC</em>, <em>2025</em>(1), 8831503. (<a href='https://doi.org/10.1155/acis/8831503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal vessel segmentation algorithms are crucial in automated retinal disease screening systems, as accurate determination of blood vessel structures is vital for ocular disease identification and diagnosis. In this study, we propose an efficient approach combining dynamic contrast stretching (DCS) method, advanced morphological operation–based segmentation, triangle thresholding, and a final postprocessing step. Our preprocessing step enhances the contrast of retinal images acquired under various lighting conditions, enabling reliable and accurate segmentation. This enhancement is achieved using the DCS method, which is compared to two widely used contrast enhancement techniques: adaptive histogram equalization (AHE) and contrast-limited adaptive histogram equalization (CLAHE). The second step combines morphological operations and triangle thresholding to enhance vessel structures, eliminate noise, and separate blood vessels effectively. Postprocessing addresses artifacts and ambiguous areas at image boundaries. Our approach is evaluated using widely recognized reference datasets, including Digital Retinal Images for Vessel Extraction (DRIVE), Structured Analysis of the Retina (STARE), and High-Resolution Fundus (HRF). The experimental results demonstrate that the proposed method achieves superior segmentation accuracy compared to the state-of-the-art techniques. Specifically, we achieve average accuracy rates of 98.08%, 97.14%, and 98.94% for the DRIVE, STARE, and HRF datasets, respectively. In addition, our method is distinguished by exceptionally fast execution times, reaching 0.013 s for the DRIVE and STARE datasets. These results underline the importance of our time-reduced approach to improving the accuracy and efficiency of fully automated retinal disease screening systems.},
  archive      = {J_ACISC},
  author       = {El-Mehdi Chakour and Yasmine Mrad and Anass Mansouri and Yaroub Elloumi and Idriss Benatiya Andaloussi and Mohamed Hedi Bedoui and Ali Ahaitouf},
  doi          = {10.1155/acis/8831503},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {8831503},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Enhanced retinal vessel segmentation using dynamic contrast stretching and mathematical morphology on fundus images},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel hybrid deep learning model based on simulated annealing and cuckoo search algorithms for automatic radiomics-based COVID-19 diagnosis. <em>ACISC</em>, <em>2025</em>(1), 8829294. (<a href='https://doi.org/10.1155/acis/8829294'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the outbreak of Coronavirus Disease 2019 (COVID-19), the virus has posed a grave threat to human health. Automated segmentation of COVID-19 lung computed tomography (CT) scans is a crucial diagnostic tool that aids physicians in providing accurate and timely diagnoses, as it contains significant radiomics information. Given that the specificity for discriminating between the causes of conventional pulmonary features is lower than its sensitivity, the primary goal of this study is to develop and evaluate a CT-based radiomics model capable of distinguishing between COVID-19 and other lung diseases. To address this, we propose an efficient, modified radiomics feature processing method that integrates an optimal aerial perspective (OAP) parameter-based intensity dark channel prior (IDCP) with a 50-layer residual deep neural network (ResNet50 DNN) for autolesion segmentation (ALS-IOAP-DNN). To further enhance COVID-19 lesion estimation, novel optimization strategies, including a hybrid simulated annealing-cuckoo search (SA-CS) algorithm, are introduced alongside the original SA method. The SA-CS algorithm extends SA by preventing entrapment in local minimum and enhancing global exploration. Five benchmark functions are used to accelerate convergence and address the issue of local optima. As a result, the hybrid approach outperforms 10 recent studies on two publicly available datasets (COVID-CT-Dataset and HUST-19), achieving an average accuracy score of 100% across different epochs, along with perfect accuracy, 100% sensitivity, and 100% specificity. The proposed models significantly outperform the baseline model, with accuracy improvements of 13.6% on Data1 and 2.5% on Data2. While the baseline model achieves 88% accuracy on Data1 and 97.6% on Data2, the proposed ALS-IOAP-DNN4 model attains perfect accuracy (100%) on both datasets, demonstrating the effectiveness of ALS and advanced optimization techniques. Furthermore, the use of OAP with IDCP enhances the precision of COVID-19 lesion estimation, underscoring its significance in COVID-19 diagnosis and medical imaging management.},
  archive      = {J_ACISC},
  author       = {Basma Jumaa Saleh and Zaid Omar and Muhammad Amir As’ari and Vikrant Bhateja and Lila Iznita Izhar},
  doi          = {10.1155/acis/8829294},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {8829294},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {A novel hybrid deep learning model based on simulated annealing and cuckoo search algorithms for automatic radiomics-based COVID-19 diagnosis},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predictive modeling of river water temperatures in catu river: A neural network-based approach. <em>ACISC</em>, <em>2025</em>(1), 8810911. (<a href='https://doi.org/10.1155/acis/8810911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting water temperature ( T w ) in tropical environments is crucial for ecosystem monitoring and the sustainable management of water resources. Highly accurate and reliable T w forecasts are essential for the ecological management of rivers. This study evaluates the performance of machine learning-based predictive models in forecasting T w in the Catu River. The models were trained using climatic and hydrological data collected from 2009 to 2016 and validated with real data from 2023. The evaluated models include backpropagation neural network (BPNN), Random Forest, Bidirectional LSTM (BiLSTM), Air2Stream, and NARX, employing nine input variables such as atmospheric pressure, air temperature, and water vapor concentration. The results show that the BiLSTM model achieved the best performance, with a root mean square error (RMSE) of 0.12°C and R 2 = 0.98, followed by BPNN with an RMSE of 0.18°C and R 2 = 0.91, and the Random Forest model, which obtained an NSE of 0.95. These models demonstrated a strong ability to predict T w under both normal and extreme conditions, capturing the thermal dynamics of the Catu River with high precision during events involving minor thermal variations. Conversely, the NARX and Air2Stream models exhibited lower performance, proving more prone to errors under conditions of extreme variability. The findings of this study provide valuable scientific insights for river T w prediction and the protection of aquatic ecosystems, with practical applications in water resource management in tropical regions.},
  archive      = {J_ACISC},
  author       = {Carmen Goncalves de Macedo e Silva and José Roberto de Araújo Fontoura and Alarcon Matos de Oliveira and Thais de Souza Neri and Roberto Luiz Souza Monteiro and Thiago Barros Murari and Alexandre do Nascimento Silva and Leandro Brito Santos and Marcos Batista Figueredo},
  doi          = {10.1155/acis/8810911},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {8810911},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Predictive modeling of river water temperatures in catu river: A neural network-based approach},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Navigating the moral maze: Ethical challenges and opportunities of generative chatbots in global higher education. <em>ACISC</em>, <em>2025</em>(1), 8584141. (<a href='https://doi.org/10.1155/acis/8584141'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of generative artificial intelligence (AI), such as ChatGPT, enhances higher education through personalized learning, administrative automation, and increased accessibility. However, it also raises ethical concerns about data security, academic integrity, algorithmic bias, and learner autonomy. This study employs a Hybrid Thematic SWOT (HT-SWOT) analysis to examine the strengths, weaknesses, opportunities, and threats of generative AI in global higher education. Through a systematic literature review of recent studies (2020–2024), this research highlights both the benefits, such as personalized learning, accessibility, and administrative efficiency, and the risks, including digital divides, misinformation, technosolotionism, and ethical concerns. The findings emphasize the need for responsible AI policies, faculty training, and equitable implementation strategies. This study provides actionable insights for policymakers, educators, and technologists to navigate AI’s ethical integration while promoting global equity and sustainable educational practices. Addressing these challenges requires a balanced approach that safeguards academic integrity while harnessing AI’s potential to enhance education worldwide.},
  archive      = {J_ACISC},
  author       = {Dwi Mariyono and Akmal Nur Alif Hidayatullah},
  doi          = {10.1155/acis/8584141},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {8584141},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Navigating the moral maze: Ethical challenges and opportunities of generative chatbots in global higher education},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fake fingerprint classification using hybrid features learning with gradient boosting. <em>ACISC</em>, <em>2025</em>(1), 8442143. (<a href='https://doi.org/10.1155/acis/8442143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometric security systems must be able to detect phony fingerprints to provide reliable authentication. The findings of this study suggest a hybrid approach to the detection of fake fingerprints that uses information on the texture and shape of the fingerprint. The novelty of this approach lies in integrating both traditional fingerprint information and geometric features obtained through wavelet transformation, which has not been extensively explored in previous studies. The proposed procedure uses the traditional fingerprint information and the geometric features that may be collected by wavelet modification. This allows it to take advantage of the complementary capabilities that these two types of capabilities offer. In addition, the hybrid feature set improves the system’s robustness and accuracy by leveraging each feature type’s unique strengths. To achieve this goal, the standard fingerprint information and the geometric aspects of the fingerprint are combined. It is possible to efficiently identify authentic and forged fingerprints by using these hybrid features and training a gradient boosting classifier. The findings of the studies demonstrate that the suggested technique achieves an accuracy of 96% on medium spoofing photos from the SOCOFing dataset, 97% on hard spoofing images, and 98% on mixed spoofing images. This high level of accuracy, especially on mixed spoofing images, showcases the effectiveness of the novel hybrid approach in diverse and challenging scenarios. This places it in the position of being the most accurate way currently accessible among the existing state-of-the-art methods. Furthermore, the proposed method’s scalability and adaptability make it suitable for real-world applications, potentially setting a new standard in biometric security. There is a great deal of optimism that the technique that has been described can increase the reliability and safety of biometric systems when used in situations representative of the actual world.},
  archive      = {J_ACISC},
  author       = {Muhammad Salman Ali and Arslan Akram and Javed Rashid and Muhammad Arfan Jaffar and Dilawar Shah and Shujaat Ali and Muhammad Tahir},
  doi          = {10.1155/acis/8442143},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {8442143},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Fake fingerprint classification using hybrid features learning with gradient boosting},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient spectrum sharing in cognitive radio networks with NOMA using computational intelligence. <em>ACISC</em>, <em>2025</em>(1), 8168986. (<a href='https://doi.org/10.1155/acis/8168986'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of cognitive radio networks (CRNs) with nonorthogonal multiple access (NOMA) offers great potential for improving spectral efficiency in 5G and Beyond-5G (B5G) networks. This study proposes an efficient spectrum-sharing technique for dual-hop CRNs using NOMA, optimized by an improved artificial bee colony (IABC) algorithm and guided by a single-input single-output fuzzy rule-based system (SISO-FRBS). In this setup, a distant primary transmitter communicates with the primary receiver via a secondary NOMA relay. The objective is to maximize the sum data rate of secondary users (SUs) while minimizing total transmission power. SISO-FRBS enhances the IABC search process by dynamically guiding the search agents, improving both optimization quality and convergence. Simulation results show that the proposed scheme achieves the primary data rate benchmark of 5 bit/s/Hz at a transmit power of 19 mW, compared with 23 mW with traditional ABC, achieving a 19.04% improvement in power efficiency.},
  archive      = {J_ACISC},
  author       = {Kiran Sultan},
  doi          = {10.1155/acis/8168986},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {8168986},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Efficient spectrum sharing in cognitive radio networks with NOMA using computational intelligence},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning approaches for software defect prediction. <em>ACISC</em>, <em>2025</em>(1), 7933078. (<a href='https://doi.org/10.1155/acis/7933078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyses existing research about machine learning approaches in software defect prediction as a key element for improving software reliability and quality. The paper reviews the use of machine learning algorithms in software defect prediction framework’s bug prediction while assessing their performance across multiple environments. A comprehensive review of scholarly literature enables researchers to specify both advantages and drawbacks that emerge when using machine learning for automated defect detection in software defect prediction applications. The review conducts assessments of typical metrics like accuracy and precision and recall and runtime performance yet extends its evaluation to analyze new trends combining deep learning with ensemble approaches to enhance software defect prediction functionality. The examined findings provide crucial guidelines which help developers select and improve machine learning models in software defect prediction processes that result in better software reliability and robustness.},
  archive      = {J_ACISC},
  author       = {Hijab Zehra Zaidi and Ubaid Ullah and Muddassira Arshad and Hanan Aljuaid and Muhammad Arslan Rauf and Nadeem Sarwar and Rimsha Sajid},
  doi          = {10.1155/acis/7933078},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {7933078},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Machine learning approaches for software defect prediction},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel approach for enhancing plant leaf classification with the binary cuckoo search algorithm. <em>ACISC</em>, <em>2025</em>(1), 7696962. (<a href='https://doi.org/10.1155/acis/7696962'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer vision plays a crucial role in current day tasks due to its wide range of merits and applications in many fields like disease diagnosis, medical decisions, military, security, scientific applications, and business. Identifying plant species upon their leaf images is a very challenging and complex task. In this study, we introduced a model for classifying a variety set of plant leaves using different techniques such as factorization machine (FM), dimensionality reduction (DR), and ensemble learning (EL). In our study, FM is used as a classification algorithm, whereas DR is included in two stages, namely, feature extraction (FE) and feature selection (FS). FE has been used to extract the features from images in tabular form; on the other hand, FS is used to reduce the size of the data by getting rid of noisy (redundant and irrelevant) features. In addition, we utilized two methods for FS, filter-based and wrapper-based approaches. The used filter was the minimum redundancy maximum relevance, and the used wrapper was the improved binary cuckoo search algorithm that is based on Lévy flight and abandon nest functions. Regarding EL, it was used to declare different versions of FM by passing different subsets of features that are deduced from the original ones to improve its performance. We used the Swedish and Flavia leaf datasets for training and testing phases. The proposed model achieved a high performance in terms of accuracy that produced 95.67% on Swedish dataset and 99.6% on Flavia dataset. According to the results and in comparison to other methods, we proved that our proposed model ensures a favorable plant leaf classification approach. Finally, the proposed wrapper FS approach showed very good results without setting up the number of features to be selected by the user. The entire implementation of this work can be found at https://github.com/Mohammed-Ryiad-Eiadeh/Binary-Cuckoo-Search-For-Plant-Leaf-Prediction .},
  archive      = {J_ACISC},
  author       = {Mohammad Subhi Al-Batah and Mohammad Ryiad Al-Eiadeh and Yazan Alnsour},
  doi          = {10.1155/acis/7696962},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {7696962},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {A novel approach for enhancing plant leaf classification with the binary cuckoo search algorithm},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Impact of climate change on groundwater level changes: An evaluation based on deep neural networks. <em>ACISC</em>, <em>2025</em>(1), 7641994. (<a href='https://doi.org/10.1155/acis/7641994'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Climate change has a substantial influence on groundwater levels (GWLs), which are critical for agriculture, safe drinking water, and ecosystem health, which are essential to successful water resource management and adaptation strategies. Recently, there has been an increase in the use of machine learning (ML) and deep learning (DL) models in hydrogeology to estimate GWL in monitoring wells. This study presents a novel technique for predicting GWL changes that uses three independent datasets: historical GWL and climatic variables (CVs) data such as rainfall and temperature influencing groundwater dynamics. In our experimental research, the models’ prediction output on real-world datasets ensures that the model’s significant patterns are recorded while taking into account the noise in the data, resulting in a perfect balance of bias and variance. The DL models’ results show a significant score of root mean square error (RMSE) between 2.20 and 12.40 and coefficient of determination ( R -squared between 0.84–0.99), showing a significant improvement in RMSE and mean absolute error (MAE) in the testing and validation categories, when compared to the current state-of-the-art methods. This study improves our understanding of GWL modeling and provides decision-makers with a reliable tool for controlling change. The study advances environmental modeling by exhibiting methodological complexity and emphasizes the importance of comprehensive data analysis in water resource management.},
  archive      = {J_ACISC},
  author       = {Stephen Afrifa and Tao Zhang and Peter Appiahene and Xin Zhao and Vijayakumar Varadarajan and Thomas Atta-Darkwah and Yanzhang Geng and Daniel Gyamfi and Rose-Mary Owusuaa Mensah Gyening},
  doi          = {10.1155/acis/7641994},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {7641994},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Impact of climate change on groundwater level changes: An evaluation based on deep neural networks},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Developing a predictive model for stroke disease detection using a scalable machine learning approach. <em>ACISC</em>, <em>2025</em>(1), 7394597. (<a href='https://doi.org/10.1155/acis/7394597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stroke disease has been the leading cause of death globally for the last several decades. Thus, the death rate can be decreased by early recognition of disease and ongoing surveillance. However, the largest obstacle to perform advanced analytics using the conventional approach is the growth of massive amount of data from various sources, including patient histories, wearable sensor devices, and medical data. The current technology that could have a large impact on the healthcare sector is the integration of machine learning with big data analytics (scalable machine learning), particularly in the early diagnosis of this disease. To address this issue, a scalable stroke disease prediction model for a multinode distributed environment, which was developed by combining big data analytics concepts with machine learning to handle extensive healthcare datasets, an aspect not seen in the prior literature on stroke disease detection, is presented in this work. We have implemented four scalable algorithms: logistic regression, random forest, gradient-boosting tree, and decision tree, using a dataset that was collected from a Medical Quality Improvement Consortium database. As a result, two worker nodes and one master node were used to analyze the dataset. The model’s performance was assessed using performance metrics including the area under the curve (AUC) and confusion matrix. With an accuracy of 94.3% and an AUC score of 99%, the random forest was determined to be better based on the experimental results. It was also shown that the main risk factor for stroke disease is diabetes, which is followed by hypertension. This study demonstrated the effectiveness of using Spark’s scalable machine learning techniques to forecast stroke disease and identify risk factors earlier. The findings of this study can be utilized by physicians as clinical decision aids to aid in the more accurate identification of stroke disease.},
  archive      = {J_ACISC},
  author       = {Assefa Senbato Genale and Tsion Ayalew Dessalegn},
  doi          = {10.1155/acis/7394597},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {7394597},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Developing a predictive model for stroke disease detection using a scalable machine learning approach},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid recurrent neural network architecture for the prediction of subscriber traffic in a mobile telecommunication network. <em>ACISC</em>, <em>2025</em>(1), 7322398. (<a href='https://doi.org/10.1155/acis/7322398'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate prediction of subscriber traffic is a critical challenge in telecommunication networks, as it is essential for making informed decisions to maintain consistent service quality. Various artificial intelligence (AI) methods have been explored for this purpose, with recurrent neural networks (RNNs) being particularly popular. However, RNNs often suffer from the gradient vanishing problem, which reduces their effectiveness in processing long sequences of data. Long short–term memory (LSTM) networks partially address this issue by controlling the propagation of learning errors, but they still face challenges related to convergence speed and residual learning errors. To address these limitations, this study proposes a new hybrid RNN architecture that combines features of Jordan and Frasconi networks for improved subscriber traffic prediction. The proposed architecture integrates two sublayers, a sigmoid and a Gaussian function, within a hidden layer that forms a loop. This configuration enables the network to leverage incremental learning through restricted Coulomb energy (RCE) at the local level, while also benefiting from global learning through backpropagation. The architecture was tested on a dataset consisting of cellular traffic data collected from a telecommunication operator in Cameroon. The results demonstrated that the hybrid RNN model outperforms traditional Jordan and Frasconi networks, achieving a root mean square error (RMSE) of 14.18 and a mean absolute error (MAE) of 8.61 using the Adam optimizer with a batch size of 64. In addition, the hybrid model showed superior performance in terms of RMSE, MAE, and convergence speed compared to the existing models. These findings suggest that the proposed model could support telecom operators in proactive congestion management and resource optimization.},
  archive      = {J_ACISC},
  author       = {Giquel Therance Sassa and Aurelle Tchagna Kouanou and Jean Louis Kedieng Ebongue Fendji and Arnauld Nzegha Fountsop and Thomas Bouetou Bouetou and Yves Sébastien Emvudu},
  doi          = {10.1155/acis/7322398},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {7322398},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {A hybrid recurrent neural network architecture for the prediction of subscriber traffic in a mobile telecommunication network},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Precision healthcare for UTIs: Leveraging machine learning to reduce readmissions. <em>ACISC</em>, <em>2025</em>(1), 7182123. (<a href='https://doi.org/10.1155/acis/7182123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hospital readmissions impose a significant financial strain on healthcare systems and can adversely affect patients. Unfortunately, traditional approaches to predicting readmissions frequently lack accuracy. This presents a critical challenge, as identifying patients at high risk for readmission is essential for implementing preventive measures. The study introduces a novel method that employs machine learning to automatically extract features from patient data, eliminating labor-intensive manual feature engineering. The primary goal is to develop predictive models for unplanned readmissions for UTI patients at Jordan University Hospital within 3 months postdischarge. This is executed through a retrospective analysis of electronic health records from January 2020 to June 2023. By leveraging machine learning techniques, the study identifies high-risk patients by evaluating demographic, clinical, and outcome characteristics, ensuring model reliability through thorough optimization, validation, and performance assessment. Three predictive models were developed as follows: a gradient-boosting classifier (GBC), logistic regression (LR), and stochastic gradient descent (SGD). The GBC, SGD, and LR achieved impressive accuracy rates of 99%, 95%, and 89%, providing strong confidence in the methodology. The study’s findings reveal key risk factors associated with readmissions, enhancing our understanding of this process and offering a valuable framework for improving patient care, optimizing resource allocation, and supporting evidence-based decision-making in healthcare management.},
  archive      = {J_ACISC},
  author       = {Odai Mohammad Al-Jbour and Mohammad Alshraideh and Bahaaldeen Alshraideh},
  doi          = {10.1155/acis/7182123},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {7182123},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Precision healthcare for UTIs: Leveraging machine learning to reduce readmissions},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Binary classification of meningioma grades using CNN and VGG16 + XGBoost deep learning models. <em>ACISC</em>, <em>2025</em>(1), 7151706. (<a href='https://doi.org/10.1155/acis/7151706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meningioma, a common type of brain tumor, highlights the critical need for early detection and treatment. The proposed research work addresses the severity level of meningial brain tumors by classifying the meningioma grades. The proposed work makes use of a dataset containing 35 Grade II and 49 Grade I images. To achieve accurate binary classification of meningioma grades, two deep learning models SimpleCNN and VGG16 + XGBoost were proposed. The proposed models use MRI image dataset to train the SimpleCNN model, allowing it to directly extract pertinent characteristics from the images. VGG16 model is a pretrained model used for extracting complex characteristics from the images in the MRI dataset. Then, the VGG16 model is integrated with the XGBoost classifier for the classification of meningioma grades. By comparing the performance of two models, VGG16 + XGBoost model outperforms the simple CNN, with an accuracy of 98.4%, in binary classification tests.},
  archive      = {J_ACISC},
  author       = {L. Priya and D. Saraswathi and M. Bhuvaneshwari and K. Dhanya and K. Krishna Kousalya},
  doi          = {10.1155/acis/7151706},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {7151706},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Binary classification of meningioma grades using CNN and VGG16 + XGBoost deep learning models},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image-based breast cancer histopathology classification and diagnosis using deep learning approaches. <em>ACISC</em>, <em>2025</em>(1), 7011984. (<a href='https://doi.org/10.1155/acis/7011984'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is characterized by abnormal cell growth, which leads to tumor formation. Autonomous breast cancer detection has seen good progress. However, there are still several challenges to robust detection. This survey article explores the complexities inherent in multiclass classification for breast cancer diagnosis, aiming to improve patient care, efficiency, and timeliness. In our study, we focus on using histopathology slide images and assess the current state of breast cancer classification, particularly with artificial intelligence, specifically deep learning and convolutional neural networks. The histopathology images are key tools in the diagnosis process, allowing pathologists to visually assess tissue samples for signs of cancer. Our analysis reveals several challenges that hinder the effectiveness of current diagnostic methods. One significant issue is the need for more diversity in the existing datasets, which often fail to represent a wide range of patient populations. This limitation reduces the accuracy of diagnostic results, mainly when applied to different clinical environments. Furthermore, class imbalances within these datasets, where certain cancer types or stages are underrepresented, lead to biased diagnoses, with more common cases being easily identified while rarer cases are frequently missed. Another challenge is the limited generalizability of current diagnostic techniques, which perform well in controlled environments but often need to improve when applied to new, unseen data from different institutions or imaging systems. Additionally, the complexity of histopathological analysis means that it can be difficult for clinicians to interpret certain findings, leading to uncertainty in the diagnostic process. Our study reveals that addressing these issues requires collaborative efforts to improve the quality of datasets, reduce class imbalances, and develop optimal standardized diagnostic methods. By overcoming these challenges, we can enhance the accuracy, efficiency, and accessibility of breast cancer diagnosis, ultimately leading to better patient outcomes and global healthcare. We believe that by examining several factors and variables and conducting an in-depth analysis of the state of the art, this study will contribute to the state of the art and benefit researchers in both computing and medical domains.},
  archive      = {J_ACISC},
  author       = {Lama A. Aldakhil and Haifa F. Alhasson and Shuaa S. Alharbi and Rehan Ullah Khan and Ali Mustafa Qamar},
  doi          = {10.1155/acis/7011984},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {7011984},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Image-based breast cancer histopathology classification and diagnosis using deep learning approaches},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimising content recommendations in context-aware mobile learning platform through machine learning. <em>ACISC</em>, <em>2025</em>(1), 6982455. (<a href='https://doi.org/10.1155/acis/6982455'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s mobile communication society, the integration of mobile technology in education has revolutionised learning through m-Learning. This approach leverages wireless mobile technology and computing, enabling learners to access educational resources anytime and anywhere, thereby enhancing flexibility and freedom. Mobile devices, such as smartphones, tablets and PDAs, facilitate m-Learning by providing mobility and interactive learning environments. M-Learning is characterised by its personalised, collaborative, and ubiquitous nature, offering learners context-aware experiences tailored to their immediate surroundings and needs. Context awareness plays a pivotal role in m-Learning, distinguishing it from traditional education by dynamically adapting content delivery based on factors beyond just location, including time, network conditions and user preferences. This adaptability poses significant challenges in designing effective teaching strategies that meet diverse learner requirements. To address these challenges, this study explores the application of machine learning techniques—specifically “Artificial Neural Networks (ANN), K-Nearest Neighbours (KNN) and Adaptive Neuro-Fuzzy Inference Systems (ANFIS)”—in developing a Context-Aware m-Learning platform. Performance comparisons based on RMSE, MAE and accuracy metrics reveal ANFIS as the optimal method for enhancing the proposed m-Learning system, aligning with the contextual demands and parameters defined for effective mobile education. ANFIS’s ability to minimise absolute prediction errors more effectively than the other methods. In terms of accuracy, ANFIS again leads the performance metrics, achieving an accuracy of 82.46% with 10 neurons. In comparison, ANN and KNN achieved accuracies of 81.17% and 80.74%, respectively. These accuracy values indicate that ANFIS not only reduces prediction errors but also consistently delivers higher predictive accuracy. This research contributes to advancing the field by providing insights into leveraging machine learning for adaptive and context-aware educational technologies, thereby optimising learning experiences in today’s mobile-centric educational landscape.},
  archive      = {J_ACISC},
  author       = {Sudhindra B. Deshpande and Goh Kah Ong Michael and Rakesh J. Kadkol and N. V. Karekar and Uttam Deshpande and Dharmanna Lamani},
  doi          = {10.1155/acis/6982455},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {6982455},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Optimising content recommendations in context-aware mobile learning platform through machine learning},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Security and privacy preservation in smart cities during security surveillance: A mapping study. <em>ACISC</em>, <em>2025</em>(1), 6727022. (<a href='https://doi.org/10.1155/acis/6727022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As smart cities have evolved through the constant incorporation of advanced technologies such as Internet of Things, the importance of efficient data collection and robust security monitoring has increased massively. These smart cities, while monitoring and evaluating different activities, utilize a network of interconnected sensors and devices. This would not only enhance the provision of public services but also ensure increased safety measures. However, the extensive implementation of such systems has increased the concerns related to privacy and data protection. The growing dependence on surveillance technology in smart cities, though beneficial in terms of security, has also increased challenges associated with the protection of individual privacy. As such, different research has been conducted to develop advanced solutions that ensure the security of an individual while also safeguarding their personal privacy. This study examines the different aspects of privacy preservation in the context of security surveillance in smart cities. By conducting a comprehensive analysis of 100 research articles, it elucidates the current state of research and identifies emerging solutions aimed at safeguarding citizen privacy while simultaneously upholding the integrity of smart urban environments.},
  archive      = {J_ACISC},
  author       = {Fatima Tariq and Ayesha Afzaal and Muhammad Junaid Anjum and Faria Kanwal and Komal Bashir and Momina Shaheen},
  doi          = {10.1155/acis/6727022},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {6727022},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Security and privacy preservation in smart cities during security surveillance: A mapping study},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive transformer model for long-term time-series forecasting of temperature and radiation in photovoltaic energy generation. <em>ACISC</em>, <em>2025</em>(1), 6671565. (<a href='https://doi.org/10.1155/acis/6671565'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting weather parameters, particularly temperature and solar radiation, plays a vital role in enhancing the efficiency of photovoltaic (PV) systems. This study introduces a cutting-edge transformer-based model specifically tailored for long-term time-series forecasting, aimed at improving the performance of PV generation systems. Leveraging the robust attention mechanisms and parallel processing capabilities inherent in encoder–decoder transformer architecture, the model effectively captures intricate relationships within weather data. A unique positional encoding layer is incorporated to bolster the model’s comprehension of the chronological sequence of data points. Furthermore, the multihead attention mechanism adeptly identifies interactions between key meteorological factors, especially temperature and radiation, which are crucial for precise PV generation predictions. Evaluation using real-world weather datasets reveals that the proposed model significantly surpasses conventional forecasting methods in mean squared error and mean absolute error metrics. This work underscores the applicability of transformer models in predicting temperature and radiation for PV generation, offering a scalable and efficient forecasting solution vital for sustainable energy management. The model is suitable for both large-scale solar installations and smaller setups, enhancing operational strategies and energy capture. Its improved accuracy in forecasting global horizontal radiation and temperature contributes to better planning and more effective energy utilization.},
  archive      = {J_ACISC},
  author       = {Asmaa Mohamed El-Saieed},
  doi          = {10.1155/acis/6671565},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {6671565},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {An adaptive transformer model for long-term time-series forecasting of temperature and radiation in photovoltaic energy generation},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ocular disease detection using fundus images: A hybrid approach of grad-CAM and multiscale retinex preprocessing with VGG16 deep features and fine KNN classification. <em>ACISC</em>, <em>2025</em>(1), 6653543. (<a href='https://doi.org/10.1155/acis/6653543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of deep learning has markedly enhanced the identification and diagnosis of ocular diseases, providing considerable benefits compared to conventional machine learning techniques. This research investigates the application of deep feature extraction for classifying eight different ocular diseases. The VGG16, a pretrained convolutional neural network (CNN) model, was employed for feature extraction, while the fine k-nearest neighbor (KNN) classifier was utilized for classification. Experimental results showed an initial classification accuracy of 89.2% using features from Gradient-weighted Class Activation Mapping (Grad-CAM) heatmaps and 83.1% using Multiscale Retinex (MSR) enhanced images. However, combining both feature sets led to an improved classification accuracy of 96.5%. Despite these promising results, several challenges remain, including the need for models that generalize across diverse patient imaging and demographics modalities, the accessibility of extensive annotated datasets, and the interpretability of models. Ethical issues and legal frameworks are also crucial for the safe and fair implementation of AI in medical services. The study suggests that future efforts in deep learning for ophthalmology should focus on creating large-scale, annotated datasets to enhance the detection of ocular diseases.},
  archive      = {J_ACISC},
  author       = {Shreemat Kumar Dash and Kante Satyanarayana and Santi Kumari Behera and Sudarson Jena and Ashoka Kumar Ratha and Prabira Kumar Sethy and Aziz Nanthaamornphong},
  doi          = {10.1155/acis/6653543},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {6653543},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Ocular disease detection using fundus images: A hybrid approach of grad-CAM and multiscale retinex preprocessing with VGG16 deep features and fine KNN classification},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thai morning glory price forecasting using deep learning. <em>ACISC</em>, <em>2025</em>(1), 6626517. (<a href='https://doi.org/10.1155/acis/6626517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study established advanced machine-learning-driven forecasting models to enhance the accuracy of price predictions for Thai morning glory, a widely consumed leafy green vegetable. The models were trained using historical price, weather, and rainfall data using time-series forecasting methods, specifically LSTM and CNN. The findings indicate that stepwise feature selection minimizes prediction errors and improves MSE, RMSE, MAPE, and MAE. Preliminary experiments revealed that the LSTM model with feature selection outperformed the other models, particularly in feature selection. Employing standard hyperparameters of 100 epochs, 32 batches, and five windows, the model demonstrated superior performance with a lower MSE (0.0010), RMSE (0.0274), MAPE (3.7803), and MAE (0.0158) than the CNN model. Statistical hypothesis testing revealed significant variations between the LSTM and CNN models, with feature selection p -values below 0.05. These results indicate that LSTM with feature selection models optimized through refined hyperparameters leads to more accurate Thai morning glory price forecasting, providing valuable insights for stakeholders in their decision-making processes. Additionally, this study can forecast prices for 5, 7, 14, and 21 days in advance based on different Window_len values, addressing various planning needs. The 5- and 7-day forecasts support short-term decision-making, such as scheduling harvest cycles and weekly market planning, whereas the 14-day forecast assists farmers in optimizing planting schedules and logistics. Furthermore, the 21-day forecast is beneficial for medium-term market planning, including negotiating forward contracts and adjusting distribution strategies to maximize profitability.},
  archive      = {J_ACISC},
  author       = {Kanokwan Waeodi and Laor Boongasame and Karanrat Thammarak},
  doi          = {10.1155/acis/6626517},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {6626517},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Thai morning glory price forecasting using deep learning},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Addressing label noise in colorectal cancer classification using cross-entropy loss and pLOF methods with stacking-ensemble technique. <em>ACISC</em>, <em>2025</em>(1), 6552580. (<a href='https://doi.org/10.1155/acis/6552580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorectal cancer is a significant global health issue, ranking as the third most common cancer and the second leading cause of cancer-related deaths worldwide. Early diagnosis of this disease is of utmost importance to increase the survival rate and enhance the healthcare system. Many machine learning (ML) and deep learning (DL) methods have been proposed to facilitate automated early diagnosis of this cancer. However, label noise in medical images and the dependence on a single model can lead to suboptimal model performance, which could potentially hinder the development of a sophisticated automated solution. In this paper, we address label noise in training data and propose a stacking-ensemble model for classifying colorectal cancer along with a trustworthy computer-aided diagnosis (CAD) system. Initially, a variety of filtering methods are extensively analyzed to determine the most suitable image representation, with subsequent data augmentation techniques. Second, a modified VGG-16 model was proposed with fine-tuning that was utilized as a feature extractor to extract meaningful features from the training samples. Third, a prediction uncertainty and probabilistic local outlier factor (pLOF) were applied to the extracted features to address the label noise issue in the training data. Fourth, we adopted a random forest–based recursive feature elimination (RF-RFE) feature selection method with various combinations of features to recursively select the most influential ones for accurate predictions. Fifth, four base ML classifiers and a metamodel were selected to build our final stacking-ensemble model, which integrates the prediction probabilities of multiple models into a meta-feature set to ensure trustworthy predictions. Finally, we integrated these strategies and deployed them into a web application to demonstrate a CAD system. This system not only predicts the disease but also generates the prediction probabilities of each class, which enhances both clarity and diagnostic insight. Our proposed model was compared with different state-of-the-art ML classifiers on a publicly available dataset and demonstrated the highest accuracy of 92.43%.},
  archive      = {J_ACISC},
  author       = {Ishrat Zahan Tani and Kah Ong Michael Goh and Md Nazmul Islam and Md Tarek Aziz and S. M. Hasan Mahmud and Dip Nandi},
  doi          = {10.1155/acis/6552580},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {6552580},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Addressing label noise in colorectal cancer classification using cross-entropy loss and pLOF methods with stacking-ensemble technique},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CNN-based obesity detection framework using typical regions of body thermograms and soft-vote fusion algorithm. <em>ACISC</em>, <em>2025</em>(1), 6405253. (<a href='https://doi.org/10.1155/acis/6405253'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It would be more beneficial and practical to detect obesity using typical regions of body thermograms instead of all regions of thermograms. In this study, we aimed to (1) determine the typical region of body thermograms and (2) propose a soft-vote fusion algorithm to develop a more accurate result in obesity detection. The typical regions of thermograms were selected by training and testing the pretrained CNN models with the thermogram dataset of all-region and single-region. All-region dataset includes thermograms from five regions, namely, supraclavicular (SCV), abdomen, forearm, palm, and shank, while each of single-region dataset consists of thermograms from an individual region. When tested on all-region dataset, the CNN model achieved the highest accuracy of 90.00%. When tested with a single-region dataset, three regions, namely, SCV, abdomen, and forearm, achieved the highest accuracy of 94.23% (SCV) and 96.15% (abdomen and forearm), which indicated that these regions were more representative than palm and shank. Then, we proposed a soft-vote fusion algorithm in which different trained CNN models from the previous experiments were combined to improve the detection performance. We found that the combination of those three regions can achieve the highest accuracy with the smallest model size. One of those proposed combinations achieved an accuracy of 98.08% with a framework size of 19.4 MB by only using SCV and abdomen thermogram as the inputs.},
  archive      = {J_ACISC},
  author       = {Hendrik Leo and Rusdha Muharar and Khairul Munadi and Fitri Arnia},
  doi          = {10.1155/acis/6405253},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {6405253},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {CNN-based obesity detection framework using typical regions of body thermograms and soft-vote fusion algorithm},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing an object detection algorithm for detecting oil palm fruit bunches and their ripeness. <em>ACISC</em>, <em>2025</em>(1), 6263757. (<a href='https://doi.org/10.1155/acis/6263757'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection and classification of oil palm fruit bunches are critical for optimizing palm oil yield and quality. Traditional methods relying on human visual inspection are prone to errors and inconsistencies. To address these challenges, this study proposes an optimized You Only Look Once Version 7 (YOLOv7) algorithm for real-time detection and classification of oil palm fruit bunches. By leveraging a comprehensive dataset and implementing strategic fine-tuning techniques, we significantly improved the model’s performance. The optimized model achieved a classification accuracy of 92.55% and a mean average precision (mAP) of 95.08%, demonstrating its effectiveness in real-world applications. The model was integrated into web application, allowing farmers and processing facilities to assess the ripeness of palm fruit in real time, thereby improving decision-making and operational efficiency. This research highlights the potential of advanced deep learning models in agricultural applications, promising a transformative impact on the palm oil industry by ensuring consistent quality assessments and optimizing production processes.},
  archive      = {J_ACISC},
  author       = {Piyanart Chotikawanid and Pattanapong Saeleung and Yutthapong Pianroj and Saysunee Jumrat and Teerasak Punvichai and Jirapond Muangprathub},
  doi          = {10.1155/acis/6263757},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {6263757},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Optimizing an object detection algorithm for detecting oil palm fruit bunches and their ripeness},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-grounded attention-based neural machine translation model. <em>ACISC</em>, <em>2025</em>(1), 6234949. (<a href='https://doi.org/10.1155/acis/6234949'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural machine translation (NMT) model processes sentences in isolation and ignores additional contextual or side information beyond sentences. The input text alone often provides limited knowledge to generate contextually correct and meaningful translation. Relying solely on the input text could yield translations that lack accuracy. Side information related to either source or target side is helpful in the context of NMT. In this study, we empirically show that training an NMT model with target-side additional information used as knowledge can significantly improve the translation quality. The acquired knowledge is leveraged in the encoder-/decoder-based model utilizing multiencoder framework. The additional encoder converts knowledge into dense semantic representation called attention. These attentions from the input sentence and additional knowledge are then combined into a unified attention. The decoder generates the translation by conditioning on both the input text and acquired knowledge. Evaluation of translation from Urdu to English with a low-resource setting yields promising results in terms of both perplexity reduction and improved BLEU scores. The proposed models in the respective group outperform in LSTM and GRU with attention mechanism by +3.1 and +2.9 BLEU score, respectively. Extensive analysis confirms our claim that the translations influenced by additional information may occasionally contain rare low-frequency words and faithful translation. Experimental results on a different language pair DE-EN demonstrate that our suggested method is more efficient and general.},
  archive      = {J_ACISC},
  author       = {Huma Israr and Safdar Abbas Khan and Muhammad Ali Tahir and Muhammad Khuram Shahzad and Muneer Ahmad and Jasni Mohamad Zain},
  doi          = {10.1155/acis/6234949},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {6234949},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Knowledge-grounded attention-based neural machine translation model},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of sustainable performance of industry 4.0 technologies using a novel fuzzy OPLO-POCOD method. <em>ACISC</em>, <em>2025</em>(1), 5821453. (<a href='https://doi.org/10.1155/acis/5821453'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the rapidly evolving landscape of decision-making, particularly amid the complexities of managing extensive data, it is crucial to develop methodologies that facilitate informed choices. This paper presents a novel technique designed to address multicriteria decision-making (MCDM) challenges through the opportunity losses-based polar coordinate distance (OPLO-POCOD) method. By integrating the principle of opportunity losses—a fundamental concept in economics and management—into the evaluation process, this approach enhances the decision-making framework, providing a clearer understanding of the trade-offs involved in selecting alternatives. The innovative methodology is applied to assess the sustainability impact of Industry 4.0 technologies within Iran’s automotive industry, a sector facing unique challenges such as the need for technological adaptation. Utilizing the fuzzy OPLO-POCOD method, the study analyzes various sustainable performance indicators, ultimately identifying simulation, blockchain, and radio frequency identification as critical enablers of sustainable development. These technologies exhibit remarkably low opportunity loss scores of 0.0212, 0.0232, and 0.0270, respectively, underscoring their pivotal roles in enhancing energy and resource efficiency in production activities. This research provides significant insights for industry stakeholders and policymakers, emphasizing the importance of integrating advanced technological solutions into sustainable development strategies. By aligning technological advancements with sustainability objectives, this study not only illuminates the transformative potential of Industry 4.0 technologies but also paves the way for future inquiries in this essential field, offering a strategic roadmap for promoting sustainable practices in the automotive sector and beyond.},
  archive      = {J_ACISC},
  author       = {Reza Sheikh and Soheila Senfi},
  doi          = {10.1155/acis/5821453},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {5821453},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Evaluation of sustainable performance of industry 4.0 technologies using a novel fuzzy OPLO-POCOD method},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GTN-GCN: Real-time traffic forecasting using graph convolutional network and transformer. <em>ACISC</em>, <em>2025</em>(1), 5572638. (<a href='https://doi.org/10.1155/acis/5572638'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A traffic network exhibits inherent characteristics of networks while also possessing unique features that hold significant research value. In this study, the limitations of static graph structures and the challenges of accurately modeling spatiotemporal dependencies in traffic flow have been addressed through a hybrid GCN-gated recurrent unit (GRU)-transformer model. The proposed model integrates a dynamic topology module (DTM) with graph attention networks (GATs), GRUs, and transformer-based temporal modules to adaptively capture the evolving dynamics of traffic networks. The DTM dynamically updates graph structures based on real-time traffic conditions, while GATs focus on identifying critical spatial relationships. GRUs efficiently capture temporal dependencies, and the transformer model captures long-term sequential patterns, providing a comprehensive framework for real-time traffic forecasting. The proposed model was trained and evaluated using the METR-LA dataset, which comprises traffic data from 207 sensors at 5-minute intervals. The model demonstrated superior performance across various metrics, achieving RMSE, MAE, and MAPE values of 4.125%, 2.985%, and 5.432%, respectively, for 15-minute predictions, with an R 2 value of 0.928. For longer prediction horizons (30, 45, and 60 min), the model consistently outperformed baseline methods, maintaining competitive RMSE and MAPE values. The experimental setup included normalization, graph construction using adjacency matrices, and preprocessing steps to ensure data quality and robustness. The integration of spatial and temporal features through the GCN-GRU-transformer framework enhanced the model’s ability to generalize across varying traffic scenarios, including peak hours and disruptions. Compared to traditional methods, which often rely on static graphs and fail to adapt to real-time changes, the hybrid model effectively addresses both spatial heterogeneity and temporal dependencies. The results indicate its robustness in handling complex traffic dynamics, adaptability to real-world variations, and potential applications in intelligent transportation systems. Future work will focus on incorporating multimodal data sources and enhancing computational efficiency to achieve broader scalability and deployment in smart city infrastructures.},
  archive      = {J_ACISC},
  author       = {Sadia Naj Jinia and Sumaiya Binte Azad and Rima Akter and Taivan Reza Dipto and Md. Khaliluzzaman},
  doi          = {10.1155/acis/5572638},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {5572638},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {GTN-GCN: Real-time traffic forecasting using graph convolutional network and transformer},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detection of hate speech and offensive language in arabic text: A systematic literature review. <em>ACISC</em>, <em>2025</em>(1), 5565888. (<a href='https://doi.org/10.1155/acis/5565888'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media sites facilitate users’ discussions, expression of opinions, sharing of information and news, and promotion of ideas and products, thus rapidly increasing the volume of hate speech and offensive content on online platforms. Consequently, hate speech and offensive content have turned out to be a widespread issue that negatively affects both individuals and society and needs to be controlled through detection and removal. This paper aims to provide a further understanding of the meaning of hate speech and offensive language and to provide a comprehensive discussion of the various techniques to detect hate speech and offensive language. A systematic literature review (SLR) of 90 research papers published between 2018 and 2024 was conducted to discover gaps within the literature. This review revealed challenges and possibilities for further development and improvement of previous findings. The results show that most of these works classified hate speech and offensive language using techniques from machine learning (ML) and deep learning (DL), and the most common performance metrics were Accuracy, Precision, Recall, and F-measure. The benchmark datasets are also described. Twitter was the most commonly utilized social network for obtaining datasets, while Facebook is sometimes used. Moreover, the findings of this review offer insight into research trends in Arabic hate speech and offensive language, as well as new research directions. The most interesting finding is that until now most Social Media Network Developers have not included autodetection of hate speech or offensive language plugins. Finally, this study presents a guideline for choosing the best strategies and techniques to detect and predict Arabic offensive language and hate speech.},
  archive      = {J_ACISC},
  author       = {Eman S. Alshahrani and Mehmet S. Aksoy and Ahmed Emam},
  doi          = {10.1155/acis/5565888},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {5565888},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Detection of hate speech and offensive language in arabic text: A systematic literature review},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting residential energy consumption in south africa using ensemble models. <em>ACISC</em>, <em>2025</em>(1), 5211419. (<a href='https://doi.org/10.1155/acis/5211419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents ensemble machine learning (ML) models for predicting residential energy consumption in South Africa. By combining the best features of individual ML models, ensemble models reduce the drawbacks of each model and improve prediction accuracy. We present four ensemble models: ensemble by averaging (EA), ensemble by stacking each estimator (ESE), ensemble by boosting (EB), and ensemble by voting estimator (EVE). These models are built on top of Random Forest (RF) and Decision Tree (DT). These base predictor models leverage historical energy consumption patterns to capture temporal intricacies, including seasonal variations and rolling averages. In addition, we employed feature engineering methodologies to further enhance their predictive abilities. The accuracy of each ensemble model was evaluated by assessing various performance indicators, including the mean squared error (MSE), mean absolute error (MAE), mean absolute percentage error (MAPE), and coefficient of determination R 2 . Overall, the findings illustrate the efficiency of ensemble learning models in providing accurate predictions for residential energy consumption. This study provides valuable insights for researchers and practitioners in predicting energy consumption in residential buildings and the benefits of using ensemble learning models in the building and energy research domains.},
  archive      = {J_ACISC},
  author       = {David Attipoe and Donatien Koulla Moulla and Ernest Mnkandla and Alain Abran},
  doi          = {10.1155/acis/5211419},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {5211419},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Predicting residential energy consumption in south africa using ensemble models},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A feedback-assisted inverse neural network controller for cart-mounted inverted pendulum. <em>ACISC</em>, <em>2025</em>(1), 4873425. (<a href='https://doi.org/10.1155/acis/4873425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A vast variety of neural network (NN)–based controllers use indirect adaptive control structures for their implementation, which primarily aims at estimating the nonlinear dynamics of the system and thereby generating a suitable control action. However, the most commonly used gradient descent weight update rule of the NN-based indirect adaptive controllers often fails to identify the system dynamics appropriately, and the control action becomes ineffective on the system under control. Further, a significant number of existing works in this domain employ randomized or suboptimal initial NN weights, which can potentially hamper the transient performance of the control loop. To address these issues, this paper proposes an innovative control scheme that utilizes the strength of indirect adaptive control of NN, along with the robustness of the PID controller. Since the PID control structure is often independent of plant dynamics and generates a control action to mitigate any error between the reference and the current plant output, it can be easily augmented with the control action generated by inverse neural network (INN) to mitigate any effects of unlearnt dynamics by INN. Further, we have used a bio-inspired optimization algorithm, that is, particle swarm optimization (PSO), to optimize the initial weights of the INN along with the PID controller’s parameters to get an optimal control performance. The proposed INN + PID controller scheme has been tested on a cart-mounted inverted pendulum system due to its challenging control requirement owing to its intricate nonlinear dynamics. Detailed simulation studies for the proposed INN + PID and PID controllers have been carried out for various control requirements, viz. set point tracking, disturbance rejection, and robustness testing. Further, an extensive comparative study has been devised based on the integral of absolute error (IAE) to test the efficacy of the proposed INN + PID controller against the conventional PID controller. Through extensive comparative studies, it was deduced that the proposed INN + PID controller is capable of handling the intricate nonlinear dynamics of the cart-mounted inverted pendulum system and provides a sturdy stabilization of the angular position of the pendulum with respect to the desired trajectory and superior transient control in comparison with the conventional PID controller. In terms of quantitative comparison, the improvement in IAE achieved by the proposed INN + PID controller was found to be 94.84%, 94.62%, and 69.86% better in comparison to the conventional PID controller for set point tracking, disturbance rejection for introduced impulsive force, and time-varying force variation, respectively.},
  archive      = {J_ACISC},
  author       = {ManMahendra Singh Daksh and Puneet Mishra},
  doi          = {10.1155/acis/4873425},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {4873425},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {A feedback-assisted inverse neural network controller for cart-mounted inverted pendulum},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fusion of deep and Time–Frequency local features for melanoma skin cancer detection. <em>ACISC</em>, <em>2025</em>(1), 4767052. (<a href='https://doi.org/10.1155/acis/4767052'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer spreads quickly as the skin is the most vulnerable organ, and melanoma (MEL) is a fatal type of skin cancer. Detecting MEL in the early stage can hugely increase the chance of a cure. There are several methods based on machine learning to detect MEL from dermoscopic images. However, increasing the accuracy of detection is still challenging. This paper presents a new method for MEL detection that considers the combination of deep and handcrafted time–frequency local features. After short preprocessing, the convolutional neural networks (CNNs) extract the deep features. To this end, feature maps at the output of the flatten layer are considered as deep features. The scale-invariant feature transform (SIFT) descriptors are handcrafted local features computed from the four subbands of one-level two-dimensional discrete wavelet transform (2D DWT). After the fusion of the mentioned features, semisupervised discriminant analysis (SDA) reduces the highly correlated and redundant features. The Bayesian optimizer finds the optimum parameters of the SDA and Gaussian kernel of the support vector machine (SVM) classifier to maximize the classification accuracy. The HAM10000 dataset with data augmentation is considered to assess the performance of the proposed method. Simulation results show that the proposed method reaches the accuracy and sensitivity of 94.19% and 96.22%, respectively. The most challenging parts of the proposed method are extraction of deep features and tuning the parameters of SDA and Gaussian-SVM.},
  archive      = {J_ACISC},
  author       = {Hamidreza Eghtesaddoust and Morteza Valizadeh and Mehdi Chehel Amirani},
  doi          = {10.1155/acis/4767052},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {4767052},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Fusion of deep and Time–Frequency local features for melanoma skin cancer detection},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A sentence-level Encoder–Decoder architecture for designing an administrative roman urdu chatbot. <em>ACISC</em>, <em>2025</em>(1), 4728280. (<a href='https://doi.org/10.1155/acis/4728280'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research focuses on developing an intelligent administrative chatbot for Roman Urdu to overcome the language barrier that hinders individuals who are not fluent in English from utilizing existing chatbot frameworks. While chatbot architectures can be rule based or artificial intelligence (AI) based, the core objective of a chatbot is to effectively address user queries across diverse domains. AI-based chatbots have demonstrated higher interactivity, scalability, adaptability to human interests, and evolving knowledge compared with rule-based architectures. However, the majority of existing chatbot frameworks is in English, which poses a challenge in regions like Pakistan where only a small percentage of the population is proficient in English. In response to this challenge, this research introduces an intelligent administrative chatbot specifically developed for Roman Urdu. Roman Urdu is the practice of writing Urdu, the native language of Pakistan, using the English alphabet. The proposed chatbot allows students to post their questions in either English or Roman Urdu, enabling them to obtain conclusive answers. The chatbot system utilizes a sentence analysis approach to generate relevant and productive responses to user queries. The core building block of the proposed chatbot is the recurrent neural networks (RNNs) sequence-to-sequence (Seq2Seq) model with long short-term memory (LSTM) units. To train the model, a dataset was meticulously collected from various administrative offices at the University of Engineering and Technology (UET), Lahore, initially in English and subsequently translated into Roman Urdu using different writing styles. The effectiveness of the proposed system was evaluated through a human judgment approach, assessing the contextual relevance and productivity of the chatbot’s responses to relevant questions. In conclusion, this research aims to bridge the language gap in chatbot frameworks, enhancing accessibility and usability.},
  archive      = {J_ACISC},
  author       = {Muhammad Nazam Maqbool and Rana Muhammad Saleem and Nadeem Sarwar and Muhammad Ibrahim and Muhammad Shadab Alam Hashmi},
  doi          = {10.1155/acis/4728280},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {4728280},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {A sentence-level Encoder–Decoder architecture for designing an administrative roman urdu chatbot},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing face recognition model performance through HyperStyle-driven data augmentation. <em>ACISC</em>, <em>2025</em>(1), 4097213. (<a href='https://doi.org/10.1155/acis/4097213'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face recognition is a reliable biometric technology that utilizes artificial intelligence and computer vision to identify and verify an individual’s identity based on facial features. Its rapid development has enabled integration into diverse applications, including security systems, access control, forensics, and mobile devices. However, challenges such as recognizing faces across different ages persist, presenting opportunities for further research. Developing robust face recognition models requires substantial training datasets, but manually labeling large collections of facial images is both time-intensive and costly. Our previous study demonstrated that a ResNet-50 model trained on a dataset of 44,000 facial images, combining the original FaceScrub dataset with HyperStyle age and smile augmentations, achieved an F1-score of 79%, significantly outperforming the model trained solely on the authentic FaceScrub dataset (F1-score: 63%). Building upon these findings, this study explores a broader range of augmentation styles, including pose and domain adaptation, e.g., Pixar, Toonify, Sketch, and Disney, using the HyperStyle scheme. Models trained with domain adaptation showed reduced performance (F1-score: 64%) due to the domain gap introduced by cartoon-like styles. In contrast, models trained with pose augmentation achieved an F1-score of 75%, demonstrating the importance of augmentations resembling real-world variations. When training incorporated all augmentation styles, e.g., age, smile, pose, and domain adaptation, the F1-score reached 78%, slightly lower than the model trained with age and smile augmentations only (F1-score: 79%). To further evaluate the impact of age and smile augmentations, additional experiments were conducted using various CNN models, including VGGNet-16, MobileNetV3Small, SEResNet-18, and ResNet-50, under different hyperparameter configurations. Among these, ResNet-50 achieved the highest F1-score (82%), surpassing VGGNet-16 (60%), MobileNetV3Small (65%), and SEResNet-18 (81%). The study also introduced modifications to the HyperStyle scheme in both the preprocessing and postprocessing stages, which further enhanced model performance. The ResNet-50 model trained with the modified HyperStyle scheme, and the original FaceScrub dataset achieved the highest F1-score of 83%, demonstrating the effectiveness of these modifications in improving face recognition performance.},
  archive      = {J_ACISC},
  author       = {Muhammad Chaidir and Taufik F. Abidin and Hizir Sofyan and Kahlil Muchtar},
  doi          = {10.1155/acis/4097213},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {4097213},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Enhancing face recognition model performance through HyperStyle-driven data augmentation},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing predictive capabilities for identifying at-risk stocks using multivariate time-series classification: A case study of the thai stock market. <em>ACISC</em>, <em>2025</em>(1), 3874667. (<a href='https://doi.org/10.1155/acis/3874667'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a multivariate time-series classification approach using deep learning to predict stocks likely to be flagged by the Market Surveillance Measure List in the Thai stock market. Formulated as a binary classification problem, the model distinguishes At-Risk and Normal stocks based on two primary datasets: End-of-Day stock prices and Market Surveillance Measure List records, incorporating trading volumes and technical indicators. To address data imbalance, concept drift, and long-term dependencies, the framework integrates feature engineering, cost-sensitive learning, and rolling window training. Experimental results show deep learning models significantly outperform traditional baseline methods in capturing financial risk patterns. The study identifies models that effectively balance predictive accuracy with computational efficiency, with performance varying based on forecasting horizons. Despite improvements from specialized techniques, the study identifies challenges in long-term financial risk prediction. These findings support market surveillance, algorithmic trading, and portfolio risk management, with future work exploring explainable AI, adaptive learning, and alternative data sources to enhance interpretability and long-term forecasting.},
  archive      = {J_ACISC},
  author       = {Katsamapol Petchpol and Laor Boongasame},
  doi          = {10.1155/acis/3874667},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {3874667},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Enhancing predictive capabilities for identifying at-risk stocks using multivariate time-series classification: A case study of the thai stock market},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ensemble Transformer–Based detection of fake and AI–Generated news. <em>ACISC</em>, <em>2025</em>(1), 3268456. (<a href='https://doi.org/10.1155/acis/3268456'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of fake online and AI–generated news content poses a significant threat to information integrity. This work leverages advanced natural language processing, machine learning, and deep learning algorithms to effectively detect fake and AI–generated content. The utilized dataset, combined with multiple open-source datasets, comprises 43,000 real, 31,000 fake, and 80,000 AI–generated news articles and is augmented with an ensemble large language model. We combined three open-source LLMs (GPT-2, GPT-NEO, and Distil-GPT-2) into an ensemble LLM to generate new news titles, selecting the best outputs through majority voting for further dataset expansion. Preprocessing involved data cleaning, lowercasing, stop word removal, tokenization, and lemmatization. We applied six machine learning and five natural language processing models to this dataset. The two top-performing natural language–based models (RoBERTa and DeBERTa) have been combined to develop an ensemble transformer model. Among the machine learning models, random forest achieved the highest performance, with an accuracy of 92.49% and an F1 score of 92.60%. Among the natural language processing models, the ensemble transformer model attained the highest results, with 96.65% accuracy and an F1 score of 96.66%. The proposed ensemble model is optimized by applying model pruning (reducing parameters from 265M to 210M, improving training time by 25%) and dynamic quantization (reducing model size by 50%, maintaining 95.68% accuracy), enhancing scalability and efficiency while minimizing computational overhead. The DistilBERT-Student model, trained using a balanced combination of feature- and logit-based distillation from the RoBERTa-base Teacher network, achieved strong classification performance with 96.17% accuracy. Visualize-based attention maps are constructed for different news categories to enhance the interpretability of the applied transformer–based ensemble news detection models. Finally, a website was developed to enable users to identify fake, real, or AI–generated news content. The employed dataset, including AI–generated news articles and implementation scripts, can be found at the following website: https://github.com/ishraqisheree99/Combined-News-Dataset.git .},
  archive      = {J_ACISC},
  author       = {Md. Ishraquzzaman and Mohammed Ashraful Islam Chowdhury and Shahreen Rahman and Riasat Khan},
  doi          = {10.1155/acis/3268456},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {3268456},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Ensemble Transformer–Based detection of fake and AI–Generated news},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effective techniques for handling missing values in thyroid disease diagnosis: A comparative analysis. <em>ACISC</em>, <em>2025</em>(1), 2766701. (<a href='https://doi.org/10.1155/acis/2766701'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handling missing values presents a critical challenge in thyroid disease prediction, significantly impacting diagnostic accuracy. This study evaluates the effectiveness of cold-deck, mean, and K-nearest neighbor (KNN) imputation techniques for predicting thyroid disease using a dataset of 9172 observations with 31 clinical features (5.2% missing values). Feature importance analysis identified thyroid-stimulating hormone (TSH), thyroxine (TT4), and free thyroxine index (FTI) as consistently significant biomarkers across all imputation methods. Five classifiers—Naïve Bayes, linear regression, support vector machines (SVM), LightGBM, and recurrent neural networks (RNN)—were assessed on imputed datasets, with performance evaluated through accuracy, F1 score, and recall. The KNN imputation method enhanced LightGBM’s accuracy by 0.47% over mean imputation (99.06% vs. 98.99%) and by 1.47% over cold deck (99.06% vs. 98.59%), demonstrating its superiority in preserving feature relationships and enhancing predictive power. LightGBM achieved the highest performance with KNN imputation (accuracy: 99.06%, F1: 97.57%, and recall: 97.83%), outperforming other classifiers by 2.5%–4.0% in accuracy. These results underscore the necessity of robust imputation techniques for reliable thyroid disease prediction. The study provides a reproducible framework for managing missing data in healthcare analytics, emphasizing the interplay between imputation, feature importance, and classifier selection to optimize diagnostic accuracy.},
  archive      = {J_ACISC},
  author       = {Dhekre Saber Saleh and Mohd Shahizan Othman and Wshyar Omar Khudhur and Eman Attallah Aljabarti},
  doi          = {10.1155/acis/2766701},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {2766701},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Effective techniques for handling missing values in thyroid disease diagnosis: A comparative analysis},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AD-KMeans: A novel clustering algorithm for fraud detection in imbalanced datasets. <em>ACISC</em>, <em>2025</em>(1), 2070857. (<a href='https://doi.org/10.1155/acis/2070857'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit card fraud detection remains a critical challenge due to the rarity and evolving nature of fraudulent transactions. Traditional clustering methods, such as K-means, are limited by fixed cluster numbers and sensitivity to outliers, often missing small or irregular fraud patterns. This research introduces an adaptive clustering algorithm (AD-KMeans) that dynamically adjusts the number of clusters based on variance and density thresholds, enabling better identification of hidden fraudulent activity. Using the Kaggle Credit Card Fraud Detection Dataset, the proposed method is evaluated against standard K-means using metrics such as accuracy, precision, recall, F 1-score, silhouette score, Davies–Bouldin index (DBI), and the Calinski–Harabasz index (CHI). Experimental results show that compared to state-of-the-art methods, the proposed AD-KMeans achieves the highest fraud recall (91.2%) and F 1-score (87.6%), improving recall by 22.3 percentage points over the best hybrid model (hybrid DNN + clustering, 68.9%) and F 1-score by 11.5 points (from 76.1% to 87.6%). Moreover, it identifies distinct fraud-prone clusters and adapts effectively to data structure variations. These findings highlight the algorithm’s potential as a robust unsupervised approach for improving fraud detection in highly imbalanced financial datasets.},
  archive      = {J_ACISC},
  author       = {Mohammad Aman Ullah},
  doi          = {10.1155/acis/2070857},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {2070857},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {AD-KMeans: A novel clustering algorithm for fraud detection in imbalanced datasets},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heart disease prediction using ensemble tree algorithms: A supervised learning perspective. <em>ACISC</em>, <em>2025</em>(1), 1989813. (<a href='https://doi.org/10.1155/acis/1989813'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart disease stands as a leading cause of morbidity and mortality globally, presenting a significant public health challenge. Therefore, early prediction and detection are critical, leading to timely and appropriate interventions at early stages. Four ensemble tree-based algorithms were used in this study: adaptive boosting, extreme gradient boosting, random forest, and extremely randomized trees, investigating their ability to predict heart disease. Data related to heart disease clinical features was obtained from the open Kaggle Machine Learning Dataset repository. Adaptive Boosting stands out as the highest performer, achieving an average testing accuracy of 93.70%, precision of 93.71%, recall of 93.70%, and F1 score of 93.69%, along with the highest AUC score of 0.9708, across all competing models considered in the study. These metrics indicate a superior ability to distinguish between patients with and without heart disease, effectively making it particularly valuable for clinical applications where early detection can save lives. The SHapley Additive exPlanations (SHAP) framework adopted to investigate the relative importance of the features in predicting heart disease revealed the most influential predictors (ST slope, chest pain type, old peak, and cholesterol), further aiding the understanding of heart disease mechanisms. Future work should explore the integration of ensemble learning algorithms with real-time patient monitoring systems. This integration could allow for continuous health status updates, equipping predictive models with the information necessary to facilitate dynamic, real-time interventions that are more closely aligned with patient needs.},
  archive      = {J_ACISC},
  author       = {Enoch Sakyi-Yeboah and Edmund Fosu Agyemang and Vincent Agbenyeavu and Akua Osei-Nkwantabisa and Priscilla Kissi-Appiah and Lateef Moshood and Lawrence Agbota and Ezekiel N. N. Nortey},
  doi          = {10.1155/acis/1989813},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {1989813},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Heart disease prediction using ensemble tree algorithms: A supervised learning perspective},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning framework for enhancing recommender systems with dual-feedback integration. <em>ACISC</em>, <em>2025</em>(1), 1951982. (<a href='https://doi.org/10.1155/acis/1951982'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative filtering (CF)-based personalized recommendation systems are among the most widely adopted strategies for addressing information overload in modern markets. However, a significant challenge that hinders the effectiveness of these systems is data sparsity. To address this limitation, advanced methodologies such as matrix factorization and deep learning models have been developed to improve CF system performance in sparse data scenarios. Despite their advancements, most existing models rely solely on either implicit or explicit user–item interactions to generate recommendations. Traditional CF approaches often struggle with sparsity, necessitating the development of hybrid methods that integrate both explicit and implicit feedback to enhance performance. To address this gap, this study introduces DeepBlendRec, an innovative deep learning-based framework that leverages both explicit user ratings and implicit user behaviour. By utilizing this dual-input methodology, the model captures richer information regarding user–item interactions, thereby significantly improving recommendation accuracy. DeepBlendRec employs an enhanced autoencoder with a constrained decoder to process implicit ratings, thereby improving reconstruction quality and facilitating the creation of robust latent space representations. Simultaneously, explicit ratings are processed through a multilayer perceptron. The reconstructed outputs are then fused to generate a Top-N recommendation list. Experimental evaluations conducted on the MovieLens datasets demonstrate that DeepBlendRec consistently outperforms existing models across several key performance metrics, including mean-squared error (MSE), root-mean-squared error (RMSE), mean absolute error (MAE), precision, recall, and F1-score. These results highlight the potential of DeepBlendRec to advance the capabilities of recommendation systems in handling data sparsity and improving predictive accuracy.},
  archive      = {J_ACISC},
  author       = {V. Lakshmi Chetana and Hari Seetha},
  doi          = {10.1155/acis/1951982},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {1951982},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {A deep learning framework for enhancing recommender systems with dual-feedback integration},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing constrained engineering optimization problems using improved mountain gazelle optimizer. <em>ACISC</em>, <em>2025</em>(1), 1922567. (<a href='https://doi.org/10.1155/acis/1922567'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel approach to engineering design optimization through the development of an improved mountain gazelle optimizer (iMGO) that incorporates variable neighborhood search (VNS) techniques. The enhanced algorithm effectively addresses engineering optimization challenges by identifying optimal design solutions within specified constraints. In particular, iMGO significantly improves solution diversity and mitigates the risk of premature convergence to local optima, thereby overcoming the limitations of the original MGO. A comprehensive analysis was conducted using 12 functions from the CEC 2022 benchmark suite, and the algorithm was applied to five engineering problems, including the design of an I-beam, pressure vessel, three-bar truss, cantilever beam, and tension spring. Comparative results indicate that iMGO outperforms established metaheuristic techniques, such as MFO, WOA, GOA, MPA, TSO, and SCSO, as well as the original MGO. The results validate iMGO’s effectiveness in navigating the complexities of constrained engineering optimization. For instance, in practical applications, the manufacturing cost of the pressure vessel design was reduced from 6014.4537 to 5915.3358, and the weight of the tension spring was decreased from 0.0149154 to 0.0130101 relative to the original MGO. These enhancements underscore the significant potential of iMGO in real-world applications across aerospace engineering, structural design optimization, energy system planning, and other fields, thereby contributing to more efficient and sustainable engineering solutions.},
  archive      = {J_ACISC},
  author       = {Vu Hong Son Pham and Nghiep Trinh Nguyen Dang and Van Nam Nguyen},
  doi          = {10.1155/acis/1922567},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {1922567},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Optimizing constrained engineering optimization problems using improved mountain gazelle optimizer},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified deep architecture for segmentation in remote sensing images. <em>ACISC</em>, <em>2025</em>(1), 1918054. (<a href='https://doi.org/10.1155/acis/1918054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning–based segmentation models have gained significant focus in various computer vision applications, including remote sensing and medical imaging. There exist deep learning architectures for semantic and instance segmentation separately, with limitations prevailing such as imprecise boundary delineation, poor spatial consistency, improper fine-grained object separation, and inaccurate instance segmentation, particularly while handling intricate object structures in remote sensing images (RSI). To mitigate the aforementioned issues, in the present work, we propose a unified deep framework that integrates both semantic and instance segmentation within a single architecture tailored for high-resolution RSI. Our framework combines an improved attention residual U-Net (IARU-Net) for pixel-level semantic segmentation and a dynamic Mask R-CNN for instance-level segmentation. To further refine spatial coherence and boundary delineation, we incorporate the postprocessing technique such as conditional random fields (CRFs) on the output segmentation map of the enhanced U-Net to improve spatial consistency and edge sharpness. This refined semantic mask serves as input to the dynamic Mask R-CNN model for instance segmentation, where the graph-based refinement module (GRM) is employed to improve boundary accuracy by leveraging graph-based smoothing techniques. Our approach ensures improved object delineation, increases the segmentation accuracy, and decreases false positives compared to conventional deep learning architectures. Evaluation outcomes on standard datasets illustrate that the proposed approach attains superior performance, highlighting its effectiveness in both semantic and instance segmentation tasks. The results validate the effectiveness of jointly modeling semantic and instance-level information, providing a more comprehensive understanding of complex remote sensing scenes.},
  archive      = {J_ACISC},
  author       = {Nagamani Gonthina and L. V. Narasimha Prasad},
  doi          = {10.1155/acis/1918054},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {1918054},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {A unified deep architecture for segmentation in remote sensing images},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning in medical imaging: Chronological evolution, frameworks, core methods, and recent advances in breast cancer segmentation (2023–2024). <em>ACISC</em>, <em>2025</em>(1), 1913589. (<a href='https://doi.org/10.1155/acis/1913589'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical imaging plays a crucial role in modern healthcare, facilitating the diagnosis and treatment of various diseases. The advent of deep learning has revolutionized the processing and analysis of medical images. This paper reviews recent literature on deep learning applications in medical imaging, focusing specifically on segmentation and classification for disease diagnosis and treatment. We discuss recent advancements in deep learning architectures tailored for these tasks, highlighting their relevance and effectiveness. The studies reviewed span the period from January 2023 to April 2024, concentrating on the latest deep learning methods proposed for breast cancer segmentation. Additionally, we explore the availability and characteristics of publicly available medical image datasets for breast cancer, emphasizing their importance in training and evaluating deep learning models. An overview of commonly used metrics for assessing model efficacy is provided, underscoring their role in quantifying performance. Furthermore, we address the challenges and limitations faced by deep learning methods in medical imaging. Through analysis and discussion, we propose innovative directions to address these challenges, paving the way for promising future applications in early disease detection and personalized treatment planning.},
  archive      = {J_ACISC},
  author       = {Youness Riouali and Naoual El Aboudi and Nezha El Bahaoui and Othman Arsalan and Fouad Tijami and Hafid Hachi and Youssef Omor and Rachida Latib and Laila Benhlima},
  doi          = {10.1155/acis/1913589},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {1913589},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Deep learning in medical imaging: Chronological evolution, frameworks, core methods, and recent advances in breast cancer segmentation (2023–2024)},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cooperative optimization hunting control of multi-MSV based on reinforcement learning. <em>ACISC</em>, <em>2025</em>(1), 1415549. (<a href='https://doi.org/10.1155/acis/1415549'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a cooperative hunting optimal control problem is studied for multimarine surface vehicle (MSV) systems based on reinforcement learning (RL). First, in order to enhance the efficiency of cooperative hunting, a novel task allocation method is proposed based on a leader–follower structure, where follower and leader MSVs perform the target encircling task and the target tracking task, respectively. Second, on the basis of task allocation, adaptive control design is employed for the follower MSVs to enhance the control performance of target encircling; optimal feedback control design combined with adaptive feedforward control design is considered using the RL algorithm for the leader MSVs to ensure the optimality of target tracking. Finally, the stability of the multi-MSV hunting control system is guaranteed and all signals are uniformly ultimately bounded based on the Lyapunov theory in the closed-loop system. The effectiveness of the proposed scheme is demonstrated through simulation results.},
  archive      = {J_ACISC},
  author       = {Yuanhao Wang and Weiwei Bai and Wenjun Zhang},
  doi          = {10.1155/acis/1415549},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {1415549},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Cooperative optimization hunting control of multi-MSV based on reinforcement learning},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Addressing class imbalance problem in health data classification: Practical application from an oversampling viewpoint. <em>ACISC</em>, <em>2025</em>(1), 1013769. (<a href='https://doi.org/10.1155/acis/1013769'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While analyzing health data is important for improving health outcomes, class imbalance in datasets poses major challenges to machine learning classification models. This work, therefore, considers the class imbalance problem in stroke prediction using models such as K-nearest neighbors, support vector machine, logistic regression, random forest, and decision tree. This work balances the stroke dataset, thereby enhancing model performance, through various oversampling strategies: random oversampling (RO), ADASYN, SMOTE, and SMOTE–Tomek. Compared to the results of the imbalanced dataset, all applied oversampling techniques enhanced the correct classification of stroke events by the ML model. Among these, RO–SVM with RBF kernel was the best in terms of sensitivity, specificity, G-mean, F1-score, and accuracy values, offering the highest results with respective values of 89.87%, 94.91%, 92.36%, 89.64%, and 89.87%. After applying oversampling techniques, all the machine learning classifications were good enough to classify stroke status, especially for the minority class. This study has highlighted the importance of class imbalance issues in health datasets. Precise detection of instances of minority classes can be enhanced considerably by employing classification models with the implementation of hybrid strategies to effectively solve class imbalance issues, which, in turn, will help improve healthcare outcomes. Further research in integrating more advanced deep learning techniques into other health datasets with imbalances is encouraged to further validate or refine class imbalance approaches, as effective handling of imbalanced classes can substantially promote predictive model performance in the analysis of healthcare.},
  archive      = {J_ACISC},
  author       = {Edmund Fosu Agyemang and Joseph Agyapong Mensah and Eric Nyarko and Dennis Arku and Benedict Mbeah-Baiden and Enock Opoku and Ezekiel Nii Noye Nortey},
  doi          = {10.1155/acis/1013769},
  journal      = {Applied Computational Intelligence and Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {1013769},
  shortjournal = {Appl. Comput. Intell. Soft Comput.},
  title        = {Addressing class imbalance problem in health data classification: Practical application from an oversampling viewpoint},
  volume       = {2025},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
