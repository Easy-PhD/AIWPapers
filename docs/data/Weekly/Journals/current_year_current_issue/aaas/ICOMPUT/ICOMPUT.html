<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ICOMPUT</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="icomput">ICOMPUT - 2</h2>
<ul>
<li><details>
<summary>
(2025). Graph-enhanced spatiotemporal trajectory similarity learning. <em>ICOMPUT</em>, <em>4</em>, 0169. (<a href='https://doi.org/10.34133/icomputing.0169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of location information platforms based on global positioning systems has led to a proliferation of spatiotemporal trajectory data, which has, in turn, made the analysis of such data available to a broad range of applications, including traffic prediction, route planning, and trajectory similarity computation. Traditional methods for calculating trajectory similarity often suffer from high computational costs due to quadratic time complexity, particularly when dealing with large datasets. To this end, deep learning-based approaches to trajectory similarity learning have been proposed, with a view to offering enhanced efficiency and adaptability in comparison with traditional methods. However, these methods primarily focus on spatial trajectory similarity and fail to capture important temporal periodicity. Moreover, most of them directly use recurrent neural networks to obtain trajectory representations, while ignoring the spatial proximity information between neighboring regions. To address these limitations, we propose a graph-enhanced spatiotemporal trajectory network, named GST, which integrates both spatial and temporal information to effectively learn trajectory similarity. Specifically, our model incorporates a graph neural network to capture the spatial proximity relationships and a time-embedding module to model the temporal periodicity information, thereby providing a more comprehensive spatiotemporal trajectory representation learning paradigm. Extensive experiments on 2 real-life datasets demonstrate that our model outperforms existing state-of-the-art methods in terms of accuracy. In addition, ablation studies demonstrate the effectiveness of the proposed spatiotemporal learning mechanism.},
  archive      = {J_ICOMPUT},
  author       = {Xijuan Liu and Zhangyi Xu and Haobo Wei and Peilun Yang},
  doi          = {10.34133/icomputing.0169},
  journal      = {Intelligent Computing},
  month        = {9},
  pages        = {0169},
  shortjournal = {Intell. Comput.},
  title        = {Graph-enhanced spatiotemporal trajectory similarity learning},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent time series analysis for intrusion detection in the internet of things: A generative-adversarial-network-enhanced convolutional-neural-Network–Long-short-term-memory framework using signal features. <em>ICOMPUT</em>, <em>4</em>, 0127. (<a href='https://doi.org/10.34133/icomputing.0127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From smart cities to healthcare, the internet of things (IoT) has transformed numerous industries. However, this expansion has raised security concerns, particularly cyberattacks. Traditional IoT intrusion detection systems (IDSs) have high false-positive rates and low detection accuracy due to IoT devices and traffic patterns. To overcome these challenges, this research proposes an intelligent-computing-based time series IDS that utilizes sophisticated data augmentation, signal transformation, and deep learning methods. The system begins by augmenting minority-class samples using conditional generative adversarial networks to handle class imbalance. The augmented dataset is then transformed into signal representations based on mel frequency cepstral coefficients, allowing the model to capture both the frequency and temporal characteristics of network traffic. Finally, a hybrid convolutional-neural-network–long-short-term-memory (CNN–LSTM) architecture is trained to identify anomalous behaviors with enhanced accuracy and lower false-positive rates. The proposed model utilizes the Canadian Institute for Cybersecurity CICIoT2023 dataset, which is widely used for network security experiments. The results show that the proposed method outperforms conventional deep learning models in terms of accuracy, precision, and false-positive rate. Specifically, the proposed system improves accuracy by 5% to 10% across different attack types while reducing false-positive rates considerably. The research presents a detailed exploration of the advantages of signal transformation and explains how the CNN and LSTM models complement each other in detecting anomalies. This framework addresses the pressing need for intelligent time series analysis in cybersecurity through the introduction of a scalable and interpretable IDS solution specifically designed for IoT environments.},
  archive      = {J_ICOMPUT},
  author       = {Himanshu Sharma and Prabhat Kumar and Kavita Sharma},
  doi          = {10.34133/icomputing.0127},
  journal      = {Intelligent Computing},
  month        = {9},
  pages        = {0127},
  shortjournal = {Intell. Comput.},
  title        = {Intelligent time series analysis for intrusion detection in the internet of things: A generative-adversarial-network-enhanced convolutional-neural-Network–Long-short-term-memory framework using signal features},
  volume       = {4},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
