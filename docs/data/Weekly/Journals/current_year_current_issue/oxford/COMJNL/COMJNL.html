<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>COMJNL</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="comjnl">COMJNL - 18</h2>
<ul>
<li><details>
<summary>
(2025). Small object detection in remote sensing images through multi-scale feature fusion. <em>COMJNL</em>, <em>68</em>(9), 1329-1340. (<a href='https://doi.org/10.1093/comjnl/bxaf040'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the challenges posed by background noise and the limited information available for small targets in remote sensing images, the detection performance for such targets remains unsatisfactory. To address these issues and enhance detection accuracy, we propose an improved algorithm based on RTDETR, named Adaptive Selective Transformer. Firstly, in the feature extraction network, we introduce an adaptive convolutional feature enhancement module to improve the multi-scale feature extraction capability in low-resolution remote sensing images. Secondly, we design a multi-scale enhancement structure to extract detailed information from small target images through enhanced multi-scale representation learning, thereby generating target features with stronger discriminative power. Finally, we propose a hierarchical frequency attention mechanism to achieve localized enhancement of contextual awareness, effectively capturing high-frequency local feature information of small targets. Experimental results demonstrate that the Adaptive Selective Transformer achieves superior small target detection performance, validating the effectiveness of our modifications to the original RTDETR model.},
  archive      = {J_COMJNL},
  author       = {Li, Sumin and Lin, Jinhua and Gang, Yijin and Pan, Xiuqin},
  doi          = {10.1093/comjnl/bxaf040},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1329-1340},
  shortjournal = {Comput. J.},
  title        = {Small object detection in remote sensing images through multi-scale feature fusion},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Confluence: Improving network monitoring accuracy on multi-pipeline data plane. <em>COMJNL</em>, <em>68</em>(9), 1315-1328. (<a href='https://doi.org/10.1093/comjnl/bxaf039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A sketch-based method is promising for traffic monitoring in data center networks. Existing data plane programming model (e.g. P4) assumes target switch as one single pipeline, while state-of-the-art programmable switches actually contain multiple independent pipelines. The status quo approach for deploying a sketch-based measurement application on a multi-pipeline switch is to deploy a sketch instance in each pipeline individually. However, under multi-path routing, such a naive approach leads to poor accuracy. To overcome this problem, in this paper, we present Confluence , a sketch-based network measurement system for multi-pipeline switches. For monitoring network flows that have packets arrived in bursts and spread over multiple pipelines, Confluence introduces novel data structures to collect short-term traffic statistics in ingress pipelines, and converge the measurement data to egress pipelines. Confluence is carefully designed under the switch hardware constraints, and in particular, to resolve the circular dependency in querying and updating a flow’s measurement data from sketch buckets, we propose a novel algorithm and theoretically prove its effectiveness. Both theoretical analysis and experiments driven by real-world traffic traces show that Confluence delivers higher measurement accuracies than existing solutions, especially in the critical task of detecting heavy hitters. Assessment on hardware switch suggests that Confluence is practical for real-world deployment.},
  archive      = {J_COMJNL},
  author       = {Wang, Cenman and Tian, Ye and Wu, Yiwen and Zhang, Xinming},
  doi          = {10.1093/comjnl/bxaf039},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1315-1328},
  shortjournal = {Comput. J.},
  title        = {Confluence: Improving network monitoring accuracy on multi-pipeline data plane},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatio-temporal traffic flow forecasting based on second-order continuous graph neural network. <em>COMJNL</em>, <em>68</em>(9), 1300-1314. (<a href='https://doi.org/10.1093/comjnl/bxaf038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal forecasting has wide applications across various domains, particularly in intelligent transportation systems, where it plays a crucial role. Traffic flow prediction, a typical spatio-temporal forecasting task, involves complex dependencies across both time and space dimensions. Current research predominantly relies on graph neural networks (GNNs) for modeling. However, deep GNN architectures often face the issue of over-smoothing. To address this challenge, recent studies have explored integrating residual connections or neural ordinary differential equations (ODEs) with GNNs. Nonetheless, existing graph ODE methods have limitations in initializing latent feature representations for time series data and capturing higher order spatio-temporal dependencies. Additionally, they struggle to extract multi-scale temporal dependencies. In this paper, we propose a framework called the Multiple Second-order Continuous Graph Neural Network. The framework utilizes a second-order continuous GNN, and experiments on four real-world datasets demonstrate that it outperforms mainstream baseline models, thereby confirming the effectiveness of the proposed method.},
  archive      = {J_COMJNL},
  author       = {Ma, Zhaobin and Lv, Zhiqiang and Xu, Zhihao and Ye, Rongkun and Li, Jianbo},
  doi          = {10.1093/comjnl/bxaf038},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1300-1314},
  shortjournal = {Comput. J.},
  title        = {Spatio-temporal traffic flow forecasting based on second-order continuous graph neural network},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balancing privacy and model performance in federated learning through contract-based data trading. <em>COMJNL</em>, <em>68</em>(9), 1285-1299. (<a href='https://doi.org/10.1093/comjnl/bxaf037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of the Internet of Things (IoT) has led to a huge amount of data beginning to emerge. Federated learning (FL) has received widespread attention and application as a new paradigm for data collection. However, data trading poses a threat to the privacy of data owners, and even participants in federated learning face the risk of data breaches. While many encryption methods have been proposed to mitigate these risks, the encrypted data negatively impacts the quality of the global model in federated learning. To this end, we propose an algorithm based on contract mechanisms to resolve the conflict between the privacy protection level of clients and the aggregation error on the federated learning server. Clients upload perturbed data according to their privacy protection levels, while mitigating the conflict between client data privacy protection and platform global model aggregation error. Through theoretical analysis and extensive experiments, our proposed trading method achieves desirable data utility while ensuring budget feasibility, individual rationality, and incentive compatibility.},
  archive      = {J_COMJNL},
  author       = {Liao, Gengjian and Shao, Shiyu and Feng, Zhenni},
  doi          = {10.1093/comjnl/bxaf037},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1285-1299},
  shortjournal = {Comput. J.},
  title        = {Balancing privacy and model performance in federated learning through contract-based data trading},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PHISH_ATTENTION: Achieving robust phishing website detection with balanced datasets and advanced URL features. <em>COMJNL</em>, <em>68</em>(9), 1263-1284. (<a href='https://doi.org/10.1093/comjnl/bxaf036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The escalating prevalence of phishing attacks in recent years has underscored the imperative need for a comprehensive and sophisticated response to mitigate this pervasive cyber threat. Characterized by deceptive tactics to obtain sensitive information, phishing has evolved in sophistication, resulting in severe consequences such as financial loss, identity theft, and compromise of personal data. This research addresses the inherent challenges faced by existing anti-phishing solutions, encompassing limitations in feature extraction methodologies, suboptimal feature selection, and issues related to dataset imbalance. In response to these challenges, we propose “PHISH_ATTENTION,” an advanced anti-phishing framework that integrates Variational Autoencoders and a Multi-Head Self-Attention Mechanism. The framework is further enhanced by the incorporation of a Deep Convolutional Generative Adversarial Network to effectively address dataset imbalances. Rigorous testing on benchmark datasets reveals that PHISH_ATTENTION achieves a peak detection accuracy of 98.57% with a minimal false alarm rate of 1.09%, surpassing prevailing anti-phishing models. Distinguished by its proficiency in real-time phishing website detection, the framework’s autonomous acquisition of significant URL features establishes it as a resilient and pioneering contribution to the cybersecurity domain.},
  archive      = {J_COMJNL},
  author       = {Prabhakaran, Manoj Kumar and Chandrasekar, Abinaya Devi and Meenakshi Sundaram, Parvathy},
  doi          = {10.1093/comjnl/bxaf036},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1263-1284},
  shortjournal = {Comput. J.},
  title        = {PHISH_ATTENTION: Achieving robust phishing website detection with balanced datasets and advanced URL features},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multilingual knowledge graph completion based on structural features. <em>COMJNL</em>, <em>68</em>(9), 1252-1262. (<a href='https://doi.org/10.1093/comjnl/bxaf035'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multilingual knowledge graph completion predicts missing facts in the target language knowledge graph by learning and inferring knowledge and rules in other language knowledge graphs. Existing methods tend to use aligned entities between knowledge graphs in different languages as alignment seeds, and receive information from them through alignment seeds to promote entity alignment between different knowledge graphs. However, these methods only consider the local structural information of the knowledge graph by aggregating entity neighborhood information through aligned entities, and ignore the global structural information. At the same time, the methods aboved are hardly to learn the entity representation with sparse neighborhood in isolated subgraphs. To address these two problems, this paper proposes a multilingual knowledge graph completion method based on double-branch graph neural network and self-supervised entity alignment (DBGNN-SSL). The global and local topological structures of the knowledge graph are learned through a double-branch graph attention neural network, and more aligned entities can be iteratively generated through self-supervised learning. The experimental results on datasets DBP-5L and E-PKG verify the effectiveness of the proposed method.},
  archive      = {J_COMJNL},
  author       = {He, Jinyan and Yang, Haitong},
  doi          = {10.1093/comjnl/bxaf035},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1252-1262},
  shortjournal = {Comput. J.},
  title        = {Multilingual knowledge graph completion based on structural features},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unravelling the semantic mysteries of transformers layer by layer. <em>COMJNL</em>, <em>68</em>(9), 1237-1251. (<a href='https://doi.org/10.1093/comjnl/bxaf034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the significant success of transformer models and their successors in various natural language processing (NLP) applications, their internal workings are still not fully understood. Much of the current interpretability research has focused primarily on numerical components, often missing the complex semantic layers within these models. To fill this gap, this study explores the interpretability of the transformer model, a cornerstone of modern NLP, by addressing the semantic complexities of its multi-layer architecture. We identify three key questions: (i) the influence of the multi-layer structure on semantic processing, (ii) the unique contributions of each layer to model performance, and (iii) methodologies for determining optimal layer counts for the encoder and decoder. To tackle these issues, we introduce the semantic interpreter for transformer hierarchy, an innovative framework that employs convex hull metrics to visualize and assess semantic quality and quantity. Our contributions include novel methods for semantic assessment, a dual analytical framework that integrates cumulative and layer-to-layer perspectives, and insights into the dynamics of encoding and decoding. This comprehensive approach aims to enhance the understanding of Transformer models, ultimately guiding their refinement for improved interpretability and effectiveness in natural language tasks.},
  archive      = {J_COMJNL},
  author       = {Zhang, Cheng and Lv, Jinxin and Cao, Jingxu and Sheng, Jiachuan and Song, Dawei and Zhang, Tiancheng},
  doi          = {10.1093/comjnl/bxaf034},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1237-1251},
  shortjournal = {Comput. J.},
  title        = {Unravelling the semantic mysteries of transformers layer by layer},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid approach to task offloading optimization: Integrating hybrid whale genetic algorithm and reinforcement learning. <em>COMJNL</em>, <em>68</em>(9), 1225-1236. (<a href='https://doi.org/10.1093/comjnl/bxaf033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing presents a promising approach for achieving communication Quality of Service (QoS) by employing a task offloading strategy to transfer latency-sensitive tasks into edge servers. Considering the offload equalization challenge, in this paper, we propose a novel task offloading optimization method based on a Hybrid Whale Genetic Algorithm (HWGA) with Reinforcement Learning (RL) to optimize the task offloading decisions within a tri-layer edge computing architecture comprising edge, fog, and cloud layers. Due to the expansive dimensionality of the action space from the increasing number of devices, we adapt the RL into a multi-layer architecture. In this framework, multi-layer RL techniques are first utilized to determine which layer should handle the task offloading. Subsequently, the HWGA is applied to guide the task offloading decisions for devices within each layer. Simulation results demonstrate that, when compared to baseline methods, our HWGA-based approach significantly reduces task completion time and energy consumption, while improving the task success rate, particularly in high-device-density scenarios.},
  archive      = {J_COMJNL},
  author       = {Luo, Qianhua and Xie, Bo and Wang, Jiahuan and Shuai, Jiaqi and Cui, Haixia},
  doi          = {10.1093/comjnl/bxaf033},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1225-1236},
  shortjournal = {Comput. J.},
  title        = {A hybrid approach to task offloading optimization: Integrating hybrid whale genetic algorithm and reinforcement learning},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Arming text-based gender inference with partition membership filtering and feature selection for online social network users. <em>COMJNL</em>, <em>68</em>(9), 1208-1224. (<a href='https://doi.org/10.1093/comjnl/bxaf032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study is devoted to simulating a text categorization-based gender inference attack over online social networks primarily to inspect the effect of partition membership filter (PMF) and feature selection (FS) on the performance of an attribute inference mechanism especially for the case of the distributed representation of texts. The task turning into a binary machine learning (ML) problem in the field of artificial intelligence (AI) is studied in multilingual scenarios (i.e. Turkish and English) under four main cases. The results obtained by extensive experiments show that distributed embeddings often outperform traditional embeddings. In contrast, the case involving FS on distributed embeddings is superior to other cases two of which incorporate PMF. On the other hand, the best f1-scores obtained on Turkish and English datasets are 0.727 and 0.611 obtained with the help of Random Forest and Support Vector Machine classifiers, respectively. It is worth noting that this investigation is not handled in the existing literature on text data. Therefore, it is believed that the findings of this study will provide useful insight for researchers studying text-based attribute inference attacks as well as some other text-based binary ML tasks in the field of AI.},
  archive      = {J_COMJNL},
  author       = {Çoban, Önder and Yücel Altay, Şeyma},
  doi          = {10.1093/comjnl/bxaf032},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1208-1224},
  shortjournal = {Comput. J.},
  title        = {Arming text-based gender inference with partition membership filtering and feature selection for online social network users},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient unlearning for data security in deep learning systems. <em>COMJNL</em>, <em>68</em>(9), 1197-1207. (<a href='https://doi.org/10.1093/comjnl/bxaf031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine unlearning in the context of cybersecurity and privacy protection facilitates the removal of specific training data impacts from deep learning (DL) models, adhering to security, privacy, or compliance demands. However, traditional methods can only handle short-term, independent unlearning tasks. Conversely, real-world scenarios often involve extensive unlearning demands from users. Current methods fail to adequately address these demands due to substantial computational overhead and adverse impacts on inference accuracy, leaving the security and privacy of many users at risk. To navigate these challenges adeptly, we introduce the Multi-Agent Reinforcement Learning Data Lifecycle Management (MADLM) strategy. MADLM intricately examines the interactions between unlearning and continuous learning processes, enabling the postponement of certain tasks for combined execution to optimize computational resources. Concurrently, it employs strategic data management to maintain and enhance inference accuracy. Furthermore, by utilizing Multi-Agent Reinforcement Learning (MARL), MADLM dynamically orchestrates task scheduling to minimize computational demands, improve task response times, and bolster inference reliability, crucial for upholding stringent cybersecurity and privacy standards. Our evaluations of MADLM reveal substantial enhancements, including a 6% uplift in inference accuracy and a dramatic reduction in computational overhead to merely 12% of the original demands, effectively expanding the data security protections.},
  archive      = {J_COMJNL},
  author       = {Guo, Enting and Su, Chunhua and Li, Peng},
  doi          = {10.1093/comjnl/bxaf031},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1197-1207},
  shortjournal = {Comput. J.},
  title        = {Efficient unlearning for data security in deep learning systems},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Use of data mining in identifying the risk factors of optic neuropathy. <em>COMJNL</em>, <em>68</em>(9), 1181-1196. (<a href='https://doi.org/10.1093/comjnl/bxaf030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optic nerve carries signals from the eye to the brain, where they are interpreted as visual images. Optic neuropathy is a serious eye disease that can lead to the loss of vision in the affected eye. Identifying the risk factors for optic neuropathy from large patient data is crucial and challenging. Modern techniques can assist in recognizing these risk factors. For instance, data mining algorithms such as classification and association rules can discover knowledge from datasets in many real-world applications, particularly in the medical field. This study employed a decision tree algorithm known as J48 and an association rule algorithm called Apriori to analyze the collected data. The J48 algorithm achieved an accuracy of 90%, while the Apriori algorithm discovered 52 significant association rules with a confidence level above 80%. The goal of this study was to identify risk factors for optic neuropathy and explore the connection between optic nerve damage and other conditions. The proposed algorithms aim to reduce blindness rates and increase awareness of the risk factors associated with optic nerve damage by detecting hidden risk factors at an early stage. The study's findings show that some risk factors for optic neuropathy confirmed by medical trials are also detected by these algorithms, proving the effectiveness and applicability of data mining techniques in the medical field. Moreover, this study discovered new risk factors for optic nerve damage not previously found by medical trials. This knowledge will contribute to the early detection and prevention of blindness by recognizing risk factors for optic nerve damage.},
  archive      = {J_COMJNL},
  author       = {Al-Shamiri, Abdulkawi Yahya Radman and Yu, Dong-Jun and Li, Peipei and Al-Mahweeti, Balqis Yahya Ali Abdullah},
  doi          = {10.1093/comjnl/bxaf030},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1181-1196},
  shortjournal = {Comput. J.},
  title        = {Use of data mining in identifying the risk factors of optic neuropathy},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced code slicing with pre-trained model fine-tuned for open-source component malware detection. <em>COMJNL</em>, <em>68</em>(9), 1163-1180. (<a href='https://doi.org/10.1093/comjnl/bxaf029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open Source Software (OSS) is an essential part of modern software development, with platforms such as PyPI for Python, NPM for JavaScript, and RubyGems for Ruby facilitating code sharing and reuse. However, these repositories also pose significant security risks due to potential software supply chain attacks, where payloads are injected into components, propagating threats to downstream users and critical infrastructure. Existing automatic malicious component detection tools, particularly for PyPI, struggle to distinguish between subtle differences in malicious and benign behaviors, leading to high false positive rates. To address these issues, we systematically compare and explore these subtle differences, offering a more refined and accurate detection method, Open-Source Component Code Slices BERT (OCS-BERT). OCS-BERT leverages taint-based program slicing to isolate sensitive behavior segments and fine-tunes pre-trained model to capture subtle semantic differences across programming languages. This system excels in detecting malicious Python components and exhibits encouraging cross-language transferability to JavaScript's NPM and Ruby's RubyGems. Additionally, OCS-BERT successfully detected 107 malicious components from a total of 25,759 newly-uploaded PyPI components, taking two weeks to complete the process. This achievement demonstrates the effectiveness of our method, which serves as a potent enhancement to the current repertoire of software supply chain detection methodologies.},
  archive      = {J_COMJNL},
  author       = {Wang, Yongshan and Pang, Siyuan and Fan, Zijing and Shang, Shang and Yao, Yepeng and Jiang, Zhengwei and Liu, Baoxu},
  doi          = {10.1093/comjnl/bxaf029},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1163-1180},
  shortjournal = {Comput. J.},
  title        = {Advanced code slicing with pre-trained model fine-tuned for open-source component malware detection},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced social media crime prevention via deep learning and cryptographic data encryption. <em>COMJNL</em>, <em>68</em>(9), 1150-1162. (<a href='https://doi.org/10.1093/comjnl/bxaf028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing prevalence of crime facilitated through social media platforms has become a critical concern for law enforcement and security agencies. With vast amounts of personal, sensitive, and actionable data being shared online, the risk of criminal exploitation has grown significantly, necessitating innovative approaches to crime prevention. This research addresses the problem of detecting and preventing social media-based crimes by integrating cryptographic data encryption with a focus on privacy and security. This study proposes a hybrid ECC-RSA (Elliptic Curve Cryptography—Rivest, Shamir, Adleman) model with key selection optimized using the Zebra Optimization Algorithm (ZOA) to enhance both the security and efficiency of the encryption process. Additionally, an Artificial Neural Network (ANN) is employed as a specific application to classify and detect suspicious online activities related to criminal behavior. A key challenge in this domain is achieving a balance between privacy preservation and effective crime detection. To evaluate the system, an extensive dataset of social media interactions containing both legitimate and suspicious activities was used. The results demonstrate that the integrated ECC-RSA model with ZOA optimization provides robust encryption while maintaining high detection accuracy, achieving 92% accuracy, 89% precision, and 91% recall. The ANN-based detection system successfully identifies potential criminal activities, while the cryptographic model ensures no sensitive data is exposed during analysis, maintaining user privacy. The findings suggest that the proposed hybrid model offers a promising solution for proactive crime prevention on social media, effectively balancing privacy, security, and detection performance.},
  archive      = {J_COMJNL},
  author       = {Alserhani, Faeiz},
  doi          = {10.1093/comjnl/bxaf028},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1150-1162},
  shortjournal = {Comput. J.},
  title        = {Advanced social media crime prevention via deep learning and cryptographic data encryption},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FRACE: Front-running attack classification on ethereum using ensemble learning. <em>COMJNL</em>, <em>68</em>(9), 1137-1149. (<a href='https://doi.org/10.1093/comjnl/bxaf027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid evolution of blockchain technologies, Ethereum has emerged as a central platform for advanced financial applications but has concurrently experienced a rise in security vulnerabilities, particularly from front-running attacks. These attacks exploit transaction sequencing for illegal gains. To combat this, we introduce FRACE (Front-Running Attack Classification using Ensemble Learning), a novel methodology that classifies front-running attacks into displacement, insertion, and suppression using an ensemble learning model. This precise classification facilitates tailored defensive strategies, enhancing the robustness and accuracy of attack detection. Our approach achieves an accuracy of 95.36% and an F1-score of 95.30%, significantly improving the security of decentralized applications. Extensive analysis and validation on Ethereum confirm these results. Future efforts will refine these models and extend their application to other blockchain platforms, striving for a universally secure, transparent, and reliable digital transaction ecosystem.},
  archive      = {J_COMJNL},
  author       = {Zhang, Yuheng and Wang, Guojun and Li, Peiqiang and Gu, Wanyi and Chen, Houji},
  doi          = {10.1093/comjnl/bxaf027},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1137-1149},
  shortjournal = {Comput. J.},
  title        = {FRACE: Front-running attack classification on ethereum using ensemble learning},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GitHub project recommendation based on knowledge graph and developer similarity. <em>COMJNL</em>, <em>68</em>(9), 1128-1136. (<a href='https://doi.org/10.1093/comjnl/bxaf026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding and recommending projects that match developer’s interests is always an urgent problem in open-source community. There are some problems in the existing project recommendation methods, such as insufficient use of information, ignoring the relationship between projects, one-sided consideration, and so on. To solve the above problems, we propose a project recommendation model based on project knowledge graph and developer similarity, called knowledge graphs and developer interest similarity (KGDS). KGDS mines developer interest from project similarity and developer similarity. For project similarity, we first construct the project knowledge graph. Then, content features and potential features are extracted from the project Readme document and knowledge graph, respectively, and the two features are merged to enrich the developer embedding and project embedding, which solves the problem of insufficient utilization of information. For developer similarity, we first construct a developer-project matrix, then obtain the historical developers related to candidate project, and then calculate the similarity between the historical developers and the target developer, which solves the problem of one-sided consideration. Finally, we combine the two part information to recommend projects that meet the interests of developers. We have conducted experiments on the GitHub dataset, and the results show that KGDS outperforms the baseline model.},
  archive      = {J_COMJNL},
  author       = {Yu, Song and Liu, Wenlong and Wu, Hannan and Liao, Zhifang},
  doi          = {10.1093/comjnl/bxaf026},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1128-1136},
  shortjournal = {Comput. J.},
  title        = {GitHub project recommendation based on knowledge graph and developer similarity},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A yolo-like lightweight ship detection network for unmanned surface vehicles. <em>COMJNL</em>, <em>68</em>(9), 1118-1127. (<a href='https://doi.org/10.1093/comjnl/bxaf025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread application of unmanned surface vehicles (USVs) in maritime surveillance has highlighted the need for improved ship detection models. However, hardware limitations and environmental interference impact the perception capability of USVs. In order to address these challenges, YoloS, a lightweight ship detection network, is specifically designed for USVs in complex backgrounds. Firstly, a network component Split Widely Network (SWNet) is put forward to the backbone to reduce its redundancy. SWNet leverages inter-channel interaction and the idea of group convolution to minimize redundancy of the network. Secondly, the Small Pyramid Network (SPN) is introduced as the neck network. SPN enhances the spatial information of the target regions by capturing and highlighting significant contour and texture details within target regions. SPN also utilizes these low-level features with enhanced spatial information to guide high-level features in identifying the most discriminative fine-grained details within the target regions. In order to further achieve network lightweighting, only two output heads for low-level features are retained while still preserving the capability to extract task-critical features. Extensive experiments on different datasets have verified the effectiveness of the proposed method, and it shows that YoloS can achieve 96.5 % detection accuracy and 80.1 fps on the SMD dataset with only 2.78M model parameters and 10.4G floating point operations.},
  archive      = {J_COMJNL},
  author       = {Zhou, Weina and Shao, Wei and Hu, Wenhua},
  doi          = {10.1093/comjnl/bxaf025},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1118-1127},
  shortjournal = {Comput. J.},
  title        = {A yolo-like lightweight ship detection network for unmanned surface vehicles},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-feature adaptive framework for multimodal disinformation detection. <em>COMJNL</em>, <em>68</em>(9), 1105-1117. (<a href='https://doi.org/10.1093/comjnl/bxaf024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spread of disinformation on online social media has caused massive concern. Existing disinformation detection methods neglect the diverse compositional forms of tweets in real-life scenarios, making them less applicable and effective in social media settings. Meanwhile, these methods use pattern cues but overlook important aspects such as syntax, lexicon, and shallow visual semantics, and lack attention to factual content such as time, place, and person relay in both text and images, thus failing to fully explore features of disinformation and limiting detection accuracy. Furthermore, with the popularity of large language models (LLMs), the tweets generated by these models make the style of disinformation more subtle. Since existing datasets are mostly human-generated and lack style diversity, it results in weak detection capabilities of methods trained on these datasets. To address these challenges, a dual-feature adaptive framework for multimodal disinformation detection is proposed. The framework first using a similarity-based algorithm adaptively handles different tweet forms. It then enhances pattern features by bridging multimodal output from single-modal pretrained modal, and factual features are subsequently extracted using a zero-shot method based on a large vision language model. Finally, an expert network aggregates and reweights the dual-feature representation for tweets using an LLM-text detector in gating strategy. This paper also presents two multimodal disinformation datasets that include both LLM-generated and human-generated tweets reflecting real-world scenarios. The true tweets in datasets are diverse in style, while the fake tweets are more misleading. Experimentally verified, the proposed method outperforms baseline methods by an accuracy of 1.04% and 0.72% on typical datasets while also achieving a minimum accuracy drop of 0.65% and 0.87% on the proposed dataset.},
  archive      = {J_COMJNL},
  author       = {Yan, Kexiang and Liang, Gang and Wang, Lei and Sun, Mingxu and Zhao, Kui},
  doi          = {10.1093/comjnl/bxaf024},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1105-1117},
  shortjournal = {Comput. J.},
  title        = {Dual-feature adaptive framework for multimodal disinformation detection},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PEAR: Privacy-preserving and effective aggregation for byzantine-robust federated learning in real-world scenarios. <em>COMJNL</em>, <em>68</em>(9), 1087-1104. (<a href='https://doi.org/10.1093/comjnl/bxae086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) enables collaborative training of global models among distributed clients without sharing local data. Secure aggregation, a new security primitive of FL, enhances the confidentiality of data and model parameters. Unfortunately, privacy-preserving (PP) FL is vulnerable to common poisoning attacks by Byzantine adversaries. Existing defense strategies mainly focus on identifying abnormal local gradients over plaintexts, which provides a weak privacy guarantee. In PPFL, adversaries can escape existing defenses by uploading encrypted poisonous gradients. In addition, most mainstream aggregation algorithms assume that clients’ local training data is uniformly distributed, Independent and Identically Distributed (IID), which is unrealistic for real-world FL scenarios where data are only stored on large-scale terminal devices. To address these issues, we propose PEAR, a PP aggregation strategy based on single key-dual server CKKS full homomorphic encryption in real-world distributed scenarios, which can resist encrypted poisoning attacks. Specifically, we use cosine similarity to measure the distance between encrypted gradients. Then, we propose a novel Byzantine-tolerance aggregation mechanism using cosine similarity, which includes trust score generation that can tolerate differentiated local gradients and a two-step weight generation method that considers both the degree of gradient deviation in direction and training data size. This mechanism can achieve robustness for both IID and non-IID data without compromising privacy. Our extensive evaluations for two typical poisoning attacks on different datasets show that PEAR is robust and effective in IID and non-IID data and outperforms existing mainstream Byzantine-robust algorithms, especially achieving 16.4% to 53.2% testing error rate reduction in non-IID settings with significant label distribution and quantity skew while maintaining the same efficiency as FedAvg.},
  archive      = {J_COMJNL},
  author       = {Sun, Han and Zhang, Yan and Zhuang, Huiping and Li, Jiatong and Xu, Zhen and Wu, Liji},
  doi          = {10.1093/comjnl/bxae086},
  journal      = {The Computer Journal},
  month        = {9},
  number       = {9},
  pages        = {1087-1104},
  shortjournal = {Comput. J.},
  title        = {PEAR: Privacy-preserving and effective aggregation for byzantine-robust federated learning in real-world scenarios},
  volume       = {68},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
