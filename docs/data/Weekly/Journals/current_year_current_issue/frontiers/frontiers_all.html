<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>frontiers</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="fcomp">FCOMP - 13</h2>
<ul>
<li><details>
<summary>
(2025). Legal perspectives on AI and the right to digital literacy in education. <em>FCOMP</em>, <em>7</em>, 1692268. (<a href='https://doi.org/10.3389/fcomp.2025.1692268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionArtificial intelligence (AI) is increasingly becoming a part of educational practice, providing opportunities for personalization and access but also introducing risks to equity, learner autonomy, privacy, and accountability. Focusing on European and Greek contexts, we examine whether a right to digital literacy can be grounded in existing law and how the EU AI Act reshapes duties for educational actors.MethodsWe conduct a legal-doctrinal and policy-analytic study of EU primary/secondary law, the Greek Constitution, and EU Regulations (AI Act), read alongside institutional 'grey' literature (e.g., educator toolkits, national bioethics opinions). We map AI Act recitals and Annex III to concrete governance obligations (fundamental rights impact assessment, transparency, human oversight) and test implications through targeted case vignettes (examinations, admissions, LMS/explainability). Scope is limited to EU/Greece; comparative case law is used selectively to illuminate the normative claims.ResultsFirst, a defensible right to digital literacy emerges from EU instruments and Greek constitutional provisions on participation in the information society and the mission of education. Second, many AI uses in education (e.g., admissions, outcome evaluation, proctoring) qualify as high-risk under the AI Act, triggering ex-ante and ongoing duties, while emotion recognition in education (absent medical/safety grounds) is effectively off-limits. Third, the vignette analysis shows recurring pressure points, such as bias and disparate impact, opacity in automated decisions, and excessive surveillance, where explainability and meaningful human oversight are necessary to preserve equity, autonomy, and educational quality.DiscussionWe propose an actionable governance agenda for schools and universities: mandatory fundamental-rights impact assessments adapted to educational contexts; explainability criteria as admissibility and accountability thresholds for deployed systems; clear escalation paths and complaint mechanisms; inclusive access measures to narrow the digital divide; and multi-stakeholder oversight that keeps educators central rather than substitutable. Taken together, these measures shift debate from abstract ethics to enforceable legal duties, aligning AI adoption with human-rights values and the educational mission to cultivate critical, responsible citizens.},
  archive      = {J_FCOMP},
  author       = {Panagopoulou, Fereniki and Parpoula, Christina and Karpouzis, Kostas},
  doi          = {10.3389/fcomp.2025.1692268},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {1692268},
  shortjournal = {Front. Comput. Sci.},
  title        = {Legal perspectives on AI and the right to digital literacy in education},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing medical image segmentation via complementary CNN-transformer fusion and boundary perception. <em>FCOMP</em>, <em>7</em>, 1677905. (<a href='https://doi.org/10.3389/fcomp.2025.1677905'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionVision Transformers (ViTs) show promise for image recognition but struggle with medical image segmentation due to a lack of inductive biases for local structures and an inability to adapt to diverse modalities like CT, endoscopy, and dermatology. Effectively combining multi-scale features from CNNs and ViTs remains a critical, unsolved challenge.MethodsWe propose a Pyramid Feature Fusion Network (PFF-Net) that integrates hierarchical features from pre-trained CNN and Transformer backbones. Its dual-branch architecture includes: (1) a region-aware branch for global-to-local contextual understanding via pyramid fusion, and (2) a boundary-aware branch that employs orthogonal Sobel operators and low-level features to generate precise, semantic boundaries. These boundary predictions are iteratively fed back to enhance the region branch, creating a mutually reinforcing loop between segmenting anatomical regions and delineating their boundaries.ResultsPFF-Net achieved state-of-the-art performance across three clinical segmentation tasks. On polyp segmentation, PFF-Net attained a Dice score of 91.87%, surpassing the TransUNet baseline (86.96%) by 5.6% and reducing the HD95 metric from 22.25 to 11.68 (a 47.5% reduction). For spleen CT segmentation, it reached a Dice score of 95.33%, outperforming ESFPNet-S (94.92%) by 4.3% while reducing the HD95 from 6.99 to 3.35 (a 52.1% reduction). In skin lesion segmentation, our model achieved a Dice score of 90.29%, which represents a 7.3% improvement over the ESFPNet-S baseline (89.64%).DiscussionThe results validate the effectiveness of our pyramid fusion strategy and dual-branch design in bridging the domain gap between natural and medical images. The framework demonstrates strong generalization on small-scale datasets, proving its robustness and potential for accurate segmentation across highly heterogeneous medical imaging modalities.},
  archive      = {J_FCOMP},
  author       = {Liu, Xiaowei and Tian, Juanxiu and Huang, Shangrong and Shen, Wei},
  doi          = {10.3389/fcomp.2025.1677905},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {1677905},
  shortjournal = {Front. Comput. Sci.},
  title        = {Enhancing medical image segmentation via complementary CNN-transformer fusion and boundary perception},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid voice cloning for inclusive education in low-resource environments. <em>FCOMP</em>, <em>7</em>, 1675616. (<a href='https://doi.org/10.3389/fcomp.2025.1675616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionVoice cloning can personalize speech technologies but typically requires large datasets and compute, limiting use in low-resource educational settings.MethodsWe propose a hybrid pipeline combining a GE2E-trained speaker encoder, a Tacotron-based text-to-spectrogram synthesizer, and a modified WaveRNN vocoder with gated GRUs and skip connections. The system targets few-shot adaptation (5–10 s of target speech) and near real-time synthesis on modest hardware.ResultsOn LibriSpeech, VCTK, and noisy YouTube/local corpora, the system achieves MCD ≈ 4.8–5.1 and improves MOS over baselines (e.g., LibriSpeech: 4.55 vs. 4.33; YouTube: 3.82 vs. 3.10), with EER < 12% on an external ASV, indicating strong speaker similarity.DiscussionResults show data-efficient, robust voice cloning suitable for inclusive education, with practical considerations for deployment (compute, noise) and responsible use (consent, watermarking, detection). The approach supports assistive and multilingual classroom scenarios in low-resource contexts.},
  archive      = {J_FCOMP},
  author       = {Mohtad Younus, Muhammad and Iqbal, Arshad and Durrani, Esha e Noor and Ahmad, Naveed and Ladan, Mohamad},
  doi          = {10.3389/fcomp.2025.1675616},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {1675616},
  shortjournal = {Front. Comput. Sci.},
  title        = {A hybrid voice cloning for inclusive education in low-resource environments},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Market malicious bidding user detection based on multi-agent reinforcement learning. <em>FCOMP</em>, <em>7</em>, 1670238. (<a href='https://doi.org/10.3389/fcomp.2025.1670238'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of e-commerce and online auction markets, malicious bidding activities have severely disrupted market order. Traditional detection methods face limitations due to their inability to effectively address the covert nature, dynamic characteristics, and massive data volumes associated with such behaviors. To address this challenge, this paper proposes a detection method for users engaging in malicious bidding based on Multi-Agent Reinforcement Learning (MARL). This approach first models target users as specialized agents, then integrates their historical bidding data, and finally learns optimal strategies through competitive games with adversarial agents. Additionally, this paper designs a dynamic adjustment mechanism for the maliciousness coefficient to simulate user behavior changes, enabling precise assessment of malicious intent. Compared to existing fraud detection approaches based on reinforcement learning, the fundamental innovation lies not merely in applying MARL technology, but in introducing the novel “dynamic maliciousness coefficient” mechanism. This mechanism achieves dynamic and precise maliciousness assessment through mathematical modeling and real-time iteration, addressing the shortcomings of traditional MARL models in capturing user behavioral heterogeneity. Experimental results demonstrate that this method exhibits higher detection accuracy and adaptability in complex dynamic market environments. It effectively captures bidder interaction relationships, significantly enhancing the detection of malicious behavior.},
  archive      = {J_FCOMP},
  author       = {Wang, Peng and Wang, Yimeng and Zhang, Yilin and Lan, Yin and Huang, Ziyang and Tang, Di and Liang, Yu},
  doi          = {10.3389/fcomp.2025.1670238},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {1670238},
  shortjournal = {Front. Comput. Sci.},
  title        = {Market malicious bidding user detection based on multi-agent reinforcement learning},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Changing modes of public connection: An essay on TikTok and the social affordances of personalized social media. <em>FCOMP</em>, <em>7</em>, 1655767. (<a href='https://doi.org/10.3389/fcomp.2025.1655767'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The short-video app TikTok has become one of the most used social media platforms globally. Its affordances are distinctly different from those of prior apps and platforms—specifically due to TikTok’s algorithm-centric design. This essay critically reflects on the consequences of this design logic, especially in relation to modes of public connection, resistance, and social change. Reflecting on ethnographic fieldwork on TikTok, it opens three perspectives: (1) on the modes of disconnected sociability that TikTok’s “For You” page affords, (2) the forms of infrapolitical resistance that materialize within the textual structure of the “For You” page, and (3) the importance of creativity as an element of the consumption process shaping its social meaningfulness. Across these three perspectives, the essay argues that TikTok affords relatively unique modes of public connection which, ultimately, can only be understood in their real consequences when viewed as integrated parts of the micro-social world where people’s day-to-day lives unfold.},
  archive      = {J_FCOMP},
  author       = {Schellewald, Andreas},
  doi          = {10.3389/fcomp.2025.1655767},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {1655767},
  shortjournal = {Front. Comput. Sci.},
  title        = {Changing modes of public connection: An essay on TikTok and the social affordances of personalized social media},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Left-deep join order selection with higher-order unconstrained binary optimization on quantum computers. <em>FCOMP</em>, <em>7</em>, 1649354. (<a href='https://doi.org/10.3389/fcomp.2025.1649354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Join order optimization is among the most crucial query optimization problems, and its central position is also evident in the new research field where quantum computing is applied to database optimization and data management. In this field, join order optimization is the most studied database problem, typically tackled with a quadratic unconstrained binary optimization model, which is solved using various meta-heuristics, such as quantum and digital annealing, the quantum approximate optimization algorithm, or the variational quantum eigensolver. In this study, we continue developing quantum computing techniques for left-deep join order optimization by presenting three novel quantum optimization algorithms. These algorithms are based on a higher-order unconstrained binary optimization model, which is a generalization of the quadratic model and has not previously been applied to database problems. Theoretically, these optimization problems naturally map to universal quantum computers and quantum annealers. Compared to previous studies, two of our algorithms are the first quantum algorithms to model the join order cost function precisely. We prove theoretical bounds by showing that these two methods encode the same plans as the dynamic programming algorithm with respect to the query graph, which provides the optimal result up to cross products. The third algorithm achieves plans at least as good as those of the greedy algorithm with respect to the query graph. These results establish a meaningful theoretical connection between classical and quantum algorithms for selecting left-deep join orders. To demonstrate the practical usability of our algorithms, we have conducted an extensive experimental evaluation on thousands of clique, cycle, star, tree, and chain query graphs using both quantum and classical solvers.},
  archive      = {J_FCOMP},
  author       = {Uotila, Valter},
  doi          = {10.3389/fcomp.2025.1649354},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {1649354},
  shortjournal = {Front. Comput. Sci.},
  title        = {Left-deep join order selection with higher-order unconstrained binary optimization on quantum computers},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep one-class classifier for network anomaly detection using autoencoders and one-class support vector machines. <em>FCOMP</em>, <em>7</em>, 1646679. (<a href='https://doi.org/10.3389/fcomp.2025.1646679'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe integration of deep learning models into Network Intrusion Detection Systems (NIDS) has shown promising advancements in distinguishing normal network traffic from cyber-attacks due to their capability to learn complex non-linear patterns. These approaches typically rely on both benign and malicious network traffic during training. However, in many organizations, collecting malicious traffic is challenging due to privacy restrictions, high costs of manual labeling, and requirement for advanced security expertise.MethodsIn this study, we introduce a deep one-class classification model that is trained exclusively on flow-based benign network traffic data, with the goal of identifying attacks during inference. The proposed anomaly detection model consists of two steps, a One-Class Support Vector Machine (OC-SVM) and a deep AutoEncoder (AE). While autoencoders have shown great potential in anomaly detection, their effectiveness can be undermined by spurious network activity located on the boundaries of their discriminating capabilities, thus failing to identify malicious behavior. Our model leverages the topological structure of the OC-SVM to generate decision scores for each traffic flow, which are subsequently incorporated into an autoencoder as part of the input feature space.ResultsThis approach enhances the ability of the autoencoder to detect incidents that deviate from normal patterns. Furthermore, we propose a heuristic method for tuning the trade-off parameter of the OC-SVM, based only on one-class data, achieving comparable performance to grid-based methods that require both benign and malicious labeled data. Experimental results on a benchmark network intrusion data set, the UNSW-NB15, suggest that OCSVM-AE performs well on unseen attacks and is more effective than traditional and deep-learning based one-class classifiers.DiscussionThe method makes no specific assumptions about the data distribution, making it broadly applicable and suitable as a complementary tool to signature-based intrusion detection systems.},
  archive      = {J_FCOMP},
  author       = {Bountzis, Polyzois and Kavallieros, Dimitris and Tsikrika, Theodora and Vrochidis, Stefanos and Kompatsiaris, Ioannis},
  doi          = {10.3389/fcomp.2025.1646679},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {1646679},
  shortjournal = {Front. Comput. Sci.},
  title        = {A deep one-class classifier for network anomaly detection using autoencoders and one-class support vector machines},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Entropy measurement and online quality control of bit streams by a true random bit generator. <em>FCOMP</em>, <em>7</em>, 1642566. (<a href='https://doi.org/10.3389/fcomp.2025.1642566'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating random bit streams is required in various applications, most notably in cyber-security, which is essential for Internet of Everything applications to enable secure communication between interconnected devices. Ensuring high-quality and robust randomness is crucial to mitigate risks associated with predictability and system compromise. True random numbers provide the highest levels of unpredictability. However, known systematic biases that can emerge from physical imperfections, environmental variations, and device aging in the processes exploited for random number generation must be carefully monitored. This article reports the implementation and characterization of an online procedure for the detection of anomalies in a true random bit stream. It is based on the NIST adaptive proportion and repetition count tests, complemented by statistical analysis relying on the Monobit and RUNS tests. The procedure is implemented in firmware through dedicated hardware accelerators processing configurable-length sequences, with automated anomaly detection triggering alerts after three consecutive threshold violations. The implementation is performed simultaneously with bit stream generation and also provides an estimate of the entropy of the source. A statistical analysis of the results from the NIST procedure to evaluate the symbols of the bit-stream as independently and identically distributed is also performed, leading to a computation of the minimum entropy of the source that cross-checks the previously mentioned estimate. The experimental validation of the approach is performed up the bit streams generated by a quantum, silicon-based entropy source.},
  archive      = {J_FCOMP},
  author       = {Caratozzolo, Cesare and Rossi, Valeria and Witek, Kamil and Trombetta, Alberto and Baszczyk, Mateusz and Dorosz, Piotr and Kucewicz, Wojciech and Caccia, Massimo},
  doi          = {10.3389/fcomp.2025.1642566},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {1642566},
  shortjournal = {Front. Comput. Sci.},
  title        = {Entropy measurement and online quality control of bit streams by a true random bit generator},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discomfort detection during automated driving using temporal transformers. <em>FCOMP</em>, <em>7</em>, 1639505. (<a href='https://doi.org/10.3389/fcomp.2025.1639505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionWith the recent breakthroughs in driving automation and the development of smart vehicles, human-technology interaction issues, such as detecting comfort levels in automated driving, have been gaining increasing attention. Given the evidence of discomfort levels being an evolving psychological state in time, the tracking of discomfort levels for passengers of an automated vehicle can be considered a time-varying phenomenon.MethodsWe assessed a passenger's discomfort level in a smart, automated vehicle using physiological, environmental, and vehicle automation features from different sensors. Our approach is to dynamically predict discomfort levels using time-dependent models, particularly the Temporal Fusion Transformer (TFT), an advanced attention-based deep learning architecture providing an interpretable explanation of temporal dynamics as well as high-performance forecasting over multiple horizons. The models are trained and evaluated using a dataset of 100 participants of a simulated automated driving experiment, during which they signaled their level of discomfort using a manual device. Two TFT models, TFT-full and TFT-restricted, are investigated depending on which physiological, environmental, and vehicle automation signals are used as inputs. The results are compared with the auto-regressive model DeepAR. Different window sizes are used to analyze the impact of the window size on the model's performance.ResultsAmong the tested models, TFT-restricted with a window size of 300-time steps (about 5 s) demonstrates the best performance in predicting discomfort levels on our data, with a mean absolute error (MAE) of 0.037 and a root mean square error (RMSE) of 0.131.DiscussionIn our study, TFT-restricted outperformed TFT-full and the autoregressive model DeepAR in discomfort prediction, delivering superior results for all metrics. Finally, our study shows that the TFT can capture temporal dependencies in the data and help us interpret the model for detecting discomfort, which is essential for analyzing and improving people's acceptance of automated vehicles.},
  archive      = {J_FCOMP},
  author       = {Assarzadeh, Maha and Hartwich, Franziska and Vitay, Julien and Bocklisch, Franziska and Hamker, Fred H.},
  doi          = {10.3389/fcomp.2025.1639505},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {1639505},
  shortjournal = {Front. Comput. Sci.},
  title        = {Discomfort detection during automated driving using temporal transformers},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding the role of instructor gestures during virtual lectures. <em>FCOMP</em>, <em>7</em>, 1615791. (<a href='https://doi.org/10.3389/fcomp.2025.1615791'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this study was to establish the importance of instructor gestures in online lectures. Social information processing theory explains that virtual communication can be just as effective as face-to-face communication if communicators understand how to adapt their communication to the virtual channel. This study seeks to better understand the roles of camera distance and gestures in adapting lectures to virtual classrooms. An experiment examined the impact of student gender, camera distance from the instructor, and gesture use on instructor credibility, as measured by caring, competence, and trustworthiness. The results indicate that while camera distance did not impact students’ perceptions of instructor competence, the absence of gestures did impact how trustworthy and caring male students perceived the instructor to be. In the absence of gestures, male students perceived the instructor to be less caring and trustworthy. This indicates that instructors should make efforts to speak with gestures in virtual lectures, especially for male students, just as they do in the traditional classroom.},
  archive      = {J_FCOMP},
  author       = {Kelly, Stephanie and Kim, Jihyun and Chaudhary, Pankaj},
  doi          = {10.3389/fcomp.2025.1615791},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {1615791},
  shortjournal = {Front. Comput. Sci.},
  title        = {Understanding the role of instructor gestures during virtual lectures},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving remote sensing scene classification with data augmentation techniques to mitigate class imbalance. <em>FCOMP</em>, <em>7</em>, 1613648. (<a href='https://doi.org/10.3389/fcomp.2025.1613648'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-resolution remote sensing imagery is a powerful tool that provides massive information about ground objects. However, conventional methods often fail to achieve satisfactory results for complex urban scene classification. This is attributed to the fact that conventional methods are unable to meet the requirements of high-accuracy remote sensing image scene classification (RSSC) and are hindered by challenges such as limited labeled samples and class imbalance, which may lead to classification bias in classifiers. On the contrary, deep learning-based RSSC represents an important approach for understanding semantic information. This paper explores the feasibility of mitigating classification bias by reducing the imbalance ratio (IR) of the dataset. First, a class-imbalanced dataset was constructed using very high-resolution (VHR) images, labeled into nine land use/land cover (LULC) categories. Second, comprehensive data augmentation techniques (mirroring, rotation, cropping, Hue, Saturation, Value (HSV) perturbation, and gamma transformation) were applied, successfully reducing the dataset's IR from 9.38 to 1.28. Subsequently, four architectures, MobileNet-v2, ResNet101, ResNeXt101_32 × 32d, and Transformer, were trained and evaluated on both class-balanced and class-imbalanced datasets. The results indicate that the classification bias caused by class imbalance was alleviated, significantly improving the classifier's performance. Specifically for the most severely underrepresented category (intersections), precision and recall improvements reached up to 128% and 102%, respectively, narrowing the gap with other categories and reducing classification bias. Furthermore, the average Kappa and overall accuracy (OA) increased by 11.84% and 12.97%, respectively, with reduced standard deviations in recall and precision, demonstrating enhanced model stability.},
  archive      = {J_FCOMP},
  author       = {Wang, Ping and Zhao, Xin and Chen, Yuanhui and Zhan, Lili},
  doi          = {10.3389/fcomp.2025.1613648},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {1613648},
  shortjournal = {Front. Comput. Sci.},
  title        = {Improving remote sensing scene classification with data augmentation techniques to mitigate class imbalance},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Component features based enhanced phishing website detection system using EfficientNet, FH-BERT, and SELU-CRNN methods. <em>FCOMP</em>, <em>7</em>, 1582206. (<a href='https://doi.org/10.3389/fcomp.2025.1582206'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionPhishing is a type of cybercrime used by hackers to steal sensitive user information, making it essential to detect phishing attacks on websites. Many prevailing works have utilized Uniform Resource Locator (URL) links and Document Object Model (DOM) tree structures for Phishing Website Detection (PWD). However, since phishing websites imitate legitimate websites, these approaches often produce inaccurate detection results.MethodsTo enhance detection efficiency, we propose a PWD system that focuses on important website features and components. The process begins with collecting URL links from phishing website datasets, followed by the generation of Hypertext Markup Language (HTML) formats. A DOM tree structure is then constructed from the HTML, and components are extracted along with Natural Language Processing (NLP) features, credentials, URL, DOM tree similarity, and component features. The DOM-tree components are converted into score values using Feature Hasher-Bidirectional Encoder Representations from Transformers (FH-BERT). These score values are fused with component features, and significant features are selected using an Entropy-based Chameleon Swarm Algorithm (ECSA).ResultsThe final classification is performed by Scaled Exponential Linear Unit Convolutional Recurrent Neural Network (SELU-CRNN). Simulation results demonstrate that the proposed technique improves PWD performance, achieving higher accuracy (98.42%) and reduced training time (63,003 ms) compared to prevailing methods.DiscussionBy integrating component, semantic, and structural features, the proposed model enhances both robustness and efficiency, making it an effective solution for phishing website detection.},
  archive      = {J_FCOMP},
  author       = {Murhej, Mahmoud and Nallasivan, G.},
  doi          = {10.3389/fcomp.2025.1582206},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {1582206},
  shortjournal = {Front. Comput. Sci.},
  title        = {Component features based enhanced phishing website detection system using EfficientNet, FH-BERT, and SELU-CRNN methods},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling the dynamics of misinformation spread: A multi-scenario analysis incorporating user awareness and generative AI impact. <em>FCOMP</em>, <em>7</em>, 1570085. (<a href='https://doi.org/10.3389/fcomp.2025.1570085'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of misinformation on social media threatens public trust, public health, and democratic processes. We propose three models that analyze fake news propagation and evaluate intervention strategies. Grounded in epidemiological dynamics, the models include: (1) a baseline Awareness Spread Model (ASM), (2) an Extended Model with fact-checking (EM), and (3) a Generative AI-Influenced Spread model (GIFS). Each incorporates user behavior, platform-specific dynamics, and cognitive biases such as confirmation bias and emotional contagion. We simulate six distinct scenarios: (1) Accurate Content Environment, (2) Peer Network Dynamics, (3) Emotional Engagement, (4) Belief Alignment, (5) Source Trust, and (6) Platform Intervention. All models converge to a single, stable equilibrium. Sensitivity analysis across key parameters confirms model robustness and generalizability. In the ASM, forwarding rates were lowest in scenarios 1, 4, and 6 (1.47%, 3.41%, 2.95%) and significantly higher in 2, 3, and 5 (19.67%, 56.52%, 29.47%). The EM showed that fact-checking reduced spread to as low as 0.73%, with scenario-based variation from 1.16 to 17.47%. The GIFS model revealed that generative AI amplified spread by 5.7%–37.8%, depending on context. ASM highlights the importance of awareness; EM demonstrates the effectiveness of fact-checking mechanisms; GIFS underscores the amplifying impact of generative AI tools. Early intervention, coupled with targeted platform moderation (scenarios 1, 4, 6), consistently yields the lowest misinformation spread, while emotionally resonant content (scenario 3) consistently drives the highest propagation.},
  archive      = {J_FCOMP},
  author       = {Jain, Kurunandan and Achuthan, Krishnashree},
  doi          = {10.3389/fcomp.2025.1570085},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {1570085},
  shortjournal = {Front. Comput. Sci.},
  title        = {Modeling the dynamics of misinformation spread: A multi-scenario analysis incorporating user awareness and generative AI impact},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="fcteg">FCTEG - 1</h2>
<ul>
<li><details>
<summary>
(2025). Conflict-based model predictive control for multi-agent path finding experimentally validated on a magnetic planar drive system. <em>FCTEG</em>, <em>6</em>, 1645918. (<a href='https://doi.org/10.3389/fcteg.2025.1645918'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThis work presents an approach to collision avoidance in multi-agent systems (MAS) by integrating Conflict-Based Search (CBS) with Model Predictive Control (MPC), referred to as Conflict-Based Model Predictive Control (CB-MPC).MethodsThe proposed method leverages the conflict-avoidance strengths of CBS to generate collision-free paths, which are then refined into dynamic reference trajectories using a minimum jerk trajectory optimizer and then used inside a MPC to follow the trajectories and to avoid collisions. This integration ensures real-time trajectory execution, preventing collisions and adapting to online changes. The approach is evaluated using a magnetic planar drive system for realistic multi-agent scenarios, demonstrating enhanced real-time responsiveness and adaptability. The focus is on the development of a motion planning algorithm and its validation in dynamic environments, which are becoming increasingly relevant in modern adaptive production sites.ResultsOn the MAS demonstrator with four active agents, ten different scenarios were created with varying degrees of complexity in terms of route planning. In addition, external disturbances that hinder the execution of the paths were simulated. All calculation and solution times were recorded and discussed. The result show that all scenarios could be successfully solved and executed., and the CB-MPC is therefore suitable for motion planning on the presented MAS demonstrator.DiscussionThe results show, that the CB-MPC is suitable for motion planning on the presented MAS demonstrator. The greatest limitation of the approach lies in scalability with regard to increasing the number of agents.},
  archive      = {J_FCTEG},
  author       = {Janning, Kai and Housin, Abdalsalam and Schulte, Christopher and Erkens, Frederik and Frenken, Luca and Herbst, Laura and Nießing, Bastian and Schmitt, Robert H.},
  doi          = {10.3389/fcteg.2025.1645918},
  journal      = {Frontiers in Control Engineering},
  month        = {7},
  pages        = {1645918},
  shortjournal = {Front. Control Eng.},
  title        = {Conflict-based model predictive control for multi-agent path finding experimentally validated on a magnetic planar drive system},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="fdata">FDATA - 2</h2>
<ul>
<li><details>
<summary>
(2025). Editorial: Navigating the nexus of big data, AI, and public health: Transformations, triumphs, and trials in multiple sclerosis care access. <em>FDATA</em>, <em>8</em>, 1682151. (<a href='https://doi.org/10.3389/fdata.2025.1682151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {[Joshi] provides a critical examination of how big data and AI technologies can both advance and hinder gender equality in healthcare access and treatment. This perspective article addresses one of the most pressing ethical challenges in contemporary healthcare technology: bias is a big challenge when implementing AI systems in medical settings, particularly relevant for conditions like Multiple Sclerosis, where gender disparities in diagnosis and treatment access are well-documented.The contribution by [Joshi] highlights three critical categories where machine learning can facilitate accessible, affordable, personalized, and evidence-based healthcare for women, while simultaneously addressing the algorithmic bias that threatens to undermine these advances. This work exemplifies the critical need for intersectional approaches to healthcare AI development that consider both the transformative potential and the ethical implications of these technologies in specialized treatment contexts such as neurological care.[Chen et al.] contribute valuable insights into the practical challenges of leveraging social media data for public health research and healthcare accessibility analysis. Social media has profoundly changed our modes of self-expression, communication, and participation in public discourse, generating volumes of conversations and content that cover every aspect of our social lives. Their research addresses the critical gap between the theoretical potential of social media analytics and the practical hurdles researchers face in accessing and utilizing these data sources for understanding patient experiences and healthcare navigation challenges.The work by [Chen et al.] is particularly relevant for understanding patient perspectives on healthcare accessibility, treatment barriers, and health-seeking behaviors-essential components for developing comprehensive models of healthcare access, such as those needed for MS treatment planning as an example of the United Arab Emirates. Social media platforms provide unprecedented access to real-time patient sentiment, treatment experiences, and geographic variation in healthcare access that can inform policy and practice improvements.The fourth contribution explores advanced techniques in knowledge-based recommendation systems, with direct relevance to clinical decision support and personalized treatment recommendations for complex conditions like Multiple Sclerosis. This research demonstrates how sophisticated recommendation algorithms can be applied to support clinical decisionmaking in specialized care contexts, patient education about treatment options, and healthcare resource allocation-all critical components for ensuring equitable access to Disease-Modifying Therapies.The integration of knowledge-based systems with machine learning approaches represents a significant advancement in creating transparent, including clinically interpretable, explainable AI tools for specialized healthcare settings. This work addresses the crucial challenge of AI interpretability in neurological care contexts, where understanding the rationale behind treatment recommendations is essential for both clinical acceptance and patient adherence to complex therapeutic regimens.When handling private health information, strong protections are needed to prevent breaches and unauthorized use. Across all four articles, several critical themes emerge that are directly applicable to addressing geographic and socioeconomic disparities in specialized healthcare access, particularly relevant for conditions requiring ongoing Disease-Modifying Therapy.The methodological approaches demonstrated across these studies provide frameworks for mapping healthcare accessibility patterns.[Santos et al.]'s geographic analysis of educational access barriers during the pandemic offers direct parallels to understanding how distance, infrastructure, and socioeconomic factors create barriers to specialized medical care in diverse geographic regions, including accessibility heatmaps or location allocation models, which are used in health system planning to reduce spatial inequality Algorithmic Bias and Treatment Equity: [Joshi]'s examination of gender bias in healthcare AI systems highlights challenges that extend to all aspects of specialized care delivery. The research demonstrates how historical inequities in healthcare access can be embedded in algorithmic systems used for treatment allocation, facility planning, diverse training data and patient risk stratification-directly relevant to ensuring equitable DMT access across different populations.The integration of quantitative analytics with qualitative patient experience data, demonstrated by [Santos et al.] and supported by [Chen et al.]'s social media analysis framework, provides essential methodological guidance for comprehensive healthcare accessibility studies that combine geospatial analysis with patient journey mapping.The research presented in this collection moves beyond theoretical accessibility models to address practical implementation challenges in healthcare delivery. [Chen et al.]'s analysis of data collection hurdles provides essential guidance for researchers conducting patient experience studies, while [Santos et al.]'s socioeconomic analysis offers actionable insights for policymakers addressing geographic healthcare disparities.These studies demonstrate that successful implementation of equitable healthcare access requires not only advanced analytical capabilities but also careful attention to privacy protection, stakeholder engagement, and systematic approaches to addressing the social determinants that influence treatment access and adherence patterns.Policymakers can use Big Data to subsequently review the social factors, among others, behind these health disparities. The collective insights from these four articles point toward several critical areas for future research in healthcare accessibility, with direct applications to specialized treatment access challenges.The development of comprehensive accessibility indices that integrate geographic, socioeconomic, and system-level factors becomes increasingly crucial for conditions requiring complex, ongoing treatment regimens. The methodological frameworks demonstrated in this collection provide essential building blocks for creating predictive models that can identify patients at risk of treatment discontinuation and guide targeted intervention strategies.Furthermore, the research highlights the importance of real-time monitoring systems that can track accessibility patterns and identify emerging barriers to care. The integration of social media analytics, demonstrated by [Chen et al.], with geospatial analysis approaches offers promising directions for developing systems that monitor healthcare accessibility in real time.},
  archive      = {J_FDATA},
  author       = {Moonesar, Immanuel Azaad and Kumar, M. V. Manoj and Alsayegh, Khulood and Abu-Agla, Ayat and Thomas, Likewin},
  doi          = {10.3389/fdata.2025.1682151},
  journal      = {Frontiers in Big Data},
  month        = {10},
  pages        = {1682151},
  shortjournal = {Front. Big Data},
  title        = {Editorial: Navigating the nexus of big data, AI, and public health: Transformations, triumphs, and trials in multiple sclerosis care access},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting deep vein thrombosis using machine learning and blood routine analysis. <em>FDATA</em>, <em>8</em>, 1605258. (<a href='https://doi.org/10.3389/fdata.2025.1605258'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ObjectiveLower limb deep vein thrombosis (DVT) is a serious health problem, causing local discomfort and hindering walking. It can lead to severe complications, including pulmonary embolism, chronic post-thrombotic syndrome, and limb amputation, posing risks of death or severe disability. This study aims to develop a diagnostic model for DVT using routine blood analysis and evaluate its effectiveness in early diagnosis.MethodsThis study retrospectively analyzed patient medical records from January 2022 to June 2023, including 658 DVT patients (case group) and 1,418 healthy subjects (control group). SHAP (SHapley Additive exPlanations) analysis was employed for feature selection to identify key blood indices significantly impacting DVT risk prediction. Based on the selected features, six machine learning models were constructed: k-Nearest Neighbors (kNN), Logistic Regression (LR), Decision Tree (DT), Random Forest (RF), Support Vector Machine (SVM), and Artificial Neural Network (ANN). Model performance was assessed using the area under the curve (AUC).ResultsSHAP analysis identified ten key blood routine indices. The six models constructed using these indices demonstrated strong predictive performance, with AUC values exceeding 0.8, accuracy above 70%, and sensitivity and specificity over 70%. Notably, the RF model exhibited superior performance in assessing the risk of DVT.ConclusionsOur study successfully developed machine learning models for predicting DVT risk using routine blood tests. These models achieved high predictive performance, suggesting their potential for early DVT diagnosis without additional medical burden on patients. Future research will focus on further validation and refinement of these models to enhance their clinical applicability.},
  archive      = {J_FDATA},
  author       = {Su, Jie and Tang, Yuechao and Wang, Yanan and Chen, Chao and Song, Biao},
  doi          = {10.3389/fdata.2025.1605258},
  journal      = {Frontiers in Big Data},
  month        = {10},
  pages        = {1605258},
  shortjournal = {Front. Big Data},
  title        = {Predicting deep vein thrombosis using machine learning and blood routine analysis},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="frai">FRAI - 20</h2>
<ul>
<li><details>
<summary>
(2025). Editorial: Methodology for emotion-aware education based on artificial intelligence. <em>FRAI</em>, <em>8</em>, 1704389. (<a href='https://doi.org/10.3389/frai.2025.1704389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, advances in Artificial Intelligence (AI) have opened up unprecedented horizons in educational research. The ability to recognize, interpret and respond to students' emotions presents education with a crucial challenge: to design methodologies that integrate the affective dimension as a fundamental part of the learning process. With this objective in mind, the research topic "Methodology for Emotion-Aware Education Based on Artificial Intelligence" was born. Its purpose was to bring together work that explores theoretical approaches, technological applications and empirical evidence on Educational AI linked to emotions, bridging affective computing, pedagogy, and human–computer interaction to foster more responsive and ethical emotion-aware learning environments. This research topic offers a pluralistic overview, both in terms of methods and contexts, which allows for reflection on the advances and challenges that arise when introducing AI systems capable of detecting and responding to emotional states in the educational field. The contributions range from the analysis of the social impact of scientific production to the application of deep learning models, the integration of pedagogical beliefs in the adoption of generative technologies, and the design of innovative sentiment analysis models. They also highlight ethical, methodological, and practical challenges in the field. In particular, Ni and Ni (2024) presents ECO-SAM, an innovative sentiment analysis model that combines self-attention techniques with pre-trained neural networks to improve emotion classification in texts with notable increases in accuracy. Its educational relevance lies in the potential of text analysis systems to interpret interactions on learning platforms, forums, and student social networks. The study also opens possibilities for transferring these techniques to the analysis of written work in school environments, enriching formative assessment and identifying emotional patterns in students' academic and personal writing. From another perspective, Govea et al. (2024) apply deep reinforcement learning models in hybrid learning environments, developing a system capable of detecting emotions in real time by integrating convolutional and recurrent networks. Using data from 500 students collected through cameras, microphones and biometric sensors, the authors show significant improvements in emotional detection accuracy and learning personalization. This work invites us to rethink hybrid environments as spaces where AI supports cognition and, at the same time, responds to the emotional dimension. However, it also highlights the urgent need to establish regulatory and pedagogical frameworks, so that the pursuit of efficiency does not compromise the privacy and emotional well-being of students. Cabero-Almenara et al. (2024) focuses on a decisive aspect: teacher acceptance of AI in higher education. The study, involving 425 university professors, uses the UTAUT2 model to analyze how pedagogical beliefs shape willingness to integrate generative AI tools. The results show that teachers with a constructivist orientation are more willing to incorporate these technologies than those with transmissive approaches. This emphasizes that the adoption of AI does not depend solely on technical availability, but also on the pedagogical concepts that guide teaching practice. This conclusion highlights the need for professional training programs that address the diversity of beliefs and contexts. In this sense, we see that the future of AI in education will not be played out solely in laboratories, but also in the ability of institutions to support their teachers in processes of pedagogical reflection and continuous professional development. Zhou et al. (2024) provide a novel approach by applying Item Response Theory (IRT) from a student state-aware perspective. Their SAD-IRT model incorporates parameters derived from facial expression analysis using advanced deep learning techniques, which allows for the estimation of item ability and difficulty, as well as an additional parameter linked to the cognitive-affective state of the students. The study demonstrates that this approach improves predictive capacity compared to traditional IRT models and even allows responses to be anticipated before they occur. Beyond its technical value, the article proposes a paradigm shift in educational assessment: considering students' emotions and states as part of the measurement, moving towards more personalized, sensitive and useful assessment systems to guide teaching and learning. Finally, Roda-Segarra et al. (2024) offers a pioneering study that goes beyond traditional bibliometric indicators, by examining more than 6,000 social impact records across 243 publications. They reveal that research on AI and emotions in education has a considerable impact on social media and scientific repositories, although academic impact and social visibility do not always align. This finding prompts reflection on how research reaches communities, and how social networks shape knowledge circulation. In addition, the study opens the door to reflection on the role of scientific communication in building trust around the use of AI in education, an essential aspect for building a balanced dialogue between innovation, society and schools. As we can see, the articles gathered in this research topic show that AI-mediated emotion-aware education is not a distant goal, but a field in full swing. From a social perspective, research still faces the challenge of extending its impact beyond the academic sphere and ensuring a true transfer to educational communities. From a pedagogical perspective, it is clear that teachers' beliefs influence the adoption of AI, which requires the design of training processes that are sensitive to this diversity. Finally, from a technological perspective, advanced models of deep learning and sentiment analysis open up unprecedented possibilities for creating adaptive environments capable of addressing both student performance and emotional well-being. The research published in this research topic shows that the combination of pedagogy, AI and emotion-awareness can transform the way we conceive of teaching and learning in the 21st century. The path ahead is not without ethical and practical challenges. Issues such as privacy, transparency, and fairness in personalization processes must be non-negotiable principles when using AI in an educational context. The results presented here show that this is possible, but at the same time, they reveal that there is still a long way to go in terms of academic research.},
  archive      = {J_FRAI},
  author       = {Roig-Vila, Rosabel and Cazorla, Miguel and Lallé, Sébastien},
  doi          = {10.3389/frai.2025.1704389},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1704389},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Methodology for emotion-aware education based on artificial intelligence},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Medicine for artificial intelligence: Applying a medical framework to AI anomalies. <em>FRAI</em>, <em>8</em>, 1698717. (<a href='https://doi.org/10.3389/frai.2025.1698717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose Medicine for Artificial Intelligence (MAI), a clinical framework that reconceptualizes AI anomalies as diseases requiring systematic screening, differential diagnosis, treatment, and follow-up. Contemporary discourse on failures (e.g., “hallucination”) is ad hoc and fragmented across domains, impeding cumulative knowledge and reproducible management. MAI adapts medical nosology to AI by formalizing core constructs—disease, symptom, diagnosis, treatment, and classification—and mapping a clinical workflow (examination → diagnosis → intervention) onto the AI lifecycle. As a proof-of-concept, we developed DSA-1, a prototype taxonomy of 45 disorders across nine functional chapters. This approach clarifies ambiguous failure modes (e.g., distinguishing hallucination subtypes), links diagnoses to actionable interventions and evaluation metrics, and supports lifecycle practices, including triage and “AI health checks.” MAI further maps epidemiology, severity, and detectability to risk-assessment constructs, complementing top-down governance with bottom-up technical resolution. By aligning clinical methodology with AI engineering and coordinating researchers, clinicians, and regulators, MAI offers a reproducible foundation for safer, more resilient, and auditable AI systems.},
  archive      = {J_FRAI},
  author       = {Kato, Takahiro and Komura, Daisuke and Panda, Binay and Ishikawa, Shumpei},
  doi          = {10.3389/frai.2025.1698717},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1698717},
  shortjournal = {Front. Artif. Intell.},
  title        = {Medicine for artificial intelligence: Applying a medical framework to AI anomalies},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pipeline monitoring data recovery using novel deep learning models: An engineering case study. <em>FRAI</em>, <em>8</em>, 1684018. (<a href='https://doi.org/10.3389/frai.2025.1684018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pipeline monitoring frequently encounters missing data, leading to incomplete evaluation and hindering a comprehensive assessment of the pipeline’s structural health. To address this issue, this study proposes a novel PDO-BiGRU-GAN model for missing data recovery. The model integrates three components: the prairie dog optimization algorithm (PDO) for hyperparameter tuning, the bidirectional gated recurrent unit (BiGRU) for effective temporal feature extraction, and the generative adversarial network (GAN) for data generation and completion. A comprehensive monitoring database was established using field data from an open-source pipeline project. The contributions of individual modules to the overall performance were evaluated via hyperparameter sensitivity analysis and ablation studies. The impact of missing data ratio and the number of missing sensors on the model’s recovery performance was analyzed. In addition, the proposed model was compared with eight existing mainstream deep learning models. The results show that each component of the PDO-BiGRU-GAN significantly enhances overall performance. The model achieves strong recovery accuracy across various missing data scenarios, with the R2 consistently exceeding 0.93. Moreover, the model performs optimally when the missing data ratio is below 20/24. Compared to other models, PDO-BiGRU-GAN achieves the highest R2 and the lowest error metrics (MSE, RMSE, MAPE, MAE). In terms of computational efficiency, the model requires slightly more processing time than simpler models but is faster than more complex models. Overall, the proposed model provides a robust and scalable solution for pipeline monitoring data recovery, advancing intelligent pipeline health assessment and supporting the development of infrastructure safety management and smart monitoring technologies.},
  archive      = {J_FRAI},
  author       = {Zhao, Yong and Zhang, Xinpeng and Liu, Yanli and Mao, Xuecheng and Chen, Xi and Maimaitituerxun, Yasheng and He, Weidong},
  doi          = {10.3389/frai.2025.1684018},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1684018},
  shortjournal = {Front. Artif. Intell.},
  title        = {Pipeline monitoring data recovery using novel deep learning models: An engineering case study},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Phase-specific kidney graft failure prediction with machine learning model. <em>FRAI</em>, <em>8</em>, 1682639. (<a href='https://doi.org/10.3389/frai.2025.1682639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundAccurate prediction of kidney graft failure at different phases post-transplantation is critical for timely intervention and long-term allograft preservation. Traditional survival models offer limited capacity for dynamic, time-specific risk estimation. Machine learning (ML) approaches, with their ability to model complex patterns, present a promising alternative.MethodsThis study developed and dynamically evaluated phase-specific ML models to predict kidney graft failure across five post-transplant intervals: 0–3 months, 3–9 months, 9–15 months, 15–39 months, and 39–72 months. Clinically relevant retrospective data from deceased donor kidney transplant recipients were used for training and internal validation, with performance further confirmed on a blinded external validation cohort. Predictive performance was assessed using ROC AUC, F1 score, and G-mean.ResultsThe ML models demonstrated varying performance across time intervals. Short-term predictions in the 0–3 month and 3–9 month intervals yielded moderate accuracy (ROC AUC = 0.73 ± 0.07 and 0.72 ± 0.04, respectively). The highest predictive accuracy observed in mid-term or the 9–15-month window (ROC AUC = 0.92 ± 0.02; F1 score = 0.85 ± 0.03), followed by the 15–39-month period (ROC AUC = 0.84 ± 0.04; F1 score = 0.76 ± 0.04). Long-term prediction from 39 to 72 months was more challenging (ROC AUC = 0.70 ± 0.07; F1 score = 0.65 ± 0.06).ConclusionPhase-specific ML models offer robust predictive performance for kidney graft failure, particularly in mid-term periods, supporting their integration into dynamic post-transplant surveillance strategies. These models can aid clinicians in identifying high-risk patients and tailoring follow-up protocols to optimize long-term transplant outcomes.},
  archive      = {J_FRAI},
  author       = {Salybekov, Amankeldi A. and Wolfien, Markus and Yerkos, Ainur and Buribayev, Zholdas and Hidaka, Sumi and Kobayashi, Shuzo},
  doi          = {10.3389/frai.2025.1682639},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1682639},
  shortjournal = {Front. Artif. Intell.},
  title        = {Phase-specific kidney graft failure prediction with machine learning model},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A human-centered automated machine learning agent with large language models for multimodal data management and analysis. <em>FRAI</em>, <em>8</em>, 1680845. (<a href='https://doi.org/10.3389/frai.2025.1680845'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated Machine Learning (AutoML) aims to streamline the end-to-end process of ML models, yet current approaches remain constrained by rigid rule-based frameworks and structured input requirements that create barriers for non-expert users. Despite advances in Large Language Models (LLMs) demonstrating capabilities in code generation and natural language understanding, their potential to improve AutoML accessibility has not been fully realized. We present an innovative LLM-driven AI agent that enables natural language interaction throughout the entire ML workflow while maintaining high performance standards, reducing the need for predefined rules and minimizing technical expertise requirements. The proposed agent implements an end-to-end ML pipeline, incorporating automatic data loading and pre-processing, task identification, neural architecture selection, hyperparameter optimization, and training automation. Additionally, we propose a novel data processing approach that leverages LLMs to automatically interpret and handle diverse data formats without requiring manual pre-processing or format conversion. Moreover, we propose an adaptive hyperparameter optimization strategy that combines LLMs' knowledge of ML best practices with dynamic performance feedback to intelligently adjust search spaces. Extensive evaluation on 10 diverse datasets spanning classification and regression tasks across multiple data modalities demonstrates that our approach consistently achieves superior performance compared to traditional rule-based AutoML frameworks. By bridging the gap between human intent and ML implementation, our approach contributes to the development of a more accessible AutoML framework.},
  archive      = {J_FRAI},
  author       = {Huang, Rong and Tao, Su},
  doi          = {10.3389/frai.2025.1680845},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1680845},
  shortjournal = {Front. Artif. Intell.},
  title        = {A human-centered automated machine learning agent with large language models for multimodal data management and analysis},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When AI speaks like a specialist: ChatGPT-4 in the management of inflammatory bowel disease. <em>FRAI</em>, <em>8</em>, 1678320. (<a href='https://doi.org/10.3389/frai.2025.1678320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundArtificial intelligence (AI) is gaining traction in healthcare, especially for patients’ education. Inflammatory bowel diseases (IBD) require continuous engagement, yet the quality of online information accessed by patients is inconsistent. ChatGPT, a generative AI model, has shown promise in medical scenarios, but its role in IBD communication needs further evaluation. The objective of this study was to assess the quality of ChatGPT-4’s responses to common patient questions about IBD, compared to those provided by experienced IBD specialists.MethodsTwenty-five frequently asked questions were collected during routine IBD outpatient visits and categorized into five themes: pregnancy/breastfeeding, diet, vaccinations, lifestyle, and medical therapy/surgery. Each question was answered by ChatGPT-4 and by two expert gastroenterologists. Responses were anonymized and evaluated by 12 physicians (six IBD experts and six non-experts) using a 5-point Likert scale across four dimensions: accuracy, reliability, comprehensibility, and actionability. Evaluators also attempted to identify whether responses were AI- or human-generated.ResultsChatGPT-4 responses received significantly higher overall scores than those from human experts (mean 4.28 vs. 4.05; p < 0.001). The best-rated scenarios were medical therapy and surgery; the diet scenario consistently received lower scores. Only 33% of AI-generated responses were correctly identified as such, indicating strong similarity to human-written answers. Both expert and non-expert evaluators rated AI responses highly, though IBD specialists gave higher ratings overall.ConclusionChatGPT-4 generated high-quality, clear, and actionable responses to IBD-related patient questions, often outperforming human experts. Its outputs were frequently indistinguishable from those written by physicians, suggesting potential as a supportive tool for patient education. Nonetheless, further studies are needed to assess real-world application and ensure appropriate use in personalized clinical care.},
  archive      = {J_FRAI},
  author       = {De Cristofaro, Elena and Zorzi, Francesca and Abreu, Maria and Colella, Alice and Blanco, Giovanna Del Vecchio and Fiorino, Gionata and Lolli, Elisabetta and Noor, Nurulamin and Lopetuso, Loris Riccardo and Pioche, Mathieu and Grimaldi, Jean and Paoluzi, Omero Alessandro and Roseira, Joana and Sena, Giorgia and Troncone, Edoardo and Calabrese, Emma and Monteleone, Giovanni and Marafini, Irene},
  doi          = {10.3389/frai.2025.1678320},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1678320},
  shortjournal = {Front. Artif. Intell.},
  title        = {When AI speaks like a specialist: ChatGPT-4 in the management of inflammatory bowel disease},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing surface defect detection with YOLOv9: The role of advanced backbone models. <em>FRAI</em>, <em>8</em>, 1675154. (<a href='https://doi.org/10.3389/frai.2025.1675154'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionYOLO algorithmic models are widely utilized for detecting surface defects, offering a robust and efficient approach to identifying various flaws and imperfections on material surfaces.MethodsIn this study, we explore the integration of six distinct backbone networks within the YOLOv9 framework to optimize surface defect detection in steel strips. Specifically, we improve the YOLOv9 framework by integrating six representative backbones-ResNet50, GhostNet, MobileNetV4, FasterNet, StarNet, and RepViT-and conduct a systematic evaluation on the NEU-DET dataset and the GC10-DET dataset. Using YOLOv9-C as the baseline, we compare these backbones in terms of detection accuracy, computational complexity, and model efficiency.ResultsResults show that RepViT achieves the best overall performance with an mAP50 of 68.8%, F1-score of 0.65, and a balanced precision-recall profile, while GhostNet offers superior computational efficiency with only 41.2 M parameters and 190.2 GFLOPs. Further validation on YOLOv5-m confirms the consistency of the results.DiscussionThe study offers practical guidance for backbone selection in surface defect detection tasks, highlighting the advantages of lightweight architectures for real-time industrial applications.},
  archive      = {J_FRAI},
  author       = {Zeng, Zhonglin and Wang, Hongyang and Yao, Chi and Dong, Zile and Cai, Shimin},
  doi          = {10.3389/frai.2025.1675154},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1675154},
  shortjournal = {Front. Artif. Intell.},
  title        = {Optimizing surface defect detection with YOLOv9: The role of advanced backbone models},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). There are significant differences among artificial intelligence large language models when answering scientific questions. <em>FRAI</em>, <em>8</em>, 1664303. (<a href='https://doi.org/10.3389/frai.2025.1664303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThis study investigates the efficacy of large language models (LLMs) for generating accurate scientific responses through a comparative evaluation of five prominent free models: Claude 3.5 Sonnet, Gemini, ChatGPT 4o, Mistral Large 2, and Llama 3.1 70B.MethodsSixteen expert scientific reviewers assessed these models in terms of depth, accuracy, relevance, and clarity.ResultsClaude 3.5 Sonnet emerged as the highest scoring model, followed by Gemini, with notable variability among the other models. Additionally, retrieval-augmented generation (RAG) techniques were applied to improve LLM performance, and prompts were refined to improve answers. The results indicate that although LLMs such as Claude 3.5 Sonnet have potential for scientific tasks, other models may require more development or additional prompt engineering to reach comparable accuracy. Reviewers’ perceptions of artificial intelligence (AI) utility and trustworthiness showed a positive shift after evaluation. However, ethical concerns, particularly with respect to transparency and disclosure, remained consistent.DiscussionThe study highlights the need for structured frameworks for evaluating LLMs and ethical considerations essential for responsible AI integration in scientific research. These findings should be interpreted with caution, as the limited sample size and domain-specific focus of the exam questions restrict the generalizability of the results.},
  archive      = {J_FRAI},
  author       = {Álvarez-Martínez, Francisco Javier and Esteban, Luis and Frungillo, Lucas and Butassi, Estefanía and Zambon, Alessandro and Herranz-López, María and Aranda, Mario and Pollastro, Federica and Tixier, Anne Sylvie and Garcia-Perez, Jose V. and Arráez-Román, David and Ross, Andrew and Mena, Pedro and Edrada-Ebel, Ru Angelie and Lyng, James and Micol, Vicente and Borrás-Rocher, Fernando and Barrajón-Catalán, Enrique},
  doi          = {10.3389/frai.2025.1664303},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1664303},
  shortjournal = {Front. Artif. Intell.},
  title        = {There are significant differences among artificial intelligence large language models when answering scientific questions},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A chinese question and answer system for liver cancer based on knowledge graph and large language mode. <em>FRAI</em>, <em>8</em>, 1663891. (<a href='https://doi.org/10.3389/frai.2025.1663891'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe liver cancer question-and-answer (Q&A) system is primarily intended to help patients access disease-related information more conveniently. However, there is currently no Q&A system specifically developed for liver cancer. Additionally, most existing Q&A systems lack real clinical data and have limited capability in understanding Chinese questions.MethodsThis paper proposes a Chinese liver cancer question-answering system based on knowledge graphs and Large Language Models (LLMs). To unify information from diverse sources, the system employs a knowledge graph to store entities and inter-entity relationships extracted from patients' clinical electronic medical records and the professional medical website xywy.com, which serves as the foundation for the system's responses. Specifically, ChatGLM3.5 is utilized to extract entity information from questions, while BERT is applied to understand users' intent. Subsequently, the system retrieves corresponding information from the knowledge graph. Finally, the retrieved information is integrated, and a natural language response is generated as the answer to the question.ResultsThe experimental results indicate that in terms of intent classification, our system achieves a precision of 92.34%, representing an improvement of 1.38% over the BERT model and 4.32% over the GEBERT model. In terms of response relevance, the system's outputs are more aligned with patients' daily speech patterns and exhibit higher relevance to the target questions.DiscussionIn conclusion, the improved method significantly enhances the usefulness and reliability of the liver cancer Q&A system.},
  archive      = {J_FRAI},
  author       = {Wu, Haoqi and Zhang, Min and Wang, Hailing and Jiang, Xiaoyan and Gao, Yongbin and Huang, Rong and Fang, Zhijun and Hu, Xiaojun and Fan, Yingfang},
  doi          = {10.3389/frai.2025.1663891},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1663891},
  shortjournal = {Front. Artif. Intell.},
  title        = {A chinese question and answer system for liver cancer based on knowledge graph and large language mode},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Search-optimized quantization in biomedical ontology alignment. <em>FRAI</em>, <em>8</em>, 1662984. (<a href='https://doi.org/10.3389/frai.2025.1662984'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the fast-moving world of AI, as organizations and researchers develop more advanced models, they face challenges due to their sheer size and computational demands. Deploying such models on edge devices or in resource-constrained environments adds further challenges related to energy consumption, memory usage and latency. To address these challenges, emerging trends are shaping the future of efficient model optimization techniques. From this premise, by employing supervised state-of-the-art transformer-based models, this research introduces a systematic method for ontology alignment, grounded in cosine-based semantic similarity between a biomedical layman vocabulary and the Unified Medical Language System (UMLS) Metathesaurus. It leverages Microsoft Olive to search for target optimizations among different Execution Providers (EPs) using the ONNX Runtime backend, followed by an assembled process of dynamic quantization employing Intel Neural Compressor and IPEX (Intel Extension for PyTorch). Through our optimization process, we conduct extensive assessments on the two tasks from the DEFT 2020 Evaluation Campaign, achieving a new state-of-the-art in both. We retain performance metrics intact, while attaining an average inference speed-up of 20x and reducing memory usage by 70%.},
  archive      = {J_FRAI},
  author       = {Bouaggad, Oussama and Grabar, Natalia},
  doi          = {10.3389/frai.2025.1662984},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1662984},
  shortjournal = {Front. Artif. Intell.},
  title        = {Search-optimized quantization in biomedical ontology alignment},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated learning for cognitive impairment detection using speech data. <em>FRAI</em>, <em>8</em>, 1662859. (<a href='https://doi.org/10.3389/frai.2025.1662859'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionIn Alzheimer’s disease (AD) research, clinical, neuroimaging, genetic, and biomarker data are vital for advancing its understanding and treatment. However, privacy concerns and limited datasets complicate data sharing. Federated learning (FL) offers a solution by enabling collaborative research while preserving data privacy.MethodsThis study analyzed data from patients assessed at the Memory Unit of the Ace Alzheimer Center Barcelona who completed a standardized digital speech protocol. Acoustic features extracted from these recordings were used to distinguish between cognitively unimpaired (CU) and cognitively impaired (CI) individuals. The aim was to evaluate how data heterogeneity impacted the FL model performance across three scenarios: (1) equal contributions and class ratios, (2) unequal contributions, and (3) imbalanced class ratios. In each scenario, the performance of local models trained using an MLP feed-forward neural network on institutional data was analyzed and compared to a global model created by aggregating these local models using Federated Averaging (FedAvg) and Iterative Data Aggregation (IDA).ResultsThe cohort included 2,239 participants: 221 CU individuals (mean age 66.8, 64.7% female) and 2,018 CI subjects, comprising 1,219 with mild cognitive impairment (mean age 74.3, 61.9% female) and 799 with mild AD dementia (mean age 80.8, 64.8% female). In scenarios 1 and 3, FL provided modest gains in accuracy and AUC. In scenario 2, FL markedly improved performance for the smaller dataset (balanced accuracy rising from 0.51 to 0.80) while preserving 0.86 accuracy in the larger dataset, highlighting scalability across heterogeneous conditions.ConclusionThese findings demonstrate the potential of FL to enable collaborative modeling of speech-based biomarkers for cognitive impairment detection, even under conditions of data imbalance and institutional disparity. This work highlights FL as a scalable and privacy-preserving approach for advancing digital health research in neurodegenerative diseases.},
  archive      = {J_FRAI},
  author       = {Blazquez-Folch, Josep and Limones Andrade, María and Calm, Berta and Auñón García, Juan Miguel and Alegret, Montserrat and Muñoz, Nathalia and Cano, Amanda and Fernández, Victoria and García-Gutiérrez, Fernando and De Rojas, Itziar and García-González, Pablo and Olivé, Clàudia and Puerta, Raquel and Capdevila-Bayo, María and Muñoz-Morales, Álvaro and Bayón-Buján, Paula and Miguel, Andrea and Montrreal, Laura and Espinosa, Ana and Sanz-Cartagena, Pilar and Rosende-Roca, Maitee and Zaldua, Carla and Gabirondo, Peru and Cantero-Fortiz, Yahveth and Gurruchaga, Miren Jone and Tarraga, Lluis and Boada, Mercè and Ruiz, Agustín and Marquié, Marta and Valero, Sergi},
  doi          = {10.3389/frai.2025.1662859},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1662859},
  shortjournal = {Front. Artif. Intell.},
  title        = {Federated learning for cognitive impairment detection using speech data},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable person–job recommendations: Challenges, approaches, and comparative analysis. <em>FRAI</em>, <em>8</em>, 1660548. (<a href='https://doi.org/10.3389/frai.2025.1660548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAs person–job recommendation systems (PJRS) increasingly mediate hiring decisions, concerns over their “black box” opacity have sparked demand for explainable AI (XAI) solutions.MethodsThis systematic review examines 85 studies on explainable PJRS methods published between 2019 and August 2025, selected from 150 screened articles across Google Scholar, Web of Science, and CNKI, following PRISMA 2020 guidelines.ResultsGuided by a PICOS-formulated review question, we categorize explainability techniques into three layers—data (e.g., feature attribution, causal diagrams), model (e.g., attention mechanisms, knowledge graphs), and output (e.g., SHAP, counterfactuals)—and summarize their objectives, trade-offs, and practical applications. We further synthesize these into an integrated end-to-end framework that addresses opacity across layers and supports traceable recommendations. Quantitative benchmarking of six representative methods (e.g., LIME, attention-based, KG-GNN) reveals performance–explainability trade-offs, with counterfactual approaches achieving the highest Explainability-Performance (E‑P) score (0.95).DiscussionThis review provides a taxonomy, cross-layer framework, and comparative evidence to inform the design of transparent and trustworthy PJRS systems. Future directions include multimodal causal inference, feedback-driven adaptation, and efficient explainability tools.},
  archive      = {J_FRAI},
  author       = {Tang, Fang and Zhu, Renqi and Yao, Feng and Wang, Junzhi and Luo, Lailong and Li, Bo},
  doi          = {10.3389/frai.2025.1660548},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1660548},
  shortjournal = {Front. Artif. Intell.},
  title        = {Explainable person–job recommendations: Challenges, approaches, and comparative analysis},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Big data in financial risk management: Evidence, advances, and open questions: A systematic review. <em>FRAI</em>, <em>8</em>, 1658375. (<a href='https://doi.org/10.3389/frai.2025.1658375'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe intersection of big data analytics and financial risk management has spurred significant methodological innovation and organizational change. Despite growing research activity, the literature remains fragmented, with notable gaps in comparative effectiveness, cross-sectoral applicability, and the use of non-traditional data sources.MethodsFollowing the PRISMA 2020 protocol, a systematic review was conducted on 21 peer-reviewed studies published between 2016 and June 2025. The review evaluated the methodological diversity and effectiveness of machine learning and hybrid approaches in financial risk management.ResultsThe analysis mapped the relative strengths and limitations of neural networks, ensemble learning, fuzzy logic, and hybrid optimization across credit, fraud, systemic, and operational risk. Advanced machine learning techniques consistently demonstrated strong predictive accuracy, yet real-world deployment remained geographically concentrated, primarily in Chinese and European banking and fintech sectors. Applications involving alternative and unstructured data, such as IoT signals and behavioral analytics, were largely experimental and faced both technical and governance challenges.Discussion/conclusionThe findings underscore the scarcity of systematic benchmarking across risk types and organizational contexts, as well as the limited attention to explainability in current implementations. This review identifies an urgent need for comparative, cross-jurisdictional studies, stronger field validation, and open science practices to bridge the gap between technical advances and their operational impact in big data–enabled financial risk management.},
  archive      = {J_FRAI},
  author       = {Theodorakopoulos, Leonidas and Theodoropoulou, Alexandra and Bakalis, Aristeidis},
  doi          = {10.3389/frai.2025.1658375},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1658375},
  shortjournal = {Front. Artif. Intell.},
  title        = {Big data in financial risk management: Evidence, advances, and open questions: A systematic review},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessment of demographic bias in retinal age prediction machine learning models. <em>FRAI</em>, <em>8</em>, 1653153. (<a href='https://doi.org/10.3389/frai.2025.1653153'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The retinal age gap, defined as the difference between the predicted retinal age and chronological age, is an emerging biomarker for many eye conditions and even non-ocular diseases. Machine learning (ML) models are commonly used for retinal age prediction. However, biases in ML models may lead to unfair predictions for some demographic groups, potentially exacerbating health disparities. This retrospective cross-sectional study evaluated demographic biases related to sex and ethnicity in retinal age prediction models using retinal imaging data (color fundus photography [CFP], optical coherence tomography [OCT], and combined CFP + OCT) from 9,668 healthy individuals (mean age 56.8 years; 52% female) in the UK Biobank. The RETFound foundation model was fine-tuned to predict retinal age, and bias was assessed by comparing mean absolute error (MAE) and retinal age gaps across demographic groups. The combined CFP + OCT model achieved the lowest MAE (3.01 years), outperforming CFP-only (3.40 years) and OCT-only (4.37 years) models. Significant sex differences were observed only in the CFP model (p < 0.001), while significant ethnicity differences appeared only in the OCT model (p < 0.001). No significant sex/ethnicity differences were observed in the combined model. These results demonstrate that retinal age prediction models can exhibit biases, and that these biases, along with model accuracy, are influenced by the choice of imaging modality (CFP, OCT, or combined). Identifying and addressing sources of bias is essential for safe and reliable clinical implementation. Our results emphasize the importance of comprehensive bias assessments and prospective validation, ensuring that advances in machine learning and artificial intelligence benefit all patient populations.},
  archive      = {J_FRAI},
  author       = {Nielsen, Christopher and Stanley, Emma A. M. and Wilms, Matthias and Forkert, Nils D.},
  doi          = {10.3389/frai.2025.1653153},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1653153},
  shortjournal = {Front. Artif. Intell.},
  title        = {Assessment of demographic bias in retinal age prediction machine learning models},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid recurrent with spiking neural network model for enhanced anomaly prediction in IoT networks security. <em>FRAI</em>, <em>8</em>, 1651516. (<a href='https://doi.org/10.3389/frai.2025.1651516'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAs the number of Internet of Things (IoT) devices grows quickly, cyber threats are becoming more complex and increasingly sophisticated; thus, we need a more robust network security solutions. Traditional deep learning approaches often suffer in identifying effectively anomalies in IoT network. To tackle this evolving challenge, this research proposes a hybrid architecture of Neural Network (NN) models that combine Recurrent-NN (RNN) and Spiking-NN (SNN), referred to as HRSNN, to improve IoT the security.MethodsThe proposed HRSNN technique has five steps: preprocessing data, extracting features, equalization classes, features optimization and classification. Data processing step makes sure that input data is accurate and consistent and by employing normalization and the removal of outliers’ techniques. Feature extraction makes use of the RNN part to automatically detect abnormal patterns and high-level features, which are then turned into spike trains for the SNN to process over time. In class equalization step, the Synthetic Minority-Oversampling Technique (SMOTE) is being used resulting in balanced classes. Recursive Feature Elimination (RFE) is used to keep the important features for feature optimization. Then, the dataset is split into sets for testing and training so that the model can be tested properly.ResultsThe hybrid model integrates the spatial feature learning skills of RNNs with the temporal adaptability of SNNs, results in an improved accuracy and resilience in identifying IoT network abnormalities. The proposed HRSNN approach, which was tested on the CIC-IoT23 and TON_IoT data sets, achieved better performance compared to current deep learning (DL) models. In particular, experimental assessments show that the model attained an accuracy rate of 99.5% on the “CICIoT2023” dataset and 98.75% on the “TON_IoT” dataset.DiscussionThese results confirm demonstrate that the proposed architecture of RNN and SSN can achieve significant advancement to IoT security. By combining both spatial and temporal feature learning, HRSNN can improve accuracy detection against diverse security threats. The model is reliable, accurate, and adaptable for safeguarding IoT networks against diverse security threats. Thus, the model addresses the potential solutions in the challenging problem of secured IoT networks.},
  archive      = {J_FRAI},
  author       = {Mustafa, Mohammed and Eljack Babiker, Sarah M. and Mustafa, Yasir Eltigani Ali},
  doi          = {10.3389/frai.2025.1651516},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1651516},
  shortjournal = {Front. Artif. Intell.},
  title        = {Hybrid recurrent with spiking neural network model for enhanced anomaly prediction in IoT networks security},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chimera: A block-based neural architecture search framework for event-based object detection. <em>FRAI</em>, <em>8</em>, 1644889. (<a href='https://doi.org/10.3389/frai.2025.1644889'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event-based cameras are sensors inspired by the human eye, offering advantages such as high-speed robustness and low power consumption. Established deep learning techniques have proven effective in processing event data, but there remains a significant space of possibilities that could be further explored to maximize the potential of such combinations. In this context, Chimera is a Block-Based Neural Architecture Search (NAS) framework specifically designed for Event-Based Object Detection, aiming to systematically adapt RGB-domain processing methods to the event domain. The Chimera design space is constructed from various macroblocks, including attention blocks, convolutions, State Space Models, and MLP-mixer-based architectures, providing a valuable trade-off between local and global processing capabilities, as well as varying levels of complexity. Results on Prophesee's GEN1 dataset demonstrated state-of-the-art mean Average Precision (mAP) while reducing the number of parameters by 1.6 × and achieving a 2.1 × speed-up. The project is available at: https://github.com/silvada95/Chimera.},
  archive      = {J_FRAI},
  author       = {Silva, Diego A. and Elsheikh, Ahmed and Smagulova, Kamilya and Fouda, Mohammed E. and Eltawil, Ahmed M.},
  doi          = {10.3389/frai.2025.1644889},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1644889},
  shortjournal = {Front. Artif. Intell.},
  title        = {Chimera: A block-based neural architecture search framework for event-based object detection},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing credit card fraud detection using traditional and deep learning models with class imbalance mitigation. <em>FRAI</em>, <em>8</em>, 1643292. (<a href='https://doi.org/10.3389/frai.2025.1643292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe growing complexity of fraudulent activities presents significant challenges in detecting fraud within financial transactions. Accurate and robust detection methods are essential for minimizing financial losses.MethodsThis study evaluates logistic regression, decision tree, and random forest models on real-world credit card datasets, addressing class imbalance and enhancing predictive accuracy. A deep learning model incorporating focal loss was developed to further improve detection performance. The Synthetic Minority Over-Sampling Technique (SMOTE) was applied to mitigate class imbalance, and hyperparameter tuning was conducted to optimize model configurations.ResultsExperimental results show that the random forest model achieved the best overall performance, with an accuracy of 99.95%, F1 score of 0.8256, and ROC-AUC of 0.9759. The deep learning model provided the highest precision, demonstrating its potential in minimizing false positives.DiscussionA key novelty of this work is the integration of focal loss within the deep learning framework, enabling the model to focus on hard-to-classify fraudulent transactions. Unlike many prior studies limited to the Kaggle dataset, our approach was validated on both the Kaggle credit card dataset and the PaySim synthetic mobile money dataset, demonstrating robustness and cross-domain generalizability. These findings highlight the effectiveness of combining data preprocessing, resampling techniques, and model optimization for robust fraud detection.},
  archive      = {J_FRAI},
  author       = {Albalawi, Tahani and Dardouri, Samia},
  doi          = {10.3389/frai.2025.1643292},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1643292},
  shortjournal = {Front. Artif. Intell.},
  title        = {Enhancing credit card fraud detection using traditional and deep learning models with class imbalance mitigation},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The potential of DeepSeek for AI-aided diagnosis of antibody-positive autoimmune encephalitis: A single-center, retrospective, observational study. <em>FRAI</em>, <em>8</em>, 1638904. (<a href='https://doi.org/10.3389/frai.2025.1638904'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundAutoimmune encephalitis (AIE) is challenging to diagnose, especially in primary hospitals in China with limited medical resources. DeepSeek, a newly developed AI, shows potential as a cost-effective tool for improving diagnostic efficiency. However, no studies have evaluated the diagnostic accuracy of DeepSeek for AIE.MethodsThis retrospective study included 100 patients with anti-neuronal antibody-positive AIE treated at Ruijin Hospital, Shanghai Jiao Tong University School of Medicine. After removing personally identifiable information, antibody results, and history of immunotherapy from patients’ medical histories, the following information was sequentially input into DeepSeek: sex, age, chief complaint, medical history, EEG findings, head MRI description, and cerebrospinal fluid (CSF) results. The positive rates of AIE diagnoses predicted by DeepSeek were then categorized as most likely diagnosis, differential diagnosis, and total diagnosis.ResultsUsing DeepSeek, the probabilities of AIE appearing as the most likely diagnosis and total diagnosis accuracy were 49 and 65%. When patient data were input stepwise, both the total diagnosis accuracy and the most likely diagnosis accuracy did not significantly increase. AIE patients with anti-MOG and anti-GABAbR positivity had predicted total diagnostic positivity rates of 88 and 100%, respectively. Patients presenting with headache and epilepsy were more likely to be diagnosed with AIE (96 and 100%).ConclusionDeepSeek shows limited positive diagnostic accuracy for predicting the diagnosis of AIE. The application of this new AI technology could be used to promote early screening for AIE in primary hospitals in China, improve medical education, and lead to research advances in AIE.},
  archive      = {J_FRAI},
  author       = {Meng, Huanyu and Tang, Yihua and Qi, Yuanqi and Zhou, Qinming and He, Lu and Chen, Sheng},
  doi          = {10.3389/frai.2025.1638904},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1638904},
  shortjournal = {Front. Artif. Intell.},
  title        = {The potential of DeepSeek for AI-aided diagnosis of antibody-positive autoimmune encephalitis: A single-center, retrospective, observational study},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The perceived impact of artificial intelligence on academic learning. <em>FRAI</em>, <em>8</em>, 1611183. (<a href='https://doi.org/10.3389/frai.2025.1611183'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative artificial intelligence, such as ChatGPT, is transforming higher education by enabling personalized learning, while raising ethical challenges. This study explores how technical university students perceive and leverage ChatGPT in academic tasks, focusing on motivation, learning outcomes, and ethical awareness. Using the Technology Acceptance Model and Self-Determination Theory, the research surveyed 84 students from a technical university via a 5-point Likert-scale questionnaire. Six salient dimensions of student engagement with ChatGPT emerged: perceived usefulness for problem solving, learning retention and skill acquisition, structured interaction with familiar content, consultation on unfamiliar topics, preference for conciseness, and confidence in the accuracy of AI responses. Students who perceived ChatGPT as a valuable resource for addressing academic problems reported enhanced motivation and competence, and frequent structured interaction was linked to the practice of verifying uncertain information, indicating the emergence of AI literacy. However, extensive reliance was correlated with dependence and limited citation practices, revealing risks to academic integrity. By examining ChatGPT’s role in STEM education, this study substantiates the relevance of AI literacy training and institutional policies to ensure responsible use. The findings offer practical insights for educators to integrate AI tools effectively while fostering critical thinking and academic integrity in technology-driven learning environments.},
  archive      = {J_FRAI},
  author       = {Dogaru, Mariana and Pisică, Olivia and Popa, Cosmin-Ștefan and Răgman, Andrei-Adrian and Tololoi, Ilinca-Roxana},
  doi          = {10.3389/frai.2025.1611183},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1611183},
  shortjournal = {Front. Artif. Intell.},
  title        = {The perceived impact of artificial intelligence on academic learning},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heart rates, facial expressions and self-reports: A multimodal longitudinal approach of learners' emotions in the foreign language classroom. <em>FRAI</em>, <em>8</em>, 1604110. (<a href='https://doi.org/10.3389/frai.2025.1604110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotions in educational settings are often studied through self-reports or lab experiments, limiting insights into their real-world dynamics. This study examines learner emotions in authentic foreign language classrooms using a multimodal longitudinal approach. Over 16 consecutive sessions, we collected heart rate (HR) signals, emotional facial expressions (EFE), classroom observations, and self-reports on enjoyment, anxiety, and boredom to capture both physiological and self-perceived emotional responses. Rather than aggregating data across students, we focused on individualized emotional patterns to understand variations in emotional experiences. Each dataset included extensive video recordings, continuous HR monitoring, detailed observational notes, and post-session questionnaires, providing a high-resolution picture of emotional dynamics. Using unsupervised clustering techniques, we identified key emotional episodes—peaks and drops in physiological arousal (heart rate variation) and facial expression—relative to individual emotional baselines. These moments were cross-referenced with classroom observations and self-reports for validation. Findings highlight moments of positive emotional contagion during peer interactions, emphasizing the social dimension of language learning. This multimodal approach captures the interplay of physiological, behavioral, and subjective responses, offering a scalable method for studying classroom emotions. Methodologically, it demonstrates how multimodal analytics can uncover transient emotional states in real-world settings, while practically informing adaptive teaching strategies, such as leveraging peer interactions to enhance engagement or reduce anxiety. By integrating physiological, behavioral, and subjective data, this study provides a comprehensive framework for understanding the affective dimensions of learning.},
  archive      = {J_FRAI},
  author       = {Guedat-Bittighoffer, Delphine and Moufidi, Abderrazzaq and Dewaele, Jean-Marc and Rousseau, David and Voyneau, Hugo and Rasti, Pejman},
  doi          = {10.3389/frai.2025.1604110},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1604110},
  shortjournal = {Front. Artif. Intell.},
  title        = {Heart rates, facial expressions and self-reports: A multimodal longitudinal approach of learners' emotions in the foreign language classroom},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="frobt">FROBT - 12</h2>
<ul>
<li><details>
<summary>
(2025). Reinventing the wheel: A simulation-aided design of a soft, shape-adapting, lugged wheel for locomotion on sandy terrains. <em>FROBT</em>, <em>12</em>, 1686519. (<a href='https://doi.org/10.3389/frobt.2025.1686519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Locomotion over granular terrain poses significant challenges for autonomous robotic systems, particularly in coastal regions characterized by loose, shifting sands. To optimize the locomotion on these challenging terrains, a simulation-aided design approach was used to develop a soft, shape-adapting, wheeled locomotion system. A co-simulation framework combining the discrete element method (DEM) and multibody dynamics (MBD) is employed to simulate the locomotion of a wheeled robot on varying sandy soils, covering both dry and wet sandy soil conditions. A shape-adapting wheel design is proposed, incorporating soft, inflatable elements that enable the wheel to transform between lugged and circular configurations. A discretized flexbody approach is adopted to model the interactions between the sandy soil and the soft, flexible bodies of the shape-adapting wheel design. Simulation results demonstrate improved performance of the shape-adapting wheels across a variety of sandy terrains, including slopes and obstacles. Integrating softness into the wheel improves obstacle climbing performance, while a lugged wheel configuration performs particularly well on loose, dry sandy slopes. This DEM-MBD co-simulation further enables efficient evaluation of locomotion strategies without the need for extensive physical prototyping.},
  archive      = {J_FROBT},
  author       = {Shi, H. and Klaassen, P. and Schott, D. L. and Jovanova, J.},
  doi          = {10.3389/frobt.2025.1686519},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1686519},
  shortjournal = {Front. Robot. AI},
  title        = {Reinventing the wheel: A simulation-aided design of a soft, shape-adapting, lugged wheel for locomotion on sandy terrains},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Agency-preserving robotic assistance for grasp slip recovery in body-powered prostheses. <em>FROBT</em>, <em>12</em>, 1675955. (<a href='https://doi.org/10.3389/frobt.2025.1675955'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing studies demonstrate that performance in reaction-based tasks can be improved using external robotic assistance without reducing the user’s sense of agency, particularly when assistance is delivered near the user’s natural reaction time. This finding has promise for assistive technologies like upper limb prostheses, where agency contributes to long-term use and users’ natural slip reflexes are hindered by reduced feedback and proprioception. However, prior studies lack the physical feedback of device movement inherent to many assistive devices like body-powered prostheses or exoskeletons where user and device are physically coupled. In this work, we explore the relationship between robotic assistance, performance, and agency when such feedback is present. We study how the timing of robotic assistance alters performance and agency, as experienced through the feedback of a body-powered transmission. We collect data from twenty participants in a simulated slip reaction task using a custom body-powered prosthesis emulator, with robotic grasp assistance provided at various delays relative to the onset of slip. Results show that, as assistance becomes more aligned with reaction times, agency increases while performance benefits are still obtained, even if users are aware of the assistance and perceive an increase in performance. Our findings suggest that in scenarios where users can physically perceive robotic assistance and its benefits, such as in body-grounded assistive technologies like body-powered prostheses or exoskeletons, temporal alignment between the user and robotic assistance plays a role in both performance and user experience.},
  archive      = {J_FROBT},
  author       = {Davis, Benjamin and Abbott, Michael and Stuart, Hannah S.},
  doi          = {10.3389/frobt.2025.1675955},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1675955},
  shortjournal = {Front. Robot. AI},
  title        = {Agency-preserving robotic assistance for grasp slip recovery in body-powered prostheses},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring multimodal collaborative storytelling with pepper: A preliminary study with zero-shot LLMs. <em>FROBT</em>, <em>12</em>, 1662819. (<a href='https://doi.org/10.3389/frobt.2025.1662819'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of large language models (LLMs), collaborative storytelling in virtual agents or chatbots has gained popularity. Despite storytelling has long been employed in social robotics as a means to educate, entertain, and persuade audiences, the integration of LLMs into such platforms remains largely unexplored. This paper presents the initial steps for a novel multimodal collaborative storytelling system in which users co-create stories with the social robot Pepper through natural language interaction and by presenting physical objects. The robot employs a YOLO-based vision system to recognize these objects and seamlessly incorporate them into the narrative. Story generation and adaptation are handled autonomously using the Llama model in a zero-shot setting, aiming to assess the usability and maturity of such models in interactive storytelling. To enhance immersion, the robot performs the final story using expressive gestures, emotional cues, and speech modulation. User feedback, collected through questionnaires and semi-structured interviews, indicates a high level of acceptance.},
  archive      = {J_FROBT},
  author       = {Zabala, Unai and Echevarria, Juan and Rodriguez, Igor and Lazkano, Elena},
  doi          = {10.3389/frobt.2025.1662819},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1662819},
  shortjournal = {Front. Robot. AI},
  title        = {Exploring multimodal collaborative storytelling with pepper: A preliminary study with zero-shot LLMs},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trustworthy navigation with variational policy in deep reinforcement learning. <em>FROBT</em>, <em>12</em>, 1652050. (<a href='https://doi.org/10.3389/frobt.2025.1652050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionDeveloping a reliable and trustworthy navigation policy in deep reinforcement learning (DRL) for mobile robots is extremely challenging, particularly in real-world, highly dynamic environments. Particularly, exploring and navigating unknown environments without prior knowledge, while avoiding obstacles and collisions, is very cumbersome for mobile robots. MethodsThis study introduces a novel trustworthy navigation framework that utilizes variational policy learning to quantify uncertainty in the estimation of the robot’s action, localization, and map representation. Trust-Nav employs the Bayesian variational approximation of the posterior distribution over the policy-based neural network’s parameters. Policy-based and value-based learning are combined to guide the robot’s actions in unknown environments. We derive the propagation of variational moments through all layers of the policy network and employ a first-order approximation for the nonlinear activation functions. The uncertainty in robot action is measured by the propagated variational covariance in the DRL policy network. At the same time, the uncertainty in the robot’s localization and mapping is embedded in the reward function and stems from the traditional Theory of Optimal Experimental Design. The total loss function optimizes the parameters of the policy and value networks to maximize the robot’s cumulative reward in an unknown environment.ResultsExperiments conducted using the Gazebo robotics simulator demonstrate the superior performance of the proposed Trust-Nav model in achieving robust autonomous navigation and mapping.DiscussionTrust-Nav consistently outperforms deterministic DRL approaches, particularly in complicated environments involving noisy conditions and adversarial attacks. This integration of uncertainty into the policy network promotes safer and more reliable navigation, especially in complex or unpredictable environments. Trust-Nav offers a step toward deployable, self-aware robotic systems capable of recognizing and responding to their own limitations.},
  archive      = {J_FROBT},
  author       = {Bockrath, Karla and Ernst, Liam and Nadeem, Rohaan and Pedraza, Bryan and Dera, Dimah},
  doi          = {10.3389/frobt.2025.1652050},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1652050},
  shortjournal = {Front. Robot. AI},
  title        = {Trustworthy navigation with variational policy in deep reinforcement learning},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Designing socially assistive robots for clinical practice: Insights from an asynchronous remote community of speech-language pathologists. <em>FROBT</em>, <em>12</em>, 1646880. (<a href='https://doi.org/10.3389/frobt.2025.1646880'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionSocially Assistive Robots (SARs) hold promise for augmenting speech-language therapy by addressing high caseloads and enhancing child engagement. However, many implementations remain misaligned with clinician practices and overlook expressive strategies central to speech-language pathology.MethodsWe conducted a 4-week Asynchronous Remote Community (ARC) study with thirteen licensed speech-language pathologists (SLPs). Participants engaged in weekly activities and asynchronous discussions, contributing reflective insights on emotional expression, domain-specific needs, and potential roles for SARs. The ARC format supported distributed, flexible engagement and facilitated iterative co-design through longitudinal peer dialogue. Data were analyzed using thematic analysis to identify emerging patterns.ResultsAnalysis revealed five clinician-driven design considerations for SARs: (1) the need for expressive and multi-modal communication; (2) customization of behaviors to accommodate sensory and developmental profiles; (3) adaptability of roles across therapy contexts; (4) ethical concerns surrounding overuse and fears of clinician replacement; and (5) opportunities for data tracking and personalization.DiscussionFindings highlight clinician-informed design implications that can guide the development of socially intelligent, adaptable, and ethically grounded SARs. The ARC approach proved a viable co-design framework, enabling deeper reflection and peer-driven requirements than traditional short-term methods. This work bridges the gap between robotic capabilities and clinical expectations, underscoring the importance of embedding clinician expertise in SAR design to foster meaningful integration into speech-language interventions.},
  archive      = {J_FROBT},
  author       = {Oliva, Denielle and Olszewski, Abbie and Sadeghi, Shekoufeh and Dantu, Karthik and Feil-Seifer, David},
  doi          = {10.3389/frobt.2025.1646880},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1646880},
  shortjournal = {Front. Robot. AI},
  title        = {Designing socially assistive robots for clinical practice: Insights from an asynchronous remote community of speech-language pathologists},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized causal explanations of a robot’s behavior. <em>FROBT</em>, <em>12</em>, 1637574. (<a href='https://doi.org/10.3389/frobt.2025.1637574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deployment of robots in environments shared with humans implies that they must be able to justify or explain their behavior to nonexpert users when the user, or the situation itself, requires it. We propose a framework for robots to generate personalized explanations of their behavior by integrating cause-and-effect structures, social roles, and natural language queries. Robot events are stored as cause–effect pairs in a causal log. Given a human natural language query, the system uses machine learning to identify the matching cause-and-effect entry in the causal log and determine the social role of the inquirer. An initial explanation is generated and is then further refined by a large language model (LLM) to produce linguistically diverse responses tailored to the social role and the query. This approach maintains causal and factual accuracy while providing language variation in the generated explanations. Qualitative and quantitative experiments show that combining the causal information with the social role and the query when generating the explanations yields the most appreciated explanations.},
  archive      = {J_FROBT},
  author       = {Galeas, José and Bensch, Suna and Hellström, Thomas and Bandera, Antonio},
  doi          = {10.3389/frobt.2025.1637574},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1637574},
  shortjournal = {Front. Robot. AI},
  title        = {Personalized causal explanations of a robot’s behavior},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New avenues for understanding what deep networks learn from EEG. <em>FROBT</em>, <em>12</em>, 1625732. (<a href='https://doi.org/10.3389/frobt.2025.1625732'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important but unresolved question in deep learning for EEG decoding is which features neural networks learn to solve the task. Prior interpretability studies have mainly explained individual predictions, analyzed the use of established EEG features, or examined subnetworks of larger models. In contrast, we apply interpretability methods to uncover features learned by the complete network. Specifically, we introduce two complementary architectures with dedicated visualization techniques to obtain an approximate understanding of the full network trained on binary classification into nonpathological and pathological EEG. First, we use invertible networks—networks that are designed to be invertible—to generate prototypical input signals for each class. Second, we design a very compact network that is fully visualizable, while still retaining reasonable decoding performance. Through these visualizations, we find both expected features like higher-amplitude oscillations in the delta and theta frequency bands in the temporal region for the pathological class as well as surprising differences in the very low sub-delta frequencies below 0.5 Hz. Closer investigation reveals higher spectral amplitudes for the healthy class at the frontal sensors in these sub-delta frequencies, an unexpected feature that the proposed visualizations helped identify. Overall, the study shows the potential of visualizations to understand the network prediction function without relying on specific predefined features.},
  archive      = {J_FROBT},
  author       = {Schirrmeister, Robin T. and Ball, Tonio},
  doi          = {10.3389/frobt.2025.1625732},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1625732},
  shortjournal = {Front. Robot. AI},
  title        = {New avenues for understanding what deep networks learn from EEG},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling trust and its dynamics from physiological signals and embedded measures for operational human-autonomy teaming. <em>FROBT</em>, <em>12</em>, 1624777. (<a href='https://doi.org/10.3389/frobt.2025.1624777'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-autonomy teaming is an increasingly integral component of operational environments, including crewed and remotely operated space missions, military settings, and public safety. The performance of such teams relies on proper trust in the autonomous system, thus creating an urgent need to capture the dynamic nature of trust and devise objective, non-disruptive means of precisely modeling trust. This paper describes the use of bio-signals and embedded measures to create a model capable of inferring and predicting trust. Data (2304 observations) was collected via human subject testing (n = 12, 7M/5F) during which participants interacted with a simulated autonomous system in an operationally relevant, human-on-the-loop, remote monitoring task and reported their subjective trust via visual analog scales. Electrocardiogram, respiration, electrodermal activity, electroencephalogram, functional near-infrared spectroscopy, eye-tracking, and button click data were collected during each trial. Operator background information were collected prior to the experiment. Features were extracted and algorithmically down-selected, then ordinary least squares regression was used to fit the model, and predictive capabilities were assessed on unseen trials. Model predictions achieved a high level of accuracy with a Q2 of 0.64 and captured rapid changes in trust during an operationally relevant human-autonomy teaming task. The model advances the field of non-disruptive means of inferring trust by incorporating a broad suite of physiological signals into a model that is predictive, while many current models are purely descriptive. Future work should assess model performance on unseen participants.},
  archive      = {J_FROBT},
  author       = {Rindfuss, Abigail and Leary, Sarah and Dutta, Prachi and Chen, Ryan and Clark, Torin K. and Kong, Zhaodan and Hayman, Allison P. A.},
  doi          = {10.3389/frobt.2025.1624777},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1624777},
  shortjournal = {Front. Robot. AI},
  title        = {Modeling trust and its dynamics from physiological signals and embedded measures for operational human-autonomy teaming},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive emergency response and dynamic crowd navigation for mobile robot using deep reinforcement learning. <em>FROBT</em>, <em>12</em>, 1612392. (<a href='https://doi.org/10.3389/frobt.2025.1612392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile robots have emerged as a reliable solution for dynamic navigation in real-world applications. Effective deployment in high-density crowds and emergency scenarios requires not only accurate path planning but also rapid adaptation to changing environments. However, autonomous navigation in such environments remains a significant challenge, particularly in time-sensitive applications such as emergency response. Existing path planning and reinforcement learning approaches often lack adaptability to uncertainties and time-varying obstacles, thereby making them less suitable for unstructured real-world scenarios. To address these limitations, a Deep Reinforcement Learning (DRL) framework for dynamic crowd navigation using three algorithms, Deep Deterministic Policy Gradient (DDPG), Twin Delayed Deep Deterministic Policy Gradient (TD3), and Deep Q-Network (DQN), is proposed. A context-aware state representation that combines Light Detection and Ranging (LiDAR)-based obstacle perception, goal orientation, and robot kinematics to enhance situational awareness is developed. The proposed framework is implemented in a ROS2 Gazebo simulation environment using the TurtleBot3 platform and tested in challenging scenarios to identify the most effective algorithm. Extensive simulation analysis demonstrates that TD3 outperforms the other approaches in terms of success rate, path efficiency, and collision avoidance. This study contributes a reproducible, constraint-aware DRL navigation architecture suitable for real-time, emergency-oriented mobile robot applications.},
  archive      = {J_FROBT},
  author       = {Alexander, Anusha and Vangaveeti, V. N. Suchir and Venkatesan, Kalaichelvi and Mounsef, Jinane and Ramanujam, Karthikeyan},
  doi          = {10.3389/frobt.2025.1612392},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1612392},
  shortjournal = {Front. Robot. AI},
  title        = {Adaptive emergency response and dynamic crowd navigation for mobile robot using deep reinforcement learning},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Error recovery in wearable robotic co-grasping: The role of human-led correction. <em>FROBT</em>, <em>12</em>, 1598296. (<a href='https://doi.org/10.3389/frobt.2025.1598296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionTrust in automated systems influences the use and disuse of new technologies. Although recent advances in robotics have improved wearable devices designed to assist in grasping, perfectly reliable systems have yet to be achieved. In this work, we introduce a new strategy for wearable devices called Co-Grasping, where both body power and robotics can contribute to grasping, but the user controls the allocation of the human and robot roles.MethodsOur implementation of a Co-Grasping device successfully allows the human operator to intervene using body power during simulated robot errors, in order to aid in error recovery and continue performing grasping tasks without drops.ResultsHere, we also show that the presence of recoverable errors lowers trust perception and increases physical engagement behaviors. However, when the robot becomes reliable once again, trust rebounds and most behavioral metrics return to baseline as well.DiscussionThese results indicate that trust in faulty automation can be repaired and that enabling users to assume control over system actuation in response to such faults can prevent errors from negatively affecting overall device function. Facilitating human-led dynamic changes in human and robot role allocation through this Co-Grasping device lays a promising foundation for unique human-robot interactions that promote high performance and where trust can recover quickly, despite existing challenges in developing perfect automated systems.},
  archive      = {J_FROBT},
  author       = {Chang, Erin Y. and Torres, Wilson O. and Stuart, Hannah S.},
  doi          = {10.3389/frobt.2025.1598296},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1598296},
  shortjournal = {Front. Robot. AI},
  title        = {Error recovery in wearable robotic co-grasping: The role of human-led correction},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The future of robotic disassembly: A systematic review of techniques and applications in the age of AI. <em>FROBT</em>, <em>12</em>, 1584657. (<a href='https://doi.org/10.3389/frobt.2025.1584657'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s era of digital transformation, industries have made a decisive leap by adopting data-driven, robot-assisted disassembly solutions that cut cycle time and cost relative to labor-intensive manual tear-down. Thus, including robots not only improved production activities but also strengthened the safety measures that once the human operator was handling. Minimizing the impact of the human factor in the process means minimizing incidents related to it. The disassembly of Waste Electrical and Electronic Equipment (WEEE) poses complex technical, economic, and safety challenges that traditional manual methods struggle to meet. Thus, there is a need for a decision-making tool harmonized with human cooperation, in which Artificial Intelligence (AI) plays a pivotal role by providing financially viable solutions while ensuring a secure collaborative environment for both humans and robots. This review synthesizes recent advances in AI-enabled robotic disassembly by focusing on four main research areas: i optimization and strategic planning, ii human–robot collaboration (HRC), iii computer vision (CV) integration, and (iv) Safety for Collaborative Applications. A supplementary subsection is also included to briefly acknowledge emerging topics such as reinforcement learning that lie outside the main scope but represent promising future directions. By analyzing 62 peer-reviewed studies published between 2000 and 2024, the results identify how these themes converge, highlight open challenges, and map out future research directions.},
  archive      = {J_FROBT},
  author       = {Ameur, Soufiane and Tabaa, Mohamed and Hidila, Zineb and Hamlich, Mohamed and Karboub, Kaouter and Bearee, Richard},
  doi          = {10.3389/frobt.2025.1584657},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1584657},
  shortjournal = {Front. Robot. AI},
  title        = {The future of robotic disassembly: A systematic review of techniques and applications in the age of AI},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An approach for unsupervised interaction clustering in human–robot co-work using spatiotemporal graph convolutional networks. <em>FROBT</em>, <em>12</em>, 1545712. (<a href='https://doi.org/10.3389/frobt.2025.1545712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an approach to cluster interaction forms in industrial human–robot co-work using spatiotemporal graph convolutional networks (STGCNs). Humans will increasingly work with robots in the future, whereas previously, humans worked side by side, hand in hand, or alone. The growing frequency of robotic and human–robot co-working applications and the requirement to increase flexibility affect the variety and variability of interactions between humans and robots, which can be observed at production workplaces. In this paper, we investigate the variety and variability of human–robot interactions in industrial co-work scenarios where full automation is impractical. To address the challenges of interaction modeling and clustering, we present an approach that utilizes STGCNs for interaction clustering. Data were collected from 12 realistic human–robot co-work scenarios using a high-accuracy tracking system. The approach identified 10 distinct interaction forms, revealing more granular interaction patterns than established taxonomies. These results support continuous, data-driven analysis of human–robot behavior and contribute to the development of more flexible, human-centered systems that are aligned with Industry 5.0.},
  archive      = {J_FROBT},
  author       = {Heuermann, Aaron and Ghrairi, Zied and Zitnikov, Anton and Al Noman, Abdullah and Thoben, Klaus-Dieter},
  doi          = {10.3389/frobt.2025.1545712},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1545712},
  shortjournal = {Front. Robot. AI},
  title        = {An approach for unsupervised interaction clustering in human–robot co-work using spatiotemporal graph convolutional networks},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
