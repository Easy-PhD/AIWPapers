<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>FRAI</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="frai">FRAI - 20</h2>
<ul>
<li><details>
<summary>
(2025). Editorial: Methodology for emotion-aware education based on artificial intelligence. <em>FRAI</em>, <em>8</em>, 1704389. (<a href='https://doi.org/10.3389/frai.2025.1704389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, advances in Artificial Intelligence (AI) have opened up unprecedented horizons in educational research. The ability to recognize, interpret and respond to students' emotions presents education with a crucial challenge: to design methodologies that integrate the affective dimension as a fundamental part of the learning process. With this objective in mind, the research topic "Methodology for Emotion-Aware Education Based on Artificial Intelligence" was born. Its purpose was to bring together work that explores theoretical approaches, technological applications and empirical evidence on Educational AI linked to emotions, bridging affective computing, pedagogy, and human–computer interaction to foster more responsive and ethical emotion-aware learning environments. This research topic offers a pluralistic overview, both in terms of methods and contexts, which allows for reflection on the advances and challenges that arise when introducing AI systems capable of detecting and responding to emotional states in the educational field. The contributions range from the analysis of the social impact of scientific production to the application of deep learning models, the integration of pedagogical beliefs in the adoption of generative technologies, and the design of innovative sentiment analysis models. They also highlight ethical, methodological, and practical challenges in the field. In particular, Ni and Ni (2024) presents ECO-SAM, an innovative sentiment analysis model that combines self-attention techniques with pre-trained neural networks to improve emotion classification in texts with notable increases in accuracy. Its educational relevance lies in the potential of text analysis systems to interpret interactions on learning platforms, forums, and student social networks. The study also opens possibilities for transferring these techniques to the analysis of written work in school environments, enriching formative assessment and identifying emotional patterns in students' academic and personal writing. From another perspective, Govea et al. (2024) apply deep reinforcement learning models in hybrid learning environments, developing a system capable of detecting emotions in real time by integrating convolutional and recurrent networks. Using data from 500 students collected through cameras, microphones and biometric sensors, the authors show significant improvements in emotional detection accuracy and learning personalization. This work invites us to rethink hybrid environments as spaces where AI supports cognition and, at the same time, responds to the emotional dimension. However, it also highlights the urgent need to establish regulatory and pedagogical frameworks, so that the pursuit of efficiency does not compromise the privacy and emotional well-being of students. Cabero-Almenara et al. (2024) focuses on a decisive aspect: teacher acceptance of AI in higher education. The study, involving 425 university professors, uses the UTAUT2 model to analyze how pedagogical beliefs shape willingness to integrate generative AI tools. The results show that teachers with a constructivist orientation are more willing to incorporate these technologies than those with transmissive approaches. This emphasizes that the adoption of AI does not depend solely on technical availability, but also on the pedagogical concepts that guide teaching practice. This conclusion highlights the need for professional training programs that address the diversity of beliefs and contexts. In this sense, we see that the future of AI in education will not be played out solely in laboratories, but also in the ability of institutions to support their teachers in processes of pedagogical reflection and continuous professional development. Zhou et al. (2024) provide a novel approach by applying Item Response Theory (IRT) from a student state-aware perspective. Their SAD-IRT model incorporates parameters derived from facial expression analysis using advanced deep learning techniques, which allows for the estimation of item ability and difficulty, as well as an additional parameter linked to the cognitive-affective state of the students. The study demonstrates that this approach improves predictive capacity compared to traditional IRT models and even allows responses to be anticipated before they occur. Beyond its technical value, the article proposes a paradigm shift in educational assessment: considering students' emotions and states as part of the measurement, moving towards more personalized, sensitive and useful assessment systems to guide teaching and learning. Finally, Roda-Segarra et al. (2024) offers a pioneering study that goes beyond traditional bibliometric indicators, by examining more than 6,000 social impact records across 243 publications. They reveal that research on AI and emotions in education has a considerable impact on social media and scientific repositories, although academic impact and social visibility do not always align. This finding prompts reflection on how research reaches communities, and how social networks shape knowledge circulation. In addition, the study opens the door to reflection on the role of scientific communication in building trust around the use of AI in education, an essential aspect for building a balanced dialogue between innovation, society and schools. As we can see, the articles gathered in this research topic show that AI-mediated emotion-aware education is not a distant goal, but a field in full swing. From a social perspective, research still faces the challenge of extending its impact beyond the academic sphere and ensuring a true transfer to educational communities. From a pedagogical perspective, it is clear that teachers' beliefs influence the adoption of AI, which requires the design of training processes that are sensitive to this diversity. Finally, from a technological perspective, advanced models of deep learning and sentiment analysis open up unprecedented possibilities for creating adaptive environments capable of addressing both student performance and emotional well-being. The research published in this research topic shows that the combination of pedagogy, AI and emotion-awareness can transform the way we conceive of teaching and learning in the 21st century. The path ahead is not without ethical and practical challenges. Issues such as privacy, transparency, and fairness in personalization processes must be non-negotiable principles when using AI in an educational context. The results presented here show that this is possible, but at the same time, they reveal that there is still a long way to go in terms of academic research.},
  archive      = {J_FRAI},
  author       = {Roig-Vila, Rosabel and Cazorla, Miguel and Lallé, Sébastien},
  doi          = {10.3389/frai.2025.1704389},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1704389},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Methodology for emotion-aware education based on artificial intelligence},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Medicine for artificial intelligence: Applying a medical framework to AI anomalies. <em>FRAI</em>, <em>8</em>, 1698717. (<a href='https://doi.org/10.3389/frai.2025.1698717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose Medicine for Artificial Intelligence (MAI), a clinical framework that reconceptualizes AI anomalies as diseases requiring systematic screening, differential diagnosis, treatment, and follow-up. Contemporary discourse on failures (e.g., “hallucination”) is ad hoc and fragmented across domains, impeding cumulative knowledge and reproducible management. MAI adapts medical nosology to AI by formalizing core constructs—disease, symptom, diagnosis, treatment, and classification—and mapping a clinical workflow (examination → diagnosis → intervention) onto the AI lifecycle. As a proof-of-concept, we developed DSA-1, a prototype taxonomy of 45 disorders across nine functional chapters. This approach clarifies ambiguous failure modes (e.g., distinguishing hallucination subtypes), links diagnoses to actionable interventions and evaluation metrics, and supports lifecycle practices, including triage and “AI health checks.” MAI further maps epidemiology, severity, and detectability to risk-assessment constructs, complementing top-down governance with bottom-up technical resolution. By aligning clinical methodology with AI engineering and coordinating researchers, clinicians, and regulators, MAI offers a reproducible foundation for safer, more resilient, and auditable AI systems.},
  archive      = {J_FRAI},
  author       = {Kato, Takahiro and Komura, Daisuke and Panda, Binay and Ishikawa, Shumpei},
  doi          = {10.3389/frai.2025.1698717},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1698717},
  shortjournal = {Front. Artif. Intell.},
  title        = {Medicine for artificial intelligence: Applying a medical framework to AI anomalies},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pipeline monitoring data recovery using novel deep learning models: An engineering case study. <em>FRAI</em>, <em>8</em>, 1684018. (<a href='https://doi.org/10.3389/frai.2025.1684018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pipeline monitoring frequently encounters missing data, leading to incomplete evaluation and hindering a comprehensive assessment of the pipeline’s structural health. To address this issue, this study proposes a novel PDO-BiGRU-GAN model for missing data recovery. The model integrates three components: the prairie dog optimization algorithm (PDO) for hyperparameter tuning, the bidirectional gated recurrent unit (BiGRU) for effective temporal feature extraction, and the generative adversarial network (GAN) for data generation and completion. A comprehensive monitoring database was established using field data from an open-source pipeline project. The contributions of individual modules to the overall performance were evaluated via hyperparameter sensitivity analysis and ablation studies. The impact of missing data ratio and the number of missing sensors on the model’s recovery performance was analyzed. In addition, the proposed model was compared with eight existing mainstream deep learning models. The results show that each component of the PDO-BiGRU-GAN significantly enhances overall performance. The model achieves strong recovery accuracy across various missing data scenarios, with the R2 consistently exceeding 0.93. Moreover, the model performs optimally when the missing data ratio is below 20/24. Compared to other models, PDO-BiGRU-GAN achieves the highest R2 and the lowest error metrics (MSE, RMSE, MAPE, MAE). In terms of computational efficiency, the model requires slightly more processing time than simpler models but is faster than more complex models. Overall, the proposed model provides a robust and scalable solution for pipeline monitoring data recovery, advancing intelligent pipeline health assessment and supporting the development of infrastructure safety management and smart monitoring technologies.},
  archive      = {J_FRAI},
  author       = {Zhao, Yong and Zhang, Xinpeng and Liu, Yanli and Mao, Xuecheng and Chen, Xi and Maimaitituerxun, Yasheng and He, Weidong},
  doi          = {10.3389/frai.2025.1684018},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1684018},
  shortjournal = {Front. Artif. Intell.},
  title        = {Pipeline monitoring data recovery using novel deep learning models: An engineering case study},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Phase-specific kidney graft failure prediction with machine learning model. <em>FRAI</em>, <em>8</em>, 1682639. (<a href='https://doi.org/10.3389/frai.2025.1682639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundAccurate prediction of kidney graft failure at different phases post-transplantation is critical for timely intervention and long-term allograft preservation. Traditional survival models offer limited capacity for dynamic, time-specific risk estimation. Machine learning (ML) approaches, with their ability to model complex patterns, present a promising alternative.MethodsThis study developed and dynamically evaluated phase-specific ML models to predict kidney graft failure across five post-transplant intervals: 0–3 months, 3–9 months, 9–15 months, 15–39 months, and 39–72 months. Clinically relevant retrospective data from deceased donor kidney transplant recipients were used for training and internal validation, with performance further confirmed on a blinded external validation cohort. Predictive performance was assessed using ROC AUC, F1 score, and G-mean.ResultsThe ML models demonstrated varying performance across time intervals. Short-term predictions in the 0–3 month and 3–9 month intervals yielded moderate accuracy (ROC AUC = 0.73 ± 0.07 and 0.72 ± 0.04, respectively). The highest predictive accuracy observed in mid-term or the 9–15-month window (ROC AUC = 0.92 ± 0.02; F1 score = 0.85 ± 0.03), followed by the 15–39-month period (ROC AUC = 0.84 ± 0.04; F1 score = 0.76 ± 0.04). Long-term prediction from 39 to 72 months was more challenging (ROC AUC = 0.70 ± 0.07; F1 score = 0.65 ± 0.06).ConclusionPhase-specific ML models offer robust predictive performance for kidney graft failure, particularly in mid-term periods, supporting their integration into dynamic post-transplant surveillance strategies. These models can aid clinicians in identifying high-risk patients and tailoring follow-up protocols to optimize long-term transplant outcomes.},
  archive      = {J_FRAI},
  author       = {Salybekov, Amankeldi A. and Wolfien, Markus and Yerkos, Ainur and Buribayev, Zholdas and Hidaka, Sumi and Kobayashi, Shuzo},
  doi          = {10.3389/frai.2025.1682639},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1682639},
  shortjournal = {Front. Artif. Intell.},
  title        = {Phase-specific kidney graft failure prediction with machine learning model},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A human-centered automated machine learning agent with large language models for multimodal data management and analysis. <em>FRAI</em>, <em>8</em>, 1680845. (<a href='https://doi.org/10.3389/frai.2025.1680845'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated Machine Learning (AutoML) aims to streamline the end-to-end process of ML models, yet current approaches remain constrained by rigid rule-based frameworks and structured input requirements that create barriers for non-expert users. Despite advances in Large Language Models (LLMs) demonstrating capabilities in code generation and natural language understanding, their potential to improve AutoML accessibility has not been fully realized. We present an innovative LLM-driven AI agent that enables natural language interaction throughout the entire ML workflow while maintaining high performance standards, reducing the need for predefined rules and minimizing technical expertise requirements. The proposed agent implements an end-to-end ML pipeline, incorporating automatic data loading and pre-processing, task identification, neural architecture selection, hyperparameter optimization, and training automation. Additionally, we propose a novel data processing approach that leverages LLMs to automatically interpret and handle diverse data formats without requiring manual pre-processing or format conversion. Moreover, we propose an adaptive hyperparameter optimization strategy that combines LLMs' knowledge of ML best practices with dynamic performance feedback to intelligently adjust search spaces. Extensive evaluation on 10 diverse datasets spanning classification and regression tasks across multiple data modalities demonstrates that our approach consistently achieves superior performance compared to traditional rule-based AutoML frameworks. By bridging the gap between human intent and ML implementation, our approach contributes to the development of a more accessible AutoML framework.},
  archive      = {J_FRAI},
  author       = {Huang, Rong and Tao, Su},
  doi          = {10.3389/frai.2025.1680845},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1680845},
  shortjournal = {Front. Artif. Intell.},
  title        = {A human-centered automated machine learning agent with large language models for multimodal data management and analysis},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When AI speaks like a specialist: ChatGPT-4 in the management of inflammatory bowel disease. <em>FRAI</em>, <em>8</em>, 1678320. (<a href='https://doi.org/10.3389/frai.2025.1678320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundArtificial intelligence (AI) is gaining traction in healthcare, especially for patients’ education. Inflammatory bowel diseases (IBD) require continuous engagement, yet the quality of online information accessed by patients is inconsistent. ChatGPT, a generative AI model, has shown promise in medical scenarios, but its role in IBD communication needs further evaluation. The objective of this study was to assess the quality of ChatGPT-4’s responses to common patient questions about IBD, compared to those provided by experienced IBD specialists.MethodsTwenty-five frequently asked questions were collected during routine IBD outpatient visits and categorized into five themes: pregnancy/breastfeeding, diet, vaccinations, lifestyle, and medical therapy/surgery. Each question was answered by ChatGPT-4 and by two expert gastroenterologists. Responses were anonymized and evaluated by 12 physicians (six IBD experts and six non-experts) using a 5-point Likert scale across four dimensions: accuracy, reliability, comprehensibility, and actionability. Evaluators also attempted to identify whether responses were AI- or human-generated.ResultsChatGPT-4 responses received significantly higher overall scores than those from human experts (mean 4.28 vs. 4.05; p < 0.001). The best-rated scenarios were medical therapy and surgery; the diet scenario consistently received lower scores. Only 33% of AI-generated responses were correctly identified as such, indicating strong similarity to human-written answers. Both expert and non-expert evaluators rated AI responses highly, though IBD specialists gave higher ratings overall.ConclusionChatGPT-4 generated high-quality, clear, and actionable responses to IBD-related patient questions, often outperforming human experts. Its outputs were frequently indistinguishable from those written by physicians, suggesting potential as a supportive tool for patient education. Nonetheless, further studies are needed to assess real-world application and ensure appropriate use in personalized clinical care.},
  archive      = {J_FRAI},
  author       = {De Cristofaro, Elena and Zorzi, Francesca and Abreu, Maria and Colella, Alice and Blanco, Giovanna Del Vecchio and Fiorino, Gionata and Lolli, Elisabetta and Noor, Nurulamin and Lopetuso, Loris Riccardo and Pioche, Mathieu and Grimaldi, Jean and Paoluzi, Omero Alessandro and Roseira, Joana and Sena, Giorgia and Troncone, Edoardo and Calabrese, Emma and Monteleone, Giovanni and Marafini, Irene},
  doi          = {10.3389/frai.2025.1678320},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1678320},
  shortjournal = {Front. Artif. Intell.},
  title        = {When AI speaks like a specialist: ChatGPT-4 in the management of inflammatory bowel disease},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing surface defect detection with YOLOv9: The role of advanced backbone models. <em>FRAI</em>, <em>8</em>, 1675154. (<a href='https://doi.org/10.3389/frai.2025.1675154'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionYOLO algorithmic models are widely utilized for detecting surface defects, offering a robust and efficient approach to identifying various flaws and imperfections on material surfaces.MethodsIn this study, we explore the integration of six distinct backbone networks within the YOLOv9 framework to optimize surface defect detection in steel strips. Specifically, we improve the YOLOv9 framework by integrating six representative backbones-ResNet50, GhostNet, MobileNetV4, FasterNet, StarNet, and RepViT-and conduct a systematic evaluation on the NEU-DET dataset and the GC10-DET dataset. Using YOLOv9-C as the baseline, we compare these backbones in terms of detection accuracy, computational complexity, and model efficiency.ResultsResults show that RepViT achieves the best overall performance with an mAP50 of 68.8%, F1-score of 0.65, and a balanced precision-recall profile, while GhostNet offers superior computational efficiency with only 41.2 M parameters and 190.2 GFLOPs. Further validation on YOLOv5-m confirms the consistency of the results.DiscussionThe study offers practical guidance for backbone selection in surface defect detection tasks, highlighting the advantages of lightweight architectures for real-time industrial applications.},
  archive      = {J_FRAI},
  author       = {Zeng, Zhonglin and Wang, Hongyang and Yao, Chi and Dong, Zile and Cai, Shimin},
  doi          = {10.3389/frai.2025.1675154},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1675154},
  shortjournal = {Front. Artif. Intell.},
  title        = {Optimizing surface defect detection with YOLOv9: The role of advanced backbone models},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). There are significant differences among artificial intelligence large language models when answering scientific questions. <em>FRAI</em>, <em>8</em>, 1664303. (<a href='https://doi.org/10.3389/frai.2025.1664303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThis study investigates the efficacy of large language models (LLMs) for generating accurate scientific responses through a comparative evaluation of five prominent free models: Claude 3.5 Sonnet, Gemini, ChatGPT 4o, Mistral Large 2, and Llama 3.1 70B.MethodsSixteen expert scientific reviewers assessed these models in terms of depth, accuracy, relevance, and clarity.ResultsClaude 3.5 Sonnet emerged as the highest scoring model, followed by Gemini, with notable variability among the other models. Additionally, retrieval-augmented generation (RAG) techniques were applied to improve LLM performance, and prompts were refined to improve answers. The results indicate that although LLMs such as Claude 3.5 Sonnet have potential for scientific tasks, other models may require more development or additional prompt engineering to reach comparable accuracy. Reviewers’ perceptions of artificial intelligence (AI) utility and trustworthiness showed a positive shift after evaluation. However, ethical concerns, particularly with respect to transparency and disclosure, remained consistent.DiscussionThe study highlights the need for structured frameworks for evaluating LLMs and ethical considerations essential for responsible AI integration in scientific research. These findings should be interpreted with caution, as the limited sample size and domain-specific focus of the exam questions restrict the generalizability of the results.},
  archive      = {J_FRAI},
  author       = {Álvarez-Martínez, Francisco Javier and Esteban, Luis and Frungillo, Lucas and Butassi, Estefanía and Zambon, Alessandro and Herranz-López, María and Aranda, Mario and Pollastro, Federica and Tixier, Anne Sylvie and Garcia-Perez, Jose V. and Arráez-Román, David and Ross, Andrew and Mena, Pedro and Edrada-Ebel, Ru Angelie and Lyng, James and Micol, Vicente and Borrás-Rocher, Fernando and Barrajón-Catalán, Enrique},
  doi          = {10.3389/frai.2025.1664303},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1664303},
  shortjournal = {Front. Artif. Intell.},
  title        = {There are significant differences among artificial intelligence large language models when answering scientific questions},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A chinese question and answer system for liver cancer based on knowledge graph and large language mode. <em>FRAI</em>, <em>8</em>, 1663891. (<a href='https://doi.org/10.3389/frai.2025.1663891'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe liver cancer question-and-answer (Q&A) system is primarily intended to help patients access disease-related information more conveniently. However, there is currently no Q&A system specifically developed for liver cancer. Additionally, most existing Q&A systems lack real clinical data and have limited capability in understanding Chinese questions.MethodsThis paper proposes a Chinese liver cancer question-answering system based on knowledge graphs and Large Language Models (LLMs). To unify information from diverse sources, the system employs a knowledge graph to store entities and inter-entity relationships extracted from patients' clinical electronic medical records and the professional medical website xywy.com, which serves as the foundation for the system's responses. Specifically, ChatGLM3.5 is utilized to extract entity information from questions, while BERT is applied to understand users' intent. Subsequently, the system retrieves corresponding information from the knowledge graph. Finally, the retrieved information is integrated, and a natural language response is generated as the answer to the question.ResultsThe experimental results indicate that in terms of intent classification, our system achieves a precision of 92.34%, representing an improvement of 1.38% over the BERT model and 4.32% over the GEBERT model. In terms of response relevance, the system's outputs are more aligned with patients' daily speech patterns and exhibit higher relevance to the target questions.DiscussionIn conclusion, the improved method significantly enhances the usefulness and reliability of the liver cancer Q&A system.},
  archive      = {J_FRAI},
  author       = {Wu, Haoqi and Zhang, Min and Wang, Hailing and Jiang, Xiaoyan and Gao, Yongbin and Huang, Rong and Fang, Zhijun and Hu, Xiaojun and Fan, Yingfang},
  doi          = {10.3389/frai.2025.1663891},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1663891},
  shortjournal = {Front. Artif. Intell.},
  title        = {A chinese question and answer system for liver cancer based on knowledge graph and large language mode},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Search-optimized quantization in biomedical ontology alignment. <em>FRAI</em>, <em>8</em>, 1662984. (<a href='https://doi.org/10.3389/frai.2025.1662984'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the fast-moving world of AI, as organizations and researchers develop more advanced models, they face challenges due to their sheer size and computational demands. Deploying such models on edge devices or in resource-constrained environments adds further challenges related to energy consumption, memory usage and latency. To address these challenges, emerging trends are shaping the future of efficient model optimization techniques. From this premise, by employing supervised state-of-the-art transformer-based models, this research introduces a systematic method for ontology alignment, grounded in cosine-based semantic similarity between a biomedical layman vocabulary and the Unified Medical Language System (UMLS) Metathesaurus. It leverages Microsoft Olive to search for target optimizations among different Execution Providers (EPs) using the ONNX Runtime backend, followed by an assembled process of dynamic quantization employing Intel Neural Compressor and IPEX (Intel Extension for PyTorch). Through our optimization process, we conduct extensive assessments on the two tasks from the DEFT 2020 Evaluation Campaign, achieving a new state-of-the-art in both. We retain performance metrics intact, while attaining an average inference speed-up of 20x and reducing memory usage by 70%.},
  archive      = {J_FRAI},
  author       = {Bouaggad, Oussama and Grabar, Natalia},
  doi          = {10.3389/frai.2025.1662984},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1662984},
  shortjournal = {Front. Artif. Intell.},
  title        = {Search-optimized quantization in biomedical ontology alignment},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated learning for cognitive impairment detection using speech data. <em>FRAI</em>, <em>8</em>, 1662859. (<a href='https://doi.org/10.3389/frai.2025.1662859'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionIn Alzheimer’s disease (AD) research, clinical, neuroimaging, genetic, and biomarker data are vital for advancing its understanding and treatment. However, privacy concerns and limited datasets complicate data sharing. Federated learning (FL) offers a solution by enabling collaborative research while preserving data privacy.MethodsThis study analyzed data from patients assessed at the Memory Unit of the Ace Alzheimer Center Barcelona who completed a standardized digital speech protocol. Acoustic features extracted from these recordings were used to distinguish between cognitively unimpaired (CU) and cognitively impaired (CI) individuals. The aim was to evaluate how data heterogeneity impacted the FL model performance across three scenarios: (1) equal contributions and class ratios, (2) unequal contributions, and (3) imbalanced class ratios. In each scenario, the performance of local models trained using an MLP feed-forward neural network on institutional data was analyzed and compared to a global model created by aggregating these local models using Federated Averaging (FedAvg) and Iterative Data Aggregation (IDA).ResultsThe cohort included 2,239 participants: 221 CU individuals (mean age 66.8, 64.7% female) and 2,018 CI subjects, comprising 1,219 with mild cognitive impairment (mean age 74.3, 61.9% female) and 799 with mild AD dementia (mean age 80.8, 64.8% female). In scenarios 1 and 3, FL provided modest gains in accuracy and AUC. In scenario 2, FL markedly improved performance for the smaller dataset (balanced accuracy rising from 0.51 to 0.80) while preserving 0.86 accuracy in the larger dataset, highlighting scalability across heterogeneous conditions.ConclusionThese findings demonstrate the potential of FL to enable collaborative modeling of speech-based biomarkers for cognitive impairment detection, even under conditions of data imbalance and institutional disparity. This work highlights FL as a scalable and privacy-preserving approach for advancing digital health research in neurodegenerative diseases.},
  archive      = {J_FRAI},
  author       = {Blazquez-Folch, Josep and Limones Andrade, María and Calm, Berta and Auñón García, Juan Miguel and Alegret, Montserrat and Muñoz, Nathalia and Cano, Amanda and Fernández, Victoria and García-Gutiérrez, Fernando and De Rojas, Itziar and García-González, Pablo and Olivé, Clàudia and Puerta, Raquel and Capdevila-Bayo, María and Muñoz-Morales, Álvaro and Bayón-Buján, Paula and Miguel, Andrea and Montrreal, Laura and Espinosa, Ana and Sanz-Cartagena, Pilar and Rosende-Roca, Maitee and Zaldua, Carla and Gabirondo, Peru and Cantero-Fortiz, Yahveth and Gurruchaga, Miren Jone and Tarraga, Lluis and Boada, Mercè and Ruiz, Agustín and Marquié, Marta and Valero, Sergi},
  doi          = {10.3389/frai.2025.1662859},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1662859},
  shortjournal = {Front. Artif. Intell.},
  title        = {Federated learning for cognitive impairment detection using speech data},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable person–job recommendations: Challenges, approaches, and comparative analysis. <em>FRAI</em>, <em>8</em>, 1660548. (<a href='https://doi.org/10.3389/frai.2025.1660548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAs person–job recommendation systems (PJRS) increasingly mediate hiring decisions, concerns over their “black box” opacity have sparked demand for explainable AI (XAI) solutions.MethodsThis systematic review examines 85 studies on explainable PJRS methods published between 2019 and August 2025, selected from 150 screened articles across Google Scholar, Web of Science, and CNKI, following PRISMA 2020 guidelines.ResultsGuided by a PICOS-formulated review question, we categorize explainability techniques into three layers—data (e.g., feature attribution, causal diagrams), model (e.g., attention mechanisms, knowledge graphs), and output (e.g., SHAP, counterfactuals)—and summarize their objectives, trade-offs, and practical applications. We further synthesize these into an integrated end-to-end framework that addresses opacity across layers and supports traceable recommendations. Quantitative benchmarking of six representative methods (e.g., LIME, attention-based, KG-GNN) reveals performance–explainability trade-offs, with counterfactual approaches achieving the highest Explainability-Performance (E‑P) score (0.95).DiscussionThis review provides a taxonomy, cross-layer framework, and comparative evidence to inform the design of transparent and trustworthy PJRS systems. Future directions include multimodal causal inference, feedback-driven adaptation, and efficient explainability tools.},
  archive      = {J_FRAI},
  author       = {Tang, Fang and Zhu, Renqi and Yao, Feng and Wang, Junzhi and Luo, Lailong and Li, Bo},
  doi          = {10.3389/frai.2025.1660548},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1660548},
  shortjournal = {Front. Artif. Intell.},
  title        = {Explainable person–job recommendations: Challenges, approaches, and comparative analysis},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Big data in financial risk management: Evidence, advances, and open questions: A systematic review. <em>FRAI</em>, <em>8</em>, 1658375. (<a href='https://doi.org/10.3389/frai.2025.1658375'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe intersection of big data analytics and financial risk management has spurred significant methodological innovation and organizational change. Despite growing research activity, the literature remains fragmented, with notable gaps in comparative effectiveness, cross-sectoral applicability, and the use of non-traditional data sources.MethodsFollowing the PRISMA 2020 protocol, a systematic review was conducted on 21 peer-reviewed studies published between 2016 and June 2025. The review evaluated the methodological diversity and effectiveness of machine learning and hybrid approaches in financial risk management.ResultsThe analysis mapped the relative strengths and limitations of neural networks, ensemble learning, fuzzy logic, and hybrid optimization across credit, fraud, systemic, and operational risk. Advanced machine learning techniques consistently demonstrated strong predictive accuracy, yet real-world deployment remained geographically concentrated, primarily in Chinese and European banking and fintech sectors. Applications involving alternative and unstructured data, such as IoT signals and behavioral analytics, were largely experimental and faced both technical and governance challenges.Discussion/conclusionThe findings underscore the scarcity of systematic benchmarking across risk types and organizational contexts, as well as the limited attention to explainability in current implementations. This review identifies an urgent need for comparative, cross-jurisdictional studies, stronger field validation, and open science practices to bridge the gap between technical advances and their operational impact in big data–enabled financial risk management.},
  archive      = {J_FRAI},
  author       = {Theodorakopoulos, Leonidas and Theodoropoulou, Alexandra and Bakalis, Aristeidis},
  doi          = {10.3389/frai.2025.1658375},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1658375},
  shortjournal = {Front. Artif. Intell.},
  title        = {Big data in financial risk management: Evidence, advances, and open questions: A systematic review},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessment of demographic bias in retinal age prediction machine learning models. <em>FRAI</em>, <em>8</em>, 1653153. (<a href='https://doi.org/10.3389/frai.2025.1653153'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The retinal age gap, defined as the difference between the predicted retinal age and chronological age, is an emerging biomarker for many eye conditions and even non-ocular diseases. Machine learning (ML) models are commonly used for retinal age prediction. However, biases in ML models may lead to unfair predictions for some demographic groups, potentially exacerbating health disparities. This retrospective cross-sectional study evaluated demographic biases related to sex and ethnicity in retinal age prediction models using retinal imaging data (color fundus photography [CFP], optical coherence tomography [OCT], and combined CFP + OCT) from 9,668 healthy individuals (mean age 56.8 years; 52% female) in the UK Biobank. The RETFound foundation model was fine-tuned to predict retinal age, and bias was assessed by comparing mean absolute error (MAE) and retinal age gaps across demographic groups. The combined CFP + OCT model achieved the lowest MAE (3.01 years), outperforming CFP-only (3.40 years) and OCT-only (4.37 years) models. Significant sex differences were observed only in the CFP model (p < 0.001), while significant ethnicity differences appeared only in the OCT model (p < 0.001). No significant sex/ethnicity differences were observed in the combined model. These results demonstrate that retinal age prediction models can exhibit biases, and that these biases, along with model accuracy, are influenced by the choice of imaging modality (CFP, OCT, or combined). Identifying and addressing sources of bias is essential for safe and reliable clinical implementation. Our results emphasize the importance of comprehensive bias assessments and prospective validation, ensuring that advances in machine learning and artificial intelligence benefit all patient populations.},
  archive      = {J_FRAI},
  author       = {Nielsen, Christopher and Stanley, Emma A. M. and Wilms, Matthias and Forkert, Nils D.},
  doi          = {10.3389/frai.2025.1653153},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1653153},
  shortjournal = {Front. Artif. Intell.},
  title        = {Assessment of demographic bias in retinal age prediction machine learning models},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid recurrent with spiking neural network model for enhanced anomaly prediction in IoT networks security. <em>FRAI</em>, <em>8</em>, 1651516. (<a href='https://doi.org/10.3389/frai.2025.1651516'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAs the number of Internet of Things (IoT) devices grows quickly, cyber threats are becoming more complex and increasingly sophisticated; thus, we need a more robust network security solutions. Traditional deep learning approaches often suffer in identifying effectively anomalies in IoT network. To tackle this evolving challenge, this research proposes a hybrid architecture of Neural Network (NN) models that combine Recurrent-NN (RNN) and Spiking-NN (SNN), referred to as HRSNN, to improve IoT the security.MethodsThe proposed HRSNN technique has five steps: preprocessing data, extracting features, equalization classes, features optimization and classification. Data processing step makes sure that input data is accurate and consistent and by employing normalization and the removal of outliers’ techniques. Feature extraction makes use of the RNN part to automatically detect abnormal patterns and high-level features, which are then turned into spike trains for the SNN to process over time. In class equalization step, the Synthetic Minority-Oversampling Technique (SMOTE) is being used resulting in balanced classes. Recursive Feature Elimination (RFE) is used to keep the important features for feature optimization. Then, the dataset is split into sets for testing and training so that the model can be tested properly.ResultsThe hybrid model integrates the spatial feature learning skills of RNNs with the temporal adaptability of SNNs, results in an improved accuracy and resilience in identifying IoT network abnormalities. The proposed HRSNN approach, which was tested on the CIC-IoT23 and TON_IoT data sets, achieved better performance compared to current deep learning (DL) models. In particular, experimental assessments show that the model attained an accuracy rate of 99.5% on the “CICIoT2023” dataset and 98.75% on the “TON_IoT” dataset.DiscussionThese results confirm demonstrate that the proposed architecture of RNN and SSN can achieve significant advancement to IoT security. By combining both spatial and temporal feature learning, HRSNN can improve accuracy detection against diverse security threats. The model is reliable, accurate, and adaptable for safeguarding IoT networks against diverse security threats. Thus, the model addresses the potential solutions in the challenging problem of secured IoT networks.},
  archive      = {J_FRAI},
  author       = {Mustafa, Mohammed and Eljack Babiker, Sarah M. and Mustafa, Yasir Eltigani Ali},
  doi          = {10.3389/frai.2025.1651516},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1651516},
  shortjournal = {Front. Artif. Intell.},
  title        = {Hybrid recurrent with spiking neural network model for enhanced anomaly prediction in IoT networks security},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chimera: A block-based neural architecture search framework for event-based object detection. <em>FRAI</em>, <em>8</em>, 1644889. (<a href='https://doi.org/10.3389/frai.2025.1644889'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event-based cameras are sensors inspired by the human eye, offering advantages such as high-speed robustness and low power consumption. Established deep learning techniques have proven effective in processing event data, but there remains a significant space of possibilities that could be further explored to maximize the potential of such combinations. In this context, Chimera is a Block-Based Neural Architecture Search (NAS) framework specifically designed for Event-Based Object Detection, aiming to systematically adapt RGB-domain processing methods to the event domain. The Chimera design space is constructed from various macroblocks, including attention blocks, convolutions, State Space Models, and MLP-mixer-based architectures, providing a valuable trade-off between local and global processing capabilities, as well as varying levels of complexity. Results on Prophesee's GEN1 dataset demonstrated state-of-the-art mean Average Precision (mAP) while reducing the number of parameters by 1.6 × and achieving a 2.1 × speed-up. The project is available at: https://github.com/silvada95/Chimera.},
  archive      = {J_FRAI},
  author       = {Silva, Diego A. and Elsheikh, Ahmed and Smagulova, Kamilya and Fouda, Mohammed E. and Eltawil, Ahmed M.},
  doi          = {10.3389/frai.2025.1644889},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1644889},
  shortjournal = {Front. Artif. Intell.},
  title        = {Chimera: A block-based neural architecture search framework for event-based object detection},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing credit card fraud detection using traditional and deep learning models with class imbalance mitigation. <em>FRAI</em>, <em>8</em>, 1643292. (<a href='https://doi.org/10.3389/frai.2025.1643292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe growing complexity of fraudulent activities presents significant challenges in detecting fraud within financial transactions. Accurate and robust detection methods are essential for minimizing financial losses.MethodsThis study evaluates logistic regression, decision tree, and random forest models on real-world credit card datasets, addressing class imbalance and enhancing predictive accuracy. A deep learning model incorporating focal loss was developed to further improve detection performance. The Synthetic Minority Over-Sampling Technique (SMOTE) was applied to mitigate class imbalance, and hyperparameter tuning was conducted to optimize model configurations.ResultsExperimental results show that the random forest model achieved the best overall performance, with an accuracy of 99.95%, F1 score of 0.8256, and ROC-AUC of 0.9759. The deep learning model provided the highest precision, demonstrating its potential in minimizing false positives.DiscussionA key novelty of this work is the integration of focal loss within the deep learning framework, enabling the model to focus on hard-to-classify fraudulent transactions. Unlike many prior studies limited to the Kaggle dataset, our approach was validated on both the Kaggle credit card dataset and the PaySim synthetic mobile money dataset, demonstrating robustness and cross-domain generalizability. These findings highlight the effectiveness of combining data preprocessing, resampling techniques, and model optimization for robust fraud detection.},
  archive      = {J_FRAI},
  author       = {Albalawi, Tahani and Dardouri, Samia},
  doi          = {10.3389/frai.2025.1643292},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1643292},
  shortjournal = {Front. Artif. Intell.},
  title        = {Enhancing credit card fraud detection using traditional and deep learning models with class imbalance mitigation},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The potential of DeepSeek for AI-aided diagnosis of antibody-positive autoimmune encephalitis: A single-center, retrospective, observational study. <em>FRAI</em>, <em>8</em>, 1638904. (<a href='https://doi.org/10.3389/frai.2025.1638904'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundAutoimmune encephalitis (AIE) is challenging to diagnose, especially in primary hospitals in China with limited medical resources. DeepSeek, a newly developed AI, shows potential as a cost-effective tool for improving diagnostic efficiency. However, no studies have evaluated the diagnostic accuracy of DeepSeek for AIE.MethodsThis retrospective study included 100 patients with anti-neuronal antibody-positive AIE treated at Ruijin Hospital, Shanghai Jiao Tong University School of Medicine. After removing personally identifiable information, antibody results, and history of immunotherapy from patients’ medical histories, the following information was sequentially input into DeepSeek: sex, age, chief complaint, medical history, EEG findings, head MRI description, and cerebrospinal fluid (CSF) results. The positive rates of AIE diagnoses predicted by DeepSeek were then categorized as most likely diagnosis, differential diagnosis, and total diagnosis.ResultsUsing DeepSeek, the probabilities of AIE appearing as the most likely diagnosis and total diagnosis accuracy were 49 and 65%. When patient data were input stepwise, both the total diagnosis accuracy and the most likely diagnosis accuracy did not significantly increase. AIE patients with anti-MOG and anti-GABAbR positivity had predicted total diagnostic positivity rates of 88 and 100%, respectively. Patients presenting with headache and epilepsy were more likely to be diagnosed with AIE (96 and 100%).ConclusionDeepSeek shows limited positive diagnostic accuracy for predicting the diagnosis of AIE. The application of this new AI technology could be used to promote early screening for AIE in primary hospitals in China, improve medical education, and lead to research advances in AIE.},
  archive      = {J_FRAI},
  author       = {Meng, Huanyu and Tang, Yihua and Qi, Yuanqi and Zhou, Qinming and He, Lu and Chen, Sheng},
  doi          = {10.3389/frai.2025.1638904},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1638904},
  shortjournal = {Front. Artif. Intell.},
  title        = {The potential of DeepSeek for AI-aided diagnosis of antibody-positive autoimmune encephalitis: A single-center, retrospective, observational study},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The perceived impact of artificial intelligence on academic learning. <em>FRAI</em>, <em>8</em>, 1611183. (<a href='https://doi.org/10.3389/frai.2025.1611183'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative artificial intelligence, such as ChatGPT, is transforming higher education by enabling personalized learning, while raising ethical challenges. This study explores how technical university students perceive and leverage ChatGPT in academic tasks, focusing on motivation, learning outcomes, and ethical awareness. Using the Technology Acceptance Model and Self-Determination Theory, the research surveyed 84 students from a technical university via a 5-point Likert-scale questionnaire. Six salient dimensions of student engagement with ChatGPT emerged: perceived usefulness for problem solving, learning retention and skill acquisition, structured interaction with familiar content, consultation on unfamiliar topics, preference for conciseness, and confidence in the accuracy of AI responses. Students who perceived ChatGPT as a valuable resource for addressing academic problems reported enhanced motivation and competence, and frequent structured interaction was linked to the practice of verifying uncertain information, indicating the emergence of AI literacy. However, extensive reliance was correlated with dependence and limited citation practices, revealing risks to academic integrity. By examining ChatGPT’s role in STEM education, this study substantiates the relevance of AI literacy training and institutional policies to ensure responsible use. The findings offer practical insights for educators to integrate AI tools effectively while fostering critical thinking and academic integrity in technology-driven learning environments.},
  archive      = {J_FRAI},
  author       = {Dogaru, Mariana and Pisică, Olivia and Popa, Cosmin-Ștefan and Răgman, Andrei-Adrian and Tololoi, Ilinca-Roxana},
  doi          = {10.3389/frai.2025.1611183},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1611183},
  shortjournal = {Front. Artif. Intell.},
  title        = {The perceived impact of artificial intelligence on academic learning},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heart rates, facial expressions and self-reports: A multimodal longitudinal approach of learners' emotions in the foreign language classroom. <em>FRAI</em>, <em>8</em>, 1604110. (<a href='https://doi.org/10.3389/frai.2025.1604110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotions in educational settings are often studied through self-reports or lab experiments, limiting insights into their real-world dynamics. This study examines learner emotions in authentic foreign language classrooms using a multimodal longitudinal approach. Over 16 consecutive sessions, we collected heart rate (HR) signals, emotional facial expressions (EFE), classroom observations, and self-reports on enjoyment, anxiety, and boredom to capture both physiological and self-perceived emotional responses. Rather than aggregating data across students, we focused on individualized emotional patterns to understand variations in emotional experiences. Each dataset included extensive video recordings, continuous HR monitoring, detailed observational notes, and post-session questionnaires, providing a high-resolution picture of emotional dynamics. Using unsupervised clustering techniques, we identified key emotional episodes—peaks and drops in physiological arousal (heart rate variation) and facial expression—relative to individual emotional baselines. These moments were cross-referenced with classroom observations and self-reports for validation. Findings highlight moments of positive emotional contagion during peer interactions, emphasizing the social dimension of language learning. This multimodal approach captures the interplay of physiological, behavioral, and subjective responses, offering a scalable method for studying classroom emotions. Methodologically, it demonstrates how multimodal analytics can uncover transient emotional states in real-world settings, while practically informing adaptive teaching strategies, such as leveraging peer interactions to enhance engagement or reduce anxiety. By integrating physiological, behavioral, and subjective data, this study provides a comprehensive framework for understanding the affective dimensions of learning.},
  archive      = {J_FRAI},
  author       = {Guedat-Bittighoffer, Delphine and Moufidi, Abderrazzaq and Dewaele, Jean-Marc and Rousseau, David and Voyneau, Hugo and Rasti, Pejman},
  doi          = {10.3389/frai.2025.1604110},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1604110},
  shortjournal = {Front. Artif. Intell.},
  title        = {Heart rates, facial expressions and self-reports: A multimodal longitudinal approach of learners' emotions in the foreign language classroom},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
