<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ASOC</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="asoc">ASOC - 71</h2>
<ul>
<li><details>
<summary>
(2025). Detail-aware semantic segmentation network for brain tumor MRI images combining multi-frequency directional filtering and lifting wavelets. <em>ASOC</em>, <em>185</em>, 113969. (<a href='https://doi.org/10.1016/j.asoc.2025.113969'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumors segmentation in Magnetic Resonance Imaging (MRI) images poses significant challenges owing to the uncertain location and size of the tumors, the difficulty in describing their boundaries, and the fuzzy demarcation of diseased tissues. Although U-Net and its recent variants have emerged as leading models for semantic segmentation in medical imaging, they still face structural limitations. These limitations cause the erosion of detail information during downsampling and poor performance in segmenting small lesions when handling targets of varying sizes, indicating a lack of detail handling capability. To counteract these issues, we designed a segmentation model that enhances detail features using frequency information. To reduce the loss of feature information during downsampling, we developed a downsampling module based on lifting wavelets. By lifting wavelets to group and integrate features according to frequency from high to low, we reduce feature resolution while enhancing information transmission and minimizing feature information loss. In our designed multi-frequency directional filtering edge feature extraction module, we extract low-frequency and high-frequency features and construct a dual-channel multi-directional filtering combination. This combination extracts directional information from low-frequency and high-frequency features separately, increasing the multi-angle directional information of the features and enriching the detailed information such as direction and position within the features. On the BraTS2018, BraTS2020, and BraTS2024 brain tumor datasets, our model demonstrated optimal results compared to 14 other advanced models. The average Dice Similarity Coefficients are 78.48 %, 79.80 %, and 74.35 %, while the 95th percentile Hausdorff Distances are 5.75, 6.60, and 7.72. Our code link is https://github.com/Eric-H8/BraTS_Seg_Model .},
  archive      = {J_ASOC},
  author       = {Xin Hua and Zhijiang Du and Hongjian Yu and Zibo Li and Qiaohui Lu and Hui Zhao},
  doi          = {10.1016/j.asoc.2025.113969},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113969},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Detail-aware semantic segmentation network for brain tumor MRI images combining multi-frequency directional filtering and lifting wavelets},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extracting knowledge from limited data: An updated review of data-driven and model-driven few-shot learning for agriculture. <em>ASOC</em>, <em>185</em>, 113968. (<a href='https://doi.org/10.1016/j.asoc.2025.113968'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has demonstrated considerable success in agricultural applications. However, its conventional implementations heavily depend on large-scale labelled datasets—a requirement that is often impractical in agriculture due to data scarcity, high annotation costs, or environmental variability. While insufficient training data can significantly limit the performance of standard deep learning models, Few-Shot Learning (FSL) has emerged as a transformative paradigm, enabling robust model training with minimal labelled samples by utilising limited data for training instead. Despite its potential, a critical review assessing how FSL addresses expert system challenges in agriculture remains notably absent. This paper attempts to fill this void by presenting an updated comprehensive review of FSL's applications in agriculture. We categorise FSL methodologies into two primary approaches: data processing-driven and model learning-driven. Data processing–driven approaches address data scarcity by enriching representational diversity through synthetic samples generated with models such as generative adversarial networks, or by transferring knowledge from related domains to improve generalisation. In contrast, model learning–driven strategies confront the same challenge through specialised architectures and optimisation techniques that enable effective generalisation from limited samples. Within this taxonomy, data processing–driven paradigms include transfer learning and generative artificial intelligence, while model learning–driven paradigms cover metric learning methods such as Siamese or prototypical networks, together with model-based and optimisation approaches designed for efficient generalisation. Our analysis pinpoints cutting-edge technologies within each sector, shedding light on overlooked areas and opportunities where FSL can harness limited data to yield promising outcomes when used to solve problems in agriculture.},
  archive      = {J_ASOC},
  author       = {Kam Meng Goh and Usman Ullah Sheikh and Jun Kit Chaw and Weng Kin Lai and Weng Chun Tan and Santhi Krishnamoorthy},
  doi          = {10.1016/j.asoc.2025.113968},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113968},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Extracting knowledge from limited data: An updated review of data-driven and model-driven few-shot learning for agriculture},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coverage exploration of unknown obstacle-cluttered environments using a swarm of ground robots. <em>ASOC</em>, <em>185</em>, 113964. (<a href='https://doi.org/10.1016/j.asoc.2025.113964'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a coverage exploration algorithm for unknown obstacle-cluttered environments using a swarm of ground robots. A key contribution of this work is the proposed fitness function, which balances multiple exploration objectives and encourages robots to disperse effectively, avoiding excessive overlapping visits. The robots are assumed to start from a single corner of the environment, reflecting practical situations where pre-distributing them is not feasible. This setup highlights a key feature of the algorithm, as it enables self-organization and effective distribution of the robots throughout the environment. The robustness of the method is demonstrated through experiments in various environmental setups, showing its resilience to different obstacle structures and reliable performance across diverse scenarios. The approach also leverages the benefits of swarm behavior, where an increasing number of robots improves exploration efficiency through enhanced collaboration and coverage. The algorithm is evaluated against a swarm random walk approach and two multi-robot meta-heuristic methods, significantly outperforming them in terms of coverage efficiency and robustness.},
  archive      = {J_ASOC},
  author       = {Khalil Al-rahman Youssefi and Wilfried Elmenreich},
  doi          = {10.1016/j.asoc.2025.113964},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113964},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Coverage exploration of unknown obstacle-cluttered environments using a swarm of ground robots},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WamGLM: A multimodal large-scale language model for wafer map defect information in-depth query through multi-turn dialogue based on prototypical supervised contrastive learning. <em>ASOC</em>, <em>185</em>, 113962. (<a href='https://doi.org/10.1016/j.asoc.2025.113962'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To ensure production efficiency and process stability in semiconductor manufacturing, it is of critical importance to detect wafer map defects and perform information query for tracing and solving problems during the manufacturing process. Numerous vision models based on deep learning have been successfully applied to wafer map defect recognition (WMDR), yielding remarkable results. However, the dynamic and in-depth querying of wafer map defect information remains relatively underexplored. Leveraging the rapid advancements in multimodal large language models (MLLMs), this paper proposes a novel approach for wafer map defect information query (WMDIQ). First, following the paradigm of employing cross-modal alignment model to bridge vision and language models, an end-to-end response MLLM: general language model for wafer map (WamGLM), is constructed for WMDIQ. Concurrently, by designing an interactive dialogue framework between large language models (LLMs), the first large-scale multi-turn dialogue dataset: visual multi-turn question answering dataset for wafer map defects (WaferMapVMQA Dataset), is constructed for wafer map defect analysis. Subsequently, WamGLM is trained using a two-stage fine-tuning strategy. In the first stage, a visual fine-tuning method based on prototypical supervised contrastive learning (PSCL) is introduced to enhance the intra-class compactness and inter-class separability of defect features. In the second stage, language fine-tuning is conducted using the WaferMapVMQA Dataset to infuse specialized knowledge into WamGLM. To validate the effectiveness and superiority of the proposed method, experiments are conducted on a real wafer map dataset. The results demonstrate that the proposed method significantly outperforms other methods in both defect recognition performance and information query response performance. Our code is available at: https://github.com/ZihaoLei/WamGLM .},
  archive      = {J_ASOC},
  author       = {Shulong Gu and Zihao Lei and Guangrui Wen and Quanning Xu and Zhaojun Steven Li and Xuefeng Chen and Chunsheng Yang},
  doi          = {10.1016/j.asoc.2025.113962},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113962},
  shortjournal = {Appl. Soft. Comput.},
  title        = {WamGLM: A multimodal large-scale language model for wafer map defect information in-depth query through multi-turn dialogue based on prototypical supervised contrastive learning},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-criteria linguistic optimization for covert communication in secure LLM-based steganography. <em>ASOC</em>, <em>185</em>, 113960. (<a href='https://doi.org/10.1016/j.asoc.2025.113960'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel framework for covert communication through secure steganography using large language models (LLMs). Our approach leverages multi-criteria linguistic optimization to encode secret information directly into stylistic features of auto-regressively generated text. This strategy balances embedding capacity with naturalness and coherence. The secret message is partitioned into fixed-size blocks. Each block is embedded into binary stylistic feature vectors via a surjective linear mapping, which introduces redundancy. This redundancy enables the use of a history-aware cost function that selects stylistic vectors to minimize abrupt transitions and preserve fluency across sentences. Candidate sentences are generated by prompting LLMs with contextual and stylistic constraints. Rejection sampling then ensures exact feature matching and high linguistic quality. Experimental evaluation in multiple LLMs, diverse text contexts, and parameter settings demonstrates effective embedding capacities of up to 0.30 bits per token while maintaining strong linguistic naturalness, validated through perplexity, lexical diversity, readability, and a linguistic acceptability metric. Importantly, decoding recovers the full secret with zero error under ideal conditions. This confirms the reliability of the method. The current work focuses on embedding efficiency and imperceptibility. Robustness against active text alterations and formal undetectability assessments remain open challenges for future research. The proposed multi-criteria linguistic optimization framework offers a promising avenue for advanced covert communication by harmonizing secure information embedding with fluent, human-like language generation.},
  archive      = {J_ASOC},
  author       = {Kamil Woźniak and Marek R. Ogiela and Lidia Ogiela},
  doi          = {10.1016/j.asoc.2025.113960},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113960},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-criteria linguistic optimization for covert communication in secure LLM-based steganography},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A granularity time series forecasting model combining three-way decision and trend information granule. <em>ASOC</em>, <em>185</em>, 113957. (<a href='https://doi.org/10.1016/j.asoc.2025.113957'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term forecasting of time series plays a vital role across diverse applications but is challenged by error accumulation arising from recursive predictions and the insufficient retention of trend information in conventional methods. To tackle these issues, we propose a novel forecasting model based on granular time series (GTS). The model utilizes an improved L 1 -trend filtering technique to achieve optimal segmentation of information granules, preserving essential trend features. Subsequently, we introduce dual evaluation functions based on distance similarity to jointly drive the three-way decision (TWD) process for aggregating information granules, thereby effectively reducing error propagation. Finally, the aggregated granules serve as inputs to a long short-term memory (LSTM) neural network to generate accurate forecasts. In addition, the proposed model is evaluated on several real-world datasets through sensitivity and comparative analyses. The results demonstrate that the model exhibits strong performance in long-term forecasting tasks.},
  archive      = {J_ASOC},
  author       = {Jianuan Qiu and Shuhua Su and Jingjing Qian},
  doi          = {10.1016/j.asoc.2025.113957},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113957},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A granularity time series forecasting model combining three-way decision and trend information granule},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective genetic programming for binary classification with adaptive thresholds and a generalization-optimizing fitness function. <em>ASOC</em>, <em>185</em>, 113956. (<a href='https://doi.org/10.1016/j.asoc.2025.113956'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic programming (GP) has been widely applied to classifier construction due to its flexible representation and powerful feature construction capabilities. Existing studies have proposed various fitness functions to improve GP-based classifiers, but most of them rely on a fixed decision threshold. However, when dealing with imbalanced classification problems, a fixed threshold often biases the model toward the majority class, thereby compromising overall performance. To address this issue, in this paper, we propose a novel multi-objective GP framework for constructing binary classifiers with adaptive threshold adjustment. During evolution, the method employs Youden’s Index to dynamically adjust the threshold of each individual, enabling the classifiers to better fit the underlying data distribution. In addition, we introduce a new class separation metric, dist t , to quantify the clarity of class boundaries and enhance the generalization ability of the evolved models. The framework jointly optimizes three objectives: minority class accuracy, majority class accuracy, and the proposed dist t metric. Experiments on 14 imbalanced datasets demonstrate that our method significantly outperforms conventional single-objective GP with fixed thresholds. Further results also confirm the positive impact of the proposed dist t metric on classification performance. Compared to seven existing GP algorithms and five traditional machine learning classifiers, our approach achieves superior overall performance and better generalization ability.},
  archive      = {J_ASOC},
  author       = {Minghui Bai and Yuan Gao and Xiaoying Gao and Jianbin Ma},
  doi          = {10.1016/j.asoc.2025.113956},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113956},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-objective genetic programming for binary classification with adaptive thresholds and a generalization-optimizing fitness function},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive fuzzy entropy optimization with opposition-based archimedes search for robust multilevel image segmentation. <em>ASOC</em>, <em>185</em>, 113943. (<a href='https://doi.org/10.1016/j.asoc.2025.113943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation plays a critical role in diverse computer vision applications. Multilevel thresholding (MLT) remains one of its most widely used unsupervised techniques due to its simplicity and interpretability. However, existing MLT methods often suffer from two major limitations: (1) the inability to adapt to local intensity variations and (2) the computational burden associated with high-dimensional threshold search. To address these challenges, this study proposes a novel segmentation framework that integrates a Proximity-Adaptive Fuzzy Entropy (PAFE) model with an Opposition-Based Learning-enhanced Archimedes Optimization Algorithm (OBL-EAOA). The PAFE model utilizes dynamically adjusted trapezoidal membership functions based on intensity proximity to candidate thresholds, allowing for a more adaptive and smooth entropy surface. Meanwhile, the OBL-EAOA enhances optimization performance through opposition-based learning and adaptive parameter control, improving exploration diversity and convergence speed. The proposed PAFE-EAOA framework is validated on two benchmark datasets, BSD500 and PASCAL VOC 2012, using five standard metrics: PSNR, SSIM, FSIM, SNR, and computation time. Compared with several state-of-the-art methods including Kapur Entropy (KE)-EAOA, Fuzzy Entropy (FE)-EAOA, Patch-Levy-Based Bees Algorithm (PLBA), Marine Predators Algorithm (MPA), Improved Grey Wolf Optimizer (IGWO), and standard Archimedes Optimization Algorithm (AOA), the proposed approach consistently achieves superior segmentation quality. Notably, it reduces computation time by up to 60 % and achieves statistically significant improvements, as confirmed by the Wilcoxon signed-rank test. These results demonstrate the framework’s robustness, scalability, and effectiveness for real-world MLT-based image segmentation.},
  archive      = {J_ASOC},
  author       = {Anusha Ganesan and Sungho Kim and Ganesan Nagabushnam},
  doi          = {10.1016/j.asoc.2025.113943},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113943},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive fuzzy entropy optimization with opposition-based archimedes search for robust multilevel image segmentation},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DT and LLM driven intelligent maintenance system for L-DED and DAG-based LLM fault diagnosis evaluation framework. <em>ASOC</em>, <em>185</em>, 113942. (<a href='https://doi.org/10.1016/j.asoc.2025.113942'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal additive manufacturing (AM) has revolutionized industries such as aerospace and automotive manufacturing due to its ability to rapidly prototype complex structures. Laser Directed Energy Deposition (L-DED) is a key AM technique, offering high deposition rates and superior mechanical properties. However, the inherent complexity and high cost of L-DED equipment demand reliable maintenance management to minimize downtime. Traditional maintenance approaches struggle to keep pace with escalating production demands and to cope with growing equipment complexity. To address this, we propose a dual-driven intelligent maintenance system for L-DED, integrating Digital Twins (DT) and Large Language Models (LLMs). The system features a comprehensive DT framework that synchronizes the virtual entity with the physical one in real time, it also incorporates an intelligent maintenance Q&A assistant powered by Retrieval-Augmented Generation (RAG), leveraging L-DED maintenance knowledge bases to provide accurate operational support. Additionally, we propose a Directed Acyclic Graphs (DAG)-based framework to assess LLMs’ ability to guide users through complete fault diagnosis. Our work aims to enhance the reliability and efficiency of L-DED maintenance through advanced digital technologies, ultimately improving productivity and reducing downtime in additive manufacturing.},
  archive      = {J_ASOC},
  author       = {Jian Tang and Shitong Peng and Jianan Guo and Danya Song and Dongna Gao and Weiwei Liu and Fengtao Wang},
  doi          = {10.1016/j.asoc.2025.113942},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113942},
  shortjournal = {Appl. Soft. Comput.},
  title        = {DT and LLM driven intelligent maintenance system for L-DED and DAG-based LLM fault diagnosis evaluation framework},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new large model with multi-scale feature fusion for fault diagnosis based on unified time series model. <em>ASOC</em>, <em>185</em>, 113941. (<a href='https://doi.org/10.1016/j.asoc.2025.113941'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large model technology exemplified by large language models has been applied in the field of industrial fault diagnosis. However, existing large models are optimized for specific equipment types and have yet to fully exploit the potential of time-series monitoring data to enable widespread application across diverse mechanical equipment in various industrial scenarios. To address this challenge, a fault diagnosis large model (UniTS-FD) is designed based on unified time series model (UniTS). First, a multi-scale feature fusion backbone network is developed based on UniTS backbone to capture general mechanical fault features. Second, the fault classification head integrates the Pearson correlation coefficient to assess the similarity of class information within linear space for enabling adaptive classification. Third, P-LoRA fine-tuning approach incorporating LoRA and prompt technology is proposed to fine-tune the fault classification head, which enhances the generalization ability of the UniTS-FD model for fault diagnosis tasks of various mechanical equipment. Finally, the UniTS-FD model is pre-trained on 11 fault datasets and fine-tuning experiments were conducted on four different fault datasets to achieve cross-machine fault diagnosis. Experimental results demonstrate the effectiveness of the UniTS-FD in fault diagnosis tasks.},
  archive      = {J_ASOC},
  author       = {Zhiwei Zhang and Chengbin Wei and Weimin Zhang and Long Wen},
  doi          = {10.1016/j.asoc.2025.113941},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113941},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A new large model with multi-scale feature fusion for fault diagnosis based on unified time series model},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A federated learning-based method for personalized manufacturing service recommendation with collaborative relationships. <em>ASOC</em>, <em>185</em>, 113940. (<a href='https://doi.org/10.1016/j.asoc.2025.113940'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the industrial Internet environment, the increasing complexity of manufacturing tasks has rendered them no longer accomplishable by independent manufacturing services. Meanwhile, current recommendation systems predominantly face challenges in maintaining data privacy and security during client parameter exchanges. To address these issues, this paper proposes CoFedSVD+ +, a federated learning-based method for personalized manufacturing service recommendation that integrates an enhanced SVD+ + algorithm with homomorphic encryption. First, we devise an enhanced similarity calculation method to analyze collaborative relationships among manufacturing services. Second, we implement a homomorphic encryption protocol within the federated learning framework to resolve data isolation challenges. Third, the improved SVD+ + algorithm is employed to capture implicit feedback information and predict missing Quality of Service (QoS) metrics. Fourth, a Top-N service composition recommendation list is generated through synergistic analysis of collaborative relationships and QoS predictions. Finally, we validate our approach using real-world case data from an industrial Internet platform. Experimental comparisons with existing recommendation algorithms demonstrate superior recommendation effectiveness of the proposed method.},
  archive      = {J_ASOC},
  author       = {Lei Wang and Jun Wang and Feng Xiang and Tongshun Li and Yang Xu and Yibing Li},
  doi          = {10.1016/j.asoc.2025.113940},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113940},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A federated learning-based method for personalized manufacturing service recommendation with collaborative relationships},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Span-level emotion-cause-category triplet extraction with instruction tuning LLMs and data augmentation. <em>ASOC</em>, <em>185</em>, 113938. (<a href='https://doi.org/10.1016/j.asoc.2025.113938'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Span-level emotion-cause-category triplet extraction is a fine-grained task in emotion cause analysis that aims to identify emotion spans, cause spans, and their corresponding emotion categories from documents. Existing methods, including clause-level emotion-cause pair extraction and span-level emotion-cause detection, often suffer from redundant information and difficulties in accurately classifying emotion categories, particularly when emotions are expressed implicitly or ambiguously. To overcome these challenges, this study explores a fine-grained approach to span-level emotion-cause-category triplet extraction and introduces an innovative framework that leverages instruction tuning and data augmentation techniques based on large language models. The proposed method employs task-specific triplet extraction instructions and utilizes low-rank adaptation to fine-tune large language models, eliminating the necessity for intricate task-specific architectures. Furthermore, an LLM-based data augmentation strategy is developed to address data scarcity by guiding large language models in generating high-quality synthetic training data. Extensive experimental evaluations demonstrate that the proposed approach significantly outperforms existing baseline methods, achieving at least a 12.8 % improvement in span-level emotion-cause-category triplet extraction metrics. The results demonstrate the method’s effectiveness and robustness, offering a promising avenue for advancing research in emotion cause analysis.},
  archive      = {J_ASOC},
  author       = {Xiangju Li and Dong Yang and Xiaogang Zhu and Faliang Huang and Peng Zhang and Zhongying Zhao},
  doi          = {10.1016/j.asoc.2025.113938},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113938},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Span-level emotion-cause-category triplet extraction with instruction tuning LLMs and data augmentation},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep cross-visual semantic hashing with self-calibrated collaborative attention. <em>ASOC</em>, <em>185</em>, 113937. (<a href='https://doi.org/10.1016/j.asoc.2025.113937'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep hashing has garnered considerable attention due to its remarkable retrieval efficiency and low storage cost, particularly in visual retrieval scenarios. However, current deep hashing methods generally integrate hash coding into a single-stream architecture, which limits the discriminative power of learned visual features and yields suboptimal hash codes. Additionally, over-reliance on semantic labels shared across samples fails to fully exploit the intrinsic semantic correlations between labels and corresponding visual features. To address these issues, we propose a deep cross-visual semantic hashing (DCvSH) method for image retrieval. First, we develop a visual image feature decoupling encoding network that leverages a self-calibrated collaborative attention mechanism to disentangle common and specific semantics across related images. These decoupled features are fed into a shared decoder for image reconstruction, yielding discriminative visual feature representations. Second, we construct a cross-visual semantic representation learning network with a two-level multi-layer perceptron to capture the underlying relationships between semantic label encodings and visual feature embeddings, while a hypergraph structure is introduced to preserve pairwise similarity relationships. Experimental results on the CIFAR-10, NUS-WIDE, and MIRFLICKR datasets demonstrate consistent improvements, with average mean average precision (mAP) scores reaching 0.895, 0.874, and 0.881 at different code lengths, respectively. Notably, DCvSH outperforms other baselines across all evaluation metrics.},
  archive      = {J_ASOC},
  author       = {Hao Feng and Xiangbo Zhou and Yue Wu and Jian Zhou and Banglei Zhao},
  doi          = {10.1016/j.asoc.2025.113937},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113937},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep cross-visual semantic hashing with self-calibrated collaborative attention},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large model for fault diagnosis of industrial equipment based on a knowledge graph construction. <em>ASOC</em>, <em>185</em>, 113936. (<a href='https://doi.org/10.1016/j.asoc.2025.113936'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the significant heterogeneity of multi-modal data and the challenges in capturing fault semantics for industrial equipment, a fault diagnosis framework that integrates a time-frequency knowledge graph with the large model DeepSeek-V3 is proposed. Specifically, an unsupervised knowledge graph construction method is designed based on multi-modal vibration data signals. This method mines temporal evolution relationships using dynamic time warping and quantifies the relevance between features and faults via mutual information, thereby forming a dynamic graph representation. Additionally, DeepSeek-V3 encodes the natural language descriptions of vibration features, integrating graph structure and time-frequency map features to achieve collaborative reasoning and diagnosis among text, graphs, and maps. Experimental results show that the proposed method achieves high accuracy and significantly outperforms benchmark models, surpassing traditional methods. The proposed framework, through the deep integration of data-driven knowledge graphs and large model semantic understanding, demonstrates high precision, strong robustness, and transparent decision-making capabilities, providing new insights for intelligent diagnosis of industrial equipment.},
  archive      = {J_ASOC},
  author       = {Jichao Zhuang and Jiaming Yang and Weigang Li and Jian Chen and Yunjun Zheng and Zhuyun Chen},
  doi          = {10.1016/j.asoc.2025.113936},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113936},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Large model for fault diagnosis of industrial equipment based on a knowledge graph construction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interval-valued pythagorean fuzzy distance-based extended inferior ratio method for multiattribute decision-making: Application to green supplier selection in manufacturing industry. <em>ASOC</em>, <em>185</em>, 113935. (<a href='https://doi.org/10.1016/j.asoc.2025.113935'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval-valued Pythagorean fuzzy sets (IVPFSs) have emerged as a powerful tool for handling uncertainty and vagueness in multiattribute decision-making (MADM). In this paper, we first propose a novel distance measure for IVPFSs based on triangular divergence, which satisfies all core distance axioms and significantly improves discrimination ability compared to existing measures. Building on this, we introduce a maximizing deviation strategy with a new loss function to objectively determine attribute weights. Furthermore, we develop an extended inferior ratio (EIR) method that incorporates a dynamic weight parameter to flexibly balance the influence of positive and negative ideal solutions. The performance of the proposed method is demonstrated through a case study on green supplier selection in the manufacturing industry. The results indicate that, among the seven criteria evaluated, the most suitable suppliers are ranked as follows: β (1.0000), α (0.6471), δ (0.3500), ϵ (0.0690), and θ (0.0000). In addition, sensitivity and comparative analyses confirm the robustness and consistency of the proposed method, reflecting its effectiveness and practical value for sustainable decision-making in real-world scenarios.},
  archive      = {J_ASOC},
  author       = {Zhe Liu and Donglai Wang and Muhammet Deveci and Sukumar Letchmunan},
  doi          = {10.1016/j.asoc.2025.113935},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113935},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interval-valued pythagorean fuzzy distance-based extended inferior ratio method for multiattribute decision-making: Application to green supplier selection in manufacturing industry},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multidimensional trade performance assessment for integrating sustainability and economic diversification in OECD countries using a spherical fuzzy SIWEC-SPC-based decision support model. <em>ASOC</em>, <em>185</em>, 113934. (<a href='https://doi.org/10.1016/j.asoc.2025.113934'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Countries participate in regional trade blocks to enhance their trade activities and trade performance. This study proposes a novel approach to trade performance assessment, introducing innovations both in terms of performance parameters and methodology. From a performance parameter perspective, the inclusion of sustainable development and economic diversity levels in trade performance evaluation differentiates this study from traditional trade performance measurement approaches. From a methodological perspective, a hybrid model that simultaneously considers both subjective and objective criterion weighting based on expert opinions is introduced. The spherical fuzzy (SF)−simple weight calculation (SIWEC)−symmetry point of criterion (SPC)−opportunity losses-based polar coordinate distance (OPLO-POCOD) model, developed as a decision support system, is proposed for evaluating the trade performance of country blocs. SF-SIWEC is employed as the subjective criterion weighting method, while SPC serves as the objective criterion weighting method. The OPLO-POCOD alternative ranking method is employed to calculate the trade performance of countries. The proposed methodology is applied to the Organization for Economic Cooperation and Development (OECD) countries. According to the subjective weighting method, "sustainable development (0.0978)" emerges as the most important criterion, whereas in the objective weighting method, "number of product types (export) (0.1612)" is identified as the most significant one. In the final criterion weights, "number of product types (export) (0.1232)" is also determined to be the most important criterion. Considering the final criterion weights, the United States (0.9871) has the highest trade performance among the OECD countries. Thus, when both sustainability and economic diversification are considered, it is understood that the most influential criteria in determining multidimensional trade performance are the number of exported product types and sustainable development. From this perspective, the United States stands out as the country with the highest multidimensional trade performance among OECD countries. This study contributes to the literature by integrating sustainability and economic diversification parameters into trade performance measurement as well as proposing a comprehensive methodology for performance evaluation in trade blocs.},
  archive      = {J_ASOC},
  author       = {Galip Cihan Yalçın and Karahan Kara and Emre Kadir Özekenci and Vladimir Simic and Dragan Pamucar},
  doi          = {10.1016/j.asoc.2025.113934},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113934},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multidimensional trade performance assessment for integrating sustainability and economic diversification in OECD countries using a spherical fuzzy SIWEC-SPC-based decision support model},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing supply routes in a network interdiction model with dual defense operations. <em>ASOC</em>, <em>185</em>, 113933. (<a href='https://doi.org/10.1016/j.asoc.2025.113933'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel bi-level defender–attacker model (BDAM) designed to address real-world homeland defense scenarios. Building on the shortest path network interdiction problem (SPNIP), BDAM incorporates dual defense operations—node interdiction and edge destruction—while explicitly modeling the defender’s supply support. Unlike conventional SPNIP formulations, BDAM jointly considers the attacker’s path disruption and the defender’s logistical requirements, ensuring that all interdicted nodes are supported by available supply nodes without exceeding their capacity. To solve this NP-hard problem, a hybrid metaheuristic algorithm named Improved Simplified Swarm Optimization with Dijkstra (iSSOD) is proposed. The method integrates a population-based SSO framework with a randomized repair mechanism to ensure feasibility and an entropy-guided local search to enhance exploitation. The attacker’s optimal response is computed efficiently using Dijkstra’s algorithm, embedded within the defender’s fitness evaluation. The experimental results on 36 artificial instances demonstrate that iSSOD consistently outperforms several benchmark evolutionary algorithms, providing high-quality solutions through a defense-aware, supply-constrained optimization framework. Furthermore, a real-world case study based on geographic data validates the model’s applicability under realistic defense conditions.},
  archive      = {J_ASOC},
  author       = {Wei-Chang Yeh and Chyh-Ming Lai and Tsung-Hua Wu},
  doi          = {10.1016/j.asoc.2025.113933},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113933},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Optimizing supply routes in a network interdiction model with dual defense operations},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A continuous encoding-based representation for efficient multi-fidelity multi-objective neural architecture search. <em>ASOC</em>, <em>185</em>, 113932. (<a href='https://doi.org/10.1016/j.asoc.2025.113932'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural architecture search (NAS) is a powerful tool for automatically designing optimized deep learning models but is often limited by high computational costs, especially in multi-objective settings. To address this, an adaptive Co-Kriging-assisted multi-fidelity multi-objective NAS algorithm is proposed to reduce the computational cost and accelerate convergence of NAS by incorporating a clustering-based local multi-fidelity infill sampling strategy. Additionally, we introduce a novel continuous encoding method to compactly represent node connections within a generalized U-Net backbone, significantly reducing search dimensionality. Extensive experiments demonstrate that our method consistently outperforms state-of-the-art NAS approaches under limited computational budgets on three benchmarks, a 2D Darcy flow regression task, a CHASE_DB1 biomedical image segmentation task, and an urban wind velocity prediction task. Analysis further shows that our algorithm autonomously identifies design patterns consistent with expert-curated U-Net variants in literature, confirming its efficiency and potential for insight into performant architectures.},
  archive      = {J_ASOC},
  author       = {Zhao Wei and Chin Chun Ooi and Yew-Soon Ong},
  doi          = {10.1016/j.asoc.2025.113932},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113932},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A continuous encoding-based representation for efficient multi-fidelity multi-objective neural architecture search},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-learning-based adaptive operator selection for traveling salesman problem. <em>ASOC</em>, <em>185</em>, 113930. (<a href='https://doi.org/10.1016/j.asoc.2025.113930'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In evolutionary optimization, effectively leveraging knowledge about search operator performance is crucial for enhancing algorithmic results. Traditional operator selection strategies often rely on fixed heuristics or trial-and-error, which struggle to adapt to the nonstationary search dynamics of evolutionary runs—i.e., the stage-dependent, instance-dependent, and population-dependent shifts in operator effectiveness—and typically yield suboptimal performance. To address these challenges, we propose a novel meta-learning-based adaptive operator selection (AOS) framework. It leverages a Long Short-Term Memory (LSTM) neural network to learn temporal patterns of operator performance from historical data and dynamically adjust operator choice on-the-fly. The framework also integrates domain-specific biases to preserve population diversity and promote effective exploration, and it continuously updates its selection policy through dynamic online learning as the evolutionary process unfolds. Experiments on the Traveling Salesman Problem (TSP) benchmark demonstrate that the proposed LSTM-based AOS method significantly outperforms conventional approaches to operator selection. In particular, it achieved a median optimality gap of 9.87 % on a suite of TSP instances—approximately a 20 % improvement over the best fixed-operator configuration—indicating superior solution quality. Moreover, our approach consistently surpassed other state-of-the-art AOS techniques, underscoring the efficacy of the LSTM-driven framework and its significant potential to enhance evolutionary algorithm performance on complex optimization tasks.},
  archive      = {J_ASOC},
  author       = {Ho Young Jeong and Byung Duk Song},
  doi          = {10.1016/j.asoc.2025.113930},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113930},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Meta-learning-based adaptive operator selection for traveling salesman problem},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast and robust ensemble evolving pixel cloud-based image segmentation approach. <em>ASOC</em>, <em>185</em>, 113926. (<a href='https://doi.org/10.1016/j.asoc.2025.113926'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing cluster-based image segmentation algorithms have the burden of iterative computation caused by the change of cluster centers and are sensitive to noise. In this paper, we present a fast and robust ensemble evolving pixel cloud-based image segmentation approach. The concept of pixel clouds by clustering pixels of the same pattern around their focal pixels is proposed. The following attributes distinguish the proposed algorithm: (1) The pixel clouds are evolvable according to the global densities of the incoming pixels and the number of pixel clouds is automatically determined. (2) The focal pixels of pixel clouds are dynamically updated with the highest local densities by using the recursive density estimation, which avoids redundant distance calculations when a new pixel arrives. (3) A multiscale morphological gradient reconstruction operation is employed to merge or filter meaningless pixel clouds, especially in noisy images, which helps to adaptively polish neighboring pixel clouds and compact the pixel clouds. (4) An ensemble structure is introduced to fasten the image segmentation speed by splitting the whole image into multiple independent sub-images, in which the pixel clouds are independently formed and evolved. Comprehensive experiments on natural images, remote sensing images and medical images reveal that the proposed approach surpasses the state-of-the-art algorithms in both segmentation accuracy and computational efficiency. Even for the noisy images, the proposed approach demonstrates more robust performance.},
  archive      = {J_ASOC},
  author       = {Tao Zhang and Hai-Jun Rong and Zhao-Xu Yang and Chi-Man Vong},
  doi          = {10.1016/j.asoc.2025.113926},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113926},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A fast and robust ensemble evolving pixel cloud-based image segmentation approach},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A data-driven approach to tackling academic stress-coping and mental health issues in college students using spherical fuzzy MARCOS methodology. <em>ASOC</em>, <em>185</em>, 113925. (<a href='https://doi.org/10.1016/j.asoc.2025.113925'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The drastically developing nature of the knowledge economy and the rising need for top-notch expertise have placed tremendous pressure on college students. As higher education becomes more accessible, masses of students are enrolling in colleges, which puts additional pressure on colleges and institutions; as a result, they cannot provide adequate resources to the students. As the class size increases, many students require mental health assistance, academic guidance, and financial aid, which then puts pressure on the teachers and the facilities. This flood of students overloads the facilities, resulting in it becoming more challenging to provide attention and concern, leading many students to feel overlooked and affecting their mental health. Due to not getting timely support, students may find it challenging to handle their academic responsibilities. Moreover, the students face a heavy workload, unclear guidance, and limited resource access. The objective of this study is to develop a structured, data-driven decision-making framework for systematically evaluating and improving student mental health and academic stress-coping strategies in a college setting. To address this, a comprehensive decision-making structure, measurement of alternatives, and ranking according to the compromised solution (MARCOS) within the spherical fuzzy (SF) environment, has been applied, which evaluates the key factors causing mental health issues by comparing the ideal and anti-ideal alternatives. The novelty of the proposed approach lies in leveraging the SF framework’s explicit ability to model hesitation (abstinence) alongside truth and falsity degrees, enabling more accurate representation of subjective psychological assessments compared to traditional fuzzy models. Furthermore, the method calculates utility functions corresponding to each alternative (coping technique), prioritizes the strategies, and selects the most effective intervention. The results reveal that personalized mental health plans emerged as the top-ranked coping strategy, highlighting the importance of tailored support in culturally and contextually diverse academic environments.},
  archive      = {J_ASOC},
  author       = {Raiha Imran and Munazza Amin and Kifayat Ullah and Dragan Pamucar and Zeeshan Ali and Oumaima Saidani and Vladimir Simic},
  doi          = {10.1016/j.asoc.2025.113925},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113925},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A data-driven approach to tackling academic stress-coping and mental health issues in college students using spherical fuzzy MARCOS methodology},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Secure and efficient vehicle control of autonomous vehicles using federated deep reinforcement learning. <em>ASOC</em>, <em>185</em>, 113924. (<a href='https://doi.org/10.1016/j.asoc.2025.113924'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous driving is largely considered a revolutionary technology and the ultimate alternative for smart urban mobility. Artificial Intelligence (AI) has been the main pillar of AV technology. However, despite the significant success achieved through the application of various Deep Reinforcement Learning (DRL) techniques in the field of AVs, numerous challenges remain to be addressed. Particularly, in the case of vehicle control, existing works have shown limited results when extensive action and state spaces are involved, and where the efficacy of agents is often compromised due to the variability of states and actions. In response to these challenges, we introduce a pioneering approach leveraging Federated Deep Reinforcement Learning (FDRL), which fosters the exchange of experiences among participating agents while safeguarding their privacy. FDRL enhances the exploration of all agents’ actions and states in different environments and effectively overcomes the problem of low sample efficiency in action and state spaces for all agents. Our approach is based on three distinct FDRL algorithms: Federated Proximal Policy Optimization (FPPO), Federated Deep Deterministic Policy Gradient (FDDPG), and Federated Deep Q-Network (FDQN), each tailored to control AVs within unique environments. Our results demonstrate the superiority of our approach in terms of average reward, waiting time, and speed, when compared to local models such as PPO, DDPG, and DQN.},
  archive      = {J_ASOC},
  author       = {Badr Ben Elallid and Nabil Benamar and Miloud Bagaa and Nabil Mrani},
  doi          = {10.1016/j.asoc.2025.113924},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113924},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Secure and efficient vehicle control of autonomous vehicles using federated deep reinforcement learning},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simulating phenomenal consciousness using generative agents based on large language models. <em>ASOC</em>, <em>185</em>, 113922. (<a href='https://doi.org/10.1016/j.asoc.2025.113922'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) still face challenges in tasks requiring understanding implicit instructions and applying common-sense knowledge. In such scenarios, LLMs may require multiple attempts to achieve human-level performance, potentially leading to inaccurate responses or inferences in practical environments, affecting their long-term consistency and behavior. This paper introduces the Internal Time-Consciousness Machine (ITCM), a computational consciousness structure to simulate the process of human consciousness. We further propose the ITCM-based Agent (ITCMA), which supports action generation and reasoning in open-world settings, and can independently complete tasks. ITCMA enhances LLMs’ ability to understand implicit instructions and apply common-sense knowledge by considering agents’ interaction and reasoning with the environment. The trained ITCMA performs better than state-of-the-art (SOTA) in the seen set. Even untrained ITCMA can achieve higher task completion rates than SOTA on the seen set, indicating its superiority over traditional intelligent agents in utility and generalization. In real-world tasks with quadruped robots, the task completion rate of untrained ITCMA is close to its performance in the unseen set, demonstrating its comparable utility and universality in real-world settings. CCS Concepts: ∙ Human-centered computing → Interactive systems and tools; ∙ Computing methodologies → Natural language processing.},
  archive      = {J_ASOC},
  author       = {Hanzhong Zhang and Jibin Yin and Haoyang Wang and Ziwei Xiang},
  doi          = {10.1016/j.asoc.2025.113922},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113922},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Simulating phenomenal consciousness using generative agents based on large language models},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Asymmetrical variable driven simulated binary crossover operator for large scale multi-objective optimization. <em>ASOC</em>, <em>185</em>, 113921. (<a href='https://doi.org/10.1016/j.asoc.2025.113921'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the excessive number of decision variables, large scale multi-objective optimization has gradually become a hot research topic over the past few years. Although various reproduction operators have been proposed to effectively generate offspring solutions in the huge decision space, they have a common issue in that most of them are focused on the symmetrical variables and neglect asymmetrical variables. Based on the summary above, it is empirically proved that asymmetrical variables with great similarities play an important role in facilitating each other ′ s effective exploration of the huge decision space. Therefore, to effectively tackle large scale multi-objective optimization problems, the asymmetrical variables are incorporated into the design of a new asymmetrical variable driven simulated binary crossover operator. On the basis of the proposed asymmetrical variable driven simulated binary crossover operator, this paper further constructs a large scale multi-objective evolutionary framework based on asymmetrical variable driven simulated binary crossover operator. Extensive experiments and analyses on typical large scale multi-objective optimization problems with up to 10,000 decision variables and practical engineering problems with 6000 decision variables show its superiority over state-of-the-art optimizers.},
  archive      = {J_ASOC},
  author       = {Maoqing Zhang and Kun Wang},
  doi          = {10.1016/j.asoc.2025.113921},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113921},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Asymmetrical variable driven simulated binary crossover operator for large scale multi-objective optimization},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards agentic smart design: An industrial large model-driven human-in-the-loop agentic workflow for geometric modelling. <em>ASOC</em>, <em>185</em>, 113920. (<a href='https://doi.org/10.1016/j.asoc.2025.113920'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agentic workflows, powered by Industrial Large Models (ILMs), represent a significant development emphasizing collaboration between humans and intelligent systems. This paper presents a structured perspective on the role of agentic workflows for smart design and manufacturing, grounded in integrating ILMs. We define an agentic workflow as a labeled Activity-on-Vertex (AOV) graph, where each node represents a functionally closed subtask and is executed by an ILM-based agent, a human operator, or an automated system. This formalism supports analyzable, modular, and hybrid execution, offering a foundation for modeling complex, mixed-initiative processes in manufacturing environments. To support real-world deployment, we introduce a set of reusable agentic workflow patterns that describe how ILM agents perceive, plan, and act in coordination with other components. Besides, a proof-of-concept case study illustrates the practical application of the human-in-the-loop framework through the agentic generation of CAD models. The study covers task decomposition, workflow implementation, and benchmarking, providing evidence for the feasibility of agentic workflows. Building upon these findings, this work contributes to advancing the development and application of agentic workflows in smart manufacturing contexts.},
  archive      = {J_ASOC},
  author       = {Keyou Zheng and Yuanwei Zhong and Xuyang Su and Jiewu Leng and Qiang Liu and Xin Chen},
  doi          = {10.1016/j.asoc.2025.113920},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113920},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Towards agentic smart design: An industrial large model-driven human-in-the-loop agentic workflow for geometric modelling},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive fault diagnosis of railway vehicle on-board controller with large language models. <em>ASOC</em>, <em>185</em>, 113919. (<a href='https://doi.org/10.1016/j.asoc.2025.113919'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately identifying fault types of the Vehicle On-Board Controller (VOBC) in railway systems is of great significance for ensuring the safe operation of trains. Recently, Large Language Models (LLMs) have demonstrated excellent semantic understanding and natural language interaction capabilities, offering a novel solution for VOBC fault diagnosis. However, LLMs pretrained on general domains lack specific knowledge related to railway VOBC fault diagnosis scenarios, resulting in insufficient adaptability to railway-specific text corpora. This paper conducts an in-depth study on the adaptability of LLMs to VOBC fault diagnosis and proposes Railway Fault Diagnosis Large Language Model (RFD-LLM). First, we adopt railway domain adaptation based on Low-Rank Adaptation (LoRA) to match VOBC fault patterns. Second, instruction tuning is applied to achieve domain knowledge alignment and enhance the model’s ability to follow instructions. The proposed RFD-LLM is the first large language model-based fault diagnosis model for railway VOBC, capable of efficiently and accurately identifying seven types of VOBC fault patterns. RFD-LLM provides a new solution for the development of large models in the railway domain.},
  archive      = {J_ASOC},
  author       = {Cong Peng and Jiali Peng and Zisheng Wang and Zongyao Wang and Junjie Chen and Jianping Xuan and Tielin Shi},
  doi          = {10.1016/j.asoc.2025.113919},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113919},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive fault diagnosis of railway vehicle on-board controller with large language models},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An MADM model using frank operations based power aggregation operator under p,q-quasirung orthopair fuzzy sets for highway selection in war-plane landing. <em>ASOC</em>, <em>185</em>, 113918. (<a href='https://doi.org/10.1016/j.asoc.2025.113918'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In military logistics and operational planning, selecting an optimal highway for war-plane landings and take-offs is a critical and strategic decision. This process involves several key factors that directly affect mission success, operational safety, and public security. Among the most important attributes are the highway’s straight and long stretch with sufficient width to accommodate war-plane landing distances, and its surface condition, which must be free from obstacles, debris, and damage. Low traffic density is crucial to avoid the risk of collisions during landing. Additionally, favourable weather conditions, proximity to military camps, availability of emergency services and fuel, and a secure and hazard-free surrounding terrain are essential for safe and efficient operations. These factors collectively form the backbone of a reliable and tactical approach to highway selection for military air operations. Thus, in order to assess and rank various options for the landing and take-off of war planes, a strong and trustworthy procedure for making decisions is required. The purpose of this experiment is to build a comprehensive structure in multi-attribute decision making environment, using suggested p , q -quasirung orthopair fuzzy Frank power averaging as well as p , q -quasirung orthopair fuzzy Frank power geometric operators to capture ambiguity and uncertainty in highway selection. Furthermore, p , q -quasirung orthopair fuzzy Frank power weighted aggregation along with p , q -quasirung orthopair fuzzy Frank power weighted geometric operators are implemented for integrating the distance as well as similarity measures. Finally, sensitivity analysis and a comparison with the present technique are included to further demonstrate the superiority and validity of the technique that is suggested.},
  archive      = {J_ASOC},
  author       = {Sanjita Giri and Sankar Kumar Roy and Muhammet Deveci},
  doi          = {10.1016/j.asoc.2025.113918},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113918},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An MADM model using frank operations based power aggregation operator under p,q-quasirung orthopair fuzzy sets for highway selection in war-plane landing},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time traffic flow optimization using large language models and reinforcement learning for smart urban mobility. <em>ASOC</em>, <em>185</em>, 113917. (<a href='https://doi.org/10.1016/j.asoc.2025.113917'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of metropolitan populations causes transportation network congestion, which increases fuel usage, travel time, and environmental damage. Traditional traffic management systems (TMS) seldom handle these issues in real time. Recently developed Large Language Models (LLMs), especially those using Reinforcement Learning (RL), may enhance urban transportation systems. Traffic management technology's real-time flexibility and shifting congestion patterns provide improved potential. Traditional approaches cannot estimate traffic flow or adapt to urban settings. A strong AI-driven method is needed to improve urban mobility and traffic flow. This paper introduces the LLM-RL Traffic Optimization Framework (LLM-RL-TOF). LLMs analyze real-time traffic data and give predictive insights in this context. Due to these new insights, the RL algorithm can improve traffic flow in real time and reduce congestion via dynamic traffic management. IoT sensors and urban traffic cameras capture real-time traffic data, including traffic volume and incidents. This data helps the LLM estimate bottlenecks, accidents, and traffic congestion. An RL agent uses LLM outputs to adjust traffic signal timing and suggest alternate routes. With real-time alternatives, traffic flow and urban mobility may be optimized. The junction throughput rate rose 17.5 %, the queue length accumulation index fell 22.3 %, and the average vehicle delay fell 18.6 %. The decrease in average vehicle delay enabled all these gains.},
  archive      = {J_ASOC},
  author       = {Arvind R. Singh and Muhammad Wasim Abbas Ashraf and Rajkumar Singh Rathore and Bin Li and M.S. Sujatha},
  doi          = {10.1016/j.asoc.2025.113917},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113917},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Real-time traffic flow optimization using large language models and reinforcement learning for smart urban mobility},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving speech emotion recognition using gated cross-modal attention and multimodal homogeneous feature discrepancy learning. <em>ASOC</em>, <em>185</em>, 113915. (<a href='https://doi.org/10.1016/j.asoc.2025.113915'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech emotion recognition (SER) remains a significant and crucial challenge due to the complex and multifaceted nature of human emotions. To tackle this challenge, researchers strive to integrate information from diverse modalities through multimodal learning. However, existing multimodal fusion techniques often overlook the intricacies of interactions between different modalities, resulting in suboptimal feature representations. In this paper, we propose WavFusion, a multimodal framework designed for SER that tackles key research challenges, such as effective multimodal fusion, modality heterogeneity, and discriminative representation learning. By utilizing a gated cross-modal attention mechanism and multimodal homogeneous feature discrepancy learning, WavFusion outperforms existing state-of-the-art methods on benchmark datasets. Our research highlights the importance of capturing subtle cross-modal interactions and learning discriminative representations for accurate multimodal SER. Experimental results indicate that the proposed method is highly competitive and better than most of the latest state-of-the-art methods for SER. WavFusion achieves 0.78 % and 1.27 % improvement in accuracy and 0.74 % and 0.44 % improvement in weighted F1 score over the previous methods on the IEMOCAP and MELD datasets, respectively.},
  archive      = {J_ASOC},
  author       = {Feng Li and Jiusong Luo and Wanjun Xia},
  doi          = {10.1016/j.asoc.2025.113915},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113915},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Improving speech emotion recognition using gated cross-modal attention and multimodal homogeneous feature discrepancy learning},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wind turbine blades defect detection based on global and local attention with multi-feature fusion. <em>ASOC</em>, <em>185</em>, 113914. (<a href='https://doi.org/10.1016/j.asoc.2025.113914'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind turbine blades are prone to small-scale defects—such as cracks, corrosion, and contamination—during long-term operation. Accurate detection of these defects is essential for ensuring the safety and efficiency of wind power systems. However, small-object detection remains challenging due to limited feature representation and weak discriminative cues. To address this, an enhanced YOLOX-s-based framework called Global-Frequency Dual-aware YOLOX (GFD-YOLOX) is proposed. GFD-YOLOX introduces three main improvements. First, the Path Aggregation Feature Pyramid Network (PAFPN) in the neck is replaced with Dual-Frequency Fused Bidirectional Feature Pyramid Network (DFF-BiFPN) to strengthen multi-scale contextual representation. Second, the backbone bottleneck is redesigned with a lightweight structure, improving computational efficiency and convergence speed. Third, a Hierarchical Frequency-Adaptive Fusion (HFAF) module is integrated to enhance cross-scale feature interaction by combining fine-grained and global information. On the self-constructed WTBlade-Defect dataset (3570 annotated images, five defect types: corrosion, hide-craze, surface-eye, thunderstrike, dirt), GFD-YOLOX achieves mAP@0.5 and mAP@0.5:0.95 scores of 94.5 % and 68.9 %, respectively, with 44.3 FPS inference—improving by 13.6 % and 14.4 % over state-of-the-art models. On the public dataset of Ashley Foster et al., it achieves 94.8 % and 69.3 %, with gains of 10.4 % and 10.9 %. These results demonstrate that GFD-YOLOX delivers substantial accuracy gains while maintaining real-time speed and strong cross-dataset generalization, indicating high potential for deployment in operational wind turbine inspection systems.},
  archive      = {J_ASOC},
  author       = {Dandan Liu and Mingjie Liu},
  doi          = {10.1016/j.asoc.2025.113914},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113914},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Wind turbine blades defect detection based on global and local attention with multi-feature fusion},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous feature selection with group structure mining in fuzzy decision systems for medical diagnosis. <em>ASOC</em>, <em>185</em>, 113913. (<a href='https://doi.org/10.1016/j.asoc.2025.113913'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical applications such as medical diagnosis and group decision making, the potential structural information contained in multi-dimensional features in the form of group domains plays an important role. However, most existing feature selection methods adopt transformed feature spaces for group structure analysis, which lack intrinsic semantic information interpretation. Meanwhile, fuzzy and uncertain heterogeneous data acquired from multiple devices increase the difficulty of task learning. Motivated by these two issues, this work devises a Heterogeneous Feature Selection method with Group Structure Mining in fuzzy decision systems (HFS-GSM), which follows the principle of one “strategy" and one “mechanism". Specifically, a feature group generation strategy based on fuzzy approximation Markov blanket is first designed for mining features with group structure, which introduces the concept of Markov blanket into the fuzzy rough set and utilizes the idea of approximation and fuzzy uncertainty measures. Then, a fuzzy dependency-based overlapping group elimination mechanism is proposed by attribution division, which avoids local redundancy while preserving global discriminative information. Furthermore, the effectiveness of HFS-GSM is verified in comparison with seven representative feature selection methods on publicly available medical datasets. Finally, medical diagnosis data provided by a hospital are obtained to demonstrate the reliability and utility of HFS-GSM in practical applications.},
  archive      = {J_ASOC},
  author       = {Jihong Wan and Hongmei Chen and Li Xiao and Chuangpeng Shen and Wei Huang and Xiaoping Li},
  doi          = {10.1016/j.asoc.2025.113913},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113913},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Heterogeneous feature selection with group structure mining in fuzzy decision systems for medical diagnosis},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ahybrid ICEEMDAN-BO-GRU model for real-time grouting parameter prediction. <em>ASOC</em>, <em>185</em>, 113912. (<a href='https://doi.org/10.1016/j.asoc.2025.113912'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unit injection volume is one of the core control indicators for evaluating the construction quality of curtain grouting. In actual construction processes, accurate prediction of unit injection volume enables early warning of abnormal conditions during construction. However, geological conditions and construction parameters significantly influence unit injection volume, among other factors, and the data exhibits high nonlinearity. Previous studies have achieved suboptimal prediction accuracy. To address the issue of low prediction accuracy in traditional algorithms when handling highly nonlinear data, this study first applies the Improved Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (ICEEMDAN) algorithm to decompose the raw data, and the nonlinear features in the curtain grouting data are effectively eliminated. Subsequently, the Gated Recurrent Unit (GRU) and Bayesian Optimization (BO) algorithms are organically integrated, and Bayesian optimization is applied to the hyperparameters of the GRU model to enhance its predictive performance, thereby constructing an intelligent predictive model for the curtain grouting unit injection volume. Finally, an engineering application study was conducted using an actual curtain grouting project at a pumped-storage power station. The results indicate that the model exhibits good computational accuracy and efficiency, providing theoretical and methodological support for constructing intelligent prediction models in curtain grouting.},
  archive      = {J_ASOC},
  author       = {Fei Tong and Dongqing Bai and Xufei Ma and Lin Cheng and Jie Yang and Xiangyu Cao},
  doi          = {10.1016/j.asoc.2025.113912},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113912},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Ahybrid ICEEMDAN-BO-GRU model for real-time grouting parameter prediction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DefGCL: Defence-enhanced graph contrastive learning against attribute inference attacks. <em>ASOC</em>, <em>185</em>, 113911. (<a href='https://doi.org/10.1016/j.asoc.2025.113911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-structured data are prevalent in many real-world applications, such as social networks, drug discovery, and fraud detection. While Graph Neural Networks (GNNs) have shown remarkable performance by capturing rich relational patterns, their success often relies on large labeled datasets and raises growing privacy concerns. Graph Contrastive Learning (GCL) has emerged as a powerful unsupervised alternative by leveraging data augmentations to learn robust representations without labeled data. However, recent studies reveal that GCL models are particularly vulnerable to attribute inference attacks, and existing works prioritize performance improvement over privacy protection. To address this issue, we propose a D e f ense-enhanced G raph C ontrastive L earning, dubbed DefGCL , that integrates four coordinated defense strategies to enhance privacy without degrading utility. Specifically, DefGCL employs edge-based graph augmentations to limit exposure to structural attributes, selects negative samples with low attribute sensitivity scores to reduce leakage, modifies the contrastive loss to decouple graph embeddings from attributes, and injects differential privacy noise during the embedding stage. Extensive experiments on five benchmark datasets demonstrate that DefGCL achieves state-of-the-art (SOTA) performance in both privacy preservation and task accuracy. For instance, on the AIDS dataset, DefGCL reduces attribute inference accuracy by 35 % while incurring only a 0.60 % drop in main task performance. Additionally, DefGCL improves computational efficiency by reducing runtime by nearly 50 % compared to baseline methods. 1},
  archive      = {J_ASOC},
  author       = {Jinyin Chen and Fanyu Ao and Wenbo Mu and Haiyang Xiong},
  doi          = {10.1016/j.asoc.2025.113911},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113911},
  shortjournal = {Appl. Soft. Comput.},
  title        = {DefGCL: Defence-enhanced graph contrastive learning against attribute inference attacks},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interval multi-feature sparse transformer-CNN: A synergistic approach to precise and efficient spatio-temporal wind speed interval-value prediction. <em>ASOC</em>, <em>185</em>, 113910. (<a href='https://doi.org/10.1016/j.asoc.2025.113910'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and reliable wind speed prediction is critical for stabilizing wind power integration. However, current methods are limited by accuracy and stability issues, hindering their large-scale application in wind farms. To overcome these problems, this study innovatively proposes an IMFSformer-CNN model integrating three core components. First, the spatio-temporal and multi-factor feature extraction technology comprehensively captures the spatio-temporal patterns and complex dependencies of wind speed dynamics, incorporating multiple factors such as meteorological variables and spatial correlation. Second, the multi-feature sparse attention mechanism reduces computational complexity by combining sparse attention with multi-feature attention, enhancing representation ability and scalability for precise interval value prediction. Finally, the enhanced interval spatio-temporal prediction fusion model combines the global dependency modeling capabilities of the improved Transformer architecture with the local receptive field advantages of CNN. This hybrid design facilitates the simultaneous capture of both macro-scale atmospheric patterns and micro-scale wind speed fluctuations. The model achieved prediction interval coverage probabilities of 0.921 and 0.899, and coverage width criteria of 1.493 and 3.776, outperforming other models on both datasets. This significantly enhances accuracy and practical value for wind farm cluster forecasting, supporting more reliable and efficient wind energy integration into power grids.},
  archive      = {J_ASOC},
  author       = {Weiyi Jiang and Jujie Wang and Xuecheng He},
  doi          = {10.1016/j.asoc.2025.113910},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113910},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interval multi-feature sparse transformer-CNN: A synergistic approach to precise and efficient spatio-temporal wind speed interval-value prediction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-granularity spatiotemporal fusion neural network with denoising reconstruction for human motion prediction. <em>ASOC</em>, <em>185</em>, 113909. (<a href='https://doi.org/10.1016/j.asoc.2025.113909'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human motion prediction has significant application value in many fields. However, existing methods often fail to fully capture the spatial relationships between joints and the temporal flow of information when modeling complex spatiotemporal dependencies. Additionally, these methods are prone to overfitting dominant features while neglecting other important aspects, and struggle with perceiving contour features effectively. To address these issues, this study introduces a novel encoder-decoder framework. The encoder generates a dual-layer adaptive adjacency matrix using a distance partition strategy to parameterize joint relationships, while incorporating a gating mechanism to control the temporal flow of information. The decoder then employs separate spatiotemporal attention modules to decode temporal and spatial features independently. These features are subsequently reconstructed through a spatiotemporal fusion strategy, effectively decoupling and modeling complex spatiotemporal dependencies. To address the issue of overfitting to dominant features, we introduce a denoising reconstruction strategy that allows the model to learn richer combinations of spatiotemporal features under multiple constraints. Furthermore, a multi-granularity information adaptive fusion module is incorporated to achieve adaptive fusion of both local and contour features. Experimental results across several benchmark datasets demonstrate that our method significantly outperforms the state-of-the-art approaches, showcasing its effectiveness in human motion prediction tasks.},
  archive      = {J_ASOC},
  author       = {Yong Li and Linfeng Zhu and Haofei Xie and Xinchang Yi},
  doi          = {10.1016/j.asoc.2025.113909},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113909},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-granularity spatiotemporal fusion neural network with denoising reconstruction for human motion prediction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FFNN: Fractional order basis function multi-step neural network method for fractional partial differential equations. <em>ASOC</em>, <em>185</em>, 113907. (<a href='https://doi.org/10.1016/j.asoc.2025.113907'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement in artificial intelligence technology, the increasing number of researchers utilize it to address complex equations in ocean engineering. So the technology of artificial intelligence has become a practical area of research. In this paper, we design a novel method to solve the fractional order long water wave equation, which is called the fractional order basis function multi-step neural network. Firstly, a power series is constructed based on a fractional order basis function, which serves as the approximate solution. Secondly, neural networks and the initial conditions of differential equations are integrated into the construction of approximate solutions. Furthermore, the solution is discretized, and a multi-step unfolding strategy is employed on the resulting discrete solution. This approach ensures that each point in the solution is influenced by its predecessor. By means of repeated applications of the optimization algorithm, the residuals are successively diminished, thereby yielding approximate solutions to the equations. Finally, the efficacy and versatility of the proposed strategy were validated through a series of numerical experiments. Compared with the method of fractional physics-informed neural networks, there are up to 18.7 -fold and 22.8 -fold increases in stability of average and maximum residuals. Simultaneously, initial conditions are retained in new solutions.},
  archive      = {J_ASOC},
  author       = {Jianke Zhang and Xudong Tian and Chang Zhou},
  doi          = {10.1016/j.asoc.2025.113907},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113907},
  shortjournal = {Appl. Soft. Comput.},
  title        = {FFNN: Fractional order basis function multi-step neural network method for fractional partial differential equations},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discrimination index based attribute reduction for partially labeled heterogeneous data via a new prediction label strategy and statistical distribution of data. <em>ASOC</em>, <em>185</em>, 113904. (<a href='https://doi.org/10.1016/j.asoc.2025.113904'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing methods often struggle to effectively utilize the statistical distribution of data and unlabeled information when dealing with partially labeled heterogeneous data, leading to limited performance in attribute reduction. To address this issue, this paper presents a novel semi-supervised attribute reduction method that integrates statistical distribution of data, conditional discrimination index and a new prediction label strategy. Initially, the similarity between objects is constructed by analyzing the statistical distribution of data. Subsequently, a new prediction label strategy is introduced, which not only utilizes existing label information but also completes missing information by predicting new labels, thereby enhancing the completeness and usability of data. Finally, conditional discrimination index, a tool for measuring the importance of attributes in classification tasks, is employed to design an attribute reduction algorithm. The experimental results on real-world partially labeled heterogeneous datasets show that the proposed p-CDIAR algorithm exhibits superior performance compared to the existing nine reduction algorithms, with an average increase of 4.67 % in classification accuracy and 6.32 % in outlier detection performance.},
  archive      = {J_ASOC},
  author       = {Qingnian Li and Haixin Huang and Tao Lu and Huaming Wei and Zhaowen Li},
  doi          = {10.1016/j.asoc.2025.113904},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113904},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Discrimination index based attribute reduction for partially labeled heterogeneous data via a new prediction label strategy and statistical distribution of data},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extended belief rule-based system with online joint learning strategy. <em>ASOC</em>, <em>185</em>, 113901. (<a href='https://doi.org/10.1016/j.asoc.2025.113901'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the proliferation of dynamic data streams in the advanced technology environment, it is necessary to solve the evolving classification problems by using adaptable and interpretable artificial intelligence techniques. To meet this challenge, a new extended belief rule-based (EBRB) system incorporating online joint learning strategy is proposed in this paper. The online joint learning strategy comprises two key components: rule update and parameter update schemes. In the rule update scheme, different rule incorporation processes are designed for the labeled or unlabeled input data while overlapping and redundant rules are removed from the rule base. To adapt the updated rule base, the parameter update scheme is designed to retune the parameters within updated rule base. The antecedent attribute weights are optimized using the Bayesian optimization algorithm and the rule weights are updated based on the consistency of rules. To evaluate the performance of the developed system, it is applied to assist radiologists in diagnosing thyroid nodules. Compared with the existing offline EBRB systems and online learning methods, the proposed online joint learning EBRB system could generate higher classification accuracy with fewer rules in the limited running time.},
  archive      = {J_ASOC},
  author       = {Bingbing Hou and Min Xue and Leilei Chang and Zijian Wu},
  doi          = {10.1016/j.asoc.2025.113901},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113901},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Extended belief rule-based system with online joint learning strategy},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fusing local density and approximate distance for nonparametric outlier detection. <em>ASOC</em>, <em>185</em>, 113898. (<a href='https://doi.org/10.1016/j.asoc.2025.113898'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection is an essential yet challenging task in intelligent data analysis, and some density-based unsupervised methods have been introduced to identify outliers in low-density regions. However, these methods still suffer from inaccurate density estimation and limited capability in detecting diverse types of outliers. In this study, we propose a nonparametric outlier detection method with the fusion of density and distance (POD-FDD). The proposed method employs adaptive kernel density estimation based on natural neighborhoods, which reduces the sensitivity to parameters in density estimation. Moreover, the optimistic and pessimistic densities are introduced to enhance the reliability of density estimation in the local neighborhood. In addition, approximate reachability distance information is integrated to improve the capability of identifying cluster outliers. Ultimately, a robust parametric-free outlier detection method is developed to detect different types of outliers. Extensive comparative experiments and statistical significance analysis on synthetic and public datasets demonstrate its superior performance, achieving an average improvement of 1.97 % in the AUC metric.},
  archive      = {J_ASOC},
  author       = {Zhiyu Chen and Can Gao and Jie Zhou and Ying Yu},
  doi          = {10.1016/j.asoc.2025.113898},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113898},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fusing local density and approximate distance for nonparametric outlier detection},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of the risk level of saltwater intrusion in the modaomen waterway of the pearl river estuary based on the deep temporal clustering model. <em>ASOC</em>, <em>185</em>, 113897. (<a href='https://doi.org/10.1016/j.asoc.2025.113897'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, extreme events caused by global climate change have intensified the phenomenon of saltwater intrusion (SWI) in estuaries. The nonlinear and non-stationary characteristics of estuarine SWI have led to an exponential decline in the timeliness of traditional regression prediction models, making it difficult to meet the operational needs of SWI forecasting. To address this, this study proposed a technical framework for SWI risk level forecasting based on temporal clustering, with its core innovation lying in algorithmic improvements for accurately characterizing complex disaster systems. The key challenges in forecasting SWI risk levels involved capturing the dynamic nonlinear relationships between multidimensional disaster factors (such as runoff, tide level, and wind) and SWI severity, as well as enhancing feature discriminability in label-limited scenarios. Accordingly, this study optimized algorithms through dual-path supervised and unsupervised learning: In the supervised learning framework, LightGBM, RF, XGBoost, and Extra trees were introduced as base learners into the Deep Forest (DF) model. The complementary feature-space partitioning of diverse learners was leveraged to improve the model’s ability to distinguish risk -level boundaries, achieving an average performance gain of 7.8 %. In the unsupervised learning framework, discriminative regularization was incorporated into the Extreme Learning Machine-Autoencoder (ELM-AE) model. By forcing features of samples from the same class to cluster toward the class center, the model’s feature separability for rare events (e.g., severe SWI) was enhanced, leading to an average performance improvement of 11 %. Finally, the optimal model was used to extract dynamic evolution patterns between multidimensional disaster factors and SWI risk levels, with interpretability analysis conducted for real-world forecasting. Notably, upstream flow sequences exhibited high distinguishability between no-SWI and severe-SWI, while mild and moderate SWI showed similar flow patterns, with tidal sequences being the primary differentiator. The algorithmic advancements not only enhanced the accuracy and efficiency of SWI forecasting but also provided a generalizable framework for risk classification in nonlinear hydrological systems.},
  archive      = {J_ASOC},
  author       = {Qingqing Tian and Hongyu Yang and Yu Tian and Peiyao Weng},
  doi          = {10.1016/j.asoc.2025.113897},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113897},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prediction of the risk level of saltwater intrusion in the modaomen waterway of the pearl river estuary based on the deep temporal clustering model},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive learning with mirror-task for multimodal sentiment analysis. <em>ASOC</em>, <em>185</em>, 113896. (<a href='https://doi.org/10.1016/j.asoc.2025.113896'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Task Learning (MTL) in Multimodal Sentiment Analysis (MSA) involves implementing various parameter-sharing strategies among tasks. Currently, MSA primarily focuses on hard parameter-sharing mechanisms based on encoder sharing, while soft parameter-sharing is often neglected. To explore a reasonable combination of soft and hard mechanisms in MSA and optimize multimodal representations, along with multimodal contrastive learning, we propose D 3 MSA. It consists of D ouble network (primaryNet and MirrorNet), D ouble parameter-sharing strategies and D ouble contrastive learning modes for multimodal sentiment analysis. D 3 MSA utilizes hard-sharing to consolidate correlations between positive samples of intra-sample contrastive learning. In soft-sharing, we propose a pre-trained MirrorNet (MN) that generates negative samples by the learned inverse distributions. This optimizes the feature space of negative samples. MN interacts with the MSA task through soft-sharing during inter-sample contrastive learning. Experimental results demonstrate that our proposed method can achieve advanced performance on the CMU-MOSI and CMU-MOSEI datasets with lightweight training that requires only a small number of parameters.},
  archive      = {J_ASOC},
  author       = {Hang Shi and Lianmin Zhou and Yuanyuan Pu and Zhengpeng Zhao and Jinjing Gu and Dan Xu},
  doi          = {10.1016/j.asoc.2025.113896},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113896},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Contrastive learning with mirror-task for multimodal sentiment analysis},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nearest-best neighbors optimization algorithm for constrained multimodal multiobjective problems. <em>ASOC</em>, <em>185</em>, 113895. (<a href='https://doi.org/10.1016/j.asoc.2025.113895'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multimodal multiobjective problems (CMMOPs) have multiple equivalent constrained Pareto optimal sets in the decision space corresponding to the identical constrained Pareto front in the objective space. The key to solving CMMOPs is how to balance feasibility, convergence, and diversity of solutions in both the decision and objective spaces. In view of this, this paper proposes a Nearest-Best neighbors optimization algorithm with constraint-based fitness (NBNOA) to solve CMMOPs. First, a constraint-based fitness assignment scheme is designed to assign specific fitness values to individuals in the population. Then, the Nearest-better-neighbor clustering method is adopted to identify the nearest-better neighbor and best neighbor of each individual according to the specific fitness values. On this basis, a Nearest-Best neighbors guided strategy is developed to guide the search direction of individuals, striking a better balance between exploration and exploitation capabilities. Moreover, a CDP-density elite selection mechanism is constructed to obtain feasible Pareto optimal solutions with higher precision and better diversity. Extensive experiments on two CMMOPs test suites demonstrated that the proposed NBNOA significantly outperforms nine state-of-the-art algorithms. Notably, NBNOA ranks first among all ten algorithms and achieves the best values for 23 out of 31 benchmark functions regarding the reciprocal of Pareto sets proximity and inverted generational distance. Furthermore, NBNOA is applied to a real-world CMMOP, verifying its effective practical application capability. Additionally, NBNOA is tested on two high-dimensional constrained multiobjective optimization problems test suites, further proving its competitive performance in solving complex problems.},
  archive      = {J_ASOC},
  author       = {Xuming Han and Ting Zhou and Limin Wang and Yali Chu},
  doi          = {10.1016/j.asoc.2025.113895},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113895},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A nearest-best neighbors optimization algorithm for constrained multimodal multiobjective problems},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency decomposition and patch modeling framework for time-series forecasting. <em>ASOC</em>, <em>185</em>, 113890. (<a href='https://doi.org/10.1016/j.asoc.2025.113890'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is widely applied across diverse fields, including finance, transportation, and energy, and has made significant contributions in these areas. However, in real-world applications, time series data can be complex and dynamic. Current methodologies still encounter several challenges in managing high-dimensional data, extracting intricate features, and making long-term forecasts. In this study, we propose a Frequency Decomposition and Patch Modeling Framework (FPF). Our FPF consists of the Frequency Domain Decomposition Block (FDB) and the Dual Patch Modeling Block (DPMB). DPMB consists of Patch Enhancement Block and Patch Mixing Block. First, FDB transforms the input sequence to the frequency domain through the Fast Fourier Transform and designs frequency masks to decompose the data into high-frequency and low-frequency components, to extract fast-changing patterns and trend information respectively. Subsequently, DPMB divides the components into patches, where the high-frequency components are modeled by MLP-based Patch Enhancement Block to capture local features, and the low-frequency components are modeled by Transformer-based Patch Mixing Block to capture global dependencies and cross-patch correlations. We conducted comprehensive experiments using seven real-world time series forecasting datasets, including ETT, Traffic, Electricity, and Weather. The findings indicate that this method demonstrates superior performance in the field of time series forecasting.},
  archive      = {J_ASOC},
  author       = {Denghui Xu and Hua Wang and Fan Zhang},
  doi          = {10.1016/j.asoc.2025.113890},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113890},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Frequency decomposition and patch modeling framework for time-series forecasting},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OdML: An optimization-driven meta-learning framework for multi-task approximate model predictive control. <em>ASOC</em>, <em>185</em>, 113882. (<a href='https://doi.org/10.1016/j.asoc.2025.113882'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in approximate model predictive control (MPC) have leveraged deep neural networks (DNNs) to imitate optimal control laws, significantly reducing the computational cost of real-time optimization. However, these methods often struggle to adapt efficiently to previously unseen system dynamics and suffer from poor data efficiency in real time. In this paper, we address these challenges by treating control problems with different system parameters as separate tasks within a meta-learning scope. Under this scope, we propose OdML, an Optimization-driven Meta-Learning approach for approximate MPC that enables rapid online fine-tuning of DNN-based controllers. We introduce an optimization-driven fine-tuning mechanism that allows for fast adaptation to new tasks using limited online data, without requiring full knowledge of the system parameters. Furthermore, to ensure safety during adaptation, we incorporate control barrier functions into the optimization process, allowing the controller to satisfy safety constraints even under previously unseen conditions. We demonstrate the effectiveness of OdML through various simulation scenarios, highlighting its ability to achieve safe and efficient control.},
  archive      = {J_ASOC},
  author       = {Junbo Tong and Shuhan Du and Daming Shi and Wenhui Fan},
  doi          = {10.1016/j.asoc.2025.113882},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113882},
  shortjournal = {Appl. Soft. Comput.},
  title        = {OdML: An optimization-driven meta-learning framework for multi-task approximate model predictive control},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep reinforcement learning trader without offline training. <em>ASOC</em>, <em>185</em>, 113881. (<a href='https://doi.org/10.1016/j.asoc.2025.113881'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we pursue the question of a fully online trading algorithm (i.e. one that does not need offline training on previously gathered data). For this task we consider Double Deep Q -learning in the episodic setting with Fast Learning Networks approximating the expected reward Q . Additionally, we define the possible terminal states of an episode in such a way as to introduce a mechanism to conserve some of the money in the trading pool when market conditions are seen as unfavourable. Some of these money are taken as profit and some are reused at a later time according to certain criteria. After describing the algorithm, we test it using 1-minute-tick price data for 4 major cryptocurrencies from Binance. We see that the agent performs better than trading with randomly chosen actions on each timestep. And it does so when tested on the whole dataset for a given market as well as on different subsets, representing different market trends.},
  archive      = {J_ASOC},
  author       = {Boian Lazov},
  doi          = {10.1016/j.asoc.2025.113881},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113881},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A deep reinforcement learning trader without offline training},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Density peak clustering algorithm based on boundary elimination and backbone construction. <em>ASOC</em>, <em>185</em>, 113880. (<a href='https://doi.org/10.1016/j.asoc.2025.113880'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density peak clustering (DPC) is an effective clustering algorithm, but it still has some problems and faces some challenges. For instance, it cannot identify the variable density datasets, the assignment strategy is easy to produce domino phenomenon, and the clustering results of DPC and its improved algorithms are easily affected by the intersection points between clusters. To solve these problems, in this paper, we propose a novel density peak clustering algorithm based on boundary elimination and backbone construction, called BEBC-DPC. A new local density is defined based on the natural neighbor search, and the boundary degree is defined by the position relationship between each point and its neighbors, which accurately describes the local distribution information of the point. The boundary points of clusters are eliminated by fusing the density and the boundary degree, which reduces the influence of the intersection points on the cluster division. In addition, the cluster backbone construction method based on representative points and representative sets is proposed. The density relationship among non-boundary points is used to form representative sets, and the similarity between representative sets is used to construct the cluster backbones, which can effectively describe the overall distribution structure characteristics of the clusters. Moreover, the adjacency degree of each boundary point is defined by using the neighbor information and distance information, and the boundary points are gradually assigned to the most appropriate cluster backbone based on it to complete the clustering. Finally, sufficient experiments are performed on synthetic, UCI and image datasets, and the proposed BEBC-DPC is compared with DPC and its improved algorithms. Experimental results show the effectiveness of the proposed BEBC-DPC on various types of datasets.},
  archive      = {J_ASOC},
  author       = {Zhizhong Zhao and Sugen Chen and Cong Hu},
  doi          = {10.1016/j.asoc.2025.113880},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113880},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Density peak clustering algorithm based on boundary elimination and backbone construction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-criteria decision analysis-based framework for supply chain management evaluation with multi-dimensional sensitivity analysis: A green logistics perspective. <em>ASOC</em>, <em>185</em>, 113879. (<a href='https://doi.org/10.1016/j.asoc.2025.113879'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transition toward sustainable Supply Chain Management (SCM) presents complex decision-making challenges that require robust and transparent evaluation methods. Effective decision-making in this context requires robust evaluation methods capable of handling complex, multi-dimensional aspects of the decision process. This study proposes a comprehensive decision-support framework that integrates Multi-Criteria Decision Analysis (MCDA) with advanced sensitivity analysis techniques to assess the stability and reliability of alternative rankings under uncertainty. The framework combines established MCDA methods with submodel exclusion analysis and the Comprehensive Sensitivity Analysis Method (COMSAM), which allows for systematic perturbation of the decision matrix and evaluation of robustness across multiple dimensions. Applied to a green logistics case study, the framework demonstrates its capacity to support sustainable decision-making by accounting for varying stakeholder priorities and data uncertainty. The approach offers methodological advances in robustness assessment, practical relevance for sustainability-focused SCM, and open-source implementation to ensure reproducibility. The proposed framework is adaptable to a wide range of decision contexts, contributing to the development of more reliable and explainable MCDA-based evaluations.},
  archive      = {J_ASOC},
  author       = {Jakub Więckowski and Wojciech Sałabun},
  doi          = {10.1016/j.asoc.2025.113879},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113879},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-criteria decision analysis-based framework for supply chain management evaluation with multi-dimensional sensitivity analysis: A green logistics perspective},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reliable type 2 fuzzy Min–Max neural networks for pattern classification. <em>ASOC</em>, <em>185</em>, 113875. (<a href='https://doi.org/10.1016/j.asoc.2025.113875'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Fuzzy Min–Max (FMM) algorithm is a powerful classification method capable of handling non-linear class boundaries and making both hard and soft decisions while learning from online data. However, it faces significant challenges, including sensitivity to the expansion coefficient, information loss during the contraction stage, and the overlap problem. To address these limitations, we propose a Reliable Type-2 Fuzzy Min–Max (RT2FMM) algorithm, which incorporates type-2 fuzzy logic to consider hyperbox uncertainty and effectively resolve the overlap problem. By assigning distinct certainties to overlapping regions, RT2FMM eliminates the need for the contraction stage and the overlap test. Additionally, we introduce weighted factors for hyperboxes, which enhances the reliability of membership values and models their mutual effects. Our comprehensive experimental evaluation across twenty datasets demonstrates that RT2FMM significantly outperforms existing FMM-based models in terms of robustness and accuracy. The Friedman test further confirms the superior performance of RT2FMM compared to commonly used classifiers, highlighting its potential as a robust solution for complex classification tasks.},
  archive      = {J_ASOC},
  author       = {Ali Nik-Khorasani and Mohammad-R. Akbarzadeh-T.},
  doi          = {10.1016/j.asoc.2025.113875},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113875},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Reliable type 2 fuzzy Min–Max neural networks for pattern classification},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fortifying vision models: A comprehensive survey of defences against adversarial examples. <em>ASOC</em>, <em>185</em>, 113874. (<a href='https://doi.org/10.1016/j.asoc.2025.113874'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence and Machine learning (ML) have seen many advancements in the past two decades. It has led to the creation of several techniques, including Deep Neural Networks (DNN), Convolution Neural Networks (CNN), Autoencoders, Generative Adversarial Networks (GAN) and Diffusion models. These techniques have been applied to various real-world applications, such as self-driving cars, medical diagnosis and voice assistants. Despite these advancements, a carefully crafted input can fool the ML model. Such attacks are known as adversarial examples. It is a serious threat to safety critical systems. This survey provides a comprehensive review of defences against adversarial examples by tracing their evolution from early empirical methods to more principled, theoretically grounded approaches. We systematically categorise defences based on their underlying mechanisms. In addition to surveying state-of-the-art techniques, we spotlight emerging trends such as generative defences and diffusion-based purification. Finally, we identify persistent vulnerabilities and outline promising directions for future research towards building truly resilient vision models. This work aims to equip researchers and practitioners with a deep understanding of current defences and inspire innovation in adversarial robustness for the next generation of vision applications.},
  archive      = {J_ASOC},
  author       = {Siddheshwar Kumar and Shashank Srivastava and Shashwati Banerjea},
  doi          = {10.1016/j.asoc.2025.113874},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113874},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fortifying vision models: A comprehensive survey of defences against adversarial examples},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AOT-PixelNet: Lightweight and interpretable detection of forged images via adaptive orthogonal transform. <em>ASOC</em>, <em>185</em>, 113873. (<a href='https://doi.org/10.1016/j.asoc.2025.113873'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative image detection faces persistent challenges in terms of generalization and interpretability, limiting its reliability in complex scenarios. To address these issues, we propose AOT-PixelNet, a lightweight and interpretable detection framework that integrates an Adaptive Orthogonal Transform (AOT) module with a streamlined 1 × 1 convolution-based PixelNet architecture. The AOT module leverages diverse orthogonal transforms, such as FFT and DCT, to extract informative frequency-domain features, thereby enhancing sensitivity to medium- and high-frequency artifacts. Meanwhile, PixelNet minimizes parameter count (only 0.98 million) while effectively capturing cross-channel inconsistencies and mitigating overfitting. Experimental evaluations on multiple unseen GAN and diffusion-based datasets demonstrate that AOT-PixelNet achieves superior performance with minimal computational cost. Specifically, it outperforms the NPR method by 0.6% and 11.76% on the ForenSynths and GenImage datasets, respectively, validating the framework’s robustness, effectiveness, and interpretability.},
  archive      = {J_ASOC},
  author       = {Dengtai Tan and Deyi Yang and Boao Tan and Chengyu Niu and Yang Yang and Shichao Li},
  doi          = {10.1016/j.asoc.2025.113873},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113873},
  shortjournal = {Appl. Soft. Comput.},
  title        = {AOT-PixelNet: Lightweight and interpretable detection of forged images via adaptive orthogonal transform},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Status prediction using attentive and cascaded deep network by fault tolerant and priority-based scheduling for load balancing in cloud. <em>ASOC</em>, <em>185</em>, 113872. (<a href='https://doi.org/10.1016/j.asoc.2025.113872'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cloud facilitates the user to complete their work utilizing the cost strategy of pay-as-you-go, which is based on the consumed Virtual Machine (VM) hours. Thus, the scheduler must offer the highest throughput to attain efficient allocation of resources in the cloud paradigm. Cloud services are dependent on characteristics such as fault tolerance, security, scalability, and availability. Hence, an effective scheduler is necessary to arrange the scheduling tasks and adjust the server loads. Typically, a load-balancing task focuses on detecting the overloaded and under-loaded nodes and adjusting the load between them. When considering the significant role of fault-tolerance in load-balancing algorithms, it seems to suffer from poor organization and a lack of in-depth experiments in this sector. This paper proposes a new task for the load-balancing operation. Initially, task scheduling is performed where the fault tolerance and the priority-aided scheduling approach are adopted. Furthermore, resource optimization is carried out in the scheduling task using Randomly Improved Electric Fish Optimization (RIEFO). To validate the load balancing operation, several multi-objective functions such as resource utilization, delay, time, makespan, active servers, throughput, success rate, fault tolerance rate, and energy consumption are derived. Moreover, because of the system’s dynamic environment, the status of the server varies simultaneously. The server status prediction is significant in allocating the tasks to the server or the VM resources. Thus, the Attention-based Cascaded Residual Bidirectional Long Short-Term Memory (ACRes-BiLSTM) is employed to predict the server status before performing the resource allocation. Finally, the tasks are scheduled effectively using the predicted server status. The performance is estimated using numerous performance metrics.},
  archive      = {J_ASOC},
  author       = {Gudivada Lokesh and Kasarapu Ramani and K.K. Baseer},
  doi          = {10.1016/j.asoc.2025.113872},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113872},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Status prediction using attentive and cascaded deep network by fault tolerant and priority-based scheduling for load balancing in cloud},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid deep learning framework for detecting grape leaf diseases by integrating ResNeSt-50 and CBAM attention into DeepLabv3 +. <em>ASOC</em>, <em>185</em>, 113871. (<a href='https://doi.org/10.1016/j.asoc.2025.113871'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grape leaf diseases, such as black rot, powdery mildew, and downy mildew, pose a significant threat to global viticulture, leading to substantial yield losses and reduced fruit quality. Early and accurate identification of these diseases is essential for precision agriculture and sustainable crop management. This study presents a comprehensive comparison of traditional and deep learning-based image segmentation methods for detecting grape leaf lesions. A series of classical segmentation techniques, including Mean Shift, Fuzzy C-Means (FCM), Normalized Cut, K-Means, and Fuzzy K-Means (FKM), were evaluated alongside an advanced DeepLabv3 + model. The baseline DeepLabv3 + architecture was further enhanced by integrating a ResNeSt-50 backbone with various attention mechanisms, including Squeeze-and-Excitation (SE) Block, Convolutional Block Attention Module (CBAM), Bottleneck Attention Module (BAM), Self-Attention, and Dual Attention Network (DANet). Among all models, DeepLabv3 + with ResNeSt-50 and CBAM achieved the highest performance, attaining 98.2 % accuracy, 97.1 % precision, 96.7 % recall, 96.6 % mean Intersection over Union (mIoU), and a 96.8 % Dice Score. The results demonstrate that attention-augmented deep networks significantly outperform classical methods, especially in handling complex lesion structures under diverse environmental conditions. While traditional algorithms remain useful in resource-constrained scenarios, deep learning models, particularly those enhanced with spatial and channel-wise attention, offer greater accuracy and robustness, making them ideal for integration into intelligent agricultural platforms such as drones, mobile scanners, and automated disease monitoring systems. Future work will focus on incorporating temporal and multimodal data, expanding dataset diversity, and optimizing lightweight models for real-time deployment on edge devices.},
  archive      = {J_ASOC},
  author       = {Kittipol Wisaeng},
  doi          = {10.1016/j.asoc.2025.113871},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113871},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A hybrid deep learning framework for detecting grape leaf diseases by integrating ResNeSt-50 and CBAM attention into DeepLabv3 +},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stochastic proportional–differential TLBO algorithm and its applications for wafer transfer finger. <em>ASOC</em>, <em>185</em>, 113870. (<a href='https://doi.org/10.1016/j.asoc.2025.113870'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Teaching-Learning-Based optimization (TLBO) algorithm, which includes teacher phase and learner phase, is a widely used method for global optimization. However, TLBO will experience premature convergence and get stuck in local optimum when faced with complex optimization challenges. Especially when tackling complex problems in practical engineering applications, which involves multiple variables and numerous constraints. To address this issue, a new variant termed Stochastic Proportional–Differential TLBO (SPD-TLBO) has been developed. The SPD phase allows students to learn not only from the current population but also from previous stochastic errors and their generation differences using adaptive random operators. By incorporating an SPD operator into the original TLBO framework, the algorithm’s search diversity is enhanced, reducing the likelihood of premature convergence to local optimum. The experimental results conducted at the IEEE Conference on Evolutionary Computation 2014 (CEC 2014) indicated that the proposed SPD-TLBO algorithm achieved an effective balance between exploration and exploitation capabilities. Specifically, the SPD-TLBO algorithm achieves the highest ranking in 21 out of 30 cases (70%) for 30-dimensional problems and 18 out of 30 cases (60%) for 50-dimensional problems. Statistical tests and convergence analyses show that the SPD-TLBO algorithm outperforms other algorithms in solving global optimization problems. Additionally, when applied to engineering optimization problems, the SPD-TLBO algorithm shows significant advantages over other algorithms. Therefore, the SPD-TLBO algorithm is further applied to optimize the structure of a wafer transfer finger in semiconductor manufacturing.},
  archive      = {J_ASOC},
  author       = {Jinfeng Sun and Yunlang Xu and Haibo Zhou},
  doi          = {10.1016/j.asoc.2025.113870},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113870},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A stochastic proportional–differential TLBO algorithm and its applications for wafer transfer finger},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of the health effects of COVID using hybrid classifier with attention-based LSTM-deep temporal convolution network. <em>ASOC</em>, <em>185</em>, 113867. (<a href='https://doi.org/10.1016/j.asoc.2025.113867'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronavirus Disease 2019 (COVID-19) is an infectious illness that affects both humans and animals. Individuals infected with COVID-19 are prone to lung complications during the recovery phase . Radiography and Computed Tomography (CT) are the most commonly used methods for diagnosing lung-related diseases. The primary aim of this paper is to assess the impact of COVID-19 on patients’ lungs, heart, and blood sugar levels using a deep learning-based approach. Initially, data related to the heart, blood sugar levels, and lungs of COVID-19-infected individuals are collected. From this dataset, three types of features are extracted. Deep features are obtained using Iterated Dilated Convolutional Neural Networks (IDCNN). From these deep features, which are obtained from the IDCNN, the optimal weighted features are derived by implementing the Hybrid Dolphin Pod Cuttlefish Optimization (HDPCO) algorithm. Subsequently, the HDPCO algorithm is also employed for optimal feature extraction. In addition, dimensionality reduction is performed using Principal Component Analysis (PCA). These three sets of features from the IDCNN, HDPCO, and PCA, are then fused into a single feature set . This fused feature set is fed into a hybrid classifier composed of a Deep Temporal Convolutional Network (DTCN) and an Attention-based Long Short-Term Memory (ALSTM) network . The classifier parameters are optimized using the HDPCO algorithm. The output from the hybrid classifier provides the final prediction result. Experimental results demonstrate that the proposed COVID-19 impact prediction model significantly outperforms existing models in terms of prediction accuracy and efficiency.},
  archive      = {J_ASOC},
  author       = {Sadanandam Kalvala and B. Baranidharan},
  doi          = {10.1016/j.asoc.2025.113867},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113867},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prediction of the health effects of COVID using hybrid classifier with attention-based LSTM-deep temporal convolution network},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum fuzzy logic for edge detection: A demonstration on NISQ hardware. <em>ASOC</em>, <em>185</em>, 113866. (<a href='https://doi.org/10.1016/j.asoc.2025.113866'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computing offers the potential to enhance computational efficiency beyond classical methods, but practical implementation remains challenging due to the limitations of Noisy Intermediate-Scale Quantum (NISQ) hardware, namely, restricted qubit counts, limited connectivity, and the presence of noise and decoherence. This study presents a novel approach to edge detection by leveraging a recently developed Quantum Fuzzy Inference Engine, implemented on a NISQ device. We introduce an optimized quantum circuit for its implementation, reducing qubit requirements and gate depth to improve execution on NISQ hardware. To overcome constraints related to large-scale image processing, a hybrid quantum–classical lookup table approach is employed. Edge detection performance is evaluated on the Berkeley Segmentation Data Set and Benchmarks 500 dataset under different conditions, including classical execution, ideal quantum simulation, noisy quantum simulation, and NISQ hardware calculation. Results demonstrate that the quantum fuzzy logic-based edge detection achieves outcomes comparable to classical methods by using fewer operations, marking a step toward practical quantum-enhanced image processing.},
  archive      = {J_ASOC},
  author       = {G. Nunziata and S. Crisci and G. De Gregorio and R. Schiattarella and G. Acampora and L. Coraggio and N. Itaco},
  doi          = {10.1016/j.asoc.2025.113866},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113866},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Quantum fuzzy logic for edge detection: A demonstration on NISQ hardware},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent cooperation-based bi-criteria evolutionary many-objective optimization. <em>ASOC</em>, <em>185</em>, 113865. (<a href='https://doi.org/10.1016/j.asoc.2025.113865'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many-objective evolutionary algorithms (MaOEAs) excel in solving many-objective optimization problems (MaOPs), which are mainly classified into two frameworks: the Pareto domination and the non-Pareto domination. The Pareto criterion (PC) obtains a well-converged solution set in multi-objective spaces through the Pareto dominance relationship between solutions. However, insufficient environmental selection pressure in many-objective spaces leads to slow convergence. The non-Pareto criterion (NPC) enhances the selection pressure by evaluating the solution set with a set of sortable scalar values. However, it is difficult to ensure the Pareto-optimal consistency of convergence and distribution when facing highly irregular Pareto fronts (PFs). Therefore, combining the two sets of criteria can satisfy the demand for uniform distribution while bringing significant selection pressure. A multi-agent cooperative strategy is proposed in this study to realize the combination of the two criteria. This strategy controls the evolutionary direction of two populations separately by deploying two agents, and promotes cooperative evolution between these populations through the exchange and flow of large amounts of information. In order to better realize the cooperative effect, we adopt the multi-agent reinforcement learning (MARL) strategy to accurately regulate the variation operator and parameter configurations of the bi-population. In addition, the effectiveness of the proposed method is validated on 74 test problems (DTLZ, WFG, and UF) and 3 real-world problems. The results show that the proposed algorithm is more competitive than 6 state-of-the-art algorithms.},
  archive      = {J_ASOC},
  author       = {Jiazheng Li and Yuan Liu and Juan Zou and Shuyi Liu and Shengxiang Yang and Jinhua Zheng},
  doi          = {10.1016/j.asoc.2025.113865},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113865},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-agent cooperation-based bi-criteria evolutionary many-objective optimization},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prompted complex context generation guided fine-grained ship recognition. <em>ASOC</em>, <em>185</em>, 113856. (<a href='https://doi.org/10.1016/j.asoc.2025.113856'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained ship recognition in complex marine environments is challenged by background interference, high inter-class similarity, and limited labeled data. Existing methods often rely on inefficient cascades or holistic feature extraction, which limits both accuracy and efficiency. To address these issues, we propose a Prompted Complex Context Generation Guided Fine-Grained Ship Recognition framework, consisting of two core modules. The Cross-Attention Context Generation Module utilizes a diffusion model to generate diverse background images from prompts, maintaining target consistency and enriching the training data to mitigate data scarcity. It also employs a cross-attention map to highlight target-relevant regions, guiding the Attention Map Guided Fusion Module. The Attention Map Guided Fusion Module adopts a dual-branch transformer architecture: one branch extracts global features from background-enhanced images, and the other captures local features through attention-guided cropping of target-specific regions. By integrating both global and local features, our method effectively identifies key target characteristics. Experimental results demonstrate that our approach achieves 97.04% accuracy on the publicly available MAR-ships dataset and 84.57% accuracy on the challenging GCS dataset, outperforming state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Runtian Wang and Kejun Wu and Renjie Qiao and Chunsheng Yang and Chengtao Cai},
  doi          = {10.1016/j.asoc.2025.113856},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113856},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prompted complex context generation guided fine-grained ship recognition},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label feature selection via asymmetric redundancy and variable precision dependency. <em>ASOC</em>, <em>185</em>, 113852. (<a href='https://doi.org/10.1016/j.asoc.2025.113852'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection is an effective data preprocessing technique that can significantly mitigate the challenges posed by high-dimensional features in multi-label learning. However, the exploration of feature-label correlations has often been strictly limited to inclusion relationships, while ignoring the fusion of local and global label information. Moreover, most previous work has typically assumed that redundancy between features is fully symmetric, overlooking the valuable insights that asymmetric redundancy provides for designing feature selection. To address these issues, this paper proposes a novel multi-label feature selection via asymmetric redundancy and variable precision dependency. Specifically, it constructs a conditional probability model to reflect the local label semantics, incorporating this into the construction of the variable precision dependency through a fusion indicator. Subsequently, the optimistic and pessimistic information overlap between features is discussed, allowing variable precision granularity to capture asymmetric redundancy between features. Building upon this, an information fusion method is proposed to quantify the pessimistic asymmetric redundancy between features by inducing knowledge granularity in the feature space. Finally, a comprehensive evaluation metric, Maximum Correlation-maximum Discrimination-minimum Redundancy (MCDR), is proposed to evaluate the significance of features. The experimental results on fifteen multi-label benchmark datasets indicate that the proposed method outperforms the other seven state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Wenbin Qian and Xiwen Lu and Shiming Dai and Jintao Huang},
  doi          = {10.1016/j.asoc.2025.113852},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113852},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-label feature selection via asymmetric redundancy and variable precision dependency},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-granularity decision tree algorithm based on variable precision rough sets and zentropy. <em>ASOC</em>, <em>185</em>, 113851. (<a href='https://doi.org/10.1016/j.asoc.2025.113851'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing decision tree algorithms often use a single-layer measure to process data, which cannot fully consider the complex interactions and dependencies between different granularity levels. In addition, decision tree algorithms inevitably face the issue of multi-value preference, which may lead to the selection of unreasonable attributes in the process of partition, thereby affecting the performance of the algorithms. Therefore, this paper proposes an improved decision tree algorithm, called Ze-VNDT, which combines variable precision rough sets with Zentropy. First, to avoid the information loss caused by data discretization, this paper introduces variable precision neighborhood rough sets for data processing. Second, by analyzing the granularity level structure within the variable precision neighborhood rough set model, knowledge uncertainty is analyzed from three granularity levels: decision classes, approximate relations, and similarity classes. We describe the uncertain knowledge from the overall to the internal using the idea of going from coarse to fine, and design a Zentropy to measure uncertainty. To address the issue of multi-value preference, an adaptive weighted Zentropy uncertainty measure is designed based on the definition of uncertainty measure based on Zentropy. Third, when constructing the improved decision tree algorithm, the optimal attributes are selected based on the designed uncertainty measure. Finally, numerical experiments on 18 UCI datasets validated the effectiveness and rationality of the proposed algorithm. The experimental results showed that, compared to traditional algorithms and the latest improved algorithms, the proposed algorithm achieved an average accuracy of 94.79%, an average precision of 85.77%, an average recall rate of 84.68%, and an F1-score of 84.97% across the 18 datasets. It ranked first in all five evaluation metrics, demonstrating higher stability and accuracy.},
  archive      = {J_ASOC},
  author       = {Hui Dong and Caihui Liu and Xiying Chen and Duoqian Miao},
  doi          = {10.1016/j.asoc.2025.113851},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113851},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-granularity decision tree algorithm based on variable precision rough sets and zentropy},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Skin lesion classification with mini-batch sampling and deep metric learning. <em>ASOC</em>, <em>185</em>, 113850. (<a href='https://doi.org/10.1016/j.asoc.2025.113850'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin lesion image classification based on deep learning has recently garnered significant attention. However, directly applying methods that perform well in general computer vision tasks to skin lesion image classification is not ideal, as skin lesion image datasets possess intrinsic characteristics, such as class imbalance, intra-class variability, and inter-class similarity. To tackle these challenges simultaneously, we propose a novel unified learning framework, named mBSML, which integrates mini-batch sampling and deep metric learning. In this framework, mini-batch sampling re-samples data in real-time during each iteration of learning, while a new loss function combines mini-batch distance metric-based loss with cross-entropy loss. Through the alternating training procedure on both imbalanced training data and balanced re-sampling data, mBSML effectively learns from global distribution information and local similarity information, not only from the original dataset but also from the minority classes. Extensive experiments conducted on two publicly available datasets demonstrate the effectiveness of mBSML for skin lesion image classification.},
  archive      = {J_ASOC},
  author       = {Shengdan Hu and Zhifei Zhang and Li Ying and Guangming Lang},
  doi          = {10.1016/j.asoc.2025.113850},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113850},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Skin lesion classification with mini-batch sampling and deep metric learning},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AOD-YOLO: A self-modulating multi-scale feature aggregation mechanism for small object detection in airport surface scenes. <em>ASOC</em>, <em>185</em>, 113849. (<a href='https://doi.org/10.1016/j.asoc.2025.113849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in airport surface scenes is crucial for enhancing safety. However, the coexistence of objects with significant scale disparities within the same region complicates feature representation, limiting existing models’ ability to capture fine-grained details, especially for small objects. To address this challenge, we propose AOD-YOLO, an Airport Object Detection (AOD) model incorporating a Self-Modulating Multi-Scale Feature Aggregation Mechanism. This model introduces two key innovations: (1) Enhanced Context Modeling: By leveraging large-kernel convolution, frequency-domain modulation, and statistical feature analysis, our approach effectively adjusts feature contributions across different object scales, improving contextual understanding in complex scenes; (2) Optimized Small Object Representation: A dynamic gradient gain allocation strategy refines small-object features, enhancing detection accuracy and overall feature presentation. AOD-YOLO consistently improves performance across model scales. On our self-constructed Airport dataset and the public VisDrone-DET2019 dataset, it achieves mean Average Precision (mAP 0.5 ) of 87.9% and 44.9%, respectively—outperforming state-of-the-art models like YOLOv11 and Gold-YOLO by substantial margins. Additionally, through optimized network module placement, AOD-YOLO achieves 112 FPS, striking a balance between computational efficiency and accuracy, making it well-suited for real-time airport object detection.},
  archive      = {J_ASOC},
  author       = {Yingqing Wang and Weili Zeng and Ziyu Zhao and Baogeng Li and Zhibin Quan},
  doi          = {10.1016/j.asoc.2025.113849},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113849},
  shortjournal = {Appl. Soft. Comput.},
  title        = {AOD-YOLO: A self-modulating multi-scale feature aggregation mechanism for small object detection in airport surface scenes},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gloss-free sign language translation based on fusion attention. <em>ASOC</em>, <em>185</em>, 113848. (<a href='https://doi.org/10.1016/j.asoc.2025.113848'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign language translation converts sign language videos into spoken language text. Traditional gloss-based approaches require costly gloss annotations, driving recent interest in gloss-free methods. In this paper, we propose a novel gloss-free sign language translation method based on fusion attention (SLTFA) that uniquely models the intrinsic logical structure of sign language. The key innovation is the development of a dual-attention mechanism that mimics the natural hierarchical structure of sign language: intra-gloss attention captures fine-grained relationships within video frame sequences representing individual semantic units, while inter-gloss attention models the broader contextual connections between these units, similar to how words form coherent sentences. Additionally, we introduce a contrastive loss strategy for cross-modal soft alignment that effectively bridges the gap between visual and textual representations. Extensive experiments on the RWTH-PHOENIX-WEATHER-2014T dataset demonstrate SLTFA’s superior performance, achieving a BLEU-4 score of 16.99 and a ROUGE score of 40.82. On the CSL-Daily dataset, our approach achieves a BLEU-1 score of 25.56 and a ROUGE score of 27.51, demonstrating strong performance across different sign languages.},
  archive      = {J_ASOC},
  author       = {Yingchun Xie and Wei Su and Chongliang Zhong and Chuan Cai and Yongna Yuan},
  doi          = {10.1016/j.asoc.2025.113848},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113848},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Gloss-free sign language translation based on fusion attention},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient mathematical-based optimization method to optimize multi-hydropower operating rules. <em>ASOC</em>, <em>185</em>, 113846. (<a href='https://doi.org/10.1016/j.asoc.2025.113846'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing hydropower multi-reservoir systems requires both effective operating rules and efficient optimization techniques. The main contribution of this paper is offering a unique approach that elegantly combines two important parts: creating an efficient optimization method and developing hydropower operating rules. In this regard, a nonlinear rule curve (NLRC) and a linear rule curve (LRC), are tailored for the coordination of a hydropower multi-reservoir system (HMRS) in Iran. To optimize operating rules, the study fabricates a novel algorithm termed the multi-operator weighted mean of vectors (MINFO). The algorithm combines a powerful global search strategy (GSS) that thoroughly searches the solution space with an efficient local search (LS), striking a balance between solution diversity and convergence speed. To fine-tune this balance, an adaptive parameter-tuning strategy is applied. Furthermore, the active-set sequential quadratic programming (ASQP) serves as a localized escaping operator to enhance the algorithm's convergence speed. The effectiveness of the proposed MINFO algorithm is first evaluated through a nonlinear five-reservoir problem. The findings indicate that the MINFO algorithm outperforms a set of 14 distinct optimization methods. Subsequently, the MINFO algorithm is applied to identify optimal NLRC and LRC for a six-reservoir hydropower system. The results underscore the superiority of optimized NLRC, yielding a potential power augmentation of up to 17 % in comparison to the LRC approach. In summation, this study constitutes a seminal contribution by cultivating an efficient rule curve framework for the management of HMRSs.},
  archive      = {J_ASOC},
  author       = {Shuguang Li and Iman Ahmadianfar and Aitazaz A. Farooque and Zaher Mundher Yaseen},
  doi          = {10.1016/j.asoc.2025.113846},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113846},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An efficient mathematical-based optimization method to optimize multi-hydropower operating rules},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced YOLOv4 for real-time underwater object detection: An application-oriented approach. <em>ASOC</em>, <em>185</em>, 113837. (<a href='https://doi.org/10.1016/j.asoc.2025.113837'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting debris and monitoring marine life in sea aquaculture face challenges due to limited visibility and the presence of diverse. Underwater object detection by Autonomous Unmanned Vehicle(AUV) is inherently more challenging than land due to light attenuation and water turbidity, especially for small and dense objects in murky images, where extracting high-quality features is hindered. In this paper, we present an efficient approach for real-time underwater object detection through improvements in image enhancement, data augmentation, and feature aggregation. Initially, U-Shape Transformer is applied to enhance the original images. For data augmentation, it is observable that while Mosaic data augmentation enhances complex images but fails to improve small-object detection due generation of less number of images with small objects. To address this limitation, we propose Underwater-Mosaic (U-Mosaic), a modified Mosaic data augmentation technique designed to enhance small-object detection. Additionally, it was noted that existing YOLOv4 struggles with detecting small and densely populated objects in underwater images as unable to get sufficient features for small objects due to downsampling, image quality and also found difficulty in selecting anchor box size. Therefore, we propose a model called Advanced YOLOv4, tailored for underwater object detection. The proposed Advanced YOLOv4 aims to improve object detection efficiency by altering the neck and prediction layers of YOLOv4. Moreover, we introduce an additional spatial pyramid pooling layer to aggregate features and reduce feature dimensions thereby improving object detection rates. Also, the proposed work concentrates on very large object detection and for this purpose used downsampling during the detection of large objects. The proposed approach is validated through two distinct application areas: (i) detecting and locating debris (ii) detecting fish from underwater images. For validation, the Trash ICRA19 dataset is used for debris detection, while the Brackish dataset is employed for fish detection. UIQM and UCIQE, image enhancement assessment metrics are used to measure quality of enhanced images and found more than 20% better result for both the datasets. The proposed real-time underwater object detection model outperformed single-stage object detectors like YOLOv3, YOLOv4, YOLOv5, YOLOv7, and KPE-YOLOv5 by 5% in terms of mean Average Precision(mAP). Also proposed work compared with two-stage detector RCNN and found 8% better mAP than RCNN.},
  archive      = {J_ASOC},
  author       = {Pratima Sarkar and Sourav De and Prasenjit Dey and Sandeep Gurung},
  doi          = {10.1016/j.asoc.2025.113837},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113837},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Advanced YOLOv4 for real-time underwater object detection: An application-oriented approach},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UniCon: Unified image-guiding generation with noise consistency. <em>ASOC</em>, <em>185</em>, 113832. (<a href='https://doi.org/10.1016/j.asoc.2025.113832'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have demonstrated remarkable capabilities in image-to-image tasks. However, existing methods typically focus either on structural (e.g., layout, content) or stylistic guidance, with few approaches effectively excel at both. On the other hand, many methods require time-consuming fine-tuning or high inference latency, making interactive generation applications challenging to realize. To address these issues, we propose a two-stage framework referred as UniCon ( Uni fied Image-guiding Generation with Noise Con sistency). To improve time efficiency, we follow the paradigm of inversion-based image manipulation and introduce a novel method called Noise Consistency Inversion . Leveraging the nature of Consistency Models, this inversion process is highly efficient, requiring only a single neural function evaluation (NFE) in the inversion process. To achieve high consistency and finer control, we introduce a unified attention-based guidance mechanism that supports structural, stylistic, or joint reference inputs, without any additional fine-tuning. Experiments with structure- and style-specific methods show that our approach performs competitively or better in each individual aspect. In comparison of style transfer tasks that demand both structure and style, our method outperforms state-of-the-art baselines, confirming the effectiveness of our union control strategy. And overall, our approach also achieves the best efficiency in terms of runtime performance.},
  archive      = {J_ASOC},
  author       = {Yuanjun Liao and Yuning Gong and Yanci Zhang},
  doi          = {10.1016/j.asoc.2025.113832},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113832},
  shortjournal = {Appl. Soft. Comput.},
  title        = {UniCon: Unified image-guiding generation with noise consistency},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of the financial performance of the textile and apparel industry in interval type-2 fuzzy environment. <em>ASOC</em>, <em>185</em>, 113830. (<a href='https://doi.org/10.1016/j.asoc.2025.113830'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Turkish textile and apparel sector plays a crucial role in the national economy through employment, exports, and investment. The financial performance of companies is a key determinant of their sustainability and competitiveness, especially in global markets. The Turkish textile and apparel sector is one of the essential industries in terms of macro-economic indicators such as net foreign exchange inflow, employment and investment. This sector is also one of the critical actors in world trade. A robust performance evaluation model is essential for stakeholders such as investors, creditors, and managers. However, the assessment of firms is a very critical decision involving uncertainty due to various conflicting criteria based on judgements. In this study, an integrated multi-criteria decision-making (MCDM) model including interval type-2 fuzzy hierarchy process (IT2FAHP) and Compromise Ranking of Alternatives from Distance to Ideal Solution (CRADIS) approaches are proposed to assess the financial performance of Turkish textile and clothing firms that are traded in Borsa İstanbul (BİST) in the period from 2006 to 2020. In line with the determined purpose, the arithmetic average of the determined financial ratios during the analysis period covering 15 years is computed to obtain long-term performance indicators. The importance weights of the selected financial criteria for the performance evaluation model are identified by employing the IT2FAHP approach. Then, the firms are ranked according to their financial performances with the CRADIS method. In addition, the results from the sensitivity analysis validate the proposed approach and prove that it is practical. Moreover, practical and managerial implications are discussed based on the results. The results offer valuable insights for strategic decision-making and can support efforts to enhance financial stability in the textile and apparel sector. According to the results, "LUKSK" had the highest long-term financial performance among the 11 companies discussed. This company is followed by BOSSA, YATAS, and ATEKS companies. The alternatives confirm the robustness of the proposed model in maintaining its place in the ranking in 190 scenarios. In addition, the comparative analysis confirms the consistency of the proposed ranking framework.},
  archive      = {J_ASOC},
  author       = {Ömer Faruk Görçün and Mohsin Shabir and Ahmet Çalık and Özcan Işık},
  doi          = {10.1016/j.asoc.2025.113830},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113830},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Evaluation of the financial performance of the textile and apparel industry in interval type-2 fuzzy environment},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An interpretable dual-output multivariate wind speed interval prediction scheme using hyper-heuristic optimization algorithm and deep neural networks. <em>ASOC</em>, <em>185</em>, 113829. (<a href='https://doi.org/10.1016/j.asoc.2025.113829'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty analysis of wind speed forecasting using the Lower Upper Bound Estimation (LUBE) represents an advanced interval prediction method that does not require assumptions about data distribution. Previous studies, however, have exclusively focused on univariate prediction models, neglecting the information from other variables, and have not fully exploited the prediction errors in their loss function during training. To address these issues, an interpretable dual-output multivariate wind speed interval prediction scheme (IMWSIPS) that utilizes a hyper-heuristic optimization algorithm and a deep neural network is proposed, along with a novel loss function for training. The system initially takes multiple inputs such as historical wind speed and other influencing factors including wind direction, density, temperature, and pressure into a deep neural network. The actual wind speeds are then scaled up and down by factors of 1 + θ 1 (0 <θ 1 <1) and 1 + θ 2 (-1 <θ 2 <0), respectively, to produce two outputs from the network. On this basis, an optimization problem to minimize interval width under a given coverage probability is formulated and solved using the developed hyper-heuristic algorithm, yielding optimal values for θ 1 and θ 2 and the prediction intervals for sub-models. Subsequently, the advantages of five deep neural network models are leveraged to construct an ensemble model, with weights optimized by the hyper-heuristic algorithm to derive the final prediction intervals. Ultimately, the system's interpretability is analyzed at both variable and sub-model levels. Experimental and discussion results demonstrate that the introduction of IMWSIPS not only signifies enhancements in forecasting performance but also implies improvements in wind energy utilization efficiency and reductions in operational costs for power systems.},
  archive      = {J_ASOC},
  author       = {Mengzheng Lv and Jianzhou Wang and Shuai Wang and Yang Zhao and Jialu Gao and Yuansheng Qian},
  doi          = {10.1016/j.asoc.2025.113829},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113829},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An interpretable dual-output multivariate wind speed interval prediction scheme using hyper-heuristic optimization algorithm and deep neural networks},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The fuzzified grey wolf: An improved grey wolf optimizer based on dynamic fuzzy system FGWO. <em>ASOC</em>, <em>185</em>, 113818. (<a href='https://doi.org/10.1016/j.asoc.2025.113818'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Grey Wolf Optimizer (GWO) is a leading, powerful, and effective algorithm in swarm optimization techniques, showing competitive performance across various optimization problems. Yet, GWO is burdened by high tendencies toward exploitation and imprecise population diversity. This work introduces an improved GWO called the Fuzzified Grey Wolf Optimizer (FGWO) for solving global optimization problems. FGWO benefits from a dynamic fuzzy inference system (DFIS) to capture the optimal value of a → throughout iterations. DFIS integrates two inputs: the diversity rate and iteration number, and by inferring the optimal value of a → , FGOW determines whether to exploit or explore. Moreover, DFIS employs an adaptive membership function to capture the precise value of population diversity throughout the course of iteration. This optimal a → determination strategy can achieve a balanced exploitation–exploration ratio, mitigating premature convergence and enhancing diversity. FGWO is evaluated on CEC2017 benchmark functions, four engineering designs, and a breast cancer genes feature selection design. FGWO was compared with three other improved GWOs, and across all experiments, the outcomes demonstrate its superiority in terms of efficiency and applicability to real-world designed problems.},
  archive      = {J_ASOC},
  author       = {Mohammed Dheyaa Algubili and Labiba M. Alhelfi and Hana’ M. Ali},
  doi          = {10.1016/j.asoc.2025.113818},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113818},
  shortjournal = {Appl. Soft. Comput.},
  title        = {The fuzzified grey wolf: An improved grey wolf optimizer based on dynamic fuzzy system FGWO},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy lagrange interpolation method from summation of interactive fuzzy numbers. <em>ASOC</em>, <em>185</em>, 113817. (<a href='https://doi.org/10.1016/j.asoc.2025.113817'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel approach to extending the sum of interactive fuzzy numbers, which is independent of the order of its operands. Interactive fuzzy numbers are fuzzy quantities in which the values across different α -cuts are not assumed to vary independently, incorporating dependencies that better reflect real-world uncertainty. A characterization of the proposed summation is given in terms of α -cuts, making computational implementation easier. It is shown that this operation preserves essential mathematical properties, including associativity. This is particularly important, as it enables the consistent aggregation of multiple fuzzy quantities without concern for the order in which the operands are grouped. The norm and width behaviors under this new summation are also analyzed. To illustrate the theoretical results, several examples are provided. As a practical application, the classical Lagrange polynomial interpolation method is extended to handle uncertain parameters represented by interactive fuzzy numbers. A fuzzy curve fitting problem is examined using this framework, and a comparative discussion highlights the advantages of the proposed method over existing approaches.},
  archive      = {J_ASOC},
  author       = {Geizane Lima da Silva and Estevão Esmi and Vinícius Francisco Wasques and Laécio Carvalho de Barros},
  doi          = {10.1016/j.asoc.2025.113817},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113817},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fuzzy lagrange interpolation method from summation of interactive fuzzy numbers},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging the semantic-numerical gap: A numerical reasoning method of cross-modal knowledge graph for material property prediction. <em>ASOC</em>, <em>185</em>, 113776. (<a href='https://doi.org/10.1016/j.asoc.2025.113776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Material properties are illustrated by numerical data and semantic factors. In general, existing methods typically adopt machine learning (ML) algorithms to regress numerical properties or transfer other pre-trained knowledge graphs (KGs) to the material, due to the limitations of small-sample datasets. However, integrating semantic and numerical information from multi-modal data which across diverse experimental conditions remains a significant challenge in materials science. In this paper, a numerical reasoning method for material KGs (NR-KG) 1 was proposed, which constructs a cross-modal KG using semantic nodes and numerical proxy nodes. Both types of information by projecting KG into a canonical KG were captured and a graph neural network to predict material properties was utilized. In process, a novel projection prediction loss is proposed to extract semantic features from numerical information. NR-KG facilitates end-to-end processing of cross-modal data, mining relationships and cross-modal information in small-sample datasets, and fully utilizes effective experimental data to enhance the accuracy of material prediction. We propose two new high-entropy alloys (HEA) property datasets with semantic descriptions. NR-KG outperforms state-of-the-art (SOTA) methods on two material datasets, with MSE values of 3520 and 2.210, and achieving relative improvements of 25.9% and 16.1%, respectively, over the second-best methods, KANO and PCHMLP (semantic). It also achieves RMSE values of 0.584 and 0.521 on the FreeSolv and ESOL public molecular datasets, surpassing SOTA methods by 48.8% and 22.2% over KANO, highlighting its potential application and generalizability.},
  archive      = {J_ASOC},
  author       = {Guangxuan Song and Dongmei Fu and Zhongwei Qiu and Zijiang Yang and Jiaxin Dai and Lingwei Ma and Dawei Zhang},
  doi          = {10.1016/j.asoc.2025.113776},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113776},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Bridging the semantic-numerical gap: A numerical reasoning method of cross-modal knowledge graph for material property prediction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-based actor–critic for adaptive cryptocurrency portfolio rebalancing. <em>ASOC</em>, <em>185</em>, 113697. (<a href='https://doi.org/10.1016/j.asoc.2025.113697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-frequency trading in volatile markets, such as cryptocurrencies, requires portfolio models that can swiftly adapt to regime shifts while controlling risk. We propose a novel approach that frames portfolio management as a dynamic strategy-selection problem. Instead of directly predicting asset weights, our agent selects from a pool of expert strategies based on recent market trends. We introduce a Transformer-based Variational Autoencoder (VAE) to extract disentangled trend representations, and a trend-aware actor–critic model to perform expert selection. Experiments demonstrate that this modular, strategy-level control mechanism outperforms existing methods in risk-sensitive crypto portfolio management.},
  archive      = {J_ASOC},
  author       = {Ahmad Asadi and Reza Safabakhsh},
  doi          = {10.1016/j.asoc.2025.113697},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113697},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Transformer-based actor–critic for adaptive cryptocurrency portfolio rebalancing},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
