<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>KBS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="kbs">KBS - 42</h2>
<ul>
<li><details>
<summary>
(2025). Selective embedding for deep learning. <em>KBS</em>, <em>330</em>, 114535. (<a href='https://doi.org/10.1016/j.knosys.2025.114535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has revolutionized many industries by enabling models to automatically learn complex patterns from raw data, reducing dependence on manual feature engineering. However, deep learning algorithms are sensitive to input data, and performance often deteriorates under nonstationary conditions and across dissimilar domains, especially when using time-domain data. Conventional single-channel or parallel multi-source data loading strategies either limit generalization or increase computational costs. This study introduces selective embedding, a novel data loading strategy, which alternates short segments of data from multiple sources within a single input channel. Drawing inspiration from cognitive psychology, selective embedding mimics human-like information processing to reduce model overfitting, enhance generalization, and improve computational efficiency. Validation is conducted using six time-domain datasets, demonstrating that the proposed method consistently achieves high classification accuracy for many deep learning architectures while significantly reducing training times. Across multiple datasets, selective embedding consistently improves test accuracy by 20 to 30 percent compared to traditional single-channel loading strategies, while also matching or exceeding the performance of parallel multi-source loading methods. Importantly, these gains are achieved while significantly reducing training times, demonstrating both efficiency and scalability across simple and complex architectures. The approach proves particularly effective for complex systems with multiple data sources, offering a scalable and resource-efficient solution for real-world applications in healthcare, heavy machinery, marine, railway, and agriculture, where robustness and adaptability are critical.},
  archive      = {J_KBS},
  author       = {Mert Sehri and Zehui Hua and Francisco de Assis Boldt and Patrick Dumond},
  doi          = {10.1016/j.knosys.2025.114535},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114535},
  shortjournal = {Knowl. Based Syst.},
  title        = {Selective embedding for deep learning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy-efficient adaptive perception for autonomous driving via lightweight policy learning and simulation-based optimization. <em>KBS</em>, <em>330</em>, 114514. (<a href='https://doi.org/10.1016/j.knosys.2025.114514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern autonomous driving systems rely heavily on deep learning-based perception models for object detection; yet, their computational and energy demands remain critical bottlenecks. The existing adaptive-perception strategies often lack the ability to dynamically balance the detection accuracy and energy consumption, in real-time, particularly under varying environmental conditions. To address this challenge, we first construct a large-scale autonomous driving dataset based on the CARLA simulator. Then, we propose a novel metric—the balanced efficiency index—to annotate each image with the most suitable you-only-look-once version 8 (YOLOv8) model size (i.e., n, s, m, l, or x). This index is governed by two critical parameters, which are efficiently optimized using our proposed constrained stochastic DIviding RECTangles (DIRECT) algorithm. Finally, we propose a lightweight dynamic mixed receptive field transformer (DynaMixFormer), which is trained using the labelled dataset, to select the appropriate YOLOv8 model adaptively. Our results show that: (1) the constrained stochastic DIRECT algorithm determines cost-effective parameters with very limited simulation overhead; (2) DynaMixFormer achieves a high classification accuracy of 96.56 % with only 0.017 M parameters, outperforming the state-of-the-art image-classification networks; and (3) the well-trained DynaMixFormer effectively extracts real-time contextual features, such as traffic density, weather conditions, and road complexity, to intelligently select the optimal model from various YOLOv8 variants. Extensive simulations demonstrate that our approach achieves up to 70.20 % reduction in the energy consumption, compared to the static deployment of the YOLOv8x model, with only a marginal decrease of approximately 2 % in the mean average precision. Taking China as an example, this translates to an estimated energy saving of 2.73 × 10 14 W. This work not only advances energy-efficient autonomous perception but also provides a generalizable framework for adaptive model selection in resource-constrained edge-computing systems. For ease of comprehension, some key nomenclature used in this paper are summarized in Table 1.},
  archive      = {J_KBS},
  author       = {Yanzhan Chen and Fan Yu and Qian Zhang and Mahardhika Pratama},
  doi          = {10.1016/j.knosys.2025.114514},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114514},
  shortjournal = {Knowl. Based Syst.},
  title        = {Energy-efficient adaptive perception for autonomous driving via lightweight policy learning and simulation-based optimization},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven interpretation of dimensions in an embedding language model based on a reference knowledge graph. <em>KBS</em>, <em>330</em>, 114507. (<a href='https://doi.org/10.1016/j.knosys.2025.114507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As language models are used in more applications, a key problem has become clear: their numerical embeddings are hard to interpret because it is unclear how each part of the vector relates to real-world meanings in specific fields. The prevailing embedding methods are inadequate in their current state, as they are unable to effectively bridge the gap between mathematical representations and human-understandable knowledge structures. The present study proposes a novel framework that explicitly links ontology classes to specific embedding dimensions through a dual-component architecture combining a text encoder that produces the target embedding dimensions with domain knowledge graphs. The Area Under the Interpretability Curve (AUIC) metric is introduced as a means to systematically evaluate model-alignment with ontological concepts. The analysis reveals that targeted dimensional mapping enables direct interpretation of individual vector components through ontological terms. The practical applications of this framework are illustrated through case studies in biomedical contexts, demonstrating enhanced model transparency without compromising performance. This approach establishes a measurable pathway for reconciling statistical language representations with structured domain knowledge, particularly benefiting fields requiring precise concept alignment like biomedicine. The implementation is publicly available at: https://github.com/Mellandd/DEIBO .},
  archive      = {J_KBS},
  author       = {Jose L. Mellina-Andreu and Alejandro Cisterna-García and Juan A. Botía},
  doi          = {10.1016/j.knosys.2025.114507},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114507},
  shortjournal = {Knowl. Based Syst.},
  title        = {Data-driven interpretation of dimensions in an embedding language model based on a reference knowledge graph},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-granularity facial aesthetic evaluation model based on image-text modality. <em>KBS</em>, <em>330</em>, 114502. (<a href='https://doi.org/10.1016/j.knosys.2025.114502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial Beauty Prediction (FBP) is an emerging research direction at the intersection of artificial intelligence and aesthetics, which has attracted increasing attention in recent years. However, most existing methods rely solely on unimodal data and fail to comprehensively capture the multi-dimensional information of facial aesthetics. To address this challenge, we propose a multigranularity facial aesthetic evaluation model based on image-text modality (ITM-MGFA). By incorporating multi-granularity cognitive theory into the FBP task, the model effectively integrates both coarse-grained and fine-grained aesthetic features extracted from the CLIP encoder through a multigranularity representation module, a task-oriented dynamic alignment module, and a hierarchical interaction optimization module. This facilitates deep cross-modal interaction and fusion, significantly enhancing the model’s capability to model complex aesthetic attributes. Experimental results demonstrate that ITM-MGFA, leveraging the fusion of cross-modal information, achieves higher accuracy in facial aesthetic assessment task compared to traditional unimodal methods, offering a new direction for FBP research. Furthermore, the model can be applied in various scenarios, such as: simulation postoperative assessment of personalized cosmetic surgery in the medical aesthetics; selection of optimal facial aesthetic enhancement solutions on social media; and recommendation of matching solutions in cosmetic recommendation.},
  archive      = {J_KBS},
  author       = {Huanyu Chen and Yong Wang and Weisheng Li and Bin Xiao},
  doi          = {10.1016/j.knosys.2025.114502},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114502},
  shortjournal = {Knowl. Based Syst.},
  title        = {A multi-granularity facial aesthetic evaluation model based on image-text modality},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A domain generalized UAV tracking framework via frequency-aware learning and target-aligned data augmentation in complex environments. <em>KBS</em>, <em>330</em>, 114501. (<a href='https://doi.org/10.1016/j.knosys.2025.114501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) tracking plays a critical role in airborne autonomous systems, supporting applications such as disaster response, agricultural monitoring, and military surveillance. However, existing tracking methods often exhibit poor generalization in real-world deployments due to domain shifts between the training and target environments. We propose DGTrack, a novel single-source domain generalization framework for UAV visual tracking. DGTrack integrates a Frequency-Aware Learning (FAL) module that separates and adaptively modulates low- and high-frequency components to reduce stylistic interference while enhancing content representation. In addition, a Target-Aligned Augmentation (TAA) module is introduced to improve source domain diversity through multi-level transformations and to align predictions between original and augmented frames by maximizing mutual information. Extensive experiments on the UAVDT and VisDrone2019 datasets demonstrate that DGTrack achieves superior generalization to unseen domains and consistently outperforms state-of-the-art UAV trackers in single-source settings.},
  archive      = {J_KBS},
  author       = {Erfeng Liu and Xinde Li and Heqing Li and Guoliang Wu and Tao Shen},
  doi          = {10.1016/j.knosys.2025.114501},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114501},
  shortjournal = {Knowl. Based Syst.},
  title        = {A domain generalized UAV tracking framework via frequency-aware learning and target-aligned data augmentation in complex environments},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing forex market forecasting with feature-augmented multivariate LSTM models using real-time data. <em>KBS</em>, <em>330</em>, 114500. (<a href='https://doi.org/10.1016/j.knosys.2025.114500'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a feature-augmented multivariate LSTM model for real-time Forex market forecasting. By incorporating engineered financial indicators—such as Close_Change, RSI, and gold price—alongside traditional OHLCV data, the model captures nonlinear temporal dynamics and macro-financial interactions. A sliding window approach structures input sequences for a stacked LSTM network optimized for short-term prediction. Experimental results on major currency pairs demonstrate that the proposed model outperforms baseline LSTM, GRU, and classical machine learning methods in RMSE, MAE, and MAPE metrics. Statistical validation using the Wilcoxon signed-rank test confirms the improvements are significant. The model's robustness under volatility stress and noisy inputs highlights its practical relevance for real-time decision-making. Potential extensions include incorporating news-based sentiment and multimodal signals to enhance adaptability.},
  archive      = {J_KBS},
  author       = {Duong Thi Kim Chi and Ho Ngoc Trung Kien and Thanh Q. Nguyen},
  doi          = {10.1016/j.knosys.2025.114500},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114500},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing forex market forecasting with feature-augmented multivariate LSTM models using real-time data},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain-generalized token linking in vision foundation models for semantic segmentation. <em>KBS</em>, <em>330</em>, 114497. (<a href='https://doi.org/10.1016/j.knosys.2025.114497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {[S U M M A R Y] Vision Foundation Models (VFMs) achieve remarkable performance compared with traditional methods based on convolutional neural networks and vision transformer networks in Domain-Generalized Semantic Segmentation (DGSS). These VFM-based DGSS methods focus on adopting efficient parameter fine-tuning strategies that use a set of learnable tokens to fine-tune VFMs to the downstream DGSS task, yet struggle to mine domain-invariant information from VFMs since the backbone of VFMs is frozen during the fine-tuning stage. To address this issue, a Domain-Generalized Token Linking (DGTL) approach is proposed to mine domain-invariant information from VFMs for improving the performance in unseen target domains, which contains a Text-guided Dual Token Linking (TDTL) module and a Text-guided Distribution Normalization (TDN) strategy. For the TDTL module, first, a set of learnable tokens is linked to the text embeddings for building the relations between the learnable tokens and text embeddings, which is beneficial for learning domain-invariant tokens since the text embeddings generated from the CLIP model are domain-invariant. Second, the feature-level and mask-level linking strategies are proposed to link the learned domain-invariant tokens to the features and masks to guide the mining of domain-invariant information from the VFM. For the TDN strategy, the pairwise similarity between the predictive masks associated with the learnable tokens and the text embeddings is utilized to explicitly align the semantic distribution of visual features in the learnable tokens with the text embeddings. Extensive experiments demonstrate that the DGTL approach achieves superior performance to recent methods across multiple DGSS benchmarks. The code is released on GitHub: https://github.com/seabearlmx/DGTL .},
  archive      = {J_KBS},
  author       = {Muxin Liao and Jiayang Wang and Hong Deng and Yingqiong Peng and Hua Yin and Yinglong Wang and Guoguang Hua},
  doi          = {10.1016/j.knosys.2025.114497},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114497},
  shortjournal = {Knowl. Based Syst.},
  title        = {Domain-generalized token linking in vision foundation models for semantic segmentation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive exploration for few-shot incremental learning. <em>KBS</em>, <em>330</em>, 114496. (<a href='https://doi.org/10.1016/j.knosys.2025.114496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot class incremental learning (FSCIL) poses a challenging problem in computer vision, where conventional deep models suffer from catastrophic forgetting and overfitting to novel classes. Inspired by the dynamic learning processes observed in human cognition when adapting to unfamiliar scenarios, we propose a deep exploratory incremental learning framework that incrementally refines the classifier model through a trial-and-error decision making process. A joint distribution-aware reward function is introduced to guide learning, incorporating three key factors: intra-class compactness, inter-class dispersion, and cross-session consistency, enabling balanced knowledge retention and acquisition. Furthermore, we design a dynamic gradient guidance module that adaptively adjusts gradient updates within a Gaussian-derived policy space, enhancing training stability and mitigating overfitting risks in the few shot regime. Extensive experiments conducted on three publicly available datasets demonstrate the effectiveness of the proposed method, achieving state-of-the-art performance in the FSCIL setting.},
  archive      = {J_KBS},
  author       = {Cao Han and Ziqi Gu and Chunyan Xu and Zhen Cui},
  doi          = {10.1016/j.knosys.2025.114496},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114496},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adaptive exploration for few-shot incremental learning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiphysics coupling AI prediction method for thermomechanical behavior of steel ladle linings. <em>KBS</em>, <em>330</em>, 114495. (<a href='https://doi.org/10.1016/j.knosys.2025.114495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the thermomechanical responses of refractory linings in steel ladles is critical to optimizing production efficiency and ensuring safety in the iron and steel smelting industry. However, traditional numerical simulation methods suffer challenges of high computational costs and insufficient generalizability, while data-driven models are limited by a lack of physical rationality and poor interpretability. Aiming at overcoming these challenges, an artificial intelligence (AI) model, named the steel ladle Kolmogorov–Arnold network (SLKAN), is designed to predict the thermomechanical behavior of ladle linings. Based on the Kolmogorov–Arnold theorem and material constitutive equations, SLKAN precisely predicts the thermomechanical behavior of ladle linings. The model offers substantial advantages in predicting the maximum tensile stress in the steel shell and the maximum compressive stress at the working lining hot face: the coefficient of determination (R 2 ) value for compressive stress prediction reaches 0.9942, with a mean absolute error (MAE) of 9.4136 and a root mean squared error (RMSE) of 0.0192; the R 2 value for tensile stress prediction is 0.9578, with an MAE of 41.4855 and an RMSE of 0.0385. Further analysis indicates that the function expressions of SLKAN hold clear physical significance. This study provides an interpretable, efficient AI solution for multiphysics coupling modeling in complex industrial scenarios and offers theoretical guidance for the application of AI in predicting the lifespan of steel-smelting equipment.},
  archive      = {J_KBS},
  author       = {Yi Yin and Zongxian Long and Shengli Jin and Yawei Li and Fang Wang and Xin Xu},
  doi          = {10.1016/j.knosys.2025.114495},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114495},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multiphysics coupling AI prediction method for thermomechanical behavior of steel ladle linings},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient yet secure: An archive knowledge graph-enhanced native sparse attention network for lightweight privacy-preserving recommendation. <em>KBS</em>, <em>330</em>, 114490. (<a href='https://doi.org/10.1016/j.knosys.2025.114490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation Systems (RSs) aim to provide personalized recommendations by modeling user-item interaction patterns. Current attribute-enhanced RSs leverage user archival attributes to improve predictive performance. However, the use of attribute information introduces two critical challenges: 1) the risk of privacy leakage, as sensitive user attributes can be inferred from learned representations, and 2) high computational complexity, primarily due to the quadratic complexity of attention mechanisms. To address the accuracy-privacy-efficiency trilemma, we propose an Archive Knowledge Graph-enhanced Native Sparse Attention network (AKG-NSA) for privacy-preserving lightweight recommendation. Specifically, AKG-NSA introduces a two-stage privacy protection mechanism. First, we pseudonymize user identities in the archive knowledge graph, breaking the direct linkage between users and their attributes. Second, we design a Multi-channel Native Sparse Attention (MNSA) network that utilizes compressed user representations as queries to retrieve attribute patterns from the archive knowledge graph in a privacy-preserved manner. Moreover, we also construct a parallel user-item bipartite graph and operate graph convolutions to learn the representations for users and items. By employing the native sparse attention mechanism, AKG-NSA refines the learned representations while maintaining a low computational complexity. Extensive experiments on three real-world datasets demonstrate that AKG-NSA outperforms nine state-of-the-art baselines in terms of prediction accuracy, privacy preservation, and computational efficiency. The data and source codes of this work are available at https://github.com/juandu113/AKG-NSA .},
  archive      = {J_KBS},
  author       = {Juan Du and Chenxi Ma and Yaobin Wang and Limei Sun},
  doi          = {10.1016/j.knosys.2025.114490},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114490},
  shortjournal = {Knowl. Based Syst.},
  title        = {Efficient yet secure: An archive knowledge graph-enhanced native sparse attention network for lightweight privacy-preserving recommendation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-source heterogeneous sensor information fusion framework for intelligent online chatter detection in different milling conditions. <em>KBS</em>, <em>330</em>, 114488. (<a href='https://doi.org/10.1016/j.knosys.2025.114488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online chatter detection is a critical technology in intelligent manufacturing systems, essential for ensuring high-quality and efficient milling operations. Although artificial intelligence models have been developed to automatically identify chatter, the accuracy improvement is limited by the use of single sensor signals. Therefore, a multi-source heterogeneous sensor information fusion framework is proposed for intelligent online chatter detection in this paper. To effectively mitigate noise and eliminate interference from milling parameters, a heterogeneous sensor signal processing strategy is proposed based on wavelet packet decomposition and successive variational mode decomposition. Next, a multi-source, multi-stage, and multi-scale spatial-temporal fusion attention network is proposed for extracting chatter features and achieving high-precision chatter detection. It is noteworthy that multi-source signals are fused at the feature level, and comprehensive chatter features are extracted through the multi-source information fusion module, the multi-stage spatial-temporal feature extraction and fusion module, and the multi-scale gated channel attention module. In milling experiments across different conditions, the chatter detection performance of the proposed framework is evaluated in three scenarios. The results indicate that this framework can provide more accurate and reliable detection results compared to other methods.},
  archive      = {J_KBS},
  author       = {Liangshi Sun and Xianzhen Huang and Zhiyuan Jiang and Jiatong Zhao and Xu Wang},
  doi          = {10.1016/j.knosys.2025.114488},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114488},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-source heterogeneous sensor information fusion framework for intelligent online chatter detection in different milling conditions},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class-conditional image synthesis with intra-class relation preservation. <em>KBS</em>, <em>330</em>, 114487. (<a href='https://doi.org/10.1016/j.knosys.2025.114487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling class-conditional data distributions remains challenging, since the intra-class variation may be very large. Different from generic class-conditional Generative Adversarial Networks (GANs), we take inspiration from the observation that there may exist multiple modes with diverse visual appearances in a single class, and propose an Intra-class Prototype-based Relation Preservation (IPRP) approach to improve class-conditional image synthesis. Toward this end, a generator is designed to learn class-specific data distribution, conditioned on intra-class prototype-based relation. To associate label embeddings with the cluster prototypes, we incorporate an auxiliary prototypical network to perform adversarial interpolation, and the synthesized data are required to encapsulate their relation to the corresponding prototypes in the form of interpolation coefficients. The prototypical network can be further leveraged to improve the class-conditional real-fake identification performance by injecting semantics-aware features into a discriminator. This design allows the generator to better capture intra-class modes We conduct extensive experiments to demonstrate that IPRP outperforms the competing class-conditional GANs in terms of data diversity and semantic accuracy.},
  archive      = {J_KBS},
  author       = {Yunfei Zhang and Xiaoyang Huo and Tianyi Chen and Si Wu and Hau-San Wong},
  doi          = {10.1016/j.knosys.2025.114487},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114487},
  shortjournal = {Knowl. Based Syst.},
  title        = {Class-conditional image synthesis with intra-class relation preservation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A supervised learning approach to dynamic weighted fusion in multi-source ordered decision systems. <em>KBS</em>, <em>330</em>, 114485. (<a href='https://doi.org/10.1016/j.knosys.2025.114485'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of new-generation artificial intelligence technologies, machines can process and analyze large-scale data more accurately and efficiently and for more complex tasks. Enhancing the usability and value of the information derived from various information systems across multiple dimensions is essential. However, traditional data dominance relationships cannot reflect people’s different levels of attention to antithetic features, leading to higher complexity and lower classification accuracy. Therefore, it is necessary to consider the weight relationships between attributes in the data, which refers to the degree of correlation between each attribute and the decision in multi-source information systems. Based on these weights and dominance relationships, we consider an entropy-based weighted information fusion method for processing supervised data in multi-source ordered decision systems. We intend four incremental fusion mechanisms to adjust information sources and attribute changes to save running time. Furthermore, experiments are conducted on nine real datasets to demonstrate our method’s effectiveness. The results show that the inevitable accuracy comparisons by the proposed method are superior to most fusion methods. In addition, the dynamic mechanisms, compared to static mechanisms, can significantly reduce running time.},
  archive      = {J_KBS},
  author       = {Xiaoyan Zhang and Jiajia Lin},
  doi          = {10.1016/j.knosys.2025.114485},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114485},
  shortjournal = {Knowl. Based Syst.},
  title        = {A supervised learning approach to dynamic weighted fusion in multi-source ordered decision systems},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Potential subgraph rule and reasoning context enhancement for sparse multi-hop knowledge graph reasoning. <em>KBS</em>, <em>330</em>, 114483. (<a href='https://doi.org/10.1016/j.knosys.2025.114483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-hop knowledge graph reasoning aims to leverage the relations between multiple nodes in a knowledge graph to reason information about an event or entity. This reasoning process requires traversing multiple interconnected facts or knowledge points, which aids in understanding the model’s decision-making process. Multi-hop knowledge graph reasoning has driven the development of knowledge-based technologies, such as question-answering systems and recommendation systems. However, multi-hop reasoning relies on the connectivity between different entities in the knowledge graph. This characteristic makes multi-hop reasoning lack robustness when dealing with sparse data. To address the challenges of sparsity, recent studies pre-train knowledge graph embedding models to complete potential triples. The completion methods introduce noisy triples, which increases the risk of model selection errors and spurious paths. In this work, we propose a framework based on potential subgraph rule and reasoning context enhancement to mitigate the challenges of sparsity. On one hand, we leverage reasoning context to enhance state information and the reasoning process; on the other hand, we design an action perceptron based on the importance of reasoning context to reduce the introduction of noisy triples. Additionally, we analyze the phenomenon of data augmentation introducing spurious paths, and further utilize data augmentation-based potential subgraph rules to guide the reasoning process. This dual mechanism demonstrates stronger robustness in addressing sparsity challenges and spurious paths. Diverse experiments demonstrate that our model outperforms the existing multi-hop reasoning models across five datasets. Our implementations will be publicly available at: https://github.com/jianruichen/PreKGR .},
  archive      = {J_KBS},
  author       = {Congcong Sun and Jianrui Chen and Deguang Chen and Junjie Huang},
  doi          = {10.1016/j.knosys.2025.114483},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114483},
  shortjournal = {Knowl. Based Syst.},
  title        = {Potential subgraph rule and reasoning context enhancement for sparse multi-hop knowledge graph reasoning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAMR: Multi-scale graph contrastive learning with dynamic adjustment and mutual rectification. <em>KBS</em>, <em>330</em>, 114482. (<a href='https://doi.org/10.1016/j.knosys.2025.114482'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning (GCL) has emerged as a powerful self-supervised approach for learning generalized graph representations, achieving remarkable advancements in recent years. However, most existing GCL methods ignore the noise of the augmented global structure and the dynamic change in training, and lack detailed consideration in calculating local structural homogeneity. These limitations may lead to the model’s insufficient performance in capturing fine-grained semantic features at the node level, making it difficult to fully explore the potential semantic associations between adjacent nodes. Meanwhile, on a global scale, there is also a lack of the ability to model complex topological structures. To this end, we propose a new multi-scale graph contrastive learning with dynamic adjustment and mutual rectification. This method dynamically adjusts the global structure via graph reconstruction and adaptively learns node representations; Meanwhile, a mutual rectification module is designed to predict the support scores of neighbors relative to anchors and quantify each neighbor’s contribution to view agreement. Both reconstruction and rectification are integrated into the training objective and effectively capture the graph structure information from both global and local scales, improving the quality and robustness of graph representations. We conduct extensive experiments on three downstream tasks: node classification, node clustering, and link prediction. The experimental results demonstrate that our method outperforms existing GCL methods across multiple tasks and datasets, validating the effectiveness and generalizability of the proposed model.},
  archive      = {J_KBS},
  author       = {Dengdi Sun and Zhixiang Wu and Mingwei Cao and Zhifu Tao and Zhuanlian Ding},
  doi          = {10.1016/j.knosys.2025.114482},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114482},
  shortjournal = {Knowl. Based Syst.},
  title        = {DAMR: Multi-scale graph contrastive learning with dynamic adjustment and mutual rectification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). P-EVFL: Efficient verifiable federated learning with privacy. <em>KBS</em>, <em>330</em>, 114480. (<a href='https://doi.org/10.1016/j.knosys.2025.114480'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning has recently become popular and widely used in various areas. However, it still faces challenges like the leakage of the client’s local model updates and the server forging aggregation results. To address these issues, we propose an efficient verifiable federated learning scheme with privacy (P-EVFL), which seeks to ensure privacy and verifiability with a lower overhead. Specifically, we first design a lightweight masking technique to protect the honest clients’ local model updates. Next, we introduce homomorphic hash functions to develop a verifiable method to ensure the integrity of the aggregation results. Besides, to reduce the overhead of the verification process, a verification algorithm based on a Merkle tree is proposed. We also conduct comprehensive experiments and compare our scheme with other state-of-the-art schemes. The experimental results show that in a scenario with 100 clients, our scheme reduces the computational overhead by up to 8.15 % and the communication overhead by up to 67.38 %.},
  archive      = {J_KBS},
  author       = {Juan Ma and Xiangshen Ma and Yuling Chen},
  doi          = {10.1016/j.knosys.2025.114480},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114480},
  shortjournal = {Knowl. Based Syst.},
  title        = {P-EVFL: Efficient verifiable federated learning with privacy},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to extract and aggregate contexts for link prediction in heterogeneous graphs. <em>KBS</em>, <em>330</em>, 114478. (<a href='https://doi.org/10.1016/j.knosys.2025.114478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many diverse real-world graph datasets are heterogeneous graphs, and link prediction on these graphs is a fundamental task. The current trends of link prediction on heterogeneous graphs emphasize leveraging contextual information from either a path between a source node and a target node, or a sub-graph sampled around these two nodes. However, these approaches face limitations in identifying only beneficial contextual nodes around source and target and then effectively aggregating the representations of these nodes for improving overall prediction accuracy. To address these limitations, we claim that carefully-extracted context nodes can aid in accurate link prediction, and these context nodes should be similar to a source node or a target node in a representation space. To this end, we propose a new link prediction framework LEACH which learns to extract the beneficial context nodes and to aggregate their representations in heterogeneous graphs. Specifically, our approach involves three steps to learn: (i) generating heterogeneity-aware representations of nodes in the heterogeneous graph, (ii) selecting the context nodes based on the relatedness to the source and target nodes; and (iii) aggregating the representations of the context nodes to obtain the source and target representations. Extensive experiments demonstrate that LEACH significantly outperforms existing baselines on three publicly available heterogeneous graph datasets. We provide analytical insights into the rationale behind the superior performance of LEACH on link prediction.},
  archive      = {J_KBS},
  author       = {Jimin Woo and Minbae Park and Hyunjoon Kim},
  doi          = {10.1016/j.knosys.2025.114478},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114478},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning to extract and aggregate contexts for link prediction in heterogeneous graphs},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced people analytics: Integrating tournament theory, human capital theory, and social network theory for enhanced HRIS and performance evaluation. <em>KBS</em>, <em>330</em>, 114477. (<a href='https://doi.org/10.1016/j.knosys.2025.114477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the integration of advanced data analytics techniques within People Analytics and Human Resource Information Systems (HRIS), emphasizing their application in both organizational and sports performance contexts. By synthesizing Tournament Theory, Human Capital Theory, and Social Network Theory, this research provides a comprehensive framework for understanding skill dissemination, performance evaluation, and wage determination. Utilizing the NBA 2 K dataset, this study quantifies both tangible and intangible player attributes, incorporating digital engagement and social media metrics to enhance traditional performance metrics. Employing community detection algorithms and the Independent Cascade Model, the research uncovers hidden competencies and their influence on team dynamics and organizational effectiveness. The results contest established HRIS approaches, suggesting a holistic talent management strategy that takes into account the multifacetedness of skills propagation through networks. This work offers significant implications for HR professionals, providing novel insights into strategic HR planning, talent acquisition, and performance management in the digital age.},
  archive      = {J_KBS},
  author       = {Tianzi Zheng and Riyaz Sikora},
  doi          = {10.1016/j.knosys.2025.114477},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114477},
  shortjournal = {Knowl. Based Syst.},
  title        = {Advanced people analytics: Integrating tournament theory, human capital theory, and social network theory for enhanced HRIS and performance evaluation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing leadership-based metaheuristics using reinforcement learning: A case study in grey wolf optimizer. <em>KBS</em>, <em>330</em>, 114471. (<a href='https://doi.org/10.1016/j.knosys.2025.114471'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristics are widely applied in optimization because of their flexibility and ability to address complex and high-dimensional problems. Nevertheless, they face persistent challenges, including susceptibility to local optima, limited parameter adaptability, and premature convergence. Leadership-based metaheuristics, in which leaders guide the search process, encounter additional difficulties such as limited exploration capacity, leader stagnation, and reduced diversity, often stemming from underutilization of data generated during the search. To overcome these limitations, this study proposes a reinforcement learning–based approach, RL-LGWO, which enhances the Grey Wolf Optimizer (GWO) by integrating multi-agent reinforcement learning. In RL-LGWO, agents share experiences to improve decision-making, and reinforcement learning is employed to decouple and adapt the leader update mechanism, thereby improving the exploration–exploitation balance and enabling leaders to dynamically escape local optima. The proposed method was evaluated against two GWO-enhancing algorithms, three RL-based GWO variants, PSO, WOA, and the original GWO across 23 well-known benchmark functions, in addition to the recent CEC2022 benchmark suite. Experimental results show that RL-LGWO achieved the best solutions on 17 of the 23 benchmark functions, with superior convergence speed and improved stability, while incurring only a minor runtime increase compared with the original GWO. Furthermore, on the CEC2022 suite, RL-LGWO outperformed competing algorithms on 10 of 12 test functions, underscoring its robustness and adaptability to recent and challenging benchmarks. Overall, the findings indicate that RL-LGWO delivers a substantive improvement over state-of-the-art alternatives and holds strong potential to advance leadership-based metaheuristics for a wide range of optimization problems.},
  archive      = {J_KBS},
  author       = {Afifeh Maleki and Mehdy Roayaei and Seyedali Mirjalili},
  doi          = {10.1016/j.knosys.2025.114471},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114471},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing leadership-based metaheuristics using reinforcement learning: A case study in grey wolf optimizer},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MRBalance: A framework for enhancing event causality identification in multi-agent debates via role assignment. <em>KBS</em>, <em>330</em>, 114470. (<a href='https://doi.org/10.1016/j.knosys.2025.114470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of large language models (LLMs) has advanced natural language processing by improving contextual understanding and generalization abilities. However, despite these advances, determining event causality remains a challenging task. When LLMs are applied to this task, they frequently exhibit significant inconsistencies in recognizing causal representations, resulting in the phenomenon known as causal hallucinations. Specifically, LLMs perform well in predicting events with causal relationships but struggle with events without such relationships, frequently failing to achieve balanced performance across different causal scenarios. In this study, we propose MRBalance, a novel framework that uses role-based multi-agent debates to improve event causality identification. Our method transforms the task into a single-choice question-answering task, prompting LLM-based agents to engage in structured debates and justify their answers using their unique role-based perspectives. In addition, we introduce a mechanism for optimizing team members that selects the best agents to participate in the next debate when the debate rounds are lengthy. Extensive experiments on two benchmark datasets demonstrate significant performance improvements, highlighting the effectiveness of MRBalance in reducing causal hallucinations and increasing robustness.},
  archive      = {J_KBS},
  author       = {Xiang Zou and Xuanhong Li and Po Hu and Ming Dong},
  doi          = {10.1016/j.knosys.2025.114470},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114470},
  shortjournal = {Knowl. Based Syst.},
  title        = {MRBalance: A framework for enhancing event causality identification in multi-agent debates via role assignment},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MIAFEx: An attention-based feature extraction method for medical image classification. <em>KBS</em>, <em>330</em>, 114468. (<a href='https://doi.org/10.1016/j.knosys.2025.114468'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature extraction techniques are crucial in medical image classification; however, classical feature extractors, in addition to traditional machine learning classifiers, often exhibit significant limitations in providing sufficient discriminative information for complex image sets. While Convolutional Neural Networks (CNNs) and Vision Transformer (ViT) have shown promise in feature extraction, they are prone to overfitting due to the inherent characteristics of medical imaging data, including small sample sizes or high intra-class variance. In this work, the Medical Image Attention-based Feature Extractor (MIAFEx) is proposed, a novel method that employs a learnable refinement mechanism to enhance the classification token within the Transformer encoder architecture. This mechanism adjusts the token based on learned weights, improving the extraction of salient features and enhancing the model’s adaptability to the challenges presented by medical imaging data. The MIAFEx output feature quality is compared against classical feature extractors using traditional and hybrid classifiers. Also, the performance of these features is compared against modern CNN and ViT models in classification tasks, demonstrating their superiority in accuracy and robustness across multiple complex medical imaging datasets. This advantage is particularly pronounced in scenarios with limited training data, where traditional and modern models often struggle to generalize effectively. The source code of this proposal can be found at github.com/Oscar-RamosS/Medical-Image-Attention-based-Feature-Extractor-MIAFEx .},
  archive      = {J_KBS},
  author       = {Oscar Ramos-Soto and Jorge Ramos-Frutos and Ezequiel Pérez-Zarate and Diego Oliva and Sandra E. Balderas-Mata},
  doi          = {10.1016/j.knosys.2025.114468},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114468},
  shortjournal = {Knowl. Based Syst.},
  title        = {MIAFEx: An attention-based feature extraction method for medical image classification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing dual network based semi-supervised medical image segmentation with uncertainty-guided pseudo-labeling. <em>KBS</em>, <em>330</em>, 114454. (<a href='https://doi.org/10.1016/j.knosys.2025.114454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the remarkable performance of supervised medical image segmentation models, relying on a large amount of labeled data is impractical in real-world situations. Semi-supervised learning approaches aim to alleviate this challenge using unlabeled data through pseudo-label generation. Yet, existing semi-supervised segmentation methods still suffer from noisy pseudo-labels and insufficient supervision within the feature space. To solve these challenges, this paper proposes a novel semi-supervised 3D medical image segmentation framework based on a dual-network architecture. Specifically, we investigate a Cross Consistency Enhancement module using both cross pseudo and entropy-filtered supervision to reduce the noisy pseudo-labels, while we design a dynamic weighting strategy to adjust the contributions of pseudo-labels using an uncertainty-aware mechanism (i.e., Kullback–Leibler divergence). In addition, we use a self-supervised contrastive learning mechanism to align uncertain voxel features with reliable class prototypes by effectively differentiating between trustworthy and uncertain predictions, thus reducing prediction uncertainty. Extensive experiments are conducted on three 3D segmentation datasets, Left Atrial, NIH Pancreas and BraTS-2019. The proposed approach consistently exhibits superior performance across various settings (e.g., 89.95 % Dice score on left Atrial with 10 % labeled data) compared to the state-of-the-art methods. Furthermore, the usefulness of the proposed modules is further validated via ablation experiments. The code repository is available at https://github.com/AIPMLab/Semi-supervised-Segmentation .},
  archive      = {J_KBS},
  author       = {Yunyao Lu and Yihang Wu and Ahmad Chaddad and Tareef Daqqaq and Reem Kateb},
  doi          = {10.1016/j.knosys.2025.114454},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114454},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing dual network based semi-supervised medical image segmentation with uncertainty-guided pseudo-labeling},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions. <em>KBS</em>, <em>330</em>, 114452. (<a href='https://doi.org/10.1016/j.knosys.2025.114452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilization of transfer learning strategies to solve cross-domain fault diagnosis problems has achieved significant results. However, most existing multi-source domain generalization fault diagnosis methods use a single classifier or introduce auxiliary classifiers, focusing on learning domain-invariant features or global feature distribution matching. Furthermore, since the data distributions of different source domains may be significantly different, this may lose the data distribution information specific to each source domain. In addition, how to reduce the variation in risk between samples within the same domain training is also a challenging issue. Finally, it is also crucial to balance the predictive outputs of multiple classifiers to adapt them to the data distribution of the target domain. Based on the above challenges, this paper proposes a multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions. Feature weakly decoupled mechanism is achieved by employing multiple classifiers and incorporating the variance of samples within the same sample domain as a penalty term. This reduces the model’s sensitivity to changes in the extreme distribution of samples within the domain. Classifier weakly decoupled mechanism, on the other hand, reduces the inter-domain risk variance by minimizing the loss of variance in the predicted output of the source domain classifiers. This improves the robustness of the model to inter-domain distributional changes and covariate changes. Experimental results on three datasets validate the effectiveness and general applicability of the proposed approach.},
  archive      = {J_KBS},
  author       = {Yawei Sun and Hongfeng Tao and Vladimir Stojanovic},
  doi          = {10.1016/j.knosys.2025.114452},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114452},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing large language models for bitcoin time series forecasting. <em>KBS</em>, <em>330</em>, 114449. (<a href='https://doi.org/10.1016/j.knosys.2025.114449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent advancements in application of deep learning to time series forecasting, focus has shifted from training transformers end-to-end to efficiently leveraging the predictive capabilities of Large Language Models (LLMs). Models that encode the time series data to interact with a frozen LLM backbone have been shown to outperform transformers on all benchmark datasets. However, their efficiency on complex datasets, which do not show clear seasonality or trend, remains an open question. In this work, we seek to evaluate the performance of reprogrammed LLMs on the Bitcoin price chart, a financial time series known for its complexity and high volatility. We propose effective methods to improve the performance of Time-LLM, a State-of-the-art (SOTA) method, on such a time series. First, we propose structural improvements to Time-LLM. Second, we suggest an efficient way to handle the non-stationarity of the dataset. Finally, we propose an efficient method for passing additional financial information to the LLM. Our results demonstrate a 50 % improvement on the average percentage loss and a 5 % increase on accuracy of our adapted Time-LLM architecture on Bitcoin data when compared to SOTA models, including the original Time-LLM model. This highlights the impact on forecast accuracy of domain-specific decision making in data processing and feature selection.},
  archive      = {J_KBS},
  author       = {Owen Chaffard and Pablo Mollá and Marc Cavazza and Helmut Prendinger},
  doi          = {10.1016/j.knosys.2025.114449},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114449},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing large language models for bitcoin time series forecasting},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CausalEnhance: Knowledge-enhanced pre-training for causality identification and extraction. <em>KBS</em>, <em>330</em>, 114447. (<a href='https://doi.org/10.1016/j.knosys.2025.114447'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causality identification and extraction are crucial in understanding causal relationships in text. Current studies heavily rely on datasets annotated with causal relationships. However, acquiring such datasets poses a challenge due to substantial costs, hindering progress in this research field. To address this, we introduce CausalEnhance, a novel approach designed to bridge this gap by combining weakly-guided pre-training with external causal knowledge. Our method starts with a rule-based system that automates causal annotation, enriching external data with explicit causal knowledge and creating pseudo labels. These pseudo-labels are then incorporated into a weakly supervised pre-training framework. We introduce three innovative pre-training tasks: the Pre-training Causal Clues Fill-Mask task (PCM) to pinpoint causality origins, the Pre-training Causality Identification task (PCI) to capture general causal patterns, and the Pre-training Causality Extraction task (PCE) for understanding explicit causal pairs and inferring implicit ones. Our experiments, conducted across eight datasets in two languages, English and Chinese, demonstrate CausalEnhance’s effectiveness in both identifying and extracting causality, highlighting its potential as a robust method for textual causality analysis in different linguistic contexts.},
  archive      = {J_KBS},
  author       = {Meiyun Wang and Kiyoshi Izumi and Hiroki Sakaji},
  doi          = {10.1016/j.knosys.2025.114447},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114447},
  shortjournal = {Knowl. Based Syst.},
  title        = {CausalEnhance: Knowledge-enhanced pre-training for causality identification and extraction},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Margin-guided parameter decoupling-consensus framework for federated domain generalization in machinery fault diagnosis. <em>KBS</em>, <em>330</em>, 114446. (<a href='https://doi.org/10.1016/j.knosys.2025.114446'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated domain generalization (FDG) as a solution to address the cross-client data heterogeneity problem in privacy-sensitive scenarios has drawn extensive attention in the field of intelligent fault diagnosis of industrial equipment in recent years. Nevertheless, most of the existing FDG-based diagnosis methods rely on client feature distribution alignment or data augmentation strategies, risking data leakage caused by the transmission of deep features and statistical information. To overcome the above-mentioned issues, a margin-guided parameter decoupling-consensus (MGPDC) framework is proposed to decouple the dependence of conventional federated domain generalization methods on features and data distributions and realize the extraction of common knowledge across clients. This framework initially employs a federated meta-learning-driven universal feature extractor to create a transferable shared feature space amidst heterogeneous client data, effectively enhancing the generalization ability of the model for unknown working conditions. Next, a parameter decoupling-consensus synergy (PDCS) mechanism is proposed. In this mechanism, an isolation module is established based on the consistency of parameter updates for parameter decoupling, effectively suppressing model update conflict. Subsequently, an implicit alignment mapping approach is devised for the screened parameters with strong consistency to achieve the extraction of cross-domain common knowledge. Then, an adaptive global margin guidance (AGMG) strategy is proposed to mitigate the interference of the blurred class boundaries during the federated process on common knowledge extraction. Finally, extensive experiments using real wind turbine gearbox data demonstrate the effectiveness and advancement of the MGPDC framework.},
  archive      = {J_KBS},
  author       = {Linhan Gou and Qikang Li and Baoping Tang and Xiaolong Zhang and Zihao Li and Yonggang Liu},
  doi          = {10.1016/j.knosys.2025.114446},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114446},
  shortjournal = {Knowl. Based Syst.},
  title        = {Margin-guided parameter decoupling-consensus framework for federated domain generalization in machinery fault diagnosis},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural network to surrogate computational bone remodelling in the calcaneus. <em>KBS</em>, <em>330</em>, 114445. (<a href='https://doi.org/10.1016/j.knosys.2025.114445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a data-driven approach using surrogate models based on Multi-Layer Perceptrons to predict bone remodelling outcomes in the calcaneus, both with and without fractures. The objective is to develop and train a neural network that accurately captures the biomechanical factors influencing the problem and predicts the resulting bone density distribution in the calcaneus. Given the complexity of bone healing processes, a comprehensive dataset was collected to train and validate the models under two distinct scenarios: an intact calcaneus and a fractured calcaneus treated with a surgical screw. Key parameters of the surrogate model, namely, the number of hidden layers, hidden layer size, and activation function, were optimized to enhance model performance. Additionally, training parameters such as learning rate and batch size were tuned. The hyperbolic tangent activation function was found to yield a lower mean squared error compared to the rectified linear units. Larger batch sizes and learning rates were found to improve model performance. The neural network designed to predict bone density in the intact model outperformed the one used for the fractured calcaneus with a screw, largely due to the increased variability in the fractured data. When the fracture did not significantly alter the trabecular distribution, prediction accuracy improved. Finally, the structural response of the models was evaluated, and it was observed that the trabecular arrangement inferred by the neural network tended to produce less stiff responses compared to those from the finite element method, likely due to the smoother density field predicted by the network.},
  archive      = {J_KBS},
  author       = {Ana Pais and Jorge Lino Alves and Jorge Belinha},
  doi          = {10.1016/j.knosys.2025.114445},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114445},
  shortjournal = {Knowl. Based Syst.},
  title        = {A neural network to surrogate computational bone remodelling in the calcaneus},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FCAT: Federated causal adversarial training. <em>KBS</em>, <em>330</em>, 114440. (<a href='https://doi.org/10.1016/j.knosys.2025.114440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal inference has been proven to be a crucial technique for improving the efficacy and explainability of adversarial training (AT). However, its applicability in the decentralized adversarial training paradigm has not been fully explored. Where one potential challenge is to apply the causal inference in the settings of non-independent and identically distributed (Non-IID) federated learning. In particular, the imbalanced data distributions among various clients will unavoidably hinder the efficacy and adaptability of causal inference. To address this issue, this paper proposes a novel yet practical method dubbed Federated Causal Adversarial Training (FCAT), which seeks to improve causal models via calibrated correction information. Additionally, we introduce a lightweight slack aggregation method aimed at addressing client model disparities and minimizing the communication overhead in each iteration. Extensive experimental results demonstrate that FCAT significantly improves the efficacy of causal models in federated adversarial training, and remarkably outperforms the current state-of-the-art (SOTA) competitors on multiple widely-adopted benchmarks.},
  archive      = {J_KBS},
  author       = {Yunhao Feng and Yanming Guo and Mingrui Lao and Yulun Wu and Yishan Li and Yuxiang Xie},
  doi          = {10.1016/j.knosys.2025.114440},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114440},
  shortjournal = {Knowl. Based Syst.},
  title        = {FCAT: Federated causal adversarial training},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural network-based iterative heuristic algorithm for the polynomial robust knapsack problem. <em>KBS</em>, <em>330</em>, 114439. (<a href='https://doi.org/10.1016/j.knosys.2025.114439'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The polynomial robust knapsack problem (PRKP) is a variant of the classic knapsack problem by incorporating uncertain costs and benefits from item combinations, leading to a nonlinear objective function and exponential solution space. These complexities make the PRKP suitable for real-world scenarios where interactions between items unpredictably impact outcomes. However, existing algorithms struggle to efficiently solve large instances of the PRKP due to its computational complexity. Therefore, this paper presents an iterative heuristic algorithm leveraging a neural network (NN) to address the PRKP, reducing the solution space and enabling efficient resolution of subproblems. The framework integrates an NN trained in two steps: general training and fine-tuning. The trained model is then embedded in the iterative heuristic algorithm to tackle the PRKP. A synthetic dataset comprising 2500 instances, ranging from 100 to 1500 items, is created to train the NN. Comparative evaluations are conducted using 1600 benchmark instances from the literature and 140 larger instances containing between 2000 and 15,000 items. We compare our approach against two state-of-the-art algorithms for the PRKP: a genetic algorithm and a random forest-based heuristic. Computational results demonstrate that the proposed algorithm outperforms the genetic algorithm, providing superior solution quality with significantly reduced computing times. Meanwhile, against random forest-based heuristic, it delivers better solution quality with only a moderate increase in computing time. For larger instances, it maintains its advantage in solution quality while remaining computationally efficient. These results highlight the algorithm’s scalability, effectiveness, and potential to address the PRKP.},
  archive      = {J_KBS},
  author       = {José González-Cortés and Carlos Contreras-Bolton},
  doi          = {10.1016/j.knosys.2025.114439},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114439},
  shortjournal = {Knowl. Based Syst.},
  title        = {A neural network-based iterative heuristic algorithm for the polynomial robust knapsack problem},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interplay between bayesian neural networks and deep learning: A survey. <em>KBS</em>, <em>330</em>, 114438. (<a href='https://doi.org/10.1016/j.knosys.2025.114438'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While deep learning models have seen significant success across various domains, their black-box learning nature and lack of interpretability affect their reliability in safety-critical applications like medical diagnostics and autonomous vehicles. In an attempt to address these limitations, Bayesian neural networks (BNNs) offer a promising alternative by incorporating uncertainty estimation into model predictions, enhancing transparency and decision-making. However, BNN development has primarily focused on efficient, high-fidelity approximate inference and guaranteed convergence in asymptotic settings. These are unsuitable for modern high-dimensional, multi-modal, and non-asymptotic deep learning applications, undermining their theoretical advantages. To bridge this gap, this paper provides in-depth reviews on how approximate Bayesian inference leverages deep learning optimization to achieve high efficiency and fidelity in high-dimensional spaces and multi-modal loss landscapes. It also reconciles Bayesian consistency with generalization objectives in non-asymptotic settings and investigates the generalization capabilities of BNNs. Additionally, this survey examines the often-overlooked expressiveness of BNNs, emphasizing how weight uncertainty and the absence of in-between uncertainty affect their performance. This survey aims to inspire BNN practitioners to adopt a deep learning perspective and offer valuable insights to propel further advancements in the field.},
  archive      = {J_KBS},
  author       = {Yinsong Chen and Samson S. Yu and Zhong Li and Jason K. Eshraghian and Chee Peng Lim},
  doi          = {10.1016/j.knosys.2025.114438},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114438},
  shortjournal = {Knowl. Based Syst.},
  title        = {Interplay between bayesian neural networks and deep learning: A survey},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TWDT: Training-free word-level controllable diffusion model for text generation. <em>KBS</em>, <em>330</em>, 114437. (<a href='https://doi.org/10.1016/j.knosys.2025.114437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing controlled text generation (CTG) methods typically require the training of additional components, whereas diffusion models have already achieved fine control in image generation by adjusting latent feature information during the inference process. However, existing diffusion models still face issues such as “attribute leakage” and “overgeneration” when applied to text generation, leading to generated texts lacking precise control. To address these problems, we propose a training-free word-level controllable diffusion language network (TWDT). This network achieves fine-grained control of text generation by adjusting latent space features during the inference process. Specifically, TWDT introduces an Alignment and Word Evaluation (AWE) module, which ensures accurate mapping of the text to a predefined set of feature words through syntactic segmentation and multi-level semantic alignment. At the same time, a similarity threshold filtering mechanism is applied to inject Gaussian noise into low-consistency nodes, ensuring semantic consistency and stability during generation. To evaluate the rigor and accuracy of the model, we have developed a high-quality multi-disease dental diagnostic dataset, all of which are annotated by experienced dental experts, serving as the benchmark for model evaluation. Experimental results show that TWDT outperforms existing diffusion models in terms of generation accuracy and rigor.},
  archive      = {J_KBS},
  author       = {Nan Gao and Yangjie Lu and Peng Chen and Guodao Sun and Ronghua Liang and Yilong Zhang},
  doi          = {10.1016/j.knosys.2025.114437},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114437},
  shortjournal = {Knowl. Based Syst.},
  title        = {TWDT: Training-free word-level controllable diffusion model for text generation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-class intrusion detection system for in-vehicle networks using few-shot learning and convolutional anomaly transformer network. <em>KBS</em>, <em>330</em>, 114436. (<a href='https://doi.org/10.1016/j.knosys.2025.114436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern vehicles depend on the Controller Area Network (CAN) for electronic control unit (ECU) communication, but its inherent vulnerabilities necessitate robust intrusion detection systems (IDS). Current machine learning and deep learning IDS solutions struggle with limited labeled data, class imbalances, and costly data collection processes. Few-shot learning, effective with few labeled samples, remains underexplored for in-vehicle networks (IVNs) despite its potential in data-scarce automotive cybersecurity scenarios. To bridge this gap, we introduce the first few-shot learning approach for multi-class intrusion detection in IVNs, leveraging a novel, lightweight Convolutional Anomaly Transformer. By integrating a 1D convolutional layer with an Anomaly Transformer, our model effectively classifies diverse attack types with minimal training data, mitigating class imbalance. Experiments on the widely-used real-world Car Hacking dataset, the complex ROAD dataset, and the distinct CAN-ML dataset validate its efficacy. On the Car Hacking dataset, we achieve an exceptional F1 score of 0.9994 with only 2 % of training data, improving to 0.9999 with 10 %. On the challenging ROAD dataset, characterized by diverse attacks and high variability, the model achieves an F1 score of up to 0.9980 using just 10 % of training data. Demonstrating strong generalization capabilities, the model also attains an impressive F1 score of 0.9918 on the CAN-ML dataset, which features entirely different vehicles and attack distributions. Furthermore, the lightweight architecture of our proposed IDS enables practical deployment in resource-constrained automotive environments.},
  archive      = {J_KBS},
  author       = {Nguyen Thanh Minh Duy and Truong Hoang Bao Huy and Pham Van Phu and Tien-Dat Le and Daehee Kim},
  doi          = {10.1016/j.knosys.2025.114436},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114436},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-class intrusion detection system for in-vehicle networks using few-shot learning and convolutional anomaly transformer network},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterophily-aware dynamic hypergraph for semi-supervised classification. <em>KBS</em>, <em>330</em>, 114435. (<a href='https://doi.org/10.1016/j.knosys.2025.114435'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypergraph neural networks, as high-order graph neural networks, excel in handling intricate relationships within non-Euclidean infinite-dimensional spaces. However, conventional homophily assumption-based hypergraph methods exhibit limited effectiveness in semi-supervised classification scenarios involving heterophily problem, where neighboring nodes often belong to dissimilar categories. To address this challenge, this paper proposes a Heterophily-Aware Dynamic Hypergraph (HADHG) framework grounded in heterophily assumption through label domain analysis. The framework comprises three key components: a hypergraph-oriented label propagation method for deriving class-specific label features, a label tensor construction approach characterizing node-level heterophily intensity via 2D tensors, and a center attention mechanism that dynamically optimizes hypergraph structures. By enabling nodes to dynamically reconfigure the local graph structure based on microscopic heterophily intensity, HADHG effectively mitigates heterophily interference. Comprehensive experiments using real-flight data from Unmanned Aerial Vehicles and the public Gear dataset highlight the framework’s superiority over state-of-the-art methods. The codes and datasets are openly available at https://github.com/DL-LEO/HADHG .},
  archive      = {J_KBS},
  author       = {Shaojun Liang and Ying Zheng and Housheng Su and Lei Zhang and Yi Yang},
  doi          = {10.1016/j.knosys.2025.114435},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114435},
  shortjournal = {Knowl. Based Syst.},
  title        = {Heterophily-aware dynamic hypergraph for semi-supervised classification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of an enhanced heart attack diagnosis model using knowledge distillation and frequent sequence pattern mining. <em>KBS</em>, <em>330</em>, 114434. (<a href='https://doi.org/10.1016/j.knosys.2025.114434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) algorithms have displayed their effectiveness in predicting sequence modelling compared to various systems. Nevertheless, some limitations of existing methods are the demand for enormous databases, computational expense, and the risk of overfitting. To address these problems, this study proposes a novel DL technique using knowledge distillation and sequence illness pattern recognition from medical databases. Firstly, the input data is pre-processed using the data cleaning method. The size of the sequence dataset and the duration of the sequential patterns are both considered during the process of using PREFIXSPAN to manage long sequential patterns. In the proposed strategy, a lightweight student network is employed to train a strong teacher network, which is produced by a Knowledge Distillation framework. A teacher network is assessed by the Attention Based Densely Connected Capsule Model (Attention-DC). An efficient, low-weight Depthwise Separable Convolutional Neural Network (DSCNN) model is then chosen as the student network. This study uses three datasets to solve enormous database issues. The KD helps prevent the student model from overfitting to noise or specific patterns in the training data. The Improved Coot Optimization Algorithm (ICOA) is applied to adjust the parameter. The hyperparameters used to optimize the performance of the proposed model are Epochs (300), learning rate (0.001), and batch size (32), respectively. The experiments use the resources of three different datasets, and Python is employed to analyze the results. The proposed technique achieves accuracy of 99.512 %, 99.329 % and 99.351 % for the heart disease, cardiovascular disease, and Diabetes dataset.},
  archive      = {J_KBS},
  author       = {Dinesh Kumar Bhawnani and Sunita Soni and Arpana Rawal},
  doi          = {10.1016/j.knosys.2025.114434},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114434},
  shortjournal = {Knowl. Based Syst.},
  title        = {Development of an enhanced heart attack diagnosis model using knowledge distillation and frequent sequence pattern mining},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural chain of thoughts for radiology education. <em>KBS</em>, <em>330</em>, 114433. (<a href='https://doi.org/10.1016/j.knosys.2025.114433'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology education requires trainees to develop both perceptual and interpretive expertise. However, refinement of these skills is often impeded by the limited availability of mentorship, a consequence of the demanding schedules of experienced radiologists. This lack of personalized guidance makes it difficult for learners to recognize the mistakes they make, understand why those errors occurred and how to refine their perceptual processes. Many of these errors arise from subtle differences in visual attention, such as failing to fixate on an abnormality, allocating an insufficient fixation time, or overlooking an abnormality despite scanning the correct region. Although Large Language Models (LLMs) and Large Multimodal Models (LMMs) have been explored for radiology tasks, they often struggle to detect such fine-grained multimodal variations, particularly when comparing gaze behavior between experts and trainees. To address these limitations, we introduce Structural Chain of Thoughts (SCoT), a novel framework that enhances LLMs and LMMs sensitivity to nuanced multimodal differences by structuring gaze data and radiology report into a thought graph. By leveraging a structural prior, SCoT systematically identifies key perceptual and interpretive discrepancies, allowing models to provide targeted, context-aware feedback. This structured approach not only highlights missed findings but also explains the reasoning behind perceptual errors, turning them into learning opportunities. Applied within radiology education, SCoT bridges the gap between expert and novice performance, offering a scalable solution for AI-driven diagnostic training. We further contribute a simulated dataset of perceptual errors in chest X-ray (CXR) interpretation, facilitating future research into multimodal reasoning and AI-driven medical education. Unlike conventional Chain-of-Thought approaches, SCoT explicitly integrates gaze and textual information into a structured reasoning process, yielding interpretable, fine-grained, and personalized feedback tailored to the unique needs of radiology training. The code and data will be available here: GitHub Repository .},
  archive      = {J_KBS},
  author       = {Akash Awasthi and Brandon Chung and Anh Mai Vu and Saba Khan and Ngan Le and Zhigang Deng and Rishi Agrawal and Carol C. Wu and Hien Van Nguyen},
  doi          = {10.1016/j.knosys.2025.114433},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114433},
  shortjournal = {Knowl. Based Syst.},
  title        = {Structural chain of thoughts for radiology education},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized task offloading with energy efficient communication and optimal offloading network: A mobility and energy-efficient approach for augmented reality in mobile edge computing. <em>KBS</em>, <em>330</em>, 114431. (<a href='https://doi.org/10.1016/j.knosys.2025.114431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing enables the efficient execution of compute-intensive tasks by offloading them to edge servers. However, frequent user mobility in 5 G urban networks leads to increased latency, energy consumption, and resource wastage due to continuous handovers. To address these challenges, Energy Efficient Communication and Optimal Offloading Network, a framework is proposed that combines user mobility prediction and hybrid optimization for task offloading. Energy Efficient Communication and Optimal Offloading Network utilizes a modified Long Short-Term Memory model to predict user movement with high accuracy, achieving an accuracy improvement from 65 % to 95 % over ten iterations. Additionally, a Hybrid Grey Wolf Optimization Algorithm optimizes task allocation, resulting in a 30 % reduction in energy consumption and a 25 % improvement in server utilization compared to baseline methods. The framework achieves latency as low as 5 milliseconds for augmented reality tasks while maintaining scalability in high-traffic 5 G environments. The proposed model also outperforms baseline approaches in terms of task completion time, throughput, and communication efficiency, and it achieves a 94.5 % offloading success rate and 98 % augmented reality delay compliance. The proposed model provides a scalable and useful solution for real-time Augmented Reality by combining energy-constrained task allocation with mobility-aware predictions.},
  archive      = {J_KBS},
  author       = {Anitha Jebamani Soundararaj and Godfrey Winster Sathianesan},
  doi          = {10.1016/j.knosys.2025.114431},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114431},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimized task offloading with energy efficient communication and optimal offloading network: A mobility and energy-efficient approach for augmented reality in mobile edge computing},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified multi-subgraph pre-training framework for spatio-temporal graph. <em>KBS</em>, <em>330</em>, 114428. (<a href='https://doi.org/10.1016/j.knosys.2025.114428'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal graph (STG) learning has shown great potential in capturing complex spatio-temporal dependencies and has achieved significant success in various fields such as traffic flow prediction, climate forecasting, and epidemiological spread research. By learning general features from spatio-temporal graphs, pre-trained graph models can capture hidden semantic information in the data, thereby enhancing the learning effect of downstream tasks and improving overall model performance. However, most existing spatio-temporal graph learning methods use the entire graph for training, which may not fully capture local structure and feature information. In addition, existing methods usually adopt sequence modeling techniques without fully considering the time decay effect, i.e., the need to apply decaying attention to distant time steps. To address these issues, this paper proposes a u nified dual-phase m ulti- s ubgraph pre-training s patio- t emporal graph framework (UMSST). Specifically, in the first phase, the framework learns the global representation of the spatio-temporal graph and locates key graph nodes, while learning the “unit representations” of these key nodes. In the second phase, multiple spatio-temporal subgraphs are constructed based on these “unit representations” to further capture the implicit encoding information of more general features around the corresponding subgraphs, thereby helping the model make full use of general features. Experimental results on real datasets show that the proposed pre-trained spatio-temporal graph framework significantly improves the performance of downstream tasks and demonstrates its effectiveness in comparison with recent strong baseline models.},
  archive      = {J_KBS},
  author       = {Mingze Zhong and Zexuan Long and Xinglei Wang and Tao Cheng and Meng Fang and Ling Chen},
  doi          = {10.1016/j.knosys.2025.114428},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114428},
  shortjournal = {Knowl. Based Syst.},
  title        = {A unified multi-subgraph pre-training framework for spatio-temporal graph},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Provide explainable clues: A generative traceable method for knowledge graph completion. <em>KBS</em>, <em>330</em>, 114426. (<a href='https://doi.org/10.1016/j.knosys.2025.114426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the quality of Knowledge Graph Completion (KGC) results is an essential topic in the field of knowledge graphs. Recently, generative models (GMs) have gained widespread attention for addressing the generalization issues of traditional approaches. However, the black-box nature of generative models often leads to hallucinations, which reduce the model’s performance. Most methods attempt to mitigate this issue through retrieval enhancement and decoding constraints. However, they overlook one major cause of hallucinations–poor explainability. Based on this concept, we propose a G enerative T raceable M ethod, namely GTM, which aims to improve the KGC capability of GMs by exploring the inhibitory effect of explainability on hallucinations. In GTM, a clue tracker is used to find contextual evidence for explainability. In addition, to measure explainability clues, we propose a context-aware analyzer, which enhances the understanding of context through group analogy. In the reasoning phase, we ensure the validity of the generated results by integrating the interpretive capability of clues. Extensive experiments have demonstrated that GTM can adapt to various KGC tasks and significantly enhance the performance of KGC models.},
  archive      = {J_KBS},
  author       = {Ziqi Ma and Jinpeng Li and Hang Yu},
  doi          = {10.1016/j.knosys.2025.114426},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114426},
  shortjournal = {Knowl. Based Syst.},
  title        = {Provide explainable clues: A generative traceable method for knowledge graph completion},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User-defined trade-offs in LLM benchmarking: Balancing accuracy, scale, and sustainability. <em>KBS</em>, <em>330</em>, 114405. (<a href='https://doi.org/10.1016/j.knosys.2025.114405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents xLLMBench, a transparent, decision-centric benchmarking framework that empowers decision-makers to rank large language models (LLMs) based on their preferences across diverse, potentially conflicting performance and non-performance criteria, e.g., domain accuracy, model size, energy consumption, CO 2 emissions. Existing LLM benchmarking methods often rely on individual performance criteria (metrics) or human feedback, so methods systematically combining multiple criteria into a single interpretable ranking lack. Methods considering human preferences typically rely on direct human feedback to determine rankings, which can be resource-intensive and not fully aligned with application-specific requirements. Motivated by current limitations of LLM benchmarking, xLLMBench leverages multi-criteria decision-making methods to provide decision-makers with the flexibility to tailor benchmarking processes to their requirements. It focuses on the final step of the benchmarking process (robust analysis of benchmarking results) which in LLMs’ case often involves their ranking. The framework assumes that the selection of datasets, metrics, and LLMs involved in the experiment is conducted following established best practices. We demonstrate xLLMBench’s usefulness in two scenarios: combining LLM results for one metric across different datasets and combining results for multiple metrics within one dataset. Our results show that while some LLMs maintain stable rankings, others exhibit significant changes when correlated datasets are removed, when the focus shifts to contamination-free datasets or fairness metrics. This highlights that LLMs have distinct strengths/weaknesses, going beyond overall performance. Our sensitivity analysis reveals robust rankings, while the diverse visualizations enhance transparency. xLLMBench can be used with existing platforms to support transparent, reproducible, and contextually-meaningful LLM benchmarking.},
  archive      = {J_KBS},
  author       = {Ana Gjorgjevikj and Ana Nikolikj and Barbara Koroušić Seljak and Tome Eftimov},
  doi          = {10.1016/j.knosys.2025.114405},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114405},
  shortjournal = {Knowl. Based Syst.},
  title        = {User-defined trade-offs in LLM benchmarking: Balancing accuracy, scale, and sustainability},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IRTF: A new tensor factorization for irregular multidimensional data recovery. <em>KBS</em>, <em>330</em>, 114372. (<a href='https://doi.org/10.1016/j.knosys.2025.114372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor factorizations, although serving as paramount tools for exploiting prior knowledge of multidimensional data, are unsuitable for emerging irregular multidimensional data with the arbitrary shape spatial domain (i.e., spatial-irregular tensor), such as superpixels and spatial transcriptomics. Developing new tensor factorizations suitable for spatial-irregular tensors poses a compelling challenge. To meet this challenge, we introduce a novel Irregular Tensor Factorization (IRTF), which can fully capture the intrinsic spatial and channel information behind the spatial-irregular tensor. Concretely, a spatial-irregular tensor can be decomposed into the product of an intrinsic regular tensor, learnable channel transform matrices, and a learnable spatial transform matrix. Accompanying IRTF, we suggest the Total Variation on Channel and Spatial Transforms (TV-CST) to exploit the local information of spatial-irregular tensors, which is hardly excavated by traditional total variation methods. Combining the proposed IRTF and TV-CST, we built a spatial-irregular tensor recovery model. Extensive experiments on real-world spatial-irregular tensors demonstrate the promising performance of our IRTF and its significant advantages on downstream tasks.},
  archive      = {J_KBS},
  author       = {Jin-Yu Xie and Hao Zhang and Xi-Le Zhao and Yi-Si Luo},
  doi          = {10.1016/j.knosys.2025.114372},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114372},
  shortjournal = {Knowl. Based Syst.},
  title        = {IRTF: A new tensor factorization for irregular multidimensional data recovery},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Creative style transfer for image stylization via learning neural permutation. <em>KBS</em>, <em>330</em>, 114368. (<a href='https://doi.org/10.1016/j.knosys.2025.114368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating novel artistic styles from a single style poses a significant challenge for traditional style transfer techniques, which typically focus on emulating the given style without introducing novel, surprising and value elements—fundamental criteria for evaluating creativity. In this paper, we propose Creative Style transFer (CSFer), a new style transfer approach for producing creative artistic styles. We first introduce a neural permutation network (PerNet) to rearrange the feature maps of a single-style image, thus producing new style features. These features are then transferred to the feature maps of a content image, yielding stylized outputs. To evaluate creativity, we employ metrics encompassing style perception distance and artistic aesthetics to assess novelty, surprise, and aesthetic value, respectively. Using this evaluation, we select the most creative style from various stylized results generated via random permutation matrices and an input style. Finally, we effectively train PerNet using both the original and selected creative styles. Extensive experimental results demonstrate that CSFer can generate creative stylized results. Furthermore, CSFer exhibits robust generalization capabilities by seamlessly inserting PerNet into existing style transfer methods.},
  archive      = {J_KBS},
  author       = {Shimin Li and Zedong Zhang and Gan Sun and Li-Wei H. Lehman and Jian Yang and Jun Li},
  doi          = {10.1016/j.knosys.2025.114368},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114368},
  shortjournal = {Knowl. Based Syst.},
  title        = {Creative style transfer for image stylization via learning neural permutation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-driven deep learning network for image splicing forgery detection. <em>KBS</em>, <em>330</em>, 114365. (<a href='https://doi.org/10.1016/j.knosys.2025.114365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image splicing is a widely used technique for manipulating images in various social activities. Detecting splicing forgery is crucial in digital forensics to identify malicious image manipulation and protect information security. However, existing methods for detecting splicing forgery typically learn features in the spatial domain and struggle to effectively capture subtle features indicative of forgery, resulting in insufficient image splicing forgery detection accuracy. To address this challenge, we propose a novel deep-learning network named the frequency-driven deep-learning network (FreNet). Specifically, FreNet comprises three innovative modules: the frequency learnable module (FLM), the spatial-aware frequency learning module (SFLM), and the high-level feature-enhancement module (HFEM). The FLM effectively extracts high- and low-frequency features, thus enhancing frequency-domain representation and capturing subtle tampered features in splicing forgery images. The SFLM utilizes spatial information to guide frequency feature learning, thus enabling spatial-aware frequency feature learning. The HFEM enhances rich contextual and high-level semantic information through multilevel and multipath extraction and fusion. Extensive experiments on five benchmark datasets indicate that FreNet can achieve superior performance. Additionally, robustness experiments demonstrate the superior robustness of FreNet against various common attacks.},
  archive      = {J_KBS},
  author       = {Enji Liang and Kuiyuan Zhang and Zhongyun Hua and Xiaohua Jia},
  doi          = {10.1016/j.knosys.2025.114365},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114365},
  shortjournal = {Knowl. Based Syst.},
  title        = {Frequency-driven deep learning network for image splicing forgery detection},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
