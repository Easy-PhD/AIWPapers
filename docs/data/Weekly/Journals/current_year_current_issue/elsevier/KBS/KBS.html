<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>KBS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="kbs">KBS - 128</h2>
<ul>
<li><details>
<summary>
(2025). Secure and incentivized federated learning for resilient telemedicine diagnostics. <em>KBS</em>, <em>330</em>, 114622. (<a href='https://doi.org/10.1016/j.knosys.2025.114622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Telemedicine-based diabetic retinopathy (DR) screening requires solutions that ensure privacy, scalability, fairness, and auditability across distributed healthcare environments. This paper introduces a novel serverless federated learning (FL) framework that integrates deep learning (DL), secure multi-party computation (SMPC), blockchain (Hyperledger Fabric), the InterPlanetary File System (IPFS), and the Synthetic Minority Over-sampling Technique (SMOTE) to achieve accurate and privacy-preserving DR detection. Unlike traditional FL systems that rely on centralized aggregators, our design leverages blockchain for secure model orchestration, client incentives, and dynamic participation, while SMPC ensures data confidentiality without the utility loss associated with noise-based techniques like differential privacy (DP). Adaptive aggregation addresses client unavailability, and a robust on-chain statistical filter with drift detection mitigates model poisoning and concept drift. Experimental evaluation on the APTOS 2019 dataset (3,662 images, five-class classification) demonstrates state-of-the-art performance, achieving 90–92 % accuracy across 2–10 clients. Our approach significantly outperforms FL-BC-SMPC (92.50 % vs. 70.88 %, +21.62 %) and FL-BC-SMPC-DP (92.80 % vs. 52.18 %, +40.62 %, p < 0.001 ), with SMOTE improving minority class recall by 12 % and blockchain-driven incentives raising F1-score to 68.90 %. Additionally, blockchain supports 18.9 transactions per second with a maximum latency of 2.5 seconds, while IPFS reduces per-round storage from 64 GB to 100 KB (6.573 s/write), enabling efficient scalability. Compared to centralized benchmarks (e.g., FedCNN: 98 %, RSG-Net: 99.36 %), our framework offers a trade-off of 5–7 % in accuracy for substantial gains in privacy, decentralization, and regulatory compliance (GDPR/HIPAA). This work sets a new direction for secure, scalable, and equitable AI-driven diagnostics in global healthcare.},
  archive      = {J_KBS},
  author       = {Omar Dib},
  doi          = {10.1016/j.knosys.2025.114622},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114622},
  shortjournal = {Knowl. Based Syst.},
  title        = {Secure and incentivized federated learning for resilient telemedicine diagnostics},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining independent and joint spatial-angular information learning for light field image super-resolution. <em>KBS</em>, <em>330</em>, 114619. (<a href='https://doi.org/10.1016/j.knosys.2025.114619'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Light Field (LF) imaging can simultaneously record spatial and angular information of light rays, playing a significant role in applications such as digital refocusing and 3D reconstruction. Unfortunately, limited by the sensor size, LF images suffer from low spatial resolution while maintaining high angular sampling. Fully exploiting the inherent spatial-angular information of LF images is the key to achieving high-fidelity LF spatial super-resolution. However, current methods are not comprehensive enough in learning the spatial-angular information of LF images, which hinders the improvement of super-resolution performance. To this end, this study effectively combines independent and joint spatial-angular information learning through systematic domain partitioning, domain-specific modeling strategies, and novel modules designed for the characteristics of LF data. Specifically, a spatial dependency modeler and an angular dependency modeler are first designed to achieve spatial-angular independent learning, thus facilitating refined spatial and angular features extraction. Secondly, a sub-LF transformer and an epipolar plane image transformer are constructed to jointly learn spatial-angular correlations to achieve a more complete feature space exploration. Finally, a conditional feature generator and a condition-guided fusion module are introduced to adaptively fuse intermediate LF features according to the input content. The above three components constitute the basic spatial-angular information learning module. By stacking multiple basic modules, the proposed method can effectively exploit the intrinsic high-dimensional information of LF images, thereby reconstructing high-quality super-resolved LF images. Extensive experimental results on five benchmark datasets show that the proposed method outperforms the state-of-the-art methods in both objective quality and subjective visual aspects. Our code will be released in https://github.com/blackdajie/LF-CIJSANet .},
  archive      = {J_KBS},
  author       = {Dezhang Ke and Yeyao Chen and Chongchong Jin and Haiyong Xu and Zhidi Jiang and Ting Luo and Gangyi Jiang},
  doi          = {10.1016/j.knosys.2025.114619},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114619},
  shortjournal = {Knowl. Based Syst.},
  title        = {Combining independent and joint spatial-angular information learning for light field image super-resolution},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). JTA: Joint networks with tailored attention for speech depression detection. <em>KBS</em>, <em>330</em>, 114617. (<a href='https://doi.org/10.1016/j.knosys.2025.114617'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression, a prevalent mental disorder affecting approximately 5 % of adults globally, presents two critical yet under-addressed challenges in speech-based detection. The primary depressive speech features exhibit sporadic distribution and are inherently challenging to detect because patients often exhibit intermittent reticence, significantly impeding models’ ability to reliably extract clinically relevant features. The second critical challenge lies in depression severity assessment, i.e., the distinction between different levels of depression is unclear, and the detection of depression alone does not meet realistic medical needs. To address these challenges, we propose Joint Networks with Tailored Attention (JTA), i.e., a Spectrogram-Based model with Tailored Attention (STA), a pre-trained model (WavLM), and a Transactive Attention-based feature Fusion module (TAF). Specifically, we employ log-Mel spectrograms as STA inputs, introducing a Tailored Attention module ( T A 1 ) to suppress non-informative components while focusing on depression features. TAF hierarchically integrates representations from WavLM and STA through its Transactive Attention ( T A 2 ). Experiments on five challenge datasets (i.e., BioCAS2024, D 4 , DAIC-WOZ, E-DAIC, and D-vlog) illustrate the superior performance of JTA compared to SOTA methods in depression detection and depression level detection tasks. We perform interpretability analysis on JTA to visualize high-impact biomarkers, enabling clinicians to understand and validate model decisions more precisely.},
  archive      = {J_KBS},
  author       = {Xin-Heng Li and Zhen-Tao Liu and Chen-Ling Liu and Bao-Liang Zhong and Jing Chen and Jinhua She and Kaoru Hirota},
  doi          = {10.1016/j.knosys.2025.114617},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114617},
  shortjournal = {Knowl. Based Syst.},
  title        = {JTA: Joint networks with tailored attention for speech depression detection},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sample-efficient backtrack temporal difference deep reinforcement learning. <em>KBS</em>, <em>330</em>, 114613. (<a href='https://doi.org/10.1016/j.knosys.2025.114613'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning algorithms often require large amounts of training data, particularly in robotic control tasks. To address this limitation, we propose a sample-efficient backtrack temporal difference learning method that enhances target state-action ( Q ) value estimation. The proposed method dynamically prioritizes transitions based on their proximity to terminal states using backtrack sampling weights. This prioritization mechanism yields more accurate target Q -values, thereby improving the overall Q -value estimation precision. Furthermore, our analysis uncovers a novel link between curriculum learning and Bellman equation optimization. The proposed method is versatile, applicable to both discrete and continuous action spaces, and readily integrable with off-policy actor-critic algorithms. Extensive experiments show that the proposed method considerably reduces Q -value approximation errors and outperforms baselines across diverse benchmarks, achieving a 28 % performance improvement in four discrete action-space tasks and a 78 % gain in four continuous control tasks.},
  archive      = {J_KBS},
  author       = {Qi Liu and Pengbin Chen and Ke Lin and Kaidong Zhao and Jinliang Ding and Yanjie Li},
  doi          = {10.1016/j.knosys.2025.114613},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114613},
  shortjournal = {Knowl. Based Syst.},
  title        = {Sample-efficient backtrack temporal difference deep reinforcement learning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bearing fault diagnosis based on multimodal knowledge graphs under few-shot samples. <em>KBS</em>, <em>330</em>, 114604. (<a href='https://doi.org/10.1016/j.knosys.2025.114604'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional bearing fault diagnosis methods face challenges in capturing complex relationships and semantic connections between fault modes due to limited fault samples. To address this, we propose a novel Multimodal Knowledge Graph Extrapolation Network (MKGEN). Key components include: The feature fusion module effectively combines multi-modal information from different sensors with the structural information of the knowledge graph, providing more comprehensive feature representation under few-shot conditions and overcoming the limitations of single-modality processing. The node information aggregation module enhances the model’s understanding of fault mode semantics by learning complex node associations. The relation learning module uncovers latent correlations between fault modes in few-shot scenarios, thereby improving diagnostic accuracy. Additionally, the uncertainty optimization module enhances the model’s robustness under complex working conditions, while the manifold function decoder improves performance in high-dimensional spaces through precise feature decoding. Overall, the proposed model excels in few-shot learning, demonstrating strong generalization across devices and conditions. It adapts quickly to new tasks, predicts unseen entities, and effectively handles complex, high-dimensional features. Experimental results confirm its superior performance in few-shot and transfer tasks.},
  archive      = {J_KBS},
  author       = {Cheng Peng and Yanyan Sheng and Weihua Gui and Zhaohui Tang and Longxin Zhang and Xinpan Yuan},
  doi          = {10.1016/j.knosys.2025.114604},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114604},
  shortjournal = {Knowl. Based Syst.},
  title        = {Bearing fault diagnosis based on multimodal knowledge graphs under few-shot samples},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving ground-truth data for evaluating additive feature attribution in regression models with additive CBR and CQV. <em>KBS</em>, <em>330</em>, 114599. (<a href='https://doi.org/10.1016/j.knosys.2025.114599'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainable artificial intelligence (XAI) methods produce information outputs based on a target artificial intelligence model to be explained. The most popular information output is produced by XAI methods of the category feature attribution, which produce the relative contribution of each input feature in a local instance. These relative contributions indicate how important each input feature is in a decision; this type of information is expected to provide explanatory value to users. In real-world regression tasks, feature attribution methods are crucial for comprehending model predictions. However, robust evaluation of such methods remains challenging due to a lack of ground-truth data and widely accepted evaluation metrics, such as accuracy for classification or mean absolute error for regression. This paper proposes a novel approach for generating synthetic, privacy-preserving ground-truth datasets for regression problems that retain original feature behaviour, enabling rigorous feature attribution evaluation without compromising sensitive information. We introduce additive case-based reasoning (AddCBR) as a model-aligned and interpretable baseline to benchmark additive feature attribution methods. This work also demonstrates the first use of the coefficient of quartile variation (CQV) as a statistical measure to quantify the consistency and stability of feature attribution methods. Altogether, these contributions form a comprehensive evaluation methodology for objectively assessing and comparing feature attribution methods in regression models. By providing a controlled evaluation pipeline with reliable baselines and metrics, this work addresses the current lack of consensus and benchmarking in XAI evaluation for regression models.},
  archive      = {J_KBS},
  author       = {Mir Riyanul Islam and Rosina O. Weber and Mobyen Uddin Ahmed and Shahina Begum},
  doi          = {10.1016/j.knosys.2025.114599},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114599},
  shortjournal = {Knowl. Based Syst.},
  title        = {Privacy-preserving ground-truth data for evaluating additive feature attribution in regression models with additive CBR and CQV},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view enhanced truck re-identification. <em>KBS</em>, <em>330</em>, 114598. (<a href='https://doi.org/10.1016/j.knosys.2025.114598'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Truck Re-identification (ReID) is pivotal for efficient intelligent transportation systems, yet it faces significant challenges beyond those of general vehicle or person ReID due to the extreme diversity and complex structures of trucks, which render existing methods inadequate. Multi-view Truck ReID (MVT-ReID) is a promising solution, but its advancement is currently hampered by two primary limitations: the lack of a dedicated, high-quality benchmark dataset and the absence of methods designed to handle the inherent redundancy and feature entanglement in multi-view data. To bridge this gap, this paper makes two main contributions. First, we release MV-TI, the first large-scale, real-world MVT-ReID dataset with 70,479 images and four challenging retrieval tasks. Second, we propose DAG-UMB, a novel unsupervised framework featuring a Delayed Attention Integration (DAI) strategy and a Multi-Memory Bank (MMB). The DAI strategy defers attention activation until after the initial unstable training phase, learning a stable feature foundation to avoid misleading noise. The MMB then disentangles the learning of global-invariant and view-specific features, a key limitation of prior approaches. Extensive experiments on our proposed MV-TI benchmark demonstrate that DAG-UMB achieves state-of-the-art performance, significantly outperforming existing methods, setting a new foundation for future research and application in multi-view truck ReID.The MV-TI dataset and DAG-UMB code have been made publicly available at https://github.com/maybeextra/DAG-UMB .},
  archive      = {J_KBS},
  author       = {Xue-Yan Wang and Run-Sen Xia and Qiang Lv and Si-Bao Chen and Jin Tang},
  doi          = {10.1016/j.knosys.2025.114598},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114598},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-view enhanced truck re-identification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperspectral video object tracking with cross-modal spectral complementary and memory prompt network. <em>KBS</em>, <em>330</em>, 114595. (<a href='https://doi.org/10.1016/j.knosys.2025.114595'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral videos contain rich spectral, spatial, and temporal information, enabling trackers to operate efficiently even in challenging scenarios. However, existing hyperspectral trackers often suffer from scarcity of training data, insufficient utilization of spectral information, and suboptimal temporal condition mining. To address these issues, we propose a novel hyperspectral tracker with cross-modal spectral complementary and memory prompt network, termed HCSMP. To achieve spectral complementarity in feature fusion, we design a cross-modal prompt network (CPN) that employs the spectral complementary adapter (SCA) to generate adaptive weights based on modality differences for cross-modal spectral prompt learning. The advantage of CPN is its ability to significantly improve the efficiency of spectral information utilization. In addition, we introduce a memory prompt network (MPN) to incorporate temporal conditions. MPN generates memory prompts containing historical features through the encoder and enhances spatial-spectral representations using channel-spatial progressive attention (CSPA), followed by a decoder that queries and retrieves the target features. The advantage of MPN is that model can achieve robust target state modeling from historical frame information. Extensive experiments demonstrate that HCSMP delivers highly satisfactory tracking performance compared with state-of-the-art (SOTA) methods, particularly under scale variation and occlusion challenges.},
  archive      = {J_KBS},
  author       = {Wenhao Jiang and Dong Zhao and Chen Wang and Xin Yu and Pattathal V. Arun and Yuta Asano and Pei Xiang and Huixin Zhou},
  doi          = {10.1016/j.knosys.2025.114595},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114595},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hyperspectral video object tracking with cross-modal spectral complementary and memory prompt network},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RUST: Residual U-shaped transformer to approximate taylor expansion for image denoising. <em>KBS</em>, <em>330</em>, 114593. (<a href='https://doi.org/10.1016/j.knosys.2025.114593'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision Transformer (ViT) has proven its powerful ability in feature representation, to utilize such gift and provide a feasible theoretical interpretation of constructing an image denoising network, this paper presents a residual U-shaped transformer (RUST) to approximate the Taylor expansion for noise removal. To be specific, we first provide a detailed analysis of the relationship between the Taylor expansion approximation theory and the image denoising model and the adjacent derivative layers. Second, we develop a deformable convolution spatial attention network, termed as LSANet, to estimate the base layer and a U-shaped transformer to transfer as many rich multi-scale details from the noisy images to the estimated results as possible to calculate the derivative. Finally, their outputs contribute to the approximation solution of the Taylor expansion. In the experiments, the selection of network parameters is first tested and discussed to verify their effectiveness. Thereafter, quantitative and qualitative experimental results on seven synthetic datasets are compared, demonstrating that our proposed RUST can produce more competitive denoising performance with richer details than the state-of-the-art (SOTA) denoising approaches. Subsequently, these SOTA methods are applied to real-life noisy images, by which the generated results validate that the developed RUST model has a more powerful generalization capability. Additionally, experimental results on the rainy DID-MDN dataset further verify that our RUST also performs well on rain removal and is suitable for extensive applications.},
  archive      = {J_KBS},
  author       = {Zhenghua Huang and Yang Yang and Jin Liu and Chuan Liu and Yu Shi and Yaozong Zhang and Qian Li},
  doi          = {10.1016/j.knosys.2025.114593},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114593},
  shortjournal = {Knowl. Based Syst.},
  title        = {RUST: Residual U-shaped transformer to approximate taylor expansion for image denoising},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fight fire with fire: A heterogeneous graph neural network fairness framework based on heterogeneous neutralization information pre-propagation. <em>KBS</em>, <em>330</em>, 114591. (<a href='https://doi.org/10.1016/j.knosys.2025.114591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although heterogeneous information networks (HINs) enable fine-grained modeling, their heterogeneous graph neural network (HGNN) implementations may yield biased predictions in human-centric applications. In this work, we revisit the problem of bias in HINs and fairness-enhancing methods for HGNNs, and propose the concept of self-limiting heterogeneous bias information. Accordingly, we introduce FairBubble, a general framework to promote fairness in HGNNs. FairBubble automatically identifies neutralizing information from the heterogeneous neighbors of target-type nodes and utilizes a hypergraph convolution-based pre-propagation mechanism to mitigate bias. The framework constructs fairness-promoting hyperrelations, enabling the dilution of biased information prior to standard message propagation in the target HGNN. Importantly, FairBubble is plug-and-play, requires no manual metapath engineering, and is broadly applicable across different HGNN architectures and application scenarios, thus demonstrating strong generalizability. Spectral analysis confirms that hypergraph convolution-based pre-propagation effectively neutralizes bias in HINs. Experiments on three public HIN benchmarks show that FairBubble achieves superior performance in both fairness and utility metrics compared to state-of-the-art HGNN fairness approaches.},
  archive      = {J_KBS},
  author       = {Siyu Li and Jin Yang and Yong Hu and Tianrui Li},
  doi          = {10.1016/j.knosys.2025.114591},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114591},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fight fire with fire: A heterogeneous graph neural network fairness framework based on heterogeneous neutralization information pre-propagation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-robot consistent formation control based on novel leader-follower model and optimization motion planning approach. <em>KBS</em>, <em>330</em>, 114590. (<a href='https://doi.org/10.1016/j.knosys.2025.114590'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning and formation control are of great significance for improving the efficiency of robot collaboration. In practical applications, traditional algorithms are complex due to the complexity and immediacy of real scenes. Optimization algorithms with their problem independence and easy scalability, can effectively solve the difficulties encountered in multi-robot path planning and formation control. However, current optimization algorithms generally have problems such as being easily trapped in local optimality and incomplete algorithm exploration. To better solve the problems of significant path trajectory error and poor formation adaptability in the collaborative formation of multi-robot systems. Based on Crayfish Optimization Algorithm (COA), this paper introduces three strategies that effectively improve the optimization effect of the COA, and proposes a hybrid algorithm suitable for collaborative formation of multi-robot systems (SCCOA). We design a novel hierarchical leader-follower formation framework and prove the stability of the formation control model. The proposed SCCOA was combined with the framework to use to adjust and parallel control the trajectory, speed, and other related factors of the leader and follower to realize the formation control system to achieve the goal of multi-robot collaborative formation. To verify the effectiveness of the SCCOA in path planning and formation control systems, SCCOA was compared with 11 excellent algorithms in experiments, and various evaluation indicators were established by analyzing various coefficients in multi-robot path planning and formation control. Results showed that SCCOA ranked first in all metrics, demonstrating the excellent performance of the SCCOA in solving multi-robot path planning and formation control problems.},
  archive      = {J_KBS},
  author       = {Liguo Yao and Xiaoyang Yuan and Guanghui Li and Yao Lu and Taihua Zhang},
  doi          = {10.1016/j.knosys.2025.114590},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114590},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-robot consistent formation control based on novel leader-follower model and optimization motion planning approach},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gradient-based federated bayesian optimization. <em>KBS</em>, <em>330</em>, 114588. (<a href='https://doi.org/10.1016/j.knosys.2025.114588'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian optimization (BO) has evolved from traditional single-agent optimization to multi-agent collaborative optimization, known as federated BO, aiming to solve global optimization tasks such as federated hyperparameter tuning. Existing research on federated BO shares weight vectors sampled from Gaussian processes, approximated using random Fourier features, with a server for information aggregation. This line of approach helps protect the privacy of agents but may limit the performance of the algorithm. Unlike existing federated BO approaches, we propose to cluster each agent according to its characteristics, and transmit the gradients of acquisition functions between the server and agents for information aggregation. This allows for a more accurate representation of the overall landscape of the global acquisition function without explicitly constructing it. Moreover, we design a two-stage mechanism to infill the next query input based on the aggregated gradients. Specifically, multiple promising solutions are first suggested based on the aggregated gradients. Then, each agent further selects the one with the best local acquisition function value as the newly infilled solution for real function evaluation. The resulting gradient-based federated BO, termed FGBO, has demonstrated to be very competitive in tackling a set of benchmark functions and real-world problems in a privacy-preserving way.},
  archive      = {J_KBS},
  author       = {Lin Yang and Junhua Gu and Qiqi Liu and Zhigang Zhao and Yunhe Wang and Yaochu Jin},
  doi          = {10.1016/j.knosys.2025.114588},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114588},
  shortjournal = {Knowl. Based Syst.},
  title        = {Gradient-based federated bayesian optimization},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nonlocal superpatch-based reweighted low-rank representation method for hyperspectral unmixing. <em>KBS</em>, <em>330</em>, 114586. (<a href='https://doi.org/10.1016/j.knosys.2025.114586'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {More attention has been paid to spatial information in the process of exploring better hyperspectral unmixing (HU) methods for hyperspectral image (HSI). However, most spatial-regularization-based HU methods only consider the spatial context relationship of adjacent regions in an HSI, ignoring the use of information between non-adjacent ones. To this end, we propose a novel HU method named nonlocal superpatch-based reweighted low-rank and total variation sparse unmixing (NLSPRLR-TV), which uses both local and nonlocal spatial information of HSI. Unlike some previous nonlocal methods using the patch, the nonlocal homogeneous regions obtained by our method can be well consistent with the visual edge. Concretely, a superpixel-based patch called SuperPatch is firstly constructed to exploit local spatial redundancy. Then, several similar superpatches are searched in the whole HSI to form a nonlocal superpatch matrix by the SuperPatchMatch method, so that the nonlocal spatial redundancy is exploited. Finally, the proposed method imposes the collaborative sparse and TV regularizations on the whole abundance matrix, and a reweighted low-rank regularization for each superpatch matrix, to obtain the estimated abundance images. Extensive experimental results on simulated and real datasets demonstrate that the proposed NLSPRLR-TV method outperforms several state-of-the-art HU methods.},
  archive      = {J_KBS},
  author       = {Yizhe Zhao and Maoguo Gong and Xiangming Jiang and Tao Zhan and Fenlong Jiang},
  doi          = {10.1016/j.knosys.2025.114586},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114586},
  shortjournal = {Knowl. Based Syst.},
  title        = {A nonlocal superpatch-based reweighted low-rank representation method for hyperspectral unmixing},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decorrelated adaptive simple graph representation learning for next POI recommendation. <em>KBS</em>, <em>330</em>, 114585. (<a href='https://doi.org/10.1016/j.knosys.2025.114585'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next Point-of-Interest (POI) recommendation plays a pivotal role in social network services. Its objective is to predict the POI a user is most likely to visit next based on their historical visit patterns. Existing methods often rely on predefined graphs to establish relationships between POIs, with only a few studies delving into adaptive graph approaches. Adaptive graph representation learning can reveal more insightful graph structures, enabling graph neural networks to learn more significant adjacency relationships during propagation. However, existing research on adaptive graphs remains at a relatively preliminary stage. In this paper, we propose a Decorrelated Adaptive Simple Graph Representation-enhanced Attention Network (DASGRAN) for next POI recommendation task. DASGRAN adopts a more straightforward approach to graph structure learning, which not only reduces the dependency on domain knowledge but also alleviates issues of over-smoothing and over-correlation. Furthermore, we explore the interplay between self-attention mechanisms and adaptive graph learning, incorporating new extensions and regularization techniques. These enhancements allow the extended self-attention method to capture user preferences more effectively. Results from four real-world datasets demonstrate that our method overall surpasses existing state-of-the-art baselines in performance.},
  archive      = {J_KBS},
  author       = {Yanhong Li and Shijie Wang and Xuan Li and Zixi Li and Longyu Wu and Wei Tian and Guoliang Li},
  doi          = {10.1016/j.knosys.2025.114585},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114585},
  shortjournal = {Knowl. Based Syst.},
  title        = {Decorrelated adaptive simple graph representation learning for next POI recommendation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Classifier ensemble based source-free domain adaptation for time series classification. <em>KBS</em>, <em>330</em>, 114584. (<a href='https://doi.org/10.1016/j.knosys.2025.114584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-free domain adaptation (SFDA) enables adaptation to an unlabeled target domain without requiring access to source data. Existing SFDA methods can be broadly categorized into fixed classifier-based and learnable classifier-based approaches. Fixed classifier-based methods transfer a pre-trained model from the source to the target domain while keeping classifier parameters fixed. In contrast, learnable classifier-based methods dynamically adjust classifier parameters during adaptation. Fixed classifier-based methods perform well when the distribution discrepancy between domains is small but struggle with larger domain shifts. Meanwhile, learnable classifier-based methods effectively address distribution discrepancies by optimizing classifier parameters. For time series classification tasks, domain discrepancies are often larger and more intricate, leading to severe performance degradation in existing domain adaptation methods. To address this issue, we propose a novel classifier ensemble-based source-free domain adaptation (CE-SFDA) framework to mitigate domain shift in time series classification. The proposed framework adapts the classification model to the target domain while preserving source domain knowledge. Specifically, we design an classifier ensemble-based pseudo-label generation method to improve pseudo-label reliability. Additionally, we introduce a memory-aware knowledge distillation method to capture both global and local structures within the target domain. Furthermore, an information entropy-based self-supervised learning strategy is employed to align source and target domain distributions. We conduct extensive experiments on four real-world time-series domain adaptation datasets. Experimental results demonstrate that the proposed CE-SFDA framework is simple and effective, achieving superior performance over state-of-the-art methods. The code is publicly available at https://github.com/WangdongZhao99/CE-SFDA .},
  archive      = {J_KBS},
  author       = {Ercheng Pei and Wangdong Zhao and Zhanxuan Hu and Lang He and Hailong Ning and Haifeng Chen},
  doi          = {10.1016/j.knosys.2025.114584},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114584},
  shortjournal = {Knowl. Based Syst.},
  title        = {Classifier ensemble based source-free domain adaptation for time series classification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incomplete graph learning via data and representation-level interaction. <em>KBS</em>, <em>330</em>, 114583. (<a href='https://doi.org/10.1016/j.knosys.2025.114583'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph data is a fundamental resource for many modern applications. However, graph models may struggle when faced with incomplete data, such as incomplete structure or attributes. Despite partly solving the incomplete problem by modeling attributes and structure with a decoupled framework, existing methods ignore their interaction that may exploit the complementarity between attributes and structure, resulting in limited performance. In this work, we propose an interactive framework for incomplete graph learning on both the data and representation levels. Concretely, we design a data-level interactive completion approach that combines a decoupled preliminary completion with a fundamental interaction function realized by graph convolutional networks, effectively leveraging the complementarity between the completions of node attributes and graph structure to enhance incomplete graph completion. Then, we propose a representation-level interactive learning module with multi-view contrastive learning to handle representation-level interactions, generating better graph node representations and improving the performance of downstream tasks. Extensive experiments on eight benchmark datasets demonstrate the effectiveness of our methods in handling incomplete graphs, consistently outperforming existing state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Dezhi Liu and Richong Zhang and Junfan Chen and Fanshuang Kong and Jaein Kim},
  doi          = {10.1016/j.knosys.2025.114583},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114583},
  shortjournal = {Knowl. Based Syst.},
  title        = {Incomplete graph learning via data and representation-level interaction},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). H-RIL: A hopf-based robot imitation learning framework for modular antenna structure assembly. <em>KBS</em>, <em>330</em>, 114576. (<a href='https://doi.org/10.1016/j.knosys.2025.114576'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address common challenges in on-orbit assembly of modular antenna structures—such as complex trajectory planning, poor skill generalization, and low system intelligence—this paper proposes a Hopf-based robot imitation learning (H-RIL) framework, which consists of three stages: demonstration, skill learning, and skill generalization. In the demonstration stage, modular assembly trajectories are recorded via kinesthetic teaching. In the learning stage, an adaptive oscillatory primitive (AOP) is introduced. A “segmentation–learning–stitching” strategy is adopted, whereby the continuous trajectory is divided into multiple subsegments, each modeled by an individual AOP. A tunable exponential window function is used to ensure smooth stitching between sub-trajectories. In the generalization stage, a “local adjustment with neighborhood coordination” strategy is proposed, enabling adaptation of trajectory endpoints and shapes by adjusting the parameters of corresponding AOPs. To validate the proposed method, a robotic assembly platform was developed for modular unit transportation and insertion tasks. Ablation studies confirmed the effectiveness of each component within the H-RIL framework. Comparative experiments with two recent imitation learning methods in the insertion task showed average error reductions of 83.79% and 91.69%, respectively. The trained robot successfully executed assembly operations at multiple target positions, demonstrating the potential of the proposed framework for future applications in on-orbit assembly of modular structures.},
  archive      = {J_KBS},
  author       = {Yulin Zhang and Tuanjie Li and Yuming Ning and Ziang Li and Lixiang Ban and Yan Zhang and Xiangyuan Li},
  doi          = {10.1016/j.knosys.2025.114576},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114576},
  shortjournal = {Knowl. Based Syst.},
  title        = {H-RIL: A hopf-based robot imitation learning framework for modular antenna structure assembly},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AIARec: Adaptive intent-aware augmentation for graph contrastive learning recommendation method. <em>KBS</em>, <em>330</em>, 114575. (<a href='https://doi.org/10.1016/j.knosys.2025.114575'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Contrastive Learning (GCL) has recently emerged as a powerful paradigm for recommendation systems.However,its practical adoption is hindered by two critical challenges: (a) The representational capacity and interpretability of recommendation models; (b) The inherent flaws of data augmentation strategies in intent decoupling learning, which often introduce misleading self-supervised signals due to noise. To address these issues, we propose a novel framework that integrates adaptive augmentation with intent-aware modeling to improve the challenge (a), called AIARec. Our approach addresses the sparsity of implicit feedback in bipartite graphs by introducing a Gaussian distribution-based graph generation strategy for robust node feature encoding. Furthermore, we design an adaptive feature-level noise perturbation mechanism, governed by an embedding table, which judiciously guides the reconstruction of the bipartite graph using latent intent information. This mechanism not only mitigates excessive noise perturbation but also accentuates the intrinsic intention features of users and items, thereby strengthening the challenge (b). To further refine the learned representations, we develop a two-domain aware graph contrastive learning framework that optimizes the consistency and uniformity of node embeddings across multiple domains. Extensive experiments on real datasets (e.g., Yelp, Amazon-Book) show that AIARec outperforms 16 state-of-the-art baselines (e.g., BIGCF, LightGCN) on Recall and NDCG in four metrics (recall, NDCG, etc.). By explicitly modeling user-item interactions through interpretable intent factors, AIARec advances both the performance and explainability of GCL-based recommender systems, offering a principled solution to noisy augmentation and sparse interaction challenges.},
  archive      = {J_KBS},
  author       = {Xiaoyang Liu and Guiling Wen and Asgarali Bouyer and Giacomo Fiumara and Pasquale De Meo},
  doi          = {10.1016/j.knosys.2025.114575},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114575},
  shortjournal = {Knowl. Based Syst.},
  title        = {AIARec: Adaptive intent-aware augmentation for graph contrastive learning recommendation method},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised reservoir computing for multivariate denoising of severely contaminated signals. <em>KBS</em>, <em>330</em>, 114574. (<a href='https://doi.org/10.1016/j.knosys.2025.114574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interdependence and high dimensionality of multivariate signals present significant challenges for denoising, as conventional univariate methods often struggle to capture the complex interactions between variables. A successful approach must consider not only the multivariate dependencies of the desired signal but also the multivariate dependencies of the interfering noise. In our previous research, we introduced a method using machine learning to extract the maximum portion of “predictable information” from univariate signal. We extend this approach to multivariate signals with a key innovation: an interference calibration matrix that incorporates directional noise intensities back into signal reconstruction. The method applies PCA to the noise covariance matrix to identify noise variance in each principal direction, then assigns directional weights based on signal-to-noise ratios to improve reconstruction accuracy. The method works successfully for various multivariate signals, including chaotic signals and highly oscillating sinusoidal signals which are corrupted by spatially correlated intensive Gaussian/non-Gaussian noise. It consistently outperforms other existing multivariate denoising methods by 3-6 dB across a wide range of scenarios including real-world data.},
  archive      = {J_KBS},
  author       = {Jaesung Choi and Pilwon Kim},
  doi          = {10.1016/j.knosys.2025.114574},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114574},
  shortjournal = {Knowl. Based Syst.},
  title        = {Unsupervised reservoir computing for multivariate denoising of severely contaminated signals},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Objectness scan for efficient vision mamba. <em>KBS</em>, <em>330</em>, 114573. (<a href='https://doi.org/10.1016/j.knosys.2025.114573'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mamba has made its debut in several visual tasks, but a more effective scanning strategy is still needed to unfold visual data into logical one-dimensional token sequences, ensuring spatial continuity and semantic structures. In this paper, an objectness scanning strategy with a dual-attention mechanism is proposed for efficient vision Mamba. Visual data is unfolded according to its objectness. The produced one-dimensional token sequences maintain visual spatial continuity while exhibiting a clear semantic structure, akin to the syntactic structures of natural language, owing to three built-in linguistic characteristics—the dependency distance minimization, the primacy effect, and high accessibility. A multi-scale foreground proposer is also proposed as an essential component to evaluate the objectness of tokens. It mitigates interference from non-object information and prevents the attenuation of semantic information by a parallel enhancement modulation mechanism. By incorporating the objectness scanning strategy, the proposed vision Mamba model, ObjM, demonstrates significant superiority in accurately and efficiently identifying foreground objects. On both camouflaged object detection and salient object detection, it delivers improved performance while achieving an average reduction of 31.04 % in computational cost and 56.90 % in parameter count by merely replacing the backbones of several state-of-the-art camouflaged object detection models. On the MSCOCO multi-object detection and instance segmentation task, it also consumes fewer computational resources. Codes are available at https://github.com/kaiopen/objm .},
  archive      = {J_KBS},
  author       = {Kai Zhang and Xia Yuan and Chunxia Zhao},
  doi          = {10.1016/j.knosys.2025.114573},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114573},
  shortjournal = {Knowl. Based Syst.},
  title        = {Objectness scan for efficient vision mamba},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mamba with multi-frequency perception for image super-resolution. <em>KBS</em>, <em>330</em>, 114570. (<a href='https://doi.org/10.1016/j.knosys.2025.114570'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image super-resolution (SR) focuses on reconstructing a high-resolution (HR) image from a low-resolution (LR) input, aiming to restore fine details and improve perceptual quality. Recently, Mamba has shown promise for SR, owing to its efficient sequential modeling capability. However, existing Mamba-based approaches often neglect the joint impact of remote-distance information decay and insufficient local information dependencies. To address this issue, we propose MFPMamba, a novel image SR method designed to enhance both the global and local feature representation capabilities of Mamba. Specifically, a multi-frequency decoupling perception module (MFDP) is introduced to augment Mamba with frequency-domain information. In this module, features are decomposed into low- and high-frequency components via the wavelet transform, and specialized decoupled convolutions are employed to effectively process each component. In addition, a multi-domain adaptive fusion module (MDAF) is developed to facilitate the integration of spatial-domain features encoded by Mamba and frequency-domain features encoded by MFDP. The channel weights are adaptively determined through the uniform quantification of features across different domains. Extensive experiments show that state-of-the-art performance is achieved. In the ×4 task, our method improves the PSNR by 0.16 and 0.25 dB on the Urban100 and Manga109 datasets, respectively, over the baseline, and reduces the memory consumption by 12 %. These results demonstrate the effectiveness of multi-frequency perception in assisting Mamba to achieve image SR.},
  archive      = {J_KBS},
  author       = {Huimin Yang and Jingzhong Xiao and Ji Zhang and Xuchuan Zhou and Yuxing Liu},
  doi          = {10.1016/j.knosys.2025.114570},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114570},
  shortjournal = {Knowl. Based Syst.},
  title        = {Mamba with multi-frequency perception for image super-resolution},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coarse-to-fine multimodal prototype network for few-shot multimodal relation extraction. <em>KBS</em>, <em>330</em>, 114569. (<a href='https://doi.org/10.1016/j.knosys.2025.114569'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal relation extraction (MRE) aims to identify textual entity relations in free text with incorporated images. The majority of methods for MRE rely heavily on a large number of manually annotated samples, and their performance drops sharply when the available labeled data is insufficient. However, annotating data in many expert domains is knowledge-intensive and time-consuming, necessitating significant labeling efforts. Inspired by the success of meta-learning in various methods, several studies have applied few-shot learning to the MRE task for reducing labeling efforts. Nevertheless, existing few-shot multimodal relation extraction methods typically rely on shallow features from text and image modalities, neglecting the latent relation-label-aware cues in multimodal data. Besides, they struggle to capture fine-grained multimodal interactions aligned with entity semantics. These limitations hinder the models from effectively focusing on the most informative parts in text-image pairs, while simultaneously restricting their capability to reason in complex multimodal scenarios. To overcome these shortcomings, we propose a C oarse-to-fine M ultimodal P rototype Net work (CMPNet) that learns hierarchical multimodal features to solve the few-shot multimodal relation extraction task. More specifically, our model captures multimodal features through a cross-attention module in a gated way, while obtaining semantic-aware representations with two guided modules. One module guided by relation-label semantics is designed to align prototype with the semantic characteristics of relations. Another one captures multimodal features associated with entities, guiding the model to concentrate on text and visual information closely tied to the entities. Extensive experiments on two benchmark datasets demonstrate that CMPNet outperforms the previous baseline models under different few-shot settings, confirming the effectiveness of our model.},
  archive      = {J_KBS},
  author       = {Haoze Zhu and Baohang Zhou and Ziyu Lu and Xuhui Sui and Yu Zhao and Ying Zhang and Xiaojie Yuan},
  doi          = {10.1016/j.knosys.2025.114569},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114569},
  shortjournal = {Knowl. Based Syst.},
  title        = {Coarse-to-fine multimodal prototype network for few-shot multimodal relation extraction},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning spatial-channel feature refiners via wavelet-based linear mixed basis for low-light image enhancement. <em>KBS</em>, <em>330</em>, 114567. (<a href='https://doi.org/10.1016/j.knosys.2025.114567'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When images are captured in low-light conditions, they may suffer from color deviation and loss of texture details. Additionally, they may also be susceptible to noise. To solve these problems, we learn spatial-channel feature refiners via wavelet-based linear mixed basis (SCFR-WLMB). Specifically, we adopt a novel wavelet-based linear mixed basis (WLMB) instead of a single wavelet basis for wavelet transform. To the best of our knowledge, this is the first time that this approach has been applied to low-light image enhancement. The WLMB takes advantage of various wavelets to better capture the color information and texture details in the image, thereby reducing the color deviation and enhancing the recovery of texture details. We also design a rhombic-grid crossed spatial feature enhancement block (RGC-SFEB), which firstly refines the input features into rich and redundant information through thresholding and then enhances the interaction between these two types of information in a rhombic-grid crossed way to increase the diversity of information. The RGC-SFEB is more likely to identify and correct errors introduced by noise, and help to resist the interference of noise. We conduct extensive experiments to validate our design and demonstrate on seven benchmark datasets that it achieves state-of-the-art (SOTA) methods both quantitatively and qualitatively. Our code will be publicly available at https://github.com/csust7zhangjm/SCFR-WLMB .},
  archive      = {J_KBS},
  author       = {Jianming Zhang and Jia Jiang and Zhijian Feng and Jin Wang},
  doi          = {10.1016/j.knosys.2025.114567},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114567},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning spatial-channel feature refiners via wavelet-based linear mixed basis for low-light image enhancement},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Is it genuine or fake? analyzing e-commerce reviews using large language models. <em>KBS</em>, <em>330</em>, 114556. (<a href='https://doi.org/10.1016/j.knosys.2025.114556'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread acceptance of online platforms has brought user-generated reviews to the forefront as a determinant of consumer decision-making, particularly in sectors such as hospitality and e-commerce. However, the growing prevalence of fake and misleading reviews poses significant challenges, often confusing consumers and undermining the credibility of online platforms. This research proposes a transformer-based framework for fake review detection using Large Language Models, achieving an overall classification accuracy of 90.50%. The contextual capacity of transformer-based architectures enables the model to effectively resolve ambiguity between genuine and deceptive user reviews. The objective of this research is twofold: to strengthen consumer trust and to preserve the reputation of online businesses. Performance benchmarks were established through comprehensive evaluations against multiple baseline algorithms on real-world e-commerce review datasets. Finally, the effects of deceptive reviews on strategic customer experience management are discussed, and directions toward scalable and real-time review verification systems are suggested. The obtained results show how well LLMs successfully capture the fine-grained linguistic patterns behind opinion spam and provide a strong method for automatic review authenticity verification in intelligent decision support systems. The datasets and experimental framework are available in the GitHub Repository.},
  archive      = {J_KBS},
  author       = {Siddharth Bhangale and Pradeep Kumar Roy},
  doi          = {10.1016/j.knosys.2025.114556},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114556},
  shortjournal = {Knowl. Based Syst.},
  title        = {Is it genuine or fake? analyzing e-commerce reviews using large language models},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient method for maximal erasable itemset mining in incremental databases. <em>KBS</em>, <em>330</em>, 114555. (<a href='https://doi.org/10.1016/j.knosys.2025.114555'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mining maximal erasable itemsets has recently attracted significant research attention due to its importance in various fields. It is particularly valuable in manufacturing for identifying and eliminating unprofitable or low-profit products, thereby reducing costs and optimizing production processes. However, current methods are inefficient for incremental databases; they require high storage and must re-scan the entire dataset or require revalidating large candidate sets when new data is added, leading to significant computational overhead. This paper proposes IMEL, a novel method to efficiently mine maximal erasable itemsets from incremental databases. IMEL utilizes two new data structures, the ICEI-List and the ICEP-List, which significantly reduce storage by maintaining only a single representative item in each list for both the original database and incoming data increments. Additionally, an indexed search space reduction technique embedded within the ICEI-List and ICEP-List structures accelerates processing time and minimizes unnecessary comparisons. Experimental results demonstrate that the IMEL algorithm improves mining time and storage efficiency on sparse and dense incremental datasets.},
  archive      = {J_KBS},
  author       = {Linh Nguyen and Giang Nguyen and De-Thu Huynh and Bao Huynh},
  doi          = {10.1016/j.knosys.2025.114555},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114555},
  shortjournal = {Knowl. Based Syst.},
  title        = {An efficient method for maximal erasable itemset mining in incremental databases},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ICCR-diff: Identity-preserving and controllable craniofacial reconstruction with diffusion models. <em>KBS</em>, <em>330</em>, 114554. (<a href='https://doi.org/10.1016/j.knosys.2025.114554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Craniofacial reconstruction predicts craniofacial features from skull morphology to reconstruct the craniofacial surface. Although previous methods have achieved promising performance, they face three critical limitations: insufficient image quality, poor identity preservation, and difficulties with conditional control. To overcome these challenges, we propose a novel diffusion-based craniofacial reconstruction method that preserves identity across domain transfer. Our approach incorporates multiple modules to separately manage multimodal information including skull data, landmarks, texture features, and biometric information, yielding high-fidelity results under various constraints. Furthermore, by enabling flexible modification of biometric information through standardized text prompts, our method achieves fine-grained control while maintaining individual identity characteristics. Extensive experimental results demonstrate that our method outperforms existing approaches in image quality and identity retrieval, showcasing exceptional robustness, strong identity preservation, and enhanced editability. Our code is available at: https://github.com/mqzhang2024/ICCR .},
  archive      = {J_KBS},
  author       = {Mingqin Zhang and Hongjie Wu and Zhengqing Zang and Jian Wang and Chaoqun Niu and Yuan Li and Jiancheng Lv},
  doi          = {10.1016/j.knosys.2025.114554},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114554},
  shortjournal = {Knowl. Based Syst.},
  title        = {ICCR-diff: Identity-preserving and controllable craniofacial reconstruction with diffusion models},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic feature projection and grouped contrastive learning for text-to-image person re-identification. <em>KBS</em>, <em>330</em>, 114553. (<a href='https://doi.org/10.1016/j.knosys.2025.114553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-Image Person Re-Identification (TIReID) is a core task in cross-modal person re-identification, aiming to retrieve target pedestrian images through textual descriptions. Existing methods primarily enhance retrieval performance by aligning cross-modal features through the fusion of global and local text-image representations. However, limitations persist in inadequate fine-grained feature extraction and overreliance on the hardest negative samples in loss computation. To address these challenges, we propose the Dynamic Feature Projection with Grouped Contrastive Learning framework (DFP-GCL). First, we employ a max-attention strategy to select representative local features from both text and images. These features are processed via two parallel pathways: a Multilayer Perceptron (MLP) extracts nonlinear fine-grained features; Dynamic Feature Projection (DFP) generates linear fine-grained features. The outputs are then fused by summation to produce enhanced fine-grained representations. Notably, in the local feature selection stage, a novel weighted-median adaptive filtering strategy driven by token frequency distribution is proposed, replacing conventional static empirical ratio settings. To further strengthen feature alignment, Grouped Contrastive Learning (GCL) is designed, which dynamically partitions negative samples into three groups: hard-dominated, semi-hard-dominated, and easy-dominated, based on similarity score gaps with positive samples. Each group is assigned distinct margin constants to enable targeted decision boundary adjustment, effectively balancing the influence of diverse negative sample groups during training. Experimental results demonstrate that our approach significantly improves text-to-image retrieval accuracy. Specifically, on the CUHK-PEDES, ICFG-PEDES, and RSTPReid datasets, Rank-1 accuracy outperforms the method of Qin et al. [1] by 1.12 %, 0.68 %, and 1.85 %, respectively. The code is available at: https://github.com/DylanHurst/DG .},
  archive      = {J_KBS},
  author       = {Shun He and Canlong Zhang and Xiaochun Lu and Zhixin Li and Zhiwen Wang},
  doi          = {10.1016/j.knosys.2025.114553},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114553},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic feature projection and grouped contrastive learning for text-to-image person re-identification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MgHiSal: MLLM-guided hierarchical semantic alignment for multimodal knowledge graph completion. <em>KBS</em>, <em>330</em>, 114552. (<a href='https://doi.org/10.1016/j.knosys.2025.114552'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Knowledge Graph Completion (MMKGC) aims to improve link prediction and empower downstream applications like intelligent question answering, reasoning, and recommendation by integrating multimodal information. However, existing methods commonly face semantic fragmentation between visual and textual modalities. This issue largely stems from the reliance on pre-trained vision models, which often struggle to model deep entity semantics, resulting in noisy visual features and the neglect of key semantic information. To address this, we propose MgHiSal, an MLLM-guided Hierarchical Semantic Alignment framework for MMKGC. MgHiSal first generates context-aware visual descriptions by conditioning MLLM generation on existing entity text, ensuring low-noise, relevant representations for initial semantic alignment. The framework then utilizes a hierarchical gated attention mechanism that progressively unifies multimodal representations by dynamically selecting and optimizing key cross-modal features via regularization. Finally, a neighbor-aware module enhances entity representations by aggregating multimodal neighbor information. Experiments on DB15K and MKG-W show MgHiSal significantly improves MRR by approximately 13.1 % and 12.5 % over respective runner-ups. The source code is publicly available at https://github.com/wyZhang016/MgHiSal .},
  archive      = {J_KBS},
  author       = {Jie Chen and Wuyang Zhang and Shu Zhao and Yunxia Yin},
  doi          = {10.1016/j.knosys.2025.114552},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114552},
  shortjournal = {Knowl. Based Syst.},
  title        = {MgHiSal: MLLM-guided hierarchical semantic alignment for multimodal knowledge graph completion},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing deep clustering through the synergy of contrastive learning and capsule-GAN. <em>KBS</em>, <em>330</em>, 114551. (<a href='https://doi.org/10.1016/j.knosys.2025.114551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a collaborative deep clustering framework that synergistically integrates contrastive learning with a capsule-based GAN. Specifically, the framework first generates augmented image variants via employing multi-resolution cropping and rotation on real images. Both original and augmented images are processed through a clustering network, where mutual learning between data instances promotes consistent cluster label assignments. Then these labels are transformed into one-hot encoded vectors and combined with random latent variables to drive a capsule-based generator, which synthesizes high-fidelity images. A capsule-based discriminator evaluates real and synthetic images, providing informative gradient feedback to iteratively enhance the generator’s output quality. Following this, synthetic and real images are grouped into clusters using a one-vs-rest strategy. Images assigned to the same cluster are considered as positive pairs, while those from different clusters are as negative pairs. These pairwise relationships are leveraged within a contrastive learning framework to improve the model’s ability to learn discriminative, cluster-friendly representations. Experimental results on several image datasets, including MNIST, Fashion-MNIST, CIFAR-10, STL-10, ImageNet-10, and ImageNet-Dog, have demonstrated that our method consistently outperforms state-of-the-art deep clustering approaches in terms of clustering accuracy and normalized mutual information (NMI). An ablation study further confirms the effectiveness of each component and highlights their collective contribution to clustering performance improvement. Overall, this work establishes a foundation for unified representation learning and clustering through the interplay of adversarial training and contrastive optimization.},
  archive      = {J_KBS},
  author       = {Wenming Cao and Zhongfan Zhang and Man Li and Zhiwen Yu},
  doi          = {10.1016/j.knosys.2025.114551},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114551},
  shortjournal = {Knowl. Based Syst.},
  title        = {Advancing deep clustering through the synergy of contrastive learning and capsule-GAN},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual attention focus network for few-shot skeleton-based action recognition. <em>KBS</em>, <em>330</em>, 114549. (<a href='https://doi.org/10.1016/j.knosys.2025.114549'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot action recognition is a challenging yet practically significant problem that involves developing a model capable of learning discriminative features from a small number of labeled samples to recognize new action categories. Current methods typically infer spatial relationships either within or across skeletons to learn action representations, but this often results in features with insufficient discriminability and ineffective attention to critical body parts. To address these limitations, we propose DAF-Net, a novel framework that employs focal attention to jointly model intra-skeleton and inter-skeleton relationships, enhancing discriminative feature learning in few-shot skeleton-based action recognition. Unlike traditional methods that focus solely on intra-skeleton dependencies or inter-skeleton structures, DAF-Net dynamically integrates both components via focal attention, enhancing key body part representation and refining features, particularly in data-scarce conditions. Furthermore, DAF-Net incorporates an enhanced prototype generation strategy, optimizing class prototype formation via cosine similarity weighting to further improve feature discriminability in multi-shot scenarios. In temporal matching, cosine similarity evaluates local feature similarity within skeleton sequences, capturing directional variations of specific joints over time. Extensive experiments on three benchmark datasets (NTU-T, NTU-S, and Kinetics-skeleton) confirm significant performance gains, validating the effectiveness of DAF-Net.},
  archive      = {J_KBS},
  author       = {Jie Liu and Chongben Tao and Zhongwei Shen and Cong Wu and Tianyang Xu and Xizhao Luo and Feng Cao and Zhen Gao and Zufeng Zhang and Sai Xu},
  doi          = {10.1016/j.knosys.2025.114549},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114549},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual attention focus network for few-shot skeleton-based action recognition},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous graph collaborative representation learning for drug-related microbe prediction with attentive fusion and reciprocal distillation. <em>KBS</em>, <em>330</em>, 114548. (<a href='https://doi.org/10.1016/j.knosys.2025.114548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microbes are microorganisms with biological molecules and have significant therapeutic potential for treating diseases, underscoring the need for computational methods to screen microbes targeting disease-associated drugs. However, the computational methods often consider node embedding or structure features between microbes and drugs, and have a severe class imbalance problem inherent in sparse association data. In this work, we proposed a heterogeneous graph collaborative representation learning model that combines the merits of attentive fusion and reciprocal distillation for drug-related microbe prediction. First, we constructed the heterogeneous biological information and meta-path-induced graphs of microbes and drugs. Then, a topological structure feature encoder is devised to extract complex topological and semantic interaction patterns from heterogeneous biological graphs with microbes and drugs, while an efficient transformer concurrently extracts discriminative semantic and structural information based on the graph position information of nodes. Next, a reciprocal distillation schema is developed to mitigate the adverse effects of the data imbalance problem, and enable the distribution consistency of the model between topological and semantic information extraction. Moreover, we devised a dual collaborative feature fusion schema that combines graph topological and dual meta-path-based semantic features to obtain the discriminative features of microbes and drugs. Through reciprocal distillation, an efficient optimization function focuses on hard-to-classify samples of drug-related microbes via discriminative features. Extensive experiments demonstrate that our model could deal with the association sparsity problem and extract more semantics and structure. Meanwhile, case studies indicate that our model could discover reliable candidate microbes associated with a special drug.},
  archive      = {J_KBS},
  author       = {Yanbu Guo and Quanming Guo and Shengli Song and Yihan Wang and Jinde Cao},
  doi          = {10.1016/j.knosys.2025.114548},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114548},
  shortjournal = {Knowl. Based Syst.},
  title        = {Heterogeneous graph collaborative representation learning for drug-related microbe prediction with attentive fusion and reciprocal distillation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring non-negativity for improved manifold embedding: Application to t-SNE. <em>KBS</em>, <em>330</em>, 114547. (<a href='https://doi.org/10.1016/j.knosys.2025.114547'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drawing inspiration from Non-negative Matrix Factorization (NMF), this paper explores the potential of incorporating non-negativity constraints into embedding techniques, with a focus on t-SNE as an application. Specifically, we investigate the following questions: Can enforcing non-negativity in the embedding space enhance interpretability and improve the quality of embedded data? By prioritizing non-negativity, can embedding methods achieve better performance and more meaningful representations? Additionally, does enforcing non-negativity in the embedded space help preserve both the local and global structure of data in the manifold, leading to more accurate and interpretable embeddings? In this work, we could show both objectively and subjectively how enforcing t-SNE to leverage the non-negativity of the data addresses the raised questions. To achieve this, we introduced a novel approach to transforming the additive update rule of the gradient descent used by t-SNE to a multiplicative counterpart to enforce the non-negativity in the embedded space. However, grappling with full non-negativity in the gradient descent formula presents challenges, prompting our focus solely on the ( y i − y j ) term, resulting in a semi-non-negative t-SNE algorithm, shortly named SN-tSNE. Nevertheless, experimental findings substantiate the significant impact of the proposed update rule on the performance and efficacy of the SN-tSNE algorithm. Furthermore, additional experiments are performed to compare SN-tSNE with its precursor t-SNE, as well as the competitive embedding technique UMAP, alongside other relevant embedding and dimensionality reduction models like NMF. The source code of SN-tSNE is available on GitHub ( https://github.com/M-Allaoui/SN-tSNE.git ).},
  archive      = {J_KBS},
  author       = {Mebarka Allaoui and Rachid Hedjam and Khadra Bouanane and Mohand Saïd Allili and Mohammed Lamine Kherfi and Samir Brahim Belhaouari},
  doi          = {10.1016/j.knosys.2025.114547},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114547},
  shortjournal = {Knowl. Based Syst.},
  title        = {Exploring non-negativity for improved manifold embedding: Application to t-SNE},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A vision transformer-based hybrid neural architecture for automated handwritten bangla character recognition and braille conversion. <em>KBS</em>, <em>330</em>, 114546. (<a href='https://doi.org/10.1016/j.knosys.2025.114546'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancement of technology has led to notable changes in the current educational system. Nevertheless, there are still relatively few assisting aids that can help in teaching individuals with disabilities, such as those who are blind or visually impaired. An effective teaching strategy for those who are blind or visually impaired is braille. Although it has been digitized to produce an electronic version, handwritten characters are not considered in those versions. Studies on English character recognition have shown high accuracy, which is not the case with Bangla character recognition. We present an automated system that converts handwritten Bangla characters to braille using novel hybrid deep neural network architectures. Our approach begins with a Character Quality Assessment Framework (CQAF), which employs adaptive thresholds and comprehensive quality metrics designed explicitly for Bangla script characteristics. Building upon this foundation, we present two architectures. HybridNet-L represents our initial multi-stream design, while HybridNet-S is a redesigned lightweight variant that reduces parameters and achieves superior accuracy, making it the primary contribution of this work. To complete the system, we implement a comprehensive accessibility solution featuring real-time braille hardware interface and text-to-speech capabilities. The model effectively processes all 84 Bangla character classes including vowels, consonants, numerics, and compound characters. Extensive evaluation against seven baseline models demonstrates that our HybridNet-S achieves superior performance with 95.80% validation accuracy while maintaining computational efficiency suitable for embedded deployment. Statistical validation and ablation studies confirm the robustness and effectiveness of our multi-stream architecture for practical assistive technology applications.},
  archive      = {J_KBS},
  author       = {Touseef Saleh Bin Ahmed and Tawhidur Rahman and Shammo Biswas and Saifur Rahman Sabuj and Mohammed Belal Bhuian and Mohammad Ali Moni and Md Ashraful Alam},
  doi          = {10.1016/j.knosys.2025.114546},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114546},
  shortjournal = {Knowl. Based Syst.},
  title        = {A vision transformer-based hybrid neural architecture for automated handwritten bangla character recognition and braille conversion},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A winner effect based approach for multimodal review helpfulness prediction with deep learning algorithm. <em>KBS</em>, <em>330</em>, 114545. (<a href='https://doi.org/10.1016/j.knosys.2025.114545'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of multimodal online reviews, integrating texts and images, presents opportunities and poses challenges for predicting review helpfulness, which is crucial for supporting consumer decision-making. Despite growing research, persistent contradictions regarding both textual and visual features have intensified the need to identify decisive factors among reviews. This study addresses this gap by developing a neuroscientific computation framework that integrates the winner effect—a cognitive mechanism wherein dominant stimuli hierarchically shape decision-making processes—into a Winner Effect-Enhanced Attention Mechanism (WE-EAM). The proposed deep learning framework dynamically amplifies discriminative multimodal features through a novel win-increase and lose-decrease self-attention mechanism. Based on an evaluation of 30,000 Yelp restaurant reviews, three key insights emerged: 1) the proposed method of WE-EAM deep learning framework achieves 88.72 % accuracy in multimodal helpfulness prediction, outperforming state-of-the-art models by 4.45 % in late-fusion scenario. 2) Late fusion strategy in latent space outperformed early and hybrid fusion strategies across single- and multi-head attention configurations, especially the winner effect ratio achieving 0.5. Therefore, late fusion strategy leveraging the winner effect is the superior approach for mining discriminative multimodal representations. 3) Visualization analyses confirm that the model overemphasizes initial review segments where core sentiments are expressed. These findings advance computational modeling through two actionable strategies that bridge cognitive neuroscience and machine learning: both late compositing of text and image features into WE-EAM deep learning framework and highlighting early-segment content may enhance review helpfulness prediction.},
  archive      = {J_KBS},
  author       = {Donghui Yang and Mingyang Zhang and Yongbo Ni and Siyuan Xu and Kehui Zhu},
  doi          = {10.1016/j.knosys.2025.114545},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114545},
  shortjournal = {Knowl. Based Syst.},
  title        = {A winner effect based approach for multimodal review helpfulness prediction with deep learning algorithm},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic pick-up point recommendation with multi-modal deep forest and incentive-based adaptive kuhn-munkres algorithm. <em>KBS</em>, <em>330</em>, 114543. (<a href='https://doi.org/10.1016/j.knosys.2025.114543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendations for optimal pick-up points significantly enhance service efficiency, reduce economic and temporal costs, and alleviate traffic congestion. However, spatiotemporal imbalance between ride-hailing supply and passenger demand presents significant challenges. Current models often overlook critical influencing factors such as passenger satisfaction, travel environment, and travel cost factors. Moreover, solution algorithms, including exact algorithms and heuristics, struggle to achieve global optimality and computational efficiency in large-scale scenarios. This study introduces a comprehensive mathematical model that incorporates four key influencing factors: passenger walking distance, passenger waiting time, traffic conditions, and estimated ride-hailing fare. The solution approach consists of a novel pick-up point evaluation algorithm and an incentive-based adaptive Kuhn-Munkres matching algorithm. The evaluation algorithm employs a multi-modal decision tree structure, enhanced by deep learning techniques to improve the accuracy of pick-up point evaluations. The matching algorithm features a multi-scenario adaptive mechanism that dynamically adjusts edge weights and selects optimal edges for augmentation under various conditions and strategies, thereby ensuring globally optimal matching of passengers and pick-up points. Extensive experiments on large-scale real-world datasets validate the superior performance of the evaluation and matching algorithms, especially in handling large-scale instances. The developed model and algorithms assist ride-hailing platforms in optimizing operations, enhancing service quality, increasing profitability, and improving cost management.},
  archive      = {J_KBS},
  author       = {Yuhan Guo and Rushi Zhu and Wenhua Li and Youssef Boulaksil and Hamid Allaoui},
  doi          = {10.1016/j.knosys.2025.114543},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114543},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic pick-up point recommendation with multi-modal deep forest and incentive-based adaptive kuhn-munkres algorithm},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing multi-modal document distillation with energy-weighted supervision. <em>KBS</em>, <em>330</em>, 114542. (<a href='https://doi.org/10.1016/j.knosys.2025.114542'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As large multi-modal document models (e.g. LayoutLMv3) grow increasingly complex, knowledge distillation (KD) has become essential for practical deployment. EnergyKD enhances conventional logit-based KD by adjusting temperature per sample using energy scores. However, it still misleads students when teacher predictions are incorrect on high energy (i.e. low confidence) inputs. Although High-Energy Data Augmentation (HE- DA) is introduced to address this issue, it adds significant training overhead. In this work, we propose Energy-Weighted Supervision (EWS), a general-purpose supervision augmentation framework that builds upon an energy-based sample stratification mechanism. EWS dynamically adjusts the balance between hard-label and soft-label losses according to each sample’s energy score, thereby increasing the likelihood that the student model receives accurate and corrective supervision, without requiring additional data augmentation or training overhead. Our experiments demonstrate that EWS effectively improves the performance of various KD methods. On the harder FUNSD benchmark, EWS yields the largest gains (+2.35 F1), while on CORD and SROIE the improvements are smaller but consistently positive (up to +0.84 and +0.11 F1, respectively), confirming broad applicability across KD paradigms. Especially, when applied to EnergyKD, EWS addresses its core limitation, namely, the misleading influence of sharpened teacher outputs on high energy samples, by allocating greater weight to hard-label signals. Conversely, for low energy samples, EWS preserves soft-label emphasis to fully exploit the teacher’s informative predictions. Compared to conventional logit-based KD, EnergyKD, and even HE-DA, our energy-guided loss modulation approach consistently improves student performance across multiple documents understanding benchmarks, without additional training cost. To the best of our knowledge, this is the first framework in multi-modal document distillation that simultaneously integrates energy-aware temperature scaling and dynamic supervision weighting, offering a promising direction for future research and deployment on resource-limited devices.},
  archive      = {J_KBS},
  author       = {Jen-Chun Chang and Chia-Cheng Lee and Chung-Fu Lu and Victor R.L. Shen},
  doi          = {10.1016/j.knosys.2025.114542},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114542},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing multi-modal document distillation with energy-weighted supervision},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RSDC-net: Robust self-supervised dynamic collaboration network for infrared and visible image fusion. <em>KBS</em>, <em>330</em>, 114541. (<a href='https://doi.org/10.1016/j.knosys.2025.114541'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion (IVIF) aims to integrate complementary information from distinct sensors, yielding fused results that outperform the capabilities of either individual modality alone. Due to inherent modality bias, conventional fusion-reconstruction frameworks often struggle to effectively prioritize the representation of critical shared regions and diverse heterogeneous areas, while also showing deficiencies in shallow feature interactions. To address these challenges, we propose a robust self-supervised dynamic collaboration network (RSDC-Net), which adaptively and comprehensively selects complementary cues from both infrared and visible modalities. Specifically, we introduce a steady-state contrastive autoencoder that leverages a multi-task self-supervised strategy to enhance the robust representation of key shared cues in the mixed information flow. This strategy promotes deep cross-modal modeling of global dependencies across sources, thereby achieving semantic consistency. Furthermore, we design a latent inter-modal focus-guided module that integrates a bilateral transposed attention mechanism with a dynamic selection component to refine local-level heterogeneous cue allocation under the guidance of mutual global dependencies. Notably, a gated feed-forward unit is incorporated to filter outlier information flows across modalities. Quantitative results on the MSRS, TNO, and M3FD datasets demonstrate that RSDC-Net achieves the best performance on most of the eight evaluation metrics. Meanwhile, it also exhibits superior performance in qualitative visual assessments on these datasets as well as under challenging scenarios.},
  archive      = {J_KBS},
  author       = {Yun Li and Ningyuan Zhao and Xue Yang and Liping Luo and Peiguang Jing},
  doi          = {10.1016/j.knosys.2025.114541},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114541},
  shortjournal = {Knowl. Based Syst.},
  title        = {RSDC-net: Robust self-supervised dynamic collaboration network for infrared and visible image fusion},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A topology-aware multiscale feature fusion network for EEG-based motor imagery decoding. <em>KBS</em>, <em>330</em>, 114540. (<a href='https://doi.org/10.1016/j.knosys.2025.114540'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motor imagery electroencephalography (MI-EEG) decoding is a crucial component of brain-computer interface (BCI) systems, serving as a valuable tool for motor function rehabilitation and fundamental neuroscience research. However, the strong nonlinearity and non-stationarity of MI-EEG signals make achieving high-precision decoding a challenging task. Current deep learning methods primarily extract the spatiotemporal features of MI-EEG signals while neglecting their potential association with spectral-topological features, thereby limiting the ability to integrate multidimensional information. To address these limitations, this paper proposes a Topology-Aware Multiscale Feature Fusion network (TA-MFF network) for MI-EEG signal decoding. Specifically, we designed a Spectral-Topological Data Analysis-Processing (S-TDA-P) module that leverages persistent homology features to analyze the spatial topological relationships between EEG electrodes and the persistent patterns of neural activity. Then, the Inter Spectral Recursive Attention (ISRA) mechanism is employed to model the correlations between different frequency bands, enhancing critical spectral features while suppressing irrelevant noise. Finally, the Spectral-Topological and Spatio-Temporal Feature Fusion (SS-FF) Unit is employed to progressively integrate topological, spectral, and spatiotemporal features, capturing dependencies across different domains. The experimental results show that the classification accuracy of the proposed model in BCIC-IV-2a, BCIC-IV-2b, and BCIC-III-Iva is 85.87 %, 90.2 %, and 80.5 %, respectively, outperforming the most advanced methods.},
  archive      = {J_KBS},
  author       = {Chaowen Shen and Akio Namiki},
  doi          = {10.1016/j.knosys.2025.114540},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114540},
  shortjournal = {Knowl. Based Syst.},
  title        = {A topology-aware multiscale feature fusion network for EEG-based motor imagery decoding},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DriveFL: A dynamic reputation incentive mechanism for federated learning in dense internet of vehicles. <em>KBS</em>, <em>330</em>, 114539. (<a href='https://doi.org/10.1016/j.knosys.2025.114539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) enables devices to use data locally for model training and thus has received significant attention for protecting data privacy in the Internet of Vehicles (IoV). However, rational vehicles are reluctant to contribute their data to participate in training without compensation, necessitating the implementation of effective incentive algorithms to motivate vehicles to participate in training. Nevertheless, unlike incentives in other domains, the IoV has the following challenges for the design of incentive systems. First, the large number of vehicles in a dense IoT imposes a huge communication burden and pressure on computational efficiency. Second, road data used by vehicles for training may be affected by factors such as damaged sensors or harsh environments, resulting in changes in data quality. Third, intermittent participation issues are caused by the vehicle’s mobility. To address these issues, we propose DriveFL: A Dynamic Reputation Incentive Mechanism for Federated Learning in Dense Internet of Vehicles. Specifically, we employ gradient compression techniques to reduce communication costs. Subsequently, we design a similarity-based gradient compression quality assessment method capable of evaluating the quality of vehicle data in real time. Then, we develop a dynamic reputation incentive mechanism that quantifies quality assessment records and integrates reverse auction theory, which can attract vehicles with higher data quality from those that intermittently participate in training, thereby enhancing model training quality under constrained communication costs and budget limitations. Theoretical analysis demonstrates that our mechanism satisfies computational efficiency, individual rationality, budget feasibility, and truthfulness. Simulation experiments confirm the effectiveness of our approach.},
  archive      = {J_KBS},
  author       = {Xin Chang and Lixin Liu and Jingyu Wang and Jinling Yu and Xiaolin Zhang},
  doi          = {10.1016/j.knosys.2025.114539},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114539},
  shortjournal = {Knowl. Based Syst.},
  title        = {DriveFL: A dynamic reputation incentive mechanism for federated learning in dense internet of vehicles},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient cluster-guided key timestamp discovery for temporal knowledge graph completion. <em>KBS</em>, <em>330</em>, 114537. (<a href='https://doi.org/10.1016/j.knosys.2025.114537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal knowledge graph (TKG) completion aims to infer the missing links from the numerous historical facts. Accurate evolutionary representations of entities from each recent KG snapshot are fundamental for TKG completion. Recent research has focused on incorporating the fixed lengths of KG sequences as well as the timestamps information, resulting in lacking flexible judgment on “time lag” issue. To address the issue, we propose CutTKG, an efficient C luster-g u ided key t imestamps discovery method with contrastive learning for TKG completion. Specifically, we first attempt to identify the most relevant historical facts within the key timestamps by utilizing an efficient clustering method for the associated relations. Then, we propose a multi-view representation learning method to learn the representations of entities from the divided related-history view and unrelated-history view. Finally, we design a contrastive learning strategy to alleviate the negative impact of irrelevant facts and further make the CutTKG primarily focus on the most relevant facts. Extensive experiments demonstrate that our CutTKG model achieves new state-of-the-art results on four benchmark datasets.},
  archive      = {J_KBS},
  author       = {Yao Xiao and Guangyou Zhou and Zhiwen Xie and Jin Liu and Jimmy Xiangji Huang},
  doi          = {10.1016/j.knosys.2025.114537},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114537},
  shortjournal = {Knowl. Based Syst.},
  title        = {Efficient cluster-guided key timestamp discovery for temporal knowledge graph completion},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward more effective bag-of-functions architectures: Exploring initialization and sparse parameter representation. <em>KBS</em>, <em>330</em>, 114536. (<a href='https://doi.org/10.1016/j.knosys.2025.114536'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series datasets often present complex temporal patterns that challenge both feature extraction and interpretability. The Bag-of-Functions (BoF) architecture has emerged as a promising approach to model such data by capturing diverse dynamics through functional components. However, its effectiveness is constrained by limitations in both interpretability and training stability. In this work, we address these challenges by introducing two complementary contributions: a regularization strategy that promotes sparse and interpretable parameter representations, and a tailored initialization scheme based on the Kaiming method adapted to the properties of BoF models. Our proposed initialization ensures improved convergence behavior and training stability, while the regularization enhances the clarity and semantic interpretability of the learned components. Evaluations on synthetic and real-world time series datasets demonstrate that these improvements preserve model performance and generalize well across varying signal complexities. Together, these strategies provide a more robust and interpretable foundation for Bag-of-Functions architectures in time series decomposition tasks.},
  archive      = {J_KBS},
  author       = {David Orlando Salazar Torres and Diyar Altinses and Andreas Schwung},
  doi          = {10.1016/j.knosys.2025.114536},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114536},
  shortjournal = {Knowl. Based Syst.},
  title        = {Toward more effective bag-of-functions architectures: Exploring initialization and sparse parameter representation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selective embedding for deep learning. <em>KBS</em>, <em>330</em>, 114535. (<a href='https://doi.org/10.1016/j.knosys.2025.114535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has revolutionized many industries by enabling models to automatically learn complex patterns from raw data, reducing dependence on manual feature engineering. However, deep learning algorithms are sensitive to input data, and performance often deteriorates under nonstationary conditions and across dissimilar domains, especially when using time-domain data. Conventional single-channel or parallel multi-source data loading strategies either limit generalization or increase computational costs. This study introduces selective embedding, a novel data loading strategy, which alternates short segments of data from multiple sources within a single input channel. Drawing inspiration from cognitive psychology, selective embedding mimics human-like information processing to reduce model overfitting, enhance generalization, and improve computational efficiency. Validation is conducted using six time-domain datasets, demonstrating that the proposed method consistently achieves high classification accuracy for many deep learning architectures while significantly reducing training times. Across multiple datasets, selective embedding consistently improves test accuracy by 20 to 30 percent compared to traditional single-channel loading strategies, while also matching or exceeding the performance of parallel multi-source loading methods. Importantly, these gains are achieved while significantly reducing training times, demonstrating both efficiency and scalability across simple and complex architectures. The approach proves particularly effective for complex systems with multiple data sources, offering a scalable and resource-efficient solution for real-world applications in healthcare, heavy machinery, marine, railway, and agriculture, where robustness and adaptability are critical.},
  archive      = {J_KBS},
  author       = {Mert Sehri and Zehui Hua and Francisco de Assis Boldt and Patrick Dumond},
  doi          = {10.1016/j.knosys.2025.114535},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114535},
  shortjournal = {Knowl. Based Syst.},
  title        = {Selective embedding for deep learning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sequence-aware adaptive graph convolutional recurrent networks for traffic forecasting. <em>KBS</em>, <em>330</em>, 114533. (<a href='https://doi.org/10.1016/j.knosys.2025.114533'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic forecasting is a crucial task for the Intelligent Transportation System (ITS). A promising research direction for improving traffic prediction is to learn dynamic graph structures incorporating the hidden dependencies from the training sequence data. However, existing works optimize these dynamic graph structures only for the training data, regarding them as static when testing with new input sequences. This constrains the forecasting model’s ability to address potential discrepancies between training and testing sequences, which may arise from unforeseen changes in the traffic environment. To address this challenge, we propose a new encoder-decoder framework for traffic forecasting, S equence-aware Adaptive Graph Convolutional Recurrent Networks ( SAGCRN ). The encoder augments an input sequence by exploiting spatio-temporal contexts and traffic pattern storage. Then, the decoder adaptively learns a new graph structure reflecting the augmented input sequence and uses it for prediction. To further enhance the sequence-specialized graph structure, SAGCRN optimizes the stored traffic patterns to be more discriminative. We demonstrate the superior performance of SAGCRN on three real-world benchmark datasets, comparing it with nine baseline models. The additional sensitivity and qualitative analyses substantiate the effectiveness of our model. For reproducibility, the source code is available at https://github.com/gooriiie/SAGCRN .},
  archive      = {J_KBS},
  author       = {Seunghoon Han and Hyewon Lee and Daniel Y. Lee and Sung-Soo Kim and Susik Yoon and Sungsu Lim},
  doi          = {10.1016/j.knosys.2025.114533},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114533},
  shortjournal = {Knowl. Based Syst.},
  title        = {Sequence-aware adaptive graph convolutional recurrent networks for traffic forecasting},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The parallel visual perception network based on nonlinear spiking neural p systems for camouflaged object detection. <em>KBS</em>, <em>330</em>, 114532. (<a href='https://doi.org/10.1016/j.knosys.2025.114532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous species have evolved camouflage through morphological adaptations that mimic environmental colors and textures, posing significant challenges for visual detection systems. Current camouflaged object detection (COD) methods remain limited in simulating biological visual mechanisms due to inadequate multi-stage cognitive modeling and weak biological correspondence in neural computations. To address these limitations, a parallel visual perception network (NSNPVPNet) based on nonlinear spiking neural P (NSNP) systems is proposed, simulating biological visual processes through three core modules: scene perception, cognitive reasoning, and decision inference module. A bio-inspired convolutional block reconstructed through NSNP systems enhances biological-computational mapping relationships. Experimental evaluations across four benchmark datasets demonstrate superior performance over twenty state-of-the-art COD methods, achieving average metric improvements of 3.2% ( S m ), 2.5% ( a E m ), 5.4% ( F β w ), and 1.2% ( M ). These advancements validate NSNP systems’ potential in COD applications and pioneer new bio-inspired approaches for bionic visual computing. The implementation is available at: https://github.com/Williamzhounan/NSNPVPNet .},
  archive      = {J_KBS},
  author       = {Nan Zhou and Hong Peng and Zhicai Liu},
  doi          = {10.1016/j.knosys.2025.114532},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114532},
  shortjournal = {Knowl. Based Syst.},
  title        = {The parallel visual perception network based on nonlinear spiking neural p systems for camouflaged object detection},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot hyperspectral image classification with mamba and manifold convolution fusion network. <em>KBS</em>, <em>330</em>, 114531. (<a href='https://doi.org/10.1016/j.knosys.2025.114531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient modeling of global-local features is crucial for hyperspectral image (HSI) classification. The mamba network demonstrates strong capability in capturing global dependencies in HSI classification tasks, primarily utilizing a state-space model to extract first-order statistical features of spectral-spatial information in euclidean space, providing an initial representation of data characteristics. However, under few-shot conditions, fully exploiting effective features from limited samples and overcoming challenges such as class overlap and feature space sparsity caused by the insufficient extraction of second-order statistical features in riemannian space remain major research challenges. Therefore, we propose a dual branch manifold convolution-mamba network (DBMCMamba) for HSI classification. Specifically, it adaptively fuses forward and backward information through the vision mamba (Vim) block and utilizes the S6 module to extract global information, thereby enhancing global feature extraction capability. Meanwhile, the manifold convolution module extracts first-order statistical features of spectral-spatial information through convolutional layers and learns second-order statistics via the SPD manifold to strengthen DBMCMamba’s local feature representation under few-shot conditions. Finally, global and local features are fused for classification, effectively improving the accuracy and performance of HSI classification. On the Indian Pines, Pavia University, HongHu, and HanChuan datasets, DBMCMamba achieved classification accuracies of 95.23 %, 95.80 %, 95.58 %, and 94.93 %, respectively. Experimental results show that DBMCMamba demonstrates significant performance improvements compared to the state-of-the-art classification models. The code will be available online at https://github.com/ASDFFGG121EAA/DBMCMamba .},
  archive      = {J_KBS},
  author       = {Heling Cao and Yanlong Guo and Yonghe Chu and Yun Wang and Junyi Duan and Peng Li},
  doi          = {10.1016/j.knosys.2025.114531},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114531},
  shortjournal = {Knowl. Based Syst.},
  title        = {Few-shot hyperspectral image classification with mamba and manifold convolution fusion network},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing ICD classification with semantic embedding rectification and long-tail refinement. <em>KBS</em>, <em>330</em>, 114530. (<a href='https://doi.org/10.1016/j.knosys.2025.114530'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic International Classification of Diseases (ICD) coding is essential for healthcare systems, enabling accurate clinical documentation and decision-making. However, existing models struggle with two critical challenges: (1) semantic misalignment between clinical texts and ICD codes, leading to inaccurate label representations, and (2) long-tail label distribution, where low-frequency ICD codes suffer from poor generalization. To address these issues, we propose RoSimTail-ICD , an innovative framework that incorporates two newly developed modules: Semantic Space Discrepancy Correction (SSDC) and Multi-stage Adaptive Tail Refinement (MATR). SSDC enhances the alignment between clinical text embeddings and ICD label representations, mitigating semantic drift and improving prediction robustness. MATR dynamically refines tail label learning by progressively adjusting label segmentation and training dynamics, ensuring sufficient representation learning for rare labels. Extensive experiments on MIMIC-III and MIMIC-IV datasets demonstrate that RoSimTail-ICD consistently outperforms state-of-the-art models. These results demonstrate the effectiveness of our approach in tackling both semantic inconsistency and long-tail label imbalance, paving the way for more accurate and robust automated ICD coding.},
  archive      = {J_KBS},
  author       = {Yuhao Wu and Yifan Wu and Wei Fan and Min Li},
  doi          = {10.1016/j.knosys.2025.114530},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114530},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing ICD classification with semantic embedding rectification and long-tail refinement},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NPMFF-net: A training-free unified framework for point cloud classification and segmentation. <em>KBS</em>, <em>330</em>, 114529. (<a href='https://doi.org/10.1016/j.knosys.2025.114529'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-parametric networks have shown promise for understanding point clouds due to their training-free nature and low computational cost. However, existing methods such as Point-NN and Seg-NN underutilize geometric and frequency information. Although these methods demonstrate superior accuracy, we found that the potential features of point clouds can still be explored in depth. In this work, we revisit non-parametric networks and propose the Non-Parametric Multi-scale Feature Fusion Network (NPMFF-Net), a model designed to unify spatial and frequency information in point cloud analysis, featuring training-free components. The key is Plücker coordinates Encoding and Fourier Feature Mapping, combining geometric information with high-frequency features. We propose a non-parametric attention module to integrate contextual information and k-adaptive normal pooling to aggregate multi-scale features. Extensive experiments on the ModelNet10/40, ScanObjectNN, ShapeNetPart, S3DIS, and ScanNet datasets demonstrate the superiority of NPMFF-Net in point classification and segmentation tasks. We surpass Point-NN by 8.2 % OA and Seg-NN by 5.8 % OA on ModelNet40 for classification, while also achieving a 2.7 % improvement in mean IoU over Point-NN on ShapeNetPart for part segmentation.},
  archive      = {J_KBS},
  author       = {Hualong Zeng and Haijiang Zhu and Huaiyuan Yu and Mengting Liu and Ning An},
  doi          = {10.1016/j.knosys.2025.114529},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114529},
  shortjournal = {Knowl. Based Syst.},
  title        = {NPMFF-net: A training-free unified framework for point cloud classification and segmentation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical reinforcement learning for dynamic collision avoidance of autonomous ships under uncertain scenarios. <em>KBS</em>, <em>330</em>, 114528. (<a href='https://doi.org/10.1016/j.knosys.2025.114528'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous ships hold substantial potential for enhancing navigational safety, improving collision avoidance efficiency, and increasing adaptability in complex maritime environments, thereby presenting broad prospects for intelligent shipping. This paper introduces a dynamic collision avoidance control method based on a hierarchical reinforcement learning framework for autonomous ships. By integrating high-level global intent planning with low-level fine-grained rudder control, the proposed approach markedly enhances the interpretability, stability, and behavioral consistency of the learned policy. Furthermore, a multidimensional uncertainty modeling mechanism is incorporated during training, systematically accounting for variations in initial states and obstacle behavior patterns, which effectively strengthens policy adaptability and generalization under uncertain conditions. To validate the method, simulations are conducted in representative encounter scenarios as well as in omnidirectional dynamic obstacle tests. A comprehensive evaluation is carried out using multiple control performance metrics, environmental adaptability analysis, policy consistency assessment, and equivalent energy consumption comparisons. The results confirm that the proposed approach achieves stable and reliable intelligent collision avoidance control in highly dynamic environments, offering a feasible and scalable solution for high-performance collision avoidance in intelligent maritime navigation.},
  archive      = {J_KBS},
  author       = {Sijin Yu and Yunbo Li and Jiaye Gong},
  doi          = {10.1016/j.knosys.2025.114528},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114528},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hierarchical reinforcement learning for dynamic collision avoidance of autonomous ships under uncertain scenarios},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncovering novel scientific insights with a synergistic GNN-LLM framework. <em>KBS</em>, <em>330</em>, 114527. (<a href='https://doi.org/10.1016/j.knosys.2025.114527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of scientific literature demands intelligent systems capable of uncovering emerging knowledge associations and fostering creativity. While graph neural networks (GNNs) excel at modeling literature structures, their static temporal modeling and lack of semantic awareness limit the discovery of interpretable signals. Conversely, large language models (LLMs) offer deep semantic reasoning but struggle to find non-obvious, structurally-grounded patterns without structured input. To address these limitations, this paper proposes a multi-stage GNN-LLM framework that integrates structural pattern recognition and semantic interpretation for scientific knowledge discovery. The framework begins with a Semantic-Enhanced Temporal Graph Network (SE-TGN), which embeds paper-level semantic information into an event-based temporal GNN to identify emerging keyword associations. These structurally grounded candidates are refined through the Contextual Re-ranking and Evaluation Framework (CREF), which leverages LLM capabilities to assess contextual novelty and relevance. Finally, the Generative Interpretation and Contextualization (GIC) produces human-readable explanations and research prompts to support innovation. Experiments in two scientific domains demonstrate the effectiveness of the framework in discovering semantically rich, contextually grounded, and forward-looking knowledge associations, illustrating its potential to support interpretable and creativity-driven scientific exploration.},
  archive      = {J_KBS},
  author       = {Qingqing Wang and Derui Lyu and Qiuju Chen},
  doi          = {10.1016/j.knosys.2025.114527},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114527},
  shortjournal = {Knowl. Based Syst.},
  title        = {Uncovering novel scientific insights with a synergistic GNN-LLM framework},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TreeQA: Enhanced LLM-RAG with logic tree reasoning for reliable and interpretable multi-hop question answering. <em>KBS</em>, <em>330</em>, 114526. (<a href='https://doi.org/10.1016/j.knosys.2025.114526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Hop Question Answering (MHQA), crucial for complex information retrieval, remains challenging for current Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems, which often suffer from hallucination, reliance on incomplete knowledge, and opaque reasoning processes. Existing RAG methods, while beneficial, still struggle with the intricacies of multi-step inference and ensuring verifiable accuracy. This research introduces TreeQA, a novel framework designed to significantly enhance the reliability and interpretability of LLM-RAG systems in MHQA tasks. TreeQA addresses these limitations by decomposing complex multi-hop questions into a hierarchical logic tree of simpler, verifiable sub-questions, integrating evidence from both structured knowledge bases (e.g., Wikidata) and unstructured text (e.g., Wikipedia), and employing an iterative, evidence-based validation and self-correction mechanism at each reasoning step to dynamically rectify errors and prevent their accumulation. Extensive experiments on four benchmark datasets (WebQSP, QALD-en, AdvHotpotQA, and 2WikiMultiHopQA) demonstrate TreeQA’s superior performance, achieving Hit@1 scores of 87 %, 57 %, 53 %, and 59 %, respectively, representing improvements of 4 %-12 % over state-of-the-art LLM-RAG methods. These findings highlight the significant impact of structured, verifiable reasoning pathways in developing more robust, accurate, and interpretable knowledge-intensive AI systems, thereby enhancing the practical utility of LLMs in complex reasoning scenarios. Our code is publicly available at https://github.com/ACMISLab/TreeQA .},
  archive      = {J_KBS},
  author       = {Xiangrui Zhang and Fuyong Zhao and Yutian Liu and Panfeng Chen and Yanhao Wang and Xiaohua Wang and Dan Ma and Huarong Xu and Mei Chen and Hui Li},
  doi          = {10.1016/j.knosys.2025.114526},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114526},
  shortjournal = {Knowl. Based Syst.},
  title        = {TreeQA: Enhanced LLM-RAG with logic tree reasoning for reliable and interpretable multi-hop question answering},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-aligned knowledge self-distillation framework for visible-infrared cross-modal person re-identification. <em>KBS</em>, <em>330</em>, 114525. (<a href='https://doi.org/10.1016/j.knosys.2025.114525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible-infrared person re-identification (VI-ReID) significantly enhances identity retrieval across different illumination conditions by matching visible and infrared modalities. However, existing contrastive-learning-based approaches predominantly focus on cross-modal feature alignment, thus undermining model reliability in complex scenarios. To address this challenge, we introduce a Dual Alignment Knowledge Distillation (DAKD) framework that leverages comprehensive self-distillation at both instance and class levels. Our framework incorporates a temperature-modulated alignment strategy, capturing rich modality-invariant generalities as well as modality-specific discriminative details. Additionally, we propose a confidence-based selective masking mechanism that guides the distillation towards confident and informative teacher predictions. To further enhance robustness against modality discrepancies and intra-class variations, we develop a dedicated augmentation technique, CutSwap, which exchanges image channels to simulate realistic cross-modality variations. Extensive experiments on the benchmark SYSU-MM01 and RegDB datasets demonstrate superior performance compared to other state-of-the-art methods, achieving rank-1 accuracies of 76.31 % and 94.83 %, respectively and validating the efficacy of DAKD in maintaining robust cross-modal alignment while preserving essential identity-specific discriminative information.},
  archive      = {J_KBS},
  author       = {Siyuan Deng and Kunhao Yuan and Gerald Schaefer and Shihua Zhou and George Vogiatzis and Yifan Wang and Hui Fang},
  doi          = {10.1016/j.knosys.2025.114525},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114525},
  shortjournal = {Knowl. Based Syst.},
  title        = {A dual-aligned knowledge self-distillation framework for visible-infrared cross-modal person re-identification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSDiagnosis: A benchmark and framework for evaluating large language models in multi-step clinical diagnosis. <em>KBS</em>, <em>330</em>, 114524. (<a href='https://doi.org/10.1016/j.knosys.2025.114524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical diagnosis is critical in clinical decision-making, typically requiring a continuous and evolving process that includes primary, differential, and final diagnoses. However, most existing clinical diagnostic tasks are single-step processes, which do not align with the complex multi-step diagnostic procedures found in real clinical scenarios. In this paper, we propose MSDiagnosis, a Chinese multi-step clinical diagnostic benchmark consisting of 2225 cases from 12 departments, covering primary, differential, and final diagnosis tasks. Conventional approaches often rely on large language models (LLMs) to perform these tasks sequentially, which can lead to error propagation. To address this, we propose a two-stage diagnostic framework consisting of a forward inference module and a backward reasoning and refinement module. This framework is applied at each diagnostic stage to effectively mitigate error propagation across steps. The forward module retrieves similar cases to assist the LLM in generating an initial diagnosis. In the backward inference and refinement module, we first perform backward inference to infer the diagnostic criteria associated with the initially identified potential diseases. These criteria are then compared with the patient’s records to identify and eliminate possible misdiagnoses. Finally, the diagnostic conclusion is further refined and confirmed. Based on the MSDiagnosis, we evaluate medical LLMs (e.g., OpenBioLLM, PULSE, and Apollo2), general LLMs (e.g., DeepSeek-V3, OpenAI-O1, and GLM4), and our proposed framework. Experimental results show that our framework achieves state-of-the-art performance, demonstrating its effectiveness in multi-step diagnostic tasks. We also provide a detailed analysis and suggest future research directions for this task. Our code and data are publicly available at https://github.com/nlper-hou/MSDiagnosis .},
  archive      = {J_KBS},
  author       = {Ruihui Hou and Shencheng Chen and Yongqi Fan and Guangya Yu and Lifeng Zhu and Jing Sun and Jingping Liu and Tong Ruan},
  doi          = {10.1016/j.knosys.2025.114524},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114524},
  shortjournal = {Knowl. Based Syst.},
  title        = {MSDiagnosis: A benchmark and framework for evaluating large language models in multi-step clinical diagnosis},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Safe and effective post-fine-tuning alignment in large language models. <em>KBS</em>, <em>330</em>, 114523. (<a href='https://doi.org/10.1016/j.knosys.2025.114523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-tuning is critical to customizing Large Language Models (LLMs) in various applications, but it inevitably disrupts the safety alignment of the models. Current alignment methods tackle harmful fine-tuning challenges but frequently compromise model usefulness, resulting in unsatisfactory downstream task performance. To address this issue, we propose a S afe and E ffective post-fine-tuning A lignment ( SEA ) from a knowledge disentanglement perspective. SEA introduces a novel two-level pruning process that surgically removes harmful functionalities. We first propose a differential importance score to isolate harmful pathways at the parameter level, and then introduce a module-wise analysis to protect entangled modules, thereby robustly balancing safety and utility. Experimental results on Llama2, Gemma and Mistral demonstrate that SEA effectively mitigates safety risks while maintaining optimal fine-tuning accuracy. This work provides a practical solution to the safety-performance dilemma associated with harmful fine-tuning of LLMs.},
  archive      = {J_KBS},
  author       = {Minrui Jiang and Yuning Yang and Xiurui Xie and Pei Ke and Guisong Liu},
  doi          = {10.1016/j.knosys.2025.114523},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114523},
  shortjournal = {Knowl. Based Syst.},
  title        = {Safe and effective post-fine-tuning alignment in large language models},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward customized model discrepancies in personalized federated learning on non-IID data. <em>KBS</em>, <em>330</em>, 114522. (<a href='https://doi.org/10.1016/j.knosys.2025.114522'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a traditional framework comprising a central server and multiple local clients. In FL, a shared global model is trained for resource-constrained computing devices while preserving data privacy. However, in certain practical applications, the shared global model may exhibit poor inference performance in local clients owing to nonindependent and nonidentically distributed (non-IID) characteristics of data. To address this issue, researchers have proposed personalized FL (PFL), which involves learning a customized model for each client to mitigate the impact of weight divergences when the training datasets are non-IID. Unfortunately, existing studies fail to reveal the inherent connection between model discrepancies and non-IID data. Herein, we focus on demonstrating the relationship between weight divergences among customized models and non-IID data, and we provide a proposition to reveal the root cause of such divergences. Additionally, based on our theoretical analysis, we introduce two novel personalized FL methods, namely, PFL with neighbor clients (PFedNC) and PFL with neighbor layers (PFedNL), to address the issue of non-IID data scenarios. Theoretical convergence analysis and extensive experiments indicate that our proposed methods outperform state-of-the-art personalized algorithms in non-IID scenarios. Specifically, PFedNC achieves up to 4 % improvement in customized model accuracy, while PFedNL yields 8 %–10 % gains over multiple baselines.},
  archive      = {J_KBS},
  author       = {Fengrui Hao and Taihang Zhi and Tianlong Gu and Xuguang Bao},
  doi          = {10.1016/j.knosys.2025.114522},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114522},
  shortjournal = {Knowl. Based Syst.},
  title        = {Toward customized model discrepancies in personalized federated learning on non-IID data},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Node importance estimation leveraging LLMs for semantic augmentation in knowledge graphs. <em>KBS</em>, <em>330</em>, 114521. (<a href='https://doi.org/10.1016/j.knosys.2025.114521'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Node Importance Estimation (NIE) is a task that quantifies the importance of nodes in a graph. Recent research has investigated to exploit various information from Knowledge Graphs (KGs) to estimate node importance scores. However, the semantic information in KGs could be insufficient, missing, and inaccurate, which would limit the performance of existing NIE models. To address these issues, we leverage Large Language Models (LLMs) for semantic augmentation thanks to the LLMs’ extra knowledge and ability of integrating knowledge from both LLMs and KGs. To this end, we propose the LLMs Empowered Node Importance Estimation (LENIE) method to enhance the semantic information in KGs for better supporting NIE tasks. To our best knowledge, this is the first work incorporating LLMs into NIE. Specifically, LENIE employs a novel clustering-based triplet sampling strategy to extract diverse knowledge of a node sampled from the given KG. After that, LENIE adopts the node-specific adaptive prompts to integrate the sampled triplets and the original node descriptions, which are then fed into LLMs for generating richer and more precise augmented node descriptions. These augmented descriptions finally initialize node embeddings for boosting the downstream NIE model performance. Extensive experiments demonstrate LENIE’s effectiveness in addressing semantic deficiencies in KGs, enabling more informative semantic augmentation and enhancing existing NIE models to achieve the state-of-the-art performance. The source code of LENIE is freely available at https://github.com/XinyuLin-FZ/LENIE .},
  archive      = {J_KBS},
  author       = {Xinyu Lin and Tianyu Zhang and Chengbin Hou and Jinbao Wang and Jianye Xue and Hairong Lv},
  doi          = {10.1016/j.knosys.2025.114521},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114521},
  shortjournal = {Knowl. Based Syst.},
  title        = {Node importance estimation leveraging LLMs for semantic augmentation in knowledge graphs},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models enhanced graph neural architecture search for quadratic unconstrained binary optimization. <em>KBS</em>, <em>330</em>, 114520. (<a href='https://doi.org/10.1016/j.knosys.2025.114520'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quadratic unconstrained binary optimization (QUBO) refers to a subclass of unconstrained combinatorial optimization problems where the objective is to optimize a quadratic polynomial function over a set of binary variables without any explicit constraint. Recently, graph neural networks (GNNs) have been applied to solve QUBO problems by describing a QUBO problem as a graph and then learning the representation of the graph using GNNs. However, the performance of these GNNs is often unsatisfactory due to improper manual settings of the parameters of graph neural architectures. In this paper, we propose a new graph neural architecture search model (GNAS) to solve the QUBO problems ( GNAS4QUBO for short). The idea is to develop a graph neural architecture search (GNAS) model based on reinforcement learning to find the best GNNs to learn the representation of the QUBO graph. Moreover, we improve the GNAS model with large language models (LLMs) by designing a new set of GNAS4QUBO prompts to generate the best GNNs under QUBO evaluation feedback and fine-tuning the LLM using LoRA based on new graph neural architectures. The experimental evaluation indicates that the proposed method outperforms existing GNN-based models on multiple QUBO benchmark problems. In particular, the results reveal substantial improvement with respect to cut-size metric and the accuracy score in benchmark tasks, such as maximum cut, set covering, combinatorial auction , and maximum independent set . The codes are available online at https://github.com/Embrasse-moi1/GNAS4QUBO .},
  archive      = {J_KBS},
  author       = {Peng Zhang and Junxian Wu and Hong Yang and Chuan Zhou and Zhihong Tian},
  doi          = {10.1016/j.knosys.2025.114520},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114520},
  shortjournal = {Knowl. Based Syst.},
  title        = {Large language models enhanced graph neural architecture search for quadratic unconstrained binary optimization},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards robust infrared small target detection: A feature-enhanced and sensitivity-tunable framework. <em>KBS</em>, <em>330</em>, 114519. (<a href='https://doi.org/10.1016/j.knosys.2025.114519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, single-frame infrared small target (SIRST) detection technology has attracted widespread attention. Different from most existing deep learning-based methods that focus on improving network architectures, we propose a feature-enhanced and sensitivity-tunable (FEST) framework, which is compatible with existing SIRST detection networks and further enhances their detection performance. The FEST framework improves the model’s robustness from two aspects: feature enhancement and target confidence regulation. For feature enhancement, we employ a multi-scale fusion strategy to improve the model’s perception to multi-scale features of multi-size targets, and design an edge enhancement difficulty mining (EEDM) loss to guide the network to continuously focus on challenging target regions and edge features during training. For target confidence regulation, an adjustable sensitivity (AS) strategy is proposed for network post-processing. This strategy enhances the model’s adaptability in complex scenarios and significantly improves the detection rate of infrared small targets while maintaining segmentation accuracy. Extensive experimental results show that our FEST framework can effectively enhance the performance of existing SIRST detection networks. The code is available at https://github.com/YuChuang1205/FEST-Framework .},
  archive      = {J_KBS},
  author       = {Jinmiao Zhao and Zelin Shi and Chuang Yu and Yunpeng Liu and Yimain Dai},
  doi          = {10.1016/j.knosys.2025.114519},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114519},
  shortjournal = {Knowl. Based Syst.},
  title        = {Towards robust infrared small target detection: A feature-enhanced and sensitivity-tunable framework},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Secure distributor data storage and retrieval of unstructured data in blockchain enabled edge computing. <em>KBS</em>, <em>330</em>, 114518. (<a href='https://doi.org/10.1016/j.knosys.2025.114518'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern IoT applications, managing large volumes of unstructured data securely and efficiently is a growing challenge, especially within blockchain-enabled edge computing environments. Traditional data storage and retrieval methods often fall short in terms of error detection, indexing efficiency, and secure data handling. To address these limitations, this research proposes a secure and intelligent distributor framework for the storage and retrieval of unstructured data using a blockchain-supported edge computing model. The system architecture is composed of three layers, such as the IoT network layer for data collection, the blockchain-based edge computing layer for secure data handling, and the cloud layer for scalable storage. The proposed framework introduces a novel indexing mechanism, the Optimal Cluster Inverted Index (OCII), which is computed using a newly designed Taylor Fire Hawk Optimizer (Taylor FHO), which is the hybridization of the Taylor series and Fire Hawk Optimizer (FHO). The data handling framework involves five key processes, like KeyGeneration, OCII Generation, AuthGen, Check, and Dynamics, ensuring secure indexing, authentication, and data validation. Experimental evaluation demonstrates that the Taylor FHO achieves a better precision of 86.067%, recall of 87.080%, F-measure of 87.748%, and indexing time of 0.401 sec. This research provides a scalable and secure solution for real-time unstructured data processing in IoT systems.},
  archive      = {J_KBS},
  author       = {S. Premkumar and S. Sivakumar and TS. Arthi and N. Partheeban},
  doi          = {10.1016/j.knosys.2025.114518},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114518},
  shortjournal = {Knowl. Based Syst.},
  title        = {Secure distributor data storage and retrieval of unstructured data in blockchain enabled edge computing},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploitability prediction of vulnerabilities based on heterogeneous graphs. <em>KBS</em>, <em>330</em>, 114517. (<a href='https://doi.org/10.1016/j.knosys.2025.114517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vulnerability exploitability prediction is the process predicting the likelihood of being exploited in real attacks by the assessment of known software vulnerabilities. Many methods have been proposed to solve the problem of exploitability prediction. However, they generally suffer from two problems. First, they only extract features from a single vulnerability, ignoring the impact of associated vulnerabilities. Second, they usually adopt simple methods (such as concatenation) to aggregate different information, which may overlook important relationships between features. In this paper, we propose a novel exploitability prediction method based on heterogeneous graphs, called ExPreHet. First, ExPreHet defines nodes and edges to construct a heterogeneous graph. Following a series of preprocessing steps, ExPreHet generates multiple attribute vectors for each node. By implementing a restart random walk strategy, ExPreHet ensures that each node can sample all categories of neighboring nodes and group them by node category. Then, ExPreHet aggregates all the attributes of each node to generate the content vector, and each category of neighboring nodes of this node to generate a category vector. After that, the content vector and all the category vectors are aggregated to generate the final representation of the node. Finally, these final representations are input into random forest (RF) for training the classifier. To effectively assess ExPreHet, this paper conducts experiments on a dataset, which contains 66,877 vulnerabilities. The experimental results show that ExPreHet achieves 83.24 %, 83.22 %, 83.28 %, 83.25 %, and 83.24 % in terms of accuracy, precision, recall, F1-score, and area under curve (AUC), respectively. ExPreHet performs significantly better than the baseline methods.},
  archive      = {J_KBS},
  author       = {Guo Xu and Xin Chen and Xinxin Cai and Dongjin Yu},
  doi          = {10.1016/j.knosys.2025.114517},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114517},
  shortjournal = {Knowl. Based Syst.},
  title        = {Exploitability prediction of vulnerabilities based on heterogeneous graphs},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel deep cognitive network for battlefield situation awareness in wargaming. <em>KBS</em>, <em>330</em>, 114516. (<a href='https://doi.org/10.1016/j.knosys.2025.114516'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an innovative approach to supporting wargaming, computer-based wargames have been well received by military researchers. The battlefield situation in wargames is complex and rapidly evolving, and analysing a single scenario is insufficient to capture the full scope of the battlefield. To address the challenge of identifying trends in situational changes, this study proposes a value network model for battlefield situational awareness in wargaming based on deep learning techniques. Focusing on the Army Tactical Wargame as the research object, this study analyses key elements of battlefield situations using feature engineering methods. It introduces a hierarchical, grid-based model for representing battlefield situation features within wargames and develops a value tagging system that integrates system scores with distance-based rewards. A convolutional neural network-based value network model for situational awareness is then constructed, and the influence of key battlefield characteristics on the model is examined. Experimental results demonstrate that the proposed value network can more accurately predict the situation value at each stage of the wargame. The prediction accuracy exhibits a hump-shaped trend from the beginning to the end of the simulation. During the attack phase, the prediction accuracy exceeds 70 %, reaching a peak of 72.98 %. These findings offer a reliable new method for supporting agents in situation recognition and intelligent decision-making.},
  archive      = {J_KBS},
  author       = {Chenhui Pan and Yong Xian and Peiyang Ma and Leliang Ren and Wancheng Ni},
  doi          = {10.1016/j.knosys.2025.114516},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114516},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel deep cognitive network for battlefield situation awareness in wargaming},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight completion with high-order semantic attributes for heterogeneous sparse attribute graph learning. <em>KBS</em>, <em>330</em>, 114515. (<a href='https://doi.org/10.1016/j.knosys.2025.114515'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous graph neural networks (HGNNs) have been widely applied in real-world scenarios. Due to various uncontrollable factors, many heterogeneous graphs suffer from attribute sparsity, which can be effectively addressed by HGNNs with attribute completion (HGNNs-AC). However, current HGNNs-AC still encounter significant challenges. (i) In the completion module, the lack of dynamic learning of higher-order semantic importance causes the completion effect to fall short. (ii) Lack of collaborative interaction and effective aggregation among completed attributes hinders the overall completion performance. (iii) Low efficiency is caused by another heterogeneous graph neural network retraining after attribute completion, which is particularly obvious on large-scale datasets. To address these challenges, we propose Lightweight Completion with High-order Semantic Attributes (LC-HSA) for heterogeneous sparse attribute graph learning, which dynamically learns two weights of multiple meta-path subgraphs to complete sparse attributes. The proposed model includes four modules: (i) A module for constructing meta-path subgraphs captures higher-order meta-path subgraphs’ semantic information. (ii) A lightweight completion module leverages an innovative lightweight graph attribute completion network to dynamically learn two weights of multiple meta-path subgraphs, achieving sparse attribute completion. (iii) We introduce an interaction aggregation module that facilitates collaborative interaction and effective aggregation among the completed attributes. (iv) The lightweight classification module increases the model’s overall efficiency. Extensive experiments on three benchmarks demonstrate that LC-HSA outperforms the state-of-the-art HGNNs-AC models on the node classification task. Our code is available at: https://github.com/HeteroMind/LC-HSA1 .},
  archive      = {J_KBS},
  author       = {Yuanjun Yang and Weihua Ou and Yunshun Wu and Jiamin Chen and Hao Tian and Jianping Gou and Zhonghua Liu and Bineng Zhong},
  doi          = {10.1016/j.knosys.2025.114515},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114515},
  shortjournal = {Knowl. Based Syst.},
  title        = {Lightweight completion with high-order semantic attributes for heterogeneous sparse attribute graph learning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy-efficient adaptive perception for autonomous driving via lightweight policy learning and simulation-based optimization. <em>KBS</em>, <em>330</em>, 114514. (<a href='https://doi.org/10.1016/j.knosys.2025.114514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern autonomous driving systems rely heavily on deep learning-based perception models for object detection; yet, their computational and energy demands remain critical bottlenecks. The existing adaptive-perception strategies often lack the ability to dynamically balance the detection accuracy and energy consumption, in real-time, particularly under varying environmental conditions. To address this challenge, we first construct a large-scale autonomous driving dataset based on the CARLA simulator. Then, we propose a novel metric—the balanced efficiency index—to annotate each image with the most suitable you-only-look-once version 8 (YOLOv8) model size (i.e., n, s, m, l, or x). This index is governed by two critical parameters, which are efficiently optimized using our proposed constrained stochastic DIviding RECTangles (DIRECT) algorithm. Finally, we propose a lightweight dynamic mixed receptive field transformer (DynaMixFormer), which is trained using the labelled dataset, to select the appropriate YOLOv8 model adaptively. Our results show that: (1) the constrained stochastic DIRECT algorithm determines cost-effective parameters with very limited simulation overhead; (2) DynaMixFormer achieves a high classification accuracy of 96.56 % with only 0.017 M parameters, outperforming the state-of-the-art image-classification networks; and (3) the well-trained DynaMixFormer effectively extracts real-time contextual features, such as traffic density, weather conditions, and road complexity, to intelligently select the optimal model from various YOLOv8 variants. Extensive simulations demonstrate that our approach achieves up to 70.20 % reduction in the energy consumption, compared to the static deployment of the YOLOv8x model, with only a marginal decrease of approximately 2 % in the mean average precision. Taking China as an example, this translates to an estimated energy saving of 2.73 × 10 14 W. This work not only advances energy-efficient autonomous perception but also provides a generalizable framework for adaptive model selection in resource-constrained edge-computing systems. For ease of comprehension, some key nomenclature used in this paper are summarized in Table 1.},
  archive      = {J_KBS},
  author       = {Yanzhan Chen and Fan Yu and Qian Zhang and Mahardhika Pratama},
  doi          = {10.1016/j.knosys.2025.114514},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114514},
  shortjournal = {Knowl. Based Syst.},
  title        = {Energy-efficient adaptive perception for autonomous driving via lightweight policy learning and simulation-based optimization},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pseudo-kNN-MT: Enhancing domain adaptability of neural machine translation via target language data. <em>KBS</em>, <em>330</em>, 114513. (<a href='https://doi.org/10.1016/j.knosys.2025.114513'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although Neural Machine Translation (NMT) has recently achieved remarkable performance improvements, it still faces challenges in domain adaptation. Previous research has focused on mitigating this issue by integrating translation knowledge from bilingual domain data. However, the limited availability of bilingual translation resources has constrained these methods in real world application. To address this inadequacy, solutions based on monolingual data, such as back-translation, have been proposed. Nevertheless, these methods often incur additional training costs due to the necessity of training reverse models to generate pseudo data. In light of this, we propose Pseudo- k NN-MT, which does not require additional training. This method creates pseudo-bilingual data pairs by retrieving semantically similar sentences from target language data and subsequently builds the k NN datastore. To effectively reduce the noise introduced by the pseudo-data, we incorporate cross-lingual retrieval distances into the k NN probability construction process. Experiments in both high-resource and low-resource machine translation scenarios across multiple domains demonstrate that our method significantly improves the domain adaptation capabilities of NMT in both settings, yielding average improvements of 6.08 and 7.70 SacreBLEU points and 0.66 and 1.62 COMET scores on the multi-domain dataset, respectively.},
  archive      = {J_KBS},
  author       = {Abudurexiti Reheman and Yingfeng Luo and Junhao Ruan and Hongyu Liu and Tong Xiao and Jingbo Zhu},
  doi          = {10.1016/j.knosys.2025.114513},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114513},
  shortjournal = {Knowl. Based Syst.},
  title        = {Pseudo-kNN-MT: Enhancing domain adaptability of neural machine translation via target language data},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing the performance of power distribution systems through integrated network reconfiguration and distributed generation design. <em>KBS</em>, <em>330</em>, 114512. (<a href='https://doi.org/10.1016/j.knosys.2025.114512'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconfiguration of networks and distributed generation (DG) together leads to better performance of a network. To ensure system enactment, it is therefore necessary to determine appropriate size and placement of DG. However, there is a huge solution search space for sizing and situating of demand generation with Network Reconfiguration (NR), which makes it a complicated problem. Throughout the optimization process, removing these non-radial choices adds computational burden and lead to a local optimal solution. To reduce complexity of searching, Modified Chaotic Particle Swarm Optimization (MCPSO) algorithm is adopted to obtain a near optimal solution of designing, sizing, and placing the network with improved voltage profiles and minimized power loss. It introduces a combination of chaotic inertia adaptation, uniform initialization and a stochastic personal learning strategy contributing to improved search diversity and convergence stability. For the purpose of demonstrating efficacy of a simultaneous approach taking changeable power factor, the proposed approach is assessed using IEEE-33 and 69 bus using MATLAB. The findings demonstrate that discretizing reconfiguration search space implemented by encoding the network configuration as a discrete set of switching states prevents MCPSO from getting trapped in local optimums. On contrasting with conventional Particle Swarm Optimization (PSO), the proposed MCPSO algorithm results in active and reactive power loss reduction of 27.78 % and 76.36 % respectively for 33 bus system and 6.67 % and 25.5 % respectively for 69 bus system. The outcomes reveal that suggested algorithm provides optimal solution contrasted to state of art approaches.},
  archive      = {J_KBS},
  author       = {K. Dharani Sree and P. Karpagavalli},
  doi          = {10.1016/j.knosys.2025.114512},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114512},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing the performance of power distribution systems through integrated network reconfiguration and distributed generation design},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion models with self-conditioning guidance for multivariate time series anomaly detection. <em>KBS</em>, <em>330</em>, 114511. (<a href='https://doi.org/10.1016/j.knosys.2025.114511'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting anomalies in multivariate time series data collected from industrial systems is crucial for intelligent operations and maintenance. Most existing methods leverage deep neural networks to learn normal patterns for reconstructing input data, where anomalies exhibit higher reconstruction errors. However, due to the overly powerful feature extraction and generation capabilities of these models for time series, they tend to reconstruct anomalies well, leading to high false negative rates. To address this problem, we propose a novel time series Diffusion model with Self-Conditioning guidance for Anomaly Detection (DSCAD), which utilizes self-conditional control to effectively suppress the reconstruction of anomalies without affecting the original input. We introduce a self-conditioning guidance strategy that extracts coarse-grained features from intermediate results during the diffusion process as target vectors to guide the reconstruction toward generating expected normal data. Moreover, to capture long-term trends and periodic patterns in time series, we employ a Transformer as the denoising module during the reverse process. Furthermore, we introduce a novel detection criterion based on the target vectors to amplify normal-abnormal distinguishability of anomaly scores, thereby improving the detection performance. Extensive experiments conducted on five publicly available datasets demonstrate that DSCAD achieves an average F1 score of 95.23 %, outperforming other state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Yushi Li and Zhenyu Wen and Ziwen Chen and Jie Mei and Mengxue Lin and Ming Zhu},
  doi          = {10.1016/j.knosys.2025.114511},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114511},
  shortjournal = {Knowl. Based Syst.},
  title        = {Diffusion models with self-conditioning guidance for multivariate time series anomaly detection},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust multi-view discrete clustering with unified graph learning. <em>KBS</em>, <em>330</em>, 114510. (<a href='https://doi.org/10.1016/j.knosys.2025.114510'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based multi-view clustering (GMVC) has garnered significant attention due to its ability to overcome sample space shape constraints. However, existing GMVC methods encounter two major challenges: (1) Their effectiveness diminishes because they solely rely on sample-constructed graphs and the two-stage mismatch caused by additional discretization; (2) Their robustness deteriorates substantially when applied to real-world datasets that contain complex noise. To address these limitations, we propose a robust multi-view discrete clustering model with unified graph learning (RCUGL). This model integrates richer graph structural information and accommodates complex noise clustering tasks. Specifically, we incorporated low-rank approximation graphs reconstructed from spectral embeddings and graphs constructed by samples into a unified graph to provide enriched structural insights. Subsequently, within the framework of the correntropy, discrete spectral analysis was performed directly on the unified graph to derive cluster assignments. Given the non-convex and discrete nature of the proposed RCUGL model, we developed a half-quadratic-based coordinate descent optimisation algorithm to ensure rapid and reliable convergence. Extensive experiments demonstrate that RCUGL substantially improves clustering effectiveness, comparable to state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Jiaqi Nie and Rankun Chen and Jingxiang Huang and Ben Yang and Xuetao Zhang},
  doi          = {10.1016/j.knosys.2025.114510},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114510},
  shortjournal = {Knowl. Based Syst.},
  title        = {Robust multi-view discrete clustering with unified graph learning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PDbDa: Prompt-tuned dual-branch framework for unsupervised domain adaptation. <em>KBS</em>, <em>330</em>, 114509. (<a href='https://doi.org/10.1016/j.knosys.2025.114509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale vision-language models demonstrate excellent performance on downstream tasks. However, they face challenges in unsupervised domain adaptation, particularly when domain shifts and semantic loss occur. Although existing prompt learning methods can decouple task-specific semantics from general knowledge, they face two main issues: (i) ineffective coordination between task-specific and general knowledge, leading to poor class discriminability, and (ii) inability to adequately address the domain shift. To address these challenges, we propose PDbDa, a prompt-tuned dual-branch framework for unsupervised domain adaptation that jointly optimizes learnable prompt vectors. PDbDa introduces two key innovations: (i) a foundation branch with a prompt knowledge constraint to regularize task-specific and pretrained knowledge, addressing class discriminability, and (ii) an adaptation branch with a domain-aware feature tuning block to align source and target domain features, mitigating the domain shift. These two branches function synergistically, improving model accuracy and training efficiency. The experimental results on the Office-Home, VisDA-2017, and DomainNet datasets indicate that PDbDa outperforms conventional prompt tuning and UDA methods by an average of 2.2 %-3 %.},
  archive      = {J_KBS},
  author       = {Qian Zhang and Yurui Zhao and Mingwen Shao and Hong Liang},
  doi          = {10.1016/j.knosys.2025.114509},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114509},
  shortjournal = {Knowl. Based Syst.},
  title        = {PDbDa: Prompt-tuned dual-branch framework for unsupervised domain adaptation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypergraph-based CLIP hashing for unsupervised cross-modal retrieval. <em>KBS</em>, <em>330</em>, 114508. (<a href='https://doi.org/10.1016/j.knosys.2025.114508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the surge of multi-modal data, how to effectively and efficiently find similar information has become an urgent and important need. Among the existing solutions, unsupervised cross-modal hashing can learn from unlabeled data and provide fast and satisfactory retrieval performance, making it a viable solution. However, existing unsupervised cross-modal hashing methods often inadequately model intricate cross-modal semantic relationships. To bridge this gap, this paper proposes a novel Hypergraph-based CLIP Hashing (HCH). Specifically, HCH utilizes the large-scale visual-language pre-trained model CLIP to extract visual and textual features, and employs a cross-modal Transformer to further enhance semantic fusion among these features. Then, to fully capture the semantic relevance among multi-modal data, we construct a semantic-enhanced similarity matrix and design a mean-based weighting scheme to adjust this matrix. Additionally, we compose a hypergraph convolutional network to further explore high-order semantic information within the input data, leading to more compact and high-quality hash codes. To substantiate HCH’s efficacy, we conducted experiments on three commonly used datasets, confirming its superiority over leading baselines.},
  archive      = {J_KBS},
  author       = {Qian Zhang and Jia-Rui Zhao and Xiao-Qian Liu and Yu-Wei Zhan and Zhen-Duo Chen and Xin Luo and Xin-Shun Xu},
  doi          = {10.1016/j.knosys.2025.114508},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114508},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hypergraph-based CLIP hashing for unsupervised cross-modal retrieval},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven interpretation of dimensions in an embedding language model based on a reference knowledge graph. <em>KBS</em>, <em>330</em>, 114507. (<a href='https://doi.org/10.1016/j.knosys.2025.114507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As language models are used in more applications, a key problem has become clear: their numerical embeddings are hard to interpret because it is unclear how each part of the vector relates to real-world meanings in specific fields. The prevailing embedding methods are inadequate in their current state, as they are unable to effectively bridge the gap between mathematical representations and human-understandable knowledge structures. The present study proposes a novel framework that explicitly links ontology classes to specific embedding dimensions through a dual-component architecture combining a text encoder that produces the target embedding dimensions with domain knowledge graphs. The Area Under the Interpretability Curve (AUIC) metric is introduced as a means to systematically evaluate model-alignment with ontological concepts. The analysis reveals that targeted dimensional mapping enables direct interpretation of individual vector components through ontological terms. The practical applications of this framework are illustrated through case studies in biomedical contexts, demonstrating enhanced model transparency without compromising performance. This approach establishes a measurable pathway for reconciling statistical language representations with structured domain knowledge, particularly benefiting fields requiring precise concept alignment like biomedicine. The implementation is publicly available at: https://github.com/Mellandd/DEIBO .},
  archive      = {J_KBS},
  author       = {Jose L. Mellina-Andreu and Alejandro Cisterna-García and Juan A. Botía},
  doi          = {10.1016/j.knosys.2025.114507},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114507},
  shortjournal = {Knowl. Based Syst.},
  title        = {Data-driven interpretation of dimensions in an embedding language model based on a reference knowledge graph},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient network intrusion detection model based on beta mixture models. <em>KBS</em>, <em>330</em>, 114506. (<a href='https://doi.org/10.1016/j.knosys.2025.114506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of computer networks and network applications, ensuring network security has become a critical concern and has garnered significant attention from both academia and industry. Network intrusion detection (NID) plays a pivotal role in safeguarding cybersecurity and maintaining system stability. Most existing NID approaches rely on traditional machine learning (ML) or deep learning (DL) techniques to identify threats and potential attacks based on network traffic data. However, these methods often suffer from high computational complexity and large model sizes, which significantly impede their deployment in resource-constrained environments such as the Internet of Things (IoT), edge computing infrastructures, and wireless sensor networks. In this study, we propose an efficient NID framework based on the Beta Mixture Model (BMM) classifier. The proposed method integrates the BMM with the recently introduced Extended Stochastic Variational Inference (ESVI) framework to effectively characterize both normal and intrusive behavior patterns. The ESVI framework enables simultaneous parameter estimation and model complexity control in a principled and computationally efficient manner. Experimental evaluations show that, compared to NID methods utilizing established finite mixture models, traditional ML, or state-of-the-art DL techniques, our approach substantially reduces computational overhead while achieving comparable detection performance.},
  archive      = {J_KBS},
  author       = {Yuping Lai and Zidong Wang and Ziqing Lin and Yuhan Cao and Zihao Li and Qing Ye},
  doi          = {10.1016/j.knosys.2025.114506},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114506},
  shortjournal = {Knowl. Based Syst.},
  title        = {An efficient network intrusion detection model based on beta mixture models},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchy-induced dual-channel tokenized graph learning. <em>KBS</em>, <em>330</em>, 114505. (<a href='https://doi.org/10.1016/j.knosys.2025.114505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have shown impressive performance in graph representation learning, but they struggle with capturing long-range dependencies and suffer from limited expressive power. While sequence models offer promising potential for global context modeling and high-order interaction learning in graph domains, their direct application faces critical challenges: structural semantics are inevitably distorted when permutation-invariant graph topologies are forcibly linearized into ordered sequences. In this paper, we introduce the H ierarchy- I nduced Dual-Channel T okenized G raph O perator (HITGO), a novel token-based graph learning framework that explicitly integrates structural semantics into expressive multi-granular token sequences, which are then efficiently modeled through a hybrid backbone. Specifically, HITGO employs recursive graph coarsening to construct a multi-level graph hierarchy, and leverages Hierarchy2Token to generate complementary token sequences for each node that capture nuanced structural details and long-range dependencies from both local neighborhoods and global contexts. Building upon these sequences, HITGO implements a Transformer-Mamba Dual-Channel Architecture: the Transformer channel handles shorter, coarse-grained sequences for structural abstraction, while the Mamba channel efficiently processes longer, fine-grained sequences using state-space modeling for effective long-range capture. This granularity-aware allocation strategically matches architectural strengths to token properties, enabling near-linear complexity while preserving permutation-equivariance. Experiments demonstrate HITGO’s superiority over state-of-the-art GNNs and Graph Transformers (GTs) on real-world datasets, validating its effectiveness in capturing complex graph structures while scaling efficiently.},
  archive      = {J_KBS},
  author       = {Huiwen Bai and Lizhong Ding and Guoren Wang and Ye Yuan and Junyu Zhang and Yuwan Yang and Lianpeng Qiao},
  doi          = {10.1016/j.knosys.2025.114505},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114505},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hierarchy-induced dual-channel tokenized graph learning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monotonic learning in the PAC framework: A new perspective. <em>KBS</em>, <em>330</em>, 114504. (<a href='https://doi.org/10.1016/j.knosys.2025.114504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monotone learning describes learning processes in which expected error consistently decreases as the amount of training data increases. However, recent studies challenge this conventional wisdom, revealing significant gaps in the understanding of generalization in machine learning. Addressing these gaps is crucial for advancing the theoretical foundations of the field. In this work, we utilize Probably Approximately Correct (PAC) learning theory to construct a theoretical error distribution that approximates a learning algorithm’s actual performance. We rigorously prove that this theoretical distribution exhibits monotonicity as sample sizes increase. We identify two scenarios under which deterministic algorithms based on Empirical Risk Minimization (ERM) are monotone: (1) the hypothesis space is finite, or (2) the hypothesis space has finite VC-dimension. Experiments on three classical learning problems validate our findings by demonstrating that the monotonicity of the algorithms’ generalization error is guaranteed, as its theoretical error upper bound monotonically converges to the minimum generalization error.},
  archive      = {J_KBS},
  author       = {Ming Li and Chenyi Zhang and Qin Li},
  doi          = {10.1016/j.knosys.2025.114504},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114504},
  shortjournal = {Knowl. Based Syst.},
  title        = {Monotonic learning in the PAC framework: A new perspective},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Truncated MobileNetV2 sparse vision graph attention model for explainable monkeypox disease classification. <em>KBS</em>, <em>330</em>, 114503. (<a href='https://doi.org/10.1016/j.knosys.2025.114503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current outbreak of monkeypox (mpox) presents challenges for timely and accurate diagnosis due to the disease’s diverse and unusual skin lesion patterns. Traditional deep learning models, such as Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs), struggle with these irregular features because they rely on rigid, grid-based methods. To address this, we introduce the Truncated MobileNetV2 Sparse Vision Graph Attention (TMSVGA) model. TMSVGA combines components of MobileNetV2, which focuses on identifying smaller details, with a Sparse Vision Graph Attention block enhanced by a Squeeze-and-Excitation (SE) mechanism to improve channel-wise attention. This approach enhances the understanding of complex and long-distance relationships, emphasizing diagnostically significant regions and improving classification precision. We optimized TMSVGA using the Optuna framework for automated hyperparameter tuning. Additionally, Gradient-weighted Class Activation Mapping (Grad-CAM) and Local Interpretable Model-Agnostic Explanations (LIME) provided interpretable visualizations, highlighting influential regions in decision-making. The TMSVGA model was validated on the Monkeypox Skin Images Dataset (MSID), achieving 96.79 % accuracy, 96.90 % precision, 95.34 % recall, 96.08 % F1-score, and 95.37% Matthews Correlation Coefficient (MCC). These results demonstrate that TMSVGA outperforms existing models, particularly in handling irregular lesion patterns. By achieving high diagnostic accuracy and precision, our study showcases the potential of Vision Graph Neural Networks (ViGNNs) in advancing medical image analysis for diseases with non-uniform spatial patterns. Furthermore, the lightweight architecture of TMSVGA ensures suitability for mobile and resource-constrained diagnostic applications.},
  archive      = {J_KBS},
  author       = {Mehdhar S.A.M. Al-Gaashani and Abduljabbar S. Ba Mahel and Ammar Muthanna},
  doi          = {10.1016/j.knosys.2025.114503},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114503},
  shortjournal = {Knowl. Based Syst.},
  title        = {Truncated MobileNetV2 sparse vision graph attention model for explainable monkeypox disease classification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-granularity facial aesthetic evaluation model based on image-text modality. <em>KBS</em>, <em>330</em>, 114502. (<a href='https://doi.org/10.1016/j.knosys.2025.114502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial Beauty Prediction (FBP) is an emerging research direction at the intersection of artificial intelligence and aesthetics, which has attracted increasing attention in recent years. However, most existing methods rely solely on unimodal data and fail to comprehensively capture the multi-dimensional information of facial aesthetics. To address this challenge, we propose a multigranularity facial aesthetic evaluation model based on image-text modality (ITM-MGFA). By incorporating multi-granularity cognitive theory into the FBP task, the model effectively integrates both coarse-grained and fine-grained aesthetic features extracted from the CLIP encoder through a multigranularity representation module, a task-oriented dynamic alignment module, and a hierarchical interaction optimization module. This facilitates deep cross-modal interaction and fusion, significantly enhancing the model’s capability to model complex aesthetic attributes. Experimental results demonstrate that ITM-MGFA, leveraging the fusion of cross-modal information, achieves higher accuracy in facial aesthetic assessment task compared to traditional unimodal methods, offering a new direction for FBP research. Furthermore, the model can be applied in various scenarios, such as: simulation postoperative assessment of personalized cosmetic surgery in the medical aesthetics; selection of optimal facial aesthetic enhancement solutions on social media; and recommendation of matching solutions in cosmetic recommendation.},
  archive      = {J_KBS},
  author       = {Huanyu Chen and Yong Wang and Weisheng Li and Bin Xiao},
  doi          = {10.1016/j.knosys.2025.114502},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114502},
  shortjournal = {Knowl. Based Syst.},
  title        = {A multi-granularity facial aesthetic evaluation model based on image-text modality},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A domain generalized UAV tracking framework via frequency-aware learning and target-aligned data augmentation in complex environments. <em>KBS</em>, <em>330</em>, 114501. (<a href='https://doi.org/10.1016/j.knosys.2025.114501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) tracking plays a critical role in airborne autonomous systems, supporting applications such as disaster response, agricultural monitoring, and military surveillance. However, existing tracking methods often exhibit poor generalization in real-world deployments due to domain shifts between the training and target environments. We propose DGTrack, a novel single-source domain generalization framework for UAV visual tracking. DGTrack integrates a Frequency-Aware Learning (FAL) module that separates and adaptively modulates low- and high-frequency components to reduce stylistic interference while enhancing content representation. In addition, a Target-Aligned Augmentation (TAA) module is introduced to improve source domain diversity through multi-level transformations and to align predictions between original and augmented frames by maximizing mutual information. Extensive experiments on the UAVDT and VisDrone2019 datasets demonstrate that DGTrack achieves superior generalization to unseen domains and consistently outperforms state-of-the-art UAV trackers in single-source settings.},
  archive      = {J_KBS},
  author       = {Erfeng Liu and Xinde Li and Heqing Li and Guoliang Wu and Tao Shen},
  doi          = {10.1016/j.knosys.2025.114501},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114501},
  shortjournal = {Knowl. Based Syst.},
  title        = {A domain generalized UAV tracking framework via frequency-aware learning and target-aligned data augmentation in complex environments},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing forex market forecasting with feature-augmented multivariate LSTM models using real-time data. <em>KBS</em>, <em>330</em>, 114500. (<a href='https://doi.org/10.1016/j.knosys.2025.114500'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a feature-augmented multivariate LSTM model for real-time Forex market forecasting. By incorporating engineered financial indicators—such as Close_Change, RSI, and gold price—alongside traditional OHLCV data, the model captures nonlinear temporal dynamics and macro-financial interactions. A sliding window approach structures input sequences for a stacked LSTM network optimized for short-term prediction. Experimental results on major currency pairs demonstrate that the proposed model outperforms baseline LSTM, GRU, and classical machine learning methods in RMSE, MAE, and MAPE metrics. Statistical validation using the Wilcoxon signed-rank test confirms the improvements are significant. The model's robustness under volatility stress and noisy inputs highlights its practical relevance for real-time decision-making. Potential extensions include incorporating news-based sentiment and multimodal signals to enhance adaptability.},
  archive      = {J_KBS},
  author       = {Duong Thi Kim Chi and Ho Ngoc Trung Kien and Thanh Q. Nguyen},
  doi          = {10.1016/j.knosys.2025.114500},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114500},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing forex market forecasting with feature-augmented multivariate LSTM models using real-time data},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decision-based heterogenous graph attention network for multi-class fake news detection. <em>KBS</em>, <em>330</em>, 114499. (<a href='https://doi.org/10.1016/j.knosys.2025.114499'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A promising tool for addressing fake news detection is Graph Neural Networks (GNNs). However, most existing GNN-based methods rely on binary classification, categorizing news as either real or fake. Additionally, traditional GNN models use a static neighborhood for each node, making them susceptible to issues like over-squashing. In this paper, we introduce a novel model named Decision-based Heterogeneous Graph Attention Network (DHGAT) for fake news detection in a semi-supervised setting. DHGAT effectively addresses the limitations of traditional GNNs by dynamically optimizing and selecting the neighborhood type for each node in every layer. It represents news data as a heterogeneous graph where nodes (news items) are connected by various types of edges. The architecture of DHGAT consists of a decision network that determines the optimal neighborhood type and a representation network that updates node embeddings based on this selection. As a result, each node learns an optimal and task-specific computational graph, enhancing both the accuracy and efficiency of the fake news detection process. We evaluate DHGAT on the LIAR dataset, a large and challenging dataset for multi-class fake news detection, which includes news items categorized into six classes. Our results demonstrate that DHGAT outperforms existing methods, improving accuracy by approximately 4% and showing robustness with limited labeled data.},
  archive      = {J_KBS},
  author       = {Batool Lakzaei and Mostafa Haghir Chehreghani and Alireza Bagheri},
  doi          = {10.1016/j.knosys.2025.114499},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114499},
  shortjournal = {Knowl. Based Syst.},
  title        = {A decision-based heterogenous graph attention network for multi-class fake news detection},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ReCAP2: Rectified and context-aware polarization prompting for robust depth enhancement. <em>KBS</em>, <em>330</em>, 114498. (<a href='https://doi.org/10.1016/j.knosys.2025.114498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate depth perception is fundamental for numerous computer vision applications, yet depth maps acquired from commodity sensors often suffer from artifacts and inaccuracies, necessitating effective enhancement techniques. Polarization imaging, capturing rich geometric cues robust to illumination variations, offers a promising modality to guide this process. However, effectively integrating these cues within learning-based depth enhancement frameworks remains challenging. Existing methods often overlook the inherent representational gap between depth and polarization features and employ context-agnostic fusion mechanisms, incapable of generating prompts adaptive to cross-modal relationships and local context. To address these limitations, we propose a novel Rectified and Context-Aware Polarization Prompting (ReCAP 2 ) framework for depth enhancement models. The ReCAP 2 first performs initial feature rectification across both channel and spatial dimensions to bridge the modality gap. Subsequently, it generates fine-grained polarization prompts by leveraging dual-level context: utilizing cross-modal context ensures the prompts encode pertinent inter-modality relationships, while processing spatial neighborhood context yields prompts spatially tailored to regional content. Consequently, these dual-context aware prompts provide precise, adaptive guidance for the foundation model, facilitating more robust depth enhancement. Extensive experiments demonstrate the effectiveness of our method. On the multi-modal HAMMER dataset, our method shows superior accuracy and robustness across diverse sensor types in indoor scenes under both full fine-tuning and prompt tuning settings. Furthermore, cross-domain evaluations on the challenging CroMo dataset validate its strong generalization to outdoor environments.},
  archive      = {J_KBS},
  author       = {Zhenyu Liu and Jiatong Xu and Daxin Liu and Qide Wang and Jin Cheng and Jianrong Tan},
  doi          = {10.1016/j.knosys.2025.114498},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114498},
  shortjournal = {Knowl. Based Syst.},
  title        = {ReCAP2: Rectified and context-aware polarization prompting for robust depth enhancement},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain-generalized token linking in vision foundation models for semantic segmentation. <em>KBS</em>, <em>330</em>, 114497. (<a href='https://doi.org/10.1016/j.knosys.2025.114497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {[S U M M A R Y] Vision Foundation Models (VFMs) achieve remarkable performance compared with traditional methods based on convolutional neural networks and vision transformer networks in Domain-Generalized Semantic Segmentation (DGSS). These VFM-based DGSS methods focus on adopting efficient parameter fine-tuning strategies that use a set of learnable tokens to fine-tune VFMs to the downstream DGSS task, yet struggle to mine domain-invariant information from VFMs since the backbone of VFMs is frozen during the fine-tuning stage. To address this issue, a Domain-Generalized Token Linking (DGTL) approach is proposed to mine domain-invariant information from VFMs for improving the performance in unseen target domains, which contains a Text-guided Dual Token Linking (TDTL) module and a Text-guided Distribution Normalization (TDN) strategy. For the TDTL module, first, a set of learnable tokens is linked to the text embeddings for building the relations between the learnable tokens and text embeddings, which is beneficial for learning domain-invariant tokens since the text embeddings generated from the CLIP model are domain-invariant. Second, the feature-level and mask-level linking strategies are proposed to link the learned domain-invariant tokens to the features and masks to guide the mining of domain-invariant information from the VFM. For the TDN strategy, the pairwise similarity between the predictive masks associated with the learnable tokens and the text embeddings is utilized to explicitly align the semantic distribution of visual features in the learnable tokens with the text embeddings. Extensive experiments demonstrate that the DGTL approach achieves superior performance to recent methods across multiple DGSS benchmarks. The code is released on GitHub: https://github.com/seabearlmx/DGTL .},
  archive      = {J_KBS},
  author       = {Muxin Liao and Jiayang Wang and Hong Deng and Yingqiong Peng and Hua Yin and Yinglong Wang and Guoguang Hua},
  doi          = {10.1016/j.knosys.2025.114497},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114497},
  shortjournal = {Knowl. Based Syst.},
  title        = {Domain-generalized token linking in vision foundation models for semantic segmentation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive exploration for few-shot incremental learning. <em>KBS</em>, <em>330</em>, 114496. (<a href='https://doi.org/10.1016/j.knosys.2025.114496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot class incremental learning (FSCIL) poses a challenging problem in computer vision, where conventional deep models suffer from catastrophic forgetting and overfitting to novel classes. Inspired by the dynamic learning processes observed in human cognition when adapting to unfamiliar scenarios, we propose a deep exploratory incremental learning framework that incrementally refines the classifier model through a trial-and-error decision making process. A joint distribution-aware reward function is introduced to guide learning, incorporating three key factors: intra-class compactness, inter-class dispersion, and cross-session consistency, enabling balanced knowledge retention and acquisition. Furthermore, we design a dynamic gradient guidance module that adaptively adjusts gradient updates within a Gaussian-derived policy space, enhancing training stability and mitigating overfitting risks in the few shot regime. Extensive experiments conducted on three publicly available datasets demonstrate the effectiveness of the proposed method, achieving state-of-the-art performance in the FSCIL setting.},
  archive      = {J_KBS},
  author       = {Cao Han and Ziqi Gu and Chunyan Xu and Zhen Cui},
  doi          = {10.1016/j.knosys.2025.114496},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114496},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adaptive exploration for few-shot incremental learning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiphysics coupling AI prediction method for thermomechanical behavior of steel ladle linings. <em>KBS</em>, <em>330</em>, 114495. (<a href='https://doi.org/10.1016/j.knosys.2025.114495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the thermomechanical responses of refractory linings in steel ladles is critical to optimizing production efficiency and ensuring safety in the iron and steel smelting industry. However, traditional numerical simulation methods suffer challenges of high computational costs and insufficient generalizability, while data-driven models are limited by a lack of physical rationality and poor interpretability. Aiming at overcoming these challenges, an artificial intelligence (AI) model, named the steel ladle Kolmogorov–Arnold network (SLKAN), is designed to predict the thermomechanical behavior of ladle linings. Based on the Kolmogorov–Arnold theorem and material constitutive equations, SLKAN precisely predicts the thermomechanical behavior of ladle linings. The model offers substantial advantages in predicting the maximum tensile stress in the steel shell and the maximum compressive stress at the working lining hot face: the coefficient of determination (R 2 ) value for compressive stress prediction reaches 0.9942, with a mean absolute error (MAE) of 9.4136 and a root mean squared error (RMSE) of 0.0192; the R 2 value for tensile stress prediction is 0.9578, with an MAE of 41.4855 and an RMSE of 0.0385. Further analysis indicates that the function expressions of SLKAN hold clear physical significance. This study provides an interpretable, efficient AI solution for multiphysics coupling modeling in complex industrial scenarios and offers theoretical guidance for the application of AI in predicting the lifespan of steel-smelting equipment.},
  archive      = {J_KBS},
  author       = {Yi Yin and Zongxian Long and Shengli Jin and Yawei Li and Fang Wang and Xin Xu},
  doi          = {10.1016/j.knosys.2025.114495},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114495},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multiphysics coupling AI prediction method for thermomechanical behavior of steel ladle linings},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedCleanse: Cleanse the backdoor attacks in federated learning system. <em>KBS</em>, <em>330</em>, 114494. (<a href='https://doi.org/10.1016/j.knosys.2025.114494'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) enables multiple clients to collaboratively train an efficient deep-learning model without sharing their local data. However, due to its privacy-preserving nature, FL is vulnerable to backdoor attack, which manipulates the model behaviors on the adversary-chosen input. Existing defense methods are ineffective against sophisticated stealthy backdoors, suffering from either a low benign performance or being too specific to certain assumptions and attacks. To handle the aforementioned issues, we present FedCleanse, a novel defense mechanism to address the backdoor attack in federated learning. In this work, we study the pruning-based approach, which has been proven effective but with the need for additional data for validation and suffers from high non-IID scenarios. This paper proposes a post-aggregation approach, namely FedCleanse, to neutralize backdoor effects without needing additional clean data. Our approach identifies suspicious neurons using “neuron conductance” and subsequently suppresses them after the aggregation operation, which imposes minimal impact on benign neurons. Additionally, FedCleanse is complemented by strategic perturbations to prevent backdoor transfer. Through extensive experiments, our method demonstrates superior defense capabilities across various attack types and non-IID settings, surpassing the state-of-the-art by a large margin without compromising the main task’s performance.},
  archive      = {J_KBS},
  author       = {Siquan Huang and Yijiang Li and Chong Chen and Leyu Shi and Wentian Cai and Ying Gao},
  doi          = {10.1016/j.knosys.2025.114494},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114494},
  shortjournal = {Knowl. Based Syst.},
  title        = {FedCleanse: Cleanse the backdoor attacks in federated learning system},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CQSA-KT: Research on personalized knowledge tracing based on quantum-constructivism in sparse learning environments. <em>KBS</em>, <em>330</em>, 114493. (<a href='https://doi.org/10.1016/j.knosys.2025.114493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge tracing (KT), as a key technology to enable personalized instruction, faces the challenges of data sparsity and insufficient personalization modeling in large-scale instructional environments. To this end, this paper proposes a constructivist-inspired quantum self-attention knowledge tracing model (CQSA-KT). The deep mapping relationship between Constructivist Learning Theory (CLT) and Quantum Computing (QC) is established by characterizing the multilevel nature of learning states through quantum states, modeling knowledge associations through quantum entanglement, and simulating the assessment process through quantum measurements. The model contains four core modules: The quantum knowledge representation embedding module (QKREM) utilizes quantum complex embedding to achieve a high-dimensional representation of knowledge states; the quantum attention interaction module (QAIM) applies quantum entanglement to model the non-local nature of knowledge associations; the quantum measurement module (QMM) introduces the quantum measurement theory for learning assessment; and the hybrid cognitive feature fusion module (HCFFM) integrates classical and quantum features. Experiments on three publicly available datasets show that CQSA-KT maintains better performance under high sparsity (>98 %) conditions, significantly outperforming ten existing benchmark models. Especially in extremely sparse scenarios (only 20 % training data), the model’s AUC improves by 8.5 percentage points over the benchmark models. This theory-driven technological innovation validates the application potential of QC in education and provides a new theoretical framework for the development of intelligent education.},
  archive      = {J_KBS},
  author       = {Chengke Bao and Zhiliang Xu and Weidong Ji},
  doi          = {10.1016/j.knosys.2025.114493},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114493},
  shortjournal = {Knowl. Based Syst.},
  title        = {CQSA-KT: Research on personalized knowledge tracing based on quantum-constructivism in sparse learning environments},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TransPhyX: A data-driven method for dynamic physical field prediction in stochastic load time-series. <em>KBS</em>, <em>330</em>, 114492. (<a href='https://doi.org/10.1016/j.knosys.2025.114492'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic prediction of in-service physical fields (e.g. stress, strain, and temperature fields) constitutes a cornerstone technology for digital governance of mechanical equipment. The stochasticity and time-varying characteristics of external excitation loads (e.g. thermal, vibrational, and impact loads) introduce significant complexity in physical field prediction. Online monitoring of physical fields at the assembly interfaces of mechanical systems is critical for ensuring structural safety, extending service life, and optimizing design. This study proposes TransPhyX (Transformer-Based Physical Field Prediction with XGBoost Precoder), a hybrid data-driven framework designed to overcome these challenges. The novelty of TransPhyX lies in: (1) a recursive stochastic load generation and parametric dataset construction method tailored for dynamic prediction tasks; (2) a modular hybrid architecture that decouples transient load encoding (via XGBoost) and dynamic sequence modeling (via Transformer), improving spatiotemporal continuity and generalization; and (3) an Outlier Removal Ensemble (ORE) algorithm that fuses multi-scale predictions to eliminate anomalies and enhance robustness. Validated on flip-chip thermal management and flange-bolt stress prediction, TransPhyX achieves 99.79 % prediction fidelity with a 97.79 % reduction in computational costs compared to FEM, outperforming AutoGAN and TransUNet baselines in both accuracy and stability. These contributions establish TransPhyX as a rapid, high-fidelity solution for real-time structural health monitoring and digital twin implementation in stochastic loading environments.},
  archive      = {J_KBS},
  author       = {Qiyin Lin and Feiyu Gu and Mingjun Qiu and Chen Wang and Jian Zhuang and Jun Hong},
  doi          = {10.1016/j.knosys.2025.114492},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114492},
  shortjournal = {Knowl. Based Syst.},
  title        = {TransPhyX: A data-driven method for dynamic physical field prediction in stochastic load time-series},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient yet secure: An archive knowledge graph-enhanced native sparse attention network for lightweight privacy-preserving recommendation. <em>KBS</em>, <em>330</em>, 114490. (<a href='https://doi.org/10.1016/j.knosys.2025.114490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation Systems (RSs) aim to provide personalized recommendations by modeling user-item interaction patterns. Current attribute-enhanced RSs leverage user archival attributes to improve predictive performance. However, the use of attribute information introduces two critical challenges: 1) the risk of privacy leakage, as sensitive user attributes can be inferred from learned representations, and 2) high computational complexity, primarily due to the quadratic complexity of attention mechanisms. To address the accuracy-privacy-efficiency trilemma, we propose an Archive Knowledge Graph-enhanced Native Sparse Attention network (AKG-NSA) for privacy-preserving lightweight recommendation. Specifically, AKG-NSA introduces a two-stage privacy protection mechanism. First, we pseudonymize user identities in the archive knowledge graph, breaking the direct linkage between users and their attributes. Second, we design a Multi-channel Native Sparse Attention (MNSA) network that utilizes compressed user representations as queries to retrieve attribute patterns from the archive knowledge graph in a privacy-preserved manner. Moreover, we also construct a parallel user-item bipartite graph and operate graph convolutions to learn the representations for users and items. By employing the native sparse attention mechanism, AKG-NSA refines the learned representations while maintaining a low computational complexity. Extensive experiments on three real-world datasets demonstrate that AKG-NSA outperforms nine state-of-the-art baselines in terms of prediction accuracy, privacy preservation, and computational efficiency. The data and source codes of this work are available at https://github.com/juandu113/AKG-NSA .},
  archive      = {J_KBS},
  author       = {Juan Du and Chenxi Ma and Yaobin Wang and Limei Sun},
  doi          = {10.1016/j.knosys.2025.114490},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114490},
  shortjournal = {Knowl. Based Syst.},
  title        = {Efficient yet secure: An archive knowledge graph-enhanced native sparse attention network for lightweight privacy-preserving recommendation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Asymmetric co-training with explainable cell graph ensembling for histopathological image classification. <em>KBS</em>, <em>330</em>, 114489. (<a href='https://doi.org/10.1016/j.knosys.2025.114489'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks excel in histopathological image classification, yet their pixel-level focus hampers explainability. Conversely, emerging graph convolutional networks spotlight cell-level features and medical implications. However, limited by their shallowness and suboptimal use of high-dimensional pixel data, graph convolutional networks underperform in multi-class histopathological image classification. To make full use of pixel-level and cell-level features dynamically, we propose an asymmetric co-training framework combining a deep graph convolutional network and a convolutional neural network for multi-class histopathological image classification. To improve the explainability of the entire framework by embedding morphological and topological distribution of cells, we build a 14-layer deep graph convolutional network to handle cell graph data. For the further utilization and dynamic interactions between pixel-level and cell-level information, we also design a co-training strategy to integrate the two asymmetric branches. Notably, we collect a private clinically acquired dataset termed LUAD7C, including seven subtypes of lung adenocarcinoma, which is rare and more challenging. We evaluated our approach on the private LUAD7C and public colorectal cancer datasets, showcasing its superior performance, explainability, and generalizability in multi-class histopathological image classification. Our code is released on https://github.com/NeuronXJTU/ACT.},
  archive      = {J_KBS},
  author       = {Ziqi Yang and Zhongyu Li and Chen Liu and Xiangde Luo and Yu Xu and Xingguang Wang and Dou Xu and Chaoqun Li and Xiaoying Qin and Meng Yang and Long Jin},
  doi          = {10.1016/j.knosys.2025.114489},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114489},
  shortjournal = {Knowl. Based Syst.},
  title        = {Asymmetric co-training with explainable cell graph ensembling for histopathological image classification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-source heterogeneous sensor information fusion framework for intelligent online chatter detection in different milling conditions. <em>KBS</em>, <em>330</em>, 114488. (<a href='https://doi.org/10.1016/j.knosys.2025.114488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online chatter detection is a critical technology in intelligent manufacturing systems, essential for ensuring high-quality and efficient milling operations. Although artificial intelligence models have been developed to automatically identify chatter, the accuracy improvement is limited by the use of single sensor signals. Therefore, a multi-source heterogeneous sensor information fusion framework is proposed for intelligent online chatter detection in this paper. To effectively mitigate noise and eliminate interference from milling parameters, a heterogeneous sensor signal processing strategy is proposed based on wavelet packet decomposition and successive variational mode decomposition. Next, a multi-source, multi-stage, and multi-scale spatial-temporal fusion attention network is proposed for extracting chatter features and achieving high-precision chatter detection. It is noteworthy that multi-source signals are fused at the feature level, and comprehensive chatter features are extracted through the multi-source information fusion module, the multi-stage spatial-temporal feature extraction and fusion module, and the multi-scale gated channel attention module. In milling experiments across different conditions, the chatter detection performance of the proposed framework is evaluated in three scenarios. The results indicate that this framework can provide more accurate and reliable detection results compared to other methods.},
  archive      = {J_KBS},
  author       = {Liangshi Sun and Xianzhen Huang and Zhiyuan Jiang and Jiatong Zhao and Xu Wang},
  doi          = {10.1016/j.knosys.2025.114488},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114488},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-source heterogeneous sensor information fusion framework for intelligent online chatter detection in different milling conditions},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class-conditional image synthesis with intra-class relation preservation. <em>KBS</em>, <em>330</em>, 114487. (<a href='https://doi.org/10.1016/j.knosys.2025.114487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling class-conditional data distributions remains challenging, since the intra-class variation may be very large. Different from generic class-conditional Generative Adversarial Networks (GANs), we take inspiration from the observation that there may exist multiple modes with diverse visual appearances in a single class, and propose an Intra-class Prototype-based Relation Preservation (IPRP) approach to improve class-conditional image synthesis. Toward this end, a generator is designed to learn class-specific data distribution, conditioned on intra-class prototype-based relation. To associate label embeddings with the cluster prototypes, we incorporate an auxiliary prototypical network to perform adversarial interpolation, and the synthesized data are required to encapsulate their relation to the corresponding prototypes in the form of interpolation coefficients. The prototypical network can be further leveraged to improve the class-conditional real-fake identification performance by injecting semantics-aware features into a discriminator. This design allows the generator to better capture intra-class modes We conduct extensive experiments to demonstrate that IPRP outperforms the competing class-conditional GANs in terms of data diversity and semantic accuracy.},
  archive      = {J_KBS},
  author       = {Yunfei Zhang and Xiaoyang Huo and Tianyi Chen and Si Wu and Hau-San Wong},
  doi          = {10.1016/j.knosys.2025.114487},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114487},
  shortjournal = {Knowl. Based Syst.},
  title        = {Class-conditional image synthesis with intra-class relation preservation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A supervised learning approach to dynamic weighted fusion in multi-source ordered decision systems. <em>KBS</em>, <em>330</em>, 114485. (<a href='https://doi.org/10.1016/j.knosys.2025.114485'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of new-generation artificial intelligence technologies, machines can process and analyze large-scale data more accurately and efficiently and for more complex tasks. Enhancing the usability and value of the information derived from various information systems across multiple dimensions is essential. However, traditional data dominance relationships cannot reflect people’s different levels of attention to antithetic features, leading to higher complexity and lower classification accuracy. Therefore, it is necessary to consider the weight relationships between attributes in the data, which refers to the degree of correlation between each attribute and the decision in multi-source information systems. Based on these weights and dominance relationships, we consider an entropy-based weighted information fusion method for processing supervised data in multi-source ordered decision systems. We intend four incremental fusion mechanisms to adjust information sources and attribute changes to save running time. Furthermore, experiments are conducted on nine real datasets to demonstrate our method’s effectiveness. The results show that the inevitable accuracy comparisons by the proposed method are superior to most fusion methods. In addition, the dynamic mechanisms, compared to static mechanisms, can significantly reduce running time.},
  archive      = {J_KBS},
  author       = {Xiaoyan Zhang and Jiajia Lin},
  doi          = {10.1016/j.knosys.2025.114485},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114485},
  shortjournal = {Knowl. Based Syst.},
  title        = {A supervised learning approach to dynamic weighted fusion in multi-source ordered decision systems},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature reduction causal network (FRCN): A novel approach for analyzing coupling relationships in radar system. <em>KBS</em>, <em>330</em>, 114484. (<a href='https://doi.org/10.1016/j.knosys.2025.114484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To evaluate radar performance in complex electromagnetic environments, a compact and efficient causal model is required to model such a complex, nonlinear high-stakes problem. Hence, in this paper, we propose a feature reduction causal network (FRCN). Firstly, to determine the number of hidden layer features in the FRCN, a feature extraction strategy is designed using the intrinsic dimension (ID) of raw data as key prior knowledge, thereby reducing modeling complexity and improving computational efficiency. Then, to further reveal the causal relationships between features and the final objective, a Bayesian network (BN) is constructed in the task layer, intuitively showing the coupling relationships through a directed graph and providing interpretability for decisions on high-stakes problems. Moreover, we extend the layer-wise relevance propagation to the BN in the FRCN, enabling bidirectional reasoning throughout the entire process, which is beneficial to understand the model and its behavior in a human-understandable way. In experiments, it is proved that ID plays a significance role in feature number selection. Next, we design a new interpretable evaluation indicator, called decision-specific average edge relevance, to quantify interpretability. Compared to eight representative models, FRCN not only achieves higher accuracy but also provides stronger interpretability in terms of relevance, informativeness, and trustworthiness. A detailed analysis of a radar system enhances the understanding of coupling relationships among various factors, thereby validating the effectiveness of FRCN in feature reduction, interpretability, and trustworthiness for high-dimensional, complex, and nonlinear data.},
  archive      = {J_KBS},
  author       = {Chenfeng Wang and Xiaoguang Gao and Zidong Wang and Bo Li and Kaifang Wan and Xinyu Li and Chuchao He},
  doi          = {10.1016/j.knosys.2025.114484},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114484},
  shortjournal = {Knowl. Based Syst.},
  title        = {Feature reduction causal network (FRCN): A novel approach for analyzing coupling relationships in radar system},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Potential subgraph rule and reasoning context enhancement for sparse multi-hop knowledge graph reasoning. <em>KBS</em>, <em>330</em>, 114483. (<a href='https://doi.org/10.1016/j.knosys.2025.114483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-hop knowledge graph reasoning aims to leverage the relations between multiple nodes in a knowledge graph to reason information about an event or entity. This reasoning process requires traversing multiple interconnected facts or knowledge points, which aids in understanding the model’s decision-making process. Multi-hop knowledge graph reasoning has driven the development of knowledge-based technologies, such as question-answering systems and recommendation systems. However, multi-hop reasoning relies on the connectivity between different entities in the knowledge graph. This characteristic makes multi-hop reasoning lack robustness when dealing with sparse data. To address the challenges of sparsity, recent studies pre-train knowledge graph embedding models to complete potential triples. The completion methods introduce noisy triples, which increases the risk of model selection errors and spurious paths. In this work, we propose a framework based on potential subgraph rule and reasoning context enhancement to mitigate the challenges of sparsity. On one hand, we leverage reasoning context to enhance state information and the reasoning process; on the other hand, we design an action perceptron based on the importance of reasoning context to reduce the introduction of noisy triples. Additionally, we analyze the phenomenon of data augmentation introducing spurious paths, and further utilize data augmentation-based potential subgraph rules to guide the reasoning process. This dual mechanism demonstrates stronger robustness in addressing sparsity challenges and spurious paths. Diverse experiments demonstrate that our model outperforms the existing multi-hop reasoning models across five datasets. Our implementations will be publicly available at: https://github.com/jianruichen/PreKGR .},
  archive      = {J_KBS},
  author       = {Congcong Sun and Jianrui Chen and Deguang Chen and Junjie Huang},
  doi          = {10.1016/j.knosys.2025.114483},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114483},
  shortjournal = {Knowl. Based Syst.},
  title        = {Potential subgraph rule and reasoning context enhancement for sparse multi-hop knowledge graph reasoning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAMR: Multi-scale graph contrastive learning with dynamic adjustment and mutual rectification. <em>KBS</em>, <em>330</em>, 114482. (<a href='https://doi.org/10.1016/j.knosys.2025.114482'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning (GCL) has emerged as a powerful self-supervised approach for learning generalized graph representations, achieving remarkable advancements in recent years. However, most existing GCL methods ignore the noise of the augmented global structure and the dynamic change in training, and lack detailed consideration in calculating local structural homogeneity. These limitations may lead to the model’s insufficient performance in capturing fine-grained semantic features at the node level, making it difficult to fully explore the potential semantic associations between adjacent nodes. Meanwhile, on a global scale, there is also a lack of the ability to model complex topological structures. To this end, we propose a new multi-scale graph contrastive learning with dynamic adjustment and mutual rectification. This method dynamically adjusts the global structure via graph reconstruction and adaptively learns node representations; Meanwhile, a mutual rectification module is designed to predict the support scores of neighbors relative to anchors and quantify each neighbor’s contribution to view agreement. Both reconstruction and rectification are integrated into the training objective and effectively capture the graph structure information from both global and local scales, improving the quality and robustness of graph representations. We conduct extensive experiments on three downstream tasks: node classification, node clustering, and link prediction. The experimental results demonstrate that our method outperforms existing GCL methods across multiple tasks and datasets, validating the effectiveness and generalizability of the proposed model.},
  archive      = {J_KBS},
  author       = {Dengdi Sun and Zhixiang Wu and Mingwei Cao and Zhifu Tao and Zhuanlian Ding},
  doi          = {10.1016/j.knosys.2025.114482},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114482},
  shortjournal = {Knowl. Based Syst.},
  title        = {DAMR: Multi-scale graph contrastive learning with dynamic adjustment and mutual rectification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiFusionSeg: Diffusion-driven semantic segmentation with multi-modal image fusion for enhanced perception. <em>KBS</em>, <em>330</em>, 114481. (<a href='https://doi.org/10.1016/j.knosys.2025.114481'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal data fusion harnesses complementary information from diverse sensors to enhance the comprehension of scenes. While multi-modal image integration enriches tasks like semantic segmentation, differing objectives of fusion and segmentation can cause conflicts that degrade performance. Existing methods fail to achieve an optimal trade-off between visual fusion quality and segmentation accuracy. This paper proposes DiFusionSeg, a novel fusion and segmentation model that employs a joint optimization framework to alleviate conflicts between the fusion and segmentation tasks. It not only generates fusion results with exceptional visual fidelity but also ensures precise segmentation. Through the carefully designed high-fidelity texture fusion module and diffusion-based segmentation module, DiFusionSeg effectively injects semantic guidance into the fusion process and enhances segmentation performance through denoising and feature fusion. Extensive comparative experiments on public RGB-T semantic segmentation datasets demonstrate that DiFusionSeg outperforms many state-of-the-art (SOTA) models (80.83 % mIoU on MSRS, 59.6 % mIoU on MFD). Additionally, it generates fusion results with exceptional visual fidelity. The source code and results will be released at https://github.com/warren-wzw/DiFusionSeg .},
  archive      = {J_KBS},
  author       = {Zhiwei Wang and Defeng He and Li Zhao and Bo Liu and Yayu Zheng and Xiaoqin Zhang},
  doi          = {10.1016/j.knosys.2025.114481},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114481},
  shortjournal = {Knowl. Based Syst.},
  title        = {DiFusionSeg: Diffusion-driven semantic segmentation with multi-modal image fusion for enhanced perception},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). P-EVFL: Efficient verifiable federated learning with privacy. <em>KBS</em>, <em>330</em>, 114480. (<a href='https://doi.org/10.1016/j.knosys.2025.114480'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning has recently become popular and widely used in various areas. However, it still faces challenges like the leakage of the client’s local model updates and the server forging aggregation results. To address these issues, we propose an efficient verifiable federated learning scheme with privacy (P-EVFL), which seeks to ensure privacy and verifiability with a lower overhead. Specifically, we first design a lightweight masking technique to protect the honest clients’ local model updates. Next, we introduce homomorphic hash functions to develop a verifiable method to ensure the integrity of the aggregation results. Besides, to reduce the overhead of the verification process, a verification algorithm based on a Merkle tree is proposed. We also conduct comprehensive experiments and compare our scheme with other state-of-the-art schemes. The experimental results show that in a scenario with 100 clients, our scheme reduces the computational overhead by up to 8.15 % and the communication overhead by up to 67.38 %.},
  archive      = {J_KBS},
  author       = {Juan Ma and Xiangshen Ma and Yuling Chen},
  doi          = {10.1016/j.knosys.2025.114480},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114480},
  shortjournal = {Knowl. Based Syst.},
  title        = {P-EVFL: Efficient verifiable federated learning with privacy},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modality meets re-learning: Mitigating negative transfer in sequential recommendation. <em>KBS</em>, <em>330</em>, 114479. (<a href='https://doi.org/10.1016/j.knosys.2025.114479'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning effective recommendation models from sparse user interactions represents a fundamental challenge in developing sequential recommendation methods. Recently, pre-training-based methods have been developed to tackle this challenge. Though promising, in this paper, we show that existing methods suffer from the notorious negative transfer issue, where the model adapted from the pre-trained model results in worse performance compared to the model learned from scratch in the task of interest (i.e., target task). To address this issue, we develop ANT (Addressing Negative Transfer) for transferable sequential recommendation. ANT mitigates negative transfer by 1) incorporating multi-modality item information, including item texts, images and prices, to effectively learn more transferable knowledge from related tasks (i.e., auxiliary tasks); and 2) better capturing task-specific knowledge in the target task using a re-learning-based adaptation strategy. Our experimental results on five target tasks demonstrate that ANT does not suffer from the negative transfer issue, and substantially outperforms baselines on the target tasks.},
  archive      = {J_KBS},
  author       = {Bo Peng and Hanwen Du and Srinivasan Parthasarathy and Xia Ning},
  doi          = {10.1016/j.knosys.2025.114479},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114479},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-modality meets re-learning: Mitigating negative transfer in sequential recommendation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to extract and aggregate contexts for link prediction in heterogeneous graphs. <em>KBS</em>, <em>330</em>, 114478. (<a href='https://doi.org/10.1016/j.knosys.2025.114478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many diverse real-world graph datasets are heterogeneous graphs, and link prediction on these graphs is a fundamental task. The current trends of link prediction on heterogeneous graphs emphasize leveraging contextual information from either a path between a source node and a target node, or a sub-graph sampled around these two nodes. However, these approaches face limitations in identifying only beneficial contextual nodes around source and target and then effectively aggregating the representations of these nodes for improving overall prediction accuracy. To address these limitations, we claim that carefully-extracted context nodes can aid in accurate link prediction, and these context nodes should be similar to a source node or a target node in a representation space. To this end, we propose a new link prediction framework LEACH which learns to extract the beneficial context nodes and to aggregate their representations in heterogeneous graphs. Specifically, our approach involves three steps to learn: (i) generating heterogeneity-aware representations of nodes in the heterogeneous graph, (ii) selecting the context nodes based on the relatedness to the source and target nodes; and (iii) aggregating the representations of the context nodes to obtain the source and target representations. Extensive experiments demonstrate that LEACH significantly outperforms existing baselines on three publicly available heterogeneous graph datasets. We provide analytical insights into the rationale behind the superior performance of LEACH on link prediction.},
  archive      = {J_KBS},
  author       = {Jimin Woo and Minbae Park and Hyunjoon Kim},
  doi          = {10.1016/j.knosys.2025.114478},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114478},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning to extract and aggregate contexts for link prediction in heterogeneous graphs},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced people analytics: Integrating tournament theory, human capital theory, and social network theory for enhanced HRIS and performance evaluation. <em>KBS</em>, <em>330</em>, 114477. (<a href='https://doi.org/10.1016/j.knosys.2025.114477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the integration of advanced data analytics techniques within People Analytics and Human Resource Information Systems (HRIS), emphasizing their application in both organizational and sports performance contexts. By synthesizing Tournament Theory, Human Capital Theory, and Social Network Theory, this research provides a comprehensive framework for understanding skill dissemination, performance evaluation, and wage determination. Utilizing the NBA 2 K dataset, this study quantifies both tangible and intangible player attributes, incorporating digital engagement and social media metrics to enhance traditional performance metrics. Employing community detection algorithms and the Independent Cascade Model, the research uncovers hidden competencies and their influence on team dynamics and organizational effectiveness. The results contest established HRIS approaches, suggesting a holistic talent management strategy that takes into account the multifacetedness of skills propagation through networks. This work offers significant implications for HR professionals, providing novel insights into strategic HR planning, talent acquisition, and performance management in the digital age.},
  archive      = {J_KBS},
  author       = {Tianzi Zheng and Riyaz Sikora},
  doi          = {10.1016/j.knosys.2025.114477},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114477},
  shortjournal = {Knowl. Based Syst.},
  title        = {Advanced people analytics: Integrating tournament theory, human capital theory, and social network theory for enhanced HRIS and performance evaluation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bias-in-debias-out: Hierarchical channel-spatial bias calibration for cross-domain few-shot classification. <em>KBS</em>, <em>330</em>, 114475. (<a href='https://doi.org/10.1016/j.knosys.2025.114475'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The core challenge of cross-domain few-shot learning (CD-FSL) stems from models’ inability to generalize source-domain inductive biases to target domains under significant distribution shifts. While existing methods predominantly employ strategies like auxiliary target data adaptation, feature disentanglement, or metric space alignment, they overlook two inherent biases entrenched during source-domain training: (1) channel-wise dependency on source-specific feature patterns and (2) spatial-wise preference for source-typical structures, both of which hinder cross-domain transfer. We propose the first unified C hannel- S patial D ual-dimensional B ias C alibration (CSDBC) framework to systematically address these biases through progressive dilution, recomposition, and alignment. Our approach integrates three key innovations: (1) a parameter-free S tatic B ase-class B ias D ilution (SBBD) module that dilutes source-specific channel-spatial biases through layer-wise and point-wise modulation, effectively suppressing overfitting to source-specific patterns; (2) a D ynamic N ovel-class B ias R ecomposition (DNBR) module that generates target-adaptive channel-spatial soft masks via meta-optimized lightweight depthwise separable convolutions, enabling target-domain channel reweighting and spatial preference adjustment; and (3) a N ovel-class C ross-image S emantic A lignment (NCSA) module that establishes channel correlations and spatial correspondences between support-query pairs, significantly enhancing both discriminability and semantic consistency of target-domain features. Extensive experiments across eight CD-FSL benchmarks demonstrate consistent improvements, outperforming SOTA methods by 1.35 % (5-way 1-shot) and 2.00 % (5-way 5-shot) in average accuracy under varying domain shifts.},
  archive      = {J_KBS},
  author       = {Minghui Li and Hongxun Yao},
  doi          = {10.1016/j.knosys.2025.114475},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114475},
  shortjournal = {Knowl. Based Syst.},
  title        = {Bias-in-debias-out: Hierarchical channel-spatial bias calibration for cross-domain few-shot classification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing leadership-based metaheuristics using reinforcement learning: A case study in grey wolf optimizer. <em>KBS</em>, <em>330</em>, 114471. (<a href='https://doi.org/10.1016/j.knosys.2025.114471'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristics are widely applied in optimization because of their flexibility and ability to address complex and high-dimensional problems. Nevertheless, they face persistent challenges, including susceptibility to local optima, limited parameter adaptability, and premature convergence. Leadership-based metaheuristics, in which leaders guide the search process, encounter additional difficulties such as limited exploration capacity, leader stagnation, and reduced diversity, often stemming from underutilization of data generated during the search. To overcome these limitations, this study proposes a reinforcement learning–based approach, RL-LGWO, which enhances the Grey Wolf Optimizer (GWO) by integrating multi-agent reinforcement learning. In RL-LGWO, agents share experiences to improve decision-making, and reinforcement learning is employed to decouple and adapt the leader update mechanism, thereby improving the exploration–exploitation balance and enabling leaders to dynamically escape local optima. The proposed method was evaluated against two GWO-enhancing algorithms, three RL-based GWO variants, PSO, WOA, and the original GWO across 23 well-known benchmark functions, in addition to the recent CEC2022 benchmark suite. Experimental results show that RL-LGWO achieved the best solutions on 17 of the 23 benchmark functions, with superior convergence speed and improved stability, while incurring only a minor runtime increase compared with the original GWO. Furthermore, on the CEC2022 suite, RL-LGWO outperformed competing algorithms on 10 of 12 test functions, underscoring its robustness and adaptability to recent and challenging benchmarks. Overall, the findings indicate that RL-LGWO delivers a substantive improvement over state-of-the-art alternatives and holds strong potential to advance leadership-based metaheuristics for a wide range of optimization problems.},
  archive      = {J_KBS},
  author       = {Afifeh Maleki and Mehdy Roayaei and Seyedali Mirjalili},
  doi          = {10.1016/j.knosys.2025.114471},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114471},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing leadership-based metaheuristics using reinforcement learning: A case study in grey wolf optimizer},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MRBalance: A framework for enhancing event causality identification in multi-agent debates via role assignment. <em>KBS</em>, <em>330</em>, 114470. (<a href='https://doi.org/10.1016/j.knosys.2025.114470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of large language models (LLMs) has advanced natural language processing by improving contextual understanding and generalization abilities. However, despite these advances, determining event causality remains a challenging task. When LLMs are applied to this task, they frequently exhibit significant inconsistencies in recognizing causal representations, resulting in the phenomenon known as causal hallucinations. Specifically, LLMs perform well in predicting events with causal relationships but struggle with events without such relationships, frequently failing to achieve balanced performance across different causal scenarios. In this study, we propose MRBalance, a novel framework that uses role-based multi-agent debates to improve event causality identification. Our method transforms the task into a single-choice question-answering task, prompting LLM-based agents to engage in structured debates and justify their answers using their unique role-based perspectives. In addition, we introduce a mechanism for optimizing team members that selects the best agents to participate in the next debate when the debate rounds are lengthy. Extensive experiments on two benchmark datasets demonstrate significant performance improvements, highlighting the effectiveness of MRBalance in reducing causal hallucinations and increasing robustness.},
  archive      = {J_KBS},
  author       = {Xiang Zou and Xuanhong Li and Po Hu and Ming Dong},
  doi          = {10.1016/j.knosys.2025.114470},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114470},
  shortjournal = {Knowl. Based Syst.},
  title        = {MRBalance: A framework for enhancing event causality identification in multi-agent debates via role assignment},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DMFP: Dynamic multiscale feature perturbations for transferable adversarial attacks. <em>KBS</em>, <em>330</em>, 114469. (<a href='https://doi.org/10.1016/j.knosys.2025.114469'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transferability of adversarial samples facilitates adversarial attacks for the evaluation of the robustness of deep learning models, in which mitigating overfitting is of central importance for improving the transferability of adversarial samples. Current methods use regularization approaches to improve transferability without considering the degree of fitting of the adversarial perturbation and prior multiscale information of the source model during optimization, failing to find a flat minimum and improve generalization. This results in mutual inhibition of the attack capability and transferability. Therefore, our objective is to introduce the degree of fitting of the adversarial perturbation to dynamically regularize the multiscale feature for a better tradeoff between attack capability and transferability. In this paper, we propose dynamic multiscale feature perturbations (DMFP). Specifically, we investigate the properties of legitimate and adversarial features through qualitative visualization and quantitative distance metrics and devise multiscale feature perturbations (MFP). A combination of multiscale information and feature significance can perturb the salient features of a sample. In addition, we analyze the regularization effect produced by dropout in feature-level attacks and propose dynamic features (DF) to mitigate overfitting and enhance the generalization of adversarial samples by introducing gradient information. The experimental results demonstrate that DMFP significantly enhances the transferability of existing attack methods and achieves better performance than state-of-the-art methods, i.e., improving the success rate by 3.8 % against normally trained models and 12.8 % against defense models.},
  archive      = {J_KBS},
  author       = {Shuyan Cheng and Peng Li and Keji Han and Yumiao Zheng and He Xu and Yudong Yao},
  doi          = {10.1016/j.knosys.2025.114469},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114469},
  shortjournal = {Knowl. Based Syst.},
  title        = {DMFP: Dynamic multiscale feature perturbations for transferable adversarial attacks},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MIAFEx: An attention-based feature extraction method for medical image classification. <em>KBS</em>, <em>330</em>, 114468. (<a href='https://doi.org/10.1016/j.knosys.2025.114468'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature extraction techniques are crucial in medical image classification; however, classical feature extractors, in addition to traditional machine learning classifiers, often exhibit significant limitations in providing sufficient discriminative information for complex image sets. While Convolutional Neural Networks (CNNs) and Vision Transformer (ViT) have shown promise in feature extraction, they are prone to overfitting due to the inherent characteristics of medical imaging data, including small sample sizes or high intra-class variance. In this work, the Medical Image Attention-based Feature Extractor (MIAFEx) is proposed, a novel method that employs a learnable refinement mechanism to enhance the classification token within the Transformer encoder architecture. This mechanism adjusts the token based on learned weights, improving the extraction of salient features and enhancing the model’s adaptability to the challenges presented by medical imaging data. The MIAFEx output feature quality is compared against classical feature extractors using traditional and hybrid classifiers. Also, the performance of these features is compared against modern CNN and ViT models in classification tasks, demonstrating their superiority in accuracy and robustness across multiple complex medical imaging datasets. This advantage is particularly pronounced in scenarios with limited training data, where traditional and modern models often struggle to generalize effectively. The source code of this proposal can be found at github.com/Oscar-RamosS/Medical-Image-Attention-based-Feature-Extractor-MIAFEx .},
  archive      = {J_KBS},
  author       = {Oscar Ramos-Soto and Jorge Ramos-Frutos and Ezequiel Pérez-Zarate and Diego Oliva and Sandra E. Balderas-Mata},
  doi          = {10.1016/j.knosys.2025.114468},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114468},
  shortjournal = {Knowl. Based Syst.},
  title        = {MIAFEx: An attention-based feature extraction method for medical image classification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic domain information modulation algorithm for multi-domain sentiment analysis. <em>KBS</em>, <em>330</em>, 114465. (<a href='https://doi.org/10.1016/j.knosys.2025.114465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multidomain sentiment classification aims to improve model performance constrained by limited labeled data in a single domain by utilizing labeled data from multiple domains. Models that simultaneously train domain classifiers and sentiment classifiers have shown benefits. In this framework, domain classification serves as an auxiliary task, supplying crucial information for sentiment analysis. It is generally assumed that the importance of sentiment classification tasks remains consistent across all domains. By contrast, domain classification tasks exhibit variability because the impact of domain information on sentiment analysis differs among fields. This variability can be managed through adjustable weights or hyperparameters. However, as the number of domains grows, existing hyperparameter optimization algorithms face several challenges, including (1) high computational requirements, (2) convergence difficulties, and (3) increased algorithmic complexity. To efficiently generate the domain-specific information required for sentiment classification, we propose a dynamic information modulation algorithm. Specifically, the training process is divided into two phases. In the first phase, a global modulation factor that controls the proportion of domain classification tasks across all domains is established. In the second phase, we introduce an innovative cross-domain balancing modulation algorithm to refine the domain information embedded in the input text. This refinement is achieved using a gradient- and loss-based method. Experimental results show that our approach consistently enhances performance across most domains, achieving improvements of 0.3–1.0 % on 10 of 16 Amazon domains and 0.5–1.5 % on 3 of 5 Yelp domains, while maintaining performance comparable to baseline models in other domains.},
  archive      = {J_KBS},
  author       = {Chunyi Yue and Ang Li},
  doi          = {10.1016/j.knosys.2025.114465},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114465},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic domain information modulation algorithm for multi-domain sentiment analysis},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intention-guided imitation learning methods under limited expert demonstration data. <em>KBS</em>, <em>330</em>, 114455. (<a href='https://doi.org/10.1016/j.knosys.2025.114455'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imitation Learning has achieved significant results in various fields, such as robot control, autonomous driving, and unmanned vessel decision-making. This technology aims to mimic human behavior in specific tasks by learning the mapping between states and actions, enabling agents to execute tasks based on demonstrations. However, these methods rely on the acquisition of high-quality demonstration data, facing challenges such as difficulties in collecting expert samples, high costs, and low efficiency in policy learning. Particularly under limited sample conditions, imitation learning can easily get trapped in local optima, leading to lower success rates and accuracy in decision-making. Researchers have used data augmentation and transfer learning to tackle limited data. However, in complex scenarios, these methods are less effective due to a lack of domain-specific knowledge, which affects the interpretability of the model. To address these challenges, we propose an Intention-guided Imitation Learning method under limited expert demonstration data (ITIL), which extracts deep intent features from a small number of samples to enhance the agent’s understanding of the scene and improve the accuracy of the mapping from states to actions during Imitation Learning. Specifically, the core method consists of three modules: (1) Semantic Enhancement Module, which extracts spatiotemporal feature maps from a small number of raw trajectories to enrich the semantic information of expert data; (2) Intention Expression Module, which constructs an intention tree network to establish connections between different levels, effectively expressing and capturing expert intent; (3) Strategy Generation Module, which integrates the outputs of the first two modules as input to form efficient decision-making, creating a closed-loop architecture of cognitive understanding-knowledge expression-decision optimization. Experimental results show that our model outperforms baseline methods in navigation, capture, and formation tasks, with an average success rate improvement of approximately +6 % compared to the baseline method (ValueDICE).},
  archive      = {J_KBS},
  author       = {Yilin Liu and Xiangfeng Luo and Shaorong Xie},
  doi          = {10.1016/j.knosys.2025.114455},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114455},
  shortjournal = {Knowl. Based Syst.},
  title        = {Intention-guided imitation learning methods under limited expert demonstration data},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing dual network based semi-supervised medical image segmentation with uncertainty-guided pseudo-labeling. <em>KBS</em>, <em>330</em>, 114454. (<a href='https://doi.org/10.1016/j.knosys.2025.114454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the remarkable performance of supervised medical image segmentation models, relying on a large amount of labeled data is impractical in real-world situations. Semi-supervised learning approaches aim to alleviate this challenge using unlabeled data through pseudo-label generation. Yet, existing semi-supervised segmentation methods still suffer from noisy pseudo-labels and insufficient supervision within the feature space. To solve these challenges, this paper proposes a novel semi-supervised 3D medical image segmentation framework based on a dual-network architecture. Specifically, we investigate a Cross Consistency Enhancement module using both cross pseudo and entropy-filtered supervision to reduce the noisy pseudo-labels, while we design a dynamic weighting strategy to adjust the contributions of pseudo-labels using an uncertainty-aware mechanism (i.e., Kullback–Leibler divergence). In addition, we use a self-supervised contrastive learning mechanism to align uncertain voxel features with reliable class prototypes by effectively differentiating between trustworthy and uncertain predictions, thus reducing prediction uncertainty. Extensive experiments are conducted on three 3D segmentation datasets, Left Atrial, NIH Pancreas and BraTS-2019. The proposed approach consistently exhibits superior performance across various settings (e.g., 89.95 % Dice score on left Atrial with 10 % labeled data) compared to the state-of-the-art methods. Furthermore, the usefulness of the proposed modules is further validated via ablation experiments. The code repository is available at https://github.com/AIPMLab/Semi-supervised-Segmentation .},
  archive      = {J_KBS},
  author       = {Yunyao Lu and Yihang Wu and Ahmad Chaddad and Tareef Daqqaq and Reem Kateb},
  doi          = {10.1016/j.knosys.2025.114454},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114454},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing dual network based semi-supervised medical image segmentation with uncertainty-guided pseudo-labeling},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions. <em>KBS</em>, <em>330</em>, 114452. (<a href='https://doi.org/10.1016/j.knosys.2025.114452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilization of transfer learning strategies to solve cross-domain fault diagnosis problems has achieved significant results. However, most existing multi-source domain generalization fault diagnosis methods use a single classifier or introduce auxiliary classifiers, focusing on learning domain-invariant features or global feature distribution matching. Furthermore, since the data distributions of different source domains may be significantly different, this may lose the data distribution information specific to each source domain. In addition, how to reduce the variation in risk between samples within the same domain training is also a challenging issue. Finally, it is also crucial to balance the predictive outputs of multiple classifiers to adapt them to the data distribution of the target domain. Based on the above challenges, this paper proposes a multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions. Feature weakly decoupled mechanism is achieved by employing multiple classifiers and incorporating the variance of samples within the same sample domain as a penalty term. This reduces the model’s sensitivity to changes in the extreme distribution of samples within the domain. Classifier weakly decoupled mechanism, on the other hand, reduces the inter-domain risk variance by minimizing the loss of variance in the predicted output of the source domain classifiers. This improves the robustness of the model to inter-domain distributional changes and covariate changes. Experimental results on three datasets validate the effectiveness and general applicability of the proposed approach.},
  archive      = {J_KBS},
  author       = {Yawei Sun and Hongfeng Tao and Vladimir Stojanovic},
  doi          = {10.1016/j.knosys.2025.114452},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114452},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing large language models for bitcoin time series forecasting. <em>KBS</em>, <em>330</em>, 114449. (<a href='https://doi.org/10.1016/j.knosys.2025.114449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent advancements in application of deep learning to time series forecasting, focus has shifted from training transformers end-to-end to efficiently leveraging the predictive capabilities of Large Language Models (LLMs). Models that encode the time series data to interact with a frozen LLM backbone have been shown to outperform transformers on all benchmark datasets. However, their efficiency on complex datasets, which do not show clear seasonality or trend, remains an open question. In this work, we seek to evaluate the performance of reprogrammed LLMs on the Bitcoin price chart, a financial time series known for its complexity and high volatility. We propose effective methods to improve the performance of Time-LLM, a State-of-the-art (SOTA) method, on such a time series. First, we propose structural improvements to Time-LLM. Second, we suggest an efficient way to handle the non-stationarity of the dataset. Finally, we propose an efficient method for passing additional financial information to the LLM. Our results demonstrate a 50 % improvement on the average percentage loss and a 5 % increase on accuracy of our adapted Time-LLM architecture on Bitcoin data when compared to SOTA models, including the original Time-LLM model. This highlights the impact on forecast accuracy of domain-specific decision making in data processing and feature selection.},
  archive      = {J_KBS},
  author       = {Owen Chaffard and Pablo Mollá and Marc Cavazza and Helmut Prendinger},
  doi          = {10.1016/j.knosys.2025.114449},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114449},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing large language models for bitcoin time series forecasting},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CausalEnhance: Knowledge-enhanced pre-training for causality identification and extraction. <em>KBS</em>, <em>330</em>, 114447. (<a href='https://doi.org/10.1016/j.knosys.2025.114447'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causality identification and extraction are crucial in understanding causal relationships in text. Current studies heavily rely on datasets annotated with causal relationships. However, acquiring such datasets poses a challenge due to substantial costs, hindering progress in this research field. To address this, we introduce CausalEnhance, a novel approach designed to bridge this gap by combining weakly-guided pre-training with external causal knowledge. Our method starts with a rule-based system that automates causal annotation, enriching external data with explicit causal knowledge and creating pseudo labels. These pseudo-labels are then incorporated into a weakly supervised pre-training framework. We introduce three innovative pre-training tasks: the Pre-training Causal Clues Fill-Mask task (PCM) to pinpoint causality origins, the Pre-training Causality Identification task (PCI) to capture general causal patterns, and the Pre-training Causality Extraction task (PCE) for understanding explicit causal pairs and inferring implicit ones. Our experiments, conducted across eight datasets in two languages, English and Chinese, demonstrate CausalEnhance’s effectiveness in both identifying and extracting causality, highlighting its potential as a robust method for textual causality analysis in different linguistic contexts.},
  archive      = {J_KBS},
  author       = {Meiyun Wang and Kiyoshi Izumi and Hiroki Sakaji},
  doi          = {10.1016/j.knosys.2025.114447},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114447},
  shortjournal = {Knowl. Based Syst.},
  title        = {CausalEnhance: Knowledge-enhanced pre-training for causality identification and extraction},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Margin-guided parameter decoupling-consensus framework for federated domain generalization in machinery fault diagnosis. <em>KBS</em>, <em>330</em>, 114446. (<a href='https://doi.org/10.1016/j.knosys.2025.114446'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated domain generalization (FDG) as a solution to address the cross-client data heterogeneity problem in privacy-sensitive scenarios has drawn extensive attention in the field of intelligent fault diagnosis of industrial equipment in recent years. Nevertheless, most of the existing FDG-based diagnosis methods rely on client feature distribution alignment or data augmentation strategies, risking data leakage caused by the transmission of deep features and statistical information. To overcome the above-mentioned issues, a margin-guided parameter decoupling-consensus (MGPDC) framework is proposed to decouple the dependence of conventional federated domain generalization methods on features and data distributions and realize the extraction of common knowledge across clients. This framework initially employs a federated meta-learning-driven universal feature extractor to create a transferable shared feature space amidst heterogeneous client data, effectively enhancing the generalization ability of the model for unknown working conditions. Next, a parameter decoupling-consensus synergy (PDCS) mechanism is proposed. In this mechanism, an isolation module is established based on the consistency of parameter updates for parameter decoupling, effectively suppressing model update conflict. Subsequently, an implicit alignment mapping approach is devised for the screened parameters with strong consistency to achieve the extraction of cross-domain common knowledge. Then, an adaptive global margin guidance (AGMG) strategy is proposed to mitigate the interference of the blurred class boundaries during the federated process on common knowledge extraction. Finally, extensive experiments using real wind turbine gearbox data demonstrate the effectiveness and advancement of the MGPDC framework.},
  archive      = {J_KBS},
  author       = {Linhan Gou and Qikang Li and Baoping Tang and Xiaolong Zhang and Zihao Li and Yonggang Liu},
  doi          = {10.1016/j.knosys.2025.114446},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114446},
  shortjournal = {Knowl. Based Syst.},
  title        = {Margin-guided parameter decoupling-consensus framework for federated domain generalization in machinery fault diagnosis},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural network to surrogate computational bone remodelling in the calcaneus. <em>KBS</em>, <em>330</em>, 114445. (<a href='https://doi.org/10.1016/j.knosys.2025.114445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a data-driven approach using surrogate models based on Multi-Layer Perceptrons to predict bone remodelling outcomes in the calcaneus, both with and without fractures. The objective is to develop and train a neural network that accurately captures the biomechanical factors influencing the problem and predicts the resulting bone density distribution in the calcaneus. Given the complexity of bone healing processes, a comprehensive dataset was collected to train and validate the models under two distinct scenarios: an intact calcaneus and a fractured calcaneus treated with a surgical screw. Key parameters of the surrogate model, namely, the number of hidden layers, hidden layer size, and activation function, were optimized to enhance model performance. Additionally, training parameters such as learning rate and batch size were tuned. The hyperbolic tangent activation function was found to yield a lower mean squared error compared to the rectified linear units. Larger batch sizes and learning rates were found to improve model performance. The neural network designed to predict bone density in the intact model outperformed the one used for the fractured calcaneus with a screw, largely due to the increased variability in the fractured data. When the fracture did not significantly alter the trabecular distribution, prediction accuracy improved. Finally, the structural response of the models was evaluated, and it was observed that the trabecular arrangement inferred by the neural network tended to produce less stiff responses compared to those from the finite element method, likely due to the smoother density field predicted by the network.},
  archive      = {J_KBS},
  author       = {Ana Pais and Jorge Lino Alves and Jorge Belinha},
  doi          = {10.1016/j.knosys.2025.114445},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114445},
  shortjournal = {Knowl. Based Syst.},
  title        = {A neural network to surrogate computational bone remodelling in the calcaneus},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FCAT: Federated causal adversarial training. <em>KBS</em>, <em>330</em>, 114440. (<a href='https://doi.org/10.1016/j.knosys.2025.114440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal inference has been proven to be a crucial technique for improving the efficacy and explainability of adversarial training (AT). However, its applicability in the decentralized adversarial training paradigm has not been fully explored. Where one potential challenge is to apply the causal inference in the settings of non-independent and identically distributed (Non-IID) federated learning. In particular, the imbalanced data distributions among various clients will unavoidably hinder the efficacy and adaptability of causal inference. To address this issue, this paper proposes a novel yet practical method dubbed Federated Causal Adversarial Training (FCAT), which seeks to improve causal models via calibrated correction information. Additionally, we introduce a lightweight slack aggregation method aimed at addressing client model disparities and minimizing the communication overhead in each iteration. Extensive experimental results demonstrate that FCAT significantly improves the efficacy of causal models in federated adversarial training, and remarkably outperforms the current state-of-the-art (SOTA) competitors on multiple widely-adopted benchmarks.},
  archive      = {J_KBS},
  author       = {Yunhao Feng and Yanming Guo and Mingrui Lao and Yulun Wu and Yishan Li and Yuxiang Xie},
  doi          = {10.1016/j.knosys.2025.114440},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114440},
  shortjournal = {Knowl. Based Syst.},
  title        = {FCAT: Federated causal adversarial training},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural network-based iterative heuristic algorithm for the polynomial robust knapsack problem. <em>KBS</em>, <em>330</em>, 114439. (<a href='https://doi.org/10.1016/j.knosys.2025.114439'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The polynomial robust knapsack problem (PRKP) is a variant of the classic knapsack problem by incorporating uncertain costs and benefits from item combinations, leading to a nonlinear objective function and exponential solution space. These complexities make the PRKP suitable for real-world scenarios where interactions between items unpredictably impact outcomes. However, existing algorithms struggle to efficiently solve large instances of the PRKP due to its computational complexity. Therefore, this paper presents an iterative heuristic algorithm leveraging a neural network (NN) to address the PRKP, reducing the solution space and enabling efficient resolution of subproblems. The framework integrates an NN trained in two steps: general training and fine-tuning. The trained model is then embedded in the iterative heuristic algorithm to tackle the PRKP. A synthetic dataset comprising 2500 instances, ranging from 100 to 1500 items, is created to train the NN. Comparative evaluations are conducted using 1600 benchmark instances from the literature and 140 larger instances containing between 2000 and 15,000 items. We compare our approach against two state-of-the-art algorithms for the PRKP: a genetic algorithm and a random forest-based heuristic. Computational results demonstrate that the proposed algorithm outperforms the genetic algorithm, providing superior solution quality with significantly reduced computing times. Meanwhile, against random forest-based heuristic, it delivers better solution quality with only a moderate increase in computing time. For larger instances, it maintains its advantage in solution quality while remaining computationally efficient. These results highlight the algorithm’s scalability, effectiveness, and potential to address the PRKP.},
  archive      = {J_KBS},
  author       = {José González-Cortés and Carlos Contreras-Bolton},
  doi          = {10.1016/j.knosys.2025.114439},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114439},
  shortjournal = {Knowl. Based Syst.},
  title        = {A neural network-based iterative heuristic algorithm for the polynomial robust knapsack problem},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interplay between bayesian neural networks and deep learning: A survey. <em>KBS</em>, <em>330</em>, 114438. (<a href='https://doi.org/10.1016/j.knosys.2025.114438'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While deep learning models have seen significant success across various domains, their black-box learning nature and lack of interpretability affect their reliability in safety-critical applications like medical diagnostics and autonomous vehicles. In an attempt to address these limitations, Bayesian neural networks (BNNs) offer a promising alternative by incorporating uncertainty estimation into model predictions, enhancing transparency and decision-making. However, BNN development has primarily focused on efficient, high-fidelity approximate inference and guaranteed convergence in asymptotic settings. These are unsuitable for modern high-dimensional, multi-modal, and non-asymptotic deep learning applications, undermining their theoretical advantages. To bridge this gap, this paper provides in-depth reviews on how approximate Bayesian inference leverages deep learning optimization to achieve high efficiency and fidelity in high-dimensional spaces and multi-modal loss landscapes. It also reconciles Bayesian consistency with generalization objectives in non-asymptotic settings and investigates the generalization capabilities of BNNs. Additionally, this survey examines the often-overlooked expressiveness of BNNs, emphasizing how weight uncertainty and the absence of in-between uncertainty affect their performance. This survey aims to inspire BNN practitioners to adopt a deep learning perspective and offer valuable insights to propel further advancements in the field.},
  archive      = {J_KBS},
  author       = {Yinsong Chen and Samson S. Yu and Zhong Li and Jason K. Eshraghian and Chee Peng Lim},
  doi          = {10.1016/j.knosys.2025.114438},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114438},
  shortjournal = {Knowl. Based Syst.},
  title        = {Interplay between bayesian neural networks and deep learning: A survey},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TWDT: Training-free word-level controllable diffusion model for text generation. <em>KBS</em>, <em>330</em>, 114437. (<a href='https://doi.org/10.1016/j.knosys.2025.114437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing controlled text generation (CTG) methods typically require the training of additional components, whereas diffusion models have already achieved fine control in image generation by adjusting latent feature information during the inference process. However, existing diffusion models still face issues such as “attribute leakage” and “overgeneration” when applied to text generation, leading to generated texts lacking precise control. To address these problems, we propose a training-free word-level controllable diffusion language network (TWDT). This network achieves fine-grained control of text generation by adjusting latent space features during the inference process. Specifically, TWDT introduces an Alignment and Word Evaluation (AWE) module, which ensures accurate mapping of the text to a predefined set of feature words through syntactic segmentation and multi-level semantic alignment. At the same time, a similarity threshold filtering mechanism is applied to inject Gaussian noise into low-consistency nodes, ensuring semantic consistency and stability during generation. To evaluate the rigor and accuracy of the model, we have developed a high-quality multi-disease dental diagnostic dataset, all of which are annotated by experienced dental experts, serving as the benchmark for model evaluation. Experimental results show that TWDT outperforms existing diffusion models in terms of generation accuracy and rigor.},
  archive      = {J_KBS},
  author       = {Nan Gao and Yangjie Lu and Peng Chen and Guodao Sun and Ronghua Liang and Yilong Zhang},
  doi          = {10.1016/j.knosys.2025.114437},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114437},
  shortjournal = {Knowl. Based Syst.},
  title        = {TWDT: Training-free word-level controllable diffusion model for text generation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-class intrusion detection system for in-vehicle networks using few-shot learning and convolutional anomaly transformer network. <em>KBS</em>, <em>330</em>, 114436. (<a href='https://doi.org/10.1016/j.knosys.2025.114436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern vehicles depend on the Controller Area Network (CAN) for electronic control unit (ECU) communication, but its inherent vulnerabilities necessitate robust intrusion detection systems (IDS). Current machine learning and deep learning IDS solutions struggle with limited labeled data, class imbalances, and costly data collection processes. Few-shot learning, effective with few labeled samples, remains underexplored for in-vehicle networks (IVNs) despite its potential in data-scarce automotive cybersecurity scenarios. To bridge this gap, we introduce the first few-shot learning approach for multi-class intrusion detection in IVNs, leveraging a novel, lightweight Convolutional Anomaly Transformer. By integrating a 1D convolutional layer with an Anomaly Transformer, our model effectively classifies diverse attack types with minimal training data, mitigating class imbalance. Experiments on the widely-used real-world Car Hacking dataset, the complex ROAD dataset, and the distinct CAN-ML dataset validate its efficacy. On the Car Hacking dataset, we achieve an exceptional F1 score of 0.9994 with only 2 % of training data, improving to 0.9999 with 10 %. On the challenging ROAD dataset, characterized by diverse attacks and high variability, the model achieves an F1 score of up to 0.9980 using just 10 % of training data. Demonstrating strong generalization capabilities, the model also attains an impressive F1 score of 0.9918 on the CAN-ML dataset, which features entirely different vehicles and attack distributions. Furthermore, the lightweight architecture of our proposed IDS enables practical deployment in resource-constrained automotive environments.},
  archive      = {J_KBS},
  author       = {Nguyen Thanh Minh Duy and Truong Hoang Bao Huy and Pham Van Phu and Tien-Dat Le and Daehee Kim},
  doi          = {10.1016/j.knosys.2025.114436},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114436},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-class intrusion detection system for in-vehicle networks using few-shot learning and convolutional anomaly transformer network},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterophily-aware dynamic hypergraph for semi-supervised classification. <em>KBS</em>, <em>330</em>, 114435. (<a href='https://doi.org/10.1016/j.knosys.2025.114435'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypergraph neural networks, as high-order graph neural networks, excel in handling intricate relationships within non-Euclidean infinite-dimensional spaces. However, conventional homophily assumption-based hypergraph methods exhibit limited effectiveness in semi-supervised classification scenarios involving heterophily problem, where neighboring nodes often belong to dissimilar categories. To address this challenge, this paper proposes a Heterophily-Aware Dynamic Hypergraph (HADHG) framework grounded in heterophily assumption through label domain analysis. The framework comprises three key components: a hypergraph-oriented label propagation method for deriving class-specific label features, a label tensor construction approach characterizing node-level heterophily intensity via 2D tensors, and a center attention mechanism that dynamically optimizes hypergraph structures. By enabling nodes to dynamically reconfigure the local graph structure based on microscopic heterophily intensity, HADHG effectively mitigates heterophily interference. Comprehensive experiments using real-flight data from Unmanned Aerial Vehicles and the public Gear dataset highlight the framework’s superiority over state-of-the-art methods. The codes and datasets are openly available at https://github.com/DL-LEO/HADHG .},
  archive      = {J_KBS},
  author       = {Shaojun Liang and Ying Zheng and Housheng Su and Lei Zhang and Yi Yang},
  doi          = {10.1016/j.knosys.2025.114435},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114435},
  shortjournal = {Knowl. Based Syst.},
  title        = {Heterophily-aware dynamic hypergraph for semi-supervised classification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of an enhanced heart attack diagnosis model using knowledge distillation and frequent sequence pattern mining. <em>KBS</em>, <em>330</em>, 114434. (<a href='https://doi.org/10.1016/j.knosys.2025.114434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) algorithms have displayed their effectiveness in predicting sequence modelling compared to various systems. Nevertheless, some limitations of existing methods are the demand for enormous databases, computational expense, and the risk of overfitting. To address these problems, this study proposes a novel DL technique using knowledge distillation and sequence illness pattern recognition from medical databases. Firstly, the input data is pre-processed using the data cleaning method. The size of the sequence dataset and the duration of the sequential patterns are both considered during the process of using PREFIXSPAN to manage long sequential patterns. In the proposed strategy, a lightweight student network is employed to train a strong teacher network, which is produced by a Knowledge Distillation framework. A teacher network is assessed by the Attention Based Densely Connected Capsule Model (Attention-DC). An efficient, low-weight Depthwise Separable Convolutional Neural Network (DSCNN) model is then chosen as the student network. This study uses three datasets to solve enormous database issues. The KD helps prevent the student model from overfitting to noise or specific patterns in the training data. The Improved Coot Optimization Algorithm (ICOA) is applied to adjust the parameter. The hyperparameters used to optimize the performance of the proposed model are Epochs (300), learning rate (0.001), and batch size (32), respectively. The experiments use the resources of three different datasets, and Python is employed to analyze the results. The proposed technique achieves accuracy of 99.512 %, 99.329 % and 99.351 % for the heart disease, cardiovascular disease, and Diabetes dataset.},
  archive      = {J_KBS},
  author       = {Dinesh Kumar Bhawnani and Sunita Soni and Arpana Rawal},
  doi          = {10.1016/j.knosys.2025.114434},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114434},
  shortjournal = {Knowl. Based Syst.},
  title        = {Development of an enhanced heart attack diagnosis model using knowledge distillation and frequent sequence pattern mining},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural chain of thoughts for radiology education. <em>KBS</em>, <em>330</em>, 114433. (<a href='https://doi.org/10.1016/j.knosys.2025.114433'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology education requires trainees to develop both perceptual and interpretive expertise. However, refinement of these skills is often impeded by the limited availability of mentorship, a consequence of the demanding schedules of experienced radiologists. This lack of personalized guidance makes it difficult for learners to recognize the mistakes they make, understand why those errors occurred and how to refine their perceptual processes. Many of these errors arise from subtle differences in visual attention, such as failing to fixate on an abnormality, allocating an insufficient fixation time, or overlooking an abnormality despite scanning the correct region. Although Large Language Models (LLMs) and Large Multimodal Models (LMMs) have been explored for radiology tasks, they often struggle to detect such fine-grained multimodal variations, particularly when comparing gaze behavior between experts and trainees. To address these limitations, we introduce Structural Chain of Thoughts (SCoT), a novel framework that enhances LLMs and LMMs sensitivity to nuanced multimodal differences by structuring gaze data and radiology report into a thought graph. By leveraging a structural prior, SCoT systematically identifies key perceptual and interpretive discrepancies, allowing models to provide targeted, context-aware feedback. This structured approach not only highlights missed findings but also explains the reasoning behind perceptual errors, turning them into learning opportunities. Applied within radiology education, SCoT bridges the gap between expert and novice performance, offering a scalable solution for AI-driven diagnostic training. We further contribute a simulated dataset of perceptual errors in chest X-ray (CXR) interpretation, facilitating future research into multimodal reasoning and AI-driven medical education. Unlike conventional Chain-of-Thought approaches, SCoT explicitly integrates gaze and textual information into a structured reasoning process, yielding interpretable, fine-grained, and personalized feedback tailored to the unique needs of radiology training. The code and data will be available here: GitHub Repository .},
  archive      = {J_KBS},
  author       = {Akash Awasthi and Brandon Chung and Anh Mai Vu and Saba Khan and Ngan Le and Zhigang Deng and Rishi Agrawal and Carol C. Wu and Hien Van Nguyen},
  doi          = {10.1016/j.knosys.2025.114433},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114433},
  shortjournal = {Knowl. Based Syst.},
  title        = {Structural chain of thoughts for radiology education},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized task offloading with energy efficient communication and optimal offloading network: A mobility and energy-efficient approach for augmented reality in mobile edge computing. <em>KBS</em>, <em>330</em>, 114431. (<a href='https://doi.org/10.1016/j.knosys.2025.114431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing enables the efficient execution of compute-intensive tasks by offloading them to edge servers. However, frequent user mobility in 5 G urban networks leads to increased latency, energy consumption, and resource wastage due to continuous handovers. To address these challenges, Energy Efficient Communication and Optimal Offloading Network, a framework is proposed that combines user mobility prediction and hybrid optimization for task offloading. Energy Efficient Communication and Optimal Offloading Network utilizes a modified Long Short-Term Memory model to predict user movement with high accuracy, achieving an accuracy improvement from 65 % to 95 % over ten iterations. Additionally, a Hybrid Grey Wolf Optimization Algorithm optimizes task allocation, resulting in a 30 % reduction in energy consumption and a 25 % improvement in server utilization compared to baseline methods. The framework achieves latency as low as 5 milliseconds for augmented reality tasks while maintaining scalability in high-traffic 5 G environments. The proposed model also outperforms baseline approaches in terms of task completion time, throughput, and communication efficiency, and it achieves a 94.5 % offloading success rate and 98 % augmented reality delay compliance. The proposed model provides a scalable and useful solution for real-time Augmented Reality by combining energy-constrained task allocation with mobility-aware predictions.},
  archive      = {J_KBS},
  author       = {Anitha Jebamani Soundararaj and Godfrey Winster Sathianesan},
  doi          = {10.1016/j.knosys.2025.114431},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114431},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimized task offloading with energy efficient communication and optimal offloading network: A mobility and energy-efficient approach for augmented reality in mobile edge computing},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified multi-subgraph pre-training framework for spatio-temporal graph. <em>KBS</em>, <em>330</em>, 114428. (<a href='https://doi.org/10.1016/j.knosys.2025.114428'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal graph (STG) learning has shown great potential in capturing complex spatio-temporal dependencies and has achieved significant success in various fields such as traffic flow prediction, climate forecasting, and epidemiological spread research. By learning general features from spatio-temporal graphs, pre-trained graph models can capture hidden semantic information in the data, thereby enhancing the learning effect of downstream tasks and improving overall model performance. However, most existing spatio-temporal graph learning methods use the entire graph for training, which may not fully capture local structure and feature information. In addition, existing methods usually adopt sequence modeling techniques without fully considering the time decay effect, i.e., the need to apply decaying attention to distant time steps. To address these issues, this paper proposes a u nified dual-phase m ulti- s ubgraph pre-training s patio- t emporal graph framework (UMSST). Specifically, in the first phase, the framework learns the global representation of the spatio-temporal graph and locates key graph nodes, while learning the “unit representations” of these key nodes. In the second phase, multiple spatio-temporal subgraphs are constructed based on these “unit representations” to further capture the implicit encoding information of more general features around the corresponding subgraphs, thereby helping the model make full use of general features. Experimental results on real datasets show that the proposed pre-trained spatio-temporal graph framework significantly improves the performance of downstream tasks and demonstrates its effectiveness in comparison with recent strong baseline models.},
  archive      = {J_KBS},
  author       = {Mingze Zhong and Zexuan Long and Xinglei Wang and Tao Cheng and Meng Fang and Ling Chen},
  doi          = {10.1016/j.knosys.2025.114428},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114428},
  shortjournal = {Knowl. Based Syst.},
  title        = {A unified multi-subgraph pre-training framework for spatio-temporal graph},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Provide explainable clues: A generative traceable method for knowledge graph completion. <em>KBS</em>, <em>330</em>, 114426. (<a href='https://doi.org/10.1016/j.knosys.2025.114426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the quality of Knowledge Graph Completion (KGC) results is an essential topic in the field of knowledge graphs. Recently, generative models (GMs) have gained widespread attention for addressing the generalization issues of traditional approaches. However, the black-box nature of generative models often leads to hallucinations, which reduce the model’s performance. Most methods attempt to mitigate this issue through retrieval enhancement and decoding constraints. However, they overlook one major cause of hallucinations–poor explainability. Based on this concept, we propose a G enerative T raceable M ethod, namely GTM, which aims to improve the KGC capability of GMs by exploring the inhibitory effect of explainability on hallucinations. In GTM, a clue tracker is used to find contextual evidence for explainability. In addition, to measure explainability clues, we propose a context-aware analyzer, which enhances the understanding of context through group analogy. In the reasoning phase, we ensure the validity of the generated results by integrating the interpretive capability of clues. Extensive experiments have demonstrated that GTM can adapt to various KGC tasks and significantly enhance the performance of KGC models.},
  archive      = {J_KBS},
  author       = {Ziqi Ma and Jinpeng Li and Hang Yu},
  doi          = {10.1016/j.knosys.2025.114426},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114426},
  shortjournal = {Knowl. Based Syst.},
  title        = {Provide explainable clues: A generative traceable method for knowledge graph completion},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated learning-based stacked capsule auto-encoder network with bidirectional gated recurrent unit for MVNO slicing mechanism in 6G networks. <em>KBS</em>, <em>330</em>, 114414. (<a href='https://doi.org/10.1016/j.knosys.2025.114414'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In comparison to the existing 5 G technology, 6 G technology is intended to give consumers quicker and more dependable data transport. This technology is highly anticipated and is currently experiencing popularity due to its potential to provide massive network capacity, low latency, and a significantly improved user experience. So, this paper proposes a Deep Learning network slicing architecture for 6 G networks that uses federated learning to manage Radio Access Network (RAN) network slices. Ultra-Reliable Low-Latency Communication Plus (URLLC+), Further Enhanced Mobile Broadband (FeMBB), Mobile Edge Computing Slice (MEC-Slice), and Ultra Massive Machine-Type Communication (uMTC) devices are trying to send separate packets to a single base station (BS), where the uplink of a 6 G network is considered. Furthermore, mobile network operators will lease the physical resources of the RAN, such as radio resources, to mobile virtual network operators (MVNOs), allowing MVNOs to install RAN slices in accordance with the services they provide. In this paper, federated learning serves as the foundation for the Stacked Capsule Autoencoder Network with Bidirectional Gated Recurrent Unit (FL_SCA-BiGRU) model slicing mechanism for MVNOs, which interact to enhance the efficiency of allocating communication assets to their customers. In the results section, the proposed model is compared to various models in terms of jitter, quality of service (QoS), energy consumption, latency, throughput, and cost efficiency, and the values obtained are 1.2 ms, 98.9%, 98.4%, 0.2 ms, 980 Mbps, and 98.3%, respectively. The results show the proposed model has a clear edge over all other existing models.},
  archive      = {J_KBS},
  author       = {Megha Jain and Ravi Verma and J. Amudhavel},
  doi          = {10.1016/j.knosys.2025.114414},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114414},
  shortjournal = {Knowl. Based Syst.},
  title        = {Federated learning-based stacked capsule auto-encoder network with bidirectional gated recurrent unit for MVNO slicing mechanism in 6G networks},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User-defined trade-offs in LLM benchmarking: Balancing accuracy, scale, and sustainability. <em>KBS</em>, <em>330</em>, 114405. (<a href='https://doi.org/10.1016/j.knosys.2025.114405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents xLLMBench, a transparent, decision-centric benchmarking framework that empowers decision-makers to rank large language models (LLMs) based on their preferences across diverse, potentially conflicting performance and non-performance criteria, e.g., domain accuracy, model size, energy consumption, CO 2 emissions. Existing LLM benchmarking methods often rely on individual performance criteria (metrics) or human feedback, so methods systematically combining multiple criteria into a single interpretable ranking lack. Methods considering human preferences typically rely on direct human feedback to determine rankings, which can be resource-intensive and not fully aligned with application-specific requirements. Motivated by current limitations of LLM benchmarking, xLLMBench leverages multi-criteria decision-making methods to provide decision-makers with the flexibility to tailor benchmarking processes to their requirements. It focuses on the final step of the benchmarking process (robust analysis of benchmarking results) which in LLMs’ case often involves their ranking. The framework assumes that the selection of datasets, metrics, and LLMs involved in the experiment is conducted following established best practices. We demonstrate xLLMBench’s usefulness in two scenarios: combining LLM results for one metric across different datasets and combining results for multiple metrics within one dataset. Our results show that while some LLMs maintain stable rankings, others exhibit significant changes when correlated datasets are removed, when the focus shifts to contamination-free datasets or fairness metrics. This highlights that LLMs have distinct strengths/weaknesses, going beyond overall performance. Our sensitivity analysis reveals robust rankings, while the diverse visualizations enhance transparency. xLLMBench can be used with existing platforms to support transparent, reproducible, and contextually-meaningful LLM benchmarking.},
  archive      = {J_KBS},
  author       = {Ana Gjorgjevikj and Ana Nikolikj and Barbara Koroušić Seljak and Tome Eftimov},
  doi          = {10.1016/j.knosys.2025.114405},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114405},
  shortjournal = {Knowl. Based Syst.},
  title        = {User-defined trade-offs in LLM benchmarking: Balancing accuracy, scale, and sustainability},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Open-ViTabQA: A novel benchmark for vietnamese question answering on open domain wikipedia table. <em>KBS</em>, <em>330</em>, 114391. (<a href='https://doi.org/10.1016/j.knosys.2025.114391'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents Open-ViTabQA, the first Vietnamese dataset for Table Question Answering (Table QA), addressing the lack of resources for Vietnamese natural language processing. The dataset was meticulously constructed and rigorously validated to ensure high quality. A comprehensive analysis of the structural characteristics of the dataset, including table structure, question types, and answer patterns, is presented. We also introduce BIF, a novel metric combining PhoBERT embeddings within BERTScore for semantic similarity and ViNLI for logical consistency, effectively capturing Vietnamese-specific linguistic nuances and logical coherence. The rigorously validated dataset, accompanied by an analysis of its structural characteristics, provides a robust framework for evaluating Table QA systems. Experiments with pre-trained models and large language models (LLMs) show that ViT5 achieves an F1-score of 45.22 %, an Exact Match (EM) score of 45.13 %, and a BIF score of 0.562. Among large language models, Gemini 2.0 Flash Experimental achieves 60.50 % F1 and 60.20 % EM, while Gemini 1.5 Pro-leads with a BIF score of 0.649, slightly outperforming Gemini 2.0 Flash Experimental (0.644 BIF), indicating more stable reasoning capabilities. However, a significant gap persists compared to human performance (86.49 % F1, 83.43 % EM, 0.781 BIF), highlighting challenges in capturing Vietnamese linguistic subtleties and logical intricacies. These findings underscore opportunities for advancing model performance and addressing data scarcity in Vietnamese Table QA. To facilitate reproducibility and further research, the Open-ViTabQA dataset is publicly accessible for research purposes.},
  archive      = {J_KBS},
  author       = {Dung Hoang Dao and Ngan Thi-Kim Huynh and Khanh Quoc Tran and Kiet Van Nguyen},
  doi          = {10.1016/j.knosys.2025.114391},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114391},
  shortjournal = {Knowl. Based Syst.},
  title        = {Open-ViTabQA: A novel benchmark for vietnamese question answering on open domain wikipedia table},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IRTF: A new tensor factorization for irregular multidimensional data recovery. <em>KBS</em>, <em>330</em>, 114372. (<a href='https://doi.org/10.1016/j.knosys.2025.114372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor factorizations, although serving as paramount tools for exploiting prior knowledge of multidimensional data, are unsuitable for emerging irregular multidimensional data with the arbitrary shape spatial domain (i.e., spatial-irregular tensor), such as superpixels and spatial transcriptomics. Developing new tensor factorizations suitable for spatial-irregular tensors poses a compelling challenge. To meet this challenge, we introduce a novel Irregular Tensor Factorization (IRTF), which can fully capture the intrinsic spatial and channel information behind the spatial-irregular tensor. Concretely, a spatial-irregular tensor can be decomposed into the product of an intrinsic regular tensor, learnable channel transform matrices, and a learnable spatial transform matrix. Accompanying IRTF, we suggest the Total Variation on Channel and Spatial Transforms (TV-CST) to exploit the local information of spatial-irregular tensors, which is hardly excavated by traditional total variation methods. Combining the proposed IRTF and TV-CST, we built a spatial-irregular tensor recovery model. Extensive experiments on real-world spatial-irregular tensors demonstrate the promising performance of our IRTF and its significant advantages on downstream tasks.},
  archive      = {J_KBS},
  author       = {Jin-Yu Xie and Hao Zhang and Xi-Le Zhao and Yi-Si Luo},
  doi          = {10.1016/j.knosys.2025.114372},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114372},
  shortjournal = {Knowl. Based Syst.},
  title        = {IRTF: A new tensor factorization for irregular multidimensional data recovery},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Creative style transfer for image stylization via learning neural permutation. <em>KBS</em>, <em>330</em>, 114368. (<a href='https://doi.org/10.1016/j.knosys.2025.114368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating novel artistic styles from a single style poses a significant challenge for traditional style transfer techniques, which typically focus on emulating the given style without introducing novel, surprising and value elements—fundamental criteria for evaluating creativity. In this paper, we propose Creative Style transFer (CSFer), a new style transfer approach for producing creative artistic styles. We first introduce a neural permutation network (PerNet) to rearrange the feature maps of a single-style image, thus producing new style features. These features are then transferred to the feature maps of a content image, yielding stylized outputs. To evaluate creativity, we employ metrics encompassing style perception distance and artistic aesthetics to assess novelty, surprise, and aesthetic value, respectively. Using this evaluation, we select the most creative style from various stylized results generated via random permutation matrices and an input style. Finally, we effectively train PerNet using both the original and selected creative styles. Extensive experimental results demonstrate that CSFer can generate creative stylized results. Furthermore, CSFer exhibits robust generalization capabilities by seamlessly inserting PerNet into existing style transfer methods.},
  archive      = {J_KBS},
  author       = {Shimin Li and Zedong Zhang and Gan Sun and Li-Wei H. Lehman and Jian Yang and Jun Li},
  doi          = {10.1016/j.knosys.2025.114368},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114368},
  shortjournal = {Knowl. Based Syst.},
  title        = {Creative style transfer for image stylization via learning neural permutation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-driven deep learning network for image splicing forgery detection. <em>KBS</em>, <em>330</em>, 114365. (<a href='https://doi.org/10.1016/j.knosys.2025.114365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image splicing is a widely used technique for manipulating images in various social activities. Detecting splicing forgery is crucial in digital forensics to identify malicious image manipulation and protect information security. However, existing methods for detecting splicing forgery typically learn features in the spatial domain and struggle to effectively capture subtle features indicative of forgery, resulting in insufficient image splicing forgery detection accuracy. To address this challenge, we propose a novel deep-learning network named the frequency-driven deep-learning network (FreNet). Specifically, FreNet comprises three innovative modules: the frequency learnable module (FLM), the spatial-aware frequency learning module (SFLM), and the high-level feature-enhancement module (HFEM). The FLM effectively extracts high- and low-frequency features, thus enhancing frequency-domain representation and capturing subtle tampered features in splicing forgery images. The SFLM utilizes spatial information to guide frequency feature learning, thus enabling spatial-aware frequency feature learning. The HFEM enhances rich contextual and high-level semantic information through multilevel and multipath extraction and fusion. Extensive experiments on five benchmark datasets indicate that FreNet can achieve superior performance. Additionally, robustness experiments demonstrate the superior robustness of FreNet against various common attacks.},
  archive      = {J_KBS},
  author       = {Enji Liang and Kuiyuan Zhang and Zhongyun Hua and Xiaohua Jia},
  doi          = {10.1016/j.knosys.2025.114365},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114365},
  shortjournal = {Knowl. Based Syst.},
  title        = {Frequency-driven deep learning network for image splicing forgery detection},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aspect-level sentiment analysis in social media using a hybrid deep transfer learning approach. <em>KBS</em>, <em>330</em>, 114125. (<a href='https://doi.org/10.1016/j.knosys.2025.114125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, researchers have become interested in aspect-level sentiment analysis. In the traditional sentiment analysis of documents or sentences, a label was assigned to the entire sentence or document. Whereas a sentence or document can have aspects with different sentiments. Although deep learning models have succeeded in aspect-level sentiment analysis, these models require rich labeled datasets in different domains to extract text features and sentiment analysis. This paper uses deep transfer learning for sentiment analysis of aspect-level sentiment analysis (AHDT) of social network data. The backbone of the AHDT model is a version of RoBERTa’s pre-trained deep neural network specially trained to work on social data. The features extracted from the pre-trained RoBERTa network for sentiment analysis are injected into the Bi-GRU deep neural network and then the attention layer. BI-GRU can process sequences from both sides (left to right and vice versa) and extract hidden relationships. In addition, the attention layer allows the model to pay attention to the more influential aspects of the text and provide a better interpretation. Also, this article uses the Class imbalance method to balance for training the model with almost the same polarities. The test results of the AHDT model on four SemEval datasets for the aspect-sentiment analysis task show that the model has improved the F1-score value in Resturan2014, 2015, and 2016 datasets by 0.63, 27.01, and 15.93, respectively. Also, this model has increased the accuracy value in Resturan2015 and 2016 datasets to 9.21 and 0.54, respectively. In addition, the results of experimental tests in all datasets show that the obtained values of accuracy and F1-score are close to each other, which indicates the stability of the AHDT model.},
  archive      = {J_KBS},
  author       = {Kia Jahanbin and Mohammed Ali Zare Chahooki},
  doi          = {10.1016/j.knosys.2025.114125},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114125},
  shortjournal = {Knowl. Based Syst.},
  title        = {Aspect-level sentiment analysis in social media using a hybrid deep transfer learning approach},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
