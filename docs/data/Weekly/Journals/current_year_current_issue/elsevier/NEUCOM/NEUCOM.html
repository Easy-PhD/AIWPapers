<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NEUCOM</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="neucom">NEUCOM - 81</h2>
<ul>
<li><details>
<summary>
(2025). Joint entropy search for multi-objective bayesian optimization with constraints and multiple fidelities. <em>NEUCOM</em>, <em>657</em>, 131674. (<a href='https://doi.org/10.1016/j.neucom.2025.131674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian optimization (BO) methods can be used to solve efficiently problems with several objectives and constraints. Each objective and constraint is considered a black-box function that is expensive to evaluate, lacking a closed-form expression. BO methods use a model of each black-box to guide the search for the problem’s solution. Specifically, they make intelligent decisions about where each black-box function should be evaluated next with the goal of finding the solution using a few evaluations only. Sometimes, however, the black-boxes may be evaluated at different fidelity levels. A lower fidelity is simply a cheap proxy for the corresponding black-box. These lower fidelities correlate with the actual black-boxes to optimize and can, therefore, be used to reduce the overall cost of solving the optimization problem. Here, we propose Multi-fidelity Joint Entropy Search for Multi-objective Bayesian Optimization with Constraints (MF-JESMOC), a BO method for solving the aforementioned problems. MF-JESMOC chooses the next point, and fidelity level at which to evaluate the black-boxes, as the combination that is expected to reduce the most the joint entropy of the Pareto set and the Pareto front, normalized by the fidelity’s evaluation cost. We use Deep Gaussian processes to model each black-box and the dependencies between fidelities. These are powerful probabilistic models that can learn the dependency structure among fidelity levels of each black-box. Several experiments show that MF-JESMOC outperforms other state-of-the-art methods for multi-objective BO with constraints and different fidelity levels in both synthetic and real-world problems.},
  archive      = {J_NEUCOM},
  author       = {Daniel Fernández-Sánchez and Daniel Hernández-Lobato},
  doi          = {10.1016/j.neucom.2025.131674},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131674},
  shortjournal = {Neurocomputing},
  title        = {Joint entropy search for multi-objective bayesian optimization with constraints and multiple fidelities},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). COTA-motion: Controllable image-to-video synthesis with dense semantic trajectories. <em>NEUCOM</em>, <em>657</em>, 131671. (<a href='https://doi.org/10.1016/j.neucom.2025.131671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion transfer, which aims to animate an object in a static image by transferring motion from a reference video, remains a fundamental yet challenging task in content creation. While recent diffusion-based image-to-video models offer fine-grained control over visual appearance, most existing methods rely on ambiguous text prompts or coarse drag-based motion cues, making it difficult to achieve accurate and consistent motion synthesis. To address these limitations, we propose COTA-Motion, a general framework for controllable image-to-video motion transfer. Our method leverages a dense trajectory-based semantic representation extracted from the driving video to provide explicit motion guidance. Specifically, we segment the salient object and extract its point-wise trajectories across frames. These trajectories are enriched with semantic embeddings and reprojected into a spatial-temporal tensor, forming the motion embedding. To utilize this motion representation, we introduce the COTA Adapter, which integrates image content with semantic trajectories via cross-attention, enabling accurate and flexible control over the generated motion. At inference, we further incorporate an alignment module to address discrepancies between the input image and motion cues, ensuring spatial consistency. Built upon a pre-trained video diffusion model, COTA-Motion only requires lightweight fine-tuning on a small set of videos, and it enables high-quality, controllable motion transfer from video to image. Extensive experiments demonstrate the effectiveness of our approach in generating visually coherent and motion-aligned video outputs.},
  archive      = {J_NEUCOM},
  author       = {Yirui Chen and Wenqing Chu and Ye Wu and Jie Yang and Xiaonan Mao and Wei Liu},
  doi          = {10.1016/j.neucom.2025.131671},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131671},
  shortjournal = {Neurocomputing},
  title        = {COTA-motion: Controllable image-to-video synthesis with dense semantic trajectories},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance-barrier-based event-triggered leader–follower consensus control for nonlinear multi-agent systems. <em>NEUCOM</em>, <em>657</em>, 131664. (<a href='https://doi.org/10.1016/j.neucom.2025.131664'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the leader–follower consensus issue for a class of nonlinear multi-agent systems (MASs) by putting forth a novel performance-barrier-based event-triggered control mechanism. First, a leader–follower consensus control law is proposed with a derived stability condition for the MASs, and a performance-barrier-based event-triggering mechanism is integrated to reduce control updates while guaranteeing the desired convergence of the Lyapunov function. Subsequently, the presence of the minimum inter-event time (MIET) is analytically established, reinforcing the practical feasibility of the proposed approach in real-world scenarios. In addition, a dynamic average consensus algorithm is incorporated to extend the strategy to distributed MASs. Finally, simulation results verify that the developed control protocol effectively achieves the prescribed convergence performance with strong robustness.},
  archive      = {J_NEUCOM},
  author       = {Song Gao and Jin-Liang Wang and Shun-Yan Ren and Bei Peng},
  doi          = {10.1016/j.neucom.2025.131664},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131664},
  shortjournal = {Neurocomputing},
  title        = {Performance-barrier-based event-triggered leader–follower consensus control for nonlinear multi-agent systems},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Both reliable and unreliable predictions matter: Domain adaptation for bearing fault diagnosis without source data. <em>NEUCOM</em>, <em>657</em>, 131661. (<a href='https://doi.org/10.1016/j.neucom.2025.131661'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rolling bearing fault diagnosis is crucial for maintaining the reliability and safety of industrial systems. Recently, it has attracted increasing attention to transferring a diagnosis model from the source domain to the target domain without source data in real-world diagnosis scenarios due to confidentiality and efficiency concerns. However, existing approaches are sub-optimal as they simply exploit confidently pseudo-labeled target samples, and simultaneously overlook the intrinsic structural characteristics of the feature space. Besides, the reliability of fault pseudo-labels is always estimated with entropy, whose accuracy could be improved through more sophisticated strategies. To address these issues, we propose to explore the correlation between features and pseudo-labels in the target domain to maintain the balance between feature discriminability and feature diversity. In addition, we develop a voting-based strategy associated with data augmentation for more accurate reliability estimation of fault pseudo-labels. The proposed method is able to utilize both the reliable samples and unreliable samples for diagnosis model transfer via self-supervised training and distribution structure discovering respectively. Extensive experiments on two bearing fault benchmarks demonstrate the effectiveness and superiority of our proposed method. The source code is publicly available at: https://github.com/BdLab405/SDALR .},
  archive      = {J_NEUCOM},
  author       = {Wenyi Wu and Hao Zhang and Zhisen Wei and Xiao-Yuan Jing and Qinghua Zhang and Songsong Wu},
  doi          = {10.1016/j.neucom.2025.131661},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131661},
  shortjournal = {Neurocomputing},
  title        = {Both reliable and unreliable predictions matter: Domain adaptation for bearing fault diagnosis without source data},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neuromorphic binocular framework fusing directional and depth motion cues towards precise collision prediction. <em>NEUCOM</em>, <em>657</em>, 131660. (<a href='https://doi.org/10.1016/j.neucom.2025.131660'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biological studies have significantly advanced our understanding of collision detection, driving improvements in visual systems for safer navigation of mobile intelligent machines. Directionally selective neurons (DSNs), extensively studied in insects like locusts and flies, have inspired computational models that effectively detect specific directional motion cues with low computational demands, making them suitable for real-time applications. Despite these advancements, there remains a gap between biological systems and current computational models. Typically, monocular computational approaches project the three-dimensional world onto two-dimensional representations, resulting in the loss of critical depth information essential for accurately detecting looming objects, i.e., those directly approaching the observer. Consequently, such methods often suffer interference from background motion distractors and nearby translating objects. To address these limitations, we developed a binocular visual framework integrating neuromorphic components, including directionally selective neural networks and depth-disparity computing pathway. This binocular approach enhances looming detection accuracy and improves collision prediction capabilities. Additionally, evolutionary learning techniques were employed to optimize network structures and parameters, prioritizing robustness across diverse real-world scenarios. The resulting binocular model selectively responds to imminent collision trajectories while effectively suppressing peripheral distractors such as near-miss and passing movements. We conducted comprehensive evaluations comparing our proposed framework against a latest binocular neural model across various complex scenarios. Systematic ablation studies further validated the effectiveness and robustness of our approach. The results confirm its potential for deployment in mobile robots and autonomous vehicles, assisting their collision avoidance in real-world applications.},
  archive      = {J_NEUCOM},
  author       = {Chuankai Fang and Haoting Zhou and Renyuan Liu and Qinbing Fu},
  doi          = {10.1016/j.neucom.2025.131660},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131660},
  shortjournal = {Neurocomputing},
  title        = {A neuromorphic binocular framework fusing directional and depth motion cues towards precise collision prediction},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Traffic prediction based on spatio-temporal feature embedding fusion and gate operation optimization. <em>NEUCOM</em>, <em>657</em>, 131658. (<a href='https://doi.org/10.1016/j.neucom.2025.131658'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world traffic prediction problems, there are often complex spatio-temporal features and patterns. To enhance the accuracy and performance of traffic prediction and address these complexities, it is essential to employ effective models and methods to capture spatio-temporal features and patterns of change. For this purpose, we propose a network model that integrates spatio-temporal feature embeddings with gate operation optimization(TSGO). In our model, we design a novel module: the spatio-temporal feature embedding fusion module, which combines input data to strengthen the model’s ability to extract spatio-temporal correlation features, particularly in enhancing temporal features. To further bolster the capture of spatial features, we design an adaptive graph structure learning method based on a node repository, dynamically capturing non-Euclidean spatial correlations within the traffic network. Additionally, to better capture long-term dependence and short-term variations in sequential data, we adopt a new strategy in the Gated Recurrent Unit (GRU): treating the even and odd positions in the input sequence as two separate input streams to generate corresponding update gates and reset gates. This approach enables the model to utilize data more evenly, achieving complementarity between the two sets of features and allowing it to adapt to information at different time scales within the sequential data. In short-term, medium-term, and long-term predictions across three real-world traffic datasets, the TSGO model achieved average MAE reductions of 8.76 %, 10.12 %, and 11.86 %, respectively, compared to the baseline. This demonstrates its capability to generalize across different time scales and significantly improve prediction performance.},
  archive      = {J_NEUCOM},
  author       = {Xiaotong Geng and Fan Zhang and Mingli Zhang and Hua Wang},
  doi          = {10.1016/j.neucom.2025.131658},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131658},
  shortjournal = {Neurocomputing},
  title        = {Traffic prediction based on spatio-temporal feature embedding fusion and gate operation optimization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conditional plane-based multi-scene representation for novel view synthesis. <em>NEUCOM</em>, <em>657</em>, 131657. (<a href='https://doi.org/10.1016/j.neucom.2025.131657'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing explicit and implicit-explicit hybrid neural representations for novel view synthesis are scene-specific. In other words, they represent only a single scene and require retraining for every novel scene. Implicit scene-agnostic methods rely on large multilayer perception (MLP) networks conditioned on learned features. They are computationally expensive during training and rendering times. In contrast, we propose a novel plane-based representation that learns to represent multiple static and dynamic scenes during training and renders per-scene novel views during inference. The method consists of a deformation network, explicit feature planes, and a conditional decoder. Explicit feature planes are used to represent a time-stamped view space volume and a shared canonical volume across multiple scenes. The deformation network learns the deformations across shared canonical object space and time-stamped view space. The conditional decoder estimates the color and density of each scene constrained by a scene-specific latent code. We evaluated and compared the performance of the proposed representation on static (NeRF) and dynamic (Plenoptic videos) datasets. The results show that explicit planes combined with tiny MLPs can efficiently train multiple scenes simultaneously. The project page: https://anonpubcv.github.io/cplanes/ .},
  archive      = {J_NEUCOM},
  author       = {Uchitha Rajapaksha and Hamid Laga and Dean Diepeveen and Mohammed Bennamoun and Ferdous Sohel},
  doi          = {10.1016/j.neucom.2025.131657},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131657},
  shortjournal = {Neurocomputing},
  title        = {Conditional plane-based multi-scene representation for novel view synthesis},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of neural signal decoding based on domain adaptation. <em>NEUCOM</em>, <em>657</em>, 131653. (<a href='https://doi.org/10.1016/j.neucom.2025.131653'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important objective in brain-computer interfaces (BCIs) is to develop robust and reliable neural signal decoders. However, the decoders will encounter challenges under cross-subject or cross-session conditions due to the randomness, non-stationarity, and individual variability of brain electrical activity. Reducing distributional differences is an exceptionally intuitive way to eliminate inter-subject/session differences and enhance decoder generalizability. In this context, domain adaptation (DA) emerges as a valuable technique, enabling the rapid transfer of knowledge acquired from large datasets with labeled data to new subjects or sessions. This paper provides a comprehensive survey of DA research in neural decoding from 2014 to the present. We categorize neural decoding methods related to DA by considering instance-based, feature-based, and model-based, which is motivated by three fundamental challenges in DA: How can one effectively select suitable source domains or samples for transfer? How can inter-domain distributional differences be minimized through feature space transformation? And how can decoder parameters be optimally shared? Additionally, several decoding methods that combine deep learning with DA are highlighted, given the significant advantages of deep learning over traditional feature extraction techniques. Furthermore, our paper explores the application of DA in complex scenarios, such as multiple source domains and low-resource settings. In summary, we have reviewed domain-adaptive decoding algorithms and their application considerations, while identifying various challenges that need to be addressed in future research.},
  archive      = {J_NEUCOM},
  author       = {Suchen Li and Zhuo Tang and Mengmeng Li and Lifang Yang and Zhigang Shang},
  doi          = {10.1016/j.neucom.2025.131653},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131653},
  shortjournal = {Neurocomputing},
  title        = {A survey of neural signal decoding based on domain adaptation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An 80/20 cortical balance stabilizes information-rich dynamics. <em>NEUCOM</em>, <em>657</em>, 131651. (<a href='https://doi.org/10.1016/j.neucom.2025.131651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cortex maintains a remarkably consistent 4:1 ratio between excitatory and inhibitory neurons, yet the computational advantages of such an architecture remain poorly understood. Here, we demonstrate that this ratio optimally stabilizes a dynamical regime characterized by intermittent, burst-like activity, a state associated with maximal information capacity. Using a balanced spiking network model, we show that near the 80:20 ratio, this intermittent regime emerges robustly across a wide range of parameters and with low energy cost. These findings suggest that the canonical cortical E/I ratio is not arbitrary, but that it is functionally tuned to support efficient and flexible computation. Our results provide a dynamical explanation for a long-standing anatomical observation, bridging structural organization and information processing in neural circuits.},
  archive      = {J_NEUCOM},
  author       = {Mozhgan Khanjanianpak and Maryam Pakpour and Matjaž Perc and Alireza Valizadeh},
  doi          = {10.1016/j.neucom.2025.131651},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131651},
  shortjournal = {Neurocomputing},
  title        = {An 80/20 cortical balance stabilizes information-rich dynamics},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study on generalization of random weight network with flat loss. <em>NEUCOM</em>, <em>657</em>, 131650. (<a href='https://doi.org/10.1016/j.neucom.2025.131650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the scheme of learning which adjusts model parameters by minimizing a loss function, there is a conjecture that the loss function with flatter minimum may correlate with better stability and generalization of the model. This paper provides experimental evidence within the Random Weight Network (RWN)/Extreme Learning Machine (ELM) framework and further develops a theoretical analysis linking flatness to the local generalization error upper bound by deriving the RWN loss as a quadratic polynomial with respect to random weights and representing the flatness as the maximum eigenvalue of a semi-positive definite matrix. By adjusting the random weights using a genetic algorithm, where the fitness function is defined as the flatness, we validate on 10 benchmark datasets within the ELM framework that flatter loss indeed improves the model’s generalization ability. The improvement size depends on the specific characteristics of datasets, particularly, on the relative decrease of maximum eigenvalues. This study shows that RWN generalization performance can be improved by optimizing random weight selection.},
  archive      = {J_NEUCOM},
  author       = {Chao Liu and Qiang Liu and Rihao Li and Xinlei Zhou and Mustafa Servet Kiran and Xizhao Wang},
  doi          = {10.1016/j.neucom.2025.131650},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131650},
  shortjournal = {Neurocomputing},
  title        = {A study on generalization of random weight network with flat loss},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view least squares support vector classifiers with the principles of complementarity and consensus. <em>NEUCOM</em>, <em>657</em>, 131647. (<a href='https://doi.org/10.1016/j.neucom.2025.131647'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we examine the multi-view learning framework, which adheres to the principles of complementarity and consensus. Despite significant advances in various support vector machine (SVM)-based multi-view learning methods, many focus exclusively on one of these principles. To bridge this gap, we first introduce the multi-view least squares support vector classifier (MvLSSVC-2C), which effectively minimizes the squares of the differences in decision functions across diverse views while also integrating information from multiple views through a coupling term. Furthermore, we propose a structural information-based model, termed SMvLSSVC-2C, which leverages hierarchical agglomerative clustering to enhance information exchange among views, thereby promoting complementarity and consensus. Meanwhile, by incorporating a weight allocation strategy, adaptive learning is conducted, and the importance of each view is adjusted to adhere to the principle of complementarity. We adopt the alternating optimization method to solve it. The two proposed methods exhibit superior performance, which is demonstrated by theoretical and numerical analysis. Our experimental results demonstrate the effectiveness of the proposed models on diverse datasets, highlighting their enhanced performance in multi-view learning tasks.},
  archive      = {J_NEUCOM},
  author       = {Siyuan Zhang and Qianfei Liu and Mengyang Fan and Weisong Mu and Jianying Feng},
  doi          = {10.1016/j.neucom.2025.131647},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131647},
  shortjournal = {Neurocomputing},
  title        = {Multi-view least squares support vector classifiers with the principles of complementarity and consensus},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KING: An efficient optimization approach. <em>NEUCOM</em>, <em>657</em>, 131645. (<a href='https://doi.org/10.1016/j.neucom.2025.131645'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world engineering optimization problems are often highly challenging due to narrow feasible regions, numerous local optima, and intricate constraints. Metaheuristic algorithms (MAs) have shown promise in addressing these issues owing to their global search capability, flexibility, and adaptability. However, a critical challenge with MAs is effectively balancing the global search (exploration) and local search (exploitation) phases, which significantly influences the efficiency and precision of convergence. Many MAs require problem-specific adjustments to control convergence behavior, thereby increasing computational cost and implementation effort. Moreover, existing improvements are often tailored to specific problems, lacking comprehensive validation in terms of generality, robustness, and scalability. To overcome these limitations, this paper proposes a novel high-performance optimization algorithm with enhanced adaptability, named the Three Kingdoms Optimization Algorithm (KING), inspired by historical dynamics of the Three Kingdoms period in China. We establish an analogy between key components of MAs—such as population initialization, exploration, and exploitation—and four historical phases: the ascent of the might, joint confrontation, three-legged tripod, and whole country united. KING incorporates a new reinforcement convergence mechanism to systematically guide the search process while maintaining an effective balance between exploration and exploitation, enabling rapid and efficient convergence. Additionally, a dynamic, tolerance-based constraint-handling technique is introduced to strengthen its capability in solving complex constrained problems. The performance of KING is extensively evaluated on the IEEE CEC 2017 and IEEE CEC 2022 benchmark test suites, comparing it with classical algorithms, high-performance variants, and state-of-the-art methods across problems of varying scales. Experimental results demonstrate that KING outperforms the compared algorithms in convergence speed, solution accuracy, and stability. Its superiority is further validated through applications to four real-world engineering problems. The proposed algorithm proves to be an effective and reliable tool for engineering optimization. Its source code will be made publicly available at https://aliasgharheidari.com/KING.html and other websites.},
  archive      = {J_NEUCOM},
  author       = {Dong Zhao and Zhen Wang and Yupeng Li and Ali Asghar Heidari and Zongda Wu and Yi Chen and Huiling Chen},
  doi          = {10.1016/j.neucom.2025.131645},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131645},
  shortjournal = {Neurocomputing},
  title        = {KING: An efficient optimization approach},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sensitivity-propagated dual-frequency graph neural network for multivariate time series forecasting. <em>NEUCOM</em>, <em>657</em>, 131644. (<a href='https://doi.org/10.1016/j.neucom.2025.131644'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have become one of the mainstream frameworks in multivariate time series (MTS) forecasting due to their powerful spatio-temporal dependency modeling capability. The process of extracting spatio-temporal features can be summarized into three stages: graph generation, graph convolution, and node updating. However, existing works recognize that the quality of the generated graph significantly impacts model performance, while overlooking that effective node updating can produce richer series representations. Furthermore, existing GNNs exhibit a pronounced bias toward capturing low-frequency temporal patterns, with inadequate attention to high-frequency components. Therefore, we propose SensGCN, a novel dynamic graph spatio-temporal network by introducing the concept of series sensitivity features to optimize the node updating process. Built upon a graph convolutional Gated Recurrent Unit (GRU) framework, SensGCN derives sensitivity features from series volatility patterns under non-autocorrelation conditions. These features subsequently guide node updating after aggregating external series information through graph convolution. Additionally, a novel dynamic graph estimation method is developed that extracts high-frequency components via series decomposition to jointly model time-varying spatial dependencies in MTS data, thereby enhancing GNNs’ capability in learning high-frequency features. Extensive evaluations across five public datasets show that our SensGCN achieves competitive or state-of-the-art performance in both multi-step and single-step forecasting tasks. Notably, in multi-step forecasting with a predefined graph structure, SensGCN achieves the best performance in four out of six cases and consistently attains the lowest MAE, outperforming the best baselines by up to approximately 1.3 %.},
  archive      = {J_NEUCOM},
  author       = {Yaling Xun and Shuo Han and Jianghui Cai and Haifeng Yang and Jifu Zhang},
  doi          = {10.1016/j.neucom.2025.131644},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131644},
  shortjournal = {Neurocomputing},
  title        = {Sensitivity-propagated dual-frequency graph neural network for multivariate time series forecasting},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explaining and interpreting hyperdimensional computing classifiers on tabular data. <em>NEUCOM</em>, <em>657</em>, 131643. (<a href='https://doi.org/10.1016/j.neucom.2025.131643'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the rise in the usage of artificial intelligence models and machine learning approaches in our day-to-day lives, it has become increasingly important to explain these models to increase user trust. Hyperdimensional Computing (HDC) has been introduced as a powerful, energy-efficient algorithmic framework that is intrinsically less opaque than (deep) neural networks. Nevertheless, the possibility of explaining and interpreting the HDC-based classification model has not yet been explored explicitly. Therefore, this work proposes an explanation method and an interpretation method for the HDC-based classification model working with tabular data. The proposed methods have been successfully evaluated on three tabular data sets with a diverse number of samples, features, and classes. Their faithfulness is validated with coherence checks, the deletion and insertion metrics, and a feature ablation study. The results of the proposed explanation method align well with the well-studied LIME explanations.},
  archive      = {J_NEUCOM},
  author       = {Laura Smets and Werner Van Leekwijck and Steven Latré and José Oramas},
  doi          = {10.1016/j.neucom.2025.131643},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131643},
  shortjournal = {Neurocomputing},
  title        = {Explaining and interpreting hyperdimensional computing classifiers on tabular data},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The generative adversarial network combined with noise guidance and global features generates high quality defect samples. <em>NEUCOM</em>, <em>657</em>, 131639. (<a href='https://doi.org/10.1016/j.neucom.2025.131639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous improvement of industrial production intelligence and automation, surface defect detection has become a critical aspect of industrial quality control. However, due to the significantly reduced frequency of surface defects, obtaining sufficient defect data becomes extremely difficult, which limits the performance of deep learning models. To address this challenge, we propose a generative adversarial network (GAN) with noise guidance and global information to generate high-quality defect sample images, thereby enhancing strip detection accuracy. First, the Patch method is used to divide images into blocks, and the feature context of real samples is captured through encoded information. This allows the learning of the potential spatial distribution of real samples, guiding the generator toward directional learning. Second, an adaptive simulated annealing attenuation algorithm is designed to find the global optimal solution of the training process by constraining the minimum temperature stability. Third, a denoising module is introduced to generate high-quality samples by leveraging deep multi-scale feature extraction and residual structures. Experimental results show that, compared to existing advanced models, the proposed method performs well in terms of structural similarity (SSIM) and peak signal-to-noise ratio (PSNR). The method is evaluated on two industrial small sample datasets (GC10-DET and NEU-DET), where it demonstrates particularly strong performance in generating normal images. Furthermore, the generated images are added to the training set as augmented data, improving the performance of three advanced target detection models. Overall, this research offers an effective solution for small sample defect detection in industrial scenarios and holds significant application potential.},
  archive      = {J_NEUCOM},
  author       = {Meishun Wu and Jinmin Peng and Xinyi Yu and Liulu Zhang and Chaoqi Jiang and Wenkai Dong and Liangshen Chen},
  doi          = {10.1016/j.neucom.2025.131639},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131639},
  shortjournal = {Neurocomputing},
  title        = {The generative adversarial network combined with noise guidance and global features generates high quality defect samples},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing continual semantic segmentation with visual explanations and model adaptations. <em>NEUCOM</em>, <em>657</em>, 131637. (<a href='https://doi.org/10.1016/j.neucom.2025.131637'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual Semantic Segmentation (CSS) faces challenges such as catastrophic forgetting, background shift, and limited interpretability, which hinder its real-world deployment. Existing approaches mainly rely on knowledge distillation mechanisms and adaptive pseudo-labeling but struggle with efficiency and generalization. To address these gaps, we propose a novel framework that enhances segmentation accuracy while reducing computational overhead. Our contributions include the use of replay mechanisms with augmented pseudo labels that leverage the unknown class to tackle background shift and mitigate forgetting, as well as the use of modified Atrous Spatial Pyramid Pooling (ASPP) blocks to improve feature extraction without increasing the number of parameters. Additionally, we integrate a visual model explanation loss to enhance interpretability and trust in segmentation decisions. Experimental results on the PASCAL VOC and Cityscapes datasets show that our approach outperforms prior CSS methods by more than 10 % in mIoU score while significantly reducing model size, making it more suitable for real-world applications such as autonomous driving. Further validation in the CARLA simulator demonstrates its feasibility for deployment. The source code is available at https://github.com/daoducmanh194/RRR-CISS .},
  archive      = {J_NEUCOM},
  author       = {Manh Dao and Tuan Linh Dang},
  doi          = {10.1016/j.neucom.2025.131637},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131637},
  shortjournal = {Neurocomputing},
  title        = {Enhancing continual semantic segmentation with visual explanations and model adaptations},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label webpage text classification based on feature segmentation and attention mechanism. <em>NEUCOM</em>, <em>657</em>, 131635. (<a href='https://doi.org/10.1016/j.neucom.2025.131635'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the natural distribution differences of webpage content, multi-label webpage text datasets suffer from the long-tailed label problem. Moreover, the length of multi-label webpage text varies, making it difficult for sequence based deep learning models to set the sequence length. In order to solve the above problems, a feature self segmentation strategy is proposed in this paper, which executes different segmentation strategies for webpage texts of different lengths based on the sequence length of the deep learning model, so as to preserve long webpage texts without introducing too much noisy data for short webpage texts. In addition, by calculating the attention of adjacent segments, calculating the attention of labels and different segments, and constructing the co-attention networks, not only can important content in the document be highlighted, but also content related to labels can be highlighted, which can effectively extract features associated with low-frequency labels and solve the long-tailed label problem. The comparative experimental results on the manually annotated Energy Website Multi-Label Webpage Text dataset and three benchmark multi-label text classification datasets demonstrate that the method constructed in this paper outperforms all baseline methods. The main codes are available at https://github.com/sgysgywaityou/MLWT-FSAM/tree/main/MLWT-FSAM .},
  archive      = {J_NEUCOM},
  author       = {Yanan Cheng and Wenling Li and Zhichao Zhang and Hao Chen and Zhaoxin Zhang},
  doi          = {10.1016/j.neucom.2025.131635},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131635},
  shortjournal = {Neurocomputing},
  title        = {Multi-label webpage text classification based on feature segmentation and attention mechanism},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Density peak clustering via only new upward distance on sub-cluster shared neighbors space without setting cluster centers manually. <em>NEUCOM</em>, <em>657</em>, 131634. (<a href='https://doi.org/10.1016/j.neucom.2025.131634'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density peak clustering (DPC) algorithm is widely applied in data analysis field due to its efficiency and simplicity. However, most improvements to DPC depend on human experience and prior knowledge to identify cluster centers, leading to subjective and inaccurate results. Existing non-prior DPC methods select cluster centers based on the maximum value of the product between local density and upward distance, which ignores the cluster centers of tiny or sparse clusters and identifies the noise and outlier points as cluster centers, resulting in misclassification. In order to address these challenges and provide an accurate method for defining the cluster centers, we propose a DPC algorithm that automatically determines the cluster centers using only new upward distance (NUD) within the sub-cluster shared neighbors space (SSNS). First, sub-clusters are constructed by defining neighbor density and shared neighbor distance. Next, the distance between sub-cluster centers based on shared neighbors is utilized to build the SSNS, reflecting the interconnected nature of sub-clusters. Then, we redefine the upward distance based on SSNS and automatically select cluster centers according to the maximum value of NUD. Furthermore, adaptive threshold filter is applied to adjust parameters and mitigate the effects of noise and outlier points. Finally, sub-clusters are merged based on SSNS similarity, which significantly enhances computational efficiency. Experimental results on synthetic and real datasets show that NUD-SSNS DPC outperforms state-of-the-art methods, achieving improvements of 28 % and 63 % in Fowlkes–Mallows index (FMI) and adjusted rand index (ARI), respectively, while offering computational speed advantage for large-size datasets.},
  archive      = {J_NEUCOM},
  author       = {Jinglong Wang and Jintao Tao and Yu Zhang and Changju Liu and Jiangtao Xu},
  doi          = {10.1016/j.neucom.2025.131634},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131634},
  shortjournal = {Neurocomputing},
  title        = {Density peak clustering via only new upward distance on sub-cluster shared neighbors space without setting cluster centers manually},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid neural network adaptive fuzzy sliding mode online compensatory control for robots with global stability. <em>NEUCOM</em>, <em>657</em>, 131632. (<a href='https://doi.org/10.1016/j.neucom.2025.131632'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to parameter variations, joint friction, and external disturbances, nonlinear robot system models may suffer from modeling inaccuracies or parameter identification difficulties. In addition, traditional control methods make it difficult to estimate the uncertainty of the system model accurately, and the uncertainty of the internal model parameters of the system will also seriously affect the tracking control accuracy of the robot. To solve the above problems, this paper proposes a hybrid neural network adaptive fuzzy sliding mode online compensation control method for robots with global stability. The technique uses an RBF neural network to estimate the uncertainty and dynamically compensates for it by introducing it into an adaptive fuzzy sliding mode controller. Compared to the traditional approximation network, the method ensures the stability of the global consistent final boundedness of the system signals. Also, it achieves the convergence of the neural network weights to the ideal values. To effectively suppress the system jitter, this paper proposes a scheme based on the combination of hyperbolic tangent function sliding mode and fuzzy control. The focus of this paper is on the simulation verification of the proposed control method. The simulation experiment results verify the effectiveness of the proposed method. The accuracy of the integral squared error of the technique in the presence of internal uncertainty and maximum friction moment disturbance is 3.24e-5 rad, which greatly improves the dynamic tracking performance of the robot.},
  archive      = {J_NEUCOM},
  author       = {Guocheng Xiao and Bei Liu and Yufeng Li and Haibin Yin},
  doi          = {10.1016/j.neucom.2025.131632},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131632},
  shortjournal = {Neurocomputing},
  title        = {Hybrid neural network adaptive fuzzy sliding mode online compensatory control for robots with global stability},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grade: Generative graph contrastive learning for multimodal recommendation. <em>NEUCOM</em>, <em>657</em>, 131630. (<a href='https://doi.org/10.1016/j.neucom.2025.131630'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal recommender systems based on graph convolutional networks have made significant progress by integrating multiple modal data for item recommendation. While most existing approaches learn user and item representations through modality-related interaction graphs, these approaches still encounter challenges inherent to graph convolutional networks: over-smoothing. To address this challenge, we propose a model named Grade, G enerative G r aph Contr a stive Learning for Multimo d al R e commendations. It combines generative models and contrastive learning and design four task losses. In particular, the generative graph contrastive task generates contrastive views inter-modal through variational graph reconstruction, effectively aligning modal features to improve user and item representations. In addition, the feature perturbation contrastive task generates multimodal noisy views with interference for intra-modal contrast through noise-based self-supervised learning, effectively enhancing the robustness of modality-specific representations. Finally, we incorporate the Variational Graph Autoencoders (VGAE) task and the Bayesian Personalized Ranking (BPR) task. The combination of these four task losses effectively mitigates the issues of over-smoothing. Extensive experiments conducted on three publicly available datasets confirm the superiority of our model. The related code is available on https://github.com/Ricardo-Ping/Grade .},
  archive      = {J_NEUCOM},
  author       = {Yu-Chao Ping and Shu-Qin Wang and Zi-Yi Yang and Yong-Quan Dong and Meng-Xiang Hu and Pei-Lin Zhang},
  doi          = {10.1016/j.neucom.2025.131630},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131630},
  shortjournal = {Neurocomputing},
  title        = {Grade: Generative graph contrastive learning for multimodal recommendation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GDViT: Group-level decorrelation-based vision transformer for domain generalization. <em>NEUCOM</em>, <em>657</em>, 131624. (<a href='https://doi.org/10.1016/j.neucom.2025.131624'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causality-inspired domain generalization aims to improve model generalization by removing correlations between relevant and irrelevant features. However, a key challenge lies in effectively distinguishing the two. Existing methods, lacking explicit feature grouping, often eliminate all feature correlations indiscriminately, which disrupts the internal structure of relevant features and degrades generalization performance. In this work, we propose a group-level decorrelation-based vision Transformer that explicitly separates features (tokens) into relevant and irrelevant groups. This design preserves the internal correlations within relevant features while removing the correlations between the two groups. To achieve this, we introduce a feature grouping module that guides the separation process, followed by a grouping Transformer encoder that performs inter-group decorrelation, enabling the model to focus more on task-relevant information. Additionally, a supervised contrastive loss is employed to further enhance generalization. Extensive experiments demonstrate that our method significantly improves out-of-distribution performance. Visual analysis further shows that our model suppresses attention to irrelevant features, mitigating spurious correlations and resulting in more stable predictions. Our approach achieves strong performance in both multi-source and single-source domain generalization settings.},
  archive      = {J_NEUCOM},
  author       = {Wenqiang Tang and Zhouwang Yang and Yanzhi Song},
  doi          = {10.1016/j.neucom.2025.131624},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131624},
  shortjournal = {Neurocomputing},
  title        = {GDViT: Group-level decorrelation-based vision transformer for domain generalization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed GNE seeking for aggregative games under event-triggered communication: Predefined-time convergent algorithm design. <em>NEUCOM</em>, <em>657</em>, 131623. (<a href='https://doi.org/10.1016/j.neucom.2025.131623'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the context of distributed generalized Nash equilibrium (GNE) seeking in aggregative games, it is challenging yet interesting to design fast GNE seeking algorithms using energy-efficient communication strategy. However, most existing distributed GNE seeking algorithms can only achieve asymptotic convergence under continuous-time communication setting, resulting in a slower convergence rate and greater consumption of communication resources. In this paper, by exploiting two time-varying gain feedback functions, we present a new kind of distributed GNE seeking algorithm by integrating predefined-time control law with event-triggered communication strategy. It is theoretically shown that the proposed algorithm can solve the predefined-time GNE seeking problem for aggregative games with Zeno behavior being avoided during the seeking process. Compared with the existing algorithms, the present one exhibits several salient features: 1) the convergence time can be preset according to task requirements; 2) the communication resources can be significantly saved by the event-triggered mechanism; and 3) the proposed algorithms exhibit simplicity in their structures and possess the advantage of easy implementability.},
  archive      = {J_NEUCOM},
  author       = {Zhijun Guo and Lingwei Zeng and Jinlei Cheng and Pengwen Xiong and Qian Li},
  doi          = {10.1016/j.neucom.2025.131623},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131623},
  shortjournal = {Neurocomputing},
  title        = {Distributed GNE seeking for aggregative games under event-triggered communication: Predefined-time convergent algorithm design},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FACET–VLM: Facial emotion learning with text-guided multiview fusion via vision-language model for 3D/4D facial expression recognition. <em>NEUCOM</em>, <em>657</em>, 131621. (<a href='https://doi.org/10.1016/j.neucom.2025.131621'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression recognition (FER) in 3D and 4D domains presents a significant challenge in affective computing due to the complexity of spatial and temporal facial dynamics. Its success is crucial for advancing applications in human behavior understanding, healthcare monitoring, and human-computer interaction. In this work, we propose FACET–VLM, a vision–language framework for 3D/4D FER that integrates multiview facial representation learning with semantic guidance from natural language prompts. FACET–VLM introduces three key components: Cross-View Semantic Aggregation (CVSA) for view-consistent fusion, Multiview Text-Guided Fusion (MTGF) for semantically aligned facial emotions, and a multiview consistency loss to enforce structural coherence across views. Our model achieves state-of-the-art accuracy across multiple benchmarks, including BU-3DFE, Bosphorus, BU-4DFE, and BP4D-Spontaneous. We further extend FACET–VLM to 4D micro-expression recognition (MER) on the 4DME dataset, demonstrating strong performance in capturing subtle, short-lived emotional cues. FACET–VLM achieves up to 99.41 % accuracy on BU-4DFE and outperforms prior methods by margins as high as 15.12 % in cross-dataset evaluation on BP4D. The extensive experimental results confirm the effectiveness and substantial contributions of each individual component within the framework. Overall, FACET–VLM offers a robust, extensible, and high-performing solution for multimodal FER in both posed and spontaneous settings.},
  archive      = {J_NEUCOM},
  author       = {Muzammil Behzad},
  doi          = {10.1016/j.neucom.2025.131621},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131621},
  shortjournal = {Neurocomputing},
  title        = {FACET–VLM: Facial emotion learning with text-guided multiview fusion via vision-language model for 3D/4D facial expression recognition},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-based multi-modal MRI analysis with probabilistic attention for stroke lesion detection. <em>NEUCOM</em>, <em>657</em>, 131620. (<a href='https://doi.org/10.1016/j.neucom.2025.131620'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stroke lesion detection in brain MRI remains challenging as existing deep learning methods process single modalities and ignore anatomical boundaries, limiting clinical adoption. We develop a graph-based framework that integrates neuroanatomical priors and multi-modal imaging for automated stroke lesion detection. Our approach uses anatomically-constrained supervoxel generation and graph attention networks with probabilistic attention attribution for interpretable lesion detection. Evaluated on the SOOP dataset (1715 subjects including 1461 stroke patients), our method achieves a Dice coefficient, sensitivity, and ROC-AUC of 0.85 ± 0.03, 0.88, and 0.94, respectively, outperforming CNN baselines by 15 %. The framework provides clinically meaningful attention maps and accurate automated stroke analysis.},
  archive      = {J_NEUCOM},
  author       = {Luis R. Mercado-Diaz and Derek Aguiar and Hugo F. Posada-Quintero},
  doi          = {10.1016/j.neucom.2025.131620},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131620},
  shortjournal = {Neurocomputing},
  title        = {Graph-based multi-modal MRI analysis with probabilistic attention for stroke lesion detection},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LEAD: LLM-enhanced deep reinforcement learning for stable decision-making in critical autonomous driving scenarios. <em>NEUCOM</em>, <em>657</em>, 131619. (<a href='https://doi.org/10.1016/j.neucom.2025.131619'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have demonstrated significant potential in addressing decision-making problems in the field of autonomous driving due to their strong reasoning capabilities. However, deploying LLMs in real-world driving scenarios often encounters challenges such as high computational requirements, elevated costs, and increased latency. On the other hand, Deep Reinforcement Learning (DRL) exhibits strong adaptability to decision-making tasks in autonomous driving with a relatively smaller parameter scale. Nevertheless, DRL agents often suffer from low exploration efficiency and high sensitivity to parameter variations. To address the above issues, we propose an LLM-Enhanced Autonomous Driving (LEAD) training framework, which integrates a high-level agent based on LLMs into the training process of DRL models, effectively improving the policy learning efficiency and generalization capability of DRL models. During the early stage of training, a dynamic intervention mechanism is introduced to identify key decision points within the DRL model, and a predefined expert guidance algorithm is utilized to integrate high-level decision strategies from LLMs into these critical nodes. During the later stage of training, the DRL model transitions into an autonomous optimization phase, where the agent, enhanced with LLM priors, continuously interacts with the environment to further refine the policy network, ultimately surpassing the performance of the LLM-based agent. Experimental results demonstrate that the LEAD-PPO model, built upon the proposed framework, reduces collision rates by 49.49 % and 59.4 % in low-density and high-density scenarios, respectively, during training compared to the baseline model. In the testing phase, the DRL model optimized through LEAD achieves task completion rates that are 9.60 %, 35.94 %, and 65.63 % higher than those of the baseline model in simple, moderate, and difficult scenarios, respectively. Overall, the proposed LEAD framework significantly improves the robustness, sample efficiency, and generalization ability of DRL models.},
  archive      = {J_NEUCOM},
  author       = {Dongwei Xu and Enwen Qiao and Tongcheng Gu and Hongda Fu and Chengju Sun and Haifeng Guo and Yuqing Liu},
  doi          = {10.1016/j.neucom.2025.131619},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131619},
  shortjournal = {Neurocomputing},
  title        = {LEAD: LLM-enhanced deep reinforcement learning for stable decision-making in critical autonomous driving scenarios},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed/Preassigned-time synchronization of delayed fuzzy memristive neural networks with reaction–diffusion terms. <em>NEUCOM</em>, <em>657</em>, 131618. (<a href='https://doi.org/10.1016/j.neucom.2025.131618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to effectively handle the synchronization of reaction–diffusion fuzzy memristive neural networks (MNNs) and shorten their synchronization time has become a worthwhile and meaningful issue to study. This paper mainly studies fixed-time synchronization (FXTS) and preassigned-time synchronization (PATS) problems for delayed fuzzy memristive neural networks (DFMNNs) with reaction–diffusion terms. First, a DFMNNs model with reaction–diffusion terms is introduced, which can effectively describe the spatial distribution characteristics of the network. Second, through the Lyapunov stability theory, the FXTS criterion and the upper limit of the settling-time (ST) are obtained. Subsequently, a state feedback controller is proposed to ensure that the system achieves synchronization within a specified time, and the synchronization time is independent of initial conditions and control parameters, which gives the designed controller a wider range of applications. Finally, two examples are presented to illustrate the effectiveness of the results.},
  archive      = {J_NEUCOM},
  author       = {Hanrui Chen and Dongbing Tong and Qiaoyu Chen},
  doi          = {10.1016/j.neucom.2025.131618},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131618},
  shortjournal = {Neurocomputing},
  title        = {Fixed/Preassigned-time synchronization of delayed fuzzy memristive neural networks with reaction–diffusion terms},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond sparsity: An empirical study of structured collaboration in modular AI. <em>NEUCOM</em>, <em>657</em>, 131616. (<a href='https://doi.org/10.1016/j.neucom.2025.131616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Mixture-of-Experts (MoE) architectures, the prevailing paradigm emphasizes sparse expert activation for computational efficiency. This paper explores an alternative architectural approach centered on structured collaboration, hypothesizing that the quality and nature of inter-module interactions are as significant as computational cost. We present a series of targeted proof-of-concept experiments to validate three distinct principles of structured interaction, inspired by cognitive science. First, we demonstrate that a hierarchical fusion mechanism, modeled on the brain's segregated visual pathways, enhances compositional reasoning on the VQA v2.0 benchmark. Second, by employing a redesigned reinforcement learning task in MiniGrid, we demonstrate that a system-wide differentiated credit assignment (SDCA) mechanism, with conflict detection learned end-to-end, facilitates more robust policy learning. Third, we ascertain that integrating reasoning "tools" as co-adaptive modules offers superior out-of-distribution robustness on the DROP dataset compared to a more powerful baseline agent utilizing external LLM-based tools. Our work provides concrete validation for these principles, highlighting a series of trade-offs between performance, robustness, and efficiency, and suggesting that prioritizing cognitive synergy over simple sparsity offers a promising direction for future research in modular AI.},
  archive      = {J_NEUCOM},
  author       = {Xiaofei Zhou and Soohong Kim and Yiru Wang and Kailin Zhang},
  doi          = {10.1016/j.neucom.2025.131616},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131616},
  shortjournal = {Neurocomputing},
  title        = {Beyond sparsity: An empirical study of structured collaboration in modular AI},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A graph transformer-driven reinforcement learning based on popularity for mining complex network key nodes. <em>NEUCOM</em>, <em>657</em>, 131614. (<a href='https://doi.org/10.1016/j.neucom.2025.131614'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Key nodes in complex networks play a crucial role in maintaining the stability, functionality, and robustness of networked systems. Accordingly, the accurate identification of such nodes is of fundamental importance. Their significance spans multiple domains, including communication systems, transportation infrastructures, life sciences, and social networks. Existing algorithms for key node identification typically rely on heuristic measures or standard deep reinforcement learning frameworks. However, these approaches often suffer from limited feature extraction capabilities, high computational complexity, and insufficient generalizability, and a lack of dynamic adaptability. To overcome these limitations, this study proposes a novel architecture, GTRP (Graph Transformer-Driven Reinforcement Learning Based on Popularity). GTRP extends Epidemic-aware Heterogeneous Graph Transformer (GT) by introducing distinct attention mechanisms for both nodes and edges, enabling the integration of local structural features and global propagation properties. In addition, GTRP incorporates Dual-dynamics Reward Optimization (DR) to identify key nodes based on a network disintegration strategy. The model is trained on randomly generated Barabási–Albert (BA) networks and evaluated on synthetic networks of varying scales as well as multiple real-world network scenarios. Comparative experiments with six representative algorithms demonstrate that GTRP achieves substantial performance improvements—outperforming existing methods by 6.30 % in unweighted networks and 15.90 % in weighted networks. These results underscore the potential of GTRP to advance key node detection in complex network analysis.},
  archive      = {J_NEUCOM},
  author       = {Kaili Wang and Muqing Wu and Min Zhao},
  doi          = {10.1016/j.neucom.2025.131614},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131614},
  shortjournal = {Neurocomputing},
  title        = {A graph transformer-driven reinforcement learning based on popularity for mining complex network key nodes},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CCINet: A cascaded consensus interaction network for co-saliency object detection. <em>NEUCOM</em>, <em>657</em>, 131613. (<a href='https://doi.org/10.1016/j.neucom.2025.131613'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Co-saliency object detection imitates human attention behavior, with the aim of identifying common salient objects in a set of related images. Previous approaches generally suffer from a lack of interaction among the extracted co-saliency information. As a result, the detection maps often turn out to be incomplete or redundant. In this paper, we propose a Cascaded Consensus Interaction Network (CCINet) for co-saliency object detection. This network improves the fusion and interaction among features, thus making full use of the co-saliency information. In the encoding stage, we introduce an Edge Semantic Consensus (ESC) module. It effectively integrates low-level and high-level encoding information. In this way, it is able to capture both fine edge details and rich semantics. Meanwhile, the ESC module refines the co-saliency features, which enhances the detection of co-saliency regions. During the up-sampling stage, the Cascaded Contextual Aggregation (CCA) module employs attention mechanisms, adaptive pooling, and separated-dilated convolution for comprehensive feature extraction. This approach effectively reduces background noise and controls the number of parameters. Extensive experiments indicate that our model outperforms many excellent CoSOD methods in recent years on the three most popular benchmark datasets. Source code is available at: https://github.com/JoeLAL24/CCINet.git .},
  archive      = {J_NEUCOM},
  author       = {Longsheng Wei and Xu Pei and Jiu Huang and Fan Xu},
  doi          = {10.1016/j.neucom.2025.131613},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131613},
  shortjournal = {Neurocomputing},
  title        = {CCINet: A cascaded consensus interaction network for co-saliency object detection},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). K-core-guided adaptive learning and policy optimization for targeted influence maximization in complex networks. <em>NEUCOM</em>, <em>657</em>, 131612. (<a href='https://doi.org/10.1016/j.neucom.2025.131612'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maximizing information propagation in complex networks is essential for shaping public discourse, optimizing marketing strategies, and driving social change. Traditional influence maximization approaches often emphasize network topology, neglecting the critical need to align strategies with user semantics to influence specific user groups effectively. To address this issue, we introduce the Targeted Core-based Q-learning framework (TCQ), a hybrid optimization approach that draws inspiration from evolutionary network structures derived from K-core decomposition, tailored to tackle the problem of targeted influence maximization (TIM). TCQ integrates semantic insights (e.g., interests, demographics, or topical categories) with the network structure by combining a target-based probabilistic scoring function with K-core evolutionary hierarchies, enabling the efficient identification of key influential candidates within the network. Leveraging reinforcement learning, TCQ dynamically optimizes its seed selection policy through a process of exploration and exploitation in order to minimize influence overlap among selected seeds while maintaining adaptability across diverse network scenarios. Extensive experiments on real-world and synthetic networks demonstrate that TCQ not only maximizes targeted influence effectively but also achieves computational efficiency, showcasing its potential for optimizing influence propagation in complex networks.},
  archive      = {J_NEUCOM},
  author       = {Waseem Ahmad and Bang Wang},
  doi          = {10.1016/j.neucom.2025.131612},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131612},
  shortjournal = {Neurocomputing},
  title        = {K-core-guided adaptive learning and policy optimization for targeted influence maximization in complex networks},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient classification and error correction knowledge distillation framework for remaining useful life prediction of bearings in air turbine starter. <em>NEUCOM</em>, <em>657</em>, 131611. (<a href='https://doi.org/10.1016/j.neucom.2025.131611'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prognostics and Health Management (PHM) is critical for industrial equipment maintenance, whose core task is to predict the Remaining Useful Life (RUL) of a system or component accurately. However, traditional deep learning-based approaches often demand significant computational and memory resources, limiting their feasibility for edge deployment. As an effective model compression technique, Knowledge Distillation (KD) has emerged as a core strategy for enabling edge intelligence by transferring knowledge from a teacher model to a lightweight student model. However, traditional KD methods exhibit a high dependency on the teacher model's output. This dependency limits the student model's capacity for autonomous error correction, impairing its distillation performance. To solve these problems, this paper proposes a novel Classification and Error Correction Knowledge Distillation (CEKD) framework. The framework employs Gaussian kernel-based feature entropy to dynamically evaluate teacher models' predictive capabilities, facilitating comprehensive assessment and sample differentiation. Furthermore, the knowledge self-reflection learning strategy extends error correction to continuous dynamic adjustment, enabling deep optimization of complex data. Experimental results on the air turbine starter bearing datasets show that CEKD surpasses KD methods by improving MAE and RMSE by 79.8 % and 78.6 % on average, while reducing memory consumption and inference time by nearly 10 × and 8 × , respectively, enabling deployment on resource-constrained devices.},
  archive      = {J_NEUCOM},
  author       = {Runxia Guo and Jingxu Yi and Xianfeng Luo},
  doi          = {10.1016/j.neucom.2025.131611},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131611},
  shortjournal = {Neurocomputing},
  title        = {An efficient classification and error correction knowledge distillation framework for remaining useful life prediction of bearings in air turbine starter},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Power-law-based preassigned-time bipartite output consensus for heterogeneous multi-agent systems under event-triggered control. <em>NEUCOM</em>, <em>657</em>, 131610. (<a href='https://doi.org/10.1016/j.neucom.2025.131610'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the preassigned-time (PST) bipartite output consensus problem for heterogeneous multi-agent systems (HMASs) using distributed dynamic event-triggered control (DETC). Firstly, based on PST stability lemma, a simpler PST dynamic compensator is developed to attain a novel consensus criterion, which does not require the satisfaction of the Hurwitz stability condition. Subsequently, to reduce the computational burden and the influence of control parameters, through the dynamic compensator, a novel PST control strategy with distributed dynamic event-triggered control is proposed. This control scheme not only removes the limitations of traditional control in terms of infinite control gain but also ensures error dynamics approach zero within preset time. Furthermore, the paper excludes Zeno behavior through a proof by contradiction. Finally, a numerical example is provided to demonstrate the practicality of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Wanli Jin and Huaguang Zhang and Yapeng Yang and Juan Zhang},
  doi          = {10.1016/j.neucom.2025.131610},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131610},
  shortjournal = {Neurocomputing},
  title        = {Power-law-based preassigned-time bipartite output consensus for heterogeneous multi-agent systems under event-triggered control},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite-time lag consensus and finite-time h∞ lag consensus for nonlinear multi-agent systems under communication delay. <em>NEUCOM</em>, <em>657</em>, 131609. (<a href='https://doi.org/10.1016/j.neucom.2025.131609'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, the finite-time lag consensus (FTLC) and finite-time H ∞ lag consensus (FTHLC) problems for first-order multi-agent systems (MASs) are studied. On the one hand, a new state feedback controller considering the communication delay between agents is proposed. Besides, based on several inequality scaling techniques and finite-time stability theory, a sufficient criterion is derived to guarantee the FTLC of MASs. On the other hand, an adaptive state feedback controller and the corresponding adaptive law are put forward, which can also help MASs realize lag consensus in finite time without any additional conditions. Moreover, to address inevitable external disturbances in practice, the proposed control strategies are further enhanced to achieve FTHLC, which further expands the application range of the research results. Finally, the effectiveness of these provided FTLC and FTHLC control schemes in different scenarios is manifested through some numerical simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Song Gao and Jin-Liang Wang and Kun Ling and Shun-Yan Ren and Ming-Zhu Wei and Bei Peng},
  doi          = {10.1016/j.neucom.2025.131609},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131609},
  shortjournal = {Neurocomputing},
  title        = {Finite-time lag consensus and finite-time h∞ lag consensus for nonlinear multi-agent systems under communication delay},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed generalized nash equilibrium computing based on dynamic tracking mechanism for nonsmooth aggregative games over time-varying networks. <em>NEUCOM</em>, <em>657</em>, 131608. (<a href='https://doi.org/10.1016/j.neucom.2025.131608'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the computation of generalized Nash equilibrium in aggregative games with coupling constraints over time-varying networks. The player’s cost objective comprises a differentiable function dependent on the aggregate of all players’ decisions and a possibly non-smooth term with a linear mapping. In this context, designing solution methods for such game formulation is relatively scarce. We thus develop a fully distributed equilibrium-seeking algorithm that accommodates time-varying communication networks while circumventing the need for global decision information. The proposed algorithm synergistically embeds dynamic tracking of aggregate decisions through a consensus-based mechanism with projected pseudo-gradient updates, augmented by a proximal splitting scheme to handle non-smooth components. Theoretically, we establish convergence guarantees to the variational equilibrium through a new operator splitting framework. Finally, numerical experiments are conducted to substantiate the validity of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Liang Ran and Huaqing Li and Zheng Wang and Lifeng Zheng and Jun Li and Zhe Li},
  doi          = {10.1016/j.neucom.2025.131608},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131608},
  shortjournal = {Neurocomputing},
  title        = {Distributed generalized nash equilibrium computing based on dynamic tracking mechanism for nonsmooth aggregative games over time-varying networks},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlocking spatial textures: Gradient-guided pansharpening for enhancing multispectral imagery. <em>NEUCOM</em>, <em>657</em>, 131607. (<a href='https://doi.org/10.1016/j.neucom.2025.131607'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pansharpening aims to integrate the high spatial resolution of panchromatic images (PAN) with the spectral richness of multispectral images (MSI), producing high-resolution multispectral outputs. While deep learning-based approaches have achieved remarkable performance in pansharpening, most methods primarily focus on developing advanced model architectures, often overlooking the potential of manually crafted features. Unlike previous works where gradient information has been primarily utilized in model-based optimization methods, we demonstrate that gradient features derived from the gradient magnitude can provide complementary information that guides the fusion process of PAN and MSI, significantly enhancing pansharpening performance. Specifically, we propose a gradient-guided pansharpening network, termed GGPNet, which consists of two branches: a guidance feature extraction branch that captures gradient features from the gradient magnitude, and a gradient-guided fusion branch that integrates the PAN and MSI with the additional information from gradient features. Within the fusion branch, a multi-image cross-attention block is designed to facilitate the gradual integration of features from images with varying spectral bands and resolutions. Moreover, a gradient loss is introduced to guarantee the effectiveness of the extracted gradient feature information, which is then combined with the widely-used spectral image loss. Extensive experiments on the GaoFen-2 (GF2), QuickBird (QB), and WorldView-3 (WV3) datasets validate the efficacy of our approach, demonstrating its superiority over state-of-the-art methods with substantial improvements in PSNR, ERGAS, and other commonly adopted metrics. The source code will be made publicly available at: https://github.com/sevenzero70/GGPNet_code .},
  archive      = {J_NEUCOM},
  author       = {Lanyue Liang and Tianyu Li and Guoqing Wang and Lin Mei and Xiongxin Tang and Chaofan Qiao and Dongyu Xie},
  doi          = {10.1016/j.neucom.2025.131607},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131607},
  shortjournal = {Neurocomputing},
  title        = {Unlocking spatial textures: Gradient-guided pansharpening for enhancing multispectral imagery},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network-based distributed adaptive synchronization control for multi-weighted complex networks with aperiodic intermittent coupling. <em>NEUCOM</em>, <em>657</em>, 131604. (<a href='https://doi.org/10.1016/j.neucom.2025.131604'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the synchronization control for multi-weighted complex networks (MWCNs) with unknown disturbances and aperiodic intermittent coupling. Firstly, an adaptive neural network strategy is used to approximate the unknown components derived from nonlinear function, while a novel continuous function is proposed by utilizing the idea of time-varying boundary layer technique to deal with the influence of approximation errors. Secondly, different from the continuous coupling and periodic intermittent coupling mechanisms in existing works, an aperiodic intermittent coupling mechanism is taken into consideration in MWCNs. Thirdly, to synchronize MWCNs under aperiodic intermittent coupling, adaptive strategies are developed to adjust coupling strengths and coupling gains based on all edges and partial edges, respectively. Note that these two strategies are fully distributed, i.e., they do not require any global information. Finally, some numerical simulations are provided to verify the effectiveness of theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Bin Zhang and Dan Liu and Binrui Wang and Kaibo Shi},
  doi          = {10.1016/j.neucom.2025.131604},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131604},
  shortjournal = {Neurocomputing},
  title        = {Neural network-based distributed adaptive synchronization control for multi-weighted complex networks with aperiodic intermittent coupling},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective framework with hybrid augmentation for visual reinforcement learning generalization. <em>NEUCOM</em>, <em>657</em>, 131602. (<a href='https://doi.org/10.1016/j.neucom.2025.131602'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current studies in Visual Reinforcement Learning focus on developing policies to acclimate to unknown environments through data augmentation. This paper aims to develop a new methodology to improve upon existing results. To this end, we first categorize existing methods into three groups based on the focus of augmentation: Task-Aware Augmentation, Image-Processing Augmentation, and Image-Scene Augmentation. Subsequently, we establish a unified framework that integrates these three augmentation categories. The core of our framework is hybrid data augmentation, which enhances data diversity. In this framework, we employ hyperspherical space and regularization techniques to address the side effects of such augmentation, specifically the discrepancy between augmented and original data, as well as the instability associated with hybrid augmentation. Finally, we evaluate the proposed framework across three benchmarks, demonstrating its significant advantages over current state-of-the-art methods. Notably, our framework outperforms existing approaches by an average of 4.59 % across 10 tasks in DMC-GB, 28.81 % across 6 tasks in Robosuite, and 20.50 % across 4 tasks in Adroit. The code for our framework will be released at https://github.com/csufangyu/MuHA .},
  archive      = {J_NEUCOM},
  author       = {Yu Fang and Xuehe Zhang and Haoshu Cheng and Xizhe Zang and Changle Li and Jie Zhao},
  doi          = {10.1016/j.neucom.2025.131602},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131602},
  shortjournal = {Neurocomputing},
  title        = {An effective framework with hybrid augmentation for visual reinforcement learning generalization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing robust generalization through appropriate adversarial example attack intensity. <em>NEUCOM</em>, <em>657</em>, 131599. (<a href='https://doi.org/10.1016/j.neucom.2025.131599'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) are notoriously susceptible to adversarial examples. To mitigate the impact of well-designed adversarial attacks on network models, researchers have developed various defense mechanisms, among which adversarial training has emerged as one of the most effective strategies to date. Adversarial training aims to augment training data with adversarial examples, thus giving DNNs a certain degree of robustness to defend against adversarial attacks. However, while obtaining adversarial robustness, this method comes at the cost of reducing the generalization performance, manifested in the reduced classification effect of clean test datasets. Researchers have been actively seeking to counter the balance between adversarial robustness and model generalization. We believe that the key to balancing these two aspects lies in identifying appropriate adversarial examples. Overly potent examples can lead to a decline in clean accuracy, whereas weaker examples may offer limited robustness. Based on our analysis, a new adversarial example generation algorithm called Denoising Projection Gradient Descent (DPGD) was proposed. DPGD adds a purification module and a constraint in generating adversarial examples, the former is used to limit the influence of too strong adversarial examples on model training and the latter is used to ensure the necessary attack intensity. Combining DPGD with the framework of traditional adversarial training, we obtain the Diffusion Adversarial Training (DifAT) approach. To verify the effectiveness of our proposed method, we conducted extensive experiments on benchmark datasets, including CIFAR-10, CIFAR-100, and Tiny-Imagenet. Our results demonstrate the effectiveness of DifAT in improving the robustness of DNNs while maintaining or even improving their generalization performance.},
  archive      = {J_NEUCOM},
  author       = {Xiaoguo Ding and Liangjian Zhang and Qiqi Bao and Yaguan Qian and Bin Wang and Zhaoquan Gu and Yanchun Zhang},
  doi          = {10.1016/j.neucom.2025.131599},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131599},
  shortjournal = {Neurocomputing},
  title        = {Enhancing robust generalization through appropriate adversarial example attack intensity},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User identification based on the topology consistency of cross-layer common neighbors in social network. <em>NEUCOM</em>, <em>657</em>, 131591. (<a href='https://doi.org/10.1016/j.neucom.2025.131591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, it has become a common practice to create multiple accounts on various social networks for online recreation. When accounts in different networks share similar structural features, i . e . , they have topology consistency, they may belong to the same individual. However, having multiple accounts for the same person across different networks can be inconvenient and uncertain, leading to difficulties in accurate recommendations. Therefore, some researchers have focused on identifying users within single network layers, but without involving the information from various network platforms, resulting in identification confusion and reduced algorithm accuracy. This paper proposes a novel topology consistency-based link prediction algorithm (Topology Consistency: TC) for user identification, combining separate layers of a multilayer network into a single-layer network to include more layer information. TC applies topology information from the cross-layer common neighbors produced in layer combination to distinguish target node pairs and utilizes matrix computation to reduce complexity. Furthermore, to address controversial identification situations appearing after layer combination, the edges between the cross-layer common neighbors are innovatively considered. Finally, experimental results in real-world and artificial networks show that TC has superior performance to state-of-the-art algorithms and has applicability and practicality.},
  archive      = {J_NEUCOM},
  author       = {Yujie Yang and Shuai Cao and Long Wang and Dong Liu and Marcus Kaiser},
  doi          = {10.1016/j.neucom.2025.131591},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131591},
  shortjournal = {Neurocomputing},
  title        = {User identification based on the topology consistency of cross-layer common neighbors in social network},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Implementation of linear optics network for pattern recognition task via the generation of continuous variable entangled states. <em>NEUCOM</em>, <em>657</em>, 131588. (<a href='https://doi.org/10.1016/j.neucom.2025.131588'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear optics neural networks or optical neural networks offer potential advantages over traditional electronic neural networks in terms of speed, energy efficiency, scalability, and improved parallelism, particularly for high-bandwidth applications. The use of photonics allows for more compact and integrated neural network designs, potentially enabling the development of larger and more complex networks. A linear optics network is developed to implement a quantum classifier. Indeed, the designed network is a quantum circuit consisting of some Gaussian gates such as displacement, noiseless linear amplification (NLA), squeezer and Green machine. At first, the classical inputs are encoded with the help of position-displacement operator to prepare single-mode coherent states. Then, the amplitudes of the coherent states are amplified by passing through NLA elements followed by squeezer gates that may transform classical coherent states into nonclassical ones. Finally, the transformed coherent states are fed into the Green machine which provides entangled states as the outcome of the network. As a primary goal of this work, the network generates a multi-mode entangled state by applying the displacement operator on the vacuum state encoded classical data. Besides, it is shown that the output state of the circuit may possess squeezing characteristics as another nonclassical feature. In the continuation, as a practical application, the network is implemented to perform some pattern recognition tasks. At first, the Bayes theorem is employed to define discriminant functions to perform a general classification task, then the outcome distribution of the network is utilized to classify some corrupted LEDs that display English letters. Finally, we show that the outcome of the circuit may be manipulated to embed classical neural networks into a continuous-variable variational quantum circuit (VQC). The network is trained via the logistic regression algorithm with the MNIST database. The results show that the digits can be recognized with relatively high accuracy. Ongoing research is focused on developing new linear optical techniques for machine learning, improving the efficiency and scalability of optical networks, and exploring new applications of linear optics in machine learning and quantum computing. Hence, such a quantum circuit may also be used to design novel high-accuracy pattern recognition devices.},
  archive      = {J_NEUCOM},
  author       = {Ebrahim Ghasemian and Mohammad Kazem Tavassoly and Habib Rostami},
  doi          = {10.1016/j.neucom.2025.131588},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131588},
  shortjournal = {Neurocomputing},
  title        = {Implementation of linear optics network for pattern recognition task via the generation of continuous variable entangled states},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning generic and specific prompts with contrastive constraints for multi-task visual scene understanding. <em>NEUCOM</em>, <em>657</em>, 131586. (<a href='https://doi.org/10.1016/j.neucom.2025.131586'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning has emerged as a crucial research direction in the field of computer vision, offering improved performance and efficiency across multiple tasks. Recent studies have incorporated prompt learning into multi-task learning to enhance the interaction between prompt vectors and image representations. However, these studies fail to consider the inter-task and intra-task relations of prompt vectors under multi-task scenarios. To address this issue, we propose learning Generic and Specific Prompts (GSPrompt) with contrastive constraints for multi-task visual scene understanding. Our approach assumes that each task possesses both commonality and individuality, leading us to design two distinct types of prompt vectors: task-generic prompts and task-specific prompts. By constraining the prompt vectors through pulling task-generic prompts and pushing task-specific prompts, we enable multi-task models to learn prompts capable of adapting to multiple tasks simultaneously. Extensive experiments on NYUD-v2, PASCAL-Context, and Cityscapes show that GSPrompt learns effective prompts and achieves state-of-the-art performance. The code is publicly available at https://github.com/teeyohan/GSPrompt-main .},
  archive      = {J_NEUCOM},
  author       = {Tianyu Han and Zhimin Xu and Wanying Li and Haohao Hu and Xinxin He and Song He and Peng Zan and Xiaochen Bo},
  doi          = {10.1016/j.neucom.2025.131586},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131586},
  shortjournal = {Neurocomputing},
  title        = {Learning generic and specific prompts with contrastive constraints for multi-task visual scene understanding},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision-based passenger head detection for carriage crowd density estimation. <em>NEUCOM</em>, <em>657</em>, 131584. (<a href='https://doi.org/10.1016/j.neucom.2025.131584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carriage crowd density monitoring is a key component in developing intelligent transportation systems, such as maglev transportation system. Surveillance images captured by sensors, such as carriage monitoring cameras, serve as a new solution for estimating crowd density inside the carriage due to their wide coverage and real-time updates. In this study, a passenger head detection dataset (PHD) is developed using 3717 images acquired from carriage surveillance. Based on these images, over 67,215 head instances are precisely annotated manually. To address the issue of insufficient feature fusion in existing detection algorithms, an efficient cross-scale feature enhancement (CFE) module is proposed and introduced into the advanced YoloX model. The PHD dataset is, to the best of our knowledge, the first public dataset of surveillance images for carriage crowd density estimation. To prove the usability of the PHD dataset and the validity of the proposed method, 12 different versions of detectors are applied and compared. The results demonstrate the performance of these algorithms in the detection of passenger heads. Our research offers a new approach for carriage crowd density estimation. The dataset is publicly available at: https://github.com/Xujiajing111/PHD .},
  archive      = {J_NEUCOM},
  author       = {Jiajing Xu and Mingda Zhai and Yuan Tian and Jun Wu},
  doi          = {10.1016/j.neucom.2025.131584},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131584},
  shortjournal = {Neurocomputing},
  title        = {Vision-based passenger head detection for carriage crowd density estimation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WaterBox: Weakly supervised underwater instance segmentation and a new benchmark. <em>NEUCOM</em>, <em>657</em>, 131582. (<a href='https://doi.org/10.1016/j.neucom.2025.131582'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Box-supervised instance segmentation has gained increasing attention due to its reliance on weak box annotations, which are considerably less expensive than pixel-wise mask annotations. Despite the advantage, existing methods in this category often struggle in complex underwater scenes, where degraded image quality causes foreground objects to become heavily entangled with the background. To address this issue, we propose WaterBox, a cost-effective box-supervised underwater instance segmentation method. Considering the intrinsic characteristics of underwater imaging, we introduce a novel pairwise loss function that leverages a mixed color affinity map with a dynamic threshold to effectively disambiguate foreground and background boundaries. Additionally, we devise a bounding box refinement strategy that generates tight and accurate bounding boxes for each instance, alleviating the negative impact of imprecise box annotations on segmentation performance. Furthermore, to fill in the gaps caused by data scarcity, we construct the first diver instance segmentation dataset, DSeg, which consists of 2000 underwater images with high-quality instance masks. Extensive experiments on two underwater datasets demonstrate the superiority of our approach over the state-of-the-art (SOTA) weakly supervised methods. The code and dataset will be made publicly available.},
  archive      = {J_NEUCOM},
  author       = {Meng Wu and Yifeng Cui and Rong Min and Shanghang Jiang and Lei Zhang and Jing Yu},
  doi          = {10.1016/j.neucom.2025.131582},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131582},
  shortjournal = {Neurocomputing},
  title        = {WaterBox: Weakly supervised underwater instance segmentation and a new benchmark},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-client GAN-based backdoor attacks for asynchronous federated learning. <em>NEUCOM</em>, <em>657</em>, 131580. (<a href='https://doi.org/10.1016/j.neucom.2025.131580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) enables distributed collaborative training while preserving data privacy; however, it demonstrates significant vulnerability to backdoor attacks. Existing attack methodologies predominantly require control of numerous malicious clients to achieve efficacy and largely neglect asynchronous FL scenarios. In response to these limitations, we propose a novel GAN-based backdoor attack framework capable of injecting effective and covert backdoors with minimal malicious client participation, functioning efficiently across both synchronous and asynchronous environments. Our framework operates effectively with a single malicious client, eliminating the need for coordination among multiple adversarial participants or prior knowledge of benign client data distributions. This reduction in resource requirements enhances the framework's practicality in real-world FL implementations. The malicious client employs a Generative Adversarial Network to synthesize adversarial samples containing predefined triggers, which are subsequently incorporated into local training datasets. The concurrent training on legitimate and triggered data enhances attack effectiveness, while gradient injection—manipulating differences between local and global gradients to introduce strategic noise—facilitates backdoor embedding with improved stealth characteristics. Empirical evaluations demonstrate that in a configuration of 200 clients with a single attacker, our framework achieves attack success rates of 98.66 % on MNIST and 86.29 % on CIFAR-10 datasets. Comprehensive experimentation across both datasets substantiates the framework's effectiveness, imperceptibility, and resilience in synchronous and asynchronous FL environments. This research contributes significant insights into backdoor attack strategies in FL, particularly within asynchronous contexts, and underscores the imperative for developing robust defensive countermeasures.},
  archive      = {J_NEUCOM},
  author       = {Siyu Guan and Chunguang Huang and Hai Cheng},
  doi          = {10.1016/j.neucom.2025.131580},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131580},
  shortjournal = {Neurocomputing},
  title        = {Single-client GAN-based backdoor attacks for asynchronous federated learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UA-PDFL: A personalized approach for decentralized federated learning. <em>NEUCOM</em>, <em>657</em>, 131579. (<a href='https://doi.org/10.1016/j.neucom.2025.131579'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a privacy preserving machine learning paradigm designed to collaboratively learn a global model without data leakage. Specifically, in a typical FL system, the central server solely functions as a coordinator to iteratively aggregate the collected local models trained by each client, potentially introducing single-point transmission bottleneck and security threats. To mitigate this issue, decentralized federated learning (DFL) has been proposed, where all participating clients engage in peer-to-peer communication without a central server. Nonetheless, DFL still suffers from training degradation as FL does due to the non-independent and identically distributed (non-IID) nature of client data. And incorporating personalization layers into DFL may be one of the most effective solutions to alleviate the side effects caused by non-IID data. Therefore, in this paper, we propose a novel unit representation aided personalized decentralized federated learning framework, named UA-PDFL, to deal with the non-IID challenge in DFL. By adaptively adjusting the level of personalization layers through the guidance of the unit representation, UA-PDFL is able to address the varying degrees of data skew. Based on this scheme, client-wise dropout and layer-wise personalization are proposed to further enhance the learning performance of DFL. Extensive experiments empirically prove the effectiveness of our proposed method.},
  archive      = {J_NEUCOM},
  author       = {Hangyu Zhu and Yuxiang Fan and Zhenping Xie},
  doi          = {10.1016/j.neucom.2025.131579},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131579},
  shortjournal = {Neurocomputing},
  title        = {UA-PDFL: A personalized approach for decentralized federated learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning interpretable dynamics: Influence-based clustering of energy consumption time series. <em>NEUCOM</em>, <em>657</em>, 131578. (<a href='https://doi.org/10.1016/j.neucom.2025.131578'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy consumption is governed by dynamic temporal patterns, context, and user behavior. Traditional clustering methods, often operating on raw data, struggle to capture evolving feature relationships and provide interpretable subgroup definitions. To overcome these limitations, we propose a novel framework, Dynamic Influence-Based Clustering , that leverages explainable machine learning (XML) to transform time-series data into an interpretable influence space. Unlike existing approaches that apply XML post-hoc or treat clustering and explanation separately, our framework is the first to jointly optimize influence representation generation and dynamic clustering within a unified mathematical framework. In this space, each data point is represented by a vector of feature contributions to an energy usage prediction, estimated using robust attribution methods such as SHAP or Integrated Gradients applied to predictive models like gradient boosting machines or neural networks. We then introduce a dynamic clustering algorithm that optimizes a composite objective balancing cluster cohesion in the influence space with novel constraints for temporal continuity and contextual alignment—capabilities entirely absent from existing clustering methods. This integrated design enables the robust detection of evolving consumer subgroups and facilitates subgroup transition analysis and anomaly detection. Extensive experiments on two real-world energy datasets demonstrate that our framework produces demonstrably more interpretable, stable, and coherent clusters compared to both standard clustering on raw features and state-of-the-art time-series clustering baselines. The proposed framework provides actionable insights into dynamic energy usage and offers a rigorous foundation for developing interpretable learning systems in time-sensitive domains.},
  archive      = {J_NEUCOM},
  author       = {Binbin Li and Xiufeng Liu and Rongfei Ma and Yuhao Ma},
  doi          = {10.1016/j.neucom.2025.131578},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131578},
  shortjournal = {Neurocomputing},
  title        = {Learning interpretable dynamics: Influence-based clustering of energy consumption time series},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Face clustering using a novel density peaks clustering algorithm. <em>NEUCOM</em>, <em>657</em>, 131576. (<a href='https://doi.org/10.1016/j.neucom.2025.131576'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face clustering remains a challenging task due to the high intra-class variability and uneven density distributions inherent in real-world face datasets. These characteristics often undermine the performance of conventional clustering algorithms. To address these limitations, this paper introduces a novel density-based clustering method, termed DPC-MK (Density Peak Clustering with Mixed k-Nearest Neighbor strategy). Initially, the reverse nearest neighbors and shared nearest neighbors of each sample are identified based on the k-nearest neighbor (KNN) method, and their counts are quantitatively assessed. Subsequently, the distances between each sample and its k-nearest neighbors are computed to evaluate their respective contributions to the local density. The quantified reverse and shared neighbor counts are then integrated with the distance-based density metric to yield an enhanced local density estimate. Using this refined density, the relative distance between each sample and any other point with higher density is computed. A decision graph is then constructed from the modified local density and relative distance values to identify cluster centers. Finally, non-center points are assigned to clusters by following density gradients toward their nearest higher-density neighbors. The results of the ablation study clearly demonstrate the complementary roles of each component as well as the effectiveness of the method we proposed. The efficacy of DPC-MK is further validated on multiple UCI benchmark datasets and public face clustering datasets. Comparative evaluations against baseline and state-of-the-art algorithms—including K-means, DBSCAN, FCM, DPC, DPC-KNN, DPC-NN, DPC-FWSN, and LPMNN-DPC—demonstrate that DPC-MK achieves superior clustering performance and maintains robustness across diverse clustering scenarios and varying cluster counts, highlighting its strong generalization capability.},
  archive      = {J_NEUCOM},
  author       = {Yu Zhou and Jiaoyang Cheng and Jianqiao Long and Jiguang Li and Jiaqing Li and Jichun Li},
  doi          = {10.1016/j.neucom.2025.131576},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131576},
  shortjournal = {Neurocomputing},
  title        = {Face clustering using a novel density peaks clustering algorithm},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel two-stage hybrid feature selection: Exploiting ubiquitous intrinsic feature groups. <em>NEUCOM</em>, <em>657</em>, 131574. (<a href='https://doi.org/10.1016/j.neucom.2025.131574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) has emerged as an important data pre-processing technology to solve the challenging task of data mining. However, most existing FS methods primarily focus on exploiting the independent contributions provided by individual features, while neglecting the critical contributions inherent in ubiquitous intrinsic feature groups. As a result, they may fail to fully capture the potentially valuable information embedded in data. This issue becomes more pronounced in modern large-scale data environments, such as JointCloud, where cross-organizational collaborative data analysis over non-shared datasets is often required. To address this issue, this paper proposes a N ovel T wo- S tage H ybrid FS approach (NTSHFS) that jointly considers the informative contributions of both individual features and collaborative feature groups, enabling a comprehensive evaluation of feature relevance, redundancy and discriminative capability. In the first stage, the correlation coefficient-based co-association matrix (CC-CAM) is developed to ensemble the results obtained by different univariate and structured regularization techniques. Then, a CC-CAM-based embedded FS is proposed to select and rank representative features, achieving strong relevance prioritization and redundancy elimination. In the second stage, a quasi fuzzy-rough set (QFRS) model is designed by integrating the similarity relations at both individual-feature level and multi-feature level through the intersection operation. Based on this model, a QFRS-based filter FS is presented to determine the final feature subset with stronger discriminative capability using internal rankings of feature groups. Experimental results on 24 datasets demonstrate that the proposed approach typically outperforms the compared methods (i.e., achieving an average classification accuracy improvement ranging from 1.77 % to 7.69 %), highlighting its effectiveness, robustness and generalization in data mining.},
  archive      = {J_NEUCOM},
  author       = {Lin Qiu and Xingwei Wang and Bo Yi and Yanpeng Qu and Min Huang and Kaimin Zhang},
  doi          = {10.1016/j.neucom.2025.131574},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131574},
  shortjournal = {Neurocomputing},
  title        = {A novel two-stage hybrid feature selection: Exploiting ubiquitous intrinsic feature groups},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view semi-supervised feature selection with multi-order similarity and tensor learning. <em>NEUCOM</em>, <em>657</em>, 131573. (<a href='https://doi.org/10.1016/j.neucom.2025.131573'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view data has attracted extensive attention because it can better characterize samples, and multi-view semi-supervised feature selection can not only effectively improve multi-view performance, but also maintain the original real structure of the data. To this end, many scholars have proposed various models to achieve this goal. However, most of the existing methods rely on the graph structure constructed from the original data and use the constructed graph as a guide for feature selection. This not only ignores multi-order domain knowledge, but also ignores the high-order relations between views. Therefore, this study effectively integrates multi-order domain information with graph learning, and performs tensor low-rank learning on the graph structure between multiple views. A multi-view semi-supervised feature selection method based on multi-order similarity and tensor learning is proposed, which not only integrates multi-order domain information, but also takes into account the relationship between views. Based on this, we propose an iterative method to solve the objective function and prove the superiority of our method on multiple basic datasets.},
  archive      = {J_NEUCOM},
  author       = {Hangyu Chen and Xijiong Xie and Yujie Xiong},
  doi          = {10.1016/j.neucom.2025.131573},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131573},
  shortjournal = {Neurocomputing},
  title        = {Multi-view semi-supervised feature selection with multi-order similarity and tensor learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature selection via risk-bound utility maximization. <em>NEUCOM</em>, <em>657</em>, 131572. (<a href='https://doi.org/10.1016/j.neucom.2025.131572'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ultimate goal of supervised feature selection is to identify a feature subset that minimizes classification risk. Contemporary methods, however, often rely on heuristic or model-dependent proxy criteria that lack a direct theoretical connection to this fundamental objective. To bridge this gap, we introduce a new feature selection framework that directly optimizes a model-agnostic utility function grounded in statistical learning theory. Our approach defines the utility of a feature subset based on the 1-Wasserstein distance between class-conditional distributions. This metric is theoretically powerful as it can be used to construct an upper bound on the Bayes classification error, allowing us to construct a utility function that is a direct surrogate for this risk bound. We instantiate this framework with a subset search strategy that effectively captures feature interactions by maximizing this risk-bound utility. Extensive experiments on real-world datasets demonstrate that our method not only achieves state-of-the-art classification performance but also demonstrates superior robustness and interpretability, providing a principled and powerful alternative to traditional feature selection methods, confirming our framework’s theoretical soundness.},
  archive      = {J_NEUCOM},
  author       = {Chunxu Cao and Qiang Zhang},
  doi          = {10.1016/j.neucom.2025.131572},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131572},
  shortjournal = {Neurocomputing},
  title        = {Feature selection via risk-bound utility maximization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Projected variable three-term conjugate gradient algorithm for enhancing generalization performance in deep neural network training. <em>NEUCOM</em>, <em>657</em>, 131568. (<a href='https://doi.org/10.1016/j.neucom.2025.131568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning optimization faces a fundamental trade-off between convergence efficiency and generalization. First-order methods such as stochastic gradient descent (SGD) and adaptive moment estimation (Adam) tend to find flatter minima but converge slowly, while higher-order methods converge rapidly but are often drawn to sharp minima that generalize poorly. To address this, we introduce the projected variable three-term conjugate gradient (PVTTCG) algorithm. Motivated by the geometric instabilities in modern networks that use techniques such as batch normalization (BN), PVTTCG integrates an orthogonal projection into the higher-order optimization framework. This mechanism eliminates radial components from the search direction, inherently guiding the optimization toward flatter regions without requiring additional regularization terms or hyperparameters. The effectiveness of PVTTCG is validated across diverse tasks, including language modeling, large-scale image classification, and a real-world engineering application. In complex scenarios, PVTTCG consistently improves upon its higher-order baseline, achieving up to a 3.92 percentage point gain on CIFAR-100 while remaining competitive with leading first-order methods. A systematic analysis reveals that PVTTCG demonstrates superior robustness to batch size variations, particularly excelling at larger batch sizes. This robustness enables the algorithm to process batch sizes up to 2,048 in engineering applications, achieving a 35.9% test loss reduction compared to Adam. These findings establish PVTTCG as an effective solution for bridging the convergence-generalization trade-off.},
  archive      = {J_NEUCOM},
  author       = {Sanghyuk Kim and Hansu Kim and Namwoo Kang and Tae Hee Lee},
  doi          = {10.1016/j.neucom.2025.131568},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131568},
  shortjournal = {Neurocomputing},
  title        = {Projected variable three-term conjugate gradient algorithm for enhancing generalization performance in deep neural network training},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DVC2: Deep video cascade clustering from video structures. <em>NEUCOM</em>, <em>657</em>, 131565. (<a href='https://doi.org/10.1016/j.neucom.2025.131565'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video clustering is a critical unsupervised learning task, where category labels are unavailable, unlike in supervised video classification. The primary challenge is learning meaningful video representations without annotations to effectively group similar videos. Most existing methods extract frame-level features and apply standard clustering algorithms such as K-means, but they often fail to capture temporal relationships inherent in video data. In this paper, we introduce Deep Video Cascade Clustering ( DVC 2 ), a novel unsupervised video learning paradigm. Unlike image-based clustering methods, DVC 2 first learns an initial video representation through frame clustering, which serves as guidance, and then aligns video clustering results with both long-term and short-term structures as well as nearest neighbors. We evaluate DVC 2 on benchmark datasets, including UCF101 and Kinetics-400, achieving state-of-the-art results. Notably, even in annotation-free scenarios where self-supervised learning with K-means already yields reasonable clustering, DVC 2 demonstrates significantly superior performance.},
  archive      = {J_NEUCOM},
  author       = {Zihua Wang and Siya Mi and Yu Zhang},
  doi          = {10.1016/j.neucom.2025.131565},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131565},
  shortjournal = {Neurocomputing},
  title        = {DVC2: Deep video cascade clustering from video structures},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SiFH: Siamese frequency harmonization self-supervised learning for motion forecasting. <em>NEUCOM</em>, <em>657</em>, 131563. (<a href='https://doi.org/10.1016/j.neucom.2025.131563'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion forecasting is a fundamental component of the autonomous driving system and plays an important role in ensuring safety. While supervised learning methods have achieved promising performance in many domains, their model capacity is typically limited by the availability of annotated data. Some previous works have tried to introduce this paradigm into motion forecasting. However, these early studies neglect the task-specific characteristics. To address this, we incorporate two key insights into motion forecasting tasks within the self-supervised paradigm and propose a novel self-supervised motion forecasting framework. First, we design a Frequency Information Harmonization pretext task that explicitly encourages the model to integrate frequency domain features with their time domain counterparts, making them work harmoniously. Second, we introduce an Implicit Scene Alignment task, which enables the model to learn scene-level semantics by aligning masked and unmasked views through shared prototypes. By jointly optimizing these objectives, the model is encouraged to leverage abundant unlabeled data and capture rich spatio-temporal representations. Extensive experiments conducted on the challenging Argoverse 2 and Argoverse 1 benchmarks demonstrate that our proposed model outperforms previous state-of-the-art baselines and can produce more accurate and reliable predictions.},
  archive      = {J_NEUCOM},
  author       = {Chunyu Liu and Zeyu Liu and Tiechui Yao and Shijie Li},
  doi          = {10.1016/j.neucom.2025.131563},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131563},
  shortjournal = {Neurocomputing},
  title        = {SiFH: Siamese frequency harmonization self-supervised learning for motion forecasting},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RosMS-ECDBTM: Efficient channel attention enabled distributed deep learning model for mental state detection using EEG signal. <em>NEUCOM</em>, <em>657</em>, 131559. (<a href='https://doi.org/10.1016/j.neucom.2025.131559'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, mental stress is emerging as a common social problem triggering different health disorders, including nervousness, heart attacks, strokes, and depression. Specifically, the Electroencephalography (EEG) signal, capable of reflecting the variations in brain activity, is highly used for mental state detection. Despite their promising performance, the existing EEG-based detection methods fail to capture the inherent characteristics of highly intricate and nonstationary EEG signals. In order to address the drawbacks of existing methods, this research proposes the Deep Learning model namely, Rosmarus Migrative Search Optimized Efficient channel attention enabled Distributed Bi-directional Long Short-Term Memory (RosMS-ECDBTM) model for precise mental state detection. More specifically, the efficient channel attention facilitates the proposed model to dynamically highlight the important parts of the signal characteristics while suppressing the irrelevant regions. Besides, the distributed DL architecture improves the learning capability and scalability of the proposed model to process the large datasets, through the parallel processing of sequential data. Further, the proposed approach exploits the Rosmarus Migrative Search Optimization (RosMS) algorithm for optimizing the RosMS-ECDBTM architecture, resulting in improving the training process. Ultimately, the proposed model, combining efficient channel attention and distributed learning mechanism, captures the intricate patterns and reduces the computational complexity of mental state detection. In addition, the Hybrid Discrete Wavelet transform (DWT) approach decomposes the EEG signal into several frequency components for capturing the hidden patterns and anomalous states in the EEG signal, providing key insights for improving the mental state detection. Extensive experiments show that the RosMS-ECDBTM method provides superior performance, achieving a high accuracy of 96.78 %, precision of 98.99 %, recall of 95.91 %, and F1-score of 97.42 % for the Mental Stress Detection dataset compared to other state-of-the-art methods. Ultimately, these findings reveal the high learning efficiency of the proposed deep learning approach in enhancing the mental state detection accuracy, significantly contributing to advancing the field of mental health monitoring.},
  archive      = {J_NEUCOM},
  author       = {Mandar Nitin Kakade},
  doi          = {10.1016/j.neucom.2025.131559},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131559},
  shortjournal = {Neurocomputing},
  title        = {RosMS-ECDBTM: Efficient channel attention enabled distributed deep learning model for mental state detection using EEG signal},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient semantic segmentation of remote sensing images through dynamic feature enhancement and multimodal alignment fusion. <em>NEUCOM</em>, <em>657</em>, 131555. (<a href='https://doi.org/10.1016/j.neucom.2025.131555'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal fusion has shown promising applications in integrating information from different modalities. However, existing multimodal fusion approaches in remote sensing face two main challenges: First, multimodal fusion models relying on Convolutional Neural Networks (CNNs) or Visual Transformers (ViTs) have limitations in terms of remote modeling capabilities and computational complexity, while state-space model (SSM)-based fusion models are prone to feature redundancy due to the use of multiple scanning paths, and similarly suffer from high computational complexity. Second, existing methods do not fully address inter-modal heterogeneity, leading to poor multimodal data fusion. To address these issues, we propose an efficient multimodal fusion network, AFMamba, based on the state-space model (SSM) for semantic segmentation of remote sensing images. Specifically, we design the Efficient Dynamic Visual State Space (EDVSS) module, which enhances the efficiency of the standard Mamba model by dynamically improving local features and reducing channel redundancy. Furthermore, we introduce the Cross Attention Alignment Fusion (CAAFM) module, which combines cross-image attention fusion and channel interaction alignment to effectively improve the accuracy and efficiency of cross-modal feature fusion and mitigate feature inconsistency. Experimental results demonstrate that in multimodal hyperspectral image semantic segmentation, the proposed model reduces computational complexity, measured in GFLOPs, by at least 61 % while maintaining a low parameter count, achieving optimal overall accuracy (OA) of around 92 %, and effectively balancing performance and computational efficiency.},
  archive      = {J_NEUCOM},
  author       = {Wenqian Chen and Wendie Yue and Kai Chang and Hongzhi Wang and Kaijun Tan and Xinyu Liu and Xiaoyi Cao},
  doi          = {10.1016/j.neucom.2025.131555},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131555},
  shortjournal = {Neurocomputing},
  title        = {Efficient semantic segmentation of remote sensing images through dynamic feature enhancement and multimodal alignment fusion},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-step minimax Q-learning algorithm for two-player zero-sum markov games. <em>NEUCOM</em>, <em>657</em>, 131552. (<a href='https://doi.org/10.1016/j.neucom.2025.131552'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An interesting iterative procedure is proposed to solve two-player zero-sum Markov games. Under suitable assumptions, the boundedness of the proposed iterates is obtained theoretically. Using results from stochastic approximation, the almost sure convergence of the proposed multi-step minimax Q-learning is obtained theoretically. More specifically, the proposed algorithm converges to the game theoretic optimal value with probability one, when the model information is not known. Numerical simulations authenticate that the proposed algorithm is effective and easy to implement.},
  archive      = {J_NEUCOM},
  author       = {Shreyas S.R. and Antony Vijesh},
  doi          = {10.1016/j.neucom.2025.131552},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131552},
  shortjournal = {Neurocomputing},
  title        = {A multi-step minimax Q-learning algorithm for two-player zero-sum markov games},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constrained multi-agent evasion using deep reinforcement learning. <em>NEUCOM</em>, <em>657</em>, 131550. (<a href='https://doi.org/10.1016/j.neucom.2025.131550'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing effective evasion strategies in pursuit–evasion scenarios is challenging, particularly when the pursuer’s model is unknown and inaccessible. This limitation hinders the application of conventional evasion policy design methods. To overcome this challenge, especially when evaders have constrained maneuverability against unrestricted pursuers, we propose a novel multi-agent evasion algorithm based on deep reinforcement learning. Our approach employs a staged learning framework, progressively guiding evaders from simpler to more complex tasks to refine their evasion strategies. Crucially, our algorithm enables evaders to infer pursuers’ intentions even without prior knowledge of pursuers’ objectives, allowing for optimal decision-making despite mobility constraints. Simulation results demonstrate that our method significantly enhances evasion success, validating the effectiveness of learning-based strategies. Additionally, the algorithm exhibits strong adaptability to environmental changes, ensuring reliable performance across diverse pursuit–evasion scenarios.},
  archive      = {J_NEUCOM},
  author       = {Bowei Yan and Runle Du and Xiaojun Ban and Di Zhou},
  doi          = {10.1016/j.neucom.2025.131550},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131550},
  shortjournal = {Neurocomputing},
  title        = {Constrained multi-agent evasion using deep reinforcement learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STD-explain: Generalizing explanations for spatio-temporal graph convolutional networks based on spatio-temporal decoupled perturbation. <em>NEUCOM</em>, <em>657</em>, 131539. (<a href='https://doi.org/10.1016/j.neucom.2025.131539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal graph convolutional networks utilize an alternating combination of one-dimensional ordinary convolution and graph convolution to extract spatio-temporal features. This alternation intertwines temporal and spatial features closely, leading to a tight coupling between them. The presence of spatio-temporal coupling complicates the analysis of spatio-temporal data, posing challenges for existing explainability algorithms to effectively separate and interpret these intertwined features. Therefore, we propose STD-Explain, an explainable algorithm based on spatio-temporal decoupled perturbation, which employs a two-stage perturbation approach considering subgraph and node-level explanations. Firstly, targeting the spatio-temporal coupling issue in spatio-temporal graph convolutional networks, the algorithm proposes a temporal perturbation algorithm based on Slice Graph and a spatial perturbation algorithm aimed at important subgraph node features. Secondly, to avoid introducing additional semantic information when extracting temporal subgraphs, we propose a method for generating temporal subgraphs in spatio-temporal decoupling, slicing human skeleton sequences with discrete masks to ensure each subsequence maintains spatial structure integrity without introducing additional edges. Furthermore, to ensure the maximum correlation between the interpreted subgraphs and model predictions, we propose a temporal important subgraph discrimination strategy to select the most relevant subgraphs to model predictions. Experimental results demonstrate that STD-Explain performs well in qualitative and quantitative analysis.},
  archive      = {J_NEUCOM},
  author       = {Yanshan Li and Ting Shi and Suixuan He and Zhiyuan Chen and Li Zhang and Rui Yu and Weixin Xie},
  doi          = {10.1016/j.neucom.2025.131539},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131539},
  shortjournal = {Neurocomputing},
  title        = {STD-explain: Generalizing explanations for spatio-temporal graph convolutional networks based on spatio-temporal decoupled perturbation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MGSA: Enhancing transferability of multimodal adversarial attacks via multi-granularity semantic alignment. <em>NEUCOM</em>, <em>657</em>, 131534. (<a href='https://doi.org/10.1016/j.neucom.2025.131534'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision–language pretraining (VLP) models have demonstrated exceptional performance across a wide range of image–text multimodal tasks. Despite their prominence, research confirms that these systems retain significant susceptibility to adversarial manipulation. Existing multimodal adversarial attack methods often fail to fully exploit sample-specific semantic structures, resulting in suboptimal cross-modal alignment and limited transferability of adversarial examples. To overcome this limitation, we propose MGSA—a Multi-Granularity Semantic Alignment Attack framework that enhances adversarial perturbation transferability by jointly disrupting cross-modal semantics at both global and fine-grained levels. MGSA captures coarse-grained alignment using overall representations and fine-grained correspondence by selectively aggregating key image regions and words based on importance. This dual-level joint optimization effectively perturbs both holistic consistency and detailed correspondences, thereby significantly enhancing attack effectiveness in white-box scenarios and transferability to black-box models. Extensive experiments conducted across diverse model architectures and multimodal tasks demonstrate that our method achieves strong performance in white-box settings while significantly improving black-box attack success rates. The results highlight the vulnerability of current VLP models and the effectiveness of our approach in generating transferable and semantically grounded adversarial examples.},
  archive      = {J_NEUCOM},
  author       = {Xinyu Liu and Haohua Zhou and Zhidong Shen and Hui Sun},
  doi          = {10.1016/j.neucom.2025.131534},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131534},
  shortjournal = {Neurocomputing},
  title        = {MGSA: Enhancing transferability of multimodal adversarial attacks via multi-granularity semantic alignment},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). StrongerCenter: Enhancing TransCenter for robust multi-object tracking. <em>NEUCOM</em>, <em>657</em>, 131527. (<a href='https://doi.org/10.1016/j.neucom.2025.131527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based multi-object tracking (MOT) research has made significant progress. The typical representative TransCenter method performs well by combining transformers and center-based object tracking. However, it only focuses on predicting object center coordinates, ignoring scale prediction and ReID. To address these limitations, a novel StrongerCenter framework incorporating motion prediction and ReID is proposed in this paper. To enhance spatial contextual feature representation, we first propose an Enhanced Multi-scale Attention Track Memory (EMATM) module. This module incorporates Convolutional Block Attention Module (CBAM) and deformable convolution for improved feature extraction. Then, a Kalman-Guided Motion Prediction module is designed to estimate the state of objects in scenarios involving non-linear motion, scale variations, or occlusion. To ensure robust long-term tracking under occlusion, we develop a ReID module with detail enhancement that captures both local and global features. Finally, a data association strategy that incorporates awareness of occlusion and cascade matching is designed to further improve the robustness of tracking. Extensive experimental results confirm the advantages of our method on the MOT17 and MOT20 datasets. The comparative results demonstrate that the proposed model outperforms comparable methods. Especially on the MOT17 dataset, our method has improved by 9.5 % in IDF1 and 5.2 % in HOTA.},
  archive      = {J_NEUCOM},
  author       = {Xiangzeng Liu and Heng Liu and Kailai Wang and Bocheng Zhao and Qiguang Miao},
  doi          = {10.1016/j.neucom.2025.131527},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131527},
  shortjournal = {Neurocomputing},
  title        = {StrongerCenter: Enhancing TransCenter for robust multi-object tracking},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Urban multi-domain mixing (UMDMix) based unsupervised domain adaptation for LiDAR semantic segmentation. <em>NEUCOM</em>, <em>657</em>, 131526. (<a href='https://doi.org/10.1016/j.neucom.2025.131526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D semantic maps generated from Light Detection and Ranging (LiDAR) point clouds enable scene understanding in diverse applications such as autonomous driving and urban planning. However, existing deep learning models struggle when tested on different domains, worsened by limited labeled data. Unsupervised Domain Adaptation (UDA) can bridge this gap, but existing UDA methods often face adaptation challenges due to domain shifts arising from variations in the physical environment, data sparsity, and sensor differences. To address these limitations, we propose UMDMix , a novel UDA architecture that operates on the mixing of multiple labeled source domains with unlabeled target domains to make the predictive model robust to cross-domain variations. UMDMix integrates a teacher–student learning scheme to produce a robust teacher model and an adaptable student model. The performance of the teacher model in the source domain is further strengthened by a position-aware loss that assigns greater significance to semantically rich neighborhoods. A combination of entropy regularization and KL-divergence loss in the target domain updates the knowledge of the teacher model to the student model during adaptation. Our extensive experiments across diverse environments show that UMDMix achieves an average improvement of 13 % on minor classes such as bicycle, traffic sign, and person in target domain datasets, outperforming previous State-Of-The-Art (SOTA) UDA methods.},
  archive      = {J_NEUCOM},
  author       = {Anurag Nihal and Pyare Lal and Vaibhav Kumar},
  doi          = {10.1016/j.neucom.2025.131526},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131526},
  shortjournal = {Neurocomputing},
  title        = {Urban multi-domain mixing (UMDMix) based unsupervised domain adaptation for LiDAR semantic segmentation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixtures of posterior and prior variational autoencoders for representation learning and cluster analysis in latent space. <em>NEUCOM</em>, <em>657</em>, 131524. (<a href='https://doi.org/10.1016/j.neucom.2025.131524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cluster analysis aims to identify groups of similar items within an unlabelled dataset. This is particularly challenging in high-dimensional data, necessitating the finding of hidden or latent structure within the data, for which variational methods have proven to be successful. We introduce a generative model based on the variational autoencoder (VAE) that uses a mixture distribution for both the prior and variational posterior components over the latent variables. This pair of distributions means that the algorithm can better capture the underlying structure of the data. We evaluated clustering performance on a set of benchmark datasets. Our proposed model demonstrates superior clustering performance compared with state-of-the-art deep clustering algorithms, as well as demonstrating reasonable reconstruction performance and generation of realistic examples from the latent space.},
  archive      = {J_NEUCOM},
  author       = {Mashfiqul Huq Chowdhury and Yuichi Hirose and Stephen Marsland and Yuan Yao},
  doi          = {10.1016/j.neucom.2025.131524},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131524},
  shortjournal = {Neurocomputing},
  title        = {Mixtures of posterior and prior variational autoencoders for representation learning and cluster analysis in latent space},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network-enhanced asymmetric prescribed performance control for multi-task cooperative navigation of USVs via an adaptive formation structure. <em>NEUCOM</em>, <em>657</em>, 131521. (<a href='https://doi.org/10.1016/j.neucom.2025.131521'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a prescribed performance control algorithm with asymmetric boundary for Unmanned Surface Vehicle (USV) formation to achieve cooperative navigation under marine disturbances. The proposed algorithm consists of a guidance switching mechanism and a robust adaptive control method. In the improved guidance principle, a velocity correction rule is provided to generate accurate reference signals for USVs during path following. Combined with the guidance term, the communication load between controller and actuator is significantly reduced by employing the Dynamic Event-Triggered Mechanism (DETM) with adaptive updating of threshold parameters. By integrating the initial errors into the performance boundary function, the controller can effectively adapt to different initial states. In addition, due to the smooth property of the shifting function, the error oscillation of the system before steady state is effectively suppressed. The Radial Basis Function Neural Networks (RBF-NNs) are utilized to design damping terms, enhancing the anti-interference capability in marine environments and mitigating the effects of nonlinearities in the model. Through the Lyapunov theorem, the Semi-Globally Uniformly Ultimately Bounded (SGUUB) stability of all state variables is guaranteed. Finally, quantitative validation of the algorithm is performed through numerical simulations and comparative analysis. The results demonstrate a control accuracy within 0.5 meters while showing that, compared to Static Event-Triggering Mechanisms (SETM), the DETM reduces control update frequency for surge force and yawing moment by 12.32 % and 18.78 %, respectively.},
  archive      = {J_NEUCOM},
  author       = {Guoqing Zhang and Junji Feng and Shilin Yin and Matthew Montebello},
  doi          = {10.1016/j.neucom.2025.131521},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131521},
  shortjournal = {Neurocomputing},
  title        = {Neural network-enhanced asymmetric prescribed performance control for multi-task cooperative navigation of USVs via an adaptive formation structure},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding neural networks with logarithm determinant entropy estimator. <em>NEUCOM</em>, <em>657</em>, 131520. (<a href='https://doi.org/10.1016/j.neucom.2025.131520'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring entropy and entropy-based informative functionals plays a vital role in many aspects of modern machine learning. However, recent practices find that the commonly used entropy estimators are often ineffective in handling samples with high dimensions. Meanwhile, many of them are expensive in computation and storage. These challenges have severely limited the design of information theory-based methods in machine learning. To address this, we proposed the L o g D e t estimator – a reliable matrix-based entropy estimator based on the logarithm determinant of the statistical quantities. We construct informative functionals of multivariate samples and design tests to ensure they are free from saturation problems in high dimensions. Besides, our method scales linearly in storage with the same computational complexity as the recently proposed α - R e ´ n y i entropy, which makes it more suitable for real-world practices of modern machine learning, such as neural network analysis, feature selection and design optimisation objectives. For application, we utilise this method to analyse the informative behaviour of neural networks, which provides a novel empirical interpretation of neural networks’ Information Bottleneck Theory.},
  archive      = {J_NEUCOM},
  author       = {Zhanghao Zhouyin and Ding Liu},
  doi          = {10.1016/j.neucom.2025.131520},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131520},
  shortjournal = {Neurocomputing},
  title        = {Understanding neural networks with logarithm determinant entropy estimator},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mine-SSD: Dual-threshold set abstraction and radius-adaptive grouping for 3D object detection in open-pit mines. <em>NEUCOM</em>, <em>657</em>, 131507. (<a href='https://doi.org/10.1016/j.neucom.2025.131507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and efficient 3D object detection is essential for ensuring both safety and operational efficiency in open-pit mines. Due to complex scene structures, broad perception ranges, and significant object size variations, existing point-based 3D detection methods face challenges that limit their applicability in open-pit mines. To address these issues, Mine-SSD, a single-stage 3D object detection method, is developed with dual-threshold set abstraction (DT-SA) and a radius-adaptive grouping mechanism. Specifically, a dual-head self-correlation module is introduced to calculate comprehensive importance scores for each point, enhancing the model’s ability to prioritize key features. Using these importance scores, a dual-threshold self-correlative farthest point sampling (DTSC-FPS) method is applied to retain key non-local information points during downsampling in set abstraction (SA). Additionally, a radius-adaptive grouping mechanism is designed to dynamically adjust the candidate point aggregation radius, capturing critical features of unconventional objects and supporting multi-scale feature processing. Finally, a novel regression loss function is constructed to improve prediction accuracy and balanced performance across objects of different sizes, ensuring reliable performance of Mine-SSD in multi-scale detection. Extensive experiments on an open-pit mine dataset validate the effectiveness of Mine-SSD.},
  archive      = {J_NEUCOM},
  author       = {Zhongyu Xie and Yuqian Zhao and Fan Zhang and Biao Luo and Wenliu Hu and Tenghai Qiu},
  doi          = {10.1016/j.neucom.2025.131507},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131507},
  shortjournal = {Neurocomputing},
  title        = {Mine-SSD: Dual-threshold set abstraction and radius-adaptive grouping for 3D object detection in open-pit mines},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust multimodal fault diagnosis for rod pumping systems via temporal convolutional network and multi-task learning. <em>NEUCOM</em>, <em>657</em>, 131499. (<a href='https://doi.org/10.1016/j.neucom.2025.131499'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rod pumping systems (RPSs) are crucial components in oil extraction processes, where accurate automatic fault diagnosis, including both fault detection and fault prediction, plays a pivotal role in ensuring operational efficiency. Existing diagnostic approaches often exhibit limited adaptability to complex and varying operating conditions. To address this limitation, a novel method is proposed based on a multimodal multitask temporal fusion model (MMTF). This approach integrates multimodal information and uses a temporal convolutional network (TCN), effectively capturing long-range temporal dependencies while improving continuity. The model is constructed under a multitask learning framework, featuring a cascaded structure that enables joint learning of detection and prediction tasks. Validation on archival data from the Daqing oil field demonstrates that the MMTF model achieves leading performance in both diagnostic tasks and maintains high stability under adversarial scenarios.},
  archive      = {J_NEUCOM},
  author       = {Shichao Li and Peng Zeng and Dongliang Zheng and Liting Zhang and Haibo Cheng},
  doi          = {10.1016/j.neucom.2025.131499},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131499},
  shortjournal = {Neurocomputing},
  title        = {Robust multimodal fault diagnosis for rod pumping systems via temporal convolutional network and multi-task learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SRDA: Self-regulating distribution alignment based on prompt learning for unsupervised domain adaptation. <em>NEUCOM</em>, <em>657</em>, 131498. (<a href='https://doi.org/10.1016/j.neucom.2025.131498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although large-scale pre-trained vision–language models (VLMs) exhibit significant potential for cross-domain visual tasks, existing prompt-learning-based unsupervised domain adaptation (UDA) methods suffer from source domain overfitting and target domain performance degradation. This paper experimentally demonstrates that conventional prompt learning exhibits insufficient cross-domain generalization due to optimization being heavily biased toward the source distribution. To address this challenge, we propose a Self-regulating Distribution Alignment (SRDA) framework. Its core innovation is a dual-branch collaborative optimization mechanism that dynamically balances cross-domain semantic alignment with pre-trained knowledge preservation. Specifically, the self-regulating multimodal prompt branch incorporates three constraints: semantic consistency regularization, dual-domain collaborative contrastive regularization, and text semantic diversity enhancement. This design suppresses prompt overfitting to the source domain while preserving CLIP’s zero-shot generalization capability. The cross-domain alignment branch introduces dynamic dual-domain feature bank and Cross-domain Collaborative Dual Attention module, achieving fine-grained local semantic calibration through moving average prototypes and a dual-layer attention mechanism. Extensive experiments validate SRDA’s effectiveness on downstream UDA tasks. The code is available at https://github.com/QYw12/SRDA .},
  archive      = {J_NEUCOM},
  author       = {Yang Qu and Jinlong Shi and Yun Cui and Ao Zhang and Suqin Bai and Ye Lu},
  doi          = {10.1016/j.neucom.2025.131498},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131498},
  shortjournal = {Neurocomputing},
  title        = {SRDA: Self-regulating distribution alignment based on prompt learning for unsupervised domain adaptation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault-tolerant synchronization of drive-response memristive competitive neural networks with multiple actuator failures. <em>NEUCOM</em>, <em>657</em>, 131489. (<a href='https://doi.org/10.1016/j.neucom.2025.131489'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the synchronization of drive-response memristive competitive neural networks (MCNNs) under multiple actuator failures is studied through implementing fault-tolerant control scheme. Unlike previous studies, the actuator failures considered in this paper include both bias and effectiveness failures. To address these challenges, a proper mathematical model is first established to capture the impact of actuator failures on control inputs. Subsequently, several sufficient conditions are deduced by designing an appropriate bilayer fault-tolerant controller and constructing a Lyapunov functional to achieve the global exponential synchronization, finite-time synchronization, fixed-time synchronization and predefined-time synchronization respectively. Additionally, the settling time upper bounds for the proposed synchronization methods are determined. In the end, numerical simulations with analysis and comparison are performed to confirm the validity of the proposed results.},
  archive      = {J_NEUCOM},
  author       = {Wenjing Duan and Yanli Huang and Quang Dan Le and Tse Chiu Wong},
  doi          = {10.1016/j.neucom.2025.131489},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131489},
  shortjournal = {Neurocomputing},
  title        = {Fault-tolerant synchronization of drive-response memristive competitive neural networks with multiple actuator failures},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging hyper-interval granules labeling and local mixed neighborhood entropy for semi-supervised feature selection. <em>NEUCOM</em>, <em>657</em>, 131482. (<a href='https://doi.org/10.1016/j.neucom.2025.131482'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real scenarios, most datasets contain only a small number of labeled instances and partial features may be missing. Feature selection based on local neighborhood rough set has received much attention for applications on partially labeled data. However, local neighborhood rough set is susceptible to parameterization and only considers labeled data when evaluating upper and lower approximations. Moreover, training label prediction models and labeling unlabeled instances inevitably introduce labeling errors, which subsequently bias the feature selection results. Based on these topics, in order to fully utilize the unlabeled instances and data with missing features and minimize the negative impact of labeling errors, this paper aims at selecting the informative feature subset from partially labeled data. Firstly, the local neighborhood dependency of partially labeled data is computed based on the local neighborhood rough set. Secondly, an improved hyper-interval granulation and label recovery algorithm based on adaptive local density peak for predicting unlabeled instances is proposed, which is a granular computing-based labeling method, and then the global conditional neighborhood entropy is computed on the completely labeled data. Finally, we develop a semi-supervised feature selection algorithm that combines the local neighborhood dependency and the global conditional neighborhood entropy. Comparative dataset experiments demonstrate superior accuracy of our method with fewer features versus existing semi-supervised algorithms.},
  archive      = {J_NEUCOM},
  author       = {Wenhao Shu and Guojing Liao and Wenbin Qian},
  doi          = {10.1016/j.neucom.2025.131482},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131482},
  shortjournal = {Neurocomputing},
  title        = {Leveraging hyper-interval granules labeling and local mixed neighborhood entropy for semi-supervised feature selection},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label distribution learning with structured manifold subspace. <em>NEUCOM</em>, <em>657</em>, 131481. (<a href='https://doi.org/10.1016/j.neucom.2025.131481'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, label distribution learning (LDL) has been proposed to solve the label ambiguity problem. To alleviate the overwhelming output space of LDL, most of the existing methods explore label correlations at a global or local level through common low-rank assumptions. However, the real-valued label description degrees have more complex correlations, making the low-rank assumption usually not hold. To tackle this issue, the proposed method leverages the label distribution manifold with structured subspaces, aiming for a more compact and accurate output space while preserving the high rank of the label distribution matrix. Specifically, a robust high-order correlation measure for label distributions is defined. Then, we simultaneously infer model parameters and conduct the label subspace clustering through the maximum correlation entropy (MCE) regularization to achieve mutual enhancement. It is further proven that the resulting label correlation matrix exhibits a block-diagonal structure under the assumption of independent subspaces. Extensive experiments on widely used benchmark datasets demonstrate the clear advantages of our proposed algorithm over state-of-the-art LDL methods. The code is accessible at https://github.com/yan-yp/LDL-MCE .},
  archive      = {J_NEUCOM},
  author       = {Yaping Yan and Yunlong Tang and Yongxin Jiang and Songlin Du},
  doi          = {10.1016/j.neucom.2025.131481},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131481},
  shortjournal = {Neurocomputing},
  title        = {Label distribution learning with structured manifold subspace},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double-boundary awareness of shared categories for source-free universal domain adaptation. <em>NEUCOM</em>, <em>657</em>, 131473. (<a href='https://doi.org/10.1016/j.neucom.2025.131473'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-Free Universal Domain Adaptation (SF-UniDA) aims to adapt a pre-trained source model to an unlabeled target domain without access to source data or prior knowledge of cross-domain category shifts. Existing methods focus on distinguishing target-private unknown samples and assigning pseudo-labels to known samples across the entire label space, including both shared and source-private categories as pseudo-labels, for self-training. However, this data-aware pseudo-labeling approach could mistakenly assign known samples to either source-private or target-private categories, making it sensitive to category shifts and potentially introducing errors or mislabeling. In this paper, we propose Double-boundary Awareness Domain Adaptation (DADA), a class-aware framework that partitions the target domain pseudo-label space into shared, potential source-private, and target-private categories. By labeling target-private samples as unknown and filtering out misassigned source-private samples, DADA enhances the quality of target samples and the reliability of pseudo-labels. To achieve this, we introduce Double-bounded Shared Categories Refinement (DSCR) module, which refines shared classes by identifying both source- and target-private categories based on prior class probabilities and the entropy distribution. Additionally, we incorporate Class-Aware Discriminative Learning (CADL) to enhance discrimination between shared and target-private samples across domains. Experiments on four benchmarks demonstrate the effectiveness of DADA, with overall H-score gains of 8.2 % in the OPDA scenario on Digit dataset and accuracy gains of 10.6 % in the PDA scenario on VisDA dataset. Code is available at: https://github.com/W2Wzj/DADA .},
  archive      = {J_NEUCOM},
  author       = {Zhijing Wang and Ji Guo and Xu Sun and Yi Luo and Aiguo Chen},
  doi          = {10.1016/j.neucom.2025.131473},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131473},
  shortjournal = {Neurocomputing},
  title        = {Double-boundary awareness of shared categories for source-free universal domain adaptation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SGN: Stochastic guidance network for sim-to-real generalization. <em>NEUCOM</em>, <em>657</em>, 131468. (<a href='https://doi.org/10.1016/j.neucom.2025.131468'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significant domain differences between synthetic data and real data are a challenging problem for current domain generalized segmentation networks. Therefore, this paper proposes a stochastic guidance network (SGN) for sim-to-real generalization that includes the category reweighting strategy, Multi-scale Feature Fusion Guidance (MSFFG) module and multiple style perturbation modules, which improves the issues caused by the imbalance of the source domain’s sample categories as well as large domain gap. Experimental results show that our SGN can effectively enhance the model’s generalization ability to unseen data. In terms of mean intersection over union (mIoU) metric, compared with SOTA, the SGN improves by 3.86 % and 2.05 % respectively on two real scene-enhanced datasets(Rain_Cityscapes, Foggy_Cityscapes), and an average improvement of 1.48 % on four conventional datasets (BDD100k, Cityscapes, Mapillary, Synthia). Our project can be found at https://githubcom/leo-lab-511/SGN.},
  archive      = {J_NEUCOM},
  author       = {Yao Li and Jinlong Shi and Yun Cui and Dan Xu and Wei Teng and Yan Jiang},
  doi          = {10.1016/j.neucom.2025.131468},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131468},
  shortjournal = {Neurocomputing},
  title        = {SGN: Stochastic guidance network for sim-to-real generalization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IncGridDBC: Incremental density-based clustering with grid partitioning on streaming data. <em>NEUCOM</em>, <em>657</em>, 131460. (<a href='https://doi.org/10.1016/j.neucom.2025.131460'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density-Based Spatial Clustering of Applications with Noise (DBSCAN) is a well-established algorithm, recognized for its ability to discover arbitrarily shaped clusters and detect noise. However, it suffers from a fundamental computational bottleneck in dynamic environments, as new object insertions require reprocessing the entire dataset. This paper proposes a novel method, Incremental Density-Based Clustering with a Grid Graph Structure (IncGridDBC), to address this limitation. The key idea is a grid graph structure, where nodes correspond exclusively to non-empty grid cells that contain objects. This grid graph structure abstracts complex object-level relationships into efficient cell-level connections, enabling IncGridDBC to rapidly identify a minimal subset of potentially affected regions upon a new object insertion. The cluster update process is thereby confined exclusively to this minimal subset, an approach that avoids full dataset scans and significantly reduces computational costs. Importantly, this efficiency gain is not based on approximation; the proposed method guarantees that the final clustering results are identical to those produced by a full re-execution of the standard DBSCAN algorithm. In extensive experiments on six real-world datasets with up to 78 dimensions, IncGridDBC achieved a speedup factor of up to 60 times compared to competing state-of-the-art incremental density-based clustering methods. This experimental validation establishes IncGridDBC as a practical and robust solution for high-performance, real-time analytics in dynamic environments such as the Internet of Things (IoT) and manufacturing.},
  archive      = {J_NEUCOM},
  author       = {Tserenpurev Chuluunsaikhan and Jeong-Hun Kim and Fei Hao and Jong-Hyeok Choi and Aziz Nasridinov},
  doi          = {10.1016/j.neucom.2025.131460},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131460},
  shortjournal = {Neurocomputing},
  title        = {IncGridDBC: Incremental density-based clustering with grid partitioning on streaming data},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disjointed representation learning for better fall recognition. <em>NEUCOM</em>, <em>657</em>, 131451. (<a href='https://doi.org/10.1016/j.neucom.2025.131451'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preprocessing video frames to extract the human ROIs has been widely adopted in many fall recognition tasks, demonstrating improved results compared to approaches that use raw frames. Nonetheless, these methods have limitations because the preprocessing is not optimized alongside the fall events classifier. This leads to high dependence on the quality of preprocessed results and consequently, limited generalization for the classifier in complex environments. In this study, we introduce Disjointed Representation Networks (DisJRNet) as a unified method that is capable of learning a general strategy for separating human and background components. We note that our method only needs raw frames without additional preprocessing steps to obtain human ROIs. DisJRNet first explicitly disjoints convolutional feature maps into two independent components “human” and “background”, and then reassembles them. This enables the model to learn the human-background separation process to obtain a balanced representation, which is useful for recognizing fall events as a result. Also, as the proposed model optimizes feature-level human ROI localization along with the classifier, our model learns more general representations about fall-related movements than existing approaches that use preprocessed data. In experiments, we applied our method to R(2+1)D, which is one of the variants of 3D convolutional neural networks, and achieved state-of-the-art performance on fall video benchmark datasets. Furthermore, by comparing Grad-CAMs, we observe that our model effectively separates the two components while paying more attention to the actual movements related to fall events and reducing background influence as intended.},
  archive      = {J_NEUCOM},
  author       = {Hosang Yu and Sangwook Kim and Byungeun Shon and Jungrae Cho and Dongwon Woo and Ho Young Chung and Sungmoon Jeong},
  doi          = {10.1016/j.neucom.2025.131451},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131451},
  shortjournal = {Neurocomputing},
  title        = {Disjointed representation learning for better fall recognition},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdvOT: Oblivious transfer based on generative adversarial networks against multiple attackers. <em>NEUCOM</em>, <em>657</em>, 131449. (<a href='https://doi.org/10.1016/j.neucom.2025.131449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oblivious Transfer (OT) is crucial in various security protocols, as it serves as a privacy-preserving and secure communication protocol. However, traditional OT protocols often necessitate complex encryption algorithms and involve intricate steps. Given the rapid advancements in artificial intelligence, it is imperative to explore the potential of artificial neural networks in simplifying OT protocols while still meeting stringent security and privacy requirements. To this need, we introduce the Adv ersarial O blivious T ransfer (AdvOT) protocol, which integrates OT with the adversarial learning mechanism of Generative Adversarial Network (GAN). Our approach involves training a neural network model to learn encryption techniques through end-to-end adversarial training, thereby eliminating the reliance on specific algorithms. The AdvOT protocol comprises two phases. Firstly, a Random Oblivious Transfer (ROT) protocol is employed to generate and distribute keys based on the CKKS homomorphic encryption algorithm. Subsequently, neural networks are introduced to replace specific symmetric encryption algorithms and encrypt the messages to be transferred. These neural networks undergo training using the adversarial learning mechanism to develop a symmetric encryption algorithm. Furthermore, to enhance the model, attack networks with varying capabilities are created, resulting in a more secure encryption algorithm capable of withstanding multiple attackers. Experimental results demonstrate that the execution speed of the CKKS-based ROT algorithm is significantly faster compared to the BFV and Paillier algorithms. Moreover, in adversarial network models with multiple attackers, the decryption accuracy for the recipient approaches 100 %, while the accuracy or classification error rate for attackers is approximately 50 %. These findings indicate that the proposed method effectively safeguarded communication between parties from interception.},
  archive      = {J_NEUCOM},
  author       = {Yuke Wang and Zhentian Zhong and Ninghao Liu and Xiaohui Li and Junfeng Wang},
  doi          = {10.1016/j.neucom.2025.131449},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131449},
  shortjournal = {Neurocomputing},
  title        = {AdvOT: Oblivious transfer based on generative adversarial networks against multiple attackers},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Challenges and advancements in modeling shock fronts with physics-informed neural networks: A review and benchmarking study. <em>NEUCOM</em>, <em>657</em>, 131440. (<a href='https://doi.org/10.1016/j.neucom.2025.131440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving partial differential equations (PDEs) with discontinuous solutions—such as shock waves in multiphase viscous flow in porous media—is critical for a wide range of scientific and engineering applications, as they represent sudden changes in physical quantities. Physics-Informed Neural Networks (PINNs), an approach proposed for solving PDEs, encounter significant challenges when applied to such systems. Accurately solving PDEs with discontinuities using PINNs requires specialized techniques to ensure effective solution accuracy and numerical stability. Various methods have been developed to address the challenges of modeling discontinuities within the PINNs framework. This work reviews and benchmarks these approaches across problems of varying complexity, categorizing them into three broad groups, influencing solution accuracy differently. (1) Physics-modification (PM) methods improve accuracy by modifying the system’s physics, such as adding artificial viscosity or enforcing entropy constraints. (2) Loss and training modification (LM) techniques focus on regularizing the loss landscape, often by refining the loss term in high-error regions. (3) Architecture-modification (AM) approaches, on the other hand, propose advanced network designs to handle discontinuities better. A benchmarking study was conducted on two multiphase flow problems in porous media: the classic Buckley-Leverett (BL) problem and a fully coupled system of equations involving shock waves but with varying levels of solution complexity. The findings show that PM and LM approaches can provide accurate solutions for the BL problem by effectively addressing the infinite gradients associated with shock occurrences. In contrast, AM methods failed to effectively resolve the shock waves. When applied to fully coupled PDEs (with more complex loss landscapes), the generalization error in the solutions quickly increased, highlighting the need for ongoing innovation. This study provides a comprehensive review of existing techniques for managing PDE discontinuities using PINNs, offering information on their strengths and limitations. The results underscore the necessity for further research to improve PINNs’ ability to handle complex discontinuities, particularly in more challenging problems with complex loss landscapes. This includes problems involving higher dimensions or multiphysics systems, where current methods often struggle to maintain accuracy and efficiency.},
  archive      = {J_NEUCOM},
  author       = {Jassem Abbasi and Ameya D. Jagtap and Ben Moseley and Aksel Hiorth and Pål Østebø Andersen},
  doi          = {10.1016/j.neucom.2025.131440},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131440},
  shortjournal = {Neurocomputing},
  title        = {Challenges and advancements in modeling shock fronts with physics-informed neural networks: A review and benchmarking study},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SparseSCIGaussian: Sparse snapshot compressed images 3D gaussian splatting. <em>NEUCOM</em>, <em>657</em>, 131422. (<a href='https://doi.org/10.1016/j.neucom.2025.131422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose SparseSCIGaussian, a novel method for achieving high-quality novel view synthesis under sparse input conditions. Previous methods often rely heavily on depth or neural priors, which can lead to generalization challenges and significant quality degradation on complex datasets. These limitations arise primarily from the insufficient scene information available in sparse regular images. To overcome these issues, our approach utilizes images captured through Snapshot Compressive Imaging (SCI) as input. SCI-captured images inherently encode richer scene information compared to regular images, thereby substantially improving the quality of novel view synthesis under sparse input conditions. Moreover, SCI images can be conveniently captured using a software-implemented encoder, making them as accessible as traditional images. Experimental results demonstrate that our method improves 2.65 dB (13.04 %) in PSNR compared to previous methods, and further exhibits the inherent advantages of using SCI images for sparse input novel view synthesis.},
  archive      = {J_NEUCOM},
  author       = {Haoyuan He and Xuan Wang and Nanning Zheng and Caigui Jiang},
  doi          = {10.1016/j.neucom.2025.131422},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131422},
  shortjournal = {Neurocomputing},
  title        = {SparseSCIGaussian: Sparse snapshot compressed images 3D gaussian splatting},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RehearMixup: Improving rehearsal-based continual learning. <em>NEUCOM</em>, <em>657</em>, 131404. (<a href='https://doi.org/10.1016/j.neucom.2025.131404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks often suffer from catastrophic forgetting when learning new tasks, leading to the loss of previously acquired knowledge. To address this issue, rehearsal-based methods have emerged, which involve storing a subset of data from previous tasks and accessing it during the learning of new tasks. Current rehearsal-based methods focus on selecting representative samples to store in memory. However, there is a considerable lack of exploration of how to exploit the data at hand and consider the correlation between tasks or between past and new knowledge to improve performance. Therefore, we propose a simple yet effective approach named RehearMixup that adapts the Mixup technique into rehearsal-based methods, which synthesizes new samples for learning by interpolating data from past or current tasks. Specifically, we introduce three strategies, namely Cross-Mixup , Intra-Memory-Mixup , and Intra-Current-Mixup , based on the inherent characteristics of rehearsal-based methods - involving the memory and new tasks. Through empirical evaluations under various benchmark scenarios, we compare our approach against different rehearsal-based baselines. The results demonstrate that ours, particularly Intra-Current-Mixup , improves accuracy, backward transfer, forward transfer, and enhances the model’s robustness.},
  archive      = {J_NEUCOM},
  author       = {Yan Zhang and Kaiyuan Qi and Dong Wu and Guoqiang Wu and Yilong Yin},
  doi          = {10.1016/j.neucom.2025.131404},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131404},
  shortjournal = {Neurocomputing},
  title        = {RehearMixup: Improving rehearsal-based continual learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A zero-shot high-performance fire detection framework based on large language models. <em>NEUCOM</em>, <em>657</em>, 131403. (<a href='https://doi.org/10.1016/j.neucom.2025.131403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fire detection is crucial for minimizing economic damage and safeguarding human lives. Existing methods, including advanced AI and ML techniques, face challenges such as detecting small fires in complex environments and relying on extensive labeled data for training. This paper proposes a novel zero-shot fire detection framework leveraging large language models (LLMs) and contrastive learning-based image–text pre-training models. The framework introduces an enhanced self-attention mechanism for optimizing image embeddings, diverse prompt generation using GPT-3.5 for improved generalization, and a dynamic threshold calculation method based on statistical analysis to enhance detection accuracy and reliability. The proposed method is tested on the public FLAME dataset and a self-collected dataset. Experimental results demonstrate that the proposed method outperforms state-of-the-art models in detecting small fires within complex backgrounds, achieving better detection performance without the need for any training data. This study highlights the potential of zero-shot learning in fire detection and provides a promising solution for real-world fire detection applications.},
  archive      = {J_NEUCOM},
  author       = {Hongyang Zhao and Yi Liu and Yuhang Han and Xingdong Li and Yanan Guo and Jing Jin},
  doi          = {10.1016/j.neucom.2025.131403},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131403},
  shortjournal = {Neurocomputing},
  title        = {A zero-shot high-performance fire detection framework based on large language models},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hetero-MoE by attention: Three-plus tasks learning solver. <em>NEUCOM</em>, <em>657</em>, 131333. (<a href='https://doi.org/10.1016/j.neucom.2025.131333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning (MTL) stands as a promising sub-field of machine learning, aiming to simultaneously tackle multiple tasks. By leveraging shared representations and structures across diverse tasks, MTL models often exhibit higher data efficiency compared to single-task models across various domains, including recommender system applications, multi-label classification and other AI applications. However, the efficacy of MTL models is sometimes hindered by the multi-causal task conflict problem. To address this challenge, existing research predominantly focuses on enhancing structural designs and the underlying optimizers. Nevertheless, these approaches often fall short in comprehensively mitigating task conflicts, especially in scenarios involving three or more tasks, such as recommender systems. When shared experts contend with excessive task-related information simultaneously, the effective filtration of potentially harmful knowledge becomes challenging. To this end, we propose a novel Heterogeneous Multi-Expert model with an attention layer, termed HMEA. HMEA introduces Heterogeneous Experts as shared experts to decompose signal connections among three or more tasks. Additionally, it integrates an attention layer to further decouple conflicts among mini-tasks within shared experts. The experiments and ablation studies on various standard and synthetic datasets illustrate the effectiveness of HMEA in alleviating the task conflict problem inherent in three-plus task learning systems.},
  archive      = {J_NEUCOM},
  author       = {Dandan Zhang and Guanqi Zeng and Haotian Wu and Hongwen Zhang and Zheng Ye and Yao Yang},
  doi          = {10.1016/j.neucom.2025.131333},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131333},
  shortjournal = {Neurocomputing},
  title        = {Hetero-MoE by attention: Three-plus tasks learning solver},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). T2-cGAN: A new modeling paradigm for joint DEM spatial interpolation and super-resolution reconstruction. <em>NEUCOM</em>, <em>657</em>, 131181. (<a href='https://doi.org/10.1016/j.neucom.2025.131181'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The digital elevation model (DEM) has important application value in the fields of geographic information systems, earth sciences, and path planning. However, due to the limitations of high sampling costs and complex terrain, the acquired DEM data often have the problems such as missing sampling points and low resolution. Current solutions treat these issues as highly dependent linear series tasks, and sequentially perform spatial interpolation and super-resolution reconstruction operations, ignoring the correlation and complementarity between them, which leads to a significant difference between the super-resolution reconstruction results and the real terrain. To solve this problem, we proposed the end-to-end T2-cGAN (task transformer conditional generative adversarial network) by combining DEM spatial interpolation and super-resolution reconstruction tasks, which can directly generate high-quality and high-resolution reconstruction results from low-resolution DEM data that are undersampled and contain missing values. This model can make full use of the shared information in the process of spatial interpolation and super-resolution reconstruction, achieve efficient interaction and collaborative optimization of information, and provide a brand-new idea and method for solving the super-resolution reconstruction task of DEM data. Moreover, the experimental results demonstrate that our proposed T2-cGAN can interpolate and complete the DEM data without adding additional information, while also improving the spatial resolution by 4 times. This research not only provides a practical method for high-resolution DEM modeling in resource-constrained areas, but also offers a new idea for the intelligent processing of DEM data, which is of great value for applications such as geological disaster early warning and urban layout planning.},
  archive      = {J_NEUCOM},
  author       = {Ziqiang Huo and Jiabao Wen and Desheng Chen and Meng Xi and Jiachen Yang},
  doi          = {10.1016/j.neucom.2025.131181},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131181},
  shortjournal = {Neurocomputing},
  title        = {T2-cGAN: A new modeling paradigm for joint DEM spatial interpolation and super-resolution reconstruction},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
