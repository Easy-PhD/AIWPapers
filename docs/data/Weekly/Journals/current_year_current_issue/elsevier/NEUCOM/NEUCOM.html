<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NEUCOM</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="neucom">NEUCOM - 44</h2>
<ul>
<li><details>
<summary>
(2025). GDViT: Group-level decorrelation-based vision transformer for domain generalization. <em>NEUCOM</em>, <em>657</em>, 131624. (<a href='https://doi.org/10.1016/j.neucom.2025.131624'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causality-inspired domain generalization aims to improve model generalization by removing correlations between relevant and irrelevant features. However, a key challenge lies in effectively distinguishing the two. Existing methods, lacking explicit feature grouping, often eliminate all feature correlations indiscriminately, which disrupts the internal structure of relevant features and degrades generalization performance. In this work, we propose a group-level decorrelation-based vision Transformer that explicitly separates features (tokens) into relevant and irrelevant groups. This design preserves the internal correlations within relevant features while removing the correlations between the two groups. To achieve this, we introduce a feature grouping module that guides the separation process, followed by a grouping Transformer encoder that performs inter-group decorrelation, enabling the model to focus more on task-relevant information. Additionally, a supervised contrastive loss is employed to further enhance generalization. Extensive experiments demonstrate that our method significantly improves out-of-distribution performance. Visual analysis further shows that our model suppresses attention to irrelevant features, mitigating spurious correlations and resulting in more stable predictions. Our approach achieves strong performance in both multi-source and single-source domain generalization settings.},
  archive      = {J_NEUCOM},
  author       = {Wenqiang Tang and Zhouwang Yang and Yanzhi Song},
  doi          = {10.1016/j.neucom.2025.131624},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131624},
  shortjournal = {Neurocomputing},
  title        = {GDViT: Group-level decorrelation-based vision transformer for domain generalization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed GNE seeking for aggregative games under event-triggered communication: Predefined-time convergent algorithm design. <em>NEUCOM</em>, <em>657</em>, 131623. (<a href='https://doi.org/10.1016/j.neucom.2025.131623'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the context of distributed generalized Nash equilibrium (GNE) seeking in aggregative games, it is challenging yet interesting to design fast GNE seeking algorithms using energy-efficient communication strategy. However, most existing distributed GNE seeking algorithms can only achieve asymptotic convergence under continuous-time communication setting, resulting in a slower convergence rate and greater consumption of communication resources. In this paper, by exploiting two time-varying gain feedback functions, we present a new kind of distributed GNE seeking algorithm by integrating predefined-time control law with event-triggered communication strategy. It is theoretically shown that the proposed algorithm can solve the predefined-time GNE seeking problem for aggregative games with Zeno behavior being avoided during the seeking process. Compared with the existing algorithms, the present one exhibits several salient features: 1) the convergence time can be preset according to task requirements; 2) the communication resources can be significantly saved by the event-triggered mechanism; and 3) the proposed algorithms exhibit simplicity in their structures and possess the advantage of easy implementability.},
  archive      = {J_NEUCOM},
  author       = {Zhijun Guo and Lingwei Zeng and Jinlei Cheng and Pengwen Xiong and Qian Li},
  doi          = {10.1016/j.neucom.2025.131623},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131623},
  shortjournal = {Neurocomputing},
  title        = {Distributed GNE seeking for aggregative games under event-triggered communication: Predefined-time convergent algorithm design},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-based multi-modal MRI analysis with probabilistic attention for stroke lesion detection. <em>NEUCOM</em>, <em>657</em>, 131620. (<a href='https://doi.org/10.1016/j.neucom.2025.131620'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stroke lesion detection in brain MRI remains challenging as existing deep learning methods process single modalities and ignore anatomical boundaries, limiting clinical adoption. We develop a graph-based framework that integrates neuroanatomical priors and multi-modal imaging for automated stroke lesion detection. Our approach uses anatomically-constrained supervoxel generation and graph attention networks with probabilistic attention attribution for interpretable lesion detection. Evaluated on the SOOP dataset (1715 subjects including 1461 stroke patients), our method achieves a Dice coefficient, sensitivity, and ROC-AUC of 0.85 ± 0.03, 0.88, and 0.94, respectively, outperforming CNN baselines by 15 %. The framework provides clinically meaningful attention maps and accurate automated stroke analysis.},
  archive      = {J_NEUCOM},
  author       = {Luis R. Mercado-Diaz and Derek Aguiar and Hugo F. Posada-Quintero},
  doi          = {10.1016/j.neucom.2025.131620},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131620},
  shortjournal = {Neurocomputing},
  title        = {Graph-based multi-modal MRI analysis with probabilistic attention for stroke lesion detection},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LEAD: LLM-enhanced deep reinforcement learning for stable decision-making in critical autonomous driving scenarios. <em>NEUCOM</em>, <em>657</em>, 131619. (<a href='https://doi.org/10.1016/j.neucom.2025.131619'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have demonstrated significant potential in addressing decision-making problems in the field of autonomous driving due to their strong reasoning capabilities. However, deploying LLMs in real-world driving scenarios often encounters challenges such as high computational requirements, elevated costs, and increased latency. On the other hand, Deep Reinforcement Learning (DRL) exhibits strong adaptability to decision-making tasks in autonomous driving with a relatively smaller parameter scale. Nevertheless, DRL agents often suffer from low exploration efficiency and high sensitivity to parameter variations. To address the above issues, we propose an LLM-Enhanced Autonomous Driving (LEAD) training framework, which integrates a high-level agent based on LLMs into the training process of DRL models, effectively improving the policy learning efficiency and generalization capability of DRL models. During the early stage of training, a dynamic intervention mechanism is introduced to identify key decision points within the DRL model, and a predefined expert guidance algorithm is utilized to integrate high-level decision strategies from LLMs into these critical nodes. During the later stage of training, the DRL model transitions into an autonomous optimization phase, where the agent, enhanced with LLM priors, continuously interacts with the environment to further refine the policy network, ultimately surpassing the performance of the LLM-based agent. Experimental results demonstrate that the LEAD-PPO model, built upon the proposed framework, reduces collision rates by 49.49 % and 59.4 % in low-density and high-density scenarios, respectively, during training compared to the baseline model. In the testing phase, the DRL model optimized through LEAD achieves task completion rates that are 9.60 %, 35.94 %, and 65.63 % higher than those of the baseline model in simple, moderate, and difficult scenarios, respectively. Overall, the proposed LEAD framework significantly improves the robustness, sample efficiency, and generalization ability of DRL models.},
  archive      = {J_NEUCOM},
  author       = {Dongwei Xu and Enwen Qiao and Tongcheng Gu and Hongda Fu and Chengju Sun and Haifeng Guo and Yuqing Liu},
  doi          = {10.1016/j.neucom.2025.131619},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131619},
  shortjournal = {Neurocomputing},
  title        = {LEAD: LLM-enhanced deep reinforcement learning for stable decision-making in critical autonomous driving scenarios},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed/Preassigned-time synchronization of delayed fuzzy memristive neural networks with reaction–diffusion terms. <em>NEUCOM</em>, <em>657</em>, 131618. (<a href='https://doi.org/10.1016/j.neucom.2025.131618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to effectively handle the synchronization of reaction–diffusion fuzzy memristive neural networks (MNNs) and shorten their synchronization time has become a worthwhile and meaningful issue to study. This paper mainly studies fixed-time synchronization (FXTS) and preassigned-time synchronization (PATS) problems for delayed fuzzy memristive neural networks (DFMNNs) with reaction–diffusion terms. First, a DFMNNs model with reaction–diffusion terms is introduced, which can effectively describe the spatial distribution characteristics of the network. Second, through the Lyapunov stability theory, the FXTS criterion and the upper limit of the settling-time (ST) are obtained. Subsequently, a state feedback controller is proposed to ensure that the system achieves synchronization within a specified time, and the synchronization time is independent of initial conditions and control parameters, which gives the designed controller a wider range of applications. Finally, two examples are presented to illustrate the effectiveness of the results.},
  archive      = {J_NEUCOM},
  author       = {Hanrui Chen and Dongbing Tong and Qiaoyu Chen},
  doi          = {10.1016/j.neucom.2025.131618},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131618},
  shortjournal = {Neurocomputing},
  title        = {Fixed/Preassigned-time synchronization of delayed fuzzy memristive neural networks with reaction–diffusion terms},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond sparsity: An empirical study of structured collaboration in modular AI. <em>NEUCOM</em>, <em>657</em>, 131616. (<a href='https://doi.org/10.1016/j.neucom.2025.131616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Mixture-of-Experts (MoE) architectures, the prevailing paradigm emphasizes sparse expert activation for computational efficiency. This paper explores an alternative architectural approach centered on structured collaboration, hypothesizing that the quality and nature of inter-module interactions are as significant as computational cost. We present a series of targeted proof-of-concept experiments to validate three distinct principles of structured interaction, inspired by cognitive science. First, we demonstrate that a hierarchical fusion mechanism, modeled on the brain's segregated visual pathways, enhances compositional reasoning on the VQA v2.0 benchmark. Second, by employing a redesigned reinforcement learning task in MiniGrid, we demonstrate that a system-wide differentiated credit assignment (SDCA) mechanism, with conflict detection learned end-to-end, facilitates more robust policy learning. Third, we ascertain that integrating reasoning "tools" as co-adaptive modules offers superior out-of-distribution robustness on the DROP dataset compared to a more powerful baseline agent utilizing external LLM-based tools. Our work provides concrete validation for these principles, highlighting a series of trade-offs between performance, robustness, and efficiency, and suggesting that prioritizing cognitive synergy over simple sparsity offers a promising direction for future research in modular AI.},
  archive      = {J_NEUCOM},
  author       = {Xiaofei Zhou and Soohong Kim and Yiru Wang and Kailin Zhang},
  doi          = {10.1016/j.neucom.2025.131616},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131616},
  shortjournal = {Neurocomputing},
  title        = {Beyond sparsity: An empirical study of structured collaboration in modular AI},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A graph transformer-driven reinforcement learning based on popularity for mining complex network key nodes. <em>NEUCOM</em>, <em>657</em>, 131614. (<a href='https://doi.org/10.1016/j.neucom.2025.131614'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Key nodes in complex networks play a crucial role in maintaining the stability, functionality, and robustness of networked systems. Accordingly, the accurate identification of such nodes is of fundamental importance. Their significance spans multiple domains, including communication systems, transportation infrastructures, life sciences, and social networks. Existing algorithms for key node identification typically rely on heuristic measures or standard deep reinforcement learning frameworks. However, these approaches often suffer from limited feature extraction capabilities, high computational complexity, and insufficient generalizability, and a lack of dynamic adaptability. To overcome these limitations, this study proposes a novel architecture, GTRP (Graph Transformer-Driven Reinforcement Learning Based on Popularity). GTRP extends Epidemic-aware Heterogeneous Graph Transformer (GT) by introducing distinct attention mechanisms for both nodes and edges, enabling the integration of local structural features and global propagation properties. In addition, GTRP incorporates Dual-dynamics Reward Optimization (DR) to identify key nodes based on a network disintegration strategy. The model is trained on randomly generated Barabási–Albert (BA) networks and evaluated on synthetic networks of varying scales as well as multiple real-world network scenarios. Comparative experiments with six representative algorithms demonstrate that GTRP achieves substantial performance improvements—outperforming existing methods by 6.30 % in unweighted networks and 15.90 % in weighted networks. These results underscore the potential of GTRP to advance key node detection in complex network analysis.},
  archive      = {J_NEUCOM},
  author       = {Kaili Wang and Muqing Wu and Min Zhao},
  doi          = {10.1016/j.neucom.2025.131614},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131614},
  shortjournal = {Neurocomputing},
  title        = {A graph transformer-driven reinforcement learning based on popularity for mining complex network key nodes},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient classification and error correction knowledge distillation framework for remaining useful life prediction of bearings in air turbine starter. <em>NEUCOM</em>, <em>657</em>, 131611. (<a href='https://doi.org/10.1016/j.neucom.2025.131611'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prognostics and Health Management (PHM) is critical for industrial equipment maintenance, whose core task is to predict the Remaining Useful Life (RUL) of a system or component accurately. However, traditional deep learning-based approaches often demand significant computational and memory resources, limiting their feasibility for edge deployment. As an effective model compression technique, Knowledge Distillation (KD) has emerged as a core strategy for enabling edge intelligence by transferring knowledge from a teacher model to a lightweight student model. However, traditional KD methods exhibit a high dependency on the teacher model's output. This dependency limits the student model's capacity for autonomous error correction, impairing its distillation performance. To solve these problems, this paper proposes a novel Classification and Error Correction Knowledge Distillation (CEKD) framework. The framework employs Gaussian kernel-based feature entropy to dynamically evaluate teacher models' predictive capabilities, facilitating comprehensive assessment and sample differentiation. Furthermore, the knowledge self-reflection learning strategy extends error correction to continuous dynamic adjustment, enabling deep optimization of complex data. Experimental results on the air turbine starter bearing datasets show that CEKD surpasses KD methods by improving MAE and RMSE by 79.8 % and 78.6 % on average, while reducing memory consumption and inference time by nearly 10 × and 8 × , respectively, enabling deployment on resource-constrained devices.},
  archive      = {J_NEUCOM},
  author       = {Runxia Guo and Jingxu Yi and Xianfeng Luo},
  doi          = {10.1016/j.neucom.2025.131611},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131611},
  shortjournal = {Neurocomputing},
  title        = {An efficient classification and error correction knowledge distillation framework for remaining useful life prediction of bearings in air turbine starter},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite-time lag consensus and finite-time h∞ lag consensus for nonlinear multi-agent systems under communication delay. <em>NEUCOM</em>, <em>657</em>, 131609. (<a href='https://doi.org/10.1016/j.neucom.2025.131609'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, the finite-time lag consensus (FTLC) and finite-time H ∞ lag consensus (FTHLC) problems for first-order multi-agent systems (MASs) are studied. On the one hand, a new state feedback controller considering the communication delay between agents is proposed. Besides, based on several inequality scaling techniques and finite-time stability theory, a sufficient criterion is derived to guarantee the FTLC of MASs. On the other hand, an adaptive state feedback controller and the corresponding adaptive law are put forward, which can also help MASs realize lag consensus in finite time without any additional conditions. Moreover, to address inevitable external disturbances in practice, the proposed control strategies are further enhanced to achieve FTHLC, which further expands the application range of the research results. Finally, the effectiveness of these provided FTLC and FTHLC control schemes in different scenarios is manifested through some numerical simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Song Gao and Jin-Liang Wang and Kun Ling and Shun-Yan Ren and Ming-Zhu Wei and Bei Peng},
  doi          = {10.1016/j.neucom.2025.131609},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131609},
  shortjournal = {Neurocomputing},
  title        = {Finite-time lag consensus and finite-time h∞ lag consensus for nonlinear multi-agent systems under communication delay},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed generalized nash equilibrium computing based on dynamic tracking mechanism for nonsmooth aggregative games over time-varying networks. <em>NEUCOM</em>, <em>657</em>, 131608. (<a href='https://doi.org/10.1016/j.neucom.2025.131608'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the computation of generalized Nash equilibrium in aggregative games with coupling constraints over time-varying networks. The player’s cost objective comprises a differentiable function dependent on the aggregate of all players’ decisions and a possibly non-smooth term with a linear mapping. In this context, designing solution methods for such game formulation is relatively scarce. We thus develop a fully distributed equilibrium-seeking algorithm that accommodates time-varying communication networks while circumventing the need for global decision information. The proposed algorithm synergistically embeds dynamic tracking of aggregate decisions through a consensus-based mechanism with projected pseudo-gradient updates, augmented by a proximal splitting scheme to handle non-smooth components. Theoretically, we establish convergence guarantees to the variational equilibrium through a new operator splitting framework. Finally, numerical experiments are conducted to substantiate the validity of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Liang Ran and Huaqing Li and Zheng Wang and Lifeng Zheng and Jun Li and Zhe Li},
  doi          = {10.1016/j.neucom.2025.131608},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131608},
  shortjournal = {Neurocomputing},
  title        = {Distributed generalized nash equilibrium computing based on dynamic tracking mechanism for nonsmooth aggregative games over time-varying networks},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network-based distributed adaptive synchronization control for multi-weighted complex networks with aperiodic intermittent coupling. <em>NEUCOM</em>, <em>657</em>, 131604. (<a href='https://doi.org/10.1016/j.neucom.2025.131604'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the synchronization control for multi-weighted complex networks (MWCNs) with unknown disturbances and aperiodic intermittent coupling. Firstly, an adaptive neural network strategy is used to approximate the unknown components derived from nonlinear function, while a novel continuous function is proposed by utilizing the idea of time-varying boundary layer technique to deal with the influence of approximation errors. Secondly, different from the continuous coupling and periodic intermittent coupling mechanisms in existing works, an aperiodic intermittent coupling mechanism is taken into consideration in MWCNs. Thirdly, to synchronize MWCNs under aperiodic intermittent coupling, adaptive strategies are developed to adjust coupling strengths and coupling gains based on all edges and partial edges, respectively. Note that these two strategies are fully distributed, i.e., they do not require any global information. Finally, some numerical simulations are provided to verify the effectiveness of theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Bin Zhang and Dan Liu and Binrui Wang and Kaibo Shi},
  doi          = {10.1016/j.neucom.2025.131604},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131604},
  shortjournal = {Neurocomputing},
  title        = {Neural network-based distributed adaptive synchronization control for multi-weighted complex networks with aperiodic intermittent coupling},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective framework with hybrid augmentation for visual reinforcement learning generalization. <em>NEUCOM</em>, <em>657</em>, 131602. (<a href='https://doi.org/10.1016/j.neucom.2025.131602'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current studies in Visual Reinforcement Learning focus on developing policies to acclimate to unknown environments through data augmentation. This paper aims to develop a new methodology to improve upon existing results. To this end, we first categorize existing methods into three groups based on the focus of augmentation: Task-Aware Augmentation, Image-Processing Augmentation, and Image-Scene Augmentation. Subsequently, we establish a unified framework that integrates these three augmentation categories. The core of our framework is hybrid data augmentation, which enhances data diversity. In this framework, we employ hyperspherical space and regularization techniques to address the side effects of such augmentation, specifically the discrepancy between augmented and original data, as well as the instability associated with hybrid augmentation. Finally, we evaluate the proposed framework across three benchmarks, demonstrating its significant advantages over current state-of-the-art methods. Notably, our framework outperforms existing approaches by an average of 4.59 % across 10 tasks in DMC-GB, 28.81 % across 6 tasks in Robosuite, and 20.50 % across 4 tasks in Adroit. The code for our framework will be released at https://github.com/csufangyu/MuHA .},
  archive      = {J_NEUCOM},
  author       = {Yu Fang and Xuehe Zhang and Haoshu Cheng and Xizhe Zang and Changle Li and Jie Zhao},
  doi          = {10.1016/j.neucom.2025.131602},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131602},
  shortjournal = {Neurocomputing},
  title        = {An effective framework with hybrid augmentation for visual reinforcement learning generalization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing robust generalization through appropriate adversarial example attack intensity. <em>NEUCOM</em>, <em>657</em>, 131599. (<a href='https://doi.org/10.1016/j.neucom.2025.131599'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) are notoriously susceptible to adversarial examples. To mitigate the impact of well-designed adversarial attacks on network models, researchers have developed various defense mechanisms, among which adversarial training has emerged as one of the most effective strategies to date. Adversarial training aims to augment training data with adversarial examples, thus giving DNNs a certain degree of robustness to defend against adversarial attacks. However, while obtaining adversarial robustness, this method comes at the cost of reducing the generalization performance, manifested in the reduced classification effect of clean test datasets. Researchers have been actively seeking to counter the balance between adversarial robustness and model generalization. We believe that the key to balancing these two aspects lies in identifying appropriate adversarial examples. Overly potent examples can lead to a decline in clean accuracy, whereas weaker examples may offer limited robustness. Based on our analysis, a new adversarial example generation algorithm called Denoising Projection Gradient Descent (DPGD) was proposed. DPGD adds a purification module and a constraint in generating adversarial examples, the former is used to limit the influence of too strong adversarial examples on model training and the latter is used to ensure the necessary attack intensity. Combining DPGD with the framework of traditional adversarial training, we obtain the Diffusion Adversarial Training (DifAT) approach. To verify the effectiveness of our proposed method, we conducted extensive experiments on benchmark datasets, including CIFAR-10, CIFAR-100, and Tiny-Imagenet. Our results demonstrate the effectiveness of DifAT in improving the robustness of DNNs while maintaining or even improving their generalization performance.},
  archive      = {J_NEUCOM},
  author       = {Xiaoguo Ding and Liangjian Zhang and Qiqi Bao and Yaguan Qian and Bin Wang and Zhaoquan Gu and Yanchun Zhang},
  doi          = {10.1016/j.neucom.2025.131599},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131599},
  shortjournal = {Neurocomputing},
  title        = {Enhancing robust generalization through appropriate adversarial example attack intensity},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User identification based on the topology consistency of cross-layer common neighbors in social network. <em>NEUCOM</em>, <em>657</em>, 131591. (<a href='https://doi.org/10.1016/j.neucom.2025.131591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, it has become a common practice to create multiple accounts on various social networks for online recreation. When accounts in different networks share similar structural features, i . e . , they have topology consistency, they may belong to the same individual. However, having multiple accounts for the same person across different networks can be inconvenient and uncertain, leading to difficulties in accurate recommendations. Therefore, some researchers have focused on identifying users within single network layers, but without involving the information from various network platforms, resulting in identification confusion and reduced algorithm accuracy. This paper proposes a novel topology consistency-based link prediction algorithm (Topology Consistency: TC) for user identification, combining separate layers of a multilayer network into a single-layer network to include more layer information. TC applies topology information from the cross-layer common neighbors produced in layer combination to distinguish target node pairs and utilizes matrix computation to reduce complexity. Furthermore, to address controversial identification situations appearing after layer combination, the edges between the cross-layer common neighbors are innovatively considered. Finally, experimental results in real-world and artificial networks show that TC has superior performance to state-of-the-art algorithms and has applicability and practicality.},
  archive      = {J_NEUCOM},
  author       = {Yujie Yang and Shuai Cao and Long Wang and Dong Liu and Marcus Kaiser},
  doi          = {10.1016/j.neucom.2025.131591},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131591},
  shortjournal = {Neurocomputing},
  title        = {User identification based on the topology consistency of cross-layer common neighbors in social network},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Implementation of linear optics network for pattern recognition task via the generation of continuous variable entangled states. <em>NEUCOM</em>, <em>657</em>, 131588. (<a href='https://doi.org/10.1016/j.neucom.2025.131588'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear optics neural networks or optical neural networks offer potential advantages over traditional electronic neural networks in terms of speed, energy efficiency, scalability, and improved parallelism, particularly for high-bandwidth applications. The use of photonics allows for more compact and integrated neural network designs, potentially enabling the development of larger and more complex networks. A linear optics network is developed to implement a quantum classifier. Indeed, the designed network is a quantum circuit consisting of some Gaussian gates such as displacement, noiseless linear amplification (NLA), squeezer and Green machine. At first, the classical inputs are encoded with the help of position-displacement operator to prepare single-mode coherent states. Then, the amplitudes of the coherent states are amplified by passing through NLA elements followed by squeezer gates that may transform classical coherent states into nonclassical ones. Finally, the transformed coherent states are fed into the Green machine which provides entangled states as the outcome of the network. As a primary goal of this work, the network generates a multi-mode entangled state by applying the displacement operator on the vacuum state encoded classical data. Besides, it is shown that the output state of the circuit may possess squeezing characteristics as another nonclassical feature. In the continuation, as a practical application, the network is implemented to perform some pattern recognition tasks. At first, the Bayes theorem is employed to define discriminant functions to perform a general classification task, then the outcome distribution of the network is utilized to classify some corrupted LEDs that display English letters. Finally, we show that the outcome of the circuit may be manipulated to embed classical neural networks into a continuous-variable variational quantum circuit (VQC). The network is trained via the logistic regression algorithm with the MNIST database. The results show that the digits can be recognized with relatively high accuracy. Ongoing research is focused on developing new linear optical techniques for machine learning, improving the efficiency and scalability of optical networks, and exploring new applications of linear optics in machine learning and quantum computing. Hence, such a quantum circuit may also be used to design novel high-accuracy pattern recognition devices.},
  archive      = {J_NEUCOM},
  author       = {Ebrahim Ghasemian and Mohammad Kazem Tavassoly and Habib Rostami},
  doi          = {10.1016/j.neucom.2025.131588},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131588},
  shortjournal = {Neurocomputing},
  title        = {Implementation of linear optics network for pattern recognition task via the generation of continuous variable entangled states},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning generic and specific prompts with contrastive constraints for multi-task visual scene understanding. <em>NEUCOM</em>, <em>657</em>, 131586. (<a href='https://doi.org/10.1016/j.neucom.2025.131586'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning has emerged as a crucial research direction in the field of computer vision, offering improved performance and efficiency across multiple tasks. Recent studies have incorporated prompt learning into multi-task learning to enhance the interaction between prompt vectors and image representations. However, these studies fail to consider the inter-task and intra-task relations of prompt vectors under multi-task scenarios. To address this issue, we propose learning Generic and Specific Prompts (GSPrompt) with contrastive constraints for multi-task visual scene understanding. Our approach assumes that each task possesses both commonality and individuality, leading us to design two distinct types of prompt vectors: task-generic prompts and task-specific prompts. By constraining the prompt vectors through pulling task-generic prompts and pushing task-specific prompts, we enable multi-task models to learn prompts capable of adapting to multiple tasks simultaneously. Extensive experiments on NYUD-v2, PASCAL-Context, and Cityscapes show that GSPrompt learns effective prompts and achieves state-of-the-art performance. The code is publicly available at https://github.com/teeyohan/GSPrompt-main .},
  archive      = {J_NEUCOM},
  author       = {Tianyu Han and Zhimin Xu and Wanying Li and Haohao Hu and Xinxin He and Song He and Peng Zan and Xiaochen Bo},
  doi          = {10.1016/j.neucom.2025.131586},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131586},
  shortjournal = {Neurocomputing},
  title        = {Learning generic and specific prompts with contrastive constraints for multi-task visual scene understanding},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision-based passenger head detection for carriage crowd density estimation. <em>NEUCOM</em>, <em>657</em>, 131584. (<a href='https://doi.org/10.1016/j.neucom.2025.131584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carriage crowd density monitoring is a key component in developing intelligent transportation systems, such as maglev transportation system. Surveillance images captured by sensors, such as carriage monitoring cameras, serve as a new solution for estimating crowd density inside the carriage due to their wide coverage and real-time updates. In this study, a passenger head detection dataset (PHD) is developed using 3717 images acquired from carriage surveillance. Based on these images, over 67,215 head instances are precisely annotated manually. To address the issue of insufficient feature fusion in existing detection algorithms, an efficient cross-scale feature enhancement (CFE) module is proposed and introduced into the advanced YoloX model. The PHD dataset is, to the best of our knowledge, the first public dataset of surveillance images for carriage crowd density estimation. To prove the usability of the PHD dataset and the validity of the proposed method, 12 different versions of detectors are applied and compared. The results demonstrate the performance of these algorithms in the detection of passenger heads. Our research offers a new approach for carriage crowd density estimation. The dataset is publicly available at: https://github.com/Xujiajing111/PHD .},
  archive      = {J_NEUCOM},
  author       = {Jiajing Xu and Mingda Zhai and Yuan Tian and Jun Wu},
  doi          = {10.1016/j.neucom.2025.131584},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131584},
  shortjournal = {Neurocomputing},
  title        = {Vision-based passenger head detection for carriage crowd density estimation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-client GAN-based backdoor attacks for asynchronous federated learning. <em>NEUCOM</em>, <em>657</em>, 131580. (<a href='https://doi.org/10.1016/j.neucom.2025.131580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) enables distributed collaborative training while preserving data privacy; however, it demonstrates significant vulnerability to backdoor attacks. Existing attack methodologies predominantly require control of numerous malicious clients to achieve efficacy and largely neglect asynchronous FL scenarios. In response to these limitations, we propose a novel GAN-based backdoor attack framework capable of injecting effective and covert backdoors with minimal malicious client participation, functioning efficiently across both synchronous and asynchronous environments. Our framework operates effectively with a single malicious client, eliminating the need for coordination among multiple adversarial participants or prior knowledge of benign client data distributions. This reduction in resource requirements enhances the framework's practicality in real-world FL implementations. The malicious client employs a Generative Adversarial Network to synthesize adversarial samples containing predefined triggers, which are subsequently incorporated into local training datasets. The concurrent training on legitimate and triggered data enhances attack effectiveness, while gradient injection—manipulating differences between local and global gradients to introduce strategic noise—facilitates backdoor embedding with improved stealth characteristics. Empirical evaluations demonstrate that in a configuration of 200 clients with a single attacker, our framework achieves attack success rates of 98.66 % on MNIST and 86.29 % on CIFAR-10 datasets. Comprehensive experimentation across both datasets substantiates the framework's effectiveness, imperceptibility, and resilience in synchronous and asynchronous FL environments. This research contributes significant insights into backdoor attack strategies in FL, particularly within asynchronous contexts, and underscores the imperative for developing robust defensive countermeasures.},
  archive      = {J_NEUCOM},
  author       = {Siyu Guan and Chunguang Huang and Hai Cheng},
  doi          = {10.1016/j.neucom.2025.131580},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131580},
  shortjournal = {Neurocomputing},
  title        = {Single-client GAN-based backdoor attacks for asynchronous federated learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UA-PDFL: A personalized approach for decentralized federated learning. <em>NEUCOM</em>, <em>657</em>, 131579. (<a href='https://doi.org/10.1016/j.neucom.2025.131579'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a privacy preserving machine learning paradigm designed to collaboratively learn a global model without data leakage. Specifically, in a typical FL system, the central server solely functions as a coordinator to iteratively aggregate the collected local models trained by each client, potentially introducing single-point transmission bottleneck and security threats. To mitigate this issue, decentralized federated learning (DFL) has been proposed, where all participating clients engage in peer-to-peer communication without a central server. Nonetheless, DFL still suffers from training degradation as FL does due to the non-independent and identically distributed (non-IID) nature of client data. And incorporating personalization layers into DFL may be one of the most effective solutions to alleviate the side effects caused by non-IID data. Therefore, in this paper, we propose a novel unit representation aided personalized decentralized federated learning framework, named UA-PDFL, to deal with the non-IID challenge in DFL. By adaptively adjusting the level of personalization layers through the guidance of the unit representation, UA-PDFL is able to address the varying degrees of data skew. Based on this scheme, client-wise dropout and layer-wise personalization are proposed to further enhance the learning performance of DFL. Extensive experiments empirically prove the effectiveness of our proposed method.},
  archive      = {J_NEUCOM},
  author       = {Hangyu Zhu and Yuxiang Fan and Zhenping Xie},
  doi          = {10.1016/j.neucom.2025.131579},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131579},
  shortjournal = {Neurocomputing},
  title        = {UA-PDFL: A personalized approach for decentralized federated learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel two-stage hybrid feature selection: Exploiting ubiquitous intrinsic feature groups. <em>NEUCOM</em>, <em>657</em>, 131574. (<a href='https://doi.org/10.1016/j.neucom.2025.131574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) has emerged as an important data pre-processing technology to solve the challenging task of data mining. However, most existing FS methods primarily focus on exploiting the independent contributions provided by individual features, while neglecting the critical contributions inherent in ubiquitous intrinsic feature groups. As a result, they may fail to fully capture the potentially valuable information embedded in data. This issue becomes more pronounced in modern large-scale data environments, such as JointCloud, where cross-organizational collaborative data analysis over non-shared datasets is often required. To address this issue, this paper proposes a N ovel T wo- S tage H ybrid FS approach (NTSHFS) that jointly considers the informative contributions of both individual features and collaborative feature groups, enabling a comprehensive evaluation of feature relevance, redundancy and discriminative capability. In the first stage, the correlation coefficient-based co-association matrix (CC-CAM) is developed to ensemble the results obtained by different univariate and structured regularization techniques. Then, a CC-CAM-based embedded FS is proposed to select and rank representative features, achieving strong relevance prioritization and redundancy elimination. In the second stage, a quasi fuzzy-rough set (QFRS) model is designed by integrating the similarity relations at both individual-feature level and multi-feature level through the intersection operation. Based on this model, a QFRS-based filter FS is presented to determine the final feature subset with stronger discriminative capability using internal rankings of feature groups. Experimental results on 24 datasets demonstrate that the proposed approach typically outperforms the compared methods (i.e., achieving an average classification accuracy improvement ranging from 1.77 % to 7.69 %), highlighting its effectiveness, robustness and generalization in data mining.},
  archive      = {J_NEUCOM},
  author       = {Lin Qiu and Xingwei Wang and Bo Yi and Yanpeng Qu and Min Huang and Kaimin Zhang},
  doi          = {10.1016/j.neucom.2025.131574},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131574},
  shortjournal = {Neurocomputing},
  title        = {A novel two-stage hybrid feature selection: Exploiting ubiquitous intrinsic feature groups},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view semi-supervised feature selection with multi-order similarity and tensor learning. <em>NEUCOM</em>, <em>657</em>, 131573. (<a href='https://doi.org/10.1016/j.neucom.2025.131573'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view data has attracted extensive attention because it can better characterize samples, and multi-view semi-supervised feature selection can not only effectively improve multi-view performance, but also maintain the original real structure of the data. To this end, many scholars have proposed various models to achieve this goal. However, most of the existing methods rely on the graph structure constructed from the original data and use the constructed graph as a guide for feature selection. This not only ignores multi-order domain knowledge, but also ignores the high-order relations between views. Therefore, this study effectively integrates multi-order domain information with graph learning, and performs tensor low-rank learning on the graph structure between multiple views. A multi-view semi-supervised feature selection method based on multi-order similarity and tensor learning is proposed, which not only integrates multi-order domain information, but also takes into account the relationship between views. Based on this, we propose an iterative method to solve the objective function and prove the superiority of our method on multiple basic datasets.},
  archive      = {J_NEUCOM},
  author       = {Hangyu Chen and Xijiong Xie and Yujie Xiong},
  doi          = {10.1016/j.neucom.2025.131573},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131573},
  shortjournal = {Neurocomputing},
  title        = {Multi-view semi-supervised feature selection with multi-order similarity and tensor learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature selection via risk-bound utility maximization. <em>NEUCOM</em>, <em>657</em>, 131572. (<a href='https://doi.org/10.1016/j.neucom.2025.131572'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ultimate goal of supervised feature selection is to identify a feature subset that minimizes classification risk. Contemporary methods, however, often rely on heuristic or model-dependent proxy criteria that lack a direct theoretical connection to this fundamental objective. To bridge this gap, we introduce a new feature selection framework that directly optimizes a model-agnostic utility function grounded in statistical learning theory. Our approach defines the utility of a feature subset based on the 1-Wasserstein distance between class-conditional distributions. This metric is theoretically powerful as it can be used to construct an upper bound on the Bayes classification error, allowing us to construct a utility function that is a direct surrogate for this risk bound. We instantiate this framework with a subset search strategy that effectively captures feature interactions by maximizing this risk-bound utility. Extensive experiments on real-world datasets demonstrate that our method not only achieves state-of-the-art classification performance but also demonstrates superior robustness and interpretability, providing a principled and powerful alternative to traditional feature selection methods, confirming our framework’s theoretical soundness.},
  archive      = {J_NEUCOM},
  author       = {Chunxu Cao and Qiang Zhang},
  doi          = {10.1016/j.neucom.2025.131572},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131572},
  shortjournal = {Neurocomputing},
  title        = {Feature selection via risk-bound utility maximization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Projected variable three-term conjugate gradient algorithm for enhancing generalization performance in deep neural network training. <em>NEUCOM</em>, <em>657</em>, 131568. (<a href='https://doi.org/10.1016/j.neucom.2025.131568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning optimization faces a fundamental trade-off between convergence efficiency and generalization. First-order methods such as stochastic gradient descent (SGD) and adaptive moment estimation (Adam) tend to find flatter minima but converge slowly, while higher-order methods converge rapidly but are often drawn to sharp minima that generalize poorly. To address this, we introduce the projected variable three-term conjugate gradient (PVTTCG) algorithm. Motivated by the geometric instabilities in modern networks that use techniques such as batch normalization (BN), PVTTCG integrates an orthogonal projection into the higher-order optimization framework. This mechanism eliminates radial components from the search direction, inherently guiding the optimization toward flatter regions without requiring additional regularization terms or hyperparameters. The effectiveness of PVTTCG is validated across diverse tasks, including language modeling, large-scale image classification, and a real-world engineering application. In complex scenarios, PVTTCG consistently improves upon its higher-order baseline, achieving up to a 3.92 percentage point gain on CIFAR-100 while remaining competitive with leading first-order methods. A systematic analysis reveals that PVTTCG demonstrates superior robustness to batch size variations, particularly excelling at larger batch sizes. This robustness enables the algorithm to process batch sizes up to 2,048 in engineering applications, achieving a 35.9% test loss reduction compared to Adam. These findings establish PVTTCG as an effective solution for bridging the convergence-generalization trade-off.},
  archive      = {J_NEUCOM},
  author       = {Sanghyuk Kim and Hansu Kim and Namwoo Kang and Tae Hee Lee},
  doi          = {10.1016/j.neucom.2025.131568},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131568},
  shortjournal = {Neurocomputing},
  title        = {Projected variable three-term conjugate gradient algorithm for enhancing generalization performance in deep neural network training},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DVC2: Deep video cascade clustering from video structures. <em>NEUCOM</em>, <em>657</em>, 131565. (<a href='https://doi.org/10.1016/j.neucom.2025.131565'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video clustering is a critical unsupervised learning task, where category labels are unavailable, unlike in supervised video classification. The primary challenge is learning meaningful video representations without annotations to effectively group similar videos. Most existing methods extract frame-level features and apply standard clustering algorithms such as K-means, but they often fail to capture temporal relationships inherent in video data. In this paper, we introduce Deep Video Cascade Clustering ( DVC 2 ), a novel unsupervised video learning paradigm. Unlike image-based clustering methods, DVC 2 first learns an initial video representation through frame clustering, which serves as guidance, and then aligns video clustering results with both long-term and short-term structures as well as nearest neighbors. We evaluate DVC 2 on benchmark datasets, including UCF101 and Kinetics-400, achieving state-of-the-art results. Notably, even in annotation-free scenarios where self-supervised learning with K-means already yields reasonable clustering, DVC 2 demonstrates significantly superior performance.},
  archive      = {J_NEUCOM},
  author       = {Zihua Wang and Siya Mi and Yu Zhang},
  doi          = {10.1016/j.neucom.2025.131565},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131565},
  shortjournal = {Neurocomputing},
  title        = {DVC2: Deep video cascade clustering from video structures},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SiFH: Siamese frequency harmonization self-supervised learning for motion forecasting. <em>NEUCOM</em>, <em>657</em>, 131563. (<a href='https://doi.org/10.1016/j.neucom.2025.131563'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion forecasting is a fundamental component of the autonomous driving system and plays an important role in ensuring safety. While supervised learning methods have achieved promising performance in many domains, their model capacity is typically limited by the availability of annotated data. Some previous works have tried to introduce this paradigm into motion forecasting. However, these early studies neglect the task-specific characteristics. To address this, we incorporate two key insights into motion forecasting tasks within the self-supervised paradigm and propose a novel self-supervised motion forecasting framework. First, we design a Frequency Information Harmonization pretext task that explicitly encourages the model to integrate frequency domain features with their time domain counterparts, making them work harmoniously. Second, we introduce an Implicit Scene Alignment task, which enables the model to learn scene-level semantics by aligning masked and unmasked views through shared prototypes. By jointly optimizing these objectives, the model is encouraged to leverage abundant unlabeled data and capture rich spatio-temporal representations. Extensive experiments conducted on the challenging Argoverse 2 and Argoverse 1 benchmarks demonstrate that our proposed model outperforms previous state-of-the-art baselines and can produce more accurate and reliable predictions.},
  archive      = {J_NEUCOM},
  author       = {Chunyu Liu and Zeyu Liu and Tiechui Yao and Shijie Li},
  doi          = {10.1016/j.neucom.2025.131563},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131563},
  shortjournal = {Neurocomputing},
  title        = {SiFH: Siamese frequency harmonization self-supervised learning for motion forecasting},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RosMS-ECDBTM: Efficient channel attention enabled distributed deep learning model for mental state detection using EEG signal. <em>NEUCOM</em>, <em>657</em>, 131559. (<a href='https://doi.org/10.1016/j.neucom.2025.131559'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, mental stress is emerging as a common social problem triggering different health disorders, including nervousness, heart attacks, strokes, and depression. Specifically, the Electroencephalography (EEG) signal, capable of reflecting the variations in brain activity, is highly used for mental state detection. Despite their promising performance, the existing EEG-based detection methods fail to capture the inherent characteristics of highly intricate and nonstationary EEG signals. In order to address the drawbacks of existing methods, this research proposes the Deep Learning model namely, Rosmarus Migrative Search Optimized Efficient channel attention enabled Distributed Bi-directional Long Short-Term Memory (RosMS-ECDBTM) model for precise mental state detection. More specifically, the efficient channel attention facilitates the proposed model to dynamically highlight the important parts of the signal characteristics while suppressing the irrelevant regions. Besides, the distributed DL architecture improves the learning capability and scalability of the proposed model to process the large datasets, through the parallel processing of sequential data. Further, the proposed approach exploits the Rosmarus Migrative Search Optimization (RosMS) algorithm for optimizing the RosMS-ECDBTM architecture, resulting in improving the training process. Ultimately, the proposed model, combining efficient channel attention and distributed learning mechanism, captures the intricate patterns and reduces the computational complexity of mental state detection. In addition, the Hybrid Discrete Wavelet transform (DWT) approach decomposes the EEG signal into several frequency components for capturing the hidden patterns and anomalous states in the EEG signal, providing key insights for improving the mental state detection. Extensive experiments show that the RosMS-ECDBTM method provides superior performance, achieving a high accuracy of 96.78 %, precision of 98.99 %, recall of 95.91 %, and F1-score of 97.42 % for the Mental Stress Detection dataset compared to other state-of-the-art methods. Ultimately, these findings reveal the high learning efficiency of the proposed deep learning approach in enhancing the mental state detection accuracy, significantly contributing to advancing the field of mental health monitoring.},
  archive      = {J_NEUCOM},
  author       = {Mandar Nitin Kakade},
  doi          = {10.1016/j.neucom.2025.131559},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131559},
  shortjournal = {Neurocomputing},
  title        = {RosMS-ECDBTM: Efficient channel attention enabled distributed deep learning model for mental state detection using EEG signal},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient semantic segmentation of remote sensing images through dynamic feature enhancement and multimodal alignment fusion. <em>NEUCOM</em>, <em>657</em>, 131555. (<a href='https://doi.org/10.1016/j.neucom.2025.131555'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal fusion has shown promising applications in integrating information from different modalities. However, existing multimodal fusion approaches in remote sensing face two main challenges: First, multimodal fusion models relying on Convolutional Neural Networks (CNNs) or Visual Transformers (ViTs) have limitations in terms of remote modeling capabilities and computational complexity, while state-space model (SSM)-based fusion models are prone to feature redundancy due to the use of multiple scanning paths, and similarly suffer from high computational complexity. Second, existing methods do not fully address inter-modal heterogeneity, leading to poor multimodal data fusion. To address these issues, we propose an efficient multimodal fusion network, AFMamba, based on the state-space model (SSM) for semantic segmentation of remote sensing images. Specifically, we design the Efficient Dynamic Visual State Space (EDVSS) module, which enhances the efficiency of the standard Mamba model by dynamically improving local features and reducing channel redundancy. Furthermore, we introduce the Cross Attention Alignment Fusion (CAAFM) module, which combines cross-image attention fusion and channel interaction alignment to effectively improve the accuracy and efficiency of cross-modal feature fusion and mitigate feature inconsistency. Experimental results demonstrate that in multimodal hyperspectral image semantic segmentation, the proposed model reduces computational complexity, measured in GFLOPs, by at least 61 % while maintaining a low parameter count, achieving optimal overall accuracy (OA) of around 92 %, and effectively balancing performance and computational efficiency.},
  archive      = {J_NEUCOM},
  author       = {Wenqian Chen and Wendie Yue and Kai Chang and Hongzhi Wang and Kaijun Tan and Xinyu Liu and Xiaoyi Cao},
  doi          = {10.1016/j.neucom.2025.131555},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131555},
  shortjournal = {Neurocomputing},
  title        = {Efficient semantic segmentation of remote sensing images through dynamic feature enhancement and multimodal alignment fusion},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-step minimax Q-learning algorithm for two-player zero-sum markov games. <em>NEUCOM</em>, <em>657</em>, 131552. (<a href='https://doi.org/10.1016/j.neucom.2025.131552'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An interesting iterative procedure is proposed to solve two-player zero-sum Markov games. Under suitable assumptions, the boundedness of the proposed iterates is obtained theoretically. Using results from stochastic approximation, the almost sure convergence of the proposed multi-step minimax Q-learning is obtained theoretically. More specifically, the proposed algorithm converges to the game theoretic optimal value with probability one, when the model information is not known. Numerical simulations authenticate that the proposed algorithm is effective and easy to implement.},
  archive      = {J_NEUCOM},
  author       = {Shreyas S.R. and Antony Vijesh},
  doi          = {10.1016/j.neucom.2025.131552},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131552},
  shortjournal = {Neurocomputing},
  title        = {A multi-step minimax Q-learning algorithm for two-player zero-sum markov games},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constrained multi-agent evasion using deep reinforcement learning. <em>NEUCOM</em>, <em>657</em>, 131550. (<a href='https://doi.org/10.1016/j.neucom.2025.131550'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing effective evasion strategies in pursuit–evasion scenarios is challenging, particularly when the pursuer’s model is unknown and inaccessible. This limitation hinders the application of conventional evasion policy design methods. To overcome this challenge, especially when evaders have constrained maneuverability against unrestricted pursuers, we propose a novel multi-agent evasion algorithm based on deep reinforcement learning. Our approach employs a staged learning framework, progressively guiding evaders from simpler to more complex tasks to refine their evasion strategies. Crucially, our algorithm enables evaders to infer pursuers’ intentions even without prior knowledge of pursuers’ objectives, allowing for optimal decision-making despite mobility constraints. Simulation results demonstrate that our method significantly enhances evasion success, validating the effectiveness of learning-based strategies. Additionally, the algorithm exhibits strong adaptability to environmental changes, ensuring reliable performance across diverse pursuit–evasion scenarios.},
  archive      = {J_NEUCOM},
  author       = {Bowei Yan and Runle Du and Xiaojun Ban and Di Zhou},
  doi          = {10.1016/j.neucom.2025.131550},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131550},
  shortjournal = {Neurocomputing},
  title        = {Constrained multi-agent evasion using deep reinforcement learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STD-explain: Generalizing explanations for spatio-temporal graph convolutional networks based on spatio-temporal decoupled perturbation. <em>NEUCOM</em>, <em>657</em>, 131539. (<a href='https://doi.org/10.1016/j.neucom.2025.131539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal graph convolutional networks utilize an alternating combination of one-dimensional ordinary convolution and graph convolution to extract spatio-temporal features. This alternation intertwines temporal and spatial features closely, leading to a tight coupling between them. The presence of spatio-temporal coupling complicates the analysis of spatio-temporal data, posing challenges for existing explainability algorithms to effectively separate and interpret these intertwined features. Therefore, we propose STD-Explain, an explainable algorithm based on spatio-temporal decoupled perturbation, which employs a two-stage perturbation approach considering subgraph and node-level explanations. Firstly, targeting the spatio-temporal coupling issue in spatio-temporal graph convolutional networks, the algorithm proposes a temporal perturbation algorithm based on Slice Graph and a spatial perturbation algorithm aimed at important subgraph node features. Secondly, to avoid introducing additional semantic information when extracting temporal subgraphs, we propose a method for generating temporal subgraphs in spatio-temporal decoupling, slicing human skeleton sequences with discrete masks to ensure each subsequence maintains spatial structure integrity without introducing additional edges. Furthermore, to ensure the maximum correlation between the interpreted subgraphs and model predictions, we propose a temporal important subgraph discrimination strategy to select the most relevant subgraphs to model predictions. Experimental results demonstrate that STD-Explain performs well in qualitative and quantitative analysis.},
  archive      = {J_NEUCOM},
  author       = {Yanshan Li and Ting Shi and Suixuan He and Zhiyuan Chen and Li Zhang and Rui Yu and Weixin Xie},
  doi          = {10.1016/j.neucom.2025.131539},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131539},
  shortjournal = {Neurocomputing},
  title        = {STD-explain: Generalizing explanations for spatio-temporal graph convolutional networks based on spatio-temporal decoupled perturbation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MGSA: Enhancing transferability of multimodal adversarial attacks via multi-granularity semantic alignment. <em>NEUCOM</em>, <em>657</em>, 131534. (<a href='https://doi.org/10.1016/j.neucom.2025.131534'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision–language pretraining (VLP) models have demonstrated exceptional performance across a wide range of image–text multimodal tasks. Despite their prominence, research confirms that these systems retain significant susceptibility to adversarial manipulation. Existing multimodal adversarial attack methods often fail to fully exploit sample-specific semantic structures, resulting in suboptimal cross-modal alignment and limited transferability of adversarial examples. To overcome this limitation, we propose MGSA—a Multi-Granularity Semantic Alignment Attack framework that enhances adversarial perturbation transferability by jointly disrupting cross-modal semantics at both global and fine-grained levels. MGSA captures coarse-grained alignment using overall representations and fine-grained correspondence by selectively aggregating key image regions and words based on importance. This dual-level joint optimization effectively perturbs both holistic consistency and detailed correspondences, thereby significantly enhancing attack effectiveness in white-box scenarios and transferability to black-box models. Extensive experiments conducted across diverse model architectures and multimodal tasks demonstrate that our method achieves strong performance in white-box settings while significantly improving black-box attack success rates. The results highlight the vulnerability of current VLP models and the effectiveness of our approach in generating transferable and semantically grounded adversarial examples.},
  archive      = {J_NEUCOM},
  author       = {Xinyu Liu and Haohua Zhou and Zhidong Shen and Hui Sun},
  doi          = {10.1016/j.neucom.2025.131534},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131534},
  shortjournal = {Neurocomputing},
  title        = {MGSA: Enhancing transferability of multimodal adversarial attacks via multi-granularity semantic alignment},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Urban multi-domain mixing (UMDMix) based unsupervised domain adaptation for LiDAR semantic segmentation. <em>NEUCOM</em>, <em>657</em>, 131526. (<a href='https://doi.org/10.1016/j.neucom.2025.131526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D semantic maps generated from Light Detection and Ranging (LiDAR) point clouds enable scene understanding in diverse applications such as autonomous driving and urban planning. However, existing deep learning models struggle when tested on different domains, worsened by limited labeled data. Unsupervised Domain Adaptation (UDA) can bridge this gap, but existing UDA methods often face adaptation challenges due to domain shifts arising from variations in the physical environment, data sparsity, and sensor differences. To address these limitations, we propose UMDMix , a novel UDA architecture that operates on the mixing of multiple labeled source domains with unlabeled target domains to make the predictive model robust to cross-domain variations. UMDMix integrates a teacher–student learning scheme to produce a robust teacher model and an adaptable student model. The performance of the teacher model in the source domain is further strengthened by a position-aware loss that assigns greater significance to semantically rich neighborhoods. A combination of entropy regularization and KL-divergence loss in the target domain updates the knowledge of the teacher model to the student model during adaptation. Our extensive experiments across diverse environments show that UMDMix achieves an average improvement of 13 % on minor classes such as bicycle, traffic sign, and person in target domain datasets, outperforming previous State-Of-The-Art (SOTA) UDA methods.},
  archive      = {J_NEUCOM},
  author       = {Anurag Nihal and Pyare Lal and Vaibhav Kumar},
  doi          = {10.1016/j.neucom.2025.131526},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131526},
  shortjournal = {Neurocomputing},
  title        = {Urban multi-domain mixing (UMDMix) based unsupervised domain adaptation for LiDAR semantic segmentation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network-enhanced asymmetric prescribed performance control for multi-task cooperative navigation of USVs via an adaptive formation structure. <em>NEUCOM</em>, <em>657</em>, 131521. (<a href='https://doi.org/10.1016/j.neucom.2025.131521'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a prescribed performance control algorithm with asymmetric boundary for Unmanned Surface Vehicle (USV) formation to achieve cooperative navigation under marine disturbances. The proposed algorithm consists of a guidance switching mechanism and a robust adaptive control method. In the improved guidance principle, a velocity correction rule is provided to generate accurate reference signals for USVs during path following. Combined with the guidance term, the communication load between controller and actuator is significantly reduced by employing the Dynamic Event-Triggered Mechanism (DETM) with adaptive updating of threshold parameters. By integrating the initial errors into the performance boundary function, the controller can effectively adapt to different initial states. In addition, due to the smooth property of the shifting function, the error oscillation of the system before steady state is effectively suppressed. The Radial Basis Function Neural Networks (RBF-NNs) are utilized to design damping terms, enhancing the anti-interference capability in marine environments and mitigating the effects of nonlinearities in the model. Through the Lyapunov theorem, the Semi-Globally Uniformly Ultimately Bounded (SGUUB) stability of all state variables is guaranteed. Finally, quantitative validation of the algorithm is performed through numerical simulations and comparative analysis. The results demonstrate a control accuracy within 0.5 meters while showing that, compared to Static Event-Triggering Mechanisms (SETM), the DETM reduces control update frequency for surge force and yawing moment by 12.32 % and 18.78 %, respectively.},
  archive      = {J_NEUCOM},
  author       = {Guoqing Zhang and Junji Feng and Shilin Yin and Matthew Montebello},
  doi          = {10.1016/j.neucom.2025.131521},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131521},
  shortjournal = {Neurocomputing},
  title        = {Neural network-enhanced asymmetric prescribed performance control for multi-task cooperative navigation of USVs via an adaptive formation structure},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mine-SSD: Dual-threshold set abstraction and radius-adaptive grouping for 3D object detection in open-pit mines. <em>NEUCOM</em>, <em>657</em>, 131507. (<a href='https://doi.org/10.1016/j.neucom.2025.131507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and efficient 3D object detection is essential for ensuring both safety and operational efficiency in open-pit mines. Due to complex scene structures, broad perception ranges, and significant object size variations, existing point-based 3D detection methods face challenges that limit their applicability in open-pit mines. To address these issues, Mine-SSD, a single-stage 3D object detection method, is developed with dual-threshold set abstraction (DT-SA) and a radius-adaptive grouping mechanism. Specifically, a dual-head self-correlation module is introduced to calculate comprehensive importance scores for each point, enhancing the model’s ability to prioritize key features. Using these importance scores, a dual-threshold self-correlative farthest point sampling (DTSC-FPS) method is applied to retain key non-local information points during downsampling in set abstraction (SA). Additionally, a radius-adaptive grouping mechanism is designed to dynamically adjust the candidate point aggregation radius, capturing critical features of unconventional objects and supporting multi-scale feature processing. Finally, a novel regression loss function is constructed to improve prediction accuracy and balanced performance across objects of different sizes, ensuring reliable performance of Mine-SSD in multi-scale detection. Extensive experiments on an open-pit mine dataset validate the effectiveness of Mine-SSD.},
  archive      = {J_NEUCOM},
  author       = {Zhongyu Xie and Yuqian Zhao and Fan Zhang and Biao Luo and Wenliu Hu and Tenghai Qiu},
  doi          = {10.1016/j.neucom.2025.131507},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131507},
  shortjournal = {Neurocomputing},
  title        = {Mine-SSD: Dual-threshold set abstraction and radius-adaptive grouping for 3D object detection in open-pit mines},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SRDA: Self-regulating distribution alignment based on prompt learning for unsupervised domain adaptation. <em>NEUCOM</em>, <em>657</em>, 131498. (<a href='https://doi.org/10.1016/j.neucom.2025.131498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although large-scale pre-trained vision–language models (VLMs) exhibit significant potential for cross-domain visual tasks, existing prompt-learning-based unsupervised domain adaptation (UDA) methods suffer from source domain overfitting and target domain performance degradation. This paper experimentally demonstrates that conventional prompt learning exhibits insufficient cross-domain generalization due to optimization being heavily biased toward the source distribution. To address this challenge, we propose a Self-regulating Distribution Alignment (SRDA) framework. Its core innovation is a dual-branch collaborative optimization mechanism that dynamically balances cross-domain semantic alignment with pre-trained knowledge preservation. Specifically, the self-regulating multimodal prompt branch incorporates three constraints: semantic consistency regularization, dual-domain collaborative contrastive regularization, and text semantic diversity enhancement. This design suppresses prompt overfitting to the source domain while preserving CLIP’s zero-shot generalization capability. The cross-domain alignment branch introduces dynamic dual-domain feature bank and Cross-domain Collaborative Dual Attention module, achieving fine-grained local semantic calibration through moving average prototypes and a dual-layer attention mechanism. Extensive experiments validate SRDA’s effectiveness on downstream UDA tasks. The code is available at https://github.com/QYw12/SRDA .},
  archive      = {J_NEUCOM},
  author       = {Yang Qu and Jinlong Shi and Yun Cui and Ao Zhang and Suqin Bai and Ye Lu},
  doi          = {10.1016/j.neucom.2025.131498},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131498},
  shortjournal = {Neurocomputing},
  title        = {SRDA: Self-regulating distribution alignment based on prompt learning for unsupervised domain adaptation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault-tolerant synchronization of drive-response memristive competitive neural networks with multiple actuator failures. <em>NEUCOM</em>, <em>657</em>, 131489. (<a href='https://doi.org/10.1016/j.neucom.2025.131489'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the synchronization of drive-response memristive competitive neural networks (MCNNs) under multiple actuator failures is studied through implementing fault-tolerant control scheme. Unlike previous studies, the actuator failures considered in this paper include both bias and effectiveness failures. To address these challenges, a proper mathematical model is first established to capture the impact of actuator failures on control inputs. Subsequently, several sufficient conditions are deduced by designing an appropriate bilayer fault-tolerant controller and constructing a Lyapunov functional to achieve the global exponential synchronization, finite-time synchronization, fixed-time synchronization and predefined-time synchronization respectively. Additionally, the settling time upper bounds for the proposed synchronization methods are determined. In the end, numerical simulations with analysis and comparison are performed to confirm the validity of the proposed results.},
  archive      = {J_NEUCOM},
  author       = {Wenjing Duan and Yanli Huang and Quang Dan Le and Tse Chiu Wong},
  doi          = {10.1016/j.neucom.2025.131489},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131489},
  shortjournal = {Neurocomputing},
  title        = {Fault-tolerant synchronization of drive-response memristive competitive neural networks with multiple actuator failures},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double-boundary awareness of shared categories for source-free universal domain adaptation. <em>NEUCOM</em>, <em>657</em>, 131473. (<a href='https://doi.org/10.1016/j.neucom.2025.131473'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-Free Universal Domain Adaptation (SF-UniDA) aims to adapt a pre-trained source model to an unlabeled target domain without access to source data or prior knowledge of cross-domain category shifts. Existing methods focus on distinguishing target-private unknown samples and assigning pseudo-labels to known samples across the entire label space, including both shared and source-private categories as pseudo-labels, for self-training. However, this data-aware pseudo-labeling approach could mistakenly assign known samples to either source-private or target-private categories, making it sensitive to category shifts and potentially introducing errors or mislabeling. In this paper, we propose Double-boundary Awareness Domain Adaptation (DADA), a class-aware framework that partitions the target domain pseudo-label space into shared, potential source-private, and target-private categories. By labeling target-private samples as unknown and filtering out misassigned source-private samples, DADA enhances the quality of target samples and the reliability of pseudo-labels. To achieve this, we introduce Double-bounded Shared Categories Refinement (DSCR) module, which refines shared classes by identifying both source- and target-private categories based on prior class probabilities and the entropy distribution. Additionally, we incorporate Class-Aware Discriminative Learning (CADL) to enhance discrimination between shared and target-private samples across domains. Experiments on four benchmarks demonstrate the effectiveness of DADA, with overall H-score gains of 8.2 % in the OPDA scenario on Digit dataset and accuracy gains of 10.6 % in the PDA scenario on VisDA dataset. Code is available at: https://github.com/W2Wzj/DADA .},
  archive      = {J_NEUCOM},
  author       = {Zhijing Wang and Ji Guo and Xu Sun and Yi Luo and Aiguo Chen},
  doi          = {10.1016/j.neucom.2025.131473},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131473},
  shortjournal = {Neurocomputing},
  title        = {Double-boundary awareness of shared categories for source-free universal domain adaptation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SGN: Stochastic guidance network for sim-to-real generalization. <em>NEUCOM</em>, <em>657</em>, 131468. (<a href='https://doi.org/10.1016/j.neucom.2025.131468'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significant domain differences between synthetic data and real data are a challenging problem for current domain generalized segmentation networks. Therefore, this paper proposes a stochastic guidance network (SGN) for sim-to-real generalization that includes the category reweighting strategy, Multi-scale Feature Fusion Guidance (MSFFG) module and multiple style perturbation modules, which improves the issues caused by the imbalance of the source domain’s sample categories as well as large domain gap. Experimental results show that our SGN can effectively enhance the model’s generalization ability to unseen data. In terms of mean intersection over union (mIoU) metric, compared with SOTA, the SGN improves by 3.86 % and 2.05 % respectively on two real scene-enhanced datasets(Rain_Cityscapes, Foggy_Cityscapes), and an average improvement of 1.48 % on four conventional datasets (BDD100k, Cityscapes, Mapillary, Synthia). Our project can be found at https://githubcom/leo-lab-511/SGN.},
  archive      = {J_NEUCOM},
  author       = {Yao Li and Jinlong Shi and Yun Cui and Dan Xu and Wei Teng and Yan Jiang},
  doi          = {10.1016/j.neucom.2025.131468},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131468},
  shortjournal = {Neurocomputing},
  title        = {SGN: Stochastic guidance network for sim-to-real generalization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdvOT: Oblivious transfer based on generative adversarial networks against multiple attackers. <em>NEUCOM</em>, <em>657</em>, 131449. (<a href='https://doi.org/10.1016/j.neucom.2025.131449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oblivious Transfer (OT) is crucial in various security protocols, as it serves as a privacy-preserving and secure communication protocol. However, traditional OT protocols often necessitate complex encryption algorithms and involve intricate steps. Given the rapid advancements in artificial intelligence, it is imperative to explore the potential of artificial neural networks in simplifying OT protocols while still meeting stringent security and privacy requirements. To this need, we introduce the Adv ersarial O blivious T ransfer (AdvOT) protocol, which integrates OT with the adversarial learning mechanism of Generative Adversarial Network (GAN). Our approach involves training a neural network model to learn encryption techniques through end-to-end adversarial training, thereby eliminating the reliance on specific algorithms. The AdvOT protocol comprises two phases. Firstly, a Random Oblivious Transfer (ROT) protocol is employed to generate and distribute keys based on the CKKS homomorphic encryption algorithm. Subsequently, neural networks are introduced to replace specific symmetric encryption algorithms and encrypt the messages to be transferred. These neural networks undergo training using the adversarial learning mechanism to develop a symmetric encryption algorithm. Furthermore, to enhance the model, attack networks with varying capabilities are created, resulting in a more secure encryption algorithm capable of withstanding multiple attackers. Experimental results demonstrate that the execution speed of the CKKS-based ROT algorithm is significantly faster compared to the BFV and Paillier algorithms. Moreover, in adversarial network models with multiple attackers, the decryption accuracy for the recipient approaches 100 %, while the accuracy or classification error rate for attackers is approximately 50 %. These findings indicate that the proposed method effectively safeguarded communication between parties from interception.},
  archive      = {J_NEUCOM},
  author       = {Yuke Wang and Zhentian Zhong and Ninghao Liu and Xiaohui Li and Junfeng Wang},
  doi          = {10.1016/j.neucom.2025.131449},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131449},
  shortjournal = {Neurocomputing},
  title        = {AdvOT: Oblivious transfer based on generative adversarial networks against multiple attackers},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Challenges and advancements in modeling shock fronts with physics-informed neural networks: A review and benchmarking study. <em>NEUCOM</em>, <em>657</em>, 131440. (<a href='https://doi.org/10.1016/j.neucom.2025.131440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving partial differential equations (PDEs) with discontinuous solutions—such as shock waves in multiphase viscous flow in porous media—is critical for a wide range of scientific and engineering applications, as they represent sudden changes in physical quantities. Physics-Informed Neural Networks (PINNs), an approach proposed for solving PDEs, encounter significant challenges when applied to such systems. Accurately solving PDEs with discontinuities using PINNs requires specialized techniques to ensure effective solution accuracy and numerical stability. Various methods have been developed to address the challenges of modeling discontinuities within the PINNs framework. This work reviews and benchmarks these approaches across problems of varying complexity, categorizing them into three broad groups, influencing solution accuracy differently. (1) Physics-modification (PM) methods improve accuracy by modifying the system’s physics, such as adding artificial viscosity or enforcing entropy constraints. (2) Loss and training modification (LM) techniques focus on regularizing the loss landscape, often by refining the loss term in high-error regions. (3) Architecture-modification (AM) approaches, on the other hand, propose advanced network designs to handle discontinuities better. A benchmarking study was conducted on two multiphase flow problems in porous media: the classic Buckley-Leverett (BL) problem and a fully coupled system of equations involving shock waves but with varying levels of solution complexity. The findings show that PM and LM approaches can provide accurate solutions for the BL problem by effectively addressing the infinite gradients associated with shock occurrences. In contrast, AM methods failed to effectively resolve the shock waves. When applied to fully coupled PDEs (with more complex loss landscapes), the generalization error in the solutions quickly increased, highlighting the need for ongoing innovation. This study provides a comprehensive review of existing techniques for managing PDE discontinuities using PINNs, offering information on their strengths and limitations. The results underscore the necessity for further research to improve PINNs’ ability to handle complex discontinuities, particularly in more challenging problems with complex loss landscapes. This includes problems involving higher dimensions or multiphysics systems, where current methods often struggle to maintain accuracy and efficiency.},
  archive      = {J_NEUCOM},
  author       = {Jassem Abbasi and Ameya D. Jagtap and Ben Moseley and Aksel Hiorth and Pål Østebø Andersen},
  doi          = {10.1016/j.neucom.2025.131440},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131440},
  shortjournal = {Neurocomputing},
  title        = {Challenges and advancements in modeling shock fronts with physics-informed neural networks: A review and benchmarking study},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SparseSCIGaussian: Sparse snapshot compressed images 3D gaussian splatting. <em>NEUCOM</em>, <em>657</em>, 131422. (<a href='https://doi.org/10.1016/j.neucom.2025.131422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose SparseSCIGaussian, a novel method for achieving high-quality novel view synthesis under sparse input conditions. Previous methods often rely heavily on depth or neural priors, which can lead to generalization challenges and significant quality degradation on complex datasets. These limitations arise primarily from the insufficient scene information available in sparse regular images. To overcome these issues, our approach utilizes images captured through Snapshot Compressive Imaging (SCI) as input. SCI-captured images inherently encode richer scene information compared to regular images, thereby substantially improving the quality of novel view synthesis under sparse input conditions. Moreover, SCI images can be conveniently captured using a software-implemented encoder, making them as accessible as traditional images. Experimental results demonstrate that our method improves 2.65 dB (13.04 %) in PSNR compared to previous methods, and further exhibits the inherent advantages of using SCI images for sparse input novel view synthesis.},
  archive      = {J_NEUCOM},
  author       = {Haoyuan He and Xuan Wang and Nanning Zheng and Caigui Jiang},
  doi          = {10.1016/j.neucom.2025.131422},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131422},
  shortjournal = {Neurocomputing},
  title        = {SparseSCIGaussian: Sparse snapshot compressed images 3D gaussian splatting},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RehearMixup: Improving rehearsal-based continual learning. <em>NEUCOM</em>, <em>657</em>, 131404. (<a href='https://doi.org/10.1016/j.neucom.2025.131404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks often suffer from catastrophic forgetting when learning new tasks, leading to the loss of previously acquired knowledge. To address this issue, rehearsal-based methods have emerged, which involve storing a subset of data from previous tasks and accessing it during the learning of new tasks. Current rehearsal-based methods focus on selecting representative samples to store in memory. However, there is a considerable lack of exploration of how to exploit the data at hand and consider the correlation between tasks or between past and new knowledge to improve performance. Therefore, we propose a simple yet effective approach named RehearMixup that adapts the Mixup technique into rehearsal-based methods, which synthesizes new samples for learning by interpolating data from past or current tasks. Specifically, we introduce three strategies, namely Cross-Mixup , Intra-Memory-Mixup , and Intra-Current-Mixup , based on the inherent characteristics of rehearsal-based methods - involving the memory and new tasks. Through empirical evaluations under various benchmark scenarios, we compare our approach against different rehearsal-based baselines. The results demonstrate that ours, particularly Intra-Current-Mixup , improves accuracy, backward transfer, forward transfer, and enhances the model’s robustness.},
  archive      = {J_NEUCOM},
  author       = {Yan Zhang and Kaiyuan Qi and Dong Wu and Guoqiang Wu and Yilong Yin},
  doi          = {10.1016/j.neucom.2025.131404},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131404},
  shortjournal = {Neurocomputing},
  title        = {RehearMixup: Improving rehearsal-based continual learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A zero-shot high-performance fire detection framework based on large language models. <em>NEUCOM</em>, <em>657</em>, 131403. (<a href='https://doi.org/10.1016/j.neucom.2025.131403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fire detection is crucial for minimizing economic damage and safeguarding human lives. Existing methods, including advanced AI and ML techniques, face challenges such as detecting small fires in complex environments and relying on extensive labeled data for training. This paper proposes a novel zero-shot fire detection framework leveraging large language models (LLMs) and contrastive learning-based image–text pre-training models. The framework introduces an enhanced self-attention mechanism for optimizing image embeddings, diverse prompt generation using GPT-3.5 for improved generalization, and a dynamic threshold calculation method based on statistical analysis to enhance detection accuracy and reliability. The proposed method is tested on the public FLAME dataset and a self-collected dataset. Experimental results demonstrate that the proposed method outperforms state-of-the-art models in detecting small fires within complex backgrounds, achieving better detection performance without the need for any training data. This study highlights the potential of zero-shot learning in fire detection and provides a promising solution for real-world fire detection applications.},
  archive      = {J_NEUCOM},
  author       = {Hongyang Zhao and Yi Liu and Yuhang Han and Xingdong Li and Yanan Guo and Jing Jin},
  doi          = {10.1016/j.neucom.2025.131403},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131403},
  shortjournal = {Neurocomputing},
  title        = {A zero-shot high-performance fire detection framework based on large language models},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hetero-MoE by attention: Three-plus tasks learning solver. <em>NEUCOM</em>, <em>657</em>, 131333. (<a href='https://doi.org/10.1016/j.neucom.2025.131333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning (MTL) stands as a promising sub-field of machine learning, aiming to simultaneously tackle multiple tasks. By leveraging shared representations and structures across diverse tasks, MTL models often exhibit higher data efficiency compared to single-task models across various domains, including recommender system applications, multi-label classification and other AI applications. However, the efficacy of MTL models is sometimes hindered by the multi-causal task conflict problem. To address this challenge, existing research predominantly focuses on enhancing structural designs and the underlying optimizers. Nevertheless, these approaches often fall short in comprehensively mitigating task conflicts, especially in scenarios involving three or more tasks, such as recommender systems. When shared experts contend with excessive task-related information simultaneously, the effective filtration of potentially harmful knowledge becomes challenging. To this end, we propose a novel Heterogeneous Multi-Expert model with an attention layer, termed HMEA. HMEA introduces Heterogeneous Experts as shared experts to decompose signal connections among three or more tasks. Additionally, it integrates an attention layer to further decouple conflicts among mini-tasks within shared experts. The experiments and ablation studies on various standard and synthetic datasets illustrate the effectiveness of HMEA in alleviating the task conflict problem inherent in three-plus task learning systems.},
  archive      = {J_NEUCOM},
  author       = {Dandan Zhang and Guanqi Zeng and Haotian Wu and Hongwen Zhang and Zheng Ye and Yao Yang},
  doi          = {10.1016/j.neucom.2025.131333},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131333},
  shortjournal = {Neurocomputing},
  title        = {Hetero-MoE by attention: Three-plus tasks learning solver},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
