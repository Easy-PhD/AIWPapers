<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EAAI</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="eaai">EAAI - 200</h2>
<ul>
<li><details>
<summary>
(2025). Driver risk classification for transportation safety: A machine learning approach using psychological, physiological, and demographic factors with driving simulator. <em>EAAI</em>, <em>162</em>, 112585. (<a href='https://doi.org/10.1016/j.engappai.2025.112585'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving behavior is a critical factor in ensuring road safety, particularly in commercial transportation sectors where hiring safe and reliable drivers is a priority. This study presents a machine learning-based framework for predicting driver behavior using multimodal assessments, including psychological, physiological, and demographic factors. We utilized a driving simulator equipped with biometric sensors to capture the physiological data of the driver, including heart rate, eye blink rate, pupil diameter, and point of gaze (POG), during driving sessions. The psychological attributes are collected through a self-report questionnaire. The questionnaire is structured to obtain information about nine psychological characteristics of the driver, including instrumental attitude, social anxiety, sensation seeking, premeditation, urgency, selfishness, aggressive mode, life satisfaction, and conscientiousness. In addition, some demographic attributes, such as age and gender, are also adopted to study their effect on driving behavior. Experiments were conducted on 80 participants, each driving for 10 min. Various machine learning models, along with a feature selection strategy, were used to find the relationship between the driver's modalities and his driving behavior. Results demonstrate that the k-nearest neighbors (KNN) model achieved the best performance, yielding an accuracy of 93.75 % and a False Negative Rate (FNR) of 0. Feature importance analysis revealed that gaze distraction, sensation seeking, conscientiousness, and gender are the best predictors of driving behavior. The findings suggest that our model can serve as a valuable decision-support tool for taxi companies and transportation agencies aiming to enhance driver selection processes by identifying drivers with lower accident risks.},
  archive      = {J_EAAI},
  author       = {Malek Masmoudi and Yasmin Shakrouf and Omar Hassan Omar and Amir Shikhli and Fatima Abdalla and Wadad Alketbi and Imad Alsyouf and Ali Cheaitou and Anwar Jarndal and Ali I. Siam},
  doi          = {10.1016/j.engappai.2025.112585},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112585},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Driver risk classification for transportation safety: A machine learning approach using psychological, physiological, and demographic factors with driving simulator},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-based pre-compensator design for piezoelectric actuators based on physics guided neural network and physics-precision balanced training. <em>EAAI</em>, <em>162</em>, 112576. (<a href='https://doi.org/10.1016/j.engappai.2025.112576'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing model-based pre-compensators is crucial for achieving high-precision motion control in piezoelectric actuators (PEAs), which exhibit complex nonlinear behaviors. While data-based modeling methods offer a straightforward approach, they face challenges with poor extrapolation and high complexity. Incorporating the known physics of PEAs, which is more consistent with physical principles and computationally efficient, can help overcome these limitations. Based on the above knowledge, this paper embeds physical knowledge within a neural network, forming a novel Physics Guided Neural Network (PGNN) structure as a model-based PEA pre-compensator to achieve high motion precision. Training the PGNN is challenging due to potential competition between the physics component and the neural network. The flexible nature of the neural network can easily overshadow the physical information, leading to overfitting and rendering the PGNN model ineffective. To address this, a Physics-Precision Balanced Training (PPBT) method is proposed. In the PPBT method, the physical correctness and model precision of the PGNN are mathematically defined, and these two components are balanced through a nonlinear function within the training algorithm. Experimental results show that the proposed pre-compensator based on PGNN and PPBT outperforms physics-based approaches in precision and offers greater robustness than purely data-based methods. The peak-to-peak displacement error is reduced to less than 35 nm in open-loop control. Measured by Mean Absolute Error (MAE), this method reduces displacement errors by 89 % compared to no compensation, by 77 % compared to purely neural network-based compensation, and by 73 % compared to rate-dependent Prandtl-Ishlinskii operator-based compensation.},
  archive      = {J_EAAI},
  author       = {Qin Li and Zhiwei Ruan and Chenyang Ding},
  doi          = {10.1016/j.engappai.2025.112576},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112576},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Model-based pre-compensator design for piezoelectric actuators based on physics guided neural network and physics-precision balanced training},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-to-end burst signal demodulation via adaptive masked deep learning framework. <em>EAAI</em>, <em>162</em>, 112569. (<a href='https://doi.org/10.1016/j.engappai.2025.112569'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bit error rate (BER) directly determines the quality of wireless communication transmission. Traditional demodulators are limited in operating on burst signals and exhibit poor BER performance in low signal-to-noise ratio (SNR) conditions. For real-world burst signals, symbol-by-symbol approaches fail to capture inter-symbol dependencies, and existing end-to-end frameworks cannot handle the variable output lengths required for burst signals. To address this issue, we propose an end-to-end demodulation framework based on deep learning (DL), in which detection, recognition, channel compensation, and demodulation stages were trained as a unified system, enabling the entire signal burst to be demodulated in a single operation during inference. The framework's generalization and robustness are enhanced by a proposed masking mechanism and a denoising autoencoder (DAE), respectively. The former dynamically adjusts the output bitstream length while preventing gradient flow from redundant components, and the latter compensates for channel fading effects. We further introduce a dedicated end-to-end training strategy to optimize the adaptation between these modules. Experimental results on real-world Frequency Shift Keying (FSK), Minimum Shift Keying (MSK), Phase-Shift Keying (PSK), and Quadrature Amplitude Modulation (QAM) signals demonstrate that the proposed framework achieves superior demodulation accuracy for long-sequence burst signals. Compared to existing methods, the proposed framework enables parallel demodulation, and dynamically adapts the output bit stream in terms of varying message types and lengths.},
  archive      = {J_EAAI},
  author       = {Mingdi Li and Wenzhe Fan and Yanbin Li and Chunlei Xie and Yanan Duan},
  doi          = {10.1016/j.engappai.2025.112569},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112569},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {End-to-end burst signal demodulation via adaptive masked deep learning framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mechanical properties prediction of bi-metal foam sandwiches using machine learning methods and elastic deformation behaviour. <em>EAAI</em>, <em>162</em>, 112560. (<a href='https://doi.org/10.1016/j.engappai.2025.112560'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal foam sandwiches are a kind of ultra-lightweight material made from a porous metal core bonded to two face sheets. Friction stir welding (FSW) is utilised in welding bimetal foam sandwiches. It is worth mentioning that the exact relation between mechanical properties and process parameters is challenging to determine. The innovation lies in the non-destructive estimation of mechanical properties (Young's modulus, ultimate tensile strength and fracture strain) through elastic deformation data and the novel application of artificial intelligence techniques optimised by genetic algorithms, eliminating dependency on input process parameters. After proper network training, three methods are employed to estimate these mechanical properties: a decision tree, a feedforward neural network and long-short term memory. These are chosen to investigate the influence of both machine/deep learning methods in predicting the mechanical properties of the FSW final product. Moreover, a genetic algorithm is employed to find the optimal hyperparameters of the three investigated prediction models to reach the highest accuracy. The results prove the efficiency of the proposed feedforward neural network in the estimation of Young's modulus and ultimate tensile strength for the bi-metal foam sandwiches with lower mean absolute error (MAE) and higher correlation coefficient compared to the decision tree (63.9 % lower MAE and 25.50 % higher correlation coefficient) and long-short term memory (77.50 % lower MAE and 25.05 % higher correlation coefficient). In addition, the proposed decision tree model accurately predicts the fracture strain with R-square and root mean square error as 0.61429 and 1.3862 × 10 −5 , respectively.},
  archive      = {J_EAAI},
  author       = {Mohammad Reza Chalak Qazani and Mohsen Dorudgar and Mehdi Moayyedian and Abdel-Hamid I. Mourad and Moosa Sajed and S.M. Hossein Seyedkashi and Siamak Pedrammehr},
  doi          = {10.1016/j.engappai.2025.112560},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112560},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mechanical properties prediction of bi-metal foam sandwiches using machine learning methods and elastic deformation behaviour},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal unified generalization and translation network for intelligent fault diagnosis under dynamic environments. <em>EAAI</em>, <em>162</em>, 112559. (<a href='https://doi.org/10.1016/j.engappai.2025.112559'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal data fusion can generate reliable fault representations for intelligent fault diagnosis. However, simple data fusion strategies often introduce fault-irrelevant information, thereby reducing robustness against unknown domain shifts. Moreover, traditional methods generally lack adaptive mechanisms to address missing modalities, leading to considerable performance degradation under sensor failure conditions. To address these problems, this paper proposes a multimodal unified generalization and translation network. To learn invariant unified representations for resisting unknown data distribution shifts, information-enhanced concatenation first generates intra-domain and cross-domain representations. Subsequently, mutual information maximization is applied to remove fault-unrelated information from these representations. Finally, A hybrid ensemble diagnosis strategy fully leverages the interaction of multimodal information across different levels. In addition, semantic supervision investigates the relationships among different modalities and enables intermodal translation in the event of a sensor failure within the monitoring system. Extensive experimental results based on a public bearing dataset and a self-collected motor dataset indicate that the proposed method improves accuracy by 10.53 % and 8.47 % compared to the state-of-the-art methods, respectively. The code and datasets are available at https://github.com/CHAOZHAO-1/MUGTN .},
  archive      = {J_EAAI},
  author       = {Chao Zhao and Weiming Shen and Enrico Zio and Hui Ma},
  doi          = {10.1016/j.engappai.2025.112559},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112559},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodal unified generalization and translation network for intelligent fault diagnosis under dynamic environments},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FabricMamba: A fabric surface defect detection system based on large kernel attention and visual state space. <em>EAAI</em>, <em>162</em>, 112558. (<a href='https://doi.org/10.1016/j.engappai.2025.112558'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the textile manufacturing industry, fabric defect detection is essential for ensuring product quality. Traditional approaches based on Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) often encounter scalability issues, particularly due to the high computational complexity of the self-attention mechanism in ViTs. To address these limitations, this study introduces FabricMamba, a real-time defect detection framework built on the You Only Look Once version 8 (YOLOv8) CNN architecture. The model enhances detection precision and efficiency for complex fabric defects in high-resolution images while minimizing computational cost. YOLOv8 was selected as the base model due to its strong balance between accuracy and inference speed, which is critical in fast-paced textile production settings. FabricMamba extends YOLOv8 with several innovations: the Parallel Large Separable Kernel Attention (P-LSKA) mechanism for multi-scale perception, the Visual State Space Module (MVSS) for long-range dependency modeling, the lightweight DySample module for reduced resource usage, and Programmable Gradient Information (PGI) to optimize training without increasing inference complexity. Extensive evaluations were conducted using a proprietary industrial fabric defect dataset and two public benchmarks, TILDA Textile Texture Database and FDDS Object Detection Dataset. FabricMamba achieved a mean Average Precision (mAP) of 90.0 %, 97.7 %, and 39.1 % on the respective datasets, outperforming the YOLOv8 baseline by 1.8 %, 2.3 %, and 2.0 %. Compared to Mamba-YOLO, FabricMamba reduced model size and computational requirements by 36.7 % and 33.1 %, respectively, with recall improving by 2.9 %, 1.4 %, and 4.0 %. These results confirm the model effectiveness and practical potential for industrial fabric inspection tasks.},
  archive      = {J_EAAI},
  author       = {Nengsheng Bao and Jiajun Lin and Yuchen Fan and Runxuan Bao and Alessandro Simeone},
  doi          = {10.1016/j.engappai.2025.112558},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112558},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {FabricMamba: A fabric surface defect detection system based on large kernel attention and visual state space},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing performance metrics with new distance and similarity measures using control parameters of linear diophantine fuzzy sets. <em>EAAI</em>, <em>162</em>, 112557. (<a href='https://doi.org/10.1016/j.engappai.2025.112557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The control parameters (CPs) of linear Diophantine fuzzy sets (LDFSs) provide an innovative approach for information analysis in the multi-criteria decision making (MCDM), machine learning (ML), and computational intelligence (CI). The CPs give freedom to the decision-makers in evaluating feasible alternatives in measuring performance metrics. Previous fuzzy MCDM methods often meet strict limitations in handling real-world uncertainty and dynamic MCDM. To overcome these limitations, this study extends the Preference Ranking Organization Method for Enrichment of Evaluations (PROMETHEE-II) method to linear Diophantine fuzzy sets (LDFSs) for more flexible and robust MCDM approach. The proposed MCDM approach primarily evaluates performance metrics criterion, utilizing LDFSs which are robust extension of fuzzy sets (FSs), intuitionistic fuzzy sets (IFSs) as well as interval-valued intuitionistic fuzzy sets (IVIFSs). It helps decision makers to address uncertain information with membership degree (MD), non-membership degree (NMD), and CPs. For this objective, new LDFS based distance measures (DMs) and similarity measures (SMs) are developed for the construction of LDFS PROMETHEE-II technique. The proposed MCDM approach provides a structured and comprehensive framework for optimizing investment performance metrics. Its robustness is validated through sensitivity and comparative analyses.},
  archive      = {J_EAAI},
  author       = {Masooma Raza Hashmi and Muhammad Riaz and Arshid Mahmood and Muhammad Ajmaeen and Muhammad Aslam},
  doi          = {10.1016/j.engappai.2025.112557},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112557},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing performance metrics with new distance and similarity measures using control parameters of linear diophantine fuzzy sets},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamic capsule network-based physical alert monitoring system for elderly people with disabilities. <em>EAAI</em>, <em>162</em>, 112556. (<a href='https://doi.org/10.1016/j.engappai.2025.112556'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Elderly disabled people have higher health risks due to reduced mobility, delayed emergency response, and poor real-time monitoring. Existing Internet of Things (IoT) based monitoring systems frequently have static thresholds, lack personalization, and struggle to capture complex physical and physiological fluctuations, resulting in false alerts and reduced reliability. We propose a Dynamic Capsule Network-Based Physical Alert Monitoring System (DyCN-PAM) for intelligent, real-time monitoring of elderly disabled people to overcome these constraints. Compiling accelerometer, gyroscope, and heart rate readings, and utilizing capsule routing to preserve spatiotemporal hierarchies, enables the system to detect falls, seizures, and fainting. Context-aware alerts utilize capsule confidence and heart rate baselines to distinguish between typical changes and catastrophic emergencies. The DyCN-PAM system outperforms benchmark models in terms of accuracy and robustness, achieving a 5.13 % increase in F1-score, a 28.6 % increase in precision, a 45.1 % reduction in false alarms, and a 26.3 % improvement in computational efficiency. The DyCN-PAM system enhances accuracy, precision, and efficiency, making it feasible to improve safety, independence, and quality of life for older individuals with disabilities. More real-world experiments are needed to prove its use.},
  archive      = {J_EAAI},
  author       = {Shujuan Feng and Hongying Zhu and Yangkai Wu and Ziheng Zeng and Ezzeddine Touti and Jinming Wang and Amar Jain},
  doi          = {10.1016/j.engappai.2025.112556},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112556},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A dynamic capsule network-based physical alert monitoring system for elderly people with disabilities},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning driven prediction of dynamic stress-strain response in limestone: Insights into transient mechanical behavior under complex loadings for shield tunneling. <em>EAAI</em>, <em>162</em>, 112554. (<a href='https://doi.org/10.1016/j.engappai.2025.112554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex geological conditions pose a serious challenge to improving the rock-breaking efficiency of shield cutter machines in subway tunnel constructions. This study develops a three-axis thermal-hydraulic-mechanical (THM) coupled dynamic impact system, which is integrated with a scaled shield cutter model to generate a unique dataset of stress wave propagation under multi-field coupling. A bidirectional long short-term memory (LSTM) neural network with an attention mechanism is proposed to establish a nonlinear time mapping relationship between stress waves. The determination coefficient ( R 2 ) exceeds 0.97, the symmetric mean absolute percentage error ( sMAPE ) is less than 10 %, and the average relative uncertainty ( ARU ) is less than 4 %, confirming its high accuracy and reliability. Based on predictions and test results, the new quantitative laws for the transient dynamics of limestone are further revealed. The results reveal that loading conditions do not alter the correlation trend between loading rate and dynamic parameters but significantly influence the degree of the loading rate's effect. Axial pressure dominates energy absorption with an energy contribution rate of 60 %. Confining pressure amplified the sensitivity of loading rate by 170 %, while THM coupling suppressed the dynamic deformation modulus by over 30 %. The accurate prediction of the nonlinear response of stress waves in limestone by the LSTM neural network establishes the connection between transient dynamic observation and rock fragmentation physics mechanism, providing support for quantifying energy absorption and conversion in the rock fragmentation process, and providing key strategies for optimizing shield machine performance in extreme environments.},
  archive      = {J_EAAI},
  author       = {Baoping Zou and Kejian Xia and Jingyuan Ma and Xu Long},
  doi          = {10.1016/j.engappai.2025.112554},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112554},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning driven prediction of dynamic stress-strain response in limestone: Insights into transient mechanical behavior under complex loadings for shield tunneling},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning-tuning hierarchical vehicle trajectory tracking framework based on improved kinematic model predictive control. <em>EAAI</em>, <em>162</em>, 112551. (<a href='https://doi.org/10.1016/j.engappai.2025.112551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory tracking is crucial in vehicle control, as it ensures stable driving along a predefined path. This paper proposes a deep reinforcement learning (DRL)-tuning hierarchical trajectory tracking framework, aiming to improve the tracking accuracy of traditional kinematic model predictive control (MPC) methods in uncertain environments. The proposed hierarchical vehicle trajectory tracking framework consists of two layers: the upper layer serves as a compensation layer for the vehicle side-slip angle (VSA), designed using bidirectional long short-term memory (BiLSTM); while the lower layer is the trajectory tracking layer, in which the improved kinematic MPC is enhanced by integrating the twin delayed deep deterministic policy gradient (TD3) algorithm with an external attention (EA) mechanism. The contribution in artificial intelligence is improving the TD3 algorithm with the EA mechanism, enhancing its ability to capture contextual information and improve adaptability. The contribution in engineering applications is implementing the EA-TD3-tuned hierarchical kinematic MPC framework in the field of vehicle trajectory tracking. With 95 % confidence, compared to traditional kinematic MPC controller, the proposed hierarchical vehicle trajectory tracking framework reduces the average lateral error by 33 % (confidence interval, CI: [0.0616, 0.0850]), the average heading angle error by 34 % (CI: [0.01173, 0.0157]), the average yaw rate variation by 31 % (CI: [0.0244, 0.0346]), and the average front wheel steering angle variation by 28 % (CI: [0.0244, 0.0346]).},
  archive      = {J_EAAI},
  author       = {Jiankun Peng and Xingyan Liu and Changcheng Wu and Dawei Pi and Jiaxuan Zhou},
  doi          = {10.1016/j.engappai.2025.112551},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112551},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep reinforcement learning-tuning hierarchical vehicle trajectory tracking framework based on improved kinematic model predictive control},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel decomposition-prediction hybrid model improved by dual-channel cross-attention mechanism for short-term wind speed prediction. <em>EAAI</em>, <em>162</em>, 112550. (<a href='https://doi.org/10.1016/j.engappai.2025.112550'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of wind energy is crucial for ensuring the safe operation and stability of power systems. To improve the accuracy and robustness of wind speed (WS) forecasting, a novel hybrid method based on mixture of experts (MoE), Transformer, temporal convolution network (TCN), multi-head attention (MA) mechanism, and improved by dual-channel cross-attention mechanism (DCCAM) is proposed. The wind speed data is decomposed by MoE into seasonal and trend components. The trend features are directly captured through a multi-head attention mechanism. An innovative Transformer-TCN framework associated with DCCAM is designed to handle the seasonal component, wherein the Transformer-TCN can make full use of long dependency modeling of Transformer and the local feature extraction of TCN, and DCCAM enables the information interchange and feature fusion, therefore realizing complementary advantages. Based on the proposed model, a series of experiments are conducted on multiple datasets. Ablation experiments confirm the effectiveness of the model and the role of each module in performance improvement. Experiments on seasonal datasets, including spring, summer, autumn, and winter, show that the proposed model can effectively adapt to variations in amplitude and volatility of wind speed sequences under different climatic conditions. Comparative experiments with six advanced hybrid models including decomposition and prediction modules, further demonstrate the superiority and stability of the proposed model.},
  archive      = {J_EAAI},
  author       = {Donghan Geng and Haiteng Cui and Leisen Lv and Jiamin Guo},
  doi          = {10.1016/j.engappai.2025.112550},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112550},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel decomposition-prediction hybrid model improved by dual-channel cross-attention mechanism for short-term wind speed prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A digital twin-assisted algorithm for diagnosis of permanent magnet synchronous generator interturn short circuit fault and converter open circuit fault in wind power systems using pearson correlation coefficient. <em>EAAI</em>, <em>162</em>, 112547. (<a href='https://doi.org/10.1016/j.engappai.2025.112547'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interturn short-circuit faults (ISCFs) in permanent magnet synchronous generators (PMSGs) and open-circuit faults (OCFs) in the machine-side converters represent two critical reliability challenges in wind power systems. Conventional fault diagnosis approaches typically rely on dedicated models for each fault type for each fault type, leading to excessive system complexity and suboptimal computational efficiency. To overcome these limitations, this paper proposes a novel unified digital twin-assisted framework capable of simultaneous diagnosis of both PMSG ISCFs and converter OCFs within a single integrated architecture. The high-fidelity digital twin model based on one-dimensional convolutional neural networks is established to generate real-time reference value of current space vector (SV) for online fault detection, while Pearson correlation coefficient analysis enables accurate differentiation between ISCF and OCF. For ISCFs, the fault severity assessment is performed based on the deviation between reference and measured current SV, with the faulty phase identified using phase current root mean square (RMS) values. In the case of converter OCFs, the proposed method introduces a dual-stage identification process: single and dual insulated-gate bipolar transistor (IGBT) open faults are differentiated through severity estimation analysis, and the faulty IGBT is identified by evaluating the effective current interval ratio (ECIR) and normalized current average (NCA). The experimental results validate the effectiveness of the proposed method, and comparative analysis further demonstrates its superior performance in terms of parameter dependency and diagnostic efficacy.},
  archive      = {J_EAAI},
  author       = {Bin Sun and Ying Zhu and Zhinong Wei},
  doi          = {10.1016/j.engappai.2025.112547},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112547},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A digital twin-assisted algorithm for diagnosis of permanent magnet synchronous generator interturn short circuit fault and converter open circuit fault in wind power systems using pearson correlation coefficient},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multimodal multi-scale fusion network for leak detection in marine piping systems. <em>EAAI</em>, <em>162</em>, 112545. (<a href='https://doi.org/10.1016/j.engappai.2025.112545'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Marine system monitoring data inherently exhibit multimodal characteristics, making artificial intelligence-driven correlation and fusion essential for improving fault feature recognition. However, existing intelligent diagnosis methods mostly focus on feature fusion within homogeneous data types, such as fusing multiple time-series signals or multiple image sets, while systematic exploration of joint representation learning across heterogeneous dimensions remains under-explored. This limitation constrains the recognition capability for complex failure modes. Meanwhile, the inherent differences in physical meanings and representations of multimodal data pose significant challenges in constructing effective correlations, often limiting the performance of mainstream machine learning based fault diagnosis approaches. The proposed method enhances the fault diagnosis capability of mainstream approaches through the fusion of multi-sensor data and visual data, with its core innovation residing in a multimodal fusion framework leveraging attention mechanisms to effectively integrate cross-dimensional representations of multivariate time-series data and imaging data. Compared to existing multimodal transformer techniques, this dual-strategy architecture enables the model to simultaneously capture shared systemic behaviors and modality-unique signatures, substantially elevating diagnosis precision. Experimental validation on real-world leak detection datasets demonstrates that the proposed model achieves F1-scores consistently surpassing 90 % across diverse marine monitoring scenarios, with quantitative evaluations further confirming its superior performance over conventional multivariate time-series diagnosis methods in establishing multimodal correlations, conclusively validating both technical excellence and engineering practicability.},
  archive      = {J_EAAI},
  author       = {Peng Zhang and Chaozhe Li and Shitao Peng and Bomu Tian and Si Luo and Yuewen Zhang and Taili Du},
  doi          = {10.1016/j.engappai.2025.112545},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112545},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multimodal multi-scale fusion network for leak detection in marine piping systems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified rotating machinery health management framework leveraging large language models for diverse components, conditions, and tasks. <em>EAAI</em>, <em>162</em>, 112544. (<a href='https://doi.org/10.1016/j.engappai.2025.112544'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces the Rotating Machinery Large Language Model (RotLLM), a unified framework for rotating machinery health management that integrates deep learning with large language models (LLMs) to address diverse operational conditions, components, and health management tasks. RotLLM employs a novel Spectral Folding Network (SFN) to transform vibration spectrum into a unified feature space that preserves essential health state information. A dedicated projection layer then maps these features into the semantic domain of an LLM. The framework is trained using a three-stage strategy: first, pre-training the encoder on the Large-scale Multimodal Rotating Machinery (LMR) dataset, which comprises 237,298 vibration samples collected under hundreds of operating conditions; second, initializing the projection layer with textual health state labels; and finally, fine-tuning using parameter-efficient Low-Rank Adaptation (LoRA) with high-quality corpus for various health management tasks. Experimental evaluations demonstrate that RotLLM achieves state-of-the-art performance in fault classification, maintains strong robustness under noisy conditions, and delivers rapid multi-task inference with minimal computational overhead. The framework consistently outperforms conventional methods, enabling efficient, accurate, and context-aware health management for rotating machinery across diverse conditions and tasks. The dataset and source code are open-sourced ( https://github.com/SIA-IDE/RotLLM ), fostering collaboration, reproducibility, and broader adoption in industrial prognostics research.},
  archive      = {J_EAAI},
  author       = {Haotian Peng and Jie Gao and Jiawei Liu and Jinsong Du and Wei Wang},
  doi          = {10.1016/j.engappai.2025.112544},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112544},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A unified rotating machinery health management framework leveraging large language models for diverse components, conditions, and tasks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel multi-source heterogeneous data fusion based fault diagnosis framework for manufacturing processes. <em>EAAI</em>, <em>162</em>, 112542. (<a href='https://doi.org/10.1016/j.engappai.2025.112542'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis technologies are important means to ensure the production operation safety and product quality stability for manufacturing processes. After a fault occurs in the manufacturing processes, it may be characterized by high-frequency and high-dimensional structured time series data anomalies such as sensor data, or by unstructured data anomalies such as images. Traditionally, single structured sensor data is often used for constructing diagnosis models, the fault characteristics may not be adequately characterized, thus affecting the diagnosis performance. Therefore, in this paper, in order to make full use of multi-source data and obtain more comprehensive and accurate diagnosis results, a new multi-source heterogeneous data fusion based fault diagnosis framework is designed for manufacturing processes. Specifically, to solve the problem that the important information is ignored during data level fusion of multi-source data, an adaptive weight multi-source data fusion method is proposed. Furthermore, in response to the problem of feature redundancy in feature level fusion of heterogeneous data, a feature differentiation extraction and heterogeneous feature fusion method is proposed, of which a feature source discriminator is constructed for enhancing the complementarity of the extracted heterogeneous features, and feature concatenation is performed to improve the feature expression ability. Finally, the effectiveness and feasibility of the proposed framework is verified on actual datasets from the hot rolling process and the Tennessee Eastman process. Experimental results show that the proposed framework is both effective and feasible in fault diagnosis with multi-source heterogeneous data.},
  archive      = {J_EAAI},
  author       = {Liang Ma and Qikai Yang and Orestes Llanes-Santiago and Kaixiang Peng},
  doi          = {10.1016/j.engappai.2025.112542},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112542},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel multi-source heterogeneous data fusion based fault diagnosis framework for manufacturing processes},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reducing modal differences in zero-shot anomaly detection based on vision-language generation model. <em>EAAI</em>, <em>162</em>, 112541. (<a href='https://doi.org/10.1016/j.engappai.2025.112541'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot anomaly detection methods based on vision-language model rely on alignment between image and text. These methods ignore the inherent differences between different modalities, which is unfavorable for improving the alignment between modalities. This paper reduces modal differences between image and text by using guiding vision feature and text feature from the pre-trained vision-language generation model. The vision perception text embedding is constructed by adding guiding vision feature to the weight shared text prompt. The text perception vision embedding is extracted by a vision text fusion module. The fusion module is designed to promote the visual modality to perceive the textual information locally. Anomaly regions are detected by cosine similarity between cross-modal perception embeddings. Zero-shot anomaly detection performance is evaluated on five publicly available industrial anomaly detection datasets, and a real-world dataset about automotive plastic parts. Experimental results show that the proposed method achieves highly competitive anomaly detection performance on multiple evaluation metrics.},
  archive      = {J_EAAI},
  author       = {Yanan Song and Weiming Shen and Baisong Pan and Quanhui Wu and Dawei Gu},
  doi          = {10.1016/j.engappai.2025.112541},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112541},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reducing modal differences in zero-shot anomaly detection based on vision-language generation model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel short-term prediction method for distributed photovoltaic power generation considering extreme weather. <em>EAAI</em>, <em>162</em>, 112540. (<a href='https://doi.org/10.1016/j.engappai.2025.112540'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed photovoltaic power plants are often impacted by various factors such as weather conditions and geographical locations, making it challenging to fully capture the spatial correlation characteristics among multiple photovoltaic plants. Furthermore, the failure to consider meteorological factors that influence photovoltaic output results in larger prediction errors during extreme weather events. To reduce prediction errors, this paper proposes a short-term photovoltaic forecasting method that considers meteorological factors, explores spatial correlations among photovoltaic plants, and captures temporal characteristics. Firstly, a Graph Attention Network is established to obtain spatial correlations between different plants while a Convolutional Neural Network is employed to extract feature information of meteorological factors. Then, the feature information from these two sources is integrated and input into a Long Short-Term Memory network, which is enhanced based on Spiking Neural P Systems to extract temporal characteristics of photovoltaic output and complete the prediction task. Finally, real-world power station datasets are utilized for validation and comparison with several typical photovoltaic prediction models. The results clearly show that the application of artificial intelligence in this proposed method can effectively improve the accuracy of distributed photovoltaic power forecasting, demonstrating the great potential of AI in the field of photovoltaic power prediction.},
  archive      = {J_EAAI},
  author       = {Xin Guan and Xiao Han and Jun Wang and Tao Wang},
  doi          = {10.1016/j.engappai.2025.112540},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112540},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel short-term prediction method for distributed photovoltaic power generation considering extreme weather},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An innovative method of multi-view face frontalization based on receptive field-enhanced conditional generative adversarial network. <em>EAAI</em>, <em>162</em>, 112539. (<a href='https://doi.org/10.1016/j.engappai.2025.112539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A series of theoretical and experimental investigations based on deep learning were conducted to enhance the accuracy and generalizability of face frontalization models. A series of theoretical investigations and experimental verifications based on deep learning are conducted to further enhance the face frontalization model's accuracy and generalizability. To address inadequate local feature extraction and the low realism in synthesized images, a receptive field-enhanced conditional generative adversarial network (RFC-GAN) is proposed to achieve multi-view face frontalization. RFC-GAN model integrates a novel configuration of multi-scale dilated convolutions in a multi-branch generator architecture to significantly expand the receptive field and improve feature extraction. The unique integration enhances the realism and detail of the generated images. Unlike conventional approaches that focus primarily on pixel-level accuracy, RFC-GAN introduces a perceptual loss component to enhance semantic content and structural integrity at the feature level. RFC-GAN has been experimentally validated on the Karolinska Directed Emotional Faces (KDEF) and Carnegie Mellon University Multiple Pose, Illumination, and Expression Face Database (CMU Multi-PIE). The generated facial expression images from RFC-GAN exhibit a higher degree of detailed texture reproduction in critical facial features such as the eyes, nose, and mouth. On the two datasets, the Peak Signal-to-Noise Ratio (PSNR) reaches 31.5185 for KDEF and 26.1851 for Multi-PIE, the Structural Similarity Index (SSIM) reaches 0.3604 for KDEF and 0.3965 for Multi-PIE, and the Learned Perceptual Image Patch Similarity (LPIPS) reaches 0.117 for KDEF and 0.408 for Multi-PIE, respectively. Compared to existing state-of-the-art methods, RFC-GAN exhibits marked improvements in these metrics, especially in detailed texture reproduction of critical facial features such as the eyes, nose, and mouth, establishing new benchmarks in face frontalization.},
  archive      = {J_EAAI},
  author       = {Yancong Zhou and Dongdong Wang},
  doi          = {10.1016/j.engappai.2025.112539},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112539},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An innovative method of multi-view face frontalization based on receptive field-enhanced conditional generative adversarial network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced air pollution spatiotemporal forecast model using frequency domain convolution and attention mechanism. <em>EAAI</em>, <em>162</em>, 112538. (<a href='https://doi.org/10.1016/j.engappai.2025.112538'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of air pollution, which is crucial for public health and environmental management, often faces challenges in effectively capturing the complex and intertwined spatiotemporal dynamics of pollutants. Existing models frequently struggle to simultaneously account for broad periodic spatiotemporal dependencies as well as fine-grained local temporal patterns. This paper presents a novel deep learning architecture, the Fourier Convolutional Graph Transformer (FCGformer), specifically designed to overcome these limitations. FCGformer distinctively features a dual-module approach: a Global Module that constructs an integrated spatiotemporal graph and leverages Fourier transforms with frequency domain convolution to extract long-range dependencies and crucial periodicities; and a Local Module that employs inverse temporal embedding and self-attention to meticulously capture nuanced, short-term temporal variations. The key contribution of this work lies in the synergistic integration that enables FCGformer to effectively model complex pollutant behaviors, providing a more comprehensive understanding of both global contexts and local details. Extensive experiments demonstrate that FCGformer significantly outperforms state-of-the-art benchmark models in prediction accuracy, offering a promising advancement for improved air quality management.},
  archive      = {J_EAAI},
  author       = {Haiwei Yang and Ru Yang and Ling Ding and Shiqiang Du and Maozhen Li and Bo Zhang},
  doi          = {10.1016/j.engappai.2025.112538},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112538},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced air pollution spatiotemporal forecast model using frequency domain convolution and attention mechanism},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gate-guided spatial-channel reconstruction network: An efficient lightweight framework for steel surface defect detection. <em>EAAI</em>, <em>162</em>, 112537. (<a href='https://doi.org/10.1016/j.engappai.2025.112537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the limitations in You Only Look Once version 8 (YOLOv8) for steel surface defect detection, including insufficient generalization of image enhancement, constrained feature representation capability in core modules, and poor adaptability of the loss function to scale variations and sample imbalance, this paper proposes the Gate-guided Spatial-channel Reconstruction Network, an efficient and lightweight improved network. Contrast-Limited Adaptive Histogram Equalization (CLAHE) is introduced to enhance local image details and contrast while reducing noise impact. The Gating Block and the Spatial-channel Reconstruction Block are designed to replace the original C2f (cross-stage partial bottleneck with two convolutions) module in YOLOv8, thereby enhancing feature representation capability and efficiency. The loss function is optimized using Wise-IoU (WIoU) and Slide Loss (SlideLoss) to improve convergence and robustness. The proposed network was evaluated on the Northeastern University Surface Defect Detection (NEU-DET) dataset (200 × 200 pixels) and the Chinese Academy of Sciences Defect Detection (GC10-DET) dataset (2048 × 1000 pixels). It demonstrated high detection accuracy, achieving the mean Average Precision at 50 % (mAP50) of 84.7 % and 79.4 %, respectively. Furthermore, the network maintains low complexity with only 3.6 million parameters and achieves a high detection speed of up to 154 frames per second (FPS). The Gate-guided Spatial-channel Reconstruction Network effectively detects surface defects on hot-rolled steel, achieving state-of-the-art detection accuracy. It successfully meets the requirements for precise and real-time steel surface defect detection under resource-constrained industrial conditions.},
  archive      = {J_EAAI},
  author       = {Wei Zhang},
  doi          = {10.1016/j.engappai.2025.112537},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112537},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Gate-guided spatial-channel reconstruction network: An efficient lightweight framework for steel surface defect detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tensor product-fault diagnosis-transformer based wind turbine blade fault prediction method. <em>EAAI</em>, <em>162</em>, 112535. (<a href='https://doi.org/10.1016/j.engappai.2025.112535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous iterative updating of wind turbine (WT) blade fault diagnosis (FD) technology, intelligent prediction methods based on supervisory control and data acquisition (SCADA) systems have gradually become advanced mainstream technology in the industry. However, despite the many advantages of SCADA data in fault prediction, its high-dimensional characteristics and highly unstable nature still pose significant challenges for practical applications. Accordingly, this study proposes an innovative WT blade fault prediction method based on tensor product dimensionality reduction and FD-Transformer (TP-FD-Transformer) methodology, which aims to effectively solve the problem of timely and accurate prediction of WT blade faults. The TP-FD-Transformer method combines the quantum dimensionality reduction technique with the FD-Transformer model to form a new framework for data processing and analysis. The TP-FD-Transformer method adopts the tensor product-relative position matrix composite dimensionality reduction technique, which effectively reduces the dimensionality and complexity of SCADA data while preserving its features. After data processing is completed, the TP-FD-Transformer method utilizes the FD-Transformer model for deep learning training. The FD-Transformer model has been improved for complex time series data and can effectively capture potential features in the data. The experiments under the open dataset show that the TP-FD-Transformer method demonstrates excellent prediction ability in the field of WT blade FD, with an accuracy rate of 93.65 %. The research findings verify that TP-FD-Transformer method provides a feasible solution for the intelligent diagnosis of WT blade faults, with broad application prospects and significant practical significance.},
  archive      = {J_EAAI},
  author       = {Linfei Yin and Yuhan Liu and Nannan Wang},
  doi          = {10.1016/j.engappai.2025.112535},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112535},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Tensor product-fault diagnosis-transformer based wind turbine blade fault prediction method},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid physics-based and data-driven method for the rotor angle prediction. <em>EAAI</em>, <em>162</em>, 112533. (<a href='https://doi.org/10.1016/j.engappai.2025.112533'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods are widely employed for transient stability analysis in power systems. However, the prediction performance can be adversely affected by undesirable factors in the measured data. To alleviate the effect of the undesirable factors, a hybrid physics-based and data-driven prediction network of the rotor angle trajectory is proposed in this paper. The prediction model embeds the rotor equation to form a dynamic learning model that conforms to the actual physical law. The physical consistency of the prediction results is guaranteed. Meanwhile, a dynamic error derivative integral network incorporating the Runge–Kutta method is proposed to correct the final results. The accuracy of the prediction can be improved. Finally, it is tested in the IEEE 39-bus system and the East China Power Grid system. The test results show that the model significantly outperforms other comparative models. And the dependence on the quality of measured data can be alleviated effectively.},
  archive      = {J_EAAI},
  author       = {Lingzhe Zhang and Dong Huang and Huaiyuan Wang},
  doi          = {10.1016/j.engappai.2025.112533},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112533},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid physics-based and data-driven method for the rotor angle prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed machine learning for near real-time stress prediction on a structural component: Application for landing gears. <em>EAAI</em>, <em>162</em>, 112532. (<a href='https://doi.org/10.1016/j.engappai.2025.112532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lightweight design constitutes a pivotal research and development objective for next-generation landing gear systems. Nevertheless, achieving reduced weight while maintaining structural safety and reliability presents considerable challenges. The establishment of a digital twin (DT) for structural health monitoring (SHM) offers a promising approach to address these concerns across the design, testing, and operational lifecycle of landing gears. In this study, we develop a physics-informed neural network (PINN) model for near real-time stress prediction on the drag strut of a nose landing gear (NLG), specifically for an A320-type aircraft, serving as a foundational component of a DT system. The proposed PINN framework directly outputs displacement fields while deriving stresses as secondary quantities, effectively incorporating the fundamental equations of linear elasticity into the loss function. Displacement boundary conditions, informed by finite element method (FEM) simulations, are integrated as penalty terms to enhance trainability and physical consistency. The training dataset is constructed using load cases statistically representative of actual landing gear operations, with high-fidelity FEM providing corresponding displacement and stress references. The model demonstrates strong predictive accuracy, with relative errors between 5% and 7% compared to FEM results, and significantly outperforms both pure stress-output PINNs and conventional deep neural networks (DNNs). Moreover, the trained PINN achieves inference times within seconds under time-varying loads, highlighting its capability for near real-time stress monitoring. This work underscores the potential of physics-informed machine learning for enhancing DT-enabled SHM systems in safety-critical aerospace structures.},
  archive      = {J_EAAI},
  author       = {Zixuan Zhu and Yifan Zhao and Agusmian Partogi Ompusunggu},
  doi          = {10.1016/j.engappai.2025.112532},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112532},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed machine learning for near real-time stress prediction on a structural component: Application for landing gears},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-free safe deep reinforcement learning for grid-to-vehicle management considering grid constraints and transformer thermal stress. <em>EAAI</em>, <em>162</em>, 112529. (<a href='https://doi.org/10.1016/j.engappai.2025.112529'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing penetration of Electric Vehicles (EVs) presents challenges to the distribution grid, due to more volatile power profiles and higher peak demand. One key research question is how to accommodate EVs with limited-capacity grid equipment, such as transformers and lines. However, uncertainties from the EV side and the complexity of grid equipment models challenge the performance of the control strategies implemented. Moreover, the thermal loading of the transformer is often neglected. In this work, we propose a fully model-free, safe Deep Reinforcement Learning (DRL)- based grid-to-vehicle management strategy to avoid electric and thermal overloading of the transformer and power grid constraint violation. The management strategy is based on Projection-based Constraint Policy Optimization (PCPO) and takes only the observable information from the grid and vehicles. The target is to maximize energy delivery to the EV fleet while considering safe constraints, such as transformer thermal loading, voltage magnitude limits, and line loading limits. We compared the proposed strategy with conventional DRL and other safe DRL methods and investigated its robustness against higher ambient temperatures. The results show that the proposed strategy can deliver 92 % energy and reduce violations of the grid and transformers, while the other benchmarks deliver less than 80 %. The robustness test demonstrates that the proposed strategy is effective in various temperature. Moreover, the proposed strategy can effectively reduce at most 90 % of the transformer aging incurred by the thermal stress, compared with the uncontrolled charging.},
  archive      = {J_EAAI},
  author       = {Zhewei Zhang and Rémy Rigo-Mariani and Nouredine Hadjsaid and Yan Xu},
  doi          = {10.1016/j.engappai.2025.112529},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112529},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Model-free safe deep reinforcement learning for grid-to-vehicle management considering grid constraints and transformer thermal stress},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probability forecasting for multivariate urban water demand using temporal convolutional network based on quantile regression and parzen window. <em>EAAI</em>, <em>162</em>, 112528. (<a href='https://doi.org/10.1016/j.engappai.2025.112528'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probability prediction can provide more abundant information about uncertainties in future water demand, which is gaining increasing attention in building economical and reliable water resource management plans. However, most existing literature on water demand prediction focus on provide deterministic point prediction results. To overcome this problem, a novel hybrid probability forecasting model based on quantile regression temporal convolutional network and Parzen window is proposed for the probability density forecast of multivariate urban water demand. Firstly, to address the complex coupling relationship between water demand and multiple influencing factors, a random forest-based feature selection method is employed to eliminate the redundant variables. Then, a discrete wavelet transform is deployed to decompose the original series into a variety of characteristic subseries to reduce fluctuations of the original water demand series. Secondly, a quantile regression-based temporal convolutional neural network is employed to obtain the conditional quantiles of future water demand. Moreover, a probability density prediction method based on Parzen window estimation is developed to further obtain the distribution information of prediction uncertainty. Finally, a real-world multivariate dataset from a water plant in Suzhou, China, is used for comparison experiments with state-of-the-art models. The comparison results show that the proposed model has achieved an average improvement of 15.4 % and 53.3 % in interval prediction and probability density prediction, respectively. It shows that the proposed model is a reliable prediction model that can assist policymakers to optimize the management of urban water demand.},
  archive      = {J_EAAI},
  author       = {Jun Guo and Qingya Meng and Baigang Du and Hui Sun},
  doi          = {10.1016/j.engappai.2025.112528},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112528},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Probability forecasting for multivariate urban water demand using temporal convolutional network based on quantile regression and parzen window},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Critical nodes detection for complex networks via knowledge-guided evolutionary framework. <em>EAAI</em>, <em>162</em>, 112526. (<a href='https://doi.org/10.1016/j.engappai.2025.112526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Critical Node Problem (CNP) focuses on identifying critical nodes within complex networks. These nodes play a crucial role in maintaining connectivity, and their removal impacts network performance. Among CNP variants, CNP-1a — which minimizes pairwise connectivity after removing a limited number of nodes — has attracted significant research attention due to its NP-hard nature and applications in diverse fields like epidemic control and infrastructure resilience. While state-of-the-art methods leverage memetic algorithms and variable populations, they fundamentally rely on random initialization that often converges to local optima. This limitation arises because traditional methods fail to capture higher-order topological dependencies. To address this gap, we propose K2GA, a knowledge-guided genetic algorithm initialized by a graph attention network (GAT). The GAT embeds networks into low-dimensional spaces, assigning topology-aware attention weights to nodes that guide population initialization. K2GA then employs a hybrid genetic algorithm with a local search process to identify an optimal set of critical nodes. The local search process utilizes a cut node-based greedy strategy. Experiments on 26 real-world networks demonstrate that K2GA outperforms state-of-the-art methods in terms of the best, median, and average objective values, establishing new upper bounds for minimization in eight cases. This work pioneers a GAT-guided evolutionary search framework, offering a novel paradigm for solving CNP.},
  archive      = {J_EAAI},
  author       = {Chanjuan Liu and Shike Ge and Zhihan Chen and Wenbin Pei and Enqiang Zhu and Hisao Ishibuchi},
  doi          = {10.1016/j.engappai.2025.112526},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112526},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Critical nodes detection for complex networks via knowledge-guided evolutionary framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient framework for general long-horizon time series forecasting with mamba and diffusion probabilistic models. <em>EAAI</em>, <em>162</em>, 112525. (<a href='https://doi.org/10.1016/j.engappai.2025.112525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting plays an essential role in supporting critical decision-making processes in risk management and resource allocation in various fields, including finance, transportation, industrial systems, etc. Conventional models can effectively capture volatility and, are proficient in handling specific patterns, such as the AutoRegressive Integrated Moving Average model (ARIMA) and the Generalized AutoRegressive Conditional Heteroskedasticity model (GARCH). Nonetheless, these models meet many challenges, such as high dimensionality, non-stationarity, and nonlinearity inherent in real-world data. Although deep learning methodologies can provide better performance, they may still suffer from long-term errors and heightened computational expenses. A novel framework named Mamba Diffusion Probabilistic Models (MambaDiffTS) is proposed, which integrates Mamba’s state space model with a frequency-aware diffusion process grounded in Denoising Diffusion Probabilistic Models (DDPM). Mamba’s selective state transitions enable linear-time modeling of long-range dependencies; at the same time, frequency-aware spectral decomposition isolates trends and seasonality through Fourier regularization. Furthermore, the implementation of spectral energy-guided noise scheduling preserves temporal fidelity. Extensive experiments on diverse benchmarks-financial volatility, industrial IoT sensor data, and climate modeling-demonstrate MambaDiffTS’s superiority. Notably, on stock forecasting tasks, MambaDiffTS reduces Mean Squared Error (MSE) by approximately 18.6% compared to the best-performing baseline, and substantially outperforms diffusion models, all while maintaining linear computational complexity. The proposed MambaDiffTS facilitates scalable forecasting over extended horizons.},
  archive      = {J_EAAI},
  author       = {Wenjing Wang and Qilei Li and Ziwu Jiang and Deqian Fu and David Camacho},
  doi          = {10.1016/j.engappai.2025.112525},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112525},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient framework for general long-horizon time series forecasting with mamba and diffusion probabilistic models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selecting after sales provider of complex product based on game and matching framework. <em>EAAI</em>, <em>162</em>, 112524. (<a href='https://doi.org/10.1016/j.engappai.2025.112524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a strategic enabler of high-end manufacturing, the high-quality evolution of complex equipment is indispensable for any nation aspiring to industrial leadership. After sales service (AS) long relegated to a support function, which has emerged as a decisive determinant of product life-cycle value and, consequently, of this transformative journey. This study therefore investigates the technological innovation of AS for complex products through a Stackelberg game that captures the collaborative dynamics between an original equipment manufacturer (OEM) and an after-sales service provider (ASP). We derive the necessary and sufficient conditions under which an ASP finds participation economically viable, then embed these conditions into a multi-criteria matching framework that links ASP capabilities with spare-part requirements. Leveraging an entropy weighted DEMATEL (Decision-making Trial and Evaluation Laboratory) hybrid and we first quantify the causal salience of matching attributes and build a parsimonious evaluation index system. Next, by explicitly encoding bilateral attribute preferences, we formulate a two-sided matching model that identifies the Pareto-optimal ASP portfolio for any given product architecture. Finally, backward induction over the integrated game-matching structure yields a prescriptive tool that not only screens ASPs but also prescribes contractual levers to sustain long-term co-innovation. The proposed framework thus unifies strategic participation incentives with operational compatibility, offering OEMs a rigorous, implementable roadmap for selecting and governing after-sales partners in the era of servitized, high-stakes manufacturing.},
  archive      = {J_EAAI},
  author       = {Xin Huang and Xiaoyan Qi and Xiaojuan Xu},
  doi          = {10.1016/j.engappai.2025.112524},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112524},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Selecting after sales provider of complex product based on game and matching framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable interval prediction of dam displacement based on variational autoencoder and improved temporal fusion transformer considering solar radiation effects. <em>EAAI</em>, <em>162</em>, 112520. (<a href='https://doi.org/10.1016/j.engappai.2025.112520'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring the safety of dams is critical to maintaining national economic development and social stability, requiring the implementation of accurate displacement prediction methods for early detection of structural anomalies and effective risk mitigation. However, existing statistical models primarily focus on point predictions, failing to quantify the uncertainty in displacement variations, and often neglect the critical environmental factor of solar radiation. To address these limitations, this study proposes a novel interpretable interval prediction framework that integrates solar radiation factors into an advanced hydrostatic-temperature-time (AHTT) model. A variational autoencoder (VAE) is employed to extract robust latent features from a large volume of measured temperature data, effectively reducing temperature-related noise. Subsequently, an improved temporal fusion transformer method is introduced to probabilistic dam displacement prediction. This method uses an enhanced quantile loss function based on the Huber loss to generate both point and interval predictions that dynamically reflect the prediction uncertainty. In addition, an interpretable multi-head attention module is incorporated to quantify the contribution of each environmental factor. Hyperparameter tuning of the improved temporal fusion transformer is further optimized using Bayesian optimization based on the tree-structured Parzen estimator (TPE), which improves prediction accuracy. Engineering case studies validate that the proposed model not only achieves the highest point prediction accuracy, but also provides narrower prediction intervals with the best coverage width criterion. Ablation experiments and interpretability analyses further confirm the significant impact of solar radiation on dam displacement, providing valuable insights for the development of dam displacement prediction models and risk-informed decision making.},
  archive      = {J_EAAI},
  author       = {Taiqi Lu and Hao Gu and Chongshi Gu and Chenfei Shao and Yiming Wang and Dongyang Yuan},
  doi          = {10.1016/j.engappai.2025.112520},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112520},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interpretable interval prediction of dam displacement based on variational autoencoder and improved temporal fusion transformer considering solar radiation effects},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An undersampling method for software defect prediction based on hilbert curve mapping distance. <em>EAAI</em>, <em>162</em>, 112519. (<a href='https://doi.org/10.1016/j.engappai.2025.112519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The class imbalance problem presents a significant challenge in software defect prediction. The undersampling method enhances prediction performance by eliminating non-defective instances, thereby enabling the model to focus more on defective instances. However, the effective selection of representative non-defective instances while preserving the overall data distribution remains a critical challenge. Inspired by the space-filling property of Hilbert curves, we propose the H ilbert C urve M apping D istance U ndersampling (HCMDU) method for software defect prediction. This method first maps instances to Hamming space to ensure that similar instances are positioned closer together in the space. Instance circular domains are then partitioned based on the Hamming distance between them, which facilitates the exploration of instance variability within a localized region. Finally, the Hilbert curve mapping distance is employed to further uncover the data distribution pattern within the instance circular domains. The experimental results demonstrate that HCMDU delivers outstanding performance across 16 randomly selected software defect datasets in both Random Forest (RF) and Classification and Regression Trees (CART). Moreover, the results are further corroborated by the Friedman ranking and Nemenyi post-hoc test, which indicate that HCMDU significantly improves the performance of software defect prediction.},
  archive      = {J_EAAI},
  author       = {Yu Tang and Ye Du and Ang Li and Ming-song Yang and Yan Xia},
  doi          = {10.1016/j.engappai.2025.112519},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112519},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An undersampling method for software defect prediction based on hilbert curve mapping distance},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised fault diagnosis method for rolling bearings based on federated universal domain adaptation. <em>EAAI</em>, <em>162</em>, 112518. (<a href='https://doi.org/10.1016/j.engappai.2025.112518'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the issues of low diagnostic model accuracy caused by non-sharing of rolling bearing private data, distribution differences, and label space discrepancies across multiple clients, as well as the challenges that certain clients face in obtaining labeled data, an unsupervised fault diagnosis method is proposed for rolling bearings based on federated universal domain adaptation (FUDA). First, privacy protection during the transmission process in federated learning is ensured by implementing random mapping at local clients. Second, the central server employs the proposed mixed radial basis kernel-maximum mean discrepancy (MR-MMD) method to further mitigate distributional disparities between the feature spaces of source and target clients. This achieves unsupervised features alignment between these features. Third, margin vectors are introduced to tackle label space disparities between source and target clients, enabling effective separation of unknown class samples in the dataset of the target client. Finally, a dynamic weighted loss fusion strategy is designed to adaptively optimize the weight ratios of different losses. This enhancement facilitates the learning efficiency of the model. Experimental validation on two datasets demonstrates that the proposed approach can achieve average accuracies of 95.6 % and 87.7 % for the respective datasets. Compared with other methods, it represents improvements of 6.5 % and 8.1 %, while training time is reduced by at least 27 %. These results validate the effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Shouqiang Kang and Yulin Sun and Xinrui Li and Yujing Wang and Qingyan Wang and Xintao Liang},
  doi          = {10.1016/j.engappai.2025.112518},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112518},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised fault diagnosis method for rolling bearings based on federated universal domain adaptation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-scale feature extraction and fusion framework based on wavelet Kolmogorov–Arnold networks and parallel bi-directional gated recurrent units for electric load forecasting. <em>EAAI</em>, <em>162</em>, 112517. (<a href='https://doi.org/10.1016/j.engappai.2025.112517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term electric load forecasting remains challenged by the dual requirements of accuracy and robustness due to the combined effects of strong seasonality, multi-scale spikes, and stochastic disturbances. To address this, we propose a novel multi-scale forecasting framework, NP-WavKAN-Fusion, which integrates Neural Prophet for data decomposition and a Wavelet-based Kolmogorov–Arnold Network (WavKAN) with learnable wavelet kernels for multi-scale encoding. This fusion model utilizes a Bi-directional Gated Recurrent Unit (BiGRU) to capture long-term temporal dependencies and an adaptive feature fusion gate (AFF) to dynamically re-weight static and dynamic features for final load predictions. Extensive experiments on two public datasets from Australia and Morocco show that NP-WavKAN-Fusion consistently outperforms traditional models, reducing the mean absolute error by at least 30 %. For multi-step forecasting tasks, NP-WavKAN-Fusion maintains error inflation within 15 %, demonstrating superior performance compared to state-of-the-art long-sequence models such as Informer and PatchTST. The Diebold–Mariano test confirms that NP-WavKAN-Fusion yields statistically significant improvements, with 19 out of 20 comparisons showing lower errors. Ablation studies show that removing either the Neural Prophet component or the AFF significantly increases the forecasting error, validating the necessity of our layered denoising and fusion strategies. The proposed NP-WavKAN-Fusion framework demonstrates strong potential for real-world applications in electric load forecasting, offering robust performance under various temporal and non-stationary conditions.},
  archive      = {J_EAAI},
  author       = {Chunliang Mai and Lixin Zhang and Xuewei Chao and Xue Hu and Omar Behar},
  doi          = {10.1016/j.engappai.2025.112517},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112517},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-scale feature extraction and fusion framework based on wavelet Kolmogorov–Arnold networks and parallel bi-directional gated recurrent units for electric load forecasting},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resilient kernel-based unsupervised multi-view feature selection via compact binary hashing. <em>EAAI</em>, <em>162</em>, 112515. (<a href='https://doi.org/10.1016/j.engappai.2025.112515'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view feature selection across diverse views identifying a compact subset of the most informative feature across various data views without relying on labeled information. While most of the solutions are limited to linear multi-view data or utilize weakly-supervised single-label learning to assist in feature selection, leading to the loss of valuable semantic information, especially when dealing with complex real-world multi-view datasets. To overcome these limitations, we introduce a novel Resilient Kernel-based Unsupervised Multi-view Feature Selection via compact Binary Hashing (RKUMBH), which aims to search a robust and consistent graph representation across views, leveraging binary hashing codes to guide feature selection. Specifically, we first standardize the dimensionality of multi-view data by using non-linear kernel mapping. Then, we explore consistent graph structures across different views by fusing individual similarity graph of each view under a self-representation guidance. Moreover, the low-rank constraints are used to preserve the primary structures and patterns embedding within the data, and an unsupervised hashing feature selection framework is conducted to generate reliable hashing codes across views. Additionally, we design a customized iterative optimization method to solve the unified model. Extensive experiments on six public multi-view datasets demonstrate that our proposed method obtains state-of-the-art results compared to existing works for both clustering and feature selection tasks.},
  archive      = {J_EAAI},
  author       = {Rongyao Hu and Mengmeng Zhan and Jiangzhang Gan and Li Li and Fei Ye and Tong Liu},
  doi          = {10.1016/j.engappai.2025.112515},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112515},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Resilient kernel-based unsupervised multi-view feature selection via compact binary hashing},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncovering the geometry-dependent optical asymmetry of gold nanorods helical assemblies using artificial neural networks. <em>EAAI</em>, <em>162</em>, 112513. (<a href='https://doi.org/10.1016/j.engappai.2025.112513'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optical asymmetry of gold nanorods (Au-NRs) helical assemblies is well-documented with a wide range of applications. Nevertheless, the geometry-dependent optical asymmetry within these assemblies has not been adequately explored and quantified. The present study proposes a novel approach to predict the optical asymmetry of Au-NRs helical assemblies based on geometric characteristics using artificial neural networks (ANN). The performance of the ANN termed 3 N H L 50 N N was significantly enhanced through the optimization of the hidden layer and node, resulting in an R 2 of the outcomes exceeding 0.998 and a reduction in computational time exceeding 99.99 %. In instances where the specific geometric characteristics are needed to attain a desired optical asymmetry, a retrieval of geometric characteristics of Au-NRs helical assemblies was additionally investigated using a traversing mechanism featured particle swarm optimization (PSO) algorithm. The results of the retrieval were obtained within 6 s and demonstrate a high degree of accuracy and reliability. The combination of the 3 N H L 50 N N and the PSO algorithm is capable of accurately predicting the optical asymmetry of Au-NRs helical assemblies and the retrieval of the geometry characteristics, thereby enabling the quantitative understanding of their overall geometry-dependent optical asymmetry.},
  archive      = {J_EAAI},
  author       = {Yang Liu and Yongguang Chen and Xiyang Wei and Jianhua Shang and Lina Zhao},
  doi          = {10.1016/j.engappai.2025.112513},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112513},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Uncovering the geometry-dependent optical asymmetry of gold nanorods helical assemblies using artificial neural networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting worker loss of balance events from point cloud sequence using unsupervised motion-pose learning. <em>EAAI</em>, <em>162</em>, 112512. (<a href='https://doi.org/10.1016/j.engappai.2025.112512'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workers' loss of balance (LB), such as slip and trip, may lead to severe injuries and even fatalities. Existing methods for detecting LB typically rely on wearable sensors and focus on specific body parts. This study introduces a novel, non-contact approach utilizing light detection and ranging (LiDAR) technology to detect LB events. By capturing full-body point cloud data, the proposed method extracts both static pose and dynamic motion features across multiple body sections and detects LB events through unsupervised learning. The high-dimensional point cloud sequence is transformed into interpretable gait features, enabling effective unsupervised learning through sequence reconstruction. A two-stream network and fusion strategy are also developed to combine pose and motion features for final LB detection. Experiments with various LB events demonstrate the method's effectiveness, achieving an F1 score of 0.98 and a recall of 0.98. Our analysis reveals that integrating features from multiple body parts and the fusion of pose and motion information significantly enhances detection performance. This study offers a promising alternative to traditional methods, providing effective, non-intrusive monitoring of worker safety in dynamic construction environments.},
  archive      = {J_EAAI},
  author       = {Mingyu Zhang and Lei Wang and Yinong Hu and Shuai Han and Jiawen Zhang and Heng Li},
  doi          = {10.1016/j.engappai.2025.112512},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112512},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detecting worker loss of balance events from point cloud sequence using unsupervised motion-pose learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human motion prediction using mixture-of-branch graph convolutional network. <em>EAAI</em>, <em>162</em>, 112511. (<a href='https://doi.org/10.1016/j.engappai.2025.112511'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using the same spatio-temporal feature extraction network to predict multiple types of human motions pose a challenge for the prediction model to achieve optimal performance. To address this issue and achieve differentiated training, we propose a novel Mixture-of-Branch Graph Convolutional Network model which simultaneously inserts human motion sequences into a multi-branch human motion prediction module and a branch weight allocation module. When generating the final prediction sequence, weights are assigned to the prediction results of each branch. Mixture-of-Branch Graph Convolutional Network employs loss values to control competition rather than cooperation among branches, effectively addressing the issue of mutual influence between sequences during network training. To the best of our knowledge, this marks the inaugural utilization of a Mixture-of-Branch network in the realm of human motion prediction. To optimize the efficiency of the multi-branch model and reduce prediction complexity, we introduce a spatio-temporal feature extraction method for the human skeleton that accommodates Euclidean geometric transformations. This method liberates the Mixture-of-Branch Graph Convolutional Network from the constraints of additional branches, allowing it to handle similar motion sequences under varying degrees of translation or rotation, where feature matrices may exhibit significant differences. The proposal of Mixture-of-Branch Graph Convolutional Network and its related experiments represent our contribution to the Artificial Intelligence field, with significant potential value in engineering applications as well. Mixture-of-Branch Graph Convolutional Network is tested on the Human3.6M, Carnegie Mellon University Motion Capture, and Three-Dimensional Human Pose in the Wild datasets, achieving high performance. Particularly noteworthy is the 7% overall performance improvement in Mean Per Joints Position Error prediction on the Carnegie Mellon University Motion Capture dataset.},
  archive      = {J_EAAI},
  author       = {Xianshan Li and Ang Gao and Xingxing Ning and Fengda Zhao},
  doi          = {10.1016/j.engappai.2025.112511},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112511},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Human motion prediction using mixture-of-branch graph convolutional network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inverse design of particle shapes with target sphericity and packing fraction using variational autoencoders. <em>EAAI</em>, <em>162</em>, 112509. (<a href='https://doi.org/10.1016/j.engappai.2025.112509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sphericity and packing fraction are fundamental properties governing the behavior of granular materials in many engineering applications. Conventional methods for designing particles with these target properties usually suffer from limited accuracy, diversity, and interpretability due to complex relationships between particle shape and properties. To address this, we propose an inverse design framework based on deep learning. First, a rotation- and reflection-invariant variational autoencoder (VAE) parameterizes two-dimensional convex particle shapes into a low-dimensional latent space, enabling accurate reconstruction and capturing geometric interpretations such as sphericity and symmetry. Second, a conditional variational autoencoder (CVAE) facilitates inverse design by generating particle shapes corresponding to target sphericity or packing fraction, and also enables the coupling control of both properties. Trained on a dataset of over 1600 convex shapes, the framework demonstrates robustness and universality. The rotation- and reflection-invariant architecture consistently maps different orientations of the same shape to a unified representation, which enhances interpretability. The main contribution in artificial intelligence lies in developing invariant generative models that learn shape representations and enable property-driven shape generation. The engineering contribution is providing a precise and efficient tool for the inverse design of particle shapes with target properties, supporting the optimization of granular materials in engineering applications.},
  archive      = {J_EAAI},
  author       = {Yutong Qian and Shuixiang Li},
  doi          = {10.1016/j.engappai.2025.112509},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112509},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inverse design of particle shapes with target sphericity and packing fraction using variational autoencoders},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-way dynamic clustering algorithms based on generalized neighborhood relations in incomplete hybrid information systems with applications in medical decision-making. <em>EAAI</em>, <em>162</em>, 112508. (<a href='https://doi.org/10.1016/j.engappai.2025.112508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In addressing clinical challenges related to chronic diseases, the effective use of medical data in decision-making is often hindered by issues such as incompleteness, heterogeneity, and the need for continuous updates. To cope with these challenges, this study introduces a three-way dynamic clustering strategy built upon generalized neighborhood relations, aiming to enhance clustering robustness, strengthen the model’s ability to manage uncertainty, and support adaptability to dynamically evolving data. First, generalized neighborhood relations are constructed in incomplete hybrid information systems. An evaluation function is defined from two perspectives: the number of similar attributes between objects and the distance between objects, thereby optimizing similarity measurement and accurately characterizing the data structure. Second, three-way decision rules are introduced to effectively handle uncertainty in objects while maintaining classification accuracy, thereby improving the interpretability and adaptability of the clustering model. Furthermore, to accommodate the dynamic nature of medical data, a dynamic incremental clustering method based on neighborhood information is proposed to ensure that newly added patient data can be efficiently integrated into existing clusters, enhancing model real-time performance and computational efficiency. Experiments conducted on real clinical data from Chronic kidney disease (CKD) patients validate the proposed method. The results demonstrate that, compared to existing clustering algorithms, the proposed method outperforms in terms of F1-score and Rand Index evaluation metrics. It also exhibits higher applicability in patient classification, core and boundary domain partitioning, and dynamic data processing, providing effective support for precision stratified management of chronic disease patients and intelligent medical decision-making.},
  archive      = {J_EAAI},
  author       = {Haoran Sun and Bingzhen Sun and Xixuan Zhao and Qiang Bao and Xiaoli Chu},
  doi          = {10.1016/j.engappai.2025.112508},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112508},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Three-way dynamic clustering algorithms based on generalized neighborhood relations in incomplete hybrid information systems with applications in medical decision-making},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A three-stage segmentation framework for lung cancer lesion isolation in three-dimensional positron emission tomography images. <em>EAAI</em>, <em>162</em>, 112507. (<a href='https://doi.org/10.1016/j.engappai.2025.112507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background Positron emission tomography (PET) is a critical functional medical imaging modality for the early detection and diagnosis of cancers. PET imaging faces several challenges that hinder accurate interpretation including its inherently low spatial resolution, substantial variability in cancer lesions’ appearance, and difficulties distinguishing between the image background and benign lesions. Methods We propose a novel three-stage image segmentation framework to enhance the accuracy of lung cancer lesion identification and extraction from three-dimensional (3D) PET images. The first stage conducts a coarse segmentation using an encoder-decoder structure network to roughly position lesions. The second stage employs a multi-layer feature extraction network to learn the detailed characteristics of coarse segmentation results, mitigating false positives caused by localization inaccuracy. The last stage further refines the extracted features via dividing a sub-region of the lesion into foreground and background branches, reducing false positives caused by over-segmentation of edges. A novel lesion count loss function is introduced to guide the model to generate predictions during the training, ensuring that the predicted lesion counts align with the ground truth labels. Results The proposed method was evaluated on clinical 3D PET image datasets. Experimental results demonstrated a Dice Similarity Coefficient (DSC) of 85.35 %, Accuracy of 83.97 %, and Recall of 86.83 %. Compared to existing models applied to the same datasets, our method consistently achieved superior performance. Conclusion The proposed method significantly improves the segmentation performance of lung cancer lesions, implying that our method holds substantial potential for broader clinical application, even in low-resolution images.},
  archive      = {J_EAAI},
  author       = {Yusheng Wu and Qiang Lin and Jingjun Wei and Yongchun Cao and Zhengxing Man and Xiaodi Huang},
  doi          = {10.1016/j.engappai.2025.112507},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112507},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A three-stage segmentation framework for lung cancer lesion isolation in three-dimensional positron emission tomography images},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised visual assessment of railway track curvature via homography learning based on projective curvilinear geometry model. <em>EAAI</em>, <em>162</em>, 112506. (<a href='https://doi.org/10.1016/j.engappai.2025.112506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Railway track curvature monitoring is crucial for ensuring operational safety and passenger comfort. As a robust complement to the single-point physical sensor approaches, vision-based methods have recently gained increasing adoption. However, existing approaches frequently neglect the systematic exploitation of railway ego-vision geometry in two critical aspects: (1) the rail-camera kinematic coupling that relates the rail appearance in camera’s view and the track curvature during curvilinear motion, and (2) the potential of self-supervised learning to overcome annotation scarcity in this domain. This geometric oversight limits their accuracy in real-world dynamic scenarios. To address these gaps, this study proposes a novel vision-based framework that systematically exploits the railway ego vision geometry. Our methodology comprises two key innovations: First, a projective curvilinear geometry model that mathematically relates the ground-planes-induced homography to actual track curvature, thereby establishing a mapping from curvature and its variation to rail imaging curves. Second, a self-supervised curvature prediction network trained using automatically generated labels from our geometric model, eliminating the need for manual curve annotations. The self-supervision is achieved through a cyclic consistency mechanism between predicted curvatures and reprojected image features. Experimental validation using real-world railway footage demonstrates significant improvements: Our method reduces the average root mean squared error by 23.31% compared to state-of-the-art vision-based curvature estimation methods. These results underscore the effectiveness of geometry-aware computer vision for railway geometry monitoring},
  archive      = {J_EAAI},
  author       = {Peng Tang and Zhibin Yu},
  doi          = {10.1016/j.engappai.2025.112506},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112506},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-supervised visual assessment of railway track curvature via homography learning based on projective curvilinear geometry model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Saliency and correlation learning for co-salient object detection. <em>EAAI</em>, <em>162</em>, 112504. (<a href='https://doi.org/10.1016/j.engappai.2025.112504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Co-Salient object detection aims to identify common salient objects across a given group of images. However, accurately locating co-salient objects remains challenging due to the complexity of capturing the correlation representation of each group of images. To tackle this problem, we propose a saliency and correlation learning method for co-salient object detection. This method employs a saliency learning network and a correlation learning network to generate precise co-saliency maps of a group of images. Within the saliency learning network, a saliency feature grafting module is designed to refine object edges and achieve accurate detection of salient objects. Furthermore, the correlation learning network incorporates two modules, which are designed for extracting saliency correlation representation and deriving consensus correlation representation within a group of images, respectively. Guided by prior information obtained from saliency learning of images, our method significantly improves performance in co-salient object detection through correlation representation learning. Extensive experiments on all the latest benchmarks demonstrate that our method outperforms 11 state-of-the-art models, achieving a new level of technical excellence, with an average Structural Similarity Measure score of 0.845.},
  archive      = {J_EAAI},
  author       = {Ying Tong and Xiangfeng Luo and Liyan Ma and Shaorong Xie},
  doi          = {10.1016/j.engappai.2025.112504},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112504},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Saliency and correlation learning for co-salient object detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAVREN: A multilayered adaptive framework for deploying vision-language models on resource-constrained unmanned aerial vehicles for autonomous search and rescue. <em>EAAI</em>, <em>162</em>, 112498. (<a href='https://doi.org/10.1016/j.engappai.2025.112498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAVs) have become indispensable in autonomous search and rescue (SAR) missions, where the ability to interpret complex visual scenes in real time is critical. When equipped with artificial intelligence (AI)-empowered Vision-Language Models (VLMs), UAVs can provide rich contextual insights, interpret their findings, and even suggest next steps, but their deployment on resource-constrained UAV platforms is vastly limited by high computational demands, energy constraints, and strict latency requirements. This paper introduces MAVREN, a m ultilayered a daptive scheduler for V LM execution in re source-constrained UAV n etworks for autonomous SAR operations. Evaluations conducted on NVIDIA Jetson Orin NX using state-of-the-art VLMs such as Large Language and Vision Assistant (LLaVA) 1.6 and Vision-Language Alignment (VILA) 7B demonstrate that MAVREN achieves up to 26.11% higher throughput , 23% lower energy consumption , 13.51% reduced latency , and a 7% gain in detection accuracy compared to baseline schedulers across indoor, outdoor, and multi-UAV SAR scenarios. This is achieved through the integration of a visual encoder for lightweight feature extraction, a block floating-point quantizer for precision-efficient representation, a bit-wise computation engine for fast arithmetic execution, and a branch-and-bound optimizer for dynamic central processing unit (CPU) scheduling. These tightly coupled components allow MAVREN to optimize the energy–latency–accuracy trade-off, making it a deployable solution for vision-language reasoning in real-world SAR missions. Our findings demonstrate MAVREN’s capability to deliver rapid, energy-efficient inference, advancing the deployment of computationally intensive VLMs on resource-constrained UAV platforms.},
  archive      = {J_EAAI},
  author       = {Md Tahmid Rashid and Md Jawad Siddique and Abdus Shaqur},
  doi          = {10.1016/j.engappai.2025.112498},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112498},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MAVREN: A multilayered adaptive framework for deploying vision-language models on resource-constrained unmanned aerial vehicles for autonomous search and rescue},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rapid prediction of structural deflection based on explainable machine learning. <em>EAAI</em>, <em>162</em>, 112497. (<a href='https://doi.org/10.1016/j.engappai.2025.112497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-pressure arched air-rib membrane structures (HP-ARMS) exhibit lightweight portability and modular installation. This study proposes an explainable machine learning (ML) framework for the prediction of blast-induced HP-ARMS deflection. Firstly, compare the simulation results with the experimental data to verify the numerical method accuracy. Subsequently, a database containing 500 samples was established through numerical modeling. The input features include 6 structural parameters (air-rib pressure (X1), air-rib diameter (X2), air-rib thickness (X3), air-rib width (X4), air-rib height (X5), and air-rib bottom consolidation method (X6)) and 4 external load parameters (soil cover depth (X7), lateral explosion distance (X8), explosion equivalent (X9), and charge burial depth (X10)). Use Six ML algorithms—Light Gradient Boosting Machine (LightGBM), Random Forest (RF), Adaptive Boosting (AdaBoost), K-Nearest Neighbors (KNN), Convolutional Neural Network (CNN), and Gradient Boosting (GB)— and use four evaluation metrics to assess the accuracy of the ML model. Finally, the SHapley Additive exPlans (SHAP) method was used for interpretable analysis. The results showed that the LightGBM model had the best prediction performance. Compared with LightGBM, the Random-LightGBM (R-LightGBM) model significantly improved performance after hyperparameter optimization, with Root Mean Square Error (RMSE) reduced by 2.75 %, Mean Absolute Percentage Error (MAPE) reduced by 8.16 %, Mean Absolute Error (MAE) reduced by 5.88 %, and R-Squared (R 2 ) increased by 0.01. The SHAP method indicates that the explosion equivalent (X9) and charge burial depth (X10) are the most important parameters.},
  archive      = {J_EAAI},
  author       = {Yongtao Mi and Yushuai Zhang and Yicun Chen and Chenxi Sun and Huiqi Ren},
  doi          = {10.1016/j.engappai.2025.112497},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112497},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Rapid prediction of structural deflection based on explainable machine learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A latent-coupled neural network for multiphysics long-term forecasting in reactor transients using sparse observations. <em>EAAI</em>, <em>162</em>, 112496. (<a href='https://doi.org/10.1016/j.engappai.2025.112496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex dynamical systems in safety-critical applications like nuclear reactors involve strongly coupled physical fields evolving over space and time. Accurate prediction of these fields is vital for safety monitoring but is challenged by limited sensor placement and unobservable variables ( e.g. , xenon and iodine concentrations). This paper proposes the S parse observation to H igh-dimensional coupled physical field P rediction Network (SHPNet), a deep learning framework that predicts and reconstructs multiple physical fields directly from sparse observations.SHPNet combines a three-branch autoencoder to extract shared latent representations with a neural operator that models temporal dynamics in latent space, enabling efficient long-term forecasting. Evaluated on H ua-long P ressurized R eactor (HPR1000) under varying power and burnup conditions, SHPNet outperforms traditional frameworks and end-to-end model , achieving higher accuracy, robustness to observation sparsity, and effective reconstruction of unobservable fields. These results demonstrate SHPNet’s potential as a practical tool for real-time monitoring of complex coupled systems.},
  archive      = {J_EAAI},
  author       = {Yu-Yan Xu and Jun Luo and Deng Pan and Wei Lu and Ting Liu and Guanghui Yuan and Minxiao Zhong and Qing Li and Helin Gong},
  doi          = {10.1016/j.engappai.2025.112496},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112496},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A latent-coupled neural network for multiphysics long-term forecasting in reactor transients using sparse observations},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ESIGCF: Extremely simplified but intent-enhanced graph collaborative filtering for recommendation. <em>EAAI</em>, <em>162</em>, 112495. (<a href='https://doi.org/10.1016/j.engappai.2025.112495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) and graph contrastive learning (GCL) have substantially advanced recommender systems by modeling high-order user–item interactions and leveraging self-supervised signals. However, many existing methods overemphasize user–user or item–item similarities and rely on complex intent modeling, leading to increased complexity and limited exposure to diverse items. To address these challenges, we propose ESIGCF ( E xtremely S implified but I ntent-enhanced G raph C ollaborative F iltering) — a lightweight yet effective recommendation framework. ESIGCF explicitly defines user intent as the inner product between user and item embedding vectors and comprises two primary modules: (i) an intent-enhanced GCN that uses hybrid normalization (combining mean- and symmetric-normalization) to capture fine-grained user–item preferences without additional intent parameters, and (ii) an intent-aware GCL that aligns user–item pairs and positive and generated negative items. Negative samples are generated via a non-linear activation of item embedding interactions, promoting exposure to varied candidates without data augmentation. Experiments on three public datasets (Alibaba-iFashion, Yelp2018, Amazon-Book) show that ESIGCF consistently outperforms state-of-the-art baselines. For instance, on Alibaba-iFashion, ESIGCF achieves Recall@20 of 0.1273 versus 0.1059 for the best intent-enhanced baseline (a 20.2% relative improvement). Comprehensive experiments confirm that ESIGCF effectively captures latent user intent, mitigates popularity bias, and enhances recommendation performance with reduced complexity. Our code is available at https://github.com/Yangzhi22/ESIGCF .},
  archive      = {J_EAAI},
  author       = {Zhi Yang and Ruizhang Huang and Yanping Chen and Chuan Lin and Yongbin Qin},
  doi          = {10.1016/j.engappai.2025.112495},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112495},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ESIGCF: Extremely simplified but intent-enhanced graph collaborative filtering for recommendation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fusing spatial–temporal information into deep learning via wind propagation theory to enhance wind power prediction. <em>EAAI</em>, <em>162</em>, 112494. (<a href='https://doi.org/10.1016/j.engappai.2025.112494'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting wind power poses significant challenges because of the inherent randomness and intermittency of wind speed, thereby impeding effective wind power scheduling. This study proposes an improved deep learning model which leverages wind propagation theory to uncover spatial–temporal relationships among wind turbines to enhance the performance of wind power prediction. In addition, comprehensive theoretical and empirical analyses are conducted to justify the effectiveness of leveraging wind propagation theory for capturing spatio-temporal relationships among wind turbines. Moreover, spatio-temporal dependencies are modeled through a dual mechanism: multi-channel independent modeling for per-turbine temporal dynamics and wind propagation-based matrix computations for inter-turbine spatial relationships, which together significantly reduce computational complexity while preserving predictive performance. Data from 134 wind turbines and six comparison models were employed to validate the robustness and effectiveness of the proposed model. Empirical results indicate that the proposed model outperforms the baseline models, achieving an average improvement of 6.19% in Root Mean Square Error and 7.05% in Mean Absolute Error.},
  archive      = {J_EAAI},
  author       = {Maolin He and Jujie Wang},
  doi          = {10.1016/j.engappai.2025.112494},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112494},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fusing spatial–temporal information into deep learning via wind propagation theory to enhance wind power prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed dynamic bayesian networks for time-dependent reliability prediction of subsea wellhead sealing system with multi-states. <em>EAAI</em>, <em>162</em>, 112492. (<a href='https://doi.org/10.1016/j.engappai.2025.112492'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Subsea Wellhead Sealing System (SWSS) is crucial for the safety of deepwater operating, yet its reliability assessment faces challenges from harsh environments and multi-factor interactions. This study developed a data-driven, physics-informed reliability assessment method combining Finite Element Analysis (FEA) and Dynamic Bayesian Networks (DBN). An FEA model is established based on metal sealing theory, and a data-driven reliability model is subsequently constructed through sampling analysis, with a numerical-to-state conversion method bridging FEA and DBN. The FEA-DBN approach offers two key advantages: eliminating expert scoring subjectivity through physics-based modeling and effectively capturing multi-factor interactions and time-dependent behaviors. Results show this method can precisely quantify the evolution of SWSS reliability throughout its service lifecycle, with the probability of failure increasing from 0.64 % to 3.38 % over a 30-year service life. Case studies demonstrate its effectiveness for deep-sea equipment assessment, particularly in operating environments where real-time monitoring proves challenging, thereby demonstrating significant engineering application value.},
  archive      = {J_EAAI},
  author       = {Shengnan Wu and Han Gong and Long Yu and Aibo Zhang and Laibin Zhang and Yiliu Liu},
  doi          = {10.1016/j.engappai.2025.112492},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112492},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed dynamic bayesian networks for time-dependent reliability prediction of subsea wellhead sealing system with multi-states},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constructing a robust short-text clustering model for contrastive learning based on optimized adaptive optimal transport for pseudo-label generation. <em>EAAI</em>, <em>162</em>, 112491. (<a href='https://doi.org/10.1016/j.engappai.2025.112491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-text data often suffers from noise and class imbalances, posing challenges for effective clustering. To address these issues, we propose a Short-Text Clustering Model based on Pseudo-Labels and Contrastive Learning (SCPCL). The model comprises two key components: (1) a pseudo-label acquisition module, which introduces the optimal transport theory into short-text clustering and adopts a dynamically adjusted prior distribution to enhance the clustering of minority classes; and (2) a contrastive learning module combining a supervised clustering network, an instance contrastive head, and an anchor network. These components ensure intraclass compactness, interclass separability, and robustness to noise. Experiments on six benchmark datasets showed that SCPCL achieves an average clustering accuracy improvement of 2.61%, with a maximum gain of 6.47% for long-tailed distributions. This model provides an effective solution for clustering complex short text data.},
  archive      = {J_EAAI},
  author       = {Jiahui Liu and Chun Yan and Wei Liu and Yi Ding},
  doi          = {10.1016/j.engappai.2025.112491},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112491},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Constructing a robust short-text clustering model for contrastive learning based on optimized adaptive optimal transport for pseudo-label generation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid semantic-structural graph neural network for fault knowledge graph completion in railway operational equipment. <em>EAAI</em>, <em>162</em>, 112490. (<a href='https://doi.org/10.1016/j.engappai.2025.112490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete fault knowledge graphs in railway operational equipment hinder effective fault diagnosis, prediction, and maintenance planning. This study addresses the challenge of completing fault knowledge graph by proposing a hybrid semantic-structural graph neural network (Hybrid S-GNN) that integrates both semantic and structural information for knowledge graph completion (KGC) in railway fault scenarios. The Hybrid S-GNN comprises four key modules: a semantic encoding module that enhances textual fault data representations through contextual enhancement and dynamic weight allocation; a structural encoding module that captures graph topology using multi-view structure encoding combining local aggregation, global path encoding, and relation-aware adjustment; a semantic-structural fusion module leveraging attention mechanisms to balance semantic and structural signals; and an optimization-prediction module employing margin-based ranking loss and context-aware negative sampling for accurate triple prediction. Experiments on real-world railway fault knowledge graphs demonstrate that Hybrid S-GNN achieves a Hits@10 of 80.5 % and mean reciprocal rank (MRR) of 0.640, outperforming state-of-the-art baselines by 5.8 % and 6.1 %, respectively. Ablation studies confirm the critical contributions of each module, validating the necessity of jointly modeling semantic and structural features. This work provides an effective solution to enhance railway fault knowledge graphs and paves the way for advanced fault management applications in railway operations.},
  archive      = {J_EAAI},
  author       = {Xiaorui Yang and Honghui Li and Yi Xu and Yunhao Deng and Yanhui Bai and Shufang Liu},
  doi          = {10.1016/j.engappai.2025.112490},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112490},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid semantic-structural graph neural network for fault knowledge graph completion in railway operational equipment},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive detection method for driver fatigue using facial multisource dynamic behavior fusion. <em>EAAI</em>, <em>162</em>, 112482. (<a href='https://doi.org/10.1016/j.engappai.2025.112482'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving while fatigued is a leading cause of traffic accidents. This study proposed an adaptive detection model to recognize driver fatigue based on the dynamic facial behavior information of drivers. First, drivers’ facial fatigue features were extracted to establish a general feature space, including pupil movement, eye state, and fatigue expression parameters. A differentiated feature space was then built based on individual drivers, taking into account the homogeneity, regularity, and individual variances in drivers' facial behavior at various states. A complete adaptive fatigue feature space was built by integrating the general feature space and differentiated feature space. Finally, a driver adaptive fatigue discrimination model was constructed to classify the general and adaptive fatigue feature space to detect driver fatigue states adaptively. A driver fatigue detection dataset from real scenarios had been established to validate the performance of the proposed model. Experimental results demonstrated that the proposed method significantly improved the detection accuracy of driver fatigue. In terms of artificial intelligence, this study contributes a novel adaptive feature space construction method based on multimodal dynamic feature fusion for facial fatigue recognition; in engineering application, it develops an adaptive driver fatigue detection system grounded in multimodal dynamic behaviors, which provides real-time alerts upon detecting driver fatigue and ensures driving safety.},
  archive      = {J_EAAI},
  author       = {Guoxin Zhang and Fei Yang and Xin Fang and Lili Wang and Lei Zhao and Chaoning Yu},
  doi          = {10.1016/j.engappai.2025.112482},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112482},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive detection method for driver fatigue using facial multisource dynamic behavior fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thermoeconomic optimization of climate-adaptive solar and wind multi-generation systems using artificial intelligence and thermal energy recovery. <em>EAAI</em>, <em>162</em>, 112481. (<a href='https://doi.org/10.1016/j.engappai.2025.112481'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a hybrid multi-generation energy system designed to overcome solar intermittency while meeting the global demand for integrated delivery of electricity, water, cooling, and sustainable fuels in the transition to decarbonization. The engineering application integrates solar thermal and wind energy with a modified Brayton cycle, a Steam Rankine Cycle (SRC), and a Thermoelectric Generator (TEG) to simultaneously produce electricity, fresh water via Reverse Osmosis (RO), hydrogen and oxygen via Proton Exchange Membrane Electrolyzer (PEME), and cooling (via absorption chiller) within a unified optimization framework. The system was modeled using Engineering Equation Solver (EES) and optimized via Response Surface Methodology (RSM) based on 11 decision variables. To address the complexity of optimization, a second phase applied Artificial Intelligence (AI) techniques: Adaptive Boosting (AdaBoost) for predictive modelling and Particle Swarm Optimization (PSO) for global optimization. Under optimal conditions, the Response Surface Methodology yielded an exergy efficiency of 45.8 % with a cost rate of 576.76 United States Dollars per hour (USD/h), while AI reduced costs to 211.2 USD/h with a moderate efficiency trade-off. Simulation of the optimized configuration across eight diverse climates identified Quebec as most viable, generating 22,629.6 Megawatt-hours per year (MWh/year) of electricity and avoiding 4616.4 tons of Carbon Dioxide (CO 2 ) emissions annually. Integration of wind energy stabilizes solar variability, enhancing performance. AI contributes to optimizing complex interactions, nonlinear constraints, and multiple conflicting objectives. The methodology offers a scalable, generalizable framework for designing intelligent, climate-resilient infrastructures. Future research includes AI-enabled real-time control, experimental validation, and broader deployment strategies.},
  archive      = {J_EAAI},
  author       = {Ehsanolah Assareh and Nima Izadyar and Emad Tandis and Mehdi Khiadani and Amir shahavand and Neha Agarwal and Arian Gerami and Ahmed Rezk and Minkyu Kim and Reza Kord and Tahereh Pirhoushyaran and Mehdi Hosseinzadeh and Saleh Mobayen},
  doi          = {10.1016/j.engappai.2025.112481},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112481},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thermoeconomic optimization of climate-adaptive solar and wind multi-generation systems using artificial intelligence and thermal energy recovery},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-driven prior learning-based deep unrolling for underwater image enhancement. <em>EAAI</em>, <em>162</em>, 112472. (<a href='https://doi.org/10.1016/j.engappai.2025.112472'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a physics-driven prior learning-based algorithm unrolling approach for underwater image enhancement that leverages the advantages of both model- and learning-based approaches while overcoming their limitations. Model-based algorithms are theoretically robust because of prior knowledge of the underlying physics but may degrade image quality due to modeling inaccuracies. On the other hand, learning-based algorithms exhibit better adaptivity but inferior interpretability due to their black-box models and neglect of domain knowledge. In this work, we first formulate underwater image enhancement as a joint optimization problem with physics-based underwater-related priors and two learnable regularizers to compensate for modeling inaccuracies. Then, we solve the problem by reformulating it as a set of subproblems, which are then solved iteratively. Finally, we unroll the iterative algorithm into a deep neural network comprising a series of blocks, in which the optimization variables and regularizers are updated using closed-form solutions and learned deep neural networks, respectively. Experimental results on several datasets demonstrate that the proposed algorithm outperforms state-of-the-art underwater image enhancement algorithms on both quantitative and qualitative comparisons. The source code and pretrained models will be available at https://github.com/thithuypham/BLUE-Net .},
  archive      = {J_EAAI},
  author       = {Thuy Thi Pham and Hansung Yu and Truong Thanh Nhat Mai and Chul Lee},
  doi          = {10.1016/j.engappai.2025.112472},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112472},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-driven prior learning-based deep unrolling for underwater image enhancement},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explore unicin milvus optimization-based scale invariant signal interference noise loss enabled cycle generative adversarial network for audio source separation. <em>EAAI</em>, <em>162</em>, 112470. (<a href='https://doi.org/10.1016/j.engappai.2025.112470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audio Source Separation remains the major research area as noisy audio signals lack information connectivity among users. Despite the numerous important efforts for audio source separation, there are still some challenges limiting the overall performance. Specifically, the existing methods face difficulty in working with multiple input sources and ignore the spectrum information of the signals, resulting in subpar performance. Hence, the research proposes the Explore Unicin Milvus Optimization-based Scale Invariant Signal interference Noise loss enabled Cycle Generative Adversarial Network (ExUnMO-S2NC-GAN) for addressing the challenges in the existing methods. The proposed approach utilizes the Cycle Generative Adversarial Network (C-GAN) architecture to carry out the transformation and restoration while preserving the significant details, resulting in achieving the most relevant audio source as the outcome. Specifically, the proposed model exploits the Scale Invariant Signal interference noise (S2N) loss function, improving the robustness against invariant to the signal scale and deformations of the signal. Besides, the Explore Unicin Milvus Optimization (ExUnMO) algorithm, harnessing the unique traits of Red Kite and Harris Hawk, is used for fine-tuning the hyperparameters of C-GAN, leading to improved performance. Moreover, the feature extraction with the spectral parameters added more advantages to the research model to work on more specific inputs. Extensive experiments demonstrates that theproposed model obtained high-efficiency outcomes in comparison with the state-of-the-art methods, which is evaluated with the error metrics attaining the Mean Absolute Error (MAE) of 1.79, and Mean Absolute Percentage Error (MAPE) of 3.22, whereas the signal quality metrics such as Peak Signal-to-Noise Ratio (PSNR), Signal-to-Interference Ratio (SIR) and Signal-to-Artifacts Ratio (SAR) achieved the high values of 54.81 dB (dB), 39.33 dB, and 40.56 dB respectively.},
  archive      = {J_EAAI},
  author       = {Baishakhi Dutta and Chandrakant J Gaikwad},
  doi          = {10.1016/j.engappai.2025.112470},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112470},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explore unicin milvus optimization-based scale invariant signal interference noise loss enabled cycle generative adversarial network for audio source separation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vessel behavior recognition method for preventing vessel-bridge collisions via adaptive video analytics. <em>EAAI</em>, <em>162</em>, 112467. (<a href='https://doi.org/10.1016/j.engappai.2025.112467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a comprehensive end-to-end framework for recognizing vessel behaviors aimed at preventing vessel-bridge collisions in complex maritime environments. Current monitoring approaches that rely on Automatic Identification Systems or external tracking mechanisms often suffer from class imbalance, cross-domain variability, and limited capability to detect previously unseen high-risk behaviors. To address these challenges, the proposed framework directly analyzes video streams and introduces a standardized behavioral taxonomy, classifying vessel activities into eleven categories while incorporating temporal continuity and behavior transition modeling. A robust dataset construction pipeline is established, consisting of fixed-length frame sequences and mechanisms for cross-domain generalization. The framework integrates a spatio-temporal feature extraction module based on deformable convolution and multi-scale attention, coupled with a cross-instance mutual enhancement mechanism to capture domain-invariant representations. An open-set recognition strategy, grounded in class anchor clustering, enables accurate identification of previously unobserved high-risk behaviors. Furthermore, an adaptive frame sampling strategy dynamically adjusts sampling density around behavior transitions, enhancing recall and capturing infrequent events while minimizing computational cost. Extensive evaluations on both single-domain and multi-domain benchmark datasets, as well as real-world bridge video streams, demonstrate superior performance in terms of overall accuracy, F1-score, detection of rare behaviors, and recall compared with baseline methods. Ablation studies confirm the contribution of each component, and comparisons with open-set recognition methods underscore the practical utility of the proposed approach for anomaly detection. This framework provides a scalable, artificial intelligence-driven solution for vessel behavior recognition, anomaly detection, and cross-domain generalization, supporting intelligent monitoring and early warning in safety-critical maritime operations.},
  archive      = {J_EAAI},
  author       = {Woqin Luo and Daoxin Chen and Ye Xia and Dongming Feng},
  doi          = {10.1016/j.engappai.2025.112467},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112467},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Vessel behavior recognition method for preventing vessel-bridge collisions via adaptive video analytics},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A constitutive framework for non-isothermal plasticity through micro-mechanism informed artificial neural networks. <em>EAAI</em>, <em>162</em>, 112465. (<a href='https://doi.org/10.1016/j.engappai.2025.112465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-isothermal plastic deformation creates modeling challenges for constitutive model development. Current constitutive models challenge to capture the coupled microstructural changes that occur when temperature varies during processing. The Micro-Mechanism Informed Artificial Neural Network (MMIANN) framework was developed to address these limitations using artificial intelligence (AI) and machine learning (ML) techniques. The MMIANN framework combines physics-based evolution equations for key metallurgical processes—dislocation density, grain boundary migration, and precipitation kinetics—with neural network predictions. These micro-mechanisms operate as internal state variables that guide the network's material behavior predictions. The architecture uses parallel physics-based and neural pathways, blended through adaptive coefficients. Thermodynamic constraints maintain consistency through penalty-based enforcement of the Clausius-Duhem inequality. The model was trained and validated using experimental data from simultaneous cooling and tensile deformation of AA7075 aluminum alloy. The tests replicated industrial hot forming conditions with cooling rates from 25 to 75 °C per second (°C/s). This experimental approach captures the thermal-mechanical coupling that drives microstructural evolution in practice. MMIANN achieved correlation coefficients exceeding 0.96 for stress, temperature, and grain size predictions. The framework captures thermomechanical regimes. Processing maps generated by the AI model link process parameters to microstructural outcomes. The analysis reveals an optimal processing window (40–55 °C/s cooling, 0.15–0.25 strain ( ε )) and identifies three regimes where different strengthening mechanisms dominate. By integrating metallurgical science with machine learning, this framework provides a practical tool for non-isothermal manufacturing processes. The approach bridges microstructural understanding with process control for thermal-mechanical operations through the application of artificial intelligence.},
  archive      = {J_EAAI},
  author       = {Yo-Lun Yang and Tsai-Fu Chung and Chia-Hung Liao and Liang-Yu Chen and Hsing-Yu Wu and Uthayakumar Marimuthu and Arumugaprabu Veerasimman and Sundarakannan Rajendran and Vigneshwaran Shanmugam},
  doi          = {10.1016/j.engappai.2025.112465},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112465},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A constitutive framework for non-isothermal plasticity through micro-mechanism informed artificial neural networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learnable patchmatch and self-teaching for multi-frame depth estimation in monocular endoscopy. <em>EAAI</em>, <em>162</em>, 112463. (<a href='https://doi.org/10.1016/j.engappai.2025.112463'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work delves into unsupervised monocular depth estimation in endoscopy, which leverages adjacent frames to establish supervisory signals during the training phase. For many clinical applications, e.g. , surgical navigation, temporally correlated frames are also available at test time. However, most existing monocular methods struggle to make effective use of temporal information during both training and inference, primarily due to the inherent challenges of endoscopic imagery, including low- or homogeneous-texture regions and brightness fluctuations between frames. To fully exploit the temporal information in endoscopic scenes, we propose a novel unsupervised multi-frame monocular depth estimation model. The proposed model integrates a learnable patchmatch module to adaptively increase the discriminative ability in regions with low or homogeneous textures, and enforces cross-teaching and self-teaching consistencies to provide efficacious regularizations towards brightness fluctuations. Furthermore, as a byproduct of the self-teaching paradigm, the proposed model is able to improve the depth predictions when more frames are input at test time. We conduct detailed experiments on multiple datasets, and the experimental results indicate that the proposed method exceeds prior state-of-the-art competitors. The source code and trained models will be publicly available at https://github.com/ShuweiShao/FrameDepth .},
  archive      = {J_EAAI},
  author       = {Shuwei Shao and Zhongcai Pei and Weihai Chen and Xingming Wu and Zhong Liu},
  doi          = {10.1016/j.engappai.2025.112463},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112463},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learnable patchmatch and self-teaching for multi-frame depth estimation in monocular endoscopy},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypergraph induced semi-supervised orthogonal nonnegative matrix factorization with label and constraint propagation. <em>EAAI</em>, <em>162</em>, 112462. (<a href='https://doi.org/10.1016/j.engappai.2025.112462'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a popular technology of artificial intelligence, nonnegative matrix factorization (NMF) aims at clustering and finding the differentially expressed features of each cluster. However, for complex high-dimensional sample data, it is still a challenge to design more appropriate NMF optimization models and develop more efficient algorithms to solve this model in view of enhanced theoretical properties and numerical performance. In this paper, a novel NMF optimization model with regularization is proposed such that the NMF is performed by a semi-supervised approach, as well as incorporating the strategies of hypergraph induced label propagation and constraint propagation. Specifically, different from existing NMF methods, the hypergraph structure underlying the data, together with the simple graph information, is employed to guide the pairwise constraint propagation in our built model. In recognition of sample similarity, a dataset-adaptive strategy is proposed to update the weight matrix of the graphs. By adding dual orthogonality on the factor matrices in the objective function, interpretability and feature independence of the built model are enhanced. Then, an algorithm is developed to efficiently solve this complicated model. Theoretically, it is proved that the developed algorithms are well defined and convergent. Numerically, extensive tests on the proposed model and algorithm are performed, which validate that they outperform the state-of-the-art ones in terms of different metrics of evaluating clustering performance when they are applied into solution of the problems from eight public datasets.},
  archive      = {J_EAAI},
  author       = {Jie Guo and Ting Li and Jialu Liu and Zhong Wan},
  doi          = {10.1016/j.engappai.2025.112462},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112462},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hypergraph induced semi-supervised orthogonal nonnegative matrix factorization with label and constraint propagation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel condition monitoring approach using hybrid lightweighted adaptive models for complex machinery. <em>EAAI</em>, <em>162</em>, 112461. (<a href='https://doi.org/10.1016/j.engappai.2025.112461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Condition monitoring of complex industrial systems is critical for ensuring operational reliability. Data-driven methods using artificial intelligence have advanced anomaly detection (AD) and fault diagnosis (FD), but existing approaches often treat them separately, focus on known faults, and struggle with previously unseen or rare conditions in multi-modal scenarios. This study proposes a novel condition monitoring framework that integrates AD and FD within a distributed architecture. Lightweight models—including kernel principal component analysis, support vector machines, and one-dimensional convolutional neural networks—enable efficient and scalable processing. A multilevel information fusion strategy ensures consistent detection and diagnosis while facilitating the isolation of previously unknown faults. Module test results demonstrate the effectiveness and robustness of the proposed feature extraction and adaptive modeling approaches. The overall test results for previously unknown faults vary across channels and modules. For samples with misalignment and inner blade wear, channel-level detection accuracy ranges from 0.007 to 0.989, with unknown recognition rates up to 0.933 and diagnosis probabilities from 0.508 to 0.933. For strong misalignment and fan-end inner race faults, nearly all channels achieve 100 % detection accuracy, with some diagnosis probabilities above 0.9, while unknown recognition remains minimal (mostly below 0.05). Importantly, the proposed framework integrates detection and diagnostic outputs across channels, effectively mapping previously unseen faults to similar known categories or to an unknown category. Overall, the proposed framework offers a referenced solution for condition monitoring of industrial systems like pumps, turbines, and compressors, and lays the foundation for future improvements incorporating domain knowledge and model-driven interpretability.},
  archive      = {J_EAAI},
  author       = {Yingqian Liu and Rongyong Zhang and Luigi Grossi and Zhipin Ye and Huairui Li and Rongsheng Zhu and Qiang Fu},
  doi          = {10.1016/j.engappai.2025.112461},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112461},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel condition monitoring approach using hybrid lightweighted adaptive models for complex machinery},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast and stable framework for generative adversarial imitation learning. <em>EAAI</em>, <em>162</em>, 112460. (<a href='https://doi.org/10.1016/j.engappai.2025.112460'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying reinforcement learning to complex and high-dimensional tasks encounters challenges, including the formulation of suitable reward functions, achieving sample efficiency, and developing effective exploration strategies. Adversarial imitation learning techniques address these issues by employing generative adversarial networks (GANs) to capture temporal dependencies and mitigate compounding errors. These methods exhibit enhanced efficiency relative to behavioral cloning and require fewer expert samples. Nonetheless, their complex min-max problem results in sample inefficiency and struggles with challenges such as mode collapse and training instability. This paper provides a comprehensive approach that adeptly addresses these challenges. The proposed method's design comprises three main steps. First, it uses the off-policy Twin Delayed Deep Deterministic (TD3) algorithm to enhance sample efficiency and accelerate learning. In the second step, a novel reward function based on energy-based GANs and deep regret analytic GANs is developed, which alleviates mode collapse and enhances training stability. Finally, we suggest several improvements, including the use of a pre-trained discriminator and mixed batches, to achieve a faster and more stable algorithm. The evaluation findings on continuous control tasks demonstrate that our method not only matches state-of-the-art performance but also surpasses it in both sample efficiency and stability. It achieves convergence with far fewer iterations than the compared methods.},
  archive      = {J_EAAI},
  author       = {Fateme Shahabi-Nejad and Mohammad Mehdi Ebadzadeh},
  doi          = {10.1016/j.engappai.2025.112460},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112460},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A fast and stable framework for generative adversarial imitation learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A transfer learning method of collaborating random walk and adaptive instance normalization for inscription image denoising. <em>EAAI</em>, <em>162</em>, 112458. (<a href='https://doi.org/10.1016/j.engappai.2025.112458'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mess noise hinders reading and understanding of inscriptions in images. For image restoration from noise-corrupted images, existing network-learning-based methods can construct an excellent model to generate noise patterns. However, the performance of such models is degraded owing to the lack of high-quality training data and the complex noise pattern in inscription images, e.g., mixed noise with multiple levels. Herein, we first propose a novel noise generation model that can produce more realistic synthetic noise images using the random walk algorithm. Then, we propose an explainable inscription image denoising network using a variational inference model, where the joint distribution of clean-noise image pairs is approximated in a dual adversarial manner. The proposed network exhibits improved generalizability and adaptability to different noise characteristics using an estimated noise map and adaptive instance normalization. Finally, we introduce a transfer learning scheme to migrate the network learned from the synthetic noise image domain to a real-inscription image domain with a limited number of real-inscription images. The proposed method outperforms state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Erhu Zhang and Yunjing Liu and Guangfeng Lin and Jinghong Duan},
  doi          = {10.1016/j.engappai.2025.112458},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112458},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A transfer learning method of collaborating random walk and adaptive instance normalization for inscription image denoising},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite element-integrated neural network framework for spatial modal prediction in machine tool structures. <em>EAAI</em>, <em>162</em>, 112456. (<a href='https://doi.org/10.1016/j.engappai.2025.112456'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of position-dependent structural dynamics in (CNC) machine tools is critical for ensuring machining precision, avoiding resonance, and enabling real-time health monitoring. This study proposes an integrated framework combining finite element analysis (FEA), experimental modal testing, and artificial neural networks (ANNs) to model and predict position-dependent dynamics across the machine workspace. A validated FEA model of a high-rigidity vertical machining centre is developed and correlated with experimental modal analysis using a PCB 086D20 impact hammer and tri-axial accelerometer. Natural frequencies and mode shapes are extracted and compared, showing deviation under 10 %, confirming model fidelity. To capture position-dependent dynamics, modal analysis was performed at 27 spatial locations, revealing significant frequency variation across planes, indicating localized compliance zones. A multilayer ANN is trained on the modal dataset to predict frequencies based on spatial coordinates, achieving R 2 values above 0.99. The proposed hybrid approach enables real-time estimation of structural dynamics, reducing the need for repeated testing and supporting intelligent control strategies in large-format CNC systems. This work contributes a predictive foundation for dynamic stability optimization, resonance avoidance, and digital twin development in precision machining applications.},
  archive      = {J_EAAI},
  author       = {Aman Ullah and Tzu-Chi Chan and Jun-Fa Huang and Shinn-Liang Chang},
  doi          = {10.1016/j.engappai.2025.112456},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112456},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Finite element-integrated neural network framework for spatial modal prediction in machine tool structures},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-to-end go (Weiqi) game record reconstruction from live broadcast videos. <em>EAAI</em>, <em>162</em>, 112455. (<a href='https://doi.org/10.1016/j.engappai.2025.112455'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual transcription of Go (Weiqi) game records from broadcast videos creates a major bottleneck for building training data in artificial intelligence (AI). We present an end-to-end system that reconstructs complete smart game format (SGF) records from professional tournament broadcasts. The pipeline integrates four modules: (i) video-to-frame sampling; (ii) a board detector based on a detection transformer (DETR), optimized with a size-aware loss to reliably localize both main and commentary boards; (iii) a stone classifier that uses knowledge distillation from a vision transformer (ViT) teacher to an efficient grid-based student for full-board inference; and (iv) a temporal reconstruction algorithm for occlusion recovery and move-sequence consistency. When evaluated under a zero-error-tolerance video-level protocol – where a video is counted correctly only if all sampled frames match the reference – the system achieves 82.56% accuracy on 86 real tournament videos (356 h). Component analyses reveal high board localization quality with mean average precision (mAP50-95) reaching 0.99; near-teacher board-state recognition with a 67 × speedup (377.5 frames per second, FPS) and F1 score 0.988; and a 70.23% reduction of occlusion-related misdetections. Compared with you only look once (YOLO) and faster region-based convolutional neural network (Faster R-CNN) baselines, our design improves small-board recall and end-to-end robustness in dual-board and occluded settings. The system outputs SGF records suitable for large-scale dataset construction, AI-assisted analysis, education, and digital preservation, and the approach can be generalized to other grid-structured board games with minor adaptations.},
  archive      = {J_EAAI},
  author       = {Chih-Lin Lin and Hsia-Hung Ou and Lung Hung Chen and Chih-En Kuo},
  doi          = {10.1016/j.engappai.2025.112455},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112455},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {End-to-end go (Weiqi) game record reconstruction from live broadcast videos},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting code paraphrased by large language models using coding style features. <em>EAAI</em>, <em>162</em>, 112454. (<a href='https://doi.org/10.1016/j.engappai.2025.112454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent progress in large language models (LLMs) for code generation has raised serious concerns about intellectual property protection. Malicious users can exploit LLMs to produce paraphrased versions of proprietary code that closely resemble the original. While the potential for LLM-assisted code paraphrasing continues to grow, research on detecting it remains limited, underscoring an urgent need for a detection system. We respond to this need by proposing two tasks. The first task is to detect whether code generated by an LLM is a paraphrased version of original human-written code. The second task is to identify which LLM is used to paraphrase the original code. For these tasks, we construct a dataset consisting of pairs of human-written code and LLM-paraphrased code using various LLMs. We statistically confirm significant differences in the coding styles of human-written and LLM-paraphrased code, particularly in terms of naming consistency, code structure, and readability. Based on these findings, we develop a detection method that identifies paraphrase relationships between human-written and LLM-generated code, and discover which LLM is used for the paraphrasing. Our detection method outperforms the best baselines in two tasks, improving F1 scores by 2.64% and 15.17% while achieving speedups of 1,343x and 213x, respectively.},
  archive      = {J_EAAI},
  author       = {Shinwoo Park and Hyundong Jin and Jeong-won Cha and Yo-Sub Han},
  doi          = {10.1016/j.engappai.2025.112454},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112454},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detecting code paraphrased by large language models using coding style features},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cooperative neural networks for inverse design: Integrating denoising autoencoder and surrogate model for partial design variable imputation. <em>EAAI</em>, <em>162</em>, 112453. (<a href='https://doi.org/10.1016/j.engappai.2025.112453'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven inverse design is an engineering approach where target performance criteria are specified upfront, leading to the derivation of design solutions that meet these criteria. While recent research focuses on generating complete design solutions using generative models, these approaches struggle with partial design variables and constraints that predetermine certain variables. Additionally, generative models are data-intensive and prone to overfitting with limited datasets. To address these limitations, this paper proposes a Cooperative Neural Network architecture comprising two key components: the Imputation Model and the Surrogate Model. These components collaborate to optimize design solutions while adhering to predefined performance criteria. The framework’s effectiveness is demonstrated through a case study on Glass Run Channel (GRC) designs from a Korean automotive manufacturer. Results show the architecture proficiently imputes undetermined variables and ensures the designs meet desired performance metrics, achieving Mean Squared Error (MSE) reductions of up to 98 % and R-squared values of 0.997–0.999 in initial tests. It remains robust in diverse scenarios, achieving up to 95.65 % MSE reduction and R-squared values of 0.995–0.999 for cases with the most undetermined variables, and up to 94.68 % MSE reduction with R-squared values of 0.983–0.995 for the smallest training datasets. This framework reduces design cycle times and enhances engineering design efficiency, offering a robust solution to limitations in traditional methods reliant on physical prototyping and iterative testing.},
  archive      = {J_EAAI},
  author       = {Agung Nugraha and Hyerin Kwon and Gyeongho Park and Jihwan Lee},
  doi          = {10.1016/j.engappai.2025.112453},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112453},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cooperative neural networks for inverse design: Integrating denoising autoencoder and surrogate model for partial design variable imputation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Region-based weighting-and-enhancement network with adaptive class weighting loss for postoperative inguinal hernia prediction. <em>EAAI</em>, <em>162</em>, 112451. (<a href='https://doi.org/10.1016/j.engappai.2025.112451'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Postoperative inguinal hernia (PIH) is a common complication after radical prostatectomy, subsequently leading to multiple potential risks (e.g., cardiovascular and cerebrovascular accidents) and increased surgical costs due to re-surgical reparation. Magnetic resonance imaging (MRI) examination is a widely used procedure before radical prostatectomy, which can investigate the muscle structures of the abdominal wall (MSAW). Recently, clinical studies have indicated that clinical parameters (e.g., thickness and width of the external oblique muscle) of MSAW are strongly related to PIH. However, automated MRI-based PIH prediction based on deep neural networks has not been studied previously. Motivated by these observations, we propose a novel region-based weighting-and-enhancement network to predict PIH before radical prostatectomy based on MRI images automatically. Specifically, we employ the well-designed Region Weighting-and-Enhancement module to capture informative context representations through region weighting and regional context enhancement, by fully leveraging the potential of clinical MSAW priori. Additionally, this paper designs an effective adaptive class weighting loss to emphasize or suppress the samples with varying levels of significance to further boost the PIH prediction performance. The extensive experiments on a clinical MRI-PIH dataset and one publicly available MRI dataset manifest the superiority of our proposed methods over state-of-the-art deep neural networks and advanced loss methods.},
  archive      = {J_EAAI},
  author       = {Jiawei Zhang and Lisheng Wu and Qiang Fang and Weidong Yu and Zhengyu Hu and Fengyun Zhang and Cheng Yang and Xiaoqing Zhang},
  doi          = {10.1016/j.engappai.2025.112451},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112451},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Region-based weighting-and-enhancement network with adaptive class weighting loss for postoperative inguinal hernia prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting thermal transport of blood-based penta-hybrid nanofluid in fin geometries using deep neural networks and finite difference approach. <em>EAAI</em>, <em>162</em>, 112450. (<a href='https://doi.org/10.1016/j.engappai.2025.112450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nanofluids have garnered significant research interest due to their enhanced heat transfer and thermal characteristics. A novel hybrid nanofluid has exhibited exceptional thermal properties, combining five nanoparticles of uniform shapes with a base fluid, such as blood. This study investigates the influence of fin thickness, varying with length, considering the implications of internal heat production, convection, and thermal radiation processes in rectangular, convex, and triangular fin descriptions. Wet scenarios are interpreted to evaluate differences in thermal energy dynamics for fin shapes like Rectangular, Convex and Triangular. Darcy's model is employed to account for the material's porous nature. A finite difference scheme, implemented using Partial Differential Equation solver (PDSolve) in Maple (2024), provides graphical insights into fin effectiveness and thermal steady-state responses across various parameters. Incorporating Penta hybrid nanofluids enhances fin performance, with rectangular fins' Nusselt numbers (up to 1.936) proving more efficient, delivering faster thermal responses than triangular fins and convex fins. Further, using the Adam Optimisation algorithm, Convolutional Neural Networks were used to validate the current model. It was observed that these networks could accurately forecast the truth values, and the two findings matched, as indicated in Table 3 As a potential biological application, this research offers insight into optimising cooling systems for biomedical devices, such as heat exchangers in artificial organs.},
  archive      = {J_EAAI},
  author       = {Maddina Dinesh Kumar and Nehad Ali Shah and Dharmaiah Gurram and Se-Jin Yook},
  doi          = {10.1016/j.engappai.2025.112450},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112450},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Predicting thermal transport of blood-based penta-hybrid nanofluid in fin geometries using deep neural networks and finite difference approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on the application of attention mechanism based multi-model fusion in food recommendation platforms. <em>EAAI</em>, <em>162</em>, 112449. (<a href='https://doi.org/10.1016/j.engappai.2025.112449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smartphone-based food ordering has greatly enhanced convenience in daily life, and the rise of recommendation systems has transformed the functionality and user experience of food delivery applications. Innovations in recommendation algorithms and models have significantly improved the efficiency of food, merchant, and advertisement recommendations on food platforms, leading to higher transaction rates and greater user satisfaction. To further enhance recommendation efficiency, this study introduces a novel multi-model fusion recommendation architecture based on the multi-head self-attention mechanism, utilizing a two-tier structure. The first-tier model (the attention-based homogeneous AutoInt model) acts as a teacher to guide the training of the second-tier Transformer model. This hierarchical approach integrates multiple models through knowledge distillation, significantly improving the accuracy of the recommendation system. The complexity and performance of the proposed architecture were analyzed and applied in a production environment. Testing on a private dataset reveals that the proposed multi-model fusion recommendation architecture significantly enhances recommendation performance across various food platform scenarios, achieving an accuracy of 0.7643, recall of 0.8262, and an F1 score of 0.7936. These results surpass the performance of current state-of-the-art models. Therefore, the proposed architecture is not only highly applicable to food recommendation systems but also has broad applicability in other fields such as retail and entertainment.},
  archive      = {J_EAAI},
  author       = {Linchao Zhang and Lei Hang},
  doi          = {10.1016/j.engappai.2025.112449},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112449},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Research on the application of attention mechanism based multi-model fusion in food recommendation platforms},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced multi-modal emotion recognition using the feature level fusion. <em>EAAI</em>, <em>162</em>, 112447. (<a href='https://doi.org/10.1016/j.engappai.2025.112447'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal human emotion recognition is a complex process of synthesizing information from various modalities to calculate emotion states. This field faces several challenges: (1) Acoustic is an essential component of emotion expression, but it often underperforms compared to visual and text in emotion recognition. (2) Capturing the feature interaction among different modalities is usually complex. (3) Processing high-definition videos can significantly reduce the efficiency of visual analysis. In this study, we presented a learning architecture designed to recognize human emotions effectively. For the first challenge, we implemented a multi-level acoustic encoder (MLAE) that enhances the extraction of acoustic information to improve the acoustic contribution in multi-modal emotion recognition. Facing the second challenge, we introduced the cross-attention block module, which adeptly captures the inter-modal interactions. To address the third challenge, we adopted the re-parameterized visual geometry group network (RepVGG) as the visual feature encoder, employing its multi-branch learning and single-branch reasoning structure to maintain high reasoning efficiency. Our model has demonstrated the state-of-the-art performance of the interactive emotional dyadic motion capture (IEMOCAP) dataset and the multi-modal opinion sentiment and emotion intensity of the Carnegie Mellon University (CMU-MOSEI) dataset.},
  archive      = {J_EAAI},
  author       = {Aziguli Wulamu and Yuheng Wu and Xin Liu and Yao Zhang and Jinghan Xu and Yang Zhang},
  doi          = {10.1016/j.engappai.2025.112447},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112447},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced multi-modal emotion recognition using the feature level fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep adaptive wavelet autoencoder with mutually independent empirical cumulative distribution for unsupervised motor anomaly detection. <em>EAAI</em>, <em>162</em>, 112446. (<a href='https://doi.org/10.1016/j.engappai.2025.112446'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {—Permanent magnet synchronous motors (PMSMs) are widely used in industrial applications but remain vulnerable to stator faults, such as inter-coil and inter-turn short circuits. Although recent deep learning-based fault detection methods have shown promise, they typically rely on large volumes of labelled fault data for training. To address this limitation, this paper proposes a novel unsupervised fault detection framework, termed Deep Adaptive Wavelet Autoencoder (DAWA) with Mutually Independent Empirical Cumulative Distribution (MIECD), specifically designed for PMSM fault detection. DAWA utilizes convolutional neural networks to learn adaptive wavelet filters through fast discrete wavelet transform, allowing for fully learnable, threshold-free extraction of fine-grained signal patterns. The resulting latent features are then mapped by MIECD into a mutually independent space via independent component analysis (ICA). Without assuming any prior data distribution, MIECD estimates empirical cumulative distributions (ECDs), computes tail probabilities across dimensions, and aggregates them into a unified anomaly score. Experimental results on motor vibration datasets demonstrate the effectiveness of the proposed method, showing average accuracy improvements of 15.85 % for Interturn and 15.16 % for Intercoil fault detection compared to conventional data-driven baselines across various operating conditions.},
  archive      = {J_EAAI},
  author       = {Pinze Ren and Ning Zhu and Dandan Peng and Liyuan Ren and Huan Wang},
  doi          = {10.1016/j.engappai.2025.112446},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112446},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep adaptive wavelet autoencoder with mutually independent empirical cumulative distribution for unsupervised motor anomaly detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic vision-based machine vibration sensing and fault diagnosis with signal alignment and feature clustering. <em>EAAI</em>, <em>162</em>, 112445. (<a href='https://doi.org/10.1016/j.engappai.2025.112445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, intelligent fault diagnosis methods for machines have been widely developed. The contact accelerometer has been popularly used with high measurement accuracy. However, in many industrial applications, non-contact sensors are often preferred due to practical constraints. The event camera is a novel bio-visual sensing technology for asynchronously capturing pixel-wise changes in brightness. It has various advantages including high measurement rate, exceptional resolution, wide dynamic range, etc., which thus has promising prospects in non-contact monitoring and fault diagnostic tasks. Despite these advantages, the high complexity of the dynamic vision data from the event cameras poses significant processing challenges, and the extraction of machine vibration information is of great difficulties. To address these challenges, this paper proposes a novel dynamic vision-based machine vibration sensing and fault diagnosis method. First, the dynamic vision data is reconstructed into event frame sequences. Next, a deep neural network is proposed to extract the micro-vibration information with feature clustering for enhancing model robustness. A signal alignment method is further proposed where the contact sensing data are used as a reference for optimizing model performance. Finally, the intelligent fault diagnosis is implemented with the estimated vibration data. Experimental validations are conducted with real rotating machine data, which demonstrate the promising applicability of the proposed method in non-contact machine vibration sensing and fault diagnosis.},
  archive      = {J_EAAI},
  author       = {Ruiyi Guang and Xiang Li and Yaguo Lei and Bin Yang and Naipeng Li},
  doi          = {10.1016/j.engappai.2025.112445},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112445},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic vision-based machine vibration sensing and fault diagnosis with signal alignment and feature clustering},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A reliable degradation prediction method for proton exchange membrane fuel cells based on uncertainty bayesian self-attention. <em>EAAI</em>, <em>162</em>, 112444. (<a href='https://doi.org/10.1016/j.engappai.2025.112444'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health state prediction of Proton Exchange Membrane Fuel Cells (PEMFCs) is a critical technology to ensure their long-term reliable operation. Prediction accuracy directly influences the effectiveness of maintenance strategies and risk management. However, existing PEMFC degradation prediction methods based on Recurrent Neural Networks (RNNs) or Transformer architectures mostly focus on point estimation while neglecting uncertainty quantification. This limitation makes it difficult to assess the confidence level of predictions in practical engineering applications, reducing the models' reliability in decision support. To address this issue, this paper proposes a novel Bayesian Patch Time Series Transformer (B-PatchTST) method. By deeply integrating Bayesian variational inference with time series patch modeling, the method enables probabilistic prediction of PEMFC degradation trajectories and disentangled analysis of uncertainty sources. Unlike traditional Bayesian Neural Networks (BNNs) that primarily apply Bayesian modeling to fully connected layers, B-PatchTST introduces a Bayesian Self-Attention Mechanism, which models epistemic uncertainty in three stages: patch embedding, uncertainty-aware self-attention computation, and adaptive regularization. This design significantly enhances the credibility of the model. Extensive experiments on the fuel cell datasets demonstrate the proposed method's outstanding performance. It achieves an average reduction of 36.31 % in root mean square error and an average compression of 83.39 % in the 95 % confidence interval, significantly outperforming existing methods. This approach offers a trustworthy basis for predictive maintenance in PEMFC systems, promoting a shift from “experience-based maintenance” to “reliable prognostics” in hydrogen energy applications.},
  archive      = {J_EAAI},
  author       = {Mengyu Liu and Zhe Cheng and Yu Yang and Niaoqing Hu and Guoji Shen and Yi Yang},
  doi          = {10.1016/j.engappai.2025.112444},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112444},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A reliable degradation prediction method for proton exchange membrane fuel cells based on uncertainty bayesian self-attention},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Edge computing and server-based high-precision flood level classification system. <em>EAAI</em>, <em>162</em>, 112442. (<a href='https://doi.org/10.1016/j.engappai.2025.112442'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban flooding and the resulting road water accumulation have become a significant threat to public transportation safety and the stability of municipal infrastructure. Traditional monitoring networks based on physical water level sensors suffer from low deployment density, high maintenance costs, and lagging response times. To address these shortcomings of traditional water accumulation monitoring systems, this study proposes an edge-computing intelligent monitoring system based on collaborative inference between the edge end (You Only Look Once version 5, YOLOv5) and the server end (Transform Vision Detection, TrVDet). A dual-modal perception architecture of “edge-end triggering and server-end precise analysis” has been constructed. At the edge end, the YOLOv5 model is deployed on embedded devices to achieve efficient preliminary screening of water accumulation, reducing dependence on the central server, lowering latency, and enhancing real-time response capabilities. On the server end, multi-object segmentation is performed on the detected water accumulation images, including roads, cars, motorcycles, and bicycles. Finally, a series of logical judgments is applied to determine the water accumulation level based on reference objects within the water. Since there is no publicly available dataset for target object recognition in flooded areas, we employed professional annotators to perform pixel-level labeling on the collected and organized flood data and constructed a multi-class target flood dataset (City Flood Segmentation, CityFloodSeg). Given the scarcity of moderate and severe water accumulation samples, we optimized the instance segmentation model TrVDet under the (A Visual Representation for Neon Genesis, EVA-02) framework and applied five data augmentation methods, including Mosaic and Flip, to expand the diversity of the dataset. Moreover, based on domain expert standards, we designed a logical judgment rule algorithm for model inference of water accumulation levels to classify the levels of water accumulation. Experimental results show that the server-end processing delay is stable within 0.4 s, capable of accurately judging different water accumulation risk levels. This provides centimeter-level real-time situational awareness for urban flood control decision-making and promotes the development of intelligent municipal infrastructure towards higher reliability and universality.},
  archive      = {J_EAAI},
  author       = {Ankang Lu and Runlong Cao and Yuanbin Wang and Wenjun Hu and Yuncan Gao and Zhifeng Hu and Ying Zang},
  doi          = {10.1016/j.engappai.2025.112442},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112442},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Edge computing and server-based high-precision flood level classification system},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WeedNet-X: A lightweight field weed detection algorithm. <em>EAAI</em>, <em>162</em>, 112441. (<a href='https://doi.org/10.1016/j.engappai.2025.112441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately distinguishing field weeds from crops and locating weed positions are critical prerequisites in automated weed control operations. However, weed detection and localization in unstructured field environments with complex lighting remains challenging. Firstly, data-driven deep learning based algorithms usually have a high dependence on a large number of training samples, and there are huge differences between field weeds and crops in different regions, growth cycles, and types. In addition, the conflict between hardware performance and computation cost makes it difficult for existing weed detection algorithms to maintain both detection accuracy and speed on low-performance platforms. All these problems increase the difficulty of detection. To solve the above problems, we first construct a medium-to-large weed dataset using an open-source agricultural image dataset and collect field data. Subsequently, we have proposed a lightweight weed detection algorithm using the ShuffleNetv2 network as the backbone network, with a multi-scale pyramid network, and the overall network algorithm is named WeedNet-X. The number of model parameters and the computational volume of the algorithm are only 0.57 million and 0.48 Giga floating point operations (GFLOPs), respectively. On the two constructed datasets, the mean Average Precision (mAP) of the algorithm can reach 86.31 % and 80.98 %, respectively, which are improved by 0.61 % and 3.10 % compared to the baseline model. Finally, the hardware and software systems for weed detection verify the excellence of the proposed algorithm in terms of practical performance.},
  archive      = {J_EAAI},
  author       = {Yong Li and Ao Ke and Zhiqiang Guo and Qingji Tan and Jingchao Yang},
  doi          = {10.1016/j.engappai.2025.112441},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112441},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {WeedNet-X: A lightweight field weed detection algorithm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven robust intertwined wheat supply chain: Redesigning a viable network for long-term geopolitical conflicts. <em>EAAI</em>, <em>162</em>, 112440. (<a href='https://doi.org/10.1016/j.engappai.2025.112440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent human-made conflict in 2022 severely damaged Ukraine's infrastructure, causing significant instability in the food supply chain. This crisis was further exacerbated by trade bans imposed on another major global wheat exporter. Since wheat production and export are intrinsically linked, particularly in times of crisis, it is essential to adopt the concept of an intertwined supply chain. Accordingly, this study proposes an intertwined supply chain framework for the production and export of wheat during long-term disruptions. To enhance the viability of this intertwined system, the study introduces three key strategies. First, it addresses long-term disruptions and operational risks by employing redundancies and data-driven robust optimization techniques, where uncertainty sets are generated using a support vector clustering model. Second, the proposed supply chain accounts for freshwater resource limitations by integrating water resilience measures. Third, as the framework operates within a global context, it incorporates a comprehensive model that considers exchange rates, taxation, foreign demand points, and international trade responsibilities. To optimize these strategies, two multi-objective optimization models are developed and solved using an epsilon-constraint method. A cardinality-based measure is introduced to efficiently represent the Pareto front, offering decision-makers valuable insights into non-dominated solutions. The results are divided into analyses of wheat production, export, and their combined network. Individual analyses assess network setup, viability, and uncertainty control, while the integrated analysis examines sensitivity and interdependence. Overall, improving water use, managing risks, and designing a resilient, interconnected system can greatly strengthen the wheat supply chain during long-term crises.},
  archive      = {J_EAAI},
  author       = {Hani Gilani and Mehrdad Mohammadi and Tom Van Woensel and Hadi Sahebi},
  doi          = {10.1016/j.engappai.2025.112440},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112440},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data-driven robust intertwined wheat supply chain: Redesigning a viable network for long-term geopolitical conflicts},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multitask learning-based fault detection approach for high impedance fault in resonant distribution networks. <em>EAAI</em>, <em>162</em>, 112439. (<a href='https://doi.org/10.1016/j.engappai.2025.112439'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing high impedance faults (HIF) in resonant distribution networks remains a formidable challenge. This paper introduces a multitask learning-based approach integrated with a multitask fault detection network (MTFD-Net), employing three task-specific heads—classification, segmentation, and regression—to enable precise fault detection. MTFD-Net utilizes zero-sequence voltage data and a sliding time window to perform initial coarse classification, which allows the classification head to determine whether a permanent HIF has occurred. Upon detection, MTFD-Net proceeds to pinpoint potential fault moments through the outputs of the segmentation head. The regression head further refines these moments by predicting a reference moment and calculating the distance to each potential fault, effectively isolating the exact fault moment. An industrial prototype was developed and rigorously tested on a 10 kV system, where MTFD-Net demonstrated superior performance, achieving an accuracy of 0.976, an intersection over union of 0.984, and an absolute detection deviation of 5.20 ms. Operating efficiently with inference times ranging from 9.69 to 15.45 miliseconds on a Raspberry Pi 4B, MTFD-Net surpasses existing methods in accuracy, F1-score, sensitivity, specificity, and detection accuracy, providing a robust solution for HIF detection in resonant distribution networks.},
  archive      = {J_EAAI},
  author       = {Jian-Hong Gao and Mou-Fa Guo and Shuyue Lin and Duan-Yu Chen},
  doi          = {10.1016/j.engappai.2025.112439},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112439},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multitask learning-based fault detection approach for high impedance fault in resonant distribution networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Carbon trading price prediction with spikes: A novel hybrid model framework using heuristic multi-head attention convolutional bidirectional recurrent neural network. <em>EAAI</em>, <em>162</em>, 112438. (<a href='https://doi.org/10.1016/j.engappai.2025.112438'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of carbon trading prices (CTPs) with spikes is crucial for developing carbon emission reduction policies and planning corporate investments. However, most existing CTP approaches usually focus on designing a cutting-edge model without considering spike prediction. Therefore, this paper presents a novel heuristic optimization-based hybrid model framework for CTP prediction with spikes. First, random forest is exploited to identify the relevant features of spikes and non-spikes for CTPs, and categorical boosting is employed to predict the spike occurrences of CTPs. Then, a novel hybrid model based on multiple linear regression, categorical boosting, and two dimensions convolutional neural network and bidirectional gated recurrent unit with multi-head regularized attention mechanism (2DCNN-BiGRU-MRA) is proposed to predict spikes and non-spikes for CTPs. In this model, multiple linear regression and categorical boosting are respectively applied to capture the linear and complex nonlinear features of the CTPs, in which their prediction results and deviations are integrated into the 2DCNN-BiGRU-MRA model as relevant features. The proposed 2DCNN-BiGRU-MRA can learn the spatiotemporal features and enhance representation capabilities by introducing 2DCNN, BiGRU, and MRA, thereby improving the accuracy of CTP prediction. In addition, to construct appropriate model hyperparameters of 2DCNN-BiGRU-MRA, the strength honey badger algorithm based on the adaptive momentum estimation is proposed to optimize the hyperparameters of 2DCNN-BiGRU-MRA. Finally, the proposed framework is tested on the actual data of European Union emissions trading and the carbon market in Hubei, China, and case studies have confirmed the superiority and achievable local interpretability of the proposed hybrid model framework.},
  archive      = {J_EAAI},
  author       = {Rongquan Zhang and Siqi Bu and Gangqiang Li and Min Zhou},
  doi          = {10.1016/j.engappai.2025.112438},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112438},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Carbon trading price prediction with spikes: A novel hybrid model framework using heuristic multi-head attention convolutional bidirectional recurrent neural network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inter-graph and intra-graph: Utilizing global financial markets and constituent stocks for stock index prediction. <em>EAAI</em>, <em>162</em>, 112437. (<a href='https://doi.org/10.1016/j.engappai.2025.112437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock index prediction is a significant yet difficult undertaking due to its incorporation of complex and diverse information. Following the implementation of Graph Neural Networks in financial data analysis, numerous researchers have focused on the node-level task of forecasting individual stock movements by analyzing the relationships between stocks. However, two key challenges remain: first, realizing different speeds of feature propagation among nodes in graph representation learning; second, predicting stock indices by extracting and aggregating fluctuations from constituent stocks through graph-level tasks remains unaddressed. To tackle these challenges, this paper proposes a novel spatio-temporal prediction framework combining both node-level and graph-level tasks. The framework includes two types of graphs: inter-graph and intra-graph, which combine information from the micro, meso, and macro dimensions. For the inter-graph at the node level, we introduce the Granger causality test as an innovative node filtering method, which realizes the propagation of features between nodes with different strengths and speeds in the process of graph representation learning. For the intra-graph at the graph level, we examine various graph pooling methods and pooling proportions of stock index constituents to enhance the interpretability of the results and to provide new theoretical insights for stock index prediction. In conclusion, we develop the Graph Representation Learning-based Long Short-Term Memory (GRL-LSTM) model for forecasting stock index movements, and demonstrate the superiority of our approach on four major Chinese stock markets.},
  archive      = {J_EAAI},
  author       = {Yong Shi and Yunong Wang and Jie Wu},
  doi          = {10.1016/j.engappai.2025.112437},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112437},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inter-graph and intra-graph: Utilizing global financial markets and constituent stocks for stock index prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel data-efficient double deep Q-network framework for intelligent financial portfolio management. <em>EAAI</em>, <em>162</em>, 112436. (<a href='https://doi.org/10.1016/j.engappai.2025.112436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Navigating the complexities of dynamic and uncertain financial markets demands intelligent systems capable of learning profitable strategies amidst risk and volatility. While Deep Q-Networks (DQN) offer a foundation for such systems, they often suffer from overestimation bias, training instability, and poor generalization in noisy financial environments. To address these challenges, this work introduces Portfolio Double Deep Q-Network (PDQN), a novel architecture inspired by recent advancements in reinforcement learning. PDQN enhances portfolio management by integrating Double Q-Learning to reduce overestimation, alongside Leaky ReLU activation, Xavier initialization, Huber loss, and dropout regularization to improve learning stability and generalization. Unlike prior methods that rely on large datasets and heavy computational infrastructure, PDQN achieves competitive—and often superior—performance using substantially less training data and lightweight infrastructure, making it well-suited for real-world, resource-constrained financial applications. Distinct from conventional approaches, PDQN uses separate networks to adapt portfolio decisions across varying market conditions. Empirical results across multiple market years show that PDQN often outperforms baseline strategies, including classic DQN and Buy-and-Hold, across key metrics such as Sharpe ratio, Sterling ratio, and cumulative return. PDQN—like all data-driven models—exhibits room for improvement under highly irregular or extreme financial scenarios. These observations suggest promising directions for future refinement and increased robustness, without detracting from the model's practical effectiveness and competitive edge.},
  archive      = {J_EAAI},
  author       = {Mahshad Alidousti and Morteza Khakzar Bafruei and Amir Hosein Afshar Sedigh},
  doi          = {10.1016/j.engappai.2025.112436},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112436},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel data-efficient double deep Q-network framework for intelligent financial portfolio management},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlocking few-shot wind speed prediction through a novel end-to-end transfer learning paradigm based on decomposition and gating information fusion. <em>EAAI</em>, <em>162</em>, 112435. (<a href='https://doi.org/10.1016/j.engappai.2025.112435'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate wind speed prediction is one of the key technologies for achieving intelligent and sustainable development in the engineering field. In the field of wind speed prediction, we are confronted with a challenging few-shot prediction problem. Specifically, due to the fact that some wind turbines in wind farms are newly established or there is data loss during the data collection process, these turbines only contain a small amount of wind speed data. This scarcity of data poses great difficulties for the prediction work, and traditional prediction methods often fail to achieve the desired prediction accuracy. In order to overcome the above difficulties, we propose an novel prediction paradigm of end-to-end transfer learning based on data decomposition and gated information fusion. We use the Fourier transform to find the source domain similar to the target domain to achieve feature alignment. Then, we pre-train the model on the source domain and transfer this model to the target domain, thus solving the problem of low prediction accuracy when directly predicting the target domain. In the first step, the data is decomposed and denoised by using the Variational Mode Decomposition. According to the sample entropy, the decomposed data is reorganized into three frequency components. Each component is input as an independent channel into the end-to-end prediction model. Firstly, the features of each channel are expanded to a high-dimensional space through the Multilayer Perceptron. Then, the gating mechanism is utilized to mix the features of the three channels into the features of one channel, thus achieving information fusion. Finally, the prediction result of the end-to-end model is output through the Gated Recurrent Unit. In the second step, the model pre-trained on the source domain is transferred to the small-sample target domain. The Dynamic Time Warping and cosine similarity are used to quantify the similarity of each channel between the two domains. The parameters of the channels with high similarity are locked, and at the same time, the parameters of other channels are fine-tuned to output the final prediction result. In addition, multiple sets of comparative experiments conducted using the wind speed data from wind farms in Queensland, Australia, have demonstrated the superiority of this prediction paradigm. Our strategy outperforms various baseline models in all three sets of data. Moreover, ablation experiments have proven the effectiveness of each component in this framework in improving prediction accuracy, opening up a new path for solving the difficult problem of few-shot prediction in practical engineering.},
  archive      = {J_EAAI},
  author       = {Xiaoyue Dong and Zhirui Tian},
  doi          = {10.1016/j.engappai.2025.112435},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112435},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unlocking few-shot wind speed prediction through a novel end-to-end transfer learning paradigm based on decomposition and gating information fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hyperparameter-fusion neural networks for deposition prediction. <em>EAAI</em>, <em>162</em>, 112434. (<a href='https://doi.org/10.1016/j.engappai.2025.112434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As integrated circuit manufacturing processes develop into the nanometer scale, precise control and prediction of the deposition process have become crucial. Nanoscale manufacturing imposes unprecedentedly high demands on film quality, uniformity, and consistency, presenting significant challenges to traditional control and prediction methodologies. This study proposes a novel approach that, for the first time, formulates the thin-film deposition process as a video prediction task, enabling the use of deep learning for morphological forecasting under varying process conditions, and introduces a novel hyperparameter-fusion neural network, referred to as DepositionNet (DepoNet). Unlike conventional video prediction models, DepoNet specifically accounts for the influence of deposition parameters on the entire simulation process. We have incorporated a novel Hyper Projector that allows the model to flexibly adapt to varying deposition conditions and material characteristics. Through comprehensive comparative experimental analyses, we demonstrate that DepoNet significantly outperforms existing deep-learning models and achieves a mean squared error of 17.34, representing a 3.67% improvement over the second best model and a 1,435 × speedup over physics-based methods, thereby validating its exceptional generalization capability. Extensive experiments reveal that the model maintains high performance even under conditions of limited training data, for instance, achieving a peak signal-to-noise ratio (PSNR) of 41.516 decibels (dB) when trained with only 20% of the available data.},
  archive      = {J_EAAI},
  author       = {Li Ding and Kun Pang and Junjie Li and Hua Shao and Nan Liu and Rui Chen and Zhiqiang Li and Zhenjie Yao and Ling Li},
  doi          = {10.1016/j.engappai.2025.112434},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112434},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hyperparameter-fusion neural networks for deposition prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overcoming challenges in leveraging blockchain technology: Entropy-based q-rung orthopair fuzzy model for benchmarking application barriers. <em>EAAI</em>, <em>162</em>, 112433. (<a href='https://doi.org/10.1016/j.engappai.2025.112433'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology has emerged as a transformative solution across industries, delivering enhanced transparency, security, and operational efficiency. Nevertheless, its adoption remains hindered by significant challenges, especially in complex, data-intensive domains such as logistics. This study introduces a novel integration of the entropy-based q-rung orthopair fuzzy compromise ranking of alternatives from distance to ideal solution (CRADIS) approach to systematically evaluate and prioritize key barriers to blockchain adoption. The innovation of this work lies in applying q-rung orthopair fuzzy sets which are particularly capable of handling higher degrees of uncertainty and hesitancy, and then integrated with entropy for objective criterion weighting and CRADIS for robust decision-making. A real-world case study is presented, involving five critical barriers, lack of legal and regulatory frameworks, high implementation costs, technological scalability issues, data privacy and security concerns, and cultural resistance to change evaluated against eight decision criteria. The entropy weighting revealed regulatory clarity (0.168) and security (0.154) as the most influential factors, while the CRADIS ranking identified a lack of legal frameworks as the top barrier. This framework provides a transparent, data-driven method for decision-makers to identify and prioritize adoption challenges, particularly in uncertain and multi-faceted environments. By demonstrating the model’s applicability and precision, the study contributes to the emerging body of literature on blockchain integration and supports organizations in navigating the transition towards decentralized technologies.},
  archive      = {J_EAAI},
  author       = {Sana Shahab and Naoufel Kraiem and Ashit Kumar Dutta and Mohd Anjum and Vladimir Simic and Dragan Pamucar},
  doi          = {10.1016/j.engappai.2025.112433},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112433},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Overcoming challenges in leveraging blockchain technology: Entropy-based q-rung orthopair fuzzy model for benchmarking application barriers},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual angle magnetic arc blow estimation in keyhole tungsten inert gas welding using high dynamic range imaging and a lightweight vision transformer network with coordinate attention and multiple auxiliary branches. <em>EAAI</em>, <em>162</em>, 112432. (<a href='https://doi.org/10.1016/j.engappai.2025.112432'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In high current Keyhole Tungsten Inert Gas (K-TIG) welding, magnetic arc blow frequently causes severe defects such as lack of fusion and undercut, which seriously affect weld formation quality. Conventional visual sensing systems are limited by dynamic range, making it difficult to capture arc morphology, while single angle descriptors fail to represent nonlinear deflection and lightweight convolutional models struggle with long range dependencies. To address these challenges, this study employs a High Dynamic Range (HDR, 120 decibel [dB]) imaging system to capture detailed arc variations and proposes a lightweight Vision Transformer (ViT) network with embedded Coordinate Attention (CA) and multiple auxiliary branches for real time angle estimation. A custom magnetic excitation system enables controllable arc blow simulation and consistent data acquisition. The method introduces a dual angle representation, namely the maximum curvature angle ( θ curv ) and the equivalent deviation angle ( θ eq ), to comprehensively describe arc geometry. The Artificial Intelligence (AI) framework integrates segmentation, keypoint localization, and regression tasks to improve accuracy and robustness. Trained on a self constructed HDR dataset containing 3,191 annotated images, model achieves a mean absolute error (MAE) of 1 . 12 ° , a root mean square error (RMSE) of 2 . 84 ° , a determination coefficient ( R 2 ) of 0.96, and a per frame inference latency of 12.96 ms (ms) on an NVIDIA RTX 2080Ti graphics processing unit (GPU). These results demonstrate that AI based methods combined with HDR imaging cannot only achieve accurate monitoring of welding arc states, but also provide potential support for closed loop control in all position welding applications.},
  archive      = {J_EAAI},
  author       = {Xiyin Chen and Xiaohu Zhang and Yonghua Shi and Yuxiang Huang and Junjie Pang},
  doi          = {10.1016/j.engappai.2025.112432},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112432},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual angle magnetic arc blow estimation in keyhole tungsten inert gas welding using high dynamic range imaging and a lightweight vision transformer network with coordinate attention and multiple auxiliary branches},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A diffusion model using semantic and sketch information for anomaly detection. <em>EAAI</em>, <em>162</em>, 112430. (<a href='https://doi.org/10.1016/j.engappai.2025.112430'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In anomaly detection, methods that employ diffusion models for anomaly localization and reconstruction have demonstrated significant achievements. However, these methods face challenges such as the misclassification of multiple types of anomalies and the inability to effectively reconstruct large-scale anomalies due to the absence of semantic and sketch information from the original images. To tackle these challenges, we propose a framework, A Diffusion Model using Semantic and Sketch Information for Anomaly Detection (DSAD), which includes a semantic and sketch-guided network (SSG), a pre-trained autoencoder, and Stable Diffusion (SD). Initially, within SSG, we introduce a Semantic & Sketch Feature Fusion Module to enhance the model’s comprehension of the original images and present a Multi-scale Feature Fusion Module to maximize reconstruction accuracy. Subsequently, we connect SSG with the denoising network in SD in order to guide the network in reconstructing anomalous regions. Experiments on MVTec-AD dataset demonstrate the effectiveness of our approach which surpasses the state-of-the-art methods. The dataset and code are available at https://github.com/QinLi-STUDY/DSAD/tree/master .},
  archive      = {J_EAAI},
  author       = {Li Qin and Zhenyu Yin and Feiqing Zhang and Chunhe Song and Xiaoqiang Shi},
  doi          = {10.1016/j.engappai.2025.112430},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112430},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A diffusion model using semantic and sketch information for anomaly detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A real-time spatiotemporal error compensation framework for face gear grinding. <em>EAAI</em>, <em>162</em>, 112429. (<a href='https://doi.org/10.1016/j.engappai.2025.112429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geometric and thermal errors critically affect the precision of face gear grinding, yet current modeling approaches are computationally intensive and lack real-time adaptability. This study proposes a real-time spatiotemporal error compensation framework for face gear grinding. A closed-loop feedback mechanism is introduced to adaptively update compensation intensity based on residual error feedback, ensuring robustness and efficiency under fluctuating machining conditions. Moreover, a novel spatial-temporal thermal error model is developed by integrating Taylor-graph convolutional network and modified-long short term memory network to capture both node-level spatial fusion and long-term temporal dependencies. High-order terms in geometric error modeling are eliminated using a vector decomposition and truncation-based approach, significantly reducing computational complexity. Furthermore, a high-efficiency multi-source error-tooth flank mapping model is developed based on vector decomposition and truncation function methods, enabling accurate prediction with reduced computational cost. To identify dominant error contributors, an improved Morris-based sensitivity analysis method is integrated, distinguishing geometric and thermal errors affecting tooth flank deviation. Experimental results demonstrate sub-65 ms real-time response, 24.2 μm maximum error reduction, and robust adaptability under fluctuating machining conditions. Compared with recent gear-flank compensation studies, the proposed closed-loop framework achieves a 63.4 % reduction in maximum normal flank error under real machining and <65 ms response latency. This level is comparable to reported reductions based on grid-aggregated metrics in spiral bevel gears (76.82 % reduction of the sum of absolute grid errors), while additionally ensuring real-time, delay-aware execution. These findings validate the proposed system's potential for precision, real-time compensation in multi-axis manufacturing environments.},
  archive      = {J_EAAI},
  author       = {Jialan Liu and Chi Ma and Mingming Li and Jialong He and Giovanni Totis and Chunlei Hua and Gangwei Cui and Liang Wang and Ruijun Xue and Zhi Tan and Jun Yang and Kuo Liu and Yuansheng Zhou and Jianqiang Zhou and Xiaolei Deng and Shengbin Weng},
  doi          = {10.1016/j.engappai.2025.112429},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112429},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A real-time spatiotemporal error compensation framework for face gear grinding},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multilayer perceptron-based offspring prediction model for constrained multi-objective optimization. <em>EAAI</em>, <em>162</em>, 112428. (<a href='https://doi.org/10.1016/j.engappai.2025.112428'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multi-objective optimization problems generally have both multiple constraint violations and conflicting objective functions. Some of them not only have sparse feasible regions, but also are difficult to converge. For these problems, the evolutionary operators used in traditional constrained multi-objective evolutionary algorithms (CMOEAs) are difficult to generate solutions with ideal quality. Therefore, this paper proposes a multilayer perceptron-based offspring prediction model for constrained multi-objective optimization (MOPCMO). Specifically, an evolutionary direction guidance strategy is designed that utilizes historical populations as training data to train a multilayer perceptron, which guides the evolution of the population by predicting and generating offspring, thereby improving the overall evolutionary efficiency of the algorithm. In addition, as the population iterates, evolutionary direction guidance strategy adaptively transforms the training data of multilayer perceptron. Finally, the multilayer perceptron is intermittently updated and uses an evolutionary direction guidance strategy to generate promising offspring, guiding the algorithm to achieve efficient search. Compared with seven state-of-the-art CMOEAs on 33 benchmark test problems and 8 engineering application problems, MOPCMO achieves excellent performance.},
  archive      = {J_EAAI},
  author       = {Qianlong Dang and Ruihuan Luo and Linlin Xie and Xiaochuan Gao and Weiting Bai},
  doi          = {10.1016/j.engappai.2025.112428},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112428},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multilayer perceptron-based offspring prediction model for constrained multi-objective optimization},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault diagnosis via multi-sensor fusion with auxiliary contrastive learning and phased fine-tuning. <em>EAAI</em>, <em>162</em>, 112427. (<a href='https://doi.org/10.1016/j.engappai.2025.112427'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Typically, deep learning-based fault diagnosis models fail to fully utilize the potential information in large amounts of normal state data and encounter difficulties when learning from limited fault samples. To address these challenges, this study proposes an auxiliary contrastive learning framework designed for multi-sensor data. The framework incorporates auxiliary classifiers after each sensor-specific branch to enhance feature representation, and enables model pretraining using only normal condition data. In addition, a phased fine-tuning strategy is developed, which combines full-model fine-tuning with lightweight adapter tuning to improve the adaptability of the fine-tuning process. A novel multi-sensor data augmentation technique is also introduced to enrich the contrastive learning tasks by generating structurally diverse negative samples. By enabling the effective utilization of normal condition data in model training, the proposed framework offers a new perspective for fault diagnosis applications. Experimental results on three benchmark datasets demonstrate that the proposed method significantly improves the generalization capability of the pre-trained model. Furthermore, the phased fine-tuning strategy exhibits high adaptability to the target tasks. Compared to other data fusion methods, the proposed auxiliary contrastive learning framework achieves notable performance advantages.},
  archive      = {J_EAAI},
  author       = {Yulin Jin and Xiaochuan Luo and Xiangwei Kong and Yulin Zhang},
  doi          = {10.1016/j.engappai.2025.112427},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112427},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fault diagnosis via multi-sensor fusion with auxiliary contrastive learning and phased fine-tuning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Damage and energy dissipation prediction and multi-objective optimization design of latticed concrete-filled steel tube column-composite box girder joints based on extreme gradient boosting. <em>EAAI</em>, <em>162</em>, 112426. (<a href='https://doi.org/10.1016/j.engappai.2025.112426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To optimize joint performance, a finite element (FE) model is developed based on low-cycle reciprocating load tests of latticed concrete-filled steel tubular (CFST) column-composite box girder joints. The FE-predicted hysteresis curves are compared with test results to verify model accuracy, and a data set is established accordingly. Extreme Gradient Boosting (XGBoost) algorithm is used for training and prediction, and compared with the traditional machine learning (ML) algorithm, the superiority of the XGBoost algorithm is manifested. The XGBoost algorithm is then used to predict the damage and energy values of the joint under more different parameter combinations, with the largest ratio of damage value to energy dissipation value selected as the optimal combination of the joints within the variation range of the six parameters. The results show that the FE model correlates well with the test results and can therefore be used to generate a data set. The prediction accuracy of XGBoost algorithm has high accuracy of more than 99 % in predicting damage and energy dissipation values and can thus be used for joint prediction research. Compared with other ML algorithms, XGBoost has the best prediction performance and superiority. Within the variation range of the six parameters, the ratio of damage value to energy dissipation value is the largest when the concrete strength, longitudinal bar diameter, concrete slab thickness, box girder strength, axial compression ratio, and transverse stiffener strength are respectively 30 Mega Pascal (MPa), 12 mm (mm), 90 mm, 390 MPa, 0.3, and 455 MPa.},
  archive      = {J_EAAI},
  author       = {Zhi Huang and Xin Deng and Juan Chen and Xiang Li and Lizhong Jiang and Yohchia Frank Chen and Yuner Huang and Lin Chen},
  doi          = {10.1016/j.engappai.2025.112426},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112426},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Damage and energy dissipation prediction and multi-objective optimization design of latticed concrete-filled steel tube column-composite box girder joints based on extreme gradient boosting},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-dimensional feature fusion network design and performance optimisation for small target detection. <em>EAAI</em>, <em>162</em>, 112425. (<a href='https://doi.org/10.1016/j.engappai.2025.112425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the long distance of image acquisition, high imaging resolution, complex feature background, shooting angle, etc. The result is that there are few features available for small targets and they are easily interfered by background noise, which poses a challenge to the detection of small targets. To address the above problems, this paper proposes a target detection network (Convolution-based Small Target Detection Network, CSTDNet) with enhanced feature information, which integrates a multi-dimensional information fusion strategy for small target features. An all-round efficient feature fusion mudule (AeFusion) is introduced, which emphasises the fusion of multi-dimensional feature information, enhances the model's ability to focus on key information and suppress redundant information, and strengthens the ability to characterise local features and details, improving the effectiveness of the information and computational efficiency. In order to further enhance the location-awareness capability in cross-layer interaction, this paper introduces a novel decoupling head (Self-aware task decomposition for fine-grained feature sharing, STFS), which improves the accuracy of the small-target classification and localisation tasks through efficient detail sharing and task auto-alignment functions. And localisation tasks through efficient detail sharing and task auto-alignment. This study evaluates the effectiveness of the algorithm on five different scenarios containing small target datasets. Experimental results show that CSTDNet achieved improvements of 6.6 %, 5.8 %, 5.8 %, 5.5 %, and 5.6 % over the baseline model in terms of the mean average precision (mAP@0.5) metric on the Visdrone 2019, BDD100K, WiderPerson, SODA10M, and AppleDatas datasets, respectively, demonstrating stronger detection performance.},
  archive      = {J_EAAI},
  author       = {Xiaoyao Yang and Wenyang Zhao and Pengchao Sun and Wenda Zhao and Wenlong Yang},
  doi          = {10.1016/j.engappai.2025.112425},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112425},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-dimensional feature fusion network design and performance optimisation for small target detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FDFNet: Feature-decision dual fusion network for intelligent fault diagnosis of rotating machinery under varying speed conditions. <em>EAAI</em>, <em>162</em>, 112423. (<a href='https://doi.org/10.1016/j.engappai.2025.112423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis is a critical technique for enhancing the reliability and security of rotating machinery. Existing diagnosis methods still have restricted generalization performance under speed variations owing to inadequate utilization of multisensor information. To address this problem, a novel feature-decision dual fusion network is proposed for fault diagnosis of rotating machinery under varying speed conditions. First, for each sensor, the frequency information learner is built to simultaneously extract global and local frequency domain features using global and local feature encoders. These features are then fused through a cross-attention mechanism to generate a sensor-specific initial classification decision. Subsequently, these individual sensor-wise decisions are fed into the decision dynamic ensemble to yield final fault diagnosis result. Moreover, an adaptive optimization strategy is designed to guide model learning generalizable features by flexibly adjusting the sensor loss weights during training. Finally, the effectiveness of the proposed method is validated on bearing and gearbox datasets. Experimental results demonstrate that the proposed method exhibits superior generalization and robustness for fault diagnosis under varying speed conditions.},
  archive      = {J_EAAI},
  author       = {Qi Deng and Zuoxiu Zhang and Xuyuan Tu and Zimuzhi Wang and Jun Wu},
  doi          = {10.1016/j.engappai.2025.112423},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112423},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {FDFNet: Feature-decision dual fusion network for intelligent fault diagnosis of rotating machinery under varying speed conditions},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resource-efficient cross-subject emotion recognition from electroencephalogram via spiking domain discriminators. <em>EAAI</em>, <em>162</em>, 112422. (<a href='https://doi.org/10.1016/j.engappai.2025.112422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time emotion recognition poses a significant challenge in electroencephalogram (EEG) based emotion recognition, as it requires the immediate processing of EEG data. This necessity imposes substantial demands on the model’s resource consumption. To address this issue, this paper introduces a novel approach to EEG emotion recognition using a Cross Domain Spiking Convolutional Network (CDSCN), focusing on developments in the design of the spiking convolutional block. To address individual differences, the CDSCN incorporates Z-Score normalization at the feature level and introduces a spiking domain discriminator at the model level. These innovations aim to mitigate variations in data distribution across individuals and domains, thereby enhancing the model’s robustness and generalizability. Additionally, the CDSCN introduces a novel pooling fusion layer within the spiking convolutional block to optimize computational efficiency while preserving discriminative performance. Experimental evaluations on two publicly available datasets validate the effectiveness of the proposed CDSCN in achieving both accurate and generalized emotion recognition.},
  archive      = {J_EAAI},
  author       = {Dongdong Li and Shengyao Huang and Yujun Shen and Zhe Wang},
  doi          = {10.1016/j.engappai.2025.112422},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112422},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Resource-efficient cross-subject emotion recognition from electroencephalogram via spiking domain discriminators},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight deep learning based solar cells defect detection using electroluminescence images. <em>EAAI</em>, <em>162</em>, 112421. (<a href='https://doi.org/10.1016/j.engappai.2025.112421'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solar cells are the fundamental core energy harvesting components in photovoltaic (PV) power generation stations. In view of the capability of detecting the invisible defects, the electroluminescence (EL) imaging is broadly used in the production lines of solar cells, based on which the deep learning technique is introduced to implement automatic defect detection and classification. However, the current deep learning models feature high complexity and require much computation resources, which are difficult to deploy in edge devices for real time applications. To tackle this issue, we proposed a novel lightweight and high-precision deep learning model named Cross Stage Partial Photovoltaic-You Only Look Once (CSPV-YOLO) based on the deep learning framework You Only Look Once v5 (YOLOv5) to enable the real-time solar cell defect detection. Firstly, a new module Cross Stage Partial C5 (CSPC5) is proposed to replace the initial C3 module in the YOLOv5 network to enhance the network accuracy in recognizing different types of defects. Secondly, a novel Spatial Pyramid Pooling with Cross Stage Partial (SPPFCSP) module is designed to replace the original Spatial Pyramid Pooling Fast (SPPF), which boosts the network feature extraction capabilities from defect targets at multiple scales and facilitates a more efficient integration of multiscale features. Finally, the original loss function of YOLOv5 is replaced by the Scylla intersection over union (SIoU) function to optimize the training model. The proposed models have been validated and intensively compared with many other state-of-the-art models on two public datasets. Firstly, results of experiments on the public Pascal Visual Object Classes (PASCAL VOC) 2007 datasets demonstrate that the proposed SPPFCSP block is obviously superior to other Spatial Pyramid Pooling blocks for the most state-of-the-art YOLO detectors, which can significantly improve the detection accuracy. The comparison results of experiments on the public Photovoltaic Electroluminescence Anomaly Detection Dataset (PVEL-AD) that includes 12-class defects obviously indicate that the proposed CSPV-YOLO model is better than many state-of-the-art models and achieves 91.5 % average precision (AP) and frames per second (FPS) of 177.8 on with only 2.2 million (M) parameters. Hence, it is suitable for the deployment on edge devices for real-time applications.},
  archive      = {J_EAAI},
  author       = {Zhicong Chen and Tianxiang Chen and Haoxin Zheng and Lijun Wu and Shuying Cheng and Peijie Lin},
  doi          = {10.1016/j.engappai.2025.112421},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112421},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightweight deep learning based solar cells defect detection using electroluminescence images},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A streaming variable neural speech codec. <em>EAAI</em>, <em>162</em>, 112418. (<a href='https://doi.org/10.1016/j.engappai.2025.112418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a variable bit rate streaming neural speech codec designed for ultra-low bit rate scenarios, based on the SoundStream network framework. The codec employs the vector quantized variational auto-encoder (VQ-VAE) algorithm to capture the temporal structure and spectral characteristics of the speech signal, and constructs a latent space codebook to facilitate the effective mapping of feature vectors to discrete vectors. Based on the harmonic characteristics of speech signals and the inherent defects of single-scale discriminators, we introduce multi-period discriminators and multi-scale discriminators. The training process uses a balanced training strategy to ensure the balance between codebook utilization and training weights, and utilizes the Short-Time Fourier Transform (STFT) spectrum that can provide more accurate time–frequency resolution to compute the reconstruction loss. We introduce codebook loss to improve the utilization rate of the codebook and accelerate the convergence of the model. In the inference process, we use a quantizer selection strategy to achieve adaptive adjustment of variable bitrate. Objective and subjective experiments demonstrate that our proposed new neural speech codec outperforms traditional classical speech codecs and existing neural speech codecs in terms of reconstructed speech naturalness and quality while maintaining the low latency characteristic of neural speech codecs. With a multi-stimulus test with hidden reference and anchor (MUSHRA) score of 87, it is highly suitable for ultra-low bit rate speech compression applications such as satellite speech communication and narrowband instant messaging. The demo has been publicly released at https://svcodec.github.io/ .},
  archive      = {J_EAAI},
  author       = {Huaifeng Zhang and Pengfei Wu and Guigeng Li and Yuan An and Hao Zhang},
  doi          = {10.1016/j.engappai.2025.112418},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112418},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A streaming variable neural speech codec},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LGP-DETR: An end-to-end object detection model for surface defect detection in light guide plates. <em>EAAI</em>, <em>162</em>, 112416. (<a href='https://doi.org/10.1016/j.engappai.2025.112416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose Light Guide Plate-DETR (LGP-DETR), an end-to-end object detection model tailored for identifying surface defects in light guide plates (LGPs). To address challenges such as low contrast, small target size, and complex backgrounds in industrial settings, LGP-DETR integrates three key components: Deformable Transformer Fusion Layer (DtransFusion), a deformable attention-based fusion module for capturing multi-scale features; Upsampling by Dynamic Sampling (DySample), a dynamic upsampling strategy for edge detail preservation; and OrthoC3, a channel attention module that suppresses background noise through orthogonal feature enhancement. We adopt FasterNet as a lightweight convolutional backbone to achieve a balance between accuracy and efficiency. Experimental results on a real-world LGP defect dataset demonstrate that LGP-DETR achieves a mean Average Precision (mAP) of 97.9 % and inference speed of 60 frames per second (FPS), significantly outperforming existing models. Furthermore, generalization tests on a fiberglass fabric defect dataset confirm the model's adaptability to different industrial domains. These findings validate the practical applicability and robustness of the proposed deep learning framework for industrial visual inspection.},
  archive      = {J_EAAI},
  author       = {Shuangning Liu and Cunling Liu and Junfeng Li},
  doi          = {10.1016/j.engappai.2025.112416},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112416},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {LGP-DETR: An end-to-end object detection model for surface defect detection in light guide plates},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards efficient stream monitoring: A systematic approach for model selection and continuous improvement in tiny machine learning applications. <em>EAAI</em>, <em>162</em>, 112415. (<a href='https://doi.org/10.1016/j.engappai.2025.112415'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring ephemeral stream flows is essential for ecological and hydrological studies. However, their intermittent nature and remote locations pose challenges for conventional monitoring methods, which often consume excessive energy to capture rare events. We address this with BODOQUE (Bimodal Observational Device for Optimizing Quantification of Ephemeral streams), a dual-mode system that leverages Tiny Machine Learning (TinyML) on low-power microcontrollers. The system remains in an energy-saving sensing state and activates high-precision measurements only when water flow is detected. We present a model selection methodology that balances detection accuracy with inference cost, enabling reliable operation within hardware constraints. To enhance adaptability in diverse environments, we developed a specialized component that facilitates dataset expansion through new field samples. This supports ongoing retraining to maintain model performance under changing conditions. A comprehensive evaluation using real-world data demonstrates that our system can achieve up to 97% annual energy savings compared to traditional continuous monitoring approaches.},
  archive      = {J_EAAI},
  author       = {Benjamín Arratia and Erika Rosas and Javier Prades and Salvador Peña-Haro and José M. Cecilia and Pietro Manzoni},
  doi          = {10.1016/j.engappai.2025.112415},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112415},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards efficient stream monitoring: A systematic approach for model selection and continuous improvement in tiny machine learning applications},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer architecture with illumination aware mechanisms for low-light image enhancement via retinex decomposition. <em>EAAI</em>, <em>162</em>, 112414. (<a href='https://doi.org/10.1016/j.engappai.2025.112414'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancing low-light images is a complex task that involves not only restoring brightness but also preserving color fidelity and reducing noise interference. In this paper, we propose a novel Retinex-based Transformer Model with Illumination Aware Mechanisms (TIMRetinex-Net), which achieves physically interpretable modeling through a decomposition network guided by Retinex theory. To adapt to light variations in different regions, we randomly apply gamma transformations to several subregions of the illumination component and use a Color Estimation Module to capture the color global distribution of the natural scene in the reflection component. By modeling the color global distribution and repairing the degraded regions collaboratively, we alleviate the issue of being highly sensitive to data usage during training and improve the model’s ability to handle unknown scenes. The Illumination and Reflection Adjustment Transformer Network (IRAT-Net) produces enhanced images, achieving a balanced enhancement of detail and color. In addition, IRAT-Net incorporates an attention mechanism into the feature extraction layer and introduces the Illumination-Guided Information Aggregation Module to adaptively estimate lighting conditions. In the field of image processing, our method based on artificial intelligence was evaluated on five datasets and compared with twelve state-of-the-art methods. The results demonstrated strong alignment with the ground truth, with our method achieving superior performance in both subjective and objective assessments.},
  archive      = {J_EAAI},
  author       = {Zixuan Wang and Gang Liu and Hanlin Xu and Yao Qian and Rui Chang and Durga Prasad Bavirisetti},
  doi          = {10.1016/j.engappai.2025.112414},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112414},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transformer architecture with illumination aware mechanisms for low-light image enhancement via retinex decomposition},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient interactive segmentation of three-dimensional gaussians with optimal view selection. <em>EAAI</em>, <em>162</em>, 112413. (<a href='https://doi.org/10.1016/j.engappai.2025.112413'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) scene representation has advanced rapidly in recent years, drawing the focus of more researchers. One of the main challenges for researchers is quickly and accurately segmenting 3D objects. Previous work has achieved excellent segmentation accuracy, but retraining requires a significant amount of time. Additionally, most methods fail to provide users with an efficient and convenient segmentation experience. To address these issues, we present Efficient Interactive Segmentation of 3D Gaussians (EISG), an efficient interactive segmentation method that eliminates the need for lengthy retraining. We first design an optimal view selection (OVS) method. This method uses 3D Gaussian entropy and image uncertainty to evaluate the quantity of view information. OVS helps users quickly select the optimal segmentation view, thereby enhancing interaction efficiency. Secondly, we use projection to find the target foreground rapidly and then segment the approximate objects using a clustering algorithm. Thirdly, we design a spatial-color background filter (SCBF) using the depth and color of 3D Gaussians. SCBF enables precise segmentation without needing retraining. Our method has been systematically tested on multiple datasets. Compared to other methods, the results demonstrate that EISG achieves ideal accuracy while significantly reducing processing time.},
  archive      = {J_EAAI},
  author       = {Yongtang Bao and Chengjie Tang and Yuze Wang and Yutong Qi and Ruijun Liu},
  doi          = {10.1016/j.engappai.2025.112413},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112413},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient interactive segmentation of three-dimensional gaussians with optimal view selection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial black-box attack and defense for convolutional neural network-based power quality disturbance classification. <em>EAAI</em>, <em>162</em>, 112411. (<a href='https://doi.org/10.1016/j.engappai.2025.112411'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correctly identifying power quality disturbance (PQD) is crucial for the proper functioning of power systems. Deep learning (DL) techniques have been widely used for PQD classification due to their excellent performance. However, DL models are susceptible to adversarial attacks, posing a serious security threat to DL-based PQD classification systems. This issue has received limited attention in current research. In this study, we first utilize a convolutional neural network (CNN) to recognize various types of PQD signals. To evaluate model robustness, we introduce a black-box attack method for PQD classification based on the variance-tuning momentum iterative fast gradient sign method (VMI-FGSM). VMI-FGSM integrates a variance tuning method into the iterative process of the momentum iterative fast gradient sign method (MI-FGSM) , thereby producing more transferable adversarial PQD signals. To defend against such attacks, we propose a perturbation removal defense based on a generative adversarial network (PRD-GAN). This approach is capable of removing perturbations from adversarial PQD signals before they are recognized by the target classification model. Experiments demonstrate that VMI-FGSM produces adversarial perturbations that are nearly identical to those of the advanced MI-FGSM, but its adversarial examples are significantly more effective at misleading the target CNN model. Furthermore, the proposed PRD-GAN effectively reconstructs adversarial PQD signals into clean forms under various black-box attack intensities and outperforms the multi-level denoising autoencoder (ML-DAE) in defense performance due to its superior reconstruction capability.},
  archive      = {J_EAAI},
  author       = {Xiudong Zhang and Congmei Jiang and Mingbiao Yu and Xiankui Wen and Jing Zhang and Na Rong and Song Han},
  doi          = {10.1016/j.engappai.2025.112411},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112411},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adversarial black-box attack and defense for convolutional neural network-based power quality disturbance classification},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An intrusion detection system for critical infrastructures: Modbus approach. <em>EAAI</em>, <em>162</em>, 112410. (<a href='https://doi.org/10.1016/j.engappai.2025.112410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to develop an Intrusion Detection System (IDS) using deep learning and machine learning algorithms to detect cyber attacks in the network traffic of critical infrastructures using an artificial intelligence-based approach. The research investigates various machine learning algorithms, datasets, and performance evaluations to detect the security vulnerabilities commonly found in industrial networks. Implemented in Python, the system has been tested on hybrid dataset, demonstrating the performance of different algorithms in terms of accuracy, precision, and other metrics. From artificial intelligence perspective, this study contributes machine learning and deep learning in cybersecurity, showing how normal and ensemble models can effectively detect complex threats, with fewer features but more relevant. The research employs supervised learning techniques, leveraging labeled datasets to train models that can accurately classify network traffic as either normal or attack, ensuring high detection accuracy. From an engineering standpoint, the system’s Python implementation addresses the practical challenges of real-world deployment in industrial control systems (ICS) and facilitates integration with existing infrastructures. Additionally, the custom dataset and post-dissector code contribute to the field of industrial cybersecurity, providing engineers with tools for testing, validating, and optimizing IDS solutions. As cyber–physical systems are increasingly integrated into ICS, the proposed IDS provides a crucial layer of defense against cyber threats, safeguarding both the digital and physical components of critical infrastructure. The findings reveal that the proposed system exhibits high performance in terms of detection accuracy. The results show that the system provides an effective and reliable detection mechanism using artificial intelligence techniques.},
  archive      = {J_EAAI},
  author       = {Murat Varol and Murat İskefiyeli},
  doi          = {10.1016/j.engappai.2025.112410},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112410},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An intrusion detection system for critical infrastructures: Modbus approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive resource management in dynamic Cyber–Physical systems using artificial intelligence. <em>EAAI</em>, <em>162</em>, 112409. (<a href='https://doi.org/10.1016/j.engappai.2025.112409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective resource management is crucial for the operation of dynamic Cyber–Physical Systems (CPS), yet traditional static or rule-based approaches often fail to handle their inherent complexity. This paper presents a novel Artificial Intelligence (AI)-driven framework for adaptive resource management, defined as the capability to autonomously adjust resource allocation by proactively forecasting future demands and dynamically optimizing decisions in real-time. The framework integrates a suite of AI techniques, including time-series models like Long Short-Term Memory (LSTM), chosen for their ability to capture complex temporal dependencies, for demand prediction. For resource allocation, it employs advanced actor–critic reinforcement learning (RL) algorithms like Proximal Policy Optimization (PPO) and Deep Deterministic Policy Gradient (DDPG), selected for their stability and efficiency in complex decision-making tasks. Performance was rigorously evaluated in a simulated dynamic environment. Experimental results demonstrate that combinations leveraging LSTM’s predictive accuracy with the robust optimization of PPO and DDPG achieve superior performance and stability. Specifically, the LSTM+DDPG and LSTM+PPO configurations yielded the highest average rewards (0.964 and 0.942, respectively), significantly outperforming the fixed-strategy baseline (0.497) and other AI pairings. Furthermore, the feasibility of training prediction models in a distributed manner via Federated Learning (FL) is successfully demonstrated. This research highlights that a synergistic integration of suitable AI predictors and advanced RL agents provides a powerful and resilient solution for resource management in dynamic CPS.},
  archive      = {J_EAAI},
  author       = {Xiaofei Zhao and Fangling Guo and Amin Huang and Jieqiong Ding and Chi Yan and Wei Yuan and Yunqi Su and Quanzhou Li and Qianggang Zhang},
  doi          = {10.1016/j.engappai.2025.112409},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112409},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive resource management in dynamic Cyber–Physical systems using artificial intelligence},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel prior knowledge-based and texture-enhanced network for few-shot industrial defect segmentation. <em>EAAI</em>, <em>162</em>, 112408. (<a href='https://doi.org/10.1016/j.engappai.2025.112408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based segmentation techniques have demonstrated significant potential in defect detection, which is vital for product quality. However, the existing models tend to specialize in detecting specific defect types, reducing their adaptability to a wider range of product defects, most existing methods rely on multi-scale or prototype learning to extract defect features, but still struggle with complex backgrounds, various interferences, and large intra-class variations. Additionally, the rarity of certain defects limits the availability of training samples. Herein, an innovative segmentation network, the Prior Knowledge-based and Texture-Enhanced Network (PTNet), is designed for few-shot industrial segmentation. The model is mainly composed of a self-guidance branch, a cross-guidance branch, and a texture enhancement module, enabling generalization across defect types with minimal labeled samples. Self-guidance extracts prior knowledge from the query image, while the cross-guidance branch extracts prior and prototype features from the masked support image. The texture information in the low-level features of the backbone is then enhanced by proposed texture enhancement module (TEM). Finally, the enhanced low-level texture information are fused with high-level semantic features, allowing the network to fully exploit both local details and global context before being decoded to restore the original image size. This enables the model to handle complex textures and generalize to unseen defect types. Extensive experimental results validate the effectiveness of the proposed modules. State-of-the-art performance is achieved in few-shot defect segmentation, with notable improvements in mean Intersection over Union (mIoU) of 46.05 % and 46.98 % under 1-shot and 5-shot conditions, respectively.},
  archive      = {J_EAAI},
  author       = {Xingyue Liu and Qian Wu and Yahui Cheng and Guojun Wen},
  doi          = {10.1016/j.engappai.2025.112408},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112408},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel prior knowledge-based and texture-enhanced network for few-shot industrial defect segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel reinforcement learning-based approach for optimal control: An application to multi-tank water systems. <em>EAAI</em>, <em>162</em>, 112407. (<a href='https://doi.org/10.1016/j.engappai.2025.112407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization of control actions is a critical challenge in industrial systems, especially when dealing with complex and unknown dynamics. Data collected from the environment enables the application of reinforcement learning techniques, which let the controller learn a policy based on data. This work proposes a novel model-free reinforcement learning approach that consists of a value iteration algorithm based on separate policy evaluation and policy improvement phases to provide an accurate control policy estimation. The proposed approach addresses tracking control for quadruple-tank water systems while obtaining minor tracking errors and faster transient responses. The results from the case study reveal better accurate estimation of the value function, up to 86.13% mean improvement in tracking accuracy and faster responses compared to existing methods. Therefore, the proposed approach demonstrates advantages in optimizing control performance and stands as a promising control method for industrial applications.},
  archive      = {J_EAAI},
  author       = {Eva Masero and Giacomo Mussita and Alessio La Bella and Riccardo Scattolini},
  doi          = {10.1016/j.engappai.2025.112407},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112407},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel reinforcement learning-based approach for optimal control: An application to multi-tank water systems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic weighted ensemble learning for ballast resistance estimation driven by vehicle-ground information fusion. <em>EAAI</em>, <em>162</em>, 112406. (<a href='https://doi.org/10.1016/j.engappai.2025.112406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health management of transmission parameters for railway signal equipment is a key link between intelligent operation and maintenance. As a core parameter of track circuits, ballast resistance significantly affects signal transmission. To accurately and reliably assess its health state, an ensemble learning algorithm (ELA) is introduced, tackling deviations of appraisal decision boundaries. Focusing on issues of complex weight calculation, model homogenization, and severe overfitting in ELA, an integration model based on an automatic weight allocation strategy (AWAS) is innovatively proposed, constructing a method for resistance estimations driven by information fusion, while maximizing its generalization ability. Firstly, for deterioration mechanism analysis of ballast resistance, a transmission state model for vehicle-ground collaboration is established, completing extractions of evolutionary rules. Secondly, the improved ELA leverages heterogeneous classifier optimization and automatic weighted soft voting, with its core ensemble strategy employing a secondary learner to map the fused datasets. Then, by means of data mining techniques, interpolation and denoising algorithms are applied to implement data preprocessing, facilitating the effective fusion of heterogeneous vehicle-ground information. Finally, based on occurrence of adverse conditions, an appropriate particle size is set to achieve state warning. The results indicate that the proposed AWAS for ballast resistance calculations can achieve 98.52 % testing accuracy and outperforms others.},
  archive      = {J_EAAI},
  author       = {Conghui Wang and Shiwu Yang and Chang Liu},
  doi          = {10.1016/j.engappai.2025.112406},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112406},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automatic weighted ensemble learning for ballast resistance estimation driven by vehicle-ground information fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Future of humanity in an artificial intelligence centric world. <em>EAAI</em>, <em>162</em>, 112405. (<a href='https://doi.org/10.1016/j.engappai.2025.112405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This scholarly article rigorously investigates the transformative and disruptive roles of artificial intelligence (AI) in influencing the trajectory of human society. By concentrating on three fundamental sectors—healthcare, finance, and education—it evaluates the ways in which AI augments operational efficiency, facilitates intricate decision-making processes, and introduces innovative capabilities such as personalized medicine and automated financial systems. Concurrently, the analysis underscores urgent ethical dilemmas, encompassing algorithmic bias, accountability deficiencies, data privacy vulnerabilities, and workforce displacement. Employing real-world examples such as Deepfakes, and Neuralink, the article contextualizes emerging challenges within a dynamic socio-technical framework. The research offers a cohesive conceptual model that amalgamates technical, ethical, and governance aspects of AI, while presenting policy recommendations designed to promote transparency, equity, and human-centered AI development. The study emphasizes the necessity for reliable AI systems that humans can trust. The conclusions accentuate the immediate necessity for robust regulatory frameworks and sector-specific ethical supervision to ensure that advancements in AI are harmonized with the well-being of society.},
  archive      = {J_EAAI},
  author       = {Sunil Baloda and Monika Sharma and Mukesh Kumar},
  doi          = {10.1016/j.engappai.2025.112405},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112405},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Future of humanity in an artificial intelligence centric world},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel federated deep learning for intrusion detection in smart grid cyber-physical systems. <em>EAAI</em>, <em>162</em>, 112404. (<a href='https://doi.org/10.1016/j.engappai.2025.112404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fusion of sophisticated computational, communicative, and physical elements in Smart Grid Cyber-Physical Systems (SGCPS) has greatly improved the efficiency and reliability of power grids. However, this complexity introduces enhanced cybersecurity risks, evidenced by significant cyberattacks on the Ukrainian power grid during 2015 and 2016. Despite progress in Artificial Intelligence (AI)-driven security solutions for SGCPS, practical deployment of these technologies is often limited due to a lack of high-quality attack data and owners’ hesitance to distribute sensitive details. This paper introduces an innovative strategy to fortify SGCPS against diverse network threats via a comprehensive intrusion detection system. We present a deep learning model leveraging a temporal convolutional network with multi-feature integration, aimed at robust threat identification. We also propose a federated learning framework enabling various SGCPS to jointly develop an extensive intrusion detection model, ensuring data privacy. Moreover, we incorporate a gradient compression technique utilizing the Long Short Term Memory- β -Total Correlation Variational Autoencoder (LSTM- β -TCVAE) model to enhance and secure model parameters throughout the training phase. Thorough experimental validations confirm the efficacy of our method in recognizing multiple cyber threat types to SGCPS and its advantages over current methods.},
  archive      = {J_EAAI},
  author       = {Rong Xie and Bin Wang and Xin Xu},
  doi          = {10.1016/j.engappai.2025.112404},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112404},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel federated deep learning for intrusion detection in smart grid cyber-physical systems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tunnel-YOLO: An improved you only look once algorithm for real-time shield tunnel lining leakage detection. <em>EAAI</em>, <em>162</em>, 112403. (<a href='https://doi.org/10.1016/j.engappai.2025.112403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting crack leakages in shield tunnels is crucial for ensuring structural safety and extending service life, as traditional detection methods are limited by high subjectivity and low accuracy. To address these limitations, this paper proposes Tunnel-YOLO, an improved object detection algorithm based on You Only Look Once version 8 (YOLOv8). This algorithm replaces standard convolutional blocks with a novel Receptive Field Channel Attention Convolution (RFCAConv) module, which leverages dynamic receptive fields to enhance feature capture at different scales. We also introduce a C2f_SGE module, integrating the Spatial Group-wise Enhance (SGE) attention mechanism into the C2f (CSPNet with 2 convolutions) block to significantly improve feature extraction while suppressing background interference. Furthermore, an Edge Feature Enhancement Detection Head (EFE-Head) incorporates deconvolution layers to enhance fine-grained details for more precise boundary localization. To better accommodate the shape-sensitive detection task, our LeShape-IoU (Intersection over Union) loss function is designed to focus on the shape and scale characteristics of target bounding boxes. Experimental results on a public, real-world dataset demonstrate that Tunnel-YOLO significantly outperforms the baseline, increasing Recall, Precision, and mean Average Precision at 0.5 IoU (mAP50) by 15.7%, 10.3%, and 14.8%, respectively. Comparative analysis with other mainstream algorithms further validates the effectiveness and superiority of the proposed Tunnel-YOLO.},
  archive      = {J_EAAI},
  author       = {Ruijun Yang and Hao Zhang},
  doi          = {10.1016/j.engappai.2025.112403},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112403},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Tunnel-YOLO: An improved you only look once algorithm for real-time shield tunnel lining leakage detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of data-driven predictive model and enhanced multiobjective optimization to improve the excavation performance of large-diameter slurry shields. <em>EAAI</em>, <em>162</em>, 112402. (<a href='https://doi.org/10.1016/j.engappai.2025.112402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safety, efficiency and energy consumption are important aspects for evaluating the performance of large-diameter slurry shield, and improving the performance of shield is crucial for safe and efficient excavation. To this end, a data-driven hybrid method is developed to improve the excavation performance of large-diameter slurry shields by intelligence regulating shield parameters. This method combines Bayesian Optimization with categorical boosting (BO-CatBoost) and enhanced multiobjective evolutionary algorithm based on decomposition (EMOEA/D). The method uses surface settlement, penetration and specific energy as output targets and employs the expert knowledge to select the input parameters. Subsequently, the trained BO-CatBoost model is employed to fit the input-output relationship. On this basis, the multiobjective optimization process was performed using EMOEA/D, with the important parameters determined by Shapley Additive exPlanations as decision variables and the nonlinear relationship fitted by BO-CatBoost as the objective function. Finally, the technique for order preference similarity to ideal solution is applied to obtain optimal operational parameters, thereby enhancing the excavation performance of large-diameter slurry shield. The proposed method is applied to a Wuhan rail transit line to verify the effectiveness, and the result shows that: (1) Our method can accurately predict the three targets with goodness of fit ranging from 0.938 to 0.988, respectively. (2) The proposed method can effectively improve the excavation performance of the large-diameter slurry shield, and reaches 13.88 %, 5.21 %, and 10.88 %, respectively. (3) An adaptive decision-making system for setting operational parameters is constructed, which is valuable for formulating of operational control strategies for large-diameter slurry shields.},
  archive      = {J_EAAI},
  author       = {Feiming Su and Xianguo Wu and Tiejun Li and Yang Liu},
  doi          = {10.1016/j.engappai.2025.112402},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112402},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development of data-driven predictive model and enhanced multiobjective optimization to improve the excavation performance of large-diameter slurry shields},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive active adaptive partial label learning under class distribution mismatch. <em>EAAI</em>, <em>162</em>, 112401. (<a href='https://doi.org/10.1016/j.engappai.2025.112401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial label learning is an important learning framework where each training sample is associated with a candidate label set and its ground-truth label is included in the candidate label set. Active partial label learning is a variation where training data consists of both labeled and unlabeled samples. However, there exists the problem of class distribution mismatch, wherein the unlabeled sample set contains many instances out of the target categories. In this paper, a contrastive active adaptive partial label learning method under class distribution mismatch which combines active partial label learning with contrastive coding is proposed. A novel active sample selection strategy is first established to use label propagation ability to measure the optimization ability of unlabeled samples to partially labeled samples. Furthermore, to solve the problem of class distribution mismatch, a joint query score based on contrastive coding is utilized to reduce the queries of unlabeled samples out of target categories. Finally, the above two indicators are combined adaptively to select the most valuable unlabeled samples in target categories for manual labeling and the selected samples will be added to the training sample set to train the new classifier. The effectiveness and efficiency of the method are evaluated by performing experiments on the datasets CIFAR10 and CIFAR100.},
  archive      = {J_EAAI},
  author       = {Aohan Zhang and Kezhen Dong and Hongying Zhang},
  doi          = {10.1016/j.engappai.2025.112401},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112401},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Contrastive active adaptive partial label learning under class distribution mismatch},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A framework for photovoltaic power forecasting based on hybrid data reconstruction, neural network models fusion, and multi-objective optimization. <em>EAAI</em>, <em>162</em>, 112400. (<a href='https://doi.org/10.1016/j.engappai.2025.112400'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intermittency of photovoltaic power seriously affects the safety and operation of the power grid. Accurate photovoltaic power forecasting is critical for a safe connection of large-scale solar energy to the grid. Despite the efforts of many researchers, current forecasting methodologies remain inadequate. To bridge this gap, leveraging the recent advancements in artificial intelligence algorithms, this work combines cutting-edge deep learning techniques and data preprocessing strategies to develop a forecasting system that comprehensively considers various influencing factors and integrates multiple deep learning neural networks. The framework enables deterministic forecasting and uncertainty analysis, providing reliable supporting information for accurate forecasting through hybrid decomposition data preprocessing and feature selection modules. Then, closed-form continuous-time (Cfc) neural networks are introduced as one of the core forecasting components. Theoretically, the validity of the combined model and the Pareto optimization process are proved. Practically, the multi-objective African vultures optimization (MoAvo) is employed to identify the Pareto optimal solution, integrate four models, and improve the model's adaptability to external environmental changes. The experimental results show that the average mean absolute percentage error (MAPE) of the designed combined system for 1–3 steps forecasting on the Yulara are 6.09 %, 8.15 %, and 10.03 %, respectively. The results demonstrate that the framework fully considers the influence of candidate variables on forecasting, offering significant advantages over comparison models.},
  archive      = {J_EAAI},
  author       = {Menggang Kou and Jianzhou Wang and Jingrui Li and Runze Li and Zhiwu Li},
  doi          = {10.1016/j.engappai.2025.112400},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112400},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A framework for photovoltaic power forecasting based on hybrid data reconstruction, neural network models fusion, and multi-objective optimization},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A binary particle swarm optimization with dual encoding mechanism for feature selection. <em>EAAI</em>, <em>162</em>, 112397. (<a href='https://doi.org/10.1016/j.engappai.2025.112397'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a crucial machine learning preprocessing stage with numerous practical uses. Numerous algorithms are created to tackle the task. However, these algorithms still suffer from several challenges. This study introduces a novel binary particle swarm optimization with dual encoding mechanism, named DEBPSO, to solve feature selection problems. A new transfer function, called an inverse S-shaped function, and a Boolean encoding mechanism are employed to enhance the exploration performance of DEBPSO. In addition, to better balance exploration and exploitation, a new game mechanism is proposed to find the best solution. In order to verify the performance of DEBPSO, a comprehensive experimental is designed. The experimental results on 27 well-known datasets show that DEBPSO significantly outperforms the compared algorithms on 17, 14, 13, 17, 16, 21, 14, 23, 20 datasets in terms of classification error rate, highlighting its efficiency in reducing the classification error rate and irrelevant features.},
  archive      = {J_EAAI},
  author       = {Chong Zhou and Rumeng Liang and Qi Liu and Sirui Niu},
  doi          = {10.1016/j.engappai.2025.112397},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112397},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A binary particle swarm optimization with dual encoding mechanism for feature selection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel weight-optimized machine-learning hybrid model for daily river runoff prediction. <em>EAAI</em>, <em>162</em>, 112396. (<a href='https://doi.org/10.1016/j.engappai.2025.112396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The daily runoff process has been characterized as nonlinear and unsteady due to the impacts of watershed precipitation and evaporation, vegetation coverage rate, reservoir operations and other human activities. In recent years, machine-learning (ML) models have been widely applied in the daily runoff predictions, but the robustness and effectiveness of individual ML model is always limited. A novel weight optimization scheme has been introduced to ML models to obtain accurate predictions of daily river runoff. Variational modal decomposition method is adopted in the dataset preprocessing, and the runoff prediction performance of various classic ML models, including Genetic Algorithm-Back Propagation neural network (GA-BP), Long Short-Term Memory network (LSTM), Elman neural network (Elman) and Genetic Algorithm-Support Vector Machine (GA-SVM) are subsequently evaluated. A particle swarm optimization (PSO) based weight optimization strategy is proposed to combine different types of ML models, thus more accurate and robust results could be obtained. The ten-fold cross-validation method has been adopted and the performance of the optimized hybrid models are further evaluated for different schemes. A case study at Hankou hydrological station demonstrates that root mean square error (RMSE) and mean absolute percentage error (MAPE) is improved by 35.7 %, 75.8 % respectively for the optimized hybrid model. The present study shares useful insights to the comprehensive optimization of various ML models in the intelligent management of water resources.},
  archive      = {J_EAAI},
  author       = {Zhonglian Jiang and Jianglong Ying and Zhen Yu and Xiao Chu and Chengqiang Yu},
  doi          = {10.1016/j.engappai.2025.112396},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112396},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel weight-optimized machine-learning hybrid model for daily river runoff prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent assessment of habitat quality based on multiple machine learning fusion methods. <em>EAAI</em>, <em>162</em>, 112395. (<a href='https://doi.org/10.1016/j.engappai.2025.112395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating habitat quality can help balance the relationship between economic development and biodiversity conservation, and it serves as a foundation for constructing an ecological security pattern. However, research on the intelligent construction of habitat quality is limited. This study develops a comprehensive framework to assess habitat quality based on optimized machine learning methods. The findings of the research are as follows: (1) From the perspective of human-machine interactive interpretation, ensemble learning is used to enhance the performance of basic classifiers, resulting in a classification map with high precision and recall. (2) The particle swarm optimization (PSO) algorithm can improve the goodness of fit of the Extreme Gradient Boosting (XGBoost) inversion model by 4–5 %. (3) The habitat quality inversion method based on XGBoost-PSO has high credibility and application value, with its texture structure being the result of both expert experience and image information interaction. (4) The model demonstrates certain application potential in downscaling; under the seven-band perspective, the blue and near-infrared bands are the most important, while in the four-band perspective, green and near-infrared bands take precedence.},
  archive      = {J_EAAI},
  author       = {Kui Yang and Dongge Cui and Chengrui Wang and Qi Tang and Linguang Miao},
  doi          = {10.1016/j.engappai.2025.112395},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112395},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent assessment of habitat quality based on multiple machine learning fusion methods},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical semantics guided multi-scale correlation network for alignment-free red-green-blue and thermal salient object detection. <em>EAAI</em>, <em>162</em>, 112394. (<a href='https://doi.org/10.1016/j.engappai.2025.112394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGBT (red-green-blue and thermal) salient object detection (SOD) aims to identify and highlight the most visually salient objects in an image by leveraging the complementary information from both RGB and thermal (TIR) modalities. It is particularly effective for 24/7 intelligent surveillance and autonomous perception in smart city security and traffic monitoring, especially under low light and adverse weather. However, existing methods primarily rely on manually aligned datasets, which are limited in handling the challenges posed by unaligned multi-modal data in real-world applications. Furthermore, these methods usually extract complementary information from both modalities using fixed-size windows (Liuet al., 2022, Wanget al., 2024b). However, such fixed-size windows are not effective in dealing with unaligned multi-modal images due to spatial inconsistencies. Additionally, existing methods often use single-layer high-level feature to represent semantic information, which fails to fully exploit the complementary benefits of multi-level features, thereby reducing the effectiveness of semantic guidance. To address these challenges, we propose a Hierarchical Semantics guided Multi-scale correlation Network (HSMNet) for alignment-free RGBT SOD. A Hierarchical Semantic Fusion Module (HSFM) dynamically assigns weights to features from multiple levels, enabling adaptive fusion of multi-level semantic information. A Multi-scale Asymmetric Correlation Module (MACM) employs windows of various sizes to capture asymmetric correlations between unaligned multi-modal data, enhancing cross-modal complementary information extraction even when data are not perfectly aligned. We conduct extensive experiments on unaligned, weakly aligned and aligned RGBT SOD datasets, with results demonstrating that our method outperforms state-of-the-art algorithms, achieving superior accuracy and robustness in both unaligned and weakly aligned RGBT SOD scenarios.},
  archive      = {J_EAAI},
  author       = {Chengmei Han and Lei Liu and Kunpeng Wang and Fei Xie and Bing Wei},
  doi          = {10.1016/j.engappai.2025.112394},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112394},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical semantics guided multi-scale correlation network for alignment-free red-green-blue and thermal salient object detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear dynamic modeling of turbojet engines using combined convolutional and long short-term memory networks. <em>EAAI</em>, <em>162</em>, 112393. (<a href='https://doi.org/10.1016/j.engappai.2025.112393'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Turbojet engines are widely used in small-scale aerial vehicles, but their nonlinear and time-varying dynamics present significant challenges for accurate modeling and control. Traditional system identification methods often struggle to capture these complex behaviors, particularly under limited data conditions. This study proposes a novel hybrid neural network architecture that combines convolutional neural networks and long short-term memory units. The model is specifically designed for small-sample scenarios, enabling robust learning and precise engine speed prediction from real input-output sequences. The input vector comprises the current engine speed, the next-step pulse-width modulation command, and its increment, enhancing the model’s responsiveness and reducing phase-lag effects. The proposed model is trained and evaluated on a real-world dataset containing 38,257 samples, with 80 % used for training and 20 % for testing. Its predictive performance is assessed using step input responses and three evaluation metrics: mean absolute error, root mean square error, and Pearson correlation coefficient. Experimental results demonstrate that the proposed hybrid architecture outperforms other recurrent models in capturing transient dynamics and accurately reproducing real engine behavior. These findings highlight the model’s effectiveness in modeling nonlinear engine dynamics and its potential as a data-efficient alternative to traditional identification techniques for small-scale turbojet applications.},
  archive      = {J_EAAI},
  author       = {Chen Lei and Dong Wei and Su Hang and Chi Yutian and Tian Congling and Gao Yongzhuo and Wu Dongmei and Dong Hui},
  doi          = {10.1016/j.engappai.2025.112393},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112393},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Nonlinear dynamic modeling of turbojet engines using combined convolutional and long short-term memory networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scientific machine learning for generic compact model parameter extraction of nanoscale transistors. <em>EAAI</em>, <em>162</em>, 112392. (<a href='https://doi.org/10.1016/j.engappai.2025.112392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a framework to automate modelcard extraction of industry-standard compact models. This framework presents a Scientific Machine Learning (ScML) approach capable of inverse modeling. It integrates a random forest model with an artificial neural network to produce efficient and precise regression results. This new method is used for parameter extraction in the standard compact models of the semiconductor device industry. Modeling of a multi-gate Field Effective Transistor (FET) with an industry-standard compact model like Berkeley Short-channel Insulated-Gate Field-Effect Transistor Model – Common Multi-Gate (BSIM-CMG) is taken as an example to illustrate and describe the framework and highlight its key advantages. Proposed framework is useful in numerous aspects; it holds vital principles of physics, avoids depending on massive datasets, and has a sparse architecture while avoiding accuracy trade-offs. The framework is tested on production-level experimental devices to evaluate the real-world performance. This framework significantly reduces the time and cost of parameter extraction for the Process Design Kits (PDKs) development. Therefore, this is of immediate importance for fabrication and Electronic Design Automation (EDA) industries.},
  archive      = {J_EAAI},
  author       = {Kumar Sheelvardhan and Surila Guglani and Abhilash Dubey and Shashank Dubey and Sindhu Ramaswamy and Vaidy Subramanian and Kassandra Anderson and Glenn Workman and Sourajeet Roy and Avirup Dasgupta},
  doi          = {10.1016/j.engappai.2025.112392},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112392},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Scientific machine learning for generic compact model parameter extraction of nanoscale transistors},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed graph neural network for 3D spatiotemporal structural response modeling of flexible pavements. <em>EAAI</em>, <em>162</em>, 112391. (<a href='https://doi.org/10.1016/j.engappai.2025.112391'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantifying pavement damage is crucial for roadway agencies' maintenance planning. This study proposed a Physics-informed Graph Neural Network-based Pavement Simulator (PhyGPS) to predict three-dimensional (3D) asphalt concrete pavement responses, building upon an established data-driven Graph Neural Network-based Pavement Simulator (GPS) model. The key innovation lies in integrating knowledge graphs and mechanics equations to create a physics loss function, distinguishing it from its data-driven counterpart. The physics loss function comprises strain-displacement and stress loss components derived from 3D strain-displacement relations and stress equilibrium principles. A thorough 3D finite element (FE) pavement database supported the model development. The 3D FE pavement data was transformed into graph format where nodes and edges represent 3D FE pavement models’ nodes and node connections, respectively. Performance evaluation employed two case studies: “OneStep” for assessing short-term predictive capabilities and “Rollout” for examining long-term prediction accuracy under practical conditions. Results demonstrated that the physics-informed GPS model showed superior long-term predictive capability and robustness while maintaining excellent short-term accuracy compared to the data-driven model. Both models achieve rollout time under 8 s per FE simulation case, a dramatic improvement over the 12-h runtime of traditional 3D FE pavement models. The PhyGPS model successfully integrates physics principles, spatial relationships between structural components, temporal correlations in structural data, and complex material properties, offering an accurate, robust, and computationally efficient solution for predicting 3D pavement responses.},
  archive      = {J_EAAI},
  author       = {Fangyu Liu and Imad L. Al-Qadi},
  doi          = {10.1016/j.engappai.2025.112391},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112391},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed graph neural network for 3D spatiotemporal structural response modeling of flexible pavements},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Health state estimation of retired batteries based on physical constraints. <em>EAAI</em>, <em>162</em>, 112390. (<a href='https://doi.org/10.1016/j.engappai.2025.112390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing use of retired lithium-ion batteries, accurately monitoring their health status has become increasingly important. This study proposed a method to estimate the health of retired batteries by embedding their capacity degradation characteristics directly into the loss function of a Bidirectional Long Short-Term Memory (BiLSTM) network, combined with a Physically Informed Neural Network (PINN) model. The model is developed by incorporating the dynamics of the solid electrolyte interface (SEI) membrane, which evolves as the lithium-ion poles of the retired battery move. By combining these dynamics with the governing equations of motion, a partial differential equation (PDE) is derived. This approach integrates physical constraints, data-driven learning, and PDEs into a composite loss function. The proposed method is validated on two different datasets under varying operating temperatures. The results show that the PINN-BiLSTM model achieves a Root Mean Square Percentage Error (RMSPE) of 0.024, representing a 9.67 % improvement over the PINN-LSTM. This adaptive PINN method offers highly accurate health state predictions across temperature variations, thus supporting the sustainable use of retired batteries in secondary applications and helping to mitigate energy scarcity.},
  archive      = {J_EAAI},
  author       = {Fei Xia and Qianwen Dong and Lin Xia and Zhenyi An and Ziyang Xia and Chunyang Gong},
  doi          = {10.1016/j.engappai.2025.112390},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112390},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Health state estimation of retired batteries based on physical constraints},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive cybersecurity in bio-medical modules: A dynamic programming neural network-based protection for markov-chain fabricated data attacks. <em>EAAI</em>, <em>162</em>, 112389. (<a href='https://doi.org/10.1016/j.engappai.2025.112389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advances in communication technologies, remote monitoring and control of drug delivery are becoming prevalent in bio-medical engineering. In a chemotherapy system, the measurement signals can be wirelessly transferred to the control center by communication networks. Nevertheless, the avenues of communication might be jeopardized by false data injection (FDI), which poses significant risks to the security and stability of biomedical systems. In this work, a defense mechanism is developed to tackle the effect of FDI threats in the networked chemotherapy system. In particular, the effect of FDI attacks on the chemotherapy system is modeled by the Markov chain process. The proposed defense mechanism is designed in two parts: i ) a data-driven sliding mode observer (DDSMO) is utilized to identify the occurrence of cyber attacks in the tumor signals measured by the bio-sensor, and ii ) a mitigation scheme based on a dynamic rejection compensator (DRC) to compensate for the impact of cyber threats. In the mitigation phase, a goal representation heuristic dynamic programming (GrHDP) is adopted to adaptively adjust the parameters of DRC and to dynamically handle the cyber threats. The designed mitigation mechanism not only regulates the cancerous cells against cyber threats but also minimizes the side effects of drug delivery by regulating the output of normal cell and immune cell. Compared to prevalent methodologies, the proposed approach yields significant performance, including a 60.23 % improvement over the without protection, 37.48 % over the DDSMO-based model predictive controller (MPC), 35.95 % over the reinforcement learning (RL) based Kalman filter, and 70.44 % over the proportional integral (PI) based Kalman filter.},
  archive      = {J_EAAI},
  author       = {Mostafa Taheri and Juliang Yin and Zahra Rasooli Berardehi},
  doi          = {10.1016/j.engappai.2025.112389},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112389},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive cybersecurity in bio-medical modules: A dynamic programming neural network-based protection for markov-chain fabricated data attacks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted multi-source domain unsupervised adaptive network for rotating machinery fault diagnosis based on dual adversarial. <em>EAAI</em>, <em>162</em>, 112386. (<a href='https://doi.org/10.1016/j.engappai.2025.112386'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-domain adaptive methods are becoming a growing focus of fault diagnosis, which can provide enhanced data support for models using the feature information from various source domains. As a most commonly used method, unsupervised multi-domain adaptive methods (UMA) can eliminate the requirement for the label of the target domain samples. However, the neglect of contributions from different source domains to the target domain and insufficient utilization of diagnostic information from multiple source domains are the widely limitation of UMA. Therefore, a dual-adversarial weighted multi-source domain unsupervised adaptive network (DAWMUN) is proposed to utilize diagnostic information from multi-source domains and consider the contribution of different source domains. Firstly, the shared feature extractor and dual adversarial training with the domain adversarial modules between multi-source domains and source-target domains are used to enhance domain confusion between multi-source and target domains (MSTD). Secondly, based on Multiple Kernel Maximum Mean Discrepancy (MK-MMD), a novel weighting mechanism and the corresponding training framework are constructed to effectively reduce negative transfer. Finally, a novel weighted classifier is proposed to merge the outputs of multiple classifiers and synthesize the impact of each source domain. The performance of the DAWMUN is validated using a rotating machinery dataset across various transfer tasks under different rotational speed and load conditions. The experimental results demonstrate that the diagnostic accuracy using the proposed DAWMUN is superior to existing SSDA and MSDA methods, with the average accuracies of 98.53 % and 98.23 % across six tasks in two separate experimental setups. The comparison to the existing methods results that the DAWMUN still demonstrates superior performance with improvements of 2.54 % and 2.86 %, respectively.},
  archive      = {J_EAAI},
  author       = {Wenqi Wang and Zongzhen Zhang and Jinrui Wang and Baokun Han and Huaiqian Bao and Zhikang Fan and Rongkang Ge},
  doi          = {10.1016/j.engappai.2025.112386},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112386},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Weighted multi-source domain unsupervised adaptive network for rotating machinery fault diagnosis based on dual adversarial},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Twin-stream network: Enhancing wave prediction by capturing spatiotemporal information. <em>EAAI</em>, <em>162</em>, 112385. (<a href='https://doi.org/10.1016/j.engappai.2025.112385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wave prediction is a critical challenge in ocean and coastal engineering, particularly for understanding and mitigating the effects of sea waves on structures such as ships, offshore platforms, and coastal defenses. A novel machine learning model, Twin-Stream Network (TSNet), is proposed to enhance wave prediction accuracy by leveraging temporal and spatial dependencies in historical data. The TSNet model along with other baseline models are evaluated, in both single-point and multi-point forecasting tasks, by various performance metrics across different datasets including one-dimensional-linear, one-dimensional-nonlinear, two-dimensional-linear and two-dimensional-nonlinear water waves. The comprehensive comparative analysis demonstrates that the TSNet model outperforms others, especially in the multi-point forecasting task. This study provides a valuable insight into the effectiveness of machine learning approaches and highlights the potential of the accuracy improvement for wave prediction.},
  archive      = {J_EAAI},
  author       = {Junhao Xu and Zhongying Feng and Zhan Wang and Kun Zheng and Ruipeng Li},
  doi          = {10.1016/j.engappai.2025.112385},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112385},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Twin-stream network: Enhancing wave prediction by capturing spatiotemporal information},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clean-sample guided cross-modal retrieval with adaptive weighted contrastive learning. <em>EAAI</em>, <em>162</em>, 112383. (<a href='https://doi.org/10.1016/j.engappai.2025.112383'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal retrieval enables efficient integration of information by linking different data modalities, such as images and text. As data volumes increase rapidly, the need for effective cross-modal interaction grows. Cross-modal hashing is favored for its low storage requirements and fast retrieval speed, but many existing methods depend on accurately labeled data, which can be subjective and expensive to obtain. To address this limitation, we propose Clean-guided Adaptive Weighted Contrastive Hashing (CAWCH), a novel framework designed to improve robustness against noisy labels. CAWCH incorporates two main components: a Gaussian Mixture Model (GMM)-based noise purifier that identifies reliable and noisy samples by modeling sample loss, and a contrastive learning strategy that selectively chooses positive samples and adaptively assigns weights based on multi-label similarity, considering both intra- and inter-modal relationships. Extensive experiments demonstrate that CAWCH significantly outperforms existing methods under noisy label conditions, highlighting its effectiveness and potential for real-world cross-modal retrieval applications.},
  archive      = {J_EAAI},
  author       = {Shuni Jiang and Zhixin Li},
  doi          = {10.1016/j.engappai.2025.112383},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112383},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Clean-sample guided cross-modal retrieval with adaptive weighted contrastive learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Denoising of the magnetic flux leakage signal using dynamic feature fusion and a multi-scale autoencoder network. <em>EAAI</em>, <em>162</em>, 112382. (<a href='https://doi.org/10.1016/j.engappai.2025.112382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic flux leakage (MFL) signal denoising is essential for the nondestructive inspection of oil and gas pipelines, where complex noise interference can severely degrade defect quantification accuracy. Traditional approaches such as mean filtering and wavelet transform offer limited suppression of multi-type mixed noise and often distort critical features, including defect peaks and valleys. Even deep learning–based MFL denoising methods struggle in scenarios with substantial signal-noise overlap due to inadequate feature extraction and limited adaptability.This work presents an advanced denoising framework that combines dynamic feature fusion with a multi-scale autoencoder network. The framework jointly exploits time- and frequency-domain signal components, employing an adaptive weighting mechanism for dynamic feature fusion. Parallel convolutional branches extract multi-scale features, improving the capture of both global structures and fine-grained details, while a Squeeze-and-Excitation (SE) channel attention mechanism enhances defect-sensitive features and suppresses noise. Extensive experiments demonstrate that the proposed model outperforms mean filtering, wavelet denoising, and a baseline autoencoder, achieving notable gains in signal-to-noise ratio (SNR), mean squared error (MSE), and signal similarity. Beyond superior noise suppression, the method preserves critical defect characteristics, providing a robust and reliable foundation for precise defect quantification in pipeline MFL inspection.},
  archive      = {J_EAAI},
  author       = {Lushuai Xu and Shaohua Dong and Haotian Wei and Feng Li and Pengkun Zhang and Cong Zuo and Mingxing Guo and Penghui Liao},
  doi          = {10.1016/j.engappai.2025.112382},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112382},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Denoising of the magnetic flux leakage signal using dynamic feature fusion and a multi-scale autoencoder network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optimisation approach guided by crack variation mechanism in the informer prediction model. <em>EAAI</em>, <em>162</em>, 112381. (<a href='https://doi.org/10.1016/j.engappai.2025.112381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural health monitoring (SHM) faces a fundamental challenge in reconciling predictive performance with physical interpretability for infrastructure diagnostics. Conventional deep learning (DL) approaches neglect essential mechanisms governing crack width variation—including thermal gradients, hysteretic responses, and phase-shifted correlations—limiting their reliability in real-world applications. To bridge this gap, we propose a mechanism-guided optimization (MGO) framework that integrates domain knowledge into the Informer architecture through physics-informed enhancements: auto-correlation modeling for capturing temperature-crack hysteresis, static gated fusion for multi-feature integration, and adaptive elastic net regularization for feature selection. Validated on cable-stayed bridge monitoring data, our framework achieves significant mean absolute error reductions (MAE) (5 %–60 %) and root mean square error reductions (RMSE) (10 %–55 %) versus baseline Informer across all cracks and prediction horizons, with diebold-mariano (DM) tests confirming statistical superiority in most cases. Crucially, it demonstrates superior precision relative to six state-of-the-art benchmarks across all evaluation scenarios. The ordinary least squares (OLS)-enhanced variant further delivers volatility reduction, while sensor failure tests establish quantifiable robustness benchmarks through MAE progression from 0.013 mm to 0.391 mm. This work establishes an interpretable, physics-grounded paradigm that explicitly links environmental drivers to structural degradation.},
  archive      = {J_EAAI},
  author       = {Xujia Liu and Youliang Ding and Fei Xu and Yichao Xu and Kang Yang},
  doi          = {10.1016/j.engappai.2025.112381},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112381},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An optimisation approach guided by crack variation mechanism in the informer prediction model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight segmentation model based on segment anything model for tongue image segmentation. <em>EAAI</em>, <em>162</em>, 112379. (<a href='https://doi.org/10.1016/j.engappai.2025.112379'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tongue image segmentation plays a crucial role in intelligent of diagnosis of Traditional Chinese Medicine. Accurate, efficient, and lightweight tongue segmentation significantly improves both the quality and practical applicability of intelligent disease diagnosis models. To address this challenge, we propose TongueSAM_Lite, a lightweight and fully automated tongue image segmentation model. Based on the Segment Anything Model. Our approach employs knowledge distillation and parameter-efficient fine-tuning to develop a novel lightweight image encoder, high-parameter modules in the Vision Transformer are partially replaced with lightweight image modules, which facilitate the transfer of its feature extraction capabilities while accelerating inference speed and reducing computational resource requirements. Additionally, to eliminate manual annotation of tongue region bounding boxes, we integrate a YOLOX-based automatic Box-prompt generator, enabling end-to-end fully automated prompting and segmentation of tongue images. To validate our approach, various experiments were conducted in three datasets. The results show that compared to the original large-scale model of the Segment Anything Model, TongueSAM_Lite reduces the size of the model by 42.7% and shortens the inference time to 45.43% while retaining the near-complete segmentation accuracy of few-shot learning. TongueSAM_Lite achieves Mean Intersection over Union scores of 96.48%, 98.36%, and 97.53% in the three datasets, respectively, outperforming state-of-the-art segmentation methods. Further validation confirms that the YOLOX-based prompt encoder yields optimal performance for the generation of tongue image bounding boxes. Our proposed approach provides new research insights to advance tongue diagnosis technology of Traditional Chinese Medicine. All codes in this article are available at https://github.com/ruanqunsheng/TongueSAM_Lite .},
  archive      = {J_EAAI},
  author       = {Qunsheng Ruan and Shan Cao and Zhirong Luo},
  doi          = {10.1016/j.engappai.2025.112379},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112379},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight segmentation model based on segment anything model for tongue image segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring cross-branch information for semi-supervised remote sensing object detection. <em>EAAI</em>, <em>162</em>, 112378. (<a href='https://doi.org/10.1016/j.engappai.2025.112378'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised object detection (SSOD) provides a promising solution to mitigate the annotation costs in remote sensing applications. Mainstream teacher-student based SSOD methods leverage unlabeled images through pseudo labeling, and their effectiveness is fundamentally limited by the inevitable noise in pseudo labels, particularly for remote sensing (RS) scenarios with complex backgrounds and dense, multi-scale and oriented objects. Current methods primarily focus on reducing pseudo label noise through category, scale and Intersection over Union information mining, as well as designing fine-grained confidence thresholding strategies. However, the inherent discrepancy between classification and localization reliability is neglected. In this study, with analyzing the characteristic discrepancies between the classification and localization branches, We propose artificial intelligence (AI) methodological innovation method named cross-branch information incorporation method (i.e., CBI-SSOD) to utilize these discrepancies to assist the training of the classification branch, and thus improve the performance of SSOD methods. Specifically, our method present two key AI innovations. Firstly, we propose a pretext task to extract cross-branch information, which can improve the classification ability by reinforce the consistent predictions between the classification branch and the pretext task. Besides, we propose a pseudo label reassignment approach to adjust the soft classification pseudo labels, and thus suppress pseudo label noise and improve the detection performance. Extensive experiments on Dataset for Object Detection in Aerial Images (DOTAv1.0) and DOTAv1.5 datasets validate the effectiveness and superiority of our method, and demonstrate the practical engineering impact of our method on RS applications and interpretation systems.},
  archive      = {J_EAAI},
  author       = {Shitian He and Huanxin Zou and Yingqian Wang and Xu Cao and Hao Chen and Ning Jing},
  doi          = {10.1016/j.engappai.2025.112378},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112378},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Exploring cross-branch information for semi-supervised remote sensing object detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightning risk assessment of offshore wind farms considering tropical cyclone impacts based on an improved gradient boosting algorithm. <em>EAAI</em>, <em>162</em>, 112376. (<a href='https://doi.org/10.1016/j.engappai.2025.112376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, global climate warming has led to a significant increase in both the frequency and intensity of tropical cyclones (TCs). The development of TCs is often accompanied by frequent lightning activities. The risk of lightning strikes to high offshore wind turbines is substantially elevated. This study evaluates the lightning risk faced by offshore wind farms influenced by tropical cyclones. Firstly, TC paths are analyzed in both spatial and temporal dimensions by linking them with lightning data to examine the distribution of TC-related lightning, and the lightning strike characteristics of offshore wind turbines are investigated. Secondly, a Bayesian Optimization (BO)-based eXtreme Gradient Boosting (XGBoost) model for lightning risk assessment is proposed, incorporating characteristics of TC lightning and offshore wind farms as input variables. The proposed BO-XGBoost model outperforms XGBoost, Bidirectional Long Short-Term Memory (Bi-LSTM), Support Vector Machine (SVM) and Neural Network (NN), achieving a precision of 98.9 % and a recall of 98.9 % on the test set. Additionally, SHapley Additive exPlanations (SHAP) value analysis indicates that TC lightning characteristics and offshore wind farm characteristics significantly impact the model output, enhancing the accuracy of the model. The assessment outcomes provide a theoretical basis for future offshore wind farm planning and guidance for lightning protection measures in offshore wind farms.},
  archive      = {J_EAAI},
  author       = {Qibin Zhou and Kehan Chen and Xiaoyan Bian and Shangjie Chen and Gaopeng Lu},
  doi          = {10.1016/j.engappai.2025.112376},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112376},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightning risk assessment of offshore wind farms considering tropical cyclone impacts based on an improved gradient boosting algorithm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond trial-and-error: Predicting user abandonment after a moderation intervention. <em>EAAI</em>, <em>162</em>, 112375. (<a href='https://doi.org/10.1016/j.engappai.2025.112375'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current content moderation follows a reactive, trial-and-error approach, where interventions are applied and their effects are only measured post-hoc. In contrast, we introduce a proactive, predictive approach that enables moderators to anticipate the impact of their actions before implementation. We propose and tackle the new task of predicting user abandonment following a moderation intervention. We study the reactions of 16,540 users to a massive ban of online communities on Reddit, training a set of binary classifiers to identify those users who would abandon the platform after the intervention—a problem of great practical relevance. We leverage a dataset of 13.8 million posts to compute a large and diverse set of 142 features, which convey information about the activity, toxicity, relations, and writing style of the users. We obtain promising results, with the best-performing model achieving micro F1-score = 0 . 914 . Our model shows robust generalizability when applied to users from previously unseen communities. Furthermore, we identify activity features as the most informative predictors, followed by relational and toxicity features, while writing style features exhibit limited utility. Theoretically, our results demonstrate the feasibility of adopting a predictive machine learning approach to estimate the effects of moderation interventions. Practically, this work marks a fundamental shift from reactive to predictive moderation, equipping platform administrators with intelligent tools to strategically plan interventions, minimize unintended consequences, and optimize user engagement.},
  archive      = {J_EAAI},
  author       = {Benedetta Tessa and Lorenzo Cima and Amaury Trujillo and Marco Avvenuti and Stefano Cresci},
  doi          = {10.1016/j.engappai.2025.112375},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112375},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Beyond trial-and-error: Predicting user abandonment after a moderation intervention},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A sampling interval-adaptive transformer for industrial time sequence modeling with heterogeneou s sampling rates in quality prediction. <em>EAAI</em>, <em>162</em>, 112374. (<a href='https://doi.org/10.1016/j.engappai.2025.112374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The industrial data sequences frequently exhibit irregular sampling frequencies, which pose a number of difficulties for data analysis and modeling. The traditional dynamic models like Recurrent Neural Network (RNN) and Transformer are difficult to model such data sequences. The main reason is that these models assume that data sampling frequency should be constant. To this end, a Sampling Interval-Adaptive Transformer (SIA-Trans) is proposed in this paper to adaptively model the temporal information for heterogeneous sampling sequences in industrial processes. The SIA-Trans uses the sampling interval and position embedding block to address the problem of unequal time intervals and rectify the temporal correlations in time series. Then, the interval-aware self-attention net is designed for dynamic data relationship modeling, taking the processed data through the self-attention mechanism. Finally, the predicted output is obtained after the point-wise feed-forward layer. The proposed SIA-Trans is validated on a real-world hydrocracking process to predict the content of hydrocarbon mixture with five carbon atoms (C5) hydrocarbons in light naphtha, as well as the final boiling point of jet fuel.},
  archive      = {J_EAAI},
  author       = {Zijian Xu and Nuo Xu and Kai Wang and Xiaofeng Yuan and Yalin Wang and Chunhua Yang and Weihua Gui and Shuqiao Cheng and Lingjian Ye},
  doi          = {10.1016/j.engappai.2025.112374},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112374},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A sampling interval-adaptive transformer for industrial time sequence modeling with heterogeneou s sampling rates in quality prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modality complementary learning network with cross-modality interaction and adaptive fusion for face forgery detection. <em>EAAI</em>, <em>162</em>, 112373. (<a href='https://doi.org/10.1016/j.engappai.2025.112373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of face forgery technology, many forged faces threaten information security. Although existing face forgery detection methods obtain better detection performance on intra-dataset evaluation, the generalization of cross-dataset detection and the robustness against image post-processing operations still need to be improved. To address these issues, we propose a multi-modality complementary learning network with cross-modality interaction and adaptive fusion for face forgery detection. Specifically, a two-branch architecture is designed to extract spatial and frequency features. To realize the interaction and communication of spatial and frequency information, the cross-modality interaction module is designed to explore the inter-modality correlation by applying across self-attention. Subsequently, a multi-scale feature enhancement module is introduced in the spatial branch to enhance the texture and semantic information of spatial features, improving the robustness of tackling image post-processing operations. In addition, to exploit the complementary relationship between the spatial and frequency features, an adaptive fusion module is designed to establish forged feature dependencies by leveraging spatial self-attention, while learning discriminative feature representations by fusing spatial and frequency features in an adaptive weighted manner. Extensive experimental results on four public datasets demonstrate that the proposed method outperforms other state-of-the-art methods for intra-dataset, cross-dataset, and perturbed dataset evaluations.},
  archive      = {J_EAAI},
  author       = {Chunyin Shi and Chengyou Wang and Xiao Zhou and Zhiliang Qin},
  doi          = {10.1016/j.engappai.2025.112373},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112373},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-modality complementary learning network with cross-modality interaction and adaptive fusion for face forgery detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive neural network tracking control for unknown high-order nonlinear systems: A constructive approximation set based approach. <em>EAAI</em>, <em>162</em>, 112371. (<a href='https://doi.org/10.1016/j.engappai.2025.112371'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the problem of adaptive neural network (NN) tracking control for unknown high-order nonlinear systems, with a focus on accurately constructing NN approximation sets. To guarantee the local approximation capabilities of NNs, it is crucial that their input signals remain within corresponding compact sets. However, the unknown functions and powers in high-order nonlinear systems make it difficult to determine these sets accurately. To solve this, we introduce a novel adaptive NN tracking control strategy that integrates signal substitution technique, barrier functions (BFs), and NNs. Specifically, the signal substitution technique converts the original system states into state error variables, along with the desired reference signal and its time derivatives, which serve as part of the NN input. BFs are employed to constrain the state errors, while NNs approximate the transformed unknown system functions. This approach enables precise calculation of bounds for the NN weight estimators, ensuring that the NN approximation sets are constructed. Unlike existing methods, our approach not only proves the existence of NN approximation sets but also provides a constructive design strategy, significantly enhancing the approximation accuracy for unknown nonlinear functions. Simulation results demonstrate the effectiveness and advantages of the proposed method.},
  archive      = {J_EAAI},
  author       = {Yu-Fa Liu and Yong-Hua Liu and Jin-Wa Wu and Jie Tao and Ming Lin and Chun-Yi Su and Renquan Lu},
  doi          = {10.1016/j.engappai.2025.112371},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112371},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive neural network tracking control for unknown high-order nonlinear systems: A constructive approximation set based approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic correlation graph convolution network with embedded temporal correlation extraction for stock price forecasting. <em>EAAI</em>, <em>162</em>, 112370. (<a href='https://doi.org/10.1016/j.engappai.2025.112370'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock price forecasting has become a significant and complex research area within financial technology. The dynamic correlations among stocks and the inherent noise in price volatility present considerable challenges in accurately forecasting stock prices and enhancing investment returns. This paper introduces a novel Dynamic Correlation Graph Convolution Network (DyCGCN) with embedded temporal correlation extraction. First, we propose a dual-scale dynamic graph generation method to capture the topological relationships among stocks. Second, we develop a dynamic correlation-temporal convolution module that extracts high-level temporal correlations. Third, we introduce a prospect theory-guided multi-strategy loss function that accommodates the diverse risk preferences of investors. Furthermore, we present a joint regression-classification learning method to extract and leverage stock trend information. Experiments conducted on four real-world datasets demonstrate the superiority of DyCGCN, achieving an average 24.7% reduction in prediction error and a 10.5% improvement in predictive accuracy over baseline models, underscoring its strong potential for practical stock price forecasting.},
  archive      = {J_EAAI},
  author       = {Fang He and Wei Yin and Yilun Jin and Zhengyang Chen},
  doi          = {10.1016/j.engappai.2025.112370},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112370},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic correlation graph convolution network with embedded temporal correlation extraction for stock price forecasting},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective deployment optimization for integrated sensing and communication-enabled unmanned aerial vehicle swarm. <em>EAAI</em>, <em>162</em>, 112368. (<a href='https://doi.org/10.1016/j.engappai.2025.112368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the convergence of mobile communication, sensing, and computational networks in sixth-generation technology, the integration of sensing and communication with unmanned aerial vehicles (UAVs) is promising. This paper focuses on the contribution of artificial intelligence in optimizing the deployment of UAV swarms for multi-objective target detection applications in sixth-generation networks. Specifically, the artificial intelligence contribution lies in the development of an improved multi-objective particle swarm optimization (IMOPSO) algorithm for solving a complex multi-objective deployment problem. The problem aims to simultaneously optimize communication rate, sensing quality, and energy consumption in the deployment of UAV swarms. To address this, the proposed IMOPSO incorporates chaotic initialization, Lévy flight mutation, dynamic mutation rate, and an elimination mechanism based on opposition-based learning. These innovations are designed to enhance the algorithm’s ability to explore the solution space effectively, overcome premature convergence to local solutions, and improve solution quality. In terms of engineering applications, the IMOPSO is applied to the deployment of UAV swarms for target detection, demonstrating its ability to enhance communication and sensing performance while reducing energy consumption in practical scenarios. Through extensive simulations, we show that the IMOPSO outperforms traditional optimization methods and other baseline algorithms, achieving superior results across all optimization objectives. Specifically, the IMOPSO achieves approximately 5% higher transmission data rate, 9% better sensing quality, and 19% lower energy consumption compared to baseline algorithms across multiple test scenarios. Furthermore, the solutions obtained are not only closer to the optimal front but also more concentrated, indicating higher-quality results.},
  archive      = {J_EAAI},
  author       = {Hongjuan Li and Haiyuan Chen and Miao Wang and Jiahui Li and Hui Kang and Yuzhuo Guan and Xu Lin},
  doi          = {10.1016/j.engappai.2025.112368},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112368},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective deployment optimization for integrated sensing and communication-enabled unmanned aerial vehicle swarm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive semi-supervised learning for specific emitter identification: An iterative clustering and pseudo-label refinement approach. <em>EAAI</em>, <em>162</em>, 112361. (<a href='https://doi.org/10.1016/j.engappai.2025.112361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Specific Emitter Identification (SEI) distinguishes radio-frequency (RF) devices by exploiting hardware-induced signal fingerprints, thereby strengthening wireless-layer security. Existing deep learning-based SEI methods depend heavily on labeled data and fixed confidence thresholds for pseudo-labeling, which limits their effectiveness under label scarcity or open-set conditions. To overcome these issues, we propose a progressive semi-supervised learning (ProSSL) method for SEI that combines iterative clustering with contrastive learning to generate adaptive pseudo-labels. ProSSL introduces an “uncertain” class and employs a dual-constraint selector—prediction stability and class diversity—to suppress noisy pseudo-labels and ensure robust propagation. Experiments on the public real-world long range(LoRa) RF-fingerprint dataset show that ProSSL gains 2.90%–6.01% absolute accuracy over state-of-the-art baselines, reaching 96.48% accuracy with 90% labels and 59.88% with only 5% labels. While on the public automatic dependent surveillance-broadcast(ADS-B) Top-10 dataset, ProSSL achieves 84.40% accuracy with 5% labeled data and 99.40% accuracy with 90%labeled data, again outperforming all competing methods. Open-set evaluations further demonstrate that overall accuracy rises from 18.81% when only two classes are known to 62.25% when eight classes are known, confirming strong generalization to unseen emitters and validating ProSSL’s robustness and practicality in realistic wireless environments.},
  archive      = {J_EAAI},
  author       = {Yiting Gao and Ke Wang and Hao Huang and Jiao Wang and Jiaxu Liu and Yao Zheng and Jianqing Li},
  doi          = {10.1016/j.engappai.2025.112361},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112361},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Progressive semi-supervised learning for specific emitter identification: An iterative clustering and pseudo-label refinement approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing scene text image super-resolution via gradient-based graph attention network. <em>EAAI</em>, <em>162</em>, 112360. (<a href='https://doi.org/10.1016/j.engappai.2025.112360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene text image super-resolution is crucial for enhancing text recognition in low-resolution real-world images. Existing methods usually overlook the structured and repetitive layout of text, which can serve as powerful prior knowledge for guiding reconstruction. In this work, we propose a novel framework that incorporates gradient-based graph attention to explicitly model patch-level text layout. The architecture combines a non-local group-wise attention module, a cascaded channel attention module, and a gradient-guided graph attention module to capture both global and local structural dependencies. This design enables more accurate restoration of text contours and layout consistency. Extensive experiments on the benchmark dataset demonstrate that our method achieves superior performance in both image quality and recognition accuracy, outperforming state-of-the-art methods. The code is available at: https://github.com/cvzxy/TSANv2 .},
  archive      = {J_EAAI},
  author       = {Xiangyuan Zhu and Xuchong Liu and Kehua Guo and Wei Zhao},
  doi          = {10.1016/j.engappai.2025.112360},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112360},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing scene text image super-resolution via gradient-based graph attention network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A consistency regularization-based approach integrating anatomical structural relationships and organ category representations for multi-organ segmentation in pigs. <em>EAAI</em>, <em>162</em>, 112359. (<a href='https://doi.org/10.1016/j.engappai.2025.112359'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern biomedical research and livestock management, accurate multi-organ segmentation in pigs is essential for breeding programs. However, current methods face challenges due to low imaging contrast, size disparities, and organ shape variability. Additionally, the manual annotation of computed tomography (CT) scans is labor-intensive and costly, limiting available labeled samples. To address these issues, we propose a consistency regularization-based network guided by anatomical structural relationships and global organ category representations, specifically designed for multi-organ segmentation using a limited number of annotated CT scan samples from pigs. Specifically, we designed the SpatialLink Gated Recurrent Unit (GRU) module to extract anatomical structural information and capture dynamic spatial relationships between organs, thereby minimizing segmentation biases caused by organ shape variations. Moreover, we developed the Organ Category Coding module and Guidance module, which integrate consistency regularization and attention mechanisms, enabling the network to accurately extract global organ category representations during the decoding phase, even with a small number of labeled samples, significantly improving segmentation consistency across organs of different sizes. Additionally, We are the first to apply the Visual State Space block to multi-organ segmentation in pigs, using it to extract contextual information. Experiments on 60 pigs demonstrate that our method achieves state-of-the-art results, with significant improvements in segmentation accuracy for the gallbladder and bladder, including a 9.8% and 4.2% Dice score increase, respectively, and a 12.4% and 6.2% boost in Jaccard scores compared to compared with a selection of published methods.},
  archive      = {J_EAAI},
  author       = {Xiang Pan and Hang Fan and Jianlan Wang and Yan Fu and Wei Chu and Weipeng Tai and Jing Gu and Jianming Ni},
  doi          = {10.1016/j.engappai.2025.112359},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112359},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A consistency regularization-based approach integrating anatomical structural relationships and organ category representations for multi-organ segmentation in pigs},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable chest X-ray localization using principal component-based feature selection in deep learning. <em>EAAI</em>, <em>162</em>, 112358. (<a href='https://doi.org/10.1016/j.engappai.2025.112358'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification and localization of diseases in chest X-ray (CXR) images are crucial for early diagnosis and timely medical intervention. Traditional localization techniques like Class Activation Mapping (CAM), depend on Global Average Pooling (GAP) layers, restricting their flexibility, while gradient-based methods like Grad-CAM involve computational overhead and limited interpretability. To address these limitations, this study introduces a novel Principal Component Analysis (PCA)-based localization method that eliminates reliance on GAP layers and gradient computations. Utilizing publicly available Kaggle datasets, namely the COVID-19 Radiography Dataset and Tuberculosis (TB) Chest X-ray Database. The proposed approach employs PCA to compress high-dimensional convolutional feature maps extracted from the pretrained VGG16 model into a lower-dimensional, spatially meaningful representation. This enables rapid, interpretable heatmap generation highlighting precise abnormal regions. Experimental results demonstrate that the proposed method achieved an average training loss of 0 . 0835 ± 0 . 1830 and validation loss of 0 . 1385 ± 0 . 0741 across 5-fold cross-validation. In addition, it achieved an impressive accuracy of 97.5%, sensitivity of 98.2%, specificity of 99.4%, a Dice Similarity Coefficient (DSC) of 97.5%, and an Intersection-over-Union (IoU) of 95.1%. Compared to CAM, and Grad-CAM, PCA-based localization significantly reduces inference time, enhances interpretability, and provides robust multi-class localization performance suitable for clinical deployment.},
  archive      = {J_EAAI},
  author       = {Diwakar Diwakar and Deepa Raj},
  doi          = {10.1016/j.engappai.2025.112358},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112358},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interpretable chest X-ray localization using principal component-based feature selection in deep learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast simulation for scattering muography applications using generative adversarial neural networks. <em>EAAI</em>, <em>162</em>, 112357. (<a href='https://doi.org/10.1016/j.engappai.2025.112357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Muography is an emergent non-destructive testing technique that uses cosmic muons to probe the interior of objects and structures. This technique can be employed to perform preventive maintenance of critical equipment in the industry in order to test the structural integrity of the facility. Several muography imaging algorithms based on machine learning methods are being developed in the recent years. These algorithms make exhaustive use of simulated data, usually using packages such as GEANT4 (GEometry ANd Tracking), that exhaustively simulate the detector, to produce training samples. This work presents a faster alternative for the generation of simulated samples based on generative adversarial neural networks. A speed up factor of 80 is observed with this system without any significant degradation of the quality of the simulation.},
  archive      = {J_EAAI},
  author       = {Rubén López Ruiz and Celia Fernández Madrazo and Sergio Sánchez Cruz and Lara Lloret Iglesias and Pablo Martínez Ruiz del Árbol},
  doi          = {10.1016/j.engappai.2025.112357},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112357},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fast simulation for scattering muography applications using generative adversarial neural networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on lightweight network for real-time detection of steel structure corrosion based on knowledge distillation. <em>EAAI</em>, <em>162</em>, 112356. (<a href='https://doi.org/10.1016/j.engappai.2025.112356'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regular and real-time monitoring of corrosion is crucial for ensuring structural safety and extending the service life of infrastructure. With the continuous development of advanced structural health monitoring technologies, intelligent corrosion detection has become an inevitable trend. This study addresses the issues of low accuracy, incomplete detail processing, and missed or false detections in complex scenarios in steel structure corrosion detection, as well as the challenges of high complexity and insufficient real-time performance in deep learning models. We propose a high-performance, lightweight, real-time corrosion detection model, Real-Time Detection Transformer for Corrosion (RT-DETR-Corrosion), based on knowledge distillation. By incorporating lightweight optimization on the RT-DETR-R18 baseline model and a hybrid knowledge distillation approach, the model significantly improves real-time performance and detection accuracy, meeting the application requirements for efficiency and precision in steel structure corrosion detection. Experimental results show that the model exhibits excellent optimization effects in terms of localization accuracy, classification accuracy, and position regression error on both the training and validation sets, while also demonstrating strong generalization ability. In extreme weather conditions (such as rain, fog, snow, and strong light) and complex scenarios (such as occlusion, blur, and low-light environments), the model maintains stable Precision, Recall, and mAP metrics, validating its reliability and applicability in diverse real-world engineering environments. Moreover, visualized heatmap analysis of detection results for different scenarios further confirms the model's precise attention to corrosion regions and its generalization ability, providing essential technical support for steel structure corrosion risk assessment and intelligent monitoring, with significant potential for engineering applications.},
  archive      = {J_EAAI},
  author       = {Jia Hou and Wei Chen and Zhen Duan and Hang Li and Mingyu Yu},
  doi          = {10.1016/j.engappai.2025.112356},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112356},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Research on lightweight network for real-time detection of steel structure corrosion based on knowledge distillation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Function structures of information measures for n-polygonal interval-valued intuitionistic fuzzy sets and their application in location selection strategy. <em>EAAI</em>, <em>162</em>, 112355. (<a href='https://doi.org/10.1016/j.engappai.2025.112355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interval-valued intuitionistic fuzzy set (IVIFS) represents an organic integration of interval-valued fuzzy sets and intuitionistic fuzzy sets, but it fails to meet the requirements of linearity and closure in arithmetic operations, rendering its computations relatively intricate. Consequently, this paper employs an interval partitioning strategy to mitigate the complexity of arithmetic operations, thereby constructing a novel fuzzy set structure characterized by efficient piecewise linear approximation capabilities. Furthermore, the paper presents the structural form of arithmetic operations for the IVIFS with piecewise linear approximation and demonstrates the simplicity of these operations by an numerical example. In addition, we extend the findings on information measures for polygonal interval-valued intuitionistic fuzzy set pertaining to abstract functions that fulfill particular criteria. Furthermore, we delve into the transformation relationships among these information measures, from which a range of structural formats for information measures can be deduced based on functional expressions and transformation relationships. Finally, similarity measures are applied to company site selection. The validity, practicality and stability of proposed measures have been proven through sensitivity analysis and comparative analysis.},
  archive      = {J_EAAI},
  author       = {Le Fu and Chunfeng Suo},
  doi          = {10.1016/j.engappai.2025.112355},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112355},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Function structures of information measures for n-polygonal interval-valued intuitionistic fuzzy sets and their application in location selection strategy},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-dimensional refined composite multi-scale revised ensemble dispersion entropy and its application to fault diagnosis of rolling bearing. <em>EAAI</em>, <em>162</em>, 112354. (<a href='https://doi.org/10.1016/j.engappai.2025.112354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-dimensional ensemble dispersion entropy (EDE 1D ) can effectively characterize the nonlinear dynamic characteristics of one-dimensional time series, but the complexity of two-dimensional space is not reflected, and only single-scale features can be captured. Firstly, to comprehensively capture the feature information of two-dimensional space, the symmetrized dot pattern (SDP) is introduced to overcome the shortcomings of the ordinary images lack of physical meaning and the time-frequency distribution methods exhibit incomplete information representation, etc. Simultaneously, the amplitude and frequency information are intuitively expressed by a two-dimensional mirror snowflake symmetrized image (MSSI 2D ). Secondly, to overcome the shortcomings of single-scale and traditional coarse-graining, a two-dimensional refined composite multi-scale coarse-graining method is proposed, which improves the accuracy of feature extraction and reduces the calculation deviation. After that, a new feature extraction method namely two-dimensional refined composite multi-scale revised ensemble dispersion entropy (RCMREDE 2D ) is proposed, whose parameter stability and performance are explored through simulation analysis. The results demonstrate that the RCMREDE 2D exhibits excellent stability and anti-noise interference ability. Based on the advantages of RCMREDE 2D , a novel fault diagnosis method for rolling bearings is developed by integrating RCMREDE 2D and a firefly algorithm optimized support vector machine (FA-SVM) multi-fault classifier for pattern recognition. The proposed method is further validated through two measured bearing data sets and five comparative methods, and the results indicate that the RCMREDE 2D and FA-SVM achieve the highest recognition accuracy while demonstrating superior stability.},
  archive      = {J_EAAI},
  author       = {Wenqing Ding and Jinde Zheng and Haiyang Pan and Jian Cheng and Jinyu Tong},
  doi          = {10.1016/j.engappai.2025.112354},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112354},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Two-dimensional refined composite multi-scale revised ensemble dispersion entropy and its application to fault diagnosis of rolling bearing},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse and robust elastic net support vector machine with bounded concave loss for large-scale problems. <em>EAAI</em>, <em>162</em>, 112352. (<a href='https://doi.org/10.1016/j.engappai.2025.112352'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The elastic net support vector machine is an extensively employed method for addressing a range of classification tasks. Nevertheless, a significant drawback of the elastic net support vector machine is its high computational cost when dealing with large-scale classification problems. To address this drawback, we first introduce an innovative non-convex elastic net support vector machine model that employs our newly created bounded concave loss function, which effectively attains both sparsity and robustness. Based on proximal stationary point, we have effectively constructed an innovative optimality theory tailored for our newly created elastic net support vector machine model. By leveraging the innovative optimality theory, we have successfully developed a new and exceptionally effective algorithm designed to enhance computational efficiency through the division of the entire dataset into two distinct categories: working sets and non-working sets. During each learning cycle, the parameters associated with the non-working set remain unchanged. In contrast, the parameters related to the working set are subject to updates. Consequently, our new algorithm facilitates quicker modifications on smaller datasets, improving runtime efficiency and lowering computational complexity. Numerical experiments have demonstrated significant efficiency, particularly regarding computational speed, the number of support vectors, and classification accuracy, surpassing eleven other leading solvers.},
  archive      = {J_EAAI},
  author       = {Huajun Wang and Wenqian Li},
  doi          = {10.1016/j.engappai.2025.112352},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112352},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sparse and robust elastic net support vector machine with bounded concave loss for large-scale problems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review of speaker verification: Methods, network architectures, tasks and challenges. <em>EAAI</em>, <em>162</em>, 112351. (<a href='https://doi.org/10.1016/j.engappai.2025.112351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speaker verification is an important branch of biometric recognition, with wide applications in identity authentication, audio monitoring, and other fields. In recent years, deep learning and meta-learning have made remarkable advancements in the field of speaker verification. Therefore, it is necessary to update existing reviews of speaker verification to reflect the latest research developments. We review literature from the past decade to provide a timely and comprehensive survey of the field. First, we outline the concept and system process of speaker verification. Then, we analyze the speech preprocessing process and common acoustic features used in the systems. Next, we present an overview of speaker modeling approaches, covering traditional probabilistic methods, deep learning-based speaker methods, and meta-learning-based speaker methods, focusing on the latter two methods. We provide an in-depth analysis and summary of the characteristics and the latest network architectures of these methods, focusing on the development of Transformer and large-scale pre-trained Transformer. Furthermore, we introduce the datasets and evaluation metrics used in speaker verification systems, focusing on a detailed and fair comparison of the performance of text-dependent and text-independent speaker verification systems. Finally, we explore the challenges faced by speaker verification systems and discuss future research opportunities.},
  archive      = {J_EAAI},
  author       = {Weijie Wang and Hong Zhao and Yikun Yang and Yongjuan Yang},
  doi          = {10.1016/j.engappai.2025.112351},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112351},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A review of speaker verification: Methods, network architectures, tasks and challenges},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-cost and sparsity for continual semantic segmentation. <em>EAAI</em>, <em>162</em>, 112350. (<a href='https://doi.org/10.1016/j.engappai.2025.112350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have contributed to significant progress in semantic segmentation tasks. However, deep neural networks exhibit a critical drop in performance due to catastrophic forgetting when they are required to learn new tasks incrementally. The more plastic the network is, the easier it can learn new tasks. Whereas, for continual semantic segmentation, it is more reliable to preserve the knowledge it has learned from previous tasks. Here, gated 0-1 Bernoulli variable is used as a regularization method to optimize performance by enhancing network sparsity. Then, the special case of gated 0-1 Bernoulli variable is applied in the replay-based method of continual semantic segmentation. Specifically, when the value of the sub-network sampling rate reaches 0.5, the network reaches the strongest stability. Finally, the gated 0-1 Bernoulli variable improves the network’s performance in complex scenarios and reduces cost under similar performance. Experimental results indicate that in using 100% samples for incremental training, the Mean Intersection over Union(mIoU) of the old classes improves by up to 4.6% and 5.5% compared to the baseline at the end of the overall training in continual semantic segmentation scenarios 10-1 and 10-2. Furthermore, in using 60% samples for incremental training, the performance for the old tasks only drops by less than a percentage, while the time cost to complete the full setup decreases by 22%.},
  archive      = {J_EAAI},
  author       = {Qing Ji and Bin Li and Shaobo Li and Hongchao An and Jing Yang},
  doi          = {10.1016/j.engappai.2025.112350},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112350},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Low-cost and sparsity for continual semantic segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Promoting sustainability-oriented brand activist campaigns: A spherical fuzzy decision support framework for evaluating activist advertising videos. <em>EAAI</em>, <em>162</em>, 112349. (<a href='https://doi.org/10.1016/j.engappai.2025.112349'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Activist video advertisements represent a strategic form of brand communication in which companies express their stance on social or environmental issues through emotionally driven storytelling and slogan-based narratives. Despite their growing prevalence, there is a notable lack of systematic and quantitative methods for evaluating their performance or comparing their effectiveness across competing brands. This research addresses that gap by proposing a comprehensive decision support system (DSS) designed to assess the performance of activist video advertisements in a structured and reproducible manner. The study introduces a novel hybrid multi-criteria decision-making (MCDM) framework: the spherical cubic fuzzy (SCF)–Aczel-Alsina–ranking comparison (RANCOM)–method based on the removal effects of criteria (MEREC)–deviation-based pairwise assessment ratio technique (DEPART). This methodology integrates subjective weights obtained via SCF–RANCOM and objective weights derived through SCF–MEREC, with both sets of weights combined using SCF-based aggregation operators that incorporate Aczel-Alsina t-norm and t-conorm functions. Performance rankings are then generated using the SCF–DEPART method. To demonstrate the model's applicability, a real-world case study involving eight sustainability-oriented activist video advertisements released in Türkiye was conducted. Evaluations were based on input from ten domain experts across eleven criteria. The analysis identified “convincingness and credibility” as the most critical factor, with “The Voice of Nature” campaign achieving the highest performance rating. The model's robustness was confirmed through scenario-based sensitivity analyses, and its consistency was validated by benchmarking against thirteen alternative MCDM approaches. The findings offer meaningful implications for both academic research and advertising practice.},
  archive      = {J_EAAI},
  author       = {Galip Cihan Yalçın and Karahan Kara and Gülcan Işık and Esra Serdar Tekeli and Vladimir Simic and Abdullah Ballı and Dragan Pamucar},
  doi          = {10.1016/j.engappai.2025.112349},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112349},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Promoting sustainability-oriented brand activist campaigns: A spherical fuzzy decision support framework for evaluating activist advertising videos},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated clustering with mutual knowledge distillation for traffic flow prediction. <em>EAAI</em>, <em>162</em>, 112347. (<a href='https://doi.org/10.1016/j.engappai.2025.112347'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction plays a critical role in intelligent transportation systems. Conventional traffic flow prediction methods primarily rely on centralized training, which poses a risk of privacy leakage. Federated learning, a privacy-preserving framework to machine learning, enables distributed participants to jointly train a shared model without sharing local private data. However, traffic flow is typically collected from different devices and contains different temporal patterns, leading to non-independent and identically distributed. To address these challenges, we propose a traffic flow prediction method based on federated clustering with mutual knowledge distillation. We first perform temporal decomposition on the traffic flow data and use mutual learning with adaptive distillation loss to facilitate mutual knowledge transfer among local models during training. Then, we apply spectral clustering to cluster clients based on the cosine similarity of model parameters at the server and design a global model aggregation method to improve the performance of federated learning. Finally, the proposed method is evaluated on two real-world traffic datasets, and the experiment results show significant improvements over traditional federated learning approaches and also outperform federated mutual learning. The results demonstrate that the proposed method effectively captures temporal information and mitigates the effect of non-independent and identically distributed issues.},
  archive      = {J_EAAI},
  author       = {Yao Lin and Shengwu Xiong},
  doi          = {10.1016/j.engappai.2025.112347},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112347},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Federated clustering with mutual knowledge distillation for traffic flow prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantifying hybrid failure mode in cyclic-loaded reinforced concrete shear walls: Integrating unsupervised and supervised learning techniques. <em>EAAI</em>, <em>162</em>, 112346. (<a href='https://doi.org/10.1016/j.engappai.2025.112346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to identify failure types in Reinforced Concrete Shear Walls (RCSWs) by quantifying the contributions of shear and flexural modes in the force-deformation response of the walls. The supporting research database includes images, cyclic curve backbones, and geometric and mechanical characteristics of 253 RCSWs. Initially, the database is manually classified into shear, flexure, and shear-flexure failure modes based on observations of surface damage and the cyclic response of the wall. Subsequently, unsupervised clustering and supervised learning algorithms are employed to probabilistically quantify and predict the participation of flexural and shear modes in the overall seismic response of the walls, respectively. The unsupervised model, utilizing the K-means algorithm, identifies the primary failure modes of the walls, achieving over 90 % concordance with manual expert labeling. Based on the results of unsupervised clustering, a hybridity index is proposed to demonstrate the contributions of shear and flexure failure modes to the overall seismic response. Supervised learning is then used to predict hybridity indices from wall characteristics, with the Extremely Randomized Trees (Extra Trees) model achieving the best results based on a balanced evaluation of multiple performance metrics. SHapley Additive exPlanations (SHAP), a tool for exploring model sensitivity, highlights the aspect ratio as the key influencing factor on failure mode, in accordance with relevant structural engineering codes and standards. Implementation of the proposed framework in exploring the behaviors of four unseen case studies reveals a significant correlation between the predicted hybridity indices and observed damage, consistent with existing guidelines.},
  archive      = {J_EAAI},
  author       = {Pouya Ebrahimi and Amir Hossein Asjodi and Kiarash M. Dolatshahi},
  doi          = {10.1016/j.engappai.2025.112346},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112346},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Quantifying hybrid failure mode in cyclic-loaded reinforced concrete shear walls: Integrating unsupervised and supervised learning techniques},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-path multiple attention-guided feature interaction network for camouflaged object detection. <em>EAAI</em>, <em>162</em>, 112345. (<a href='https://doi.org/10.1016/j.engappai.2025.112345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing Camouflaged Object Detection (COD) methods rely on features from a pre-trained backbone with a single-encoder structure, leading to initial features biased towards global or local preferences. This affects subsequent feature modeling and degrades COD performance. Some studies use modular or auxiliary flow structures to balance feature preferences but often focus only on interactions between hierarchical features or information flows, ignoring potential redundancy or noise within aggregated features. Therefore, we propose a novel dual-path multiple attention-guided feature interaction network (DMAFI-Net) for COD, which contains four main components: global and local features interaction module (GLFI), intra-feature interaction module (IFI), multi-scale feature enhancement module (MFE), and two decoders including neighbor connection decoder based feature aggregation (NFA) and refine decoder. Specifically, the GLFI is designed to implement the interaction and combination of global and local features, and the combined features will be sent to IFI to mine intra-feature information. Besides, the MFE is introduced to further enrich the extracted features obtained in the IFI. In the feature decoding stage, the NFA module utilizes neighbor connection decoder to fuse multi-scale features and ultimately generates a coarse prediction. Finally, the refine decoder leverages multiple attention modules to refine the initial prediction with the combined features as auxiliary cues and obtain the final camouflaged map. Extensive experiments on four COD benchmark datasets demonstrate the superiority of the proposed framework when compared to 24 state-of-the-art (SOTA) methods in terms of five widely used evaluation metrics. Furthermore, the ablation studies show the effectiveness of main components of our DMAFI-Net.},
  archive      = {J_EAAI},
  author       = {Anzhi Wang and Jintao Wu and Shuang Zhao and Yun Liu},
  doi          = {10.1016/j.engappai.2025.112345},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112345},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual-path multiple attention-guided feature interaction network for camouflaged object detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TFCTL: Time–Frequency calibrated transfer learning for cross domain depression detection. <em>EAAI</em>, <em>162</em>, 112344. (<a href='https://doi.org/10.1016/j.engappai.2025.112344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the application of speech-based depression detection systems expands, differences in cross-domain data distribution pose significant challenges. This paper proposes the framework of Time–Frequency Calibrated Transfer Learning (TFCTL). This framework first introduces Frequency-Delay Neural Network (FDNN), inspired by Time-Delay Neural Network (TDNN), extending the concept of temporal feature extraction using sliding windows and weight sharing from the time domain to the frequency domain. A multi-level information aggregation module then integrates features of varying abstraction levels from both time-delay and frequency-delay neural networks, balancing global and local speech information. Finally, TFCTL uses transfer learning to calibrate the distribution of the aggregated time–frequency embedding vectors, uncovering commonalities of depression features across different domains. Cross-speaker and cross-corpus experiments were conducted using the Chinese Multimodal Depression Corpus (CMDC) and the Distress Analysis Interview Corpus Wizard-of-Oz (DAIC-WOZ). In cross-speaker scenarios, TFCTL achieved F1 scores of 0.7324 on DAIC and 0.9660 on CMDC, outperforming other methods. In cross-corpus scenarios, TFCTL achieved F1 scores of 0.6743 on DAIC and 0.6879 on CMDC, demonstrating its robustness in addressing domain mismatch issues. The source code used in the paper is available at https://anonymous.4open.science/r/TFCTL-A545/ .},
  archive      = {J_EAAI},
  author       = {Dongdong Li and Li Ding and Zuo Yang and Zhe Wang and Ke Zhao},
  doi          = {10.1016/j.engappai.2025.112344},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112344},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TFCTL: Time–Frequency calibrated transfer learning for cross domain depression detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mutual information guided invertible image hiding network. <em>EAAI</em>, <em>162</em>, 112343. (<a href='https://doi.org/10.1016/j.engappai.2025.112343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image hiding techniques are commonly used for secure communication, copyright protection, and visual privacy. Invertible neural network (INN) have emerged as a promising approach for image steganography, enabling the concealment and recovery of secret images through forward and backward mappings within the network. However, existing methods often face limitations in the accuracy of recovered images due to challenges in estimating the lost information during the forward process. To address this issue, we propose a Mutual Information Guided Invertible Image Hiding Network (MIGIIHNet), which leverages mutual information estimation between the lost information and the stego image in the forward process to guide the backward mapping for reconstruction. Specifically, we propose a lightweight INN with a channel attention feature aggregation module (CAFAM), integrating a channel attention mechanism to optimize the multi-scale aggregation of both low-level and high-level features in a single forward pass. Also, an association learning module (ALM) is designed to model the mutual information between the stego image and the lost information during the forward hiding process. Then, the mutual information is utilized to reconstruct the secret image with high accuracy. Extensive experimental results show that MIGIIHNet outperforms existing state-of-the-art methods in terms of invisibility, security, and recovery accuracy, while maintaining low computational complexity.},
  archive      = {J_EAAI},
  author       = {Kehan Zhang and Fen Xiao and Jingwen Cai and Xieping Gao},
  doi          = {10.1016/j.engappai.2025.112343},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112343},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mutual information guided invertible image hiding network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-tailed detection and classification of wafer defects from scanning electron microscope images robust to diverse image backgrounds and defect scales. <em>EAAI</em>, <em>162</em>, 112342. (<a href='https://doi.org/10.1016/j.engappai.2025.112342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In semiconductor engineering, high yield of wafers relies on accurate detection and classification of wafer defects. The dataset for detecting wafer defects presents three primary challenges: (i) different background types, (ii) variable image or defect scales, and (iii) imbalanced data with a long-tailed distribution of defect types. These challenges create significant limitations for traditional classification techniques. To address these issues, we propose a stratified framework called Wafer Detection and Classification (WaferDC), designed specifically for detecting and classifying wafer defects from scanning electron microscope (SEM) images. Our framework achieves high defect detection performance on SEM wafer images by utilizing a multi-cluster memory bank, which effectively handles the challenges of (i) variable background types and (ii) differing image or defect scales. Building on this robust detection, we propose Segmentation and Mix (SegMix), a novel defect augmentation technique based on anomaly heatmaps, which enhances the reliability of defect detection and classification in a (iii) long-tailed imbalanced environment. Finally, we pass defect-classified images through a parameter-efficient fine-tuning (PEFT)-based classifier (Shiet al., 2023) utilizing a vision transformer (ViT) architecture, further improving overall defect detection and classification performance. We rigorously tested WaferDC on a proprietary SEM wafer dataset and the public Describable Textures Dataset-Synthetic (DTD-Synthetic) and Magnetic Tile Defect (MTD) datasets. The results confirm the effectiveness of our method in improving defect detection and classification in wafer manufacturing. Our code is available at https://github.com/SpatialAILab/WaferDC .},
  archive      = {J_EAAI},
  author       = {Taekyeong Park and Yongho Son and Sanghyuk Moon and Seungju Han and Je Hyeong Hong},
  doi          = {10.1016/j.engappai.2025.112342},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112342},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Long-tailed detection and classification of wafer defects from scanning electron microscope images robust to diverse image backgrounds and defect scales},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast trajectory planner with a reinforcement learning-based controller for robotic manipulators. <em>EAAI</em>, <em>162</em>, 112341. (<a href='https://doi.org/10.1016/j.engappai.2025.112341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating obstacle-free trajectories for robotic manipulators in unstructured and cluttered environments remains a significant challenge. Existing motion planning methods often require additional computational effort to generate the final trajectory by solving kinematic or dynamic equations. This paper highlights the strong potential of model-free reinforcement learning methods over model-based approaches for obstacle-free trajectory planning in joint space. We propose a fast trajectory planning system for manipulators that combines vision-based path planning in task space with reinforcement learning-based obstacle avoidance in joint space. We divide the framework into two key components. The first introduces an innovative vision-based trajectory planner in task space, leveraging the large-scale fast segment anything (FSA) model in conjunction with basis spline (B-spline)-optimized kinodynamic path searching. The second component enhances the proximal policy optimization (PPO) algorithm by integrating action ensembles (AE) and policy feedback (PF), which greatly improve precision and stability in goal-reaching and obstacle avoidance within joint space. These proximal policy optimization (PPO) enhancements increase the algorithm’s adaptability across diverse robotic tasks, ensuring consistent execution of commands from the first component by the manipulator, while also enhancing both obstacle avoidance efficiency and reaching accuracy. The experimental results demonstrated the effectiveness of proximal policy optimization (PPO) enhancements, as well as simulation-to-simulation (Sim-to-Sim) and simulation-to-reality (Sim-to-Real) transfer, in improving model robustness and planner efficiency in complex scenarios. These enhancements allowed the robot to perform obstacle avoidance and real-time trajectory planning in obstructed environments. https://sites.google.com/view/ftp4rm/home},
  archive      = {J_EAAI},
  author       = {Yongliang Wang and Hamidreza Kasaei},
  doi          = {10.1016/j.engappai.2025.112341},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112341},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fast trajectory planner with a reinforcement learning-based controller for robotic manipulators},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bi-level location-routing problem with time windows for mixed-load recycling of heterogeneous batteries: A transformer-based improved deep reinforcement learning algorithm. <em>EAAI</em>, <em>162</em>, 112340. (<a href='https://doi.org/10.1016/j.engappai.2025.112340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the urgency, timeliness and uncertainty of power batteries recycling, we extend a novel network model for retired battery recycling systems, bi-level capacitated location-routing problem with time windows for heterogeneous battery mixed-load (CLRPTW-HBM). Firstly, the expected interval and linear weighting methods are used to transform and process the lower-level multi-objective function that contains fuzzy variables. Secondly, a Transformer-based improved deep reinforcement learning algorithm (Transformer-IDRL) is proposed. (1) The bi-level CLRPTW-HBM is modeled as Markov decision process, and a policy network model with dual-layer encoder-decoder structure is designed based on Transformer architecture. (2) Randomly generate instance data, and the asynchronous advantage Actor-Critic with adaptive dynamic parameter tuning strategy is employed for training. (3) The action sampling strategy based on roulette reverse selection mechanism, and local search strategy incorporating problem characteristics are introduced to improve solution quality. Finally, extensive experiments are conducted on benchmark datasets and actual cases, and the results demonstrate superior performance of Transformer-IDRL, with an average Gap of 0.22 % and 0.19 %, a 5.30 % reduction in recycling cost, and a 6.06 % reduction in battery exposure risk. These satisfactory results highlight the feasibility and efficiency of the proposed model and method. Additionally, sensitivity analysis of model parameters shows that under different decision-maker preferences and vehicle loading capacity, the sensitivity range of path cost is [5.77 %, 39.85 %] and [16.04 %, 35.54 %], while that of exposure risk is [1.40 %, 3.39 %] and [1.35 %, 5.54 %], indicating that parameter variations significant influence the layout of recycling network and overall path cost. Therefore, decision-makers should flexibly adjust key parameters to balance economic benefits and sustainable development in battery recycling.},
  archive      = {J_EAAI},
  author       = {Mengna Zhao and Shiping Chen},
  doi          = {10.1016/j.engappai.2025.112340},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112340},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Bi-level location-routing problem with time windows for mixed-load recycling of heterogeneous batteries: A transformer-based improved deep reinforcement learning algorithm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Instantaneous power prediction for industrial robots using tree-based machine learning methods. <em>EAAI</em>, <em>162</em>, 112339. (<a href='https://doi.org/10.1016/j.engappai.2025.112339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a tree-based machine learning methodology for instantaneous power prediction designed, tested and validated using data from an articulated industrial robot. The proposed methodology for instantaneous power prediction materializes through a generic system architecture with functionalities consisting of data acquisition, time alignment of data samples, storage, model learning, instantaneous power prediction and integration in time to evaluate energy consumption at robot operation level. This methodology is designed to evaluate offsite energy consumption of robotized workstations for different layouts characterized by relative position of the robot with respect to the serviced and fly-by points. This is important both for offline virtual commissioning of robotized workstations (determine layout) and for online operation for maintenance purposes (determine energy spikes different from normal model). The analyzed operation is the linear motion of the robot Tool Control Point in Cartesian space, characterized by the complexity of the kinematic model: each joint operates in coordinated motion, adjusting its velocity and acceleration continuously to ensure a straight path with constant speed. A custom Internet of things (IoT) device enables synchronized energy and motion data logging for robots, ensuring consistent values for sampled trajectories. Justification for the usage of tree-based methods and experimental results are provided.},
  archive      = {J_EAAI},
  author       = {Ionuţ Lenţoiu and Silviu Răileanu and Theodor Borangiu and Mihnea Constantinescu and Octavian Morariu},
  doi          = {10.1016/j.engappai.2025.112339},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112339},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Instantaneous power prediction for industrial robots using tree-based machine learning methods},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward sustainable wastewater treatment: Transformer ensembles and multitask learning for energy consumption and quality management. <em>EAAI</em>, <em>162</em>, 112338. (<a href='https://doi.org/10.1016/j.engappai.2025.112338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wastewater treatment plants (WWTPs) are among the most energy-intensive components of urban infrastructure and bear strict regulatory responsibilities for wastewater quality. These dual challenges, minimizing energy consumption and maintaining environmental compliance, are deeply interrelated and must be managed simultaneously to achieve sustainable plant operation. This study proposes a framework that comprises two customized components. The first component employs a voting ensemble model based on transformer architecture to predict energy consumption. It processes heterogeneous feature domains — including hydraulic, wastewater, and climatic variables — through parallel attention-driven streams. The outputs from these streams are then aggregated using a weighted voting mechanism to produce the final prediction. Second, a multitask Bidirectional Gated Recurrent Unit (Bi-GRU) forecasts wastewater quality indicators concurrently (ammonia, Biochemical Oxygen Demand (BOD), and Chemical Oxygen Demand (COD)), capturing shared temporal dependencies and reducing model complexity. A hybrid preprocessing strategy is applied, incorporating domain-aware outlier detection (z-score and Interquartile Range (IQR)), K-Nearest Neighbors (KNN) Imputation, and feature selection using Extreme Gradient Boosting (XGBoost). Experimental results showed that. The voting ensemble model achieved the best results for energy consumption prediction with 31.61 of Root Mean Squared Error (RMSE). The multitask Bi-GRU achieved the best results for wastewater quality indicators with RMSE at 6.1689, 48.0323, and 88.2214 for ammonia, BOD, and COD, respectively. This work is among the first to integrate transformer ensembles and multitask learning in a unified WWTP forecasting system. Simultaneously addressing energy efficiency and water quality assurance, this offers a practical, scalable, and intelligent decision-support tool for sustainable wastewater management.},
  archive      = {J_EAAI},
  author       = {Hager Saleh and Sherif Mostafa and Shaker El-Sappagh and Abdulaziz AlMohimeed and Michael McCann and Saeed Hamood Alsamhi and Niall O’Brolchain and John G. Breslin and Marwa E. Saleh},
  doi          = {10.1016/j.engappai.2025.112338},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112338},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Toward sustainable wastewater treatment: Transformer ensembles and multitask learning for energy consumption and quality management},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complete information extraction for monocular depth estimation using a dual framework. <em>EAAI</em>, <em>162</em>, 112337. (<a href='https://doi.org/10.1016/j.engappai.2025.112337'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to address the problem of efficient extraction of complete multi-scale information for supervised monocular depth estimation. Most of the existing depth estimation methods are based on Convolutional Neural Network (CNN). By gradually exploring the contextual and semantic features, they have achieved good results in scene depth estimation. However, with the expansion of the receptive field, global information limited by the local induction bias is gradually suppressed, resulting in the performance cannot be further improved. Recently, Transformer-based methods have been widely used to model the global correlation between features. Nevertheless, since the Transformer networks are not spatially aware enough, they usually lose local details and have no clear mechanism for reusing features when processing images. The Transformer networks perform self-attention mechanism at each location and cannot directly obtain information from other locations for features. Therefore, we propose a novel dual framework called as Transformer-CNN, which includes the Transformer-branch and the CNN-branch for monocular depth estimation. Specifically, the Transformer-branch is able to model the global contextual information and the CNN-branch can capture local spatial relationships in images. However, simply fusing these two independent branches may result in insufficient feature aggregation. To this end, we design a Parallel Feature Interaction Module (PFIM), which contains a Self-Attention Module (SAM) and a Cross-Attention Module (CAM), so as to highlight features from the Transformer-branch and the CNN-branch respectively and extract complementary information between the two branches. Meanwhile, in order to make full use of the low-level features with low quality in the scene, we propose a Low-level Information Acquisition Module (LIAM) to capture texture-related information and preserve texture details in the CNN-branch. Finally, to address the lack of multi-scale contextual information in Vision Transformer (ViT), we introduce a Wide Area Multi-scale Decoder (WAMD), which incorporates the multi-scale feature representations into the decoder part via a Wide Area Attention (WAA). Extensive experiments on benchmark datasets collected in the outdoor and indoor environments demonstrate the competitive results of the proposed method, compared with the state-of-the-art monocular depth estimation methods.},
  archive      = {J_EAAI},
  author       = {Bin Li and Dazheng Zhou and Xianjie Gao and Mingliang Zhang},
  doi          = {10.1016/j.engappai.2025.112337},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112337},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Complete information extraction for monocular depth estimation using a dual framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards non-visual bowel cancer diagnosis: A certainty-aware data-driven method of lesion characterisation using a vibrating capsule. <em>EAAI</em>, <em>162</em>, 112336. (<a href='https://doi.org/10.1016/j.engappai.2025.112336'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in miniaturised, dynamically actuated robots have opened new pathways for non-visual, in-situ disease diagnosis. This study explores a novel method for early bowel cancer detection using a self-propelled robotic capsule that navigates the bowel and detects lesions based on variations in tissue stiffness. The approach capitalises on the sensitivity of the capsule’s dynamic responses to surrounding tissue properties. A dual-phase machine learning framework is proposed. The first phase uses regression models including multilayer perceptron (MLP), support vector regression (SVR), and Gaussian process regression (GPR) to predict tissue stiffness from displacement signal features. The second phase uses a Gaussian mixture model (GMM) to cluster the predicted stiffness values into different categories. Unlike our previous work, this study emphasises the robustness of the models under varying data conditions using both accuracy and reliability-oriented metrics. Based on our studies, MLP provided the most reliable regression results for simulated data and downstream clustering, though GPR performed better on experimental datasets. SVR consistently underperformed, especially on experimental data. The GMM achieved over 89% clustering accuracy across both simulated and experimental datasets, with improved results when predictions from more accurate regression models are used as the inputs. This work demonstrates a promising step toward dynamic, in-situ lesion characterisation and highlights the potential for integrating lesion biomechanics into future endoscopic diagnosis.},
  archive      = {J_EAAI},
  author       = {Kenneth Omokhagbo Afebu and Yang Liu and Evangelos Papatheou and Shyam Prasad},
  doi          = {10.1016/j.engappai.2025.112336},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112336},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards non-visual bowel cancer diagnosis: A certainty-aware data-driven method of lesion characterisation using a vibrating capsule},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond the horizon: A comprehensive analysis of artificial intelligence-based weather forecasting models. <em>EAAI</em>, <em>162</em>, 112335. (<a href='https://doi.org/10.1016/j.engappai.2025.112335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of Artificial Intelligence (AI)-based weather forecasting is growing rapidly, with continuous progress in model development, techniques, and performance improvements. This paper provides a comprehensive overview of AI-based weather forecasting models, focusing on their current status, challenges, and directions for further development. A review of more than 40 models, primarily proposed after 2015, underscores the importance of critically examining various aspects of AI-based forecasting. Unlike previous reviews that targeted only a limited number of models or features, this study addresses a complete set of aspects and analyzes existing challenges from multiple perspectives. These aspects include the Machine Learning (ML) and Deep Learning (DL) methods used, datasets, predictand parameters, overfitting, and capability for forecasting extreme weather, lead time, spatiotemporal scale, performance criteria, overfitting, data assimilation, data-driven models, and the analysis of state-of-the-art (SOTA) models such as FengWu, ClimaX, Pangu-Weather, FourCastNet, GraphCast, GenCast, and Artificial Intelligence Forecasting System (AIFS) from various viewpoints. The review also discusses current challenges, including limited historical data and data quality, small-scale weather forecasting, model explainability, uncertainty, extreme weather prediction, physical constraints, temporal adaptation, and generalization, and outlines potential future directions.},
  archive      = {J_EAAI},
  author       = {Saeid Haji-Aghajany and Witold Rohm and Piotr Lipinski and Maciej Kryza},
  doi          = {10.1016/j.engappai.2025.112335},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112335},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Beyond the horizon: A comprehensive analysis of artificial intelligence-based weather forecasting models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural model of the adaptive tuned particle impact damper. <em>EAAI</em>, <em>162</em>, 112334. (<a href='https://doi.org/10.1016/j.engappai.2025.112334'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents a novel approach for the modeling of the Adaptive Tuned Particle Impact Damper (ATPID) using Multilayer Perceptron (MLP). The main motivation was the recognition that such an approach can support the development of novel neural modeling and the optimal determination of damper parameters in terms of mechanical vibration attenuation. The training data were obtained using a theoretical model validated experimentally. The optimally selected MLP was compared with other regression models using 10 different metrics. A hyperparameter tuning of the determined neural network architecture was conducted based on the input parameters such as excitation amplitude, grain mass, and ATPID damper height. The analyses show that the proposed neural network could quickly and accurately estimate the system’s vibration amplitude and efficiently predict the optimal damper height. The ability to effectively determine the correct optimal height is crucial for ATPID damper control. The high efficiency in predicting the system’s vibration amplitude allows for the replacement of the theoretical model with applied time-consuming contact forces. The MLP accurately estimated vibration amplitudes with 1%–10% error for interpolated data and up to 15% for extrapolated cases. The issue raised is particularly important from the perspective of real-time damper control. It was found that computing a single case using the artificial neural network is more than ten times faster compared to the theoretical model. Therefore, the proposed ATPID damper model based on a neural network forms the basis for further considerations and scientific research to finally propose a control algorithm in the future.},
  archive      = {J_EAAI},
  author       = {Mateusz Żurawski and Karolina Grabska and Robert Zalewski and Adam Kulawik},
  doi          = {10.1016/j.engappai.2025.112334},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112334},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural model of the adaptive tuned particle impact damper},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive hybrid machine reading comprehension framework for multimodal emotion-cause pair extraction in conversations. <em>EAAI</em>, <em>162</em>, 112333. (<a href='https://doi.org/10.1016/j.engappai.2025.112333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal emotion-cause pair extraction in conversations (MECPEC) has gradually evolved into an emerging task aimed at discovering deeper causal relationships between emotions and their corresponding causes in conversational contexts. It has widespread application in fields such as human–computer interaction, social media analysis, customer feedback management, and empathetic companion, among others. However, the challenges posed by the oversimplified multimodal feature fusion mechanism and the failure to account for the relative positional relationship between emotions and causes still hinder the performance of MECPEC. In this study, we propose an adaptive hybrid machine reading comprehension (AHMRC) framework to extract potential emotion-cause pairs inherent in conversations. The MECPEC task is first transformed into a two-round hybrid machine reading comprehension task that sequentially enforces the global emotion query and the local cause query with the goal of exploring the relative position constraint specific to conversations. Subsequently, an adaptive multimodal attention module is designed by incorporating features extracted from text, video, and audio modalities, and adaptively fusing them according to their contributions. Extensive experiments were carried out on the benchmark datasets to demonstrate the effectiveness of the proposed AHMRC framework in comparison to other state-of-the-art methods in the literature.},
  archive      = {J_EAAI},
  author       = {Guorui Li and Xufeng Duan and Cong Wang and Sancheng Peng},
  doi          = {10.1016/j.engappai.2025.112333},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112333},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An adaptive hybrid machine reading comprehension framework for multimodal emotion-cause pair extraction in conversations},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analytical and machine learning approaches for three-dimensional orthotropic functionally graded cylindrical structure in steady heat conduction. <em>EAAI</em>, <em>162</em>, 112332. (<a href='https://doi.org/10.1016/j.engappai.2025.112332'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Theoretical and computational modelling of heat conduction in a functionally graded cylinder has been rigorously investigated in prior studies, owing to its critical significance in high-stakes engineering applications such as nuclear reactor design, aerospace structural systems, and pressure vessel technology. Despite this extensive body of work, the majority of these studies have mostly focused on simplified two-dimensional models, frequently presuming idealized thermal parameters such as isotropic thermal conductivity, constant convection coefficients, and spatially uniform ambient temperatures. These simplifications overlook the crucial role of spatially varying thermal characteristics and three-dimensional (3D) temperature distributions, which are essential for accurately simulating the complex heat conduction behaviors found in real-world engineering. Unlike prior research, this study presents an analytical solution for heat conduction under non-homogeneous generalized Robin boundary conditions, capturing 3D thermal conductivity inhomogeneities along three orthogonal directions using Sturm-Liouville theory and finite integral transforms. However, while such analytical methods are highly accurate for simpler geometries, they often encounter significant challenges when extended to scenarios involving complex material gradients and irregular domains. A gradient-enhanced physics-informed neural network (g-PINN) framework is proposed to tackle these challenges, utilizing neural networks that incorporate physical laws and gradient information to enhance its applicability to complex configurations. This combined approach presents a novel framework that integrates classical theory with machine learning, facilitating precise modelling of thermal phenomena in functionally graded cylinders. The findings indicate that both the analytical and machine learning approaches (g-PINN) align closely with presented solutions, precisely capturing the energy equation and more complex boundary conditions.},
  archive      = {J_EAAI},
  author       = {Palash Das and Md Ashraful Islam and Dipayan Mondal},
  doi          = {10.1016/j.engappai.2025.112332},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112332},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Analytical and machine learning approaches for three-dimensional orthotropic functionally graded cylindrical structure in steady heat conduction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust spurious drug–drug interaction detection via chi-square-guided bidirectional attention mechanism. <em>EAAI</em>, <em>162</em>, 112331. (<a href='https://doi.org/10.1016/j.engappai.2025.112331'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spurious drug–drug interactions arising from experimental biases can compromise treatment safety and hinder effective clinical decision-making for patients. However, current molecular representation learning methods still face significant challenges in addressing this problem. First, most graph neural network-based approaches consider only single-direction interactive semantic extraction between drug molecules, failing to capture more granular relationships between drugs fully. Moreover, during training, they are vulnerable to noise from negative sampling and cannot sufficiently leverage the complete drug–drug interaction annotations, resulting in reduced robustness and accuracy in downstream tasks. To this end, we propose a robust spurious DDI detection framework that employs chi-square-guided bidirectional attention to capture fine-grained and bidirectional interaction patterns. First, considering their mutual information flow, a two-way cross-attention mechanism is introduced for a more granular extraction of cross-drug molecular interaction semantic representations through bidirectionally perceiving interactive features between drugs. Second, on the basis of robust minimum covariance determinant theory, we propose a chi-square distribution-based spurious detection method to approximate the correctly annotated drug–drug interactive feature space to a chi-square distribution for a complete feature representation. Extensive experiments on benchmark datasets further validate our method’s effectiveness over state-of-the-art methods, particularly in noisy interference scenarios. Our code is available at https://github.com/AlexCostra/cd .},
  archive      = {J_EAAI},
  author       = {Wei-Yu Shi and Yi-Jia Zhang and Jin-Zhong Ning},
  doi          = {10.1016/j.engappai.2025.112331},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112331},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust spurious drug–drug interaction detection via chi-square-guided bidirectional attention mechanism},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A domain adaptation method to defend chinese textual adversarial attacks via prompt-tuning. <em>EAAI</em>, <em>162</em>, 112330. (<a href='https://doi.org/10.1016/j.engappai.2025.112330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The textual adversarial attack aims to fool existing models into making erroneous predictions by adding strategic perturbations to normal data without affecting the user’s understanding. Recently, methods based on Pre-trained Language Models (PLMs) and Large Language Models (LLMs) have shown promising performance in various Natural Language Processing (NLP) downstream tasks. However, due to significant deviations between the original and perturbed texts, these methods struggle to achieve satisfactory results in defending against textual adversarial attacks, especially in Chinese, which has unique syntactic structures. To address this issue, we propose a domain adaptation method for defending against Chinese textual adversarial attacks through a prompt-tuning model, which effectively mitigates the discrepancy between different domains. Specifically, the original and perturbed texts are treated as the source and target domains, respectively, with the textual adversarial defense task framed as a cross-domain classification problem. The soft prompt-tuning model trained in the source domain is iteratively adapted to uncover the true label information in the target domain. The graph attention network is incorporated to integrate Chinese syntactic structure information with semantic features. Through a voting mechanism on predicted labels generated by the iterative model, soft prompt-tuning is further optimized for cross-domain classification tasks. Extensive experimental results demonstrate the superior effectiveness of our method in Chinese textual adversarial defense tasks compared to baseline methods, including the state-of-the-art fine-tuning approaches for PLMs and LLMs.},
  archive      = {J_EAAI},
  author       = {Yi Zhu and Zhenglong Li and Yun Li and Yunhao Yuan and Jipeng Qiang},
  doi          = {10.1016/j.engappai.2025.112330},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112330},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A domain adaptation method to defend chinese textual adversarial attacks via prompt-tuning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel high-accuracy graph neural network-based rumor detection method. <em>EAAI</em>, <em>162</em>, 112329. (<a href='https://doi.org/10.1016/j.engappai.2025.112329'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rumors spreading on social media platforms result in potential damages. A precise rumor detection mechanism can help form a healthy public opinion environment. In recent years, deep learning-based rumor detection methods, especially graph model-based ones, have risen and reached promising performance. However, there are several defects in existing methods, which limit models from efficiently utilizing the propagation structure. In this paper, we propose a novel rumor detection model, which has high accuracy and reaches state-of-the-art performance. First, we design a powerful comprehensive rumor feature extractor that explicitly overcomes the restriction of previous Graph Neural Networks-based models. Then, by introducing Kernel Subtree features, our model acquires the capability to learn crucial local features from important nodes. Comparative experiments performed on two real-world social media platforms demonstrate that our work reaches state-of-the-art performance, which outperforms the best baseline with 1.6% and 1.9% in accuracy respectively.},
  archive      = {J_EAAI},
  author       = {Xi Xiao and Zeming Wu and Chengzong Cai and Tian Bian and Guangwu Hu and Qing Li and Cheng Huang},
  doi          = {10.1016/j.engappai.2025.112329},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112329},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel high-accuracy graph neural network-based rumor detection method},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Committee of multi-scale nonlinear learning frameworks for accurate stock price forecasting. <em>EAAI</em>, <em>162</em>, 112325. (<a href='https://doi.org/10.1016/j.engappai.2025.112325'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dependable stock price predictions are vital for optimizing economic policies and investment strategies in both national and corporate settings. However, the intrinsic volatility and intricacy of stock prices pose considerable challenges. Thus, this paper introduces a novel Committee of Multi-scale Nonlinear Learning Frameworks (CoML) that employs a three-stage model: decomposition, reconstruction, and prediction. First, a complete ensemble empirical mode decomposition with adaptive noise is adopted to decompose the original stock prices into multiple intrinsic mode functions. Secondly, a fine-to-coarse algorithm is applied to reconstruct the intrinsic mode functions, so as to effectively extract short-term fluctuations and long-term trends. Finally, an ensemble of nonlinear models including bidirectional long short-term memory (BiLSTM), support vector regression (SVR) and multi-layer perceptron (MLP) is used to learn and forecast features extracted to obtain high performance. Experimental results indicate that the model performs exceptionally well in both emerging and developed markets highlighting the innovative capabilities of CoML in highly complex and volatile financial markets. The proposed model is further validated using Model Confidence Set and the results indicate that the model is statistically significant.},
  archive      = {J_EAAI},
  author       = {Qian He and Yanhui Liang and Yu Lin and Dazhi Pan and Yuying Yue},
  doi          = {10.1016/j.engappai.2025.112325},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112325},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Committee of multi-scale nonlinear learning frameworks for accurate stock price forecasting},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning robust brain tumor segmentation under label corruption and data scarcity. <em>EAAI</em>, <em>162</em>, 112322. (<a href='https://doi.org/10.1016/j.engappai.2025.112322'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models for medical image segmentation often struggle with performance issues when datasets are affected by label noise or annotation errors, commonly introduced during manual process or lack of proficiency. These noisy annotations disrupt the loss function, leading to "partially incorrect" gradients that impair the model's learning and overall performance. Additionally, the limited availability of scanned data for training often makes it challenging to develop a robust model. A common approach to address this issue is to leverage similar large annotated datasets. However, differences in dataset distributions can also lead to inconsistencies, introducing erroneous gradients during training and further impacting model performance. To address these challenges, we propose MGR-DAS (Meta-Gradient Reweighting via Direction-Aware Similarity), a novel meta-learning-based approach that can automatically evaluate the reliability of training samples during training using a small, clean subset easily curated from the noisy dataset. Our method quantifies reliability by measuring the cosine similarity between the gradients of noisy training samples and those of the clean subset. Samples with higher gradient alignment are assigned greater weights during training, effectively reducing the impact of noisy labels and improving model robustness. We evaluate our method using three standard metrics for medical image segmentation: the Dice Similarity Coefficient (DSC), the 95th percentile Hausdorff Distance (HD95), and Intersection over Union (IoU). The proposed MGR-DAS achieved an overall 2.4 % improvement in the DSC on the brain tumor segmentation (BraTS, 2021) dataset. Remarkably, even with only 10 clean annotations used in the reweighting algorithm, our method yielded a 28.7 % gain in DSC. In real-world, data-scarce scenarios, our proposed MGR-DAS also improved the overall DSC score by 2.6 % on BraTS pediatric (BraTS-PEDs) and by 1.0 % on BraTS-Africa, demonstrating strong generalizability and robustness. Experimental results confirm that the proposed method reliably identifies noisy data, prioritizes clean data through adaptive weighting, and outperforms existing fine-tuning, curriculum learning techniques, and other meta-learning frameworks commonly employed in classification tasks.},
  archive      = {J_EAAI},
  author       = {Abdulkhalek Al-Fakih and Abbas Mohamed Rezk and Abdullah Shazly and Kanghyun Ryu and Mohammed A. Al-masni},
  doi          = {10.1016/j.engappai.2025.112322},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112322},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning robust brain tumor segmentation under label corruption and data scarcity},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-shot learning augmented slow feature analysis for semantic-aware industrial process fault detection. <em>EAAI</em>, <em>162</em>, 112321. (<a href='https://doi.org/10.1016/j.engappai.2025.112321'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Slow Feature Analysis (SFA) has shown considerable success in the field of industrial process fault detection. Nonetheless, due to its unsupervised nature, SFA relies solely on the normal training data and overlooks the incorporation of prior process knowledge, which consequently diminishes its efficacy in early fault detection. To mitigate this limitation, this paper introduces the concept of Zero-Shot Learning (ZSL) and proposes an improved SFA approach, referred to as ZSL-SFA. This novel method leverages fault semantic representations as auxiliary knowledge to enhance fault detection sensitivity in industrial process monitoring. The ZSL-SFA framework implements a dual-model collaborative monitoring system: (1) a primary SFA model is developed using normal operational data to capture the dynamic characteristics of the process; and (2) a semantic encoding mechanism, grounded in expert knowledge, is devised to build the auxiliary model, where a probabilistic attribute learner adaptively extracts semantic information from fault attribute descriptions, facilitating effective fault knowledge transfer through similarity analysis. The monitoring outcomes from both the primary and auxiliary models are integrated using a Bayesian fusion strategy, culminating in a comprehensive ZSL-SFA monitoring system. The main advantage of this method is its ability to fully exploit prior process knowledge to enhance the basic SFA model without the need for additional labeled fault samples. Experimental validations on the Tennessee-Eastman process simulation platform are performed to indicate that the proposed ZSL-SFA method surpasses the basic SFA method in terms of fault detection performance.},
  archive      = {J_EAAI},
  author       = {Wenjie Yang and Xiaogang Deng and Lumeng Huang and Yuping Cao},
  doi          = {10.1016/j.engappai.2025.112321},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112321},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Zero-shot learning augmented slow feature analysis for semantic-aware industrial process fault detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale embedding with guided attention for medical image analysis. <em>EAAI</em>, <em>162</em>, 112319. (<a href='https://doi.org/10.1016/j.engappai.2025.112319'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate classification of medical images is pivotal for enhancing diagnostic accuracy and optimizing treatment strategies. Traditional methods encounter challenges in delineating clear inter-class boundaries within high-dimensional feature spaces affected by class overlap. This study introduces a Multi-Scale Embedding with Guided Attention (MSEGA) framework based on deep learning autoencoders that integrates innovative guided attention learning mechanisms without explicit target mask supervision for tumor detection and classification. The framework incorporates Multi-scale Feature Extraction Blocks and Depthwise Separable Convolution Blocks to comprehensively capture image features. Through Channel Attention and Spatial Attention mechanisms, the MSEGA method prioritizes critical tumor regions across scales. We also propose a novel interpretable embedding learning loss function to optimize image embeddings, highlighting crucial regions and refining category distinctions. Empirical evaluations on two brain tumor Magnetic Resonance Imaging (MRI) datasets demonstrate our approach surpasses conventional methods including Convolutional Neural Networks and Vision Transformers in classification accuracy and generalizability. These results underscore the framework’s potential as a versatile artificial intelligence-powered tool in medical image analysis.},
  archive      = {J_EAAI},
  author       = {Zeyan Li and Yifei Peng and Yizun Lin},
  doi          = {10.1016/j.engappai.2025.112319},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112319},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-scale embedding with guided attention for medical image analysis},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodality based deep learning method for cancer-related T-cell receptor sequence prediction. <em>EAAI</em>, <em>162</em>, 112318. (<a href='https://doi.org/10.1016/j.engappai.2025.112318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {T-cell receptor sequences (TCR-seq) are closely related to cancers, and in particular, cancer-related TCR-seq are crucial in cancer diagnosis and treatment. Current prediction methods for cancer-related TCR-seq often focus solely on the sequence structure, neglecting its spatial structure. Therefore, we propose a multimodal deep learning method based on parallel and residual structures (MDPR) for the detection of cancer-related TCR-seq. MDPR can effectively integrate the spatial and sequence structure of TCR-seq for accurately identifying cancer-related sequences. First, we introduce a TCR-seq encoding method based on atomic three-dimensional spatial coordinates, allowing for more effective extraction of the spatial structural features of TCR-seq. Second, we use high-dimensional word vectors instead of the amino acid feature vectors traditionally used by other researchers. Third, we pretrain the spatial feature extraction module and then conduct joint training with the sequence feature extraction module. This approach allows the model to better consider the relationship between the two modalities, thereby improving prediction accuracy. Finally, MDPR achieved an area under the curve (AUC) of 0.971 after ten rounds of three-fold cross-validation on the dataset. The AUC of MDPR is 5% higher than that of the previous best method. In short, we propose an artificial intelligence method called MDPR, and apply it to the biomedical field. MDPR can be obtained from https://github.com/biomg/MDPR .},
  archive      = {J_EAAI},
  author       = {Junjiang Liu and Shusen Zhou and Mujun Zang and Chanjuan Liu and Tong Liu and Qingjun Wang},
  doi          = {10.1016/j.engappai.2025.112318},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112318},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodality based deep learning method for cancer-related T-cell receptor sequence prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A combined perspective self-supervised contrastive learning framework for human activity recognition integrating instance prediction and clustering. <em>EAAI</em>, <em>162</em>, 112317. (<a href='https://doi.org/10.1016/j.engappai.2025.112317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) is a significant application for wearable devices, which primarily identifies current human activities by analyzing sequential sensor data. The real-time data recording of wearable devices enables the collection of vast amount of unlabeled data. Utilizing this data for self-supervised contrastive pre-training of HAR models presents a feasible solution to the decline in recognition performance due to limited labeled data. However, traditional contrastive learning frameworks are primarily designed based on positive and negative sample pairs in the image domain. The relatively simple sequence data of HAR is prone to generating incorrect negative pairs, thus pre-training HAR models solely in this manner is unsatisfactory. Given the phenomena described above, this paper proposes an Instance Prediction and Clustering Self-supervised Contrastive Learning Framework (IPCSC) for HAR, considering the characteristics of human activity data. IPCSC circumvents negative sample pairs, instead extracting contrastive information at the instance perspective by prediction tasks among various augmented views of samples and integrating clustering concepts for contrastive learning from a holistic perspective. The primary objective is to enable the model to discern critical information within human activity data and distinguishable features between different activities, thereby improving the model’s pre-training efficacy and enhancing its downstream activity recognition performance. Numerous experimental analyses demonstrate that IPCSC outperforms other self-supervised methods, achieving an average F1-Score performance improvement of 5.65%, 4.11%, and 7.99% over supervised baselines on the UCI-HAR, MobiAct, and MotionSense datasets, respectively, with only 1% of the labeled data.},
  archive      = {J_EAAI},
  author       = {Zhixuan Yang and Kewen Li and Zongchao Huang and Zhifeng Xu and Xinyuan Zhu and Yuan Xiao},
  doi          = {10.1016/j.engappai.2025.112317},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112317},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A combined perspective self-supervised contrastive learning framework for human activity recognition integrating instance prediction and clustering},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised method for learning path-augmented knowledge graph embedding. <em>EAAI</em>, <em>162</em>, 112315. (<a href='https://doi.org/10.1016/j.engappai.2025.112315'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) consist of factual triples that describe relations between entities in the real world. Knowledge graph embedding (KGE) aims to map entities and relations into constantly low-dimensional vectors, which is important for lots of downstream tasks (e.g., KG completion and information retrieval). Current KGE methods primarily rely on explicit structural patterns, neglecting latent contextual semantics behind those structures and resulting in sub-optimal performance. While some methods incorporate additional data (e.g., textual descriptions), such dependencies limit applicability due to additional data requirements. Furthermore, most KGE models suffer from limited supervision with sparse labeled triples, restricting their capacity to learn comprehensive semantic features. Inspired by the simple but effective self-supervised language model word2vec, one interesting question is: Can KGE be performed as a simple self-supervised language model ? To achieve this, we innovatively propose a self-supervised KGE framework that learns entity and relation embeddings by adapting word2vec’s skip-gram objective to path sequences extracted from KGs. Our framework employs separate embedding spaces for entities and relations with an entity-relation mapping mechanism for effective interaction between the two embedding spaces. Further, to enhance the training efficiency, we introduce a markov chain-based negative sampling strategy, which generates semantically meaningful negative samples by preserving the structural contexts along KG paths. Our framework, which is the first attempt to follow the context-based self-supervised idea of language models to conduct KGE tasks, addresses the constraints of label-dependent supervised KGE techniques and obviates the requirement for external information, while simultaneously enabling effective extraction of the implicit contextual semantics inherent in triple structures. Experiments on two widely-used KGE datasets show state-of-the-art performance, demonstrating our framework’s ability to learn semantically rich representations solely from graph structure.},
  archive      = {J_EAAI},
  author       = {Tong Shen and Fu Zhang and Jingwei Cheng},
  doi          = {10.1016/j.engappai.2025.112315},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112315},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A self-supervised method for learning path-augmented knowledge graph embedding},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A single-cell RNA sequencing data imputation method based on non-negative matrix factorization and multi-kernel similarity network fusion. <em>EAAI</em>, <em>162</em>, 112313. (<a href='https://doi.org/10.1016/j.engappai.2025.112313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence-based single-cell RNA sequencing (scRNA-seq) technology is widely used in cell type identification and disease research, but its data often contain a large number of missing values and zero values due to technical limitations and biological differences. These zero values not only affect downstream analysis, but also make it difficult to distinguish technical zero values from biological zero values. Therefore, this paper proposes a scRNA-seq data interpolation method (sc-MKNMF) based on non-negative matrix factorization and multi-kernel similarity network fusion for the first time. This method improves the accuracy of cell clustering by accurately filling some zero values. First, sc-MKNMF uses gene-cell dual-level analysis to distinguish technical zero values from biological zero values, and then calculates the similarity network of multi-kernel fusion of genes and cells respectively. Then, this method uses non-negative matrix factorization combined with similarity network to construct the objective function, and introduces sparse regularization terms to ensure the similarity between genes and cells and improve stability. In addition, sc-MKNMF is also equipped with an efficient optimization algorithm to promote its convergence by continuously updating the objective function. Finally, the verification and comparative experiments on 12 scRNA-seq datasets show that the sc-MKNMF method outperforms other advanced data interpolation methods. In addition, the extension of sc-MKNMF to the two tasks of cell trajectory inference and differentially expressed gene analysis showed significant improvement and excellent versatility.},
  archive      = {J_EAAI},
  author       = {Pei Liu and Cheng Chen and Hao Liu and Jin Gu and Xinya Chen and Ying Su and Zhiyuan Cheng and Xiaoyi Lv and Chen Chen},
  doi          = {10.1016/j.engappai.2025.112313},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112313},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A single-cell RNA sequencing data imputation method based on non-negative matrix factorization and multi-kernel similarity network fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel object detection model for sugar beet cercospora leaf spot in field scenarios based on large kernel decomposition and spatial channel interaction attention. <em>EAAI</em>, <em>162</em>, 112311. (<a href='https://doi.org/10.1016/j.engappai.2025.112311'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cercospora leaf spot (CLS) is a widespread disease that seriously threatens beet yield and sugar quality. Timely detection enables farmers to take early control measures and reduce economic losses. Although artificial intelligence (AI)-based methods are replacing manual inspection in agriculture, CLS detection in complex field environments remains highly challenging due to subtle early-stage symptoms and severe occlusions caused by overlapping leaves and weeds. To address these challenges, this paper presents Cercospora Leaf Spot–You Only Look Once (CLS–YOLO), an enhanced detection model built upon You Only Look Once version 11 (YOLOv11), incorporating novel modules specifically designed for accurate CLS detection under challenging field conditions. To improve the detection of weak and early-stage symptoms, we design the Multi-Scale Large Kernel Decomposition (MSLKD) module, which enhances feature extraction for subtle lesions. Furthermore, we develop the Spatial-Channel Interaction Attention (SCIA) module to mitigate detection errors arising from occlusion and fragmented disease patterns by refining multi-scale feature representations. Experimental results demonstrate CLS–YOLO achieves superior performance, reaching an mAP@0.5 of 73.6% ± 0.2% and an mAP@0.5:0.95 of 40.6% ± 0.3% over five independent runs, outperforming twelve mainstream object detection algorithms while maintaining lightweight efficiency. To validate generalization capability across scenarios, crops, and diseases, we conducted comparative experiments on two public crop disease datasets, where our method achieved superior overall performance. In summary, this study provides an effective AI-driven solution for precise crop disease detection, contributing to the practical advancement of intelligent agriculture.},
  archive      = {J_EAAI},
  author       = {Hualong Dong and Yi Lu and Yurong Qian and Xuefei Ning and Ting Chen and Ke Tang},
  doi          = {10.1016/j.engappai.2025.112311},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112311},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel object detection model for sugar beet cercospora leaf spot in field scenarios based on large kernel decomposition and spatial channel interaction attention},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ElecBench: A large language model benchmark in electric power domain. <em>EAAI</em>, <em>162</em>, 112310. (<a href='https://doi.org/10.1016/j.engappai.2025.112310'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have made substantial advancements in the field of natural language processing, necessitating the development of new benchmarks to accurately track their progress. In this paper, we introduce ElecBench, the first benchmark specifically designed for the electric power domain. ElecBench comprises 24 datasets spanning different scenarios, covering general electric power knowledge and four specific business applications, with a total of 34,030 data entries. Furthermore, we evaluate the performance of a series of open-source Chinese LLMs on ElecBench. Our experiments demonstrate that ElecBench serves as an effective benchmark for electric power scenarios and highlight that existing LLMs require further optimization to gain domain-specific knowledge and achieve better performance.},
  archive      = {J_EAAI},
  author       = {Sai Zhang and Qiaochu Huang and Qiang Zhang and Xiao Liang and Weiwei Liu and Kunlun Gao and Fei Zhou and Congcong Shi},
  doi          = {10.1016/j.engappai.2025.112310},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112310},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ElecBench: A large language model benchmark in electric power domain},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature-enhanced edge-INverse attention network for skin lesion segmentation. <em>EAAI</em>, <em>162</em>, 112306. (<a href='https://doi.org/10.1016/j.engappai.2025.112306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer, particularly melanoma, is one of the most aggressive and deadly forms of cancer with its incidence rising globally. Early detection is crucial for improving survival rates, but the traditional dermatoscopy method is a highly time-consuming and subjective process. To resolve this issue, we propose a novel Feature-Enhanced Edge-INverse attention network (FEEINnet) model that helps to segment the skin lesion region more accurately. FEEINnet consists of three sub-networks: Feature Enhanced Mechanism (FEM) learns and extracts the fine-grained enhanced features from informative channels, the Edge Attention Mechanism (EAM) helps to precisely identify the edges of the lesion region and the INverse Attention Mechanism (INAM) generates inverse attention maps which emphasize the less confident or ambiguous regions thereby increasing the segmentation accuracy iteratively. These three sub-networks collectively help to improve feature extraction, enhance boundary detection, and refine segmentation maps, even in challenging scenarios with varying lesion sizes, shapes and pigmentation. FEEINnet consistently outperforms existing models, achieving a F1-score of 95.55%, 95.53%, and 94.52%; Intersection over Union (IoU) of 92.76%, 92.43%, and 91.34%; and Structural Similarity Index Measure (SSIM) of 94.63%, 93.51%, and 91.85% on the Human Against Machine 10000 (HAM10000), Pedro Hispano Hospital ( P H 2 ), and International Skin Imaging Collaboration 2018 (ISIC2018) datasets, respectively. The obtained results demonstrate that the proposed model has a greater ability to segment complex skin lesions more accurately.},
  archive      = {J_EAAI},
  author       = {Shivamm Warambhey and Aravindkumar Sekar},
  doi          = {10.1016/j.engappai.2025.112306},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112306},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature-enhanced edge-INverse attention network for skin lesion segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A severity indicator for unsupervised fault severity shift detection of heating, ventilation, and air conditioning sub-system faults using a novel adaptive feature weighing method. <em>EAAI</em>, <em>162</em>, 112305. (<a href='https://doi.org/10.1016/j.engappai.2025.112305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault-free functioning of Heating, Ventilation, and Air Conditioning (HVAC) systems is essential for reducing energy waste in modern-day buildings. Hence, data-driven approaches for HVAC fault detection have gained popularity. Faults become more severe with time. Fault detection reveals the presence of an anomaly, but it does not convey how critical the fault severity is. Fault severity indication provides this essential context, enabling urgent resource allocation to more severe faults, adding practical significance. However, faults being rare, obtaining substantial data at different severity levels to train supervised Machine Learning models is a realistic challenge. Therefore, we propose a method for estimating fault severity in an unsupervised setting. We define a robust Severity Indicator (SI) that reflects the shift in the severity levels of a fault. First, we define a healthy domain boundary for fault-free data using One-Class Support Vector Machines. SI scores are then computed using a novel adaptive feature weighing algorithm that assigns weights to individual features, adaptively, for every fault. We focus on detecting the shift in severity, rather than quantifying it. The study of the robustness of SI for different faults in HVAC subsystems, chillers, and air handling units (AHUs) yields consistently promising results. Our comparative analysis shows that our method outperforms the unweighted approach and existing state-of-the-art techniques for fault severity estimation. Notably, our method excels in detecting low-severity faults, addressing a common limitation in current methods.},
  archive      = {J_EAAI},
  author       = {Ramnath V. Prabhu Bam and Rajesh S. Prabhu Gaonkar and Clint Pazhayidam George},
  doi          = {10.1016/j.engappai.2025.112305},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112305},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A severity indicator for unsupervised fault severity shift detection of heating, ventilation, and air conditioning sub-system faults using a novel adaptive feature weighing method},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient anchor-free model for ore particle size detection. <em>EAAI</em>, <em>162</em>, 112304. (<a href='https://doi.org/10.1016/j.engappai.2025.112304'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate detection of ore size is crucial in mineral processing, directly impacting equipment efficiency and product quality. However, traditional anchor-based models often struggle with the irregular shapes and varying scales of ore particles, resulting in limited performance. To overcome these challenges, an anchor-free detection framework was proposed. It incorporates a cross-stage partial bottleneck and a spatial pyramid pooling cross-stage partial connections (SPPCSCP-DualConv), both enhanced with dual convolution, to improve feature extraction and multi-scale fusion. In the backbone, the dual convolution module combines group convolution with heterogeneous convolution to improve feature diversity. The SPPCSCP-DualConv module further enhances feature representation in complex backgrounds. Additionally, a simplified path aggregation network (simPANet) feature fusion module is employed in the neck to refine the integration of multi-scale features. The proposed model was trained using a combination of binary cross-entropy, complete intersection over union (IoU), and distribution focal loss to optimize detection accuracy. The proposed model achieved a mean average precision of 86.80 % at an IoU threshold of .5 and 78.50 % across IoU thresholds from .5 to .95, surpassing existing methods while maintaining a lightweight architecture with only 10.10 million parameters and 89.45 giga floating point operations per second. Ablation studies confirmed the effectiveness of the simPANet and SPPCSPC-DualConv modules in enhancing feature representation. Generalization tests across mining sites with similar distributions demonstrated strong performance, although limitations remain for exceptionally large ore blocks due to dataset bias. The proposed model significantly improved the accuracy and efficiency of ore particle size detection, providing reliable real-time insights to improve grinding control and mineral processing operations.},
  archive      = {J_EAAI},
  author       = {Kanghui Zhang and Qingkai Wang and Guobin Zou and Jiawei Yang and Tao Song and Yang Liu and Daoxi Liu},
  doi          = {10.1016/j.engappai.2025.112304},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112304},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient anchor-free model for ore particle size detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Propeller fault-detection method for electric-propulsion aircraft using motor signals and generative model-based semi-supervised learning. <em>EAAI</em>, <em>162</em>, 112301. (<a href='https://doi.org/10.1016/j.engappai.2025.112301'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failures in propulsion components, such as propellers, can critically affect flight safety; thus, early failure detection, preferably before flight, is essential. Traditional fault-diagnosis methods typically rely on additional sensors or operational data, which may not be available or practical in all situations. This study addresses these challenges by introducing motor-electric-signal-based fault diagnosis that is independent of airframe configuration and can detect faults, even when the aircraft is not in operation. However, difficulties arise owing to poor class variance in motor-electric-signal data and the challenge of obtaining fault data. To overcome these issues, a semi-supervised learning model based on a modified variational autoencoder-generative adversarial network (VAE-GAN) is proposed, which predicts faults using only normal motor-electric-signal data. Additionally, a new preprocessing method and patch-based ensemble inference technique are introduced to improve the poor class-variance characteristics of the data, thereby enhancing the prediction performance. This work demonstrates that propeller faults can be successfully diagnosed using motor-electric signals without the need for additional sensors or fault-data acquisition.},
  archive      = {J_EAAI},
  author       = {Sanga Lee and Dohyeong Kim and Minkyun Noh and Shinkyu Jeong and Jikang Kong and Youngjun Yoo},
  doi          = {10.1016/j.engappai.2025.112301},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112301},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Propeller fault-detection method for electric-propulsion aircraft using motor signals and generative model-based semi-supervised learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight wood defect segmentation network via multi-dimension boundary perception and guidance. <em>EAAI</em>, <em>162</em>, 112300. (<a href='https://doi.org/10.1016/j.engappai.2025.112300'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wood surface defect segmentation is extremely critical for defect refinement and quality control of wooden products. However, it is a challenging task to develop an efficient method with current algorithms due to the complicated characteristics of wood defects with obscure boundary, intraclass difference and interclass similarity. To address these issues, a lightweight network via multi-dimension boundary perception and guidance is proposed for precise segmentation of wood defects. At first, based on the Segformer, a boundary prediction branch is added to enrich detailed boundary information in the encoder, and supervised by the Gaussian signal and cosine similarity, to balance the effect of the boundary gradient information. Then, a double-flow enhancing module is designed to integrate the adjacent level features, by embedding two enhancing paths, to adaptively generate discriminative information of the defects. Finally, a binary segmentation head following the predicted map is introduced to strengthen the penalty for the false prediction results of the boundary. Experimental results demonstrate the proposed method outperforms the state-of-the-arts on our wood surface defect dataset, as well as on three public datasets.},
  archive      = {J_EAAI},
  author       = {Yuhang Zhu and Ye Lin and Zhezhuang Xu and Dan Chen and Kunxin Zheng and Yazhou Yuan},
  doi          = {10.1016/j.engappai.2025.112300},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112300},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight wood defect segmentation network via multi-dimension boundary perception and guidance},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse view tomographic reconstruction of elongated objects using learned primal-dual networks. <em>EAAI</em>, <em>162</em>, 112295. (<a href='https://doi.org/10.1016/j.engappai.2025.112295'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the wood industry, logs are commonly quality screened by discrete X-ray scans on a moving conveyor belt from a few source positions. Typically, the measurements are obtained in a single two-dimensional (2D) plane (a “slice”) by a sequential scanning geometry. The data from each slice alone does not carry sufficient information for a three-dimensional tomographic reconstruction in which biological features of interest in the log are well preserved. In the present work, we propose a learned iterative reconstruction method based on the Learned Primal-Dual neural network, suited for sequential scanning geometries. Our method accumulates information between neighbouring slices, instead of only accounting for single slices during reconstruction. Evaluations were performed by training U-Nets on segmentation of knots (branches), which are crucial features in wood processing. Our quantitative and qualitative evaluations show that with as few as five source positions our method yields reconstructions of logs that are sufficiently accurate to identify biological features like knots (branches), heartwood and sapwood.},
  archive      = {J_EAAI},
  author       = {Buda Bajić and Johannes A.J. Huber and Benedikt Neyses and Linus Olofsson and Ozan Öktem},
  doi          = {10.1016/j.engappai.2025.112295},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112295},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sparse view tomographic reconstruction of elongated objects using learned primal-dual networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep Q-network-driven multi-objective evolutionary algorithm for distributed heterogeneous hybrid flow shop scheduling with worker fatigue. <em>EAAI</em>, <em>162</em>, 112292. (<a href='https://doi.org/10.1016/j.engappai.2025.112292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hybrid flow shop scheduling problem (HFSP) is a prominent challenge in advanced manufacturing systems. Existing research often overlooks the impact of workers in production shops or treats worker fatigue as a static parameter, failing to capture its nonlinear accumulation and recovery effects on processing efficiency. However, with the advent of Industry 5.0, there has been a growing emphasis on the critical role of human factors in production scheduling. As a result, designing an effective algorithm for HFSP that considers human factors has become a prominent research focus. In this paper, an extended distributed heterogeneous hybrid flow shop scheduling problem with the dynamic effects of worker fatigue (DHHFSP-WF) is investigated. To address this problem, a Deep Q-Network-based multi-objective optimization algorithm (DQNMOEA) is designed to minimize makespan, total energy consumption (TEC), and total worker idle time (WIT). In DQNMOEA, a four-dimensional vector encoding scheme considering worker allocation represents solution, and a reconstruction strategy ensures initial population quality and diversity. Moreover, an improved order crossover, two-point crossover, and a segment-based recombination mutation method are proposed to enhance the global search performance of the algorithm. Then, a problem-specific local search strategy is designed for each layer of the vector, allowing the Deep Q-Network (DQN)-based adaptive decision-making mechanism to perform local perturbations on the current non-dominated solutions in the most suitable dimensions. Finally, seven algorithms are adopted to make a comparison on 36 sets of instances, the experimental results indicate that DQNMOEA exhibits competitive performance in solving DHHFSP-WF.},
  archive      = {J_EAAI},
  author       = {Jianlin Zhang and Longbin Ma and Wu Zhao and Jie Cao and Zuohan Chen and Tianpeng Xu},
  doi          = {10.1016/j.engappai.2025.112292},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112292},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep Q-network-driven multi-objective evolutionary algorithm for distributed heterogeneous hybrid flow shop scheduling with worker fatigue},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An angle-enhanced deep learning framework for thermal defect diagnosis in overhead transmission line composite insulators. <em>EAAI</em>, <em>162</em>, 112285. (<a href='https://doi.org/10.1016/j.engappai.2025.112285'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to long-term outdoor exposure, composite insulators are susceptible to degradation and abnormal temperature rise, making Unmanned Aerial Vehicle (UAV)-based infrared inspections essential for effective monitoring. However, traditional manual interpretation of these images is inefficient and subjective. To improve detection automation and accuracy, we propose an intelligent detection method for composite insulators in infrared images based on an improved You Only Look Once version 11 (YOLOv11) model. The proposed approach introduces Oriented Bounding Boxes (OBBs) for annotation and designs an Angle-Enhanced Probabilistic Intersection over Union (AE-ProbIoU) loss function to enhance the model's ability to detect rotated objects. Experimental results demonstrate that the proposed Angle-Enhanced You Only Look Once (AE-YOLO) model achieves a mAP50:95 of 94.0 % and an angle prediction accuracy of 94.3 %. In addition, a temperature extraction module based on the OBBs is developed to accurately derive the temperature profile of the insulator core rod. This method significantly enhances the intelligence level of infrared image analysis for composite insulators and provides technical support for condition assessment and fault prediction in power transmission lines.},
  archive      = {J_EAAI},
  author       = {Xinzhe Yu and Zhenan Zhou and Yu Deng and Kun Zhang and Chen Gu and Zheyuan Liu and Songsong Zhou},
  doi          = {10.1016/j.engappai.2025.112285},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112285},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An angle-enhanced deep learning framework for thermal defect diagnosis in overhead transmission line composite insulators},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian bidirectional long short-term memory-based kinematics-dynamics fusion for fault-tolerant vehicle state estimation under yaw rate sensor failures. <em>EAAI</em>, <em>162</em>, 112283. (<a href='https://doi.org/10.1016/j.engappai.2025.112283'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate estimation of vehicle states is a fundamental component of vehicle stability control systems. To address the issue of inaccurate estimation of vehicle state parameters resulting from yaw rate sensor failures, this study proposes a three-mode collaborative fault-tolerant state estimation method based on Bayesian Bidirectional Long Short-Term Memory (BiLSTM) kinematics-dynamics fusion. First, the kinematics-based method is established using the kinematics model. Second, the dynamics-based method is designed by integrating the Unscented Kalman Filter (UKF) with the dynamics model. Subsequently, a BiLSTM network fusion model based on Bayesian optimization is presented. The model utilizes estimates from kinematic and kinetic methods as a priori inputs and combines the bidirectional information capturing capability of BiLSTM with hyperparameter tuning from Bayesian optimization. The results indicate that when the yaw rate sensor fails, the proposed method achieves an average Root Mean Square Error (RMSE) of 0.0276 km per hour (km/h) for longitudinal speed, 0.0008 radian (rad) for side slip angle, and 0.0072 radian per second (rad/s) for yaw rate across all scenarios. This performance demonstrates a superiority over various maneuvers. This paper combines kinematics, dynamics, and deep learning to provide a reliable solution for fault-tolerant estimation of vehicle states.},
  archive      = {J_EAAI},
  author       = {Min Gao and Jiaqi Li and Wei Wang and Renguang Wang and Jin Luo and Jing Li},
  doi          = {10.1016/j.engappai.2025.112283},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112283},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Bayesian bidirectional long short-term memory-based kinematics-dynamics fusion for fault-tolerant vehicle state estimation under yaw rate sensor failures},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical binary diffing with inductive code representation learning with graph sampling-and-aggregate. <em>EAAI</em>, <em>162</em>, 112279. (<a href='https://doi.org/10.1016/j.engappai.2025.112279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary program diffing, or simply binary diffing, is a type of program analysis technique that quantifies the similarity between two binary programs to derive their differences. In particular, binary diffing is an essential technique for uncovering vulnerabilities and potential attack vectors in industrial control systems, where patch deployment is complicated by closed and restricted environments. Studies on binary diffing can be broadly categorized into dynamic analysis-based, static analysis-based, and neural network-based approaches. Each category of existing studies has its shortcomings, including limited coverage, low accuracy, and issues with on-demand learning. In this paper, we propose the binary diffing with sampling-and-aggregate, a hierarchical binary diffing model that generates inductive code representations based on graph sampling-and-aggregate. Our model sequentially produces instruction-level embedding, block-level embedding, and function-level embedding from the inter-procedural control flow graph of a given program, and then performs hierarchical code diffing based on these embeddings. We formally define the detailed models and present the algorithm of hierarchical binary diffing. Additionally, we conduct a thorough analysis of this algorithm, deriving several advantages. We implemented a prototype and evaluated it on a large-scale dataset in a cross-version, cross-optimization, and obfuscation settings. Our prototype showed F1-scores up to 0.96 and 0.968 in cross-version setting for function and basic block diffing, respectively. Also, our method demonstrated its robustness over several binary obfuscations. In conclusion, our proposal, which generates basic block- and function-level embedding by considering the control flow, has solid advantages on binary diffing and shows the robustness on the binary tampering.},
  archive      = {J_EAAI},
  author       = {Seungho Jeon and Kijong Koo and Daesung Moon and Jung Taek Seo},
  doi          = {10.1016/j.engappai.2025.112279},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112279},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical binary diffing with inductive code representation learning with graph sampling-and-aggregate},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear excavation load prediction of hydraulic excavator based on gated recurrent unit neural network. <em>EAAI</em>, <em>162</em>, 112278. (<a href='https://doi.org/10.1016/j.engappai.2025.112278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Excavator arms are integral to the mining and construction industries, where real-time excavation load prediction is a critical element for the advancement of automated excavation technology. This study presents a novel Physics-guided Neural Network (PGNN) designed to predict the excavating force of hydraulic cylinders used in earthwork excavation. The PGNN model synergizes the physical load model of excavators with a Gated Recurrent Unit (GRU) neural network and is optimized using the Hyperband algorithm to attain both high-speed and precise forecasting. Through comparative experiments, the study validates the PGNN model's ability to achieve optimal response speed and precision in predicting excavation loads. Additionally, the predictive performance of the PGNN model is assessed via a Hardware-in-the-loop (HIL) test, conducted within the context of an actual excavation experiment. This research introduces a promising approach that seamlessly integrates physics-based modeling with machine learning techniques, facilitating real-time load forecasting for excavators. The findings pave the way for more efficient and precise excavation processes, with implications for the broader fields of mining and construction automation.},
  archive      = {J_EAAI},
  author       = {Jinshi Chen and Yue Yu and Dongyang Huo and Han Zhang and Jingyan Wang},
  doi          = {10.1016/j.engappai.2025.112278},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112278},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Nonlinear excavation load prediction of hydraulic excavator based on gated recurrent unit neural network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Plug-and-play fine grained neural cognitive diagnosis framework. <em>EAAI</em>, <em>162</em>, 112276. (<a href='https://doi.org/10.1016/j.engappai.2025.112276'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive diagnosis (CD) is a core task in intelligent education, which accurately assesses students’ mastery of specific knowledge concepts (KCs) by analyzing their answer records. However, existing methods mainly rely on explicit interaction data and use diagnostic models for automatic knowledge proficiency inference. These methods lack systematic optimization for fine-grained knowledge level representation, making it difficult to fully reflect students’ true learning status. To address this, this paper introduces a Plug-and-Play F ine Grained N eural C ognitive D iagnosis Framework (FNCD) with Knowledge-Level Constraint Awareness . The framework combines a knowledge proficiency evaluation module with students’ answer records and a Q-matrix to statically assess knowledge mastery. It uses a student similarity construction method based on random grouping to reveal latent learning pattern associations. Additionally, it employs a multi-scale relational learning strategy and a Top-k attention-enhanced graph network mechanism to dynamically adjust the student similarity relationship network, accurately modeling the complex learning relationships between students. Ultimately, a joint training mechanism is used to optimize the outputs of each module, significantly improving the rationality, interpretability, and accuracy of CD. The experimental results demonstrate that FNCD, as an artificial intelligence-driven plug-and-play module, can be effectively integrated into existing CD models to enhance the modeling of fine-grained knowledge mastery and improve diagnostic accuracy, showcasing the application potential of artificial intelligence in personalized education.},
  archive      = {J_EAAI},
  author       = {Xinjie Sun and Qi Liu and Kai Zhang and Weiyin Gong and Shuanghong Shen and Fei Wang and Yan Zhuang and Meikai Bao and Shijin Wang and Yuling Ma and Enhong Chen},
  doi          = {10.1016/j.engappai.2025.112276},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112276},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Plug-and-play fine grained neural cognitive diagnosis framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Open-vocabulary object detection via neighboring region attention alignment. <em>EAAI</em>, <em>162</em>, 112270. (<a href='https://doi.org/10.1016/j.engappai.2025.112270'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nature of diversity in real-world environments necessitates neural network models to expand from closed category settings to accommodate novel emerging categories. In this paper, we study open-vocabulary object detection (OVD), which facilitates the detection of novel object classes under the supervision of only base annotations and open-vocabulary knowledge. However, we find that the inadequacy of distilled information from the detector head during the alignment process inevitably constrains the performance of recent distillation-based OVD strategies. To this end, we propose Neighboring Region Attention Alignment (NRAA), which performs alignment within the attention mechanism to boost the open-vocabulary inference. Specifically, for a given proposal region, we randomly explore the neighboring boxes to capture the surrounding contextual vocabulary knowledge. Then, a set of regional token features, encompassing both the proposal and neighboring regions, utilize our proposed Neighboring Region Attention (NRA) to extract interaction information. Finally, this information is seamlessly provided to the distillation procedure to assist the alignment between the detector and the pre-trained vision-language models (VLMs). Extensive experiments validate that our proposed model exhibits superior performance on open-vocabulary benchmarks.},
  archive      = {J_EAAI},
  author       = {Sunyuan Qiang and Xianfei Li and Yanyan Liang and Wenlong Liao and Tao He and Pai Peng},
  doi          = {10.1016/j.engappai.2025.112270},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112270},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Open-vocabulary object detection via neighboring region attention alignment},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A time and frequency convolutional autoencoder for anomaly detection in industrial robots based on inertial measurement unit error calibration. <em>EAAI</em>, <em>162</em>, 112269. (<a href='https://doi.org/10.1016/j.engappai.2025.112269'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of industrial robots, ensuring operational reliability and Long-Term Autonomy hinges on the accurate detection of anomalies. However, this sample difference due to noise, joint random errors and sensor errors increases the challenge of robot anomaly detection. To address this problem, an unsupervised deep learning method based on inertial measurement unit (IMU) error calibration is proposed. Firstly, the attitude signals acquired by the IMU from the end of the robot were calibrated using Kalman filtering. The three dimensional (3D) free acceleration was corrected based on the calibrated attitude signal and the calibrated 3D free acceleration signal was used as a signal sample. Secondly, a time and frequency convolutional autoencoder model (TFCAE) is proposed. And the distribution of the different component signals is fitted by stacking multiple encoder modules and 3D-TFCAE is used for 3D free acceleration signal reconstruction model. Then, the error sphere radius is calculated based on the reconstruction error of the 3D free acceleration signal. And the error sphere radius is used as the anomaly detection threshold to realize the robust detection of different types of anomalies. The model was evaluated on a constructed anomaly dataset. This study contributes an innovative 3D-TFCAE architecture, integrating Kalman filtering with time-frequency feature fusion, markedly enhancing anomaly detection in complex signal environments. Experimental findings reveal that 3D-TFCAE significantly outperforms 18 baseline models, improving detection accuracy by about 20 %–40 %, offering an effective solution for high-precision anomaly detection in industrial robots. The code for this project is available at https://github.com/LJlong977/3DTFCAE .},
  archive      = {J_EAAI},
  author       = {Jianlong Li and Xiaoqin Liu and Xing Wu and Dongxiao Wang and Kai Xu and Yashan Li},
  doi          = {10.1016/j.engappai.2025.112269},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112269},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A time and frequency convolutional autoencoder for anomaly detection in industrial robots based on inertial measurement unit error calibration},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight citrus detection and counting method based on deep learning model. <em>EAAI</em>, <em>162</em>, 112268. (<a href='https://doi.org/10.1016/j.engappai.2025.112268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Picking robots have become an important development direction of smart agriculture, and the accurate detection, counting and lightweight deployment of fruits are the technical basis for realizing robot picking. However, due to complex weather conditions and the possible mutual occlusion between branches and citrus, it is challenging to accurately detect and count citrus in orchards. This study proposes a lightweight small target detection model for detecting and counting citrus, and deploys it on the citrus detection platform. The model first introduces FasterNet Block into the cross-stage partial feature fusion module of the backbone network to reduce the number of parameters and calculations while improving the detection accuracy of the network. Secondly, a multi-scale attention mechanism is added to the backbone network to enhance the feature extraction ability of the network. Finally, a bounding box loss function based on a dynamic non-monotonic focusing mechanism is used to increase the model convergence speed and further improve the model accuracy. Experimental results show that the model has an accuracy of 92.7%, an average precision of 91.7%, and a model size of only 5.37 megabytes. The lightweight model is applied to the citrus detection platform. Based on this application, a citrus counting method is proposed, which obtains a mean absolute error (MAE) of 0.92, a root mean square error (RMSE) of 1.28, a determination coefficient ( R 2 ) of 0.98, and a frame rate of 80.6 per second, which meets the requirements of real-time citrus detection and counting. This provides technical support for the subsequent deployment and counting research of picking robots.},
  archive      = {J_EAAI},
  author       = {Jiqing Chen and Mingchang Zhang and Bin Lu and Quan Chen and Zhiwu Jiang and Peilin Li and Jingyao Gai},
  doi          = {10.1016/j.engappai.2025.112268},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112268},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight citrus detection and counting method based on deep learning model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Medical image fusion for high-level analysis: A mutual enhancement framework for unaligned photoacoustic tomography and magnetic resonance imaging. <em>EAAI</em>, <em>162</em>, 112259. (<a href='https://doi.org/10.1016/j.engappai.2025.112259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photoacoustic tomography (PAT) offers optical contrast, whereas magnetic resonance imaging (MRI) excels in imaging soft tissue and organ anatomy. The fusion of PAT with MRI holds promising application prospects due to their complementary advantages. Existing image fusion has made considerable progress in pre-registered images, yet spatial deformations are difficult to avoid in medical imaging scenarios. More importantly, current algorithms focus on visual quality and statistical metrics, thus overlooking the requirements of high-level tasks. To address these challenges, we propose an unsupervised fusion model, termed PAMRFuse+, which integrates image generation and registration. Specifically, a cross-modal style transfer network is introduced to simplify cross-modal registration to single-modal registration. Subsequently, a multi-level registration network is employed to predict displacement vector fields. Furthermore, a dual-branch feature decomposition fusion network is proposed to address the challenges of cross-modal feature modeling and decomposition by integrating modality-specific and modality-shared features. PAMRFuse+ achieves satisfactory results in registering and fusing unaligned PAT–MRI datasets. Moreover, for the first time, we evaluate the performance of medical image fusion with multi-organ instance segmentation. Extensive experimental demonstrations reveal the advantages of PAMRFuse+ in improving the performance of medical image analysis tasks.},
  archive      = {J_EAAI},
  author       = {Yutian Zhong and Jinchuan He and Zhichao Liang and Shuangyang Zhang and Qianjin Feng and Lijun Lu and Li Qi},
  doi          = {10.1016/j.engappai.2025.112259},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112259},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Medical image fusion for high-level analysis: A mutual enhancement framework for unaligned photoacoustic tomography and magnetic resonance imaging},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stacked machine learning-based probabilistic seismic demand and risk assessment of railway embankments with variable slopes. <em>EAAI</em>, <em>162</em>, 112245. (<a href='https://doi.org/10.1016/j.engappai.2025.112245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate seismic risk assessment of railway embankments is critical for risk mitigation, seismic design, and emergency planning. However, conventional methods often suffer from computational inefficiency and complexity. This study proposes a novel machine learning (ML) framework to rapidly and accurately evaluate probabilistic seismic demand and risk for railway embankments. Latin hypercube sampling is utilised to generate representative soil parameter samples to construct numerical models for simulating dynamic responses under near-fault pulse-like ground motions. The peak permanent settlement (PPS) of the embankment surface is used as the key performance metric. Multiple ML models, including decision trees, random forests (RFs), extreme gradient boosting (XGBoost), artificial neural networks (ANNs), and a stacked ML model that integrates RFs, XGBoost, and ANNs, are trained and compared. The stacked ML model outperforms the other models and achieves the highest predictive accuracy for the PPS. SHapley Additive exPlanations are used to identify the velocity spectrum intensity (VSI) and the internal friction angle of the embankment as the most influential factors. Seismic fragility and risk curves are subsequently developed. The VSI and a power-law seismic hazard function are combined to estimate the annual exceedance probabilities for three seismic design criteria levels. The proposed ML framework significantly enhances the efficiency of seismic risk analysis while maintaining high precision, thereby providing a transformative approach for the seismic assessment of railway embankments.},
  archive      = {J_EAAI},
  author       = {Pan Si and Liang Tang and Shuang Tian and Xianzhang Ling and Yanfang Liu},
  doi          = {10.1016/j.engappai.2025.112245},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112245},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Stacked machine learning-based probabilistic seismic demand and risk assessment of railway embankments with variable slopes},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning methods comparison by using statistical tests in solar energy forecasting based on weather features. <em>EAAI</em>, <em>162</em>, 112239. (<a href='https://doi.org/10.1016/j.engappai.2025.112239'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Climate change necessitates precise solar forecasting due to its weather-dependent intermittency. Key parameters - temperature, visibility, altitude, pressure, and wind speed - were analyzed using non-parametric tests. We prioritized short-term weather patterns over random data splitting for enhanced accuracy.Non-parametric tests, such as the Kolmogorov-Smirnov test, were used to assess data normality and select highly correlated features. Principal Component Analysis (PCA) reduces dataset dimensionality while preserving critical trends. Various machine learning approaches were evaluated, including: weighted linear regression (both with and without dimensionality reduction), boosted regression trees, and deep learning architectures-comprising both fundamental models (Convolutional Neural Networks [CNNs] and Recurrent Neural Networks [RNNs]) and advanced hybrid architectures (Temporal Convolutional Networks (TCN) Convolutional Neural Network-Long Short-Term Memory network (CNN-LSTM). All models were optimized through systematic hyperparameter tuning to enhance predictive performance, reduce computational complexity, and improve learning convergence rates. Special attention was given to addressing vanishing gradient problems in deep neural network implementations. Results show TCN outperform other deep learning models, achieving lower training and testing errors with fewer parameters and reduced time complexity. CNN-LSTM models, designed for spatial-sequence prediction, perform well but require more parameters and computational time. The lowest test and training errors belong to CNN-LSTM and TCN, with approximately 9 % and 2 % lower than the maximum amount, respectively. A trade-off between model complexity, error rates, and computational efficiency must be considered when selecting the optimal approach. Since relevant weather features vary by location, the proposed methodology serves as an adaptable algorithm for solar energy prediction in diverse geographical regions.},
  archive      = {J_EAAI},
  author       = {Mohammadreza pourmir and Seyedeh Mohadeseh Miri},
  doi          = {10.1016/j.engappai.2025.112239},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112239},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning methods comparison by using statistical tests in solar energy forecasting based on weather features},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive chemical industrial processes fault detection model based on sparse filtering-based improved mixed-gaussian probabilistic principal component analysis considering low-probability events. <em>EAAI</em>, <em>162</em>, 112236. (<a href='https://doi.org/10.1016/j.engappai.2025.112236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic Principal Component Analysis (PPCA) is widely used in process monitoring. However, its underlying assumption that data follows a Gaussian distribution limits its effectiveness in handling Low Probability Events (LPEs), which often deviate from this assumption. To address this challenge, we propose a novel method called Sparse Filtering-based Improved Mixed-Gaussian Probabilistic Principal Component Analysis (SFIMPPCA) for enhanced LPEs detection. First, a Sparse Filtering (SF) preprocessing technique with an incremental structure is employed to extract the most discriminative features. Second, to address the distortion caused by LPEs, a dynamic ratio correction mechanism based on statistical variability is introduced, followed by a newly designed Mixed-Gaussian Probabilistic Principal Component Analysis (MPPCA). Third, a Bayesian Optimization Algorithm (BOA) is applied to automatically adjust control limits, enhancing the accuracy and reliability of fault detection. The effectiveness of the proposed method is validated using the Tennessee Eastman (TE) process and the Tin Chemical Process (TCP). Experimental results demonstrate that the proposed method significantly improves performance under LPEs conditions, achieving a 10%–12% improvement in most cases.},
  archive      = {J_EAAI},
  author       = {Chuangyan Yang and Jiande Wu and Peng Li and Xun Lang and Mingxi Ai and Hancheng Wang},
  doi          = {10.1016/j.engappai.2025.112236},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112236},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive chemical industrial processes fault detection model based on sparse filtering-based improved mixed-gaussian probabilistic principal component analysis considering low-probability events},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic graph neural network with historic-sequential information representation. <em>EAAI</em>, <em>162</em>, 112234. (<a href='https://doi.org/10.1016/j.engappai.2025.112234'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s interconnected world, networks, whether social, technological, or biological, are constantly evolving, with relationships forming, shifting, and dissolving over time. Traditional models struggle to capture this fluidity, treating networks as static snapshots rather than living systems. While existing research has made strides in analyzing either spatial–temporal patterns or temporal sequences separately, these approaches often fall short in scalability and fail to unify discrete and continuous-time perspectives. To bridge this gap, we introduce DyGHS (Dynamic Graph Historical-Sequential), an innovative framework that harnesses dynamic graph neural networks to model how nodes, edges, and their historical interactions evolve together. By seamlessly integrating discrete-time and continuous-time graph representations, DyGHS not only captures the richness of real-world networks but also efficiently predicts future connections and node behaviors. Our experiments reveal that combining continuous-time Fourier transform (CTFT) with graph neural networks significantly boosts prediction accuracy, outperforming current methods in tasks like link prediction and node classification. This advancement opens new doors for understanding and anticipating the ever-changing tapestry of networked systems.},
  archive      = {J_EAAI},
  author       = {Adam Abakar Hamid and Anping Zhao and Alladoumbaye Ngueilbaye},
  doi          = {10.1016/j.engappai.2025.112234},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112234},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic graph neural network with historic-sequential information representation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAE-diff: Masked-AutoEncoder-guided diffusion framework for source-free domain adaptive medical image segmentation. <em>EAAI</em>, <em>162</em>, 112219. (<a href='https://doi.org/10.1016/j.engappai.2025.112219'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain gaps can often cause dramatic performance deterioration when applying medical image segmentation models trained on the source domain to the target domain. Although unsupervised domain adaptation methods can address the domain gap challenge to some extent, their reliance on accessing source images largely hampers their practical applicability, as source data are often inaccessible due to privacy concerns. Moreover, the low-quality characteristic of medical images can further degrade the domain adaptation performance of segmentation models. To address these issues, we propose the Masked-AutoEncoder-guided Diffusion (MAE-Diff) framework for source-free domain adaptive medical image segmentation. MAE-Diff mainly consists of a Masked AutoEncoder (MAE) Module for effective feature extraction and domain adaptation, and a Diffusion Module for effective segmentation of low-quality medical images. On source images, the MAE encoder is trained to extract image-specific features, and the Diffusion Module is trained to generate segmentation maps following a gradual denoising strategy, under the guidance of features extracted by the MAE encoder. Training on the target domain involves only fine-tuning MAE (trained on the source images) with target images, allowing MAE-Diff to adapt to the target domain distribution. Inference on target images can then be made by the source-based Diffusion Module, under the guidance of features extracted by the MAE encoder fine-tuned on the target images. Extensive experiments on three datasets demonstrate the effectiveness of the proposed framework for source-free domain-adaptive medical image segmentation. The code of MAE-Diff is available at https://github.com/xuss804/MAEDiff .},
  archive      = {J_EAAI},
  author       = {Shanshan Xu and Le Xu and Yeqing Yang and Lixia Tian},
  doi          = {10.1016/j.engappai.2025.112219},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112219},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MAE-diff: Masked-AutoEncoder-guided diffusion framework for source-free domain adaptive medical image segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic-static siamese Takagi–Sugeno-kang fuzzy system with inductive-reflection deep fuzzy rule. <em>EAAI</em>, <em>162</em>, 112199. (<a href='https://doi.org/10.1016/j.engappai.2025.112199'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The first-order Takagi–Sugeno–Kang (TSK) fuzzy classifiers are famous for their high computational efficiency and strong interpretability, but they often struggle to learn from complex and large-scale datasets, and perform not very well compared to higher-order TSK fuzzy classifiers. To address this issue, in this paper we propose a novel Dynamic-Static Siamese TSK Fuzzy classifier with Inductive-Reflection Deep Fuzzy rule. It aims to enhance the model’s self-learning capabilities by utilizing Siamese network to integrate deep fuzzy knowledge and fine-grained knowledge without the need for a teacher model. The innovations of this study are as follows: (1) The deep fuzzy rules in the proposed classifier are enriched with an “Inductive-Reflection” process, which reduces constraints on traditional basic fuzzy rule and aligns rule acquisition more closely with general human thinking manners; (2) The proposed method includes a mechanism for self-learning and improvement from both deep and fine-grained fuzzy knowledge, eliminating the complexity of retraining a new teacher model; (3) An adaptive learning function is developed to effectively adjust the learning process, adapting to tasks with different complexities. Extensive experiments results on benchmark datasets, as well as two real-world datasets, demonstrate the effectiveness of the proposed classifier in terms of classification accuracy and weighted F1-score.},
  archive      = {J_EAAI},
  author       = {Xiongtao Zhang and Qihuan Shi and Yunliang Jiang and Qing Shen and Jungang Lou and Ruiqin Wang},
  doi          = {10.1016/j.engappai.2025.112199},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112199},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic-static siamese Takagi–Sugeno-kang fuzzy system with inductive-reflection deep fuzzy rule},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing anomaly detection with few-shot fine-tuned long text-to-image models. <em>EAAI</em>, <em>162</em>, 112174. (<a href='https://doi.org/10.1016/j.engappai.2025.112174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial anomaly detection plays a crucial role in the industrial manufacturing field. Currently, utilizing generated data to improve the performance of the anomaly detection model is an effective approach. However, most existing methods often rely on mask-guided synthesis, where the distribution of the generated defects is limited by masks that are typically random or learned by a model. In addition, the scarcity of real anomalous samples makes it difficult for generative models to capture genuine defect patterns and align with the real anomaly distribution. To tackle these issues, we propose DefectGen, the first long-text-guided few-shot text-to-image data generation pipeline for industrial anomaly detection. To improve distribution alignment under limited anomaly samples, DefectGen incorporates a Prompt Generation and Variation Module, which uses MLLMs (Multimodal Large Language Models) to expand few-shot image–text pairs into diverse and semantically rich prompts, and DoKr (Weight- D ecomposed L o w-Rank Adaptation with Kr onecker product), a lightweight fine-tuning strategy with structured low-rank adaptation. To ensure the quality of synthetic data, DefectGen further introduces the Real-Guided Clustering Filter, which selects high-quality generated samples by comparing their features with those of real anomalies. Experiments on the MVTec AD(MVTec AnomalyDetection) dataset show that DefectGen generates more diverse and realistic synthetic anomalies and achieves a 5.58% average improvement in anomaly classification accuracy compared to state-of-the-art methods. Code and data are available at: https://anonymous.4open.science/r/DefectGen-CD04/ .},
  archive      = {J_EAAI},
  author       = {Jiachen Liu and Jiajia An and Junbin Lu and Zhuoqin Yang and Jinbao Wang and Ping Lu and Yuying Wang and Linlin Shen},
  doi          = {10.1016/j.engappai.2025.112174},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112174},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing anomaly detection with few-shot fine-tuned long text-to-image models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed fine-tuning for physics discovery from random and sparse data. <em>EAAI</em>, <em>162</em>, 112132. (<a href='https://doi.org/10.1016/j.engappai.2025.112132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although significant advances have been made in both numerical methods and machine learning approaches for solving differential equations across various scientific sectors, these methods often rely on complete information about the differential equations, including precise parameter values, which are not easily obtainable in real-world scenarios. To address this challenge, data-driven methods for discovering differential equations have gained growing popularity in recent years. However, many existing approaches demand unrealistic prerequisites, such as extensive high-fidelity data or carefully designed low-fidelity data and functions. In this paper, we propose a novel method: P hysics- I nformed F ine- T uning ( PIFT ) to discover the unknown parameters in differential equations when only randomly distributed sparse data points are available. PIFT consists of three stages; (i) generating low fidelity data from prior knowledge under realistic settings, (ii) pre-training a single neural network with the generated low fidelity data, and (iii) fine-tuning the pre-trained model using physics-informed loss function. PIFT is evaluated on seven scientific problems including five ordinary differential equations and two partial differential equations. We also demonstrate the robustness and generalizability of PIFT to out-of-distribution tasks. PIFT exhibits high accuracy and robustness in discovering unknown parameters of differential equations from randomly distributed sparse data points.},
  archive      = {J_EAAI},
  author       = {Yong Jin Jeong and Taesup Moon},
  doi          = {10.1016/j.engappai.2025.112132},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112132},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed fine-tuning for physics discovery from random and sparse data},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep Q-learning with feature extraction and prioritized experience replay for edge node overload in edge computing. <em>EAAI</em>, <em>162</em>, 112124. (<a href='https://doi.org/10.1016/j.engappai.2025.112124'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keeping track of the edge nodes’ status information is crucial, which is the condition of their available compute capacity as measured by their Age-of-Information. In Internet of Things-oriented edge computing systems, the computational and software-defined infrastructure resources are heterogeneous and subject to rapid change. Edge computing systems often face dynamic workloads and limited computational resources, leading to frequent node overload scenarios. These overloads degrade system responsiveness and service availability, especially in latency-sensitive applications. The scheduling of computation tasks would consider both current resource availability and predicted overload risks. An intelligent, adaptive method that learns optimal task allocation under resource constraints has the potential to boost the operational efficiency of Internet of Things-oriented edge computing systems. Addressing edge node overload is critical for the sustainable and scalable deployment of edge-based infrastructures. This research designs a resource-overloaded detection model specifically for diverse workloads in edge computing systems. The proposed Deep Reinforcement Learning model explores two significant challenges: the selection of pertinent feature sets from the workload resource utilization storage, and their classification of overload and detection of fatal failure of edge computing nodes. We propose a Deep-Q Network with a prioritized experience replay framework for edge node resource overload. The framework relies on feature learning using Linear Discriminant Analysis and Deep Q Network with a prioritized experience replay to efficiently indicate the overload status of edge nodes and reward the system with actions that enhance edge resources allocation. Deep-Q Network is well-suited for sequential decision-making in dynamic environments, while prioritized experience replay improves sample efficiency by focusing on updating on high-priority transitions with larger temporal-difference errors. Features are learned automatically from the edge node resource profiling data generated on a real edge-based container infrastructure. Linear Discriminant Analysis reduces the high-dimensional state space by emphasizing the most discriminative features for scheduling decisions. The infrastructure executes an intelligent inference of containerized applications considered as resource-intensive applications. When the feature extraction is added to the proposed deep reinforcement learning model, the overload classifier’s performance is improved. Comparing the model with selection to the one without it, the total accuracy and F1-score were improved by 1.3% and 1.4%, respectively.},
  archive      = {J_EAAI},
  author       = {Lionel Nkenyereye and Boon Giin Lee and Wan-Young Chung},
  doi          = {10.1016/j.engappai.2025.112124},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112124},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep Q-learning with feature extraction and prioritized experience replay for edge node overload in edge computing},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STEval: A framework for evaluating spatio-temporal crime prediction models. <em>EAAI</em>, <em>162</em>, 112123. (<a href='https://doi.org/10.1016/j.engappai.2025.112123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-Temporal predictive models are crucial for forecasting where and when crimes will occur, aiding public security organizations in resource allocation and crime prevention. Despite numerous literature proposals, a lack of standardized evaluation criteria hinders comparability and reliability. To address this, we propose STEval, a comprehensive and flexible evaluation framework for spatio-temporal predictive models. STEval consists of four modules: data preparation, spatial structure definition, model training, and model evaluation. The framework’s robustness was demonstrated using a 40-million-record crime dataset from Minas Gerais State (Brazil) across five experimental scenarios, including variations in temporal granularity, spatial resolution, and distribution shifts. Results demonstrate that no single model is universally superior, and the most appropriate model depends on the specific application context. For instance, Spatio-Temporal Kernel Density Estimation (STKDE) consistently achieved high Hit Rates (HR), often exceeding 0.98 in fine spatial resolutions (e.g., 100-square meters grid) for violent crimes, while Spatial-Temporal Autoregressive Integrated Moving Average (STARIMA) demonstrated strong performance in temporal granularity tests, reaching HRs of up to 0.65 for theft predictions. Conversely, Extra Tree Regressor, though exhibiting significantly lower HRs (e.g., as low as 0.02 in some spatial tests), consistently provided the fastest execution times, often under 5 s, contrasting with STKDE’s execution times that could extend to thousands of seconds in dense spatial grids. The framework’s detailed analysis provides important insights for informed model selection and optimization, revealing each model’s strengths and limitations, and providing a robust foundation for future advancements in spatio-temporal crime prediction research, leveraging Machine Learning (ML) techniques.},
  archive      = {J_EAAI},
  author       = {Gabriel Amarante and Matheus Pimenta and Yan Andrade and Matheus Senna and Rainer Menezes and Antônio Hot Faria and Marcelo Vilas-Boas and Frederico Martins de Paula Neto and João Paulo da Silva and Everton Renato de Sousa and Jamicel da Silva and Wagner Meira Jr. and George Teodoro and Leonardo Rocha and Renato Ferreira},
  doi          = {10.1016/j.engappai.2025.112123},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112123},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {STEval: A framework for evaluating spatio-temporal crime prediction models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new design of arithmetic and logic unit for enhancing the security of future internet of things devices using quantum-dot technology. <em>EAAI</em>, <em>162</em>, 112113. (<a href='https://doi.org/10.1016/j.engappai.2025.112113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) is a network of interconnected devices that collect, monitor, analyze, and exchange data. This technology plays a crucial role in the smart city infrastructure by seamlessly interconnecting various nodes. The extensive application and recognition of IoT across multiple city domains, such as healthcare, transportation, energy, education, and agriculture, bring significant challenges, with security among the most pressing. Traditional hardware technologies like Complementary Metal Oxide Semiconductor (CMOS) and Very Large Scale Integration (VLSI) suffer from limitations such as high power consumption and insufficient scalability, which hinder secure and sustainable IoT deployment. Such limitations have prompted the need to seek other technologies that would serve the dual purpose of providing security as well as energy. Quantum-based technologies can become adequate candidates offering promising solutions to make IoT devices and sustainable systems more secured. Quantum-dot Cellular Automata (QCA) has been proposed as a nanotechnology with the potential of consuming ultra-low powers, less area, and high-speed operation. QCA enhances security through sustainable computing objectives by minimizing energy usage. To improve the future security and efficiency of IoT hardware, this paper suggests a QCA-based Arithmetic Logic Unit (ALU). This ALU can generate more than 12 logical and arithmetic operations. Designed together with the majority gates, XOR gates, multiplexers, and full adders, the ALU is simulated using the QCA-Designer 2.0.3. Simulated results indicate improvements in the number of cells and reduced occupied area relative to the earlier designs. These results indicate the potential of QCA technology in enabling secure, energy-efficient, and compact computing architecture applicable in the future IoT.},
  archive      = {J_EAAI},
  author       = {Maryam Zaker and Seyed Sajad Ahmadpour and Nima Jafari Navimipour and Muhammad Zohaib and Neeraj Kumar Misra and Sankit Kassa and Ahmad Habibizad Navin and Arash Heidari and Mehdi Hosseinzadeh and Omar I. Alsaleh},
  doi          = {10.1016/j.engappai.2025.112113},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112113},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new design of arithmetic and logic unit for enhancing the security of future internet of things devices using quantum-dot technology},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inland waterway object detection in multi-environment: Dataset and approach. <em>EAAI</em>, <em>162</em>, 111994. (<a href='https://doi.org/10.1016/j.engappai.2025.111994'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has advanced intelligent ship visual perception, but the scarcity of dedicated inland waterway vessels dataset limits system adaptability in complex environments. Narrow waterways, variable weather, and urban interference challenge the robustness of existing object detection systems. To address these issues, this paper constructs the Multi-environment Inland Waterway Vessels Dataset (MEIWVD), comprising 32,478 high-quality images from diverse Yangtze River basin scenarios, including sunny, rainy, foggy, and artificially lit conditions. The diversity and multi-scale characteristics of MEIWVD establish it as a rigorous benchmark for vessel detection. To leverage the characteristics of the MEIWVD, this paper proposes a scene-guided image enhancement module for multi-environment scenarios, which adaptively enhances water surface images based on environmental conditions to improve detector performance in complex scenarios. Additionally, a parameter-limited dilated convolution is introduced to enhance the representation of salient features of inland waterway vessels by leveraging their geometric characteristics. Finally, a multi-scale dilated residual fusion method is proposed to effectively integrate multi-scale features and improve the detection of multi-scale objects. Comprehensive statistical analysis and experiments on the MEIWVD demonstrate that it poses higher demands on object detection algorithms compared to existing water surface datasets, owing to its diverse and challenging scenarios. The proposed methods, including scene-guided image enhancement, parameter-limited dilated convolution, and multi-scale dilated residual fusion, advance research in multi-environment dataset, achieving a mean average precision over intersection over union thresholds from 0.5 to 0.95 of 81.6 % on the MEIWVD, outperforming state-of-the-art object detection algorithms.},
  archive      = {J_EAAI},
  author       = {Shanshan Wang and Haixiang Xu and Hui Feng and Xiaoqian Wang and Pei Song and Sijie Liu and Jianhua He},
  doi          = {10.1016/j.engappai.2025.111994},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111994},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inland waterway object detection in multi-environment: Dataset and approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
