<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EAAI</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="eaai">EAAI - 270</h2>
<ul>
<li><details>
<summary>
(2025). Teach sample-specific knowledge: Separated distillation based on samples. <em>EAAI</em>, <em>162</em>, 112696. (<a href='https://doi.org/10.1016/j.engappai.2025.112696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in deep neural networks have revolutionized computer vision, enabling practical applications like classification and object detection. However, deploying these models on resource-constrained devices remains a critical challenge due to their high computational demands. Knowledge Distillation (KD) has emerged as an effective technique to address this issue by transferring knowledge from complex teacher models to lightweight student models, enhancing efficiency while maintaining high performance. Traditional logit-based KD methods use forward Kullback–Leibler divergence (FKLD) to transfer meaningful knowledge. However, FKLD typically exhibits a mode-averaging property, causing students to focus on non-target information, whether the teacher’s samples are correct or incorrect. Additionally, when handling uncertain samples, even teacher models may fail to classify them accurately, leading to incorrect predictions and confusing the students. To address these issues, we classify the dataset into two groups based on the teacher’s predictions: correct and incorrect samples. To ensure a more reliable transfer of knowledge from teacher to student for correct samples, we employ both forward Kullback–Leibler divergence (FKLD) and reverse Kullback–Leibler divergence (RKLD), which has mode-focusing properties. We also reduce temperature scaling for RKLD to enhance the focus on target information, ensuring that the student model prioritizes meaningful knowledge while minimizing the influence of non-target information. Conversely, for incorrect predictions, our method minimizes the teacher’s knowledge, encouraging students to rely more on the true labels by focusing on cross-entropy loss. Experimental results on both classification and object detection tasks demonstrate that our method, Teach Sample-Specific Knowledge (TSSK), outperforms state-of-the-art KD methods, making it ideal for deployment on-devices in real-world scenarios.},
  archive      = {J_EAAI},
  author       = {Seonghak Kim and Gyeongdo Ham and Suin Lee and Daeshik Kim},
  doi          = {10.1016/j.engappai.2025.112696},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112696},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Teach sample-specific knowledge: Separated distillation based on samples},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A context-adaptive and dual-dimensional collaboration method for infrared-visible image registration and fusion. <em>EAAI</em>, <em>162</em>, 112684. (<a href='https://doi.org/10.1016/j.engappai.2025.112684'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image registration and fusion are tightly coupled tasks. However, in unregistered scenarios, prioritizing registration accuracy can compromise the integrity of complementary information, whereas enforcing fusion quality may disrupt geometric consistency. To address this, we propose a Context-Adaptive and Dual-Dimensional Collaboration Method for Infrared-Visible Image Registration and Fusion. Firstly, we design an adaptive context-aware channel fusion convolution module that simultaneously serves feature extraction for both registration and fusion tasks, perceiving contextual feature relationships to coordinate corresponding regions across modalities while dynamically generating task-adaptive feature representations. Secondly, we design a dual-dimensional dynamic collaboration module leveraging interactive mapping across spatial and channel dimensions to effectively fuse complementary cross-modal features while preserving detail and texture information. Finally, the registered and fused images are reconstructed by the spatial transformer network and lightweight decoder. Extensive tests on multiple datasets show that our method exhibits excellent performance in visual effects, quantitative metrics, and generalization ability, making it suitable for application scenarios such as security monitoring, fault detection, and target recognition.},
  archive      = {J_EAAI},
  author       = {Minghao Jiang and Shaoshu Gao and Xiaodong Zhang and Xingli Wang and Qing Hu and Weiming Wang},
  doi          = {10.1016/j.engappai.2025.112684},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112684},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A context-adaptive and dual-dimensional collaboration method for infrared-visible image registration and fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight vision mamba coding UNet for medical image segmentation. <em>EAAI</em>, <em>162</em>, 112676. (<a href='https://doi.org/10.1016/j.engappai.2025.112676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The segmentation of medical images is vital for advancing research in medicine and supporting precise clinical diagnoses. Over the past few years, neural network-based methods have become a major focus of research and have been broadly adopted in medical image segmentation. However, mainstream methods like Transformer have excessive computational cost requirements, which makes them impractical for mobile medical applications. Therefore, this paper proposes a Lightweight Vision Mamba Coding UNet (LVMC-UNet), which integrates the Rotation-based Vision Mamba module (RVM) and Correlation Space Fusion module (CSF) in a lightweight manner. The RVM module processes the input images in parallel and introduces rotary positional encoding (RPE) on the Vision Mamba architecture to address the limitation of the Mamba module’s insufficient ability to capture local details. The CSF module integrates multi-stage and multi-scale feature maps and introduces blueprint separable convolutions (BSConvs) to enhance intra-kernel correlation. Comprehensive experiments on three datasets demonstrate that LVMC-UNet outperforms current lightweight segmentation methods and strikes a balance between segmentation accuracy and computational requirements.},
  archive      = {J_EAAI},
  author       = {Yuanyuan Li and Yifei Duan and Guanqiu Qi and Baisen Cong and Li Zhang and Zhiqin Zhu},
  doi          = {10.1016/j.engappai.2025.112676},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112676},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight vision mamba coding UNet for medical image segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A real-time design and implementation of intelligent drowsiness and fatigue recognition system for enhancing driver safety. <em>EAAI</em>, <em>162</em>, 112665. (<a href='https://doi.org/10.1016/j.engappai.2025.112665'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the rise in personal vehicle usage for speed and convenience has increased road accidents, with driver fatigue as a major cause. Existing drowsiness detection systems suffer from high computational complexity and poor generalization across diverse conditions. To address these challenges, we propose an Intelligent Drowsiness and Fatigue Recognition (IDFR) System leveraging deep learning for real-time driver monitoring. Our system employs a customized Convolutional Neural Network (CNN) optimized for detecting eye states (open or closed) with high accuracy. A key feature is the use of the Eye Aspect Ratio (EAR) with a threshold of 0.2, empirically validated for precise drowsiness detection across varying lighting conditions and facial features. The system is trained on the Media Research Lab (MRL) Eye dataset, containing over 84,000 images, ensuring robust generalization across diverse demographics. The proposed IDFR system achieves 98.50 % accuracy, outperforming state-of-the-art deep learning models including Visual Geometry Group 16-layer network (VGG16), Visual Geometry Group 19-layer network (VGG19), Residual Network 152-layer (ResNet152), and Densely Connected Convolutional Network 201-layer (DenseNet201) in accuracy, precision, recall, and computational efficiency. By integrating transfer learning and fine-tuning techniques, we significantly reduce computational costs while maintaining high performance. The system was evaluated under challenging conditions, such as low lighting, high glare, and partial occlusion (e.g., sunglasses, shadows, and face coverings), ensuring robust detection accuracy. Our results demonstrate the IDFR system's potential for real-time in-vehicle deployment, providing immediate driver feedback and reducing accident risks. This work advances intelligent driver assistance technologies, enhancing road safety and future transportation systems.},
  archive      = {J_EAAI},
  author       = {Samy Abd El-Nabi and Khalil F. Ramadan and El-Sayed M. El-Rabaie and Ahmed Emam and Walid El-Shafai},
  doi          = {10.1016/j.engappai.2025.112665},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112665},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A real-time design and implementation of intelligent drowsiness and fatigue recognition system for enhancing driver safety},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coupled fault diagnosis for centrifugal pumps through boruta-shap feature selection and rime-enhanced stacked denoised autoencoder. <em>EAAI</em>, <em>162</em>, 112659. (<a href='https://doi.org/10.1016/j.engappai.2025.112659'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the critical engineering challenges of diagnosing multi-condition cavitation and impeller erosion damage in deep sea centrifugal pumps, where traditional methods suffer from feature redundancy and poor generalization. An artificial intelligence (AI)-driven framework is proposed by integrating Boruta-Shap interpretable feature selection with a Rime-optimized Stacked Denoising Auto-Encoder (SDAE). Firstly, vibration signals undergo multi-domain feature extraction. The Boruta-Shap method quantifies feature interactions via Shapley values and shadow feature hypothesis testing, enabling physics-informed selection of cavitation energy indicators and impeller damage transient features, reducing feature dimensionality by approximately 70 %. Secondly, the Rime algorithm, inspired by ice-crystal growth dynamics, globally optimizes SDAE hyperparameters via balancing soft-rime exploration and hard-rime exploitation. Validated experimentally under variable conditions (0.8, 1.0 and 1.2 Q d ), the framework achieves 96 % testing accuracy, outperforming other diagnostic models, with reduced cross-condition misclassification. By bridging interpretable AI with multi-physics diagnostics, this work provides a replicable solution for predictive maintenance of energy infrastructure, advancing intelligent maintenance technologies for industrial systems facing complex hydrodynamic perturbations.},
  archive      = {J_EAAI},
  author       = {Kang Hu and Hui Sun and Wei Fan and Qiaorui Si and Yu Wu and Shouqi Yuan},
  doi          = {10.1016/j.engappai.2025.112659},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112659},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Coupled fault diagnosis for centrifugal pumps through boruta-shap feature selection and rime-enhanced stacked denoised autoencoder},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal interval prediction of carbon dioxide emissions from heavy construction machinery: A missing-data robust inverted-transformer model considering sensors failure in complex construction environment. <em>EAAI</em>, <em>162</em>, 112658. (<a href='https://doi.org/10.1016/j.engappai.2025.112658'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of carbon dioxide (CO 2 ) emissions from heavy construction machinery in large-scale infrastructure projects presents a viable avenue for mitigating climate change. However, most current studies neglect the intricate operating conditions of such machinery. Moreover, in complex construction environments with high-frequency vibrations and heavy dust, sensor failures leading to random data loss significantly increase the difficulty of emission prediction. Especially when high-emission periods account for a small proportion, existing methods struggle to effectively capture CO 2 emission peaks. To address these challenges, this study proposes an improved Inverted-Transformer (iTransformer) multimodal interval prediction model for accurate CO 2 emission forecasting in heavy construction machinery under conditions of random sensor failures. The model incorporates a Mixture of Experts (MoE) mechanism within the iTransformer framework, which adaptively adjusts expert weights for missing modalities, thereby reducing prediction errors caused by random data loss. Additionally, to capture localized CO 2 emission peaks, this study introduces a Peak Capture Loss (PCL) function, which adjusts incremental emissions between adjacent time steps by supervising the differences between generated sequences, enabling the model to track abrupt emission variations. The Bootstrap method is also utilised to quantify and estimate uncertainty in the CO 2 emission Interval Prediction. Case studies reveal that the proposed model achieves high prediction accuracy (coefficient of determination ( R 2 ) = 0.99), especially across various data missing rates (5 %, 10 %, 15 %), with the average R 2 value increasing by approximately 6 %. This provides a novel approach for predicting emissions of heavy construction machinery in large-scale infrastructure projects.},
  archive      = {J_EAAI},
  author       = {Zhouquan Dong and Xiaoling Wang and Jun Zhang and Peng Yu and Zhijian Cai},
  doi          = {10.1016/j.engappai.2025.112658},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112658},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodal interval prediction of carbon dioxide emissions from heavy construction machinery: A missing-data robust inverted-transformer model considering sensors failure in complex construction environment},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing wind power forecasting accuracy under extreme weather: Leveraging a dual-model approach with condition-based classification. <em>EAAI</em>, <em>162</em>, 112656. (<a href='https://doi.org/10.1016/j.engappai.2025.112656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate wind power forecasting is essential for grid stability, yet extreme weather events, exacerbated by climate change—pose challenges that current methods often overlook. In this study, we introduce a forecasting framework that accounts for extreme weather conditions to improve forecasting accuracy. First, we correct Numerical Weather Prediction (NWP) via temporal alignment and bias correction. Then, we address the differences in data distributions between typical and extreme weather conditions, while accounting for multivariate meteorological influences. We establish weather classification thresholds by integrating meteorological indicators (wind speed variation rate, precipitation, snowfall) with a data-driven sensitivity analysis, and optimize them via grid search to maximize the coefficient of determination ( R 2 ) while balancing false alarms and detection rates. Finally, due to the difference in distribution and data pattern, we implemented distinct forecasting models for each condition. A Convolutional Neural Network (CNN) models normal conditions by capturing temporal dependencies, while Light Gradient Boosting Machine (LightGBM) handles sparse extreme-weather samples. Compared to models that ignore extreme weather, our approach reduces Mean Absolute Error (MAE) by 21.13% and Root Mean Squared Error (RMSE) by 9.29%. Under extreme conditions, Mean Absolute Percentage Error (MAPE) is reduced by 32.76%, demonstrating enhanced robustness in handling extreme weather scenarios.},
  archive      = {J_EAAI},
  author       = {Weimin Yuan and Han Yang and Zhu Han and Yanru Zhang},
  doi          = {10.1016/j.engappai.2025.112656},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112656},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing wind power forecasting accuracy under extreme weather: Leveraging a dual-model approach with condition-based classification},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating multimodal biophysical features with hybrid deep learning for ribonucleic acid secondary structure prediction. <em>EAAI</em>, <em>162</em>, 112648. (<a href='https://doi.org/10.1016/j.engappai.2025.112648'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The secondary structure of ribonucleic acid (RNA) is pivotal for elucidating its functional roles. However, existing deep learning models predominantly rely on single-feature representations, which restricts their capacity to sufficiently capture the intricate information embedded in RNA sequences. To solve this problem, we propose a novel RNA secondary structure prediction method based on multimodal feature fusion and hybrid deep learning. By integrating multiple features of RNA are modeled to achieve the synergistic effect of the chemical microenvironment, local physical constraints and long-range interactions. We conceptualize RNA structure as an image and treat various RNA features as distinct channels of that image. To facilitate the transformation from RNA sequences to RNA images, we design a hybrid neural network architecture. Specifically, the sequence feature extraction module first extracts features directly from the RNA sequence. These features are then passed to the image feature extraction module, which focuses on capturing effective structural information from the multichannel RNA image, thereby enhancing the accuracy of RNA secondary-structure prediction. Experimental results indicate that our method achieves state-of-the-art performance compared with recent deep learning methods across several benchmark datasets and demonstrates potential in drug discovery applications.},
  archive      = {J_EAAI},
  author       = {Xiao Wang and Yongfeng Zhang and Lixiang Yang and Rong Wang},
  doi          = {10.1016/j.engappai.2025.112648},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112648},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Integrating multimodal biophysical features with hybrid deep learning for ribonucleic acid secondary structure prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geometry-informed multimodal fusion network for enhancing high-density spatial transcriptomics from histology images. <em>EAAI</em>, <em>162</em>, 112647. (<a href='https://doi.org/10.1016/j.engappai.2025.112647'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial transcriptomics (ST) is a revolutionary technology that combines spatial information with gene expression analysis, opening up new perspectives for studying the spatial distribution of genes within tissues and their regulatory mechanisms. However, it is limited by the sparsity of sequencing spots and the high cost of ST technology, which hinders its widespread application in biomedical research. An alternative and more cost-effective strategy is to leverage deep learning methods to infer high-density gene expression profiles from histological images. To this end, we developed the HisHRST (Histology-based High-Resolution Spatial Transcriptomics) method based on an offline pathological image foundation model, aiming to accurately generate high-density ST data from histological images using a geometry-guided multimodal fusion network with spatial coordinates. This method employs a multi-head attention mechanism to incorporate spatial location information, thereby enhancing feature representation. We systematically evaluated HisHRST on seven ST datasets and compared its performance with five existing methods. Experimental results demonstrate that HisHRST can accurately predict gene expression profiles for unmeasured spots, refine gene expression patterns, and effectively preserve the original spatial structure of gene expression. Furthermore, this method facilitates the identification of biologically meaningful pathways, thereby advancing the understanding of key biological processes. All code and public datasets used in this paper are available at https://github.com/wenwenmin/HisHRST and https://zenodo.org/records/15129356 .},
  archive      = {J_EAAI},
  author       = {Zhiceng Shi and Shuailin Xue and Wenwen Min},
  doi          = {10.1016/j.engappai.2025.112647},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112647},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Geometry-informed multimodal fusion network for enhancing high-density spatial transcriptomics from histology images},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). State-of-the-art of machine learning methods for fault detection and health monitoring of wind turbine system components: A comprehensive review. <em>EAAI</em>, <em>162</em>, 112645. (<a href='https://doi.org/10.1016/j.engappai.2025.112645'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the world shifts from fossil fuels to sustainable energy sources, wind energy has become an increasingly important part of the global renewable energy mix. However, maintaining the efficient operation of wind turbines remains challenging. This review presents, discusses and extracts the major trends of advancements in artificial intelligence and their application in engineering solutions for diagnosing faults in wind turbine systems. It begins with an analysis of the benefits and limitations of different generator types used in wind power generation. Next, it identifies the most frequently failing components, including power converters, generators (with rotor), sensors, gearboxes and drivetrain. Furthermore, it provides an exhaustive overview of machine learning (ML) techniques, including advanced methodologies such as attention mechanisms and ensemble learning frameworks, for wind turbine fault detection and health monitoring. This review aims to show the current trends and future research directions of machine learning applications to improve the reliability, efficiency, and sustainability of wind turbine operations. It provides valuable insights for researchers, engineers, and decision-makers in the wind energy sector, helping them select suitable ML approaches and refine existing wind turbine operational strategies. It also enables us to measure the challenges that remain towards achieving highly efficient operation of wind turbines.},
  archive      = {J_EAAI},
  author       = {Abebe Wolie Yimam and Majid Vafaeipour and Maarten Messagie and Kinde Anlay Fante and Emiyamrew Minaye Molla and Tefera Mekonnen Azerefegn and Thierry Coosemans},
  doi          = {10.1016/j.engappai.2025.112645},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112645},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {State-of-the-art of machine learning methods for fault detection and health monitoring of wind turbine system components: A comprehensive review},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Removal of cationic dyes from aqueous solutions using agricultural waste: Modeling the biosorption process with semantic immune plasma programming. <em>EAAI</em>, <em>162</em>, 112640. (<a href='https://doi.org/10.1016/j.engappai.2025.112640'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the use of celery stalks, a low-cost agricultural waste, as biosorbent for removing crystal violet (CV), a toxic cationic dye, from aqueous solutions. The biosorption process was experimentally examined under varying conditions of potential of hydrogen (pH), contact time, biosorbent dose, initial dye concentration, and temperature. To model the relationship between these input parameters and biosorption performance, we employed symbolic regression using four automatic programming (AP) methods: Genetic Programming (GP), Artificial Bee Colony Programming (ABCP), Immune Plasma Programming (IPP), and a newly proposed semantic IPP (sIPP), which introduces a semantic-based crossover operator. The novelty of the study lies in combining agricultural waste-based biosorption with interpretable Artificial Intelligence (AI), enabling both accurate prediction and transparent understanding of the system. Experimental results revealed the presence of chemisorption in the spontaneous and endothermic biosorption process, with a maximum biosorption efficiency of 90% and a biosorption capacity of 6.9 mg/g. Among the symbolic models, sIPP achieved the highest test accuracy ( R Test 2 = 0 . 99 for capacity, 0.98 for efficiency), while also generating the simplest trees (approximate mean values: 91 and 99 nodes). This confirms sIPP’s strength in balancing predictive accuracy with model transparency. The proposed framework demonstrates strong potential for sustainable and explainable modeling in environmental engineering applications.},
  archive      = {J_EAAI},
  author       = {Nurşah Kütük and Sibel Arslan},
  doi          = {10.1016/j.engappai.2025.112640},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112640},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Removal of cationic dyes from aqueous solutions using agricultural waste: Modeling the biosorption process with semantic immune plasma programming},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-enhanced fault hierarchical perception for dissolved gas analysis in power transformer. <em>EAAI</em>, <em>162</em>, 112639. (<a href='https://doi.org/10.1016/j.engappai.2025.112639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dissolved Gas Analysis (DGA) is a widely used technique for diagnosing power transformer faults by monitoring the gas content in transformer oil to identify potential issues. However, existing research often treats dissolved gas samples as loosely connected independent entities, failing to explicitly model the relationships between them. Moreover, the similarity between faults caused by different factors can sometimes be higher than that between faults caused by the same factor, highlighting the need for hierarchical modeling of fault relationships to improve diagnostic performance. To address these challenges, we propose a graph-enhanced fault hierarchical perception model for DGA. In this work, a K -Nearest Neighbors ( K NN) graph is constructed by calculating the similarity between DGA samples in the transformer oil to capture potential associations between samples. To further enhance the learning of sample representations, we generate two augmented views by randomly perturbing node features and edges to capture information about different local structures in the graph. Additionally, we introduce a consistency constraint to ensure that the prediction results from the two augmented views remain consistent. Furthermore, we design a hierarchical perception-based ranking strategy that ranks fault similarities at a fine-grained level, effectively utilizing hierarchical fault information to optimize the model. Extensive experimental results demonstrate that the proposed model achieves high accuracy and strong generalization performance in fault-type prediction.},
  archive      = {J_EAAI},
  author       = {Yingyue Zhang and Huifang Ma and Yuwei Gao and Shengjiang Peng and Ruijia Zhang},
  doi          = {10.1016/j.engappai.2025.112639},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112639},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph-enhanced fault hierarchical perception for dissolved gas analysis in power transformer},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Full autonomy in underwater robotics systems: A realistic prospect?. <em>EAAI</em>, <em>162</em>, 112638. (<a href='https://doi.org/10.1016/j.engappai.2025.112638'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous Underwater Systems (AUS) are transforming underwater exploration, environmental monitoring, and subsea operations by reducing reliance on human intervention. This review explores the advancements and challenges in achieving full operational autonomy in AUS, focusing on navigation, perception, communication, energy management, control systems, and decision-making frameworks. Current systems predominantly exhibit partial autonomy, performing pre-defined missions with limited adaptability. However, advancements in hybrid localisation techniques, multi-modal sensor fusion, and Artificial Intelligence (AI)-driven decision-making are pushing the boundaries of autonomy, enabling AUS to adapt dynamically to complex underwater environments. The integration of subsystems remains a central challenge. Navigation systems address positional drift through cooperative approaches, while perception systems enhance environmental understanding via sensor fusion. Communication technologies, although constrained by underwater limitations, are advancing through hybrid protocols that strike a balance between bandwidth and range. Energy management is evolving with innovations in battery technology, energy harvesting, and predictive resource allocation. Control systems, increasingly incorporating AI-based frameworks, translate mission commands into precise actions, bridging the gap between decision-making and physical execution. Decision-making frameworks synthesise inputs from all subsystems, enabling real-time prioritisation and adaptive behaviour. Despite significant progress, achieving full autonomy requires further innovation in subsystem integration, real-time processing, and environmental adaptability. This review emphasises the need for modular architectures and standardised protocols to ensure interoperability and scalability. The potential of fully autonomous underwater systems extends beyond technical achievements, offering profound implications for ocean exploration, resource sustainability, and environmental stewardship. The question posed – Full Autonomy in Underwater Systems: A Realistic Prospect? – is addressed with cautious optimism. While partial autonomy is well within reach, achieving full autonomy depends on sustained innovation across multiple domains. This manuscript provides a comprehensive roadmap for advancing AUS, laying the foundation for transformative advancements in one of Earth’s least understood frontiers.},
  archive      = {J_EAAI},
  author       = {Ali Rohan and Hamidreza Farhadi Tolie and Md Junayed Hasan and Somasundar Kannan},
  doi          = {10.1016/j.engappai.2025.112638},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112638},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Full autonomy in underwater robotics systems: A realistic prospect?},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and implementation of deep learning-based framework for multi-class fault diagnosis in complex chemical process systems. <em>EAAI</em>, <em>162</em>, 112630. (<a href='https://doi.org/10.1016/j.engappai.2025.112630'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis in modern chemical plants is increasingly challenging due to process complexity, nonlinearity, and high-risk operations, where undetected faults can cause severe safety and economic consequences. Conventional machine learning (ML) models suffer from reliance on handcrafted features, poor generalization in high-dimensional spaces, and limited labeled data, resulting in reduced diagnostic performance. To overcome these challenges, we propose a scalable deep learning (DL) framework for multi-class fault diagnosis in chemical processes. The framework employs convolutional neural networks (CNN), autoencoders (AE), and long short-term memory (LSTM) networks to automatically extract spatial and temporal features from multivariate process data. Validated on the Tennessee Eastman process (TEP) benchmark, CNN achieved the highest diagnostic performance, with 88 % accuracy, 91 % precision, and 89 % F1-score. AE also performed strongly, with 85 % accuracy and 82 % F1-score, while LSTM achieved 71 % accuracy and 75 % F1-score, all outperforming conventional machine learning models, which scored between 48 % and 52 % accuracy. Superior AUC scores (micro-average: 1.00; macro-average: 0.99) confirm the framework's robustness, including in detecting overlapping and rare faults. The proposed two-phase approach, offline training and real-time monitoring, offers a practical solution for improving fault diagnosis accuracy, adaptability, and early warning capabilities in industrial processes.},
  archive      = {J_EAAI},
  author       = {Remigius Nnadozie Ewuzie and Shivaneswar Gunasekaran and Zainal Ahmad and Norazwan Md Nor},
  doi          = {10.1016/j.engappai.2025.112630},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112630},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Design and implementation of deep learning-based framework for multi-class fault diagnosis in complex chemical process systems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural network approach on forecasting the engine emission using biodiesel fuel from fish oil based on injection pressure and engine operating parameters. <em>EAAI</em>, <em>162</em>, 112628. (<a href='https://doi.org/10.1016/j.engappai.2025.112628'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the influence of injection pressure on the performance and emission characteristics of a diesel engine fueled with biodiesel derived from basa fish oil blended with conventional diesel (B10, B20, and B30). Experiments were performed at injection pressures ranging from 400 to 800 bar, with 600 bar as the baseline, on an engine operating at 1400 revolutions per minute (rpm). The results indicated that reducing the injection pressure to 500 bar increased emissions of carbon monoxide (CO), hydrocarbons (HC), and smoke, while nitrogen oxides (NOx) emissions decreased. At 500 bar compared to 600 bar, CO, HC, and smoke rose by up to 23.4 %, 10.0 %, and 32.0 %, respectively, whereas NOx decreased by up to 9.1 %. Conversely, at 700 bar, CO, HC, and smoke emissions decreased by up to 20.3 %, 6.7 %, and 28.4 %, while NOx increased by up to 12.7 %. Furthermore, an exhaust emission prediction model was developed using an Artificial Neural Network (ANN) based on injection pressure and engine operating parameters. The ANN model achieved high predictive accuracy, with the coefficient of determination (R 2 ) exceeding 0.995 and root mean square error (RMSE) values as low as 0.49975 % for smoke. These findings demonstrate that injection pressure significantly affects emission trade-offs in diesel engines operating with biodiesel blends. In addition, the ANN model proves to be a reliable tool for predicting and controlling engine emissions, supporting the potential of biodiesel as a sustainable alternative fuel.},
  archive      = {J_EAAI},
  author       = {Nguyen Van Tuan and Nguyen Xuan Khoa and Nguyen Tuan Nghia},
  doi          = {10.1016/j.engappai.2025.112628},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112628},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A neural network approach on forecasting the engine emission using biodiesel fuel from fish oil based on injection pressure and engine operating parameters},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fuzzy decision-making method for unloading command at crushing stations based on deep learning and dynamic coal flow features slicing. <em>EAAI</em>, <em>162</em>, 112617. (<a href='https://doi.org/10.1016/j.engappai.2025.112617'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The contemporary world hosts numerous open-pit coal mines, as mining efficiency increases, the unloading process of the crushing station still relies on manual command. Adversely affected by the harsh production environment and the high-intensity fatigue of operators, incorrect unloading commands can lead to issues, such as blockages at the receiver bin discharge outlet and coal swelling in the crushing chamber, resulting in production accidents. To address this issue, this study analyzes the dynamic characteristics of the coal flow in the receiver bin, in addition, monitors the bin status in real time through the camera, combining a lightweight selective kernel network (Li-SKNet) with the average classification confidence from a small segment of consecutive video frames to assess the suitability of unloading conditions. By introducing a convolutional kernel attention mechanism, the model achieved a classification accuracy of 99.8 %, subsequently, in order to adapt to the changes in the working conditions of the crushing station, a segmented fuzzy function is proposed to further optimize the model inference results. Finally, an intelligent unloading command system for the crushing station is established, which has been put into production and operated stably for six months. In comparison to traditional manual commanding methods for unloading, the system has approximately demonstrated a 15 % increase in production efficiency.},
  archive      = {J_EAAI},
  author       = {Tongyu Cui and Yongtai Pan and Yankun Bi and Zhen Liu and Jiacheng Huang and Bingjia Liu},
  doi          = {10.1016/j.engappai.2025.112617},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112617},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A fuzzy decision-making method for unloading command at crushing stations based on deep learning and dynamic coal flow features slicing},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting the cyclic behavior and strength-weakening effect of saturated clays using artificial neural network. <em>EAAI</em>, <em>162</em>, 112616. (<a href='https://doi.org/10.1016/j.engappai.2025.112616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cyclic behavior of soft cohesive soils under shear loads is characterized by progressively increasing strain and by the growth of the pore pressure that can lead to an effective stress reduction and, eventually, to the sudden failure of the soil, both risks with evident engineering safety implications. Although this problem has received much attention in research, most present approaches can only predict some parameters of the clay performance separately, commonly leading to highly complex approaches requiring extensive training and expertise. The present research uses an Artificial Neural Network (ANN) and machine learning to predict the cyclic behavior of the soft clays in the investigated site, considering for the first time all the relevant parameters that characterize the problem. The proposed ANN includes 9 inputs, two hidden layers with 10 neurons each, and five outputs. Nine inputs include the vertical effective consolidation pressure, parameters from the monotonic shear test, and defined input variables from the cyclic simple shear test. As outputs, the net considers five different results, including the various parameters of the shear strain response for each cycle, the maximum number of cycles, and the pore pressure increase. The resulting ANN shows predictions with high accuracy, with R = 0.995, and individual errors below 10 % in most cases. No prior training or experience is required to use the ANN, and it can be confidently used as an alternative to other analytical and numerical approaches for analyzing clay cyclic behavior, as long as the input values fall within the defined ranges.},
  archive      = {J_EAAI},
  author       = {M.A. Millán and R. Galindo and A. Viana da Fonseca and H. Patiño},
  doi          = {10.1016/j.engappai.2025.112616},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112616},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Predicting the cyclic behavior and strength-weakening effect of saturated clays using artificial neural network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synergistic co-evolution with neural networks for evolutionary optimization. <em>EAAI</em>, <em>162</em>, 112614. (<a href='https://doi.org/10.1016/j.engappai.2025.112614'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary computation (EC) algorithms, which simulate natural selection and genetic mechanisms, are widely applied to solve complex optimization and search problems. During the evolutionary process, EC algorithms inherently generate a wealth of evolutionary data. However, conventional EC algorithms often fail to effectively utilize this data, limiting their optimization effectiveness and overall performance. Neural networks, known for their powerful learning capabilities, excel in extracting features and recognizing patterns within large datasets. They can automatically identify complex relationships through their hierarchical architectures. Inspired by this, we propose a neural-synergized co-evolutionary optimization (NSCO) framework that integrates neural networks to learn from successfully evolved individuals during the EC process. This approach extracts valuable evolutionary knowledge to guide algorithms toward improved solutions and higher-quality data. Additionally, the enhanced data enables neural networks to derive richer evolutionary insights, creating a positive feedback loop that consistently improves performance. Notably, this framework operates without the need for additional expert knowledge, relying solely on the data generated by the algorithms themselves. To validate its effectiveness, we integrate this framework with 10 distinct EC algorithms and evaluate its performance using the CEC2014 benchmark suite. Results demonstrate significant enhancements in the algorithms’ performance.},
  archive      = {J_EAAI},
  author       = {Kun Bian and Juntao Zhang and Hong Han and You Zhou and Yifei Sun and Shi Cheng and Jun Zhou},
  doi          = {10.1016/j.engappai.2025.112614},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112614},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Synergistic co-evolution with neural networks for evolutionary optimization},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of environmental emergency treatment technologies using the interval pythagorean neutrosophic set. <em>EAAI</em>, <em>162</em>, 112611. (<a href='https://doi.org/10.1016/j.engappai.2025.112611'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, the problem of environmental pollution is severe both domestically and internationally, hindering social development. Therefore, strengthening environmental protection and improving the ability to manage environmental emergencies are urgently needed. Based on this situation, this paper proposes an evaluation model for environmental emergency treatment techniques (EETTs) using the interval Pythagorean neutrosophic (IPN) set for the first time. First, the IPN is introduced, and the operating rules and fractional/exact functions of IPN numbers are defined. Second, to apply IPN numbers to multi-attribute decision-making, two types of aggregation operators (IPN weighted arithmetic average (IPNWAA) operator and IPN weighted geometric average (IPNWGA) operator) are proposed. Finally, the evaluation index system and model for EETTs are constructed, and the rationality of the model is verified through an example involving computer data processing. According to the evaluation results, enterprises can identify their strengths and weaknesses in coping with environmental emergency treatment and take corresponding corrective measures in time to improve their emergency treatment capabilities. Therefore, this study has important scientific value and practical significance.},
  archive      = {J_EAAI},
  author       = {Changxing Fan},
  doi          = {10.1016/j.engappai.2025.112611},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112611},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Evaluation of environmental emergency treatment technologies using the interval pythagorean neutrosophic set},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamic consensus-based decentralized method for multiple unmanned aerial vehicles cooperative target allocation. <em>EAAI</em>, <em>162</em>, 112609. (<a href='https://doi.org/10.1016/j.engappai.2025.112609'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates multiple unmanned aerial vehicles dynamic target allocation problem with capability-requirement matching constraints. The objective is to achieve conflict-free allocation through distributed collaboration under a dynamic environment. To address this problem, we propose a decentralized method named Dynamic Consensus-Based Group Algorithm (DCBGA). This algorithm utilizes a rule-based method known as State-Event-Condition-Action (SECA) as the decision-making framework. In addition, this algorithm consists of iterations between two phases: target selection and conflict resolution. In the target selection phase, each unmanned aerial vehicle (UAV) selects targets in a market-based method and follows the principle of “capability-requirement matching”. In the conflict resolution phase, a consensus-based mechanism is designed so that each UAV communicates with its neighbors to generate a conflict-free allocation result. In the simulation section, this paper performs convergence analysis, sensitivity analysis, and optimization comparisons. The simulation results confirm both the convergence and robustness of the DCBGA. Furthermore, the comparison results demonstrate that the proposed algorithm exhibits better optimization performance than other advanced algorithms.},
  archive      = {J_EAAI},
  author       = {Han Wang and Xiaolong Liang and Jiaqiang Zhang and Aiwu Yang},
  doi          = {10.1016/j.engappai.2025.112609},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112609},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A dynamic consensus-based decentralized method for multiple unmanned aerial vehicles cooperative target allocation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Biological visual-cognition-inspired deep network for short-term significant wave height prediction. <em>EAAI</em>, <em>162</em>, 112607. (<a href='https://doi.org/10.1016/j.engappai.2025.112607'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of Significant Wave Height (SWH) is essential to optimize wave energy conversion efficiency. However, ocean waves' stochastic and nonlinear characteristics make traditional models face the challenges of insufficient accuracy and limited interpretability. In this paper, we propose a deep network based on a biological visual cognitive mechanism, which significantly improves the short-term SWH prediction performance inspired by the functional principles of the human visual system's hierarchical perception, hemispheric collaboration and attentional decision-making mechanism. The model consists of three components: (1) a visual-spatial pyramid component, which gradually extracts local to global features through a multi-scale convolutional kernel; (2) a brain analysis component, which combines gated recurrent unit (GRU) and convolutional neural network (CNN) to capture spatiotemporal dependencies and enhance the stability through residual connectivity, respectively; and (3) an attention-driven prediction component, which dynamically filters the key features to improve the prediction accuracy. Experiments based on two real-world buoy sites show that the proposed method reduces the mean absolute percentage error (MAPE) to 5.56 % and 6.30 %, respectively. The energy capture error (ΔP) is reduced to 10.93 % and 13.02 %, respectively, and remains robust under extreme sea states. This work can effectively improve the prediction accuracy and operational reliability of industrial ocean energy systems under complex ocean conditions.},
  archive      = {J_EAAI},
  author       = {Liao Fang and Weimin Wu and Feifei Cao and Zhenguan Cao and Guodong Fan and Lin Cui and Frede Blaabjerg},
  doi          = {10.1016/j.engappai.2025.112607},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112607},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Biological visual-cognition-inspired deep network for short-term significant wave height prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-based video interpolation via complementary motion information. <em>EAAI</em>, <em>162</em>, 112606. (<a href='https://doi.org/10.1016/j.engappai.2025.112606'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video frame interpolation, the task of synthesizing intermediate frames to increase temporal resolution, often struggles with complex scenarios when constrained by the assumption of linear motion The advent of event cameras has led to significant progress in addressing this issue. Event cameras, with microsecond-level temporal resolution, bridge the gap between frames by providing accurate motion cues. However, current event-based video frame interpolation methods often overlook that event data primarily offers high-confidence features at scene edges during multi-modal feature fusion, which may limit the contribution of event signals to optical flow estimation. To address this, we propose a novel end-to-end learning framework that explicitly leverages the complementary characteristics of event signals and frames. Our method synergistically fuses dense contextual information from frames with sparse but precise edge motion from events via a proposed Edge Guided Attention (EGA) module. The EGA employs a coarse-to-fine strategy, where event-based optical flow directly refines the frame-based motion estimation at each level of a pyramidal architecture. Additionally, we introduce an event-based visibility map, co-learned within our event-processing network, to adaptively mitigate occlusions during the warping process. Extensive experiments conducted on a diverse suite of six benchmarks, including four synthetic and two real-world datasets validate the effectiveness of this novel approach. A dedicated discussion of the method’s trade-offs and potential limitations is presented in the Limitations section.},
  archive      = {J_EAAI},
  author       = {Yuhan Liu and Linghui Fu and Hao Chen and Zhen Yang and Youfu Li and Yongjian Deng},
  doi          = {10.1016/j.engappai.2025.112606},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112606},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Event-based video interpolation via complementary motion information},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time dynamic coordinated optimization control with near-global optimal learning for connected plug-in hybrid electric vehicles. <em>EAAI</em>, <em>162</em>, 112602. (<a href='https://doi.org/10.1016/j.engappai.2025.112602'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the application of connected technologies, such as vehicle-to-vehicle and vehicle-to-cloud communication in connected vehicles to obtain various traffic information, it is crucial to balance the optimality and computational burden of the energy management strategy for further improving the fuel economy of the connected plug-in hybrid electric vehicle. Another key factor affecting the improvement of fuel economy and control performance in connected plug-in hybrid electric vehicles is the fluctuation in driving torque resulting from the different response characteristics of the engine and motor during mode switching of the powertrain for the power distribution of the energy management strategy. To address these challenges, this paper proposes a novel real-time dynamic coordinated optimization control scheme that incorporates energy management at the upper layer and adaptive coordination at the lower layer for the connected plug-in hybrid electric vehicle in a vehicle-following scenario. Based on the offline optimal control rules extracted by the extreme learning machine, which possesses good generalization capabilities, the upper-layer guided model predictive control for energy management is implemented by applying the particle swarm optimization algorithm within variable horizons across different road sections. The bottom-layer adaptive fixed-time control scheme, equipped with a coordinated mechanism, is designed to address transient response deviations in the upper-layer results. The effectiveness and advantages of the proposed hierarchical scheme are validated through both the co-simulation platform and a hardware-in-loop test.},
  archive      = {J_EAAI},
  author       = {Jiaqi Xue and Chao Yang and Jiayi Fang and Xiao Zhang and Muyao Wang},
  doi          = {10.1016/j.engappai.2025.112602},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112602},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Real-time dynamic coordinated optimization control with near-global optimal learning for connected plug-in hybrid electric vehicles},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multichannel framework for multitask learning fusion in modulation recognition tasks. <em>EAAI</em>, <em>162</em>, 112601. (<a href='https://doi.org/10.1016/j.engappai.2025.112601'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic modulation recognition is an essential process linking signal detection to signal demodulation, and it is a promising technology for improving spectrum usage efficiency in cognitive radio. With the advent of fifth generation mobile communication technology, wireless communication systems have had massive data throughput. As a result, integrating artificial intelligence techniques with modulation recognition has emerged as a key focus area in the communication sector. To enhance the precision of signal modulation recognition, this study proposes a multitask learning fusion multichannel network modulation recognition framework—Multitask Residual Convolution Long Short Memory-Transformer Deep Neural Network. The primary task network is a two stream network composed of Convolutional Neural Network module, Long Short-Term Memory module and Transformer-Encoder module, allowing for the simultaneous extraction of both time and frequency features from the signal. The auxiliary task network is composed of residual convolution module paired with Transformer-Encoder module, designed for extracting the power spectral density characteristics of straightforward signals. Ultimately, the features derived from both the primary task network and the auxiliary task network are combined. The auxiliary network enhances the primary task network’s ability to characterize features, thereby boosting the neural network’s overall versatility and precision. The experimental findings indicate that the proposed model achieved peak recognition accuracies of 99.73%, 93.9%, and 94.1% on the three datasets, respectively. Moreover, the recognition accuracy of the proposed model is better than the baseline model in the low Signal-to-Noise Ratio environment (-18 decibel ∼ 0 decibel).},
  archive      = {J_EAAI},
  author       = {Wenshi Xiao and Zhongqiang Luo and Mengxuan Lan},
  doi          = {10.1016/j.engappai.2025.112601},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112601},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multichannel framework for multitask learning fusion in modulation recognition tasks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy-efficiency prediction of fluid machinery based on knowledge-aided ensemble learning. <em>EAAI</em>, <em>162</em>, 112600. (<a href='https://doi.org/10.1016/j.engappai.2025.112600'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fluid machinery is a type of high-energy-consumption equipment. Accurate prediction of energy efficiency enables the optimization of energy management and enhances equipment performance. However, factors such as equipment aging, sensor anomalies, and complex interferences pose challenges to accurately predicting energy efficiency solely through knowledge-based models or machine learning approaches. To address this issue, a fluid machinery energy efficiency prediction method based on knowledge-aided ensemble learning is proposed by integrating mechanistic knowledge and machine learning. During data repair, the physical characteristics of fluid machinery are used to identify condition anomalies, and a sliding window-based Local Outlier Factor (WLOF) algorithm is designed to identify other types of anomalies. Different types of anomalies are repaired using mechanistic knowledge and eXtreme Gradient Boosting (XGBoost), respectively. The preprocessed data is subsequently employed to train models for energy efficiency prediction. This method has been applied to predict the energy efficiency of fans in a large-scale steel plant. Compared with various energy efficiency prediction models, the application results show that the prediction based on Knowledge-WLOF-XGBoost exhibits higher accuracy and robustness than single physical models or machine learning models.},
  archive      = {J_EAAI},
  author       = {Weijian Kong and Rong Zhuo and Linfu Zheng},
  doi          = {10.1016/j.engappai.2025.112600},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112600},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Energy-efficiency prediction of fluid machinery based on knowledge-aided ensemble learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pretrained transformers for multimodal fake news detection: Explainability using SHapley additive exPlanations for contributions from text, image, and image captions. <em>EAAI</em>, <em>162</em>, 112590. (<a href='https://doi.org/10.1016/j.engappai.2025.112590'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The wide use of Online Social Networks (OSNs) for news consumption necessitates the identification and flagging of fake news to reduce its negative impacts. Existing research mostly emphasizes deep learning techniques that examine textual features or combinations of text and images for the detection of fake news. In this study, we propose two enhanced models for fake news detection. First, we present a multimodal framework that leverages Vision Transformer embeddings for image representation instead of traditional Convolutional Neural Network (CNN) features, which achieves significant improvements over baseline approaches. Second, we implemented an image caption-augmented multimodal model that integrates image captions as an additional modality alongside text and images. Caption embeddings act as semantic bridges that strengthen cross-modal alignment and contextual understanding. The experiments conducted on the FakeNewsNet and Fakeddit datasets show that the model incorporating image captions consistently surpasses the baseline BERT-VIT framework. It achieves improvements of up to +7.9% in accuracy, +11.5% in precision, and +5.3% in the F1-score, while still maintaining competitive levels of recall and Area Under the Curve (AUC). Statistical significance testing verifies the reliability of these enhancements. Additionally, a SHapley Additive exPlanations (SHAP)-based analysis highlights the contribution of each modality, which enhances the interpretability of the proposed framework.},
  archive      = {J_EAAI},
  author       = {Athira A.B. and S.D. Madhu Kumar and Anu Mary Chacko},
  doi          = {10.1016/j.engappai.2025.112590},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112590},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Pretrained transformers for multimodal fake news detection: Explainability using SHapley additive exPlanations for contributions from text, image, and image captions},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing the morphological quality of zizania latifolia shoot based on instance segmentation. <em>EAAI</em>, <em>162</em>, 112589. (<a href='https://doi.org/10.1016/j.engappai.2025.112589'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The breeding of Zizania latifolia primarily relies on the cross-regional introduction of varieties and manual selection, which involves the assessment of morphological quality. Traditional methods are time-consuming and labor-intensive. This paper proposed a morphological assessment method based on instance segmentation. Assessment indicators, including enlargement degree, color, straightness, and slenderness, were defined according to national grading standards and expert knowledge to provide a comprehensive assessment framework. For the segmentation task, the irregular contours, similar internal regions, and indistinct boundaries pose significant challenges. Additionally, classification heavily relies on the spatial relationships. To solve these problems, this study proposed a sub-stem segmentation algorithm, which based on You Only Look Once Version 8 (YOLOv8). The Linear Deformable Convolution (LDConv) module was employed to recognize irregular sub-stems through learnable offsets. Next, the Efficient Multi-Scale Attention (EMA) mechanism was added to refine image features by emphasizing the interactions between channels and spatial dimensions. We also employed the Wise Intersection over Union Version 3 (WIoU v3) loss function, which evaluated the anchor box quality based on outlier degree. The proposed model outperformed YOLOv8 and other state-of-the-art models on the Zizania latifolia dataset, achieving Precision, Recall, and mean Average Precision (mAP) values of 95.3 %, 93.9 %, and 97.7 %. Additionally, our model achieved 35.7 % mAP on the Microsoft Common Objects in COntext (MS COCO) dataset. Based on the segmentation results, we extracted phenotypic parameters, such as height, width, and two-dimensional area. We determined the top-10 individuals with superior morphological quality among 65 varieties, providing robust support for Zizania latifolia breeding.},
  archive      = {J_EAAI},
  author       = {Chenmin Yang and Shanyong Wang and Tingting Lou and Ruiqi Song and Huanliang Xu and Zhaoyu Zhai},
  doi          = {10.1016/j.engappai.2025.112589},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112589},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Assessing the morphological quality of zizania latifolia shoot based on instance segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A combined adaptive gaussian short-term fourier transform and mamba framework for stock price prediction. <em>EAAI</em>, <em>162</em>, 112588. (<a href='https://doi.org/10.1016/j.engappai.2025.112588'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In financial investment, predicting stock prices precisely is challenging due to the inherent volatility and non-stationarity of market data. To address this, we propose a pioneering hybrid approach, introducing the Adaptive Gaussian Short-Time Fourier Transform (AG-STFT) in Mamba for the first time—it dynamically adjusts the window size based on frequency content to enhance the representation of non-stationary modes. We further present AGSMNet, a novel hybrid architecture fusing AG-STFT with the Mamba framework, which addresses the dual-domain modeling challenge (time + frequency) through an end-to-end deep learning solution leveraging both signal processing and structured state-space modeling techniques, enabling robust sequence modeling with enhanced temporal and spectral sensitivity. The AG-STFT dissects and represents temporal and spectral features of stock price movements, capturing dynamics often overlooked by traditional models, while Mamba — known for discerning complex patterns — enhances predictive capabilities. The model employs a Multiple Feature Extraction (MFE) module for shallow features and a Residual State-Space Group (RSSG) module for deep features, fed into a predictor module to predict next-day prices. Extensive experiments across ten major stock and index datasets demonstrate that AGSMNet consistently achieves the lowest MAE, MSE, and RMSE, and the highest R 2 values, outperforming leading models such as TimesNet, Autoformer, and MambaStock. These results confirm AGSMNet’s superior generalization, robustness across volatile markets, and practical effectiveness. It is applicable to non-stationary datasets, outperforms traditional, machine learning, and deep learning-based methods, and shows potential as a transformative tool for financial analysts and investors, with adaptability to other financial modeling areas promising advancements in predictive analytics.},
  archive      = {J_EAAI},
  author       = {Yuling Huang and Zhiyuan Pei and Jin Yan and Chujin Zhou and Xiaoping Lu},
  doi          = {10.1016/j.engappai.2025.112588},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112588},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A combined adaptive gaussian short-term fourier transform and mamba framework for stock price prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Driver risk classification for transportation safety: A machine learning approach using psychological, physiological, and demographic factors with driving simulator. <em>EAAI</em>, <em>162</em>, 112585. (<a href='https://doi.org/10.1016/j.engappai.2025.112585'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving behavior is a critical factor in ensuring road safety, particularly in commercial transportation sectors where hiring safe and reliable drivers is a priority. This study presents a machine learning-based framework for predicting driver behavior using multimodal assessments, including psychological, physiological, and demographic factors. We utilized a driving simulator equipped with biometric sensors to capture the physiological data of the driver, including heart rate, eye blink rate, pupil diameter, and point of gaze (POG), during driving sessions. The psychological attributes are collected through a self-report questionnaire. The questionnaire is structured to obtain information about nine psychological characteristics of the driver, including instrumental attitude, social anxiety, sensation seeking, premeditation, urgency, selfishness, aggressive mode, life satisfaction, and conscientiousness. In addition, some demographic attributes, such as age and gender, are also adopted to study their effect on driving behavior. Experiments were conducted on 80 participants, each driving for 10 min. Various machine learning models, along with a feature selection strategy, were used to find the relationship between the driver's modalities and his driving behavior. Results demonstrate that the k-nearest neighbors (KNN) model achieved the best performance, yielding an accuracy of 93.75 % and a False Negative Rate (FNR) of 0. Feature importance analysis revealed that gaze distraction, sensation seeking, conscientiousness, and gender are the best predictors of driving behavior. The findings suggest that our model can serve as a valuable decision-support tool for taxi companies and transportation agencies aiming to enhance driver selection processes by identifying drivers with lower accident risks.},
  archive      = {J_EAAI},
  author       = {Malek Masmoudi and Yasmin Shakrouf and Omar Hassan Omar and Amir Shikhli and Fatima Abdalla and Wadad Alketbi and Imad Alsyouf and Ali Cheaitou and Anwar Jarndal and Ali I. Siam},
  doi          = {10.1016/j.engappai.2025.112585},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112585},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Driver risk classification for transportation safety: A machine learning approach using psychological, physiological, and demographic factors with driving simulator},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A credibility and consistency-oriented stochastic aggregation framework for heterogeneous multi-attribute large-scale group decision making with several attribute sets. <em>EAAI</em>, <em>162</em>, 112584. (<a href='https://doi.org/10.1016/j.engappai.2025.112584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In large-scale group decision making, experts usually provide their individual preferences on attribute values, as well as attribute sets. The coexistence of large-scale heterogeneous information poses a significant challenge to the credibility and consistency on decision making. To this issue, the paper proposes a credibility and consistency-oriented stochastic aggregation framework, including four primarily research points. Firstly, a simplified transformation method is developed to convert heterogeneous attribute values into individual attribute superiority-probability-based pairwise comparison matrix (IA-SPMs), which saves transformation cost as well as provides abundant references for credibility analysis. Secondly, the deviation-based credibility measures and the credibility-based weighting methods are proposed. Thirdly, a cluster-based aggregation operator is introduced by considering group consistent preferences on attributes selection to get the collective SPM (C-SPM). Fourthly, the ranking probability matrix (RPM) and the possibility ranking result are calculated based on the C-SPM. Using experiment and application analyses we illustrate that the proposed methods can enhance the credibility of decision outcomes, as well as the stability of the results. This research can provide technical support for effective fusion of heterogeneous information from multiple sources in the artificial intelligence (AI) era, and has broad application potential in large-scale democratic decision making and pre-evaluation engineering projects.},
  archive      = {J_EAAI},
  author       = {Weiwei Li and Pingtao Yi and Danning Zhang},
  doi          = {10.1016/j.engappai.2025.112584},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112584},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A credibility and consistency-oriented stochastic aggregation framework for heterogeneous multi-attribute large-scale group decision making with several attribute sets},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic machine learning with a cascaded framework for robust failure mode classification and capacity estimation of rectangular concrete-filled steel tube columns under axial compression. <em>EAAI</em>, <em>162</em>, 112581. (<a href='https://doi.org/10.1016/j.engappai.2025.112581'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study develops an advanced probabilistic machine learning (ML) framework to predict failure modes and axial load-bearing capacity of rectangular concrete-filled steel tube (CFST) columns, addressing critical challenges of class imbalance and prediction uncertainty. Leveraging a comprehensive dataset of 597 experimental samples, a rigorous feature selection procedure is conducted to optimize the ML applications. Three ML models are developed and evaluated: a deterministic approach (Random Forest) and two probabilistic models (Gaussian Process and Natural Gradient Boosting, NGBoost). To address the issue of class imbalance in failure mode classification, a hybrid resampling strategy combining the Synthetic Minority Over-sampling Technique and Tomek Links method (SMOTE-Tomek) is implemented. Furthermore, A novel classification-regression cascaded framework is proposed, where failure modes are first classified, followed by category-specific regression for capacity prediction. Results demonstrate that SMOTE-Tomek significantly improves minority failure mode classification, increasing the average F1-scores by 8.1 % (for flexural failure) and 118.2 % (for combined failure). The cascaded framework outperforms direct regression in estimating capacity, achieving a 56 % higher coefficient of determination (R 2 ) and 15–30 % lower error metrics on average. NGBoost excels in both probabilistic failure mode prediction and uncertainty-aware capacity estimation, enabling reliability-based design and risk-informed decision-making for CFST structures in engineering practice.},
  archive      = {J_EAAI},
  author       = {Xueqi Zhong and Dade Lai and Qiyao Yu and Feiyu Liao},
  doi          = {10.1016/j.engappai.2025.112581},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112581},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Probabilistic machine learning with a cascaded framework for robust failure mode classification and capacity estimation of rectangular concrete-filled steel tube columns under axial compression},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing precision tomato harvesting with feature sharing and intersection screening. <em>EAAI</em>, <em>162</em>, 112580. (<a href='https://doi.org/10.1016/j.engappai.2025.112580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tomato is a significant economic crop cultivated extensively worldwide. Rapid and accurate localization of picking points is fundamental to automating the tomato harvesting process. To address this, we develop a lightweight dual-task network built upon the YOLOv10 (You Only Look Once) architecture. The backbone integrates the ADown module for efficient downsampling, and utilizes a Dysample-based cross-scale feature fusion module (CCFM) in the detection neck, while the segmentation neck employs Simulated Annealing Adaptive Concatenation (SAAC) for feature fusion. Furthermore, the conditionally restricted Hungarian algorithm is employed to match ripe tomatoes with their corresponding corollas. Two localization techniques are proposed: local skeleton line fitting and boundary intersection screening. In local skeleton line fitting, the corolla detection box is expanded, and the stem mask within this region is used to extract the skeleton line and find the intersection point. Boundary intersection screening determines whether to directly compute the midpoint of intersecting lines or use skeleton line fitting, based on the number of intersections between the stem mask and the corolla box. The detection Precision and Recall of the proposed model are 0.970 and 0.983, respectively, while the IoU (Intersection over Union) and MIoU (Mean Intersection over Union) for segmentation are 0.962 and 0.980. The localization precision for picking points is 0.922, with a recognition rate of 0.988. Achieving an average processing time of only 55.89 ms per image, the proposed artificial intelligence application exhibits excellent efficiency and accuracy in real-world conditions, offering a promising foundation for further development of automated tomato harvesting systems.},
  archive      = {J_EAAI},
  author       = {Xueke An and Bin Dai and Zhaolei Yang and Hassan H.A. Mostafa and Wang Fangyan and Yuliang Yun},
  doi          = {10.1016/j.engappai.2025.112580},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112580},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing precision tomato harvesting with feature sharing and intersection screening},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting the compression index of expansive soils with hybrid machine learning approaches. <em>EAAI</em>, <em>162</em>, 112579. (<a href='https://doi.org/10.1016/j.engappai.2025.112579'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expansive soils pose significant challenges for geo-infrastructure design, construction, and maintenance because of their moisture-induced volume changes. Despite extensive research on swelling behavior, the compression index ( C c ), an important indicator of soil compressibility has received relatively limited attention. C c is conventionally obtained from time-consuming and costly consolidation tests, while empirical equations derived from general clays may not provide reliable estimates for expansive soils. To address this gap, seven machine learning models based on five algorithms were developed to estimate the C c of expansive soils using soil properties readily obtained from conventional laboratory tests. A comprehensive dataset comprising 238 expansive soil samples, compiled from 60 years of published literature across various regions of the world, is employed to train and validate the proposed models. Among them, Model 2 based on Newton-Raphson-Based Optimizer optimized Extreme Gradient Boosting (NRBO-XGBoost) achieved the best performance, with a coefficient of determination ( R 2 ) of 0.903 and a root mean square error (RMSE) of 0.029 on the test set. Sensitivity analysis showed that the plasticity index was the most influential factor (31.1 %), followed by liquid limit (29.4 %), initial void ratio (25.3 %), and dry density (14.1 %), highlighting its primary influence on soil compressibility. Additionally, a simplified equation derived from the Multilayer Perceptron (MLP) designated as Model 4 is validated through three case studies. The settlement predictions deviated by 5–14 % from field measurements, offering a practical tool without the need for machine learning techniques. The findings provide useful guidance for developing rational design strategies for geo-infrastructures affected by expansive soils.},
  archive      = {J_EAAI},
  author       = {Aolin Zhang and Sai K. Vanapalli},
  doi          = {10.1016/j.engappai.2025.112579},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112579},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Predicting the compression index of expansive soils with hybrid machine learning approaches},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-based pre-compensator design for piezoelectric actuators based on physics guided neural network and physics-precision balanced training. <em>EAAI</em>, <em>162</em>, 112576. (<a href='https://doi.org/10.1016/j.engappai.2025.112576'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing model-based pre-compensators is crucial for achieving high-precision motion control in piezoelectric actuators (PEAs), which exhibit complex nonlinear behaviors. While data-based modeling methods offer a straightforward approach, they face challenges with poor extrapolation and high complexity. Incorporating the known physics of PEAs, which is more consistent with physical principles and computationally efficient, can help overcome these limitations. Based on the above knowledge, this paper embeds physical knowledge within a neural network, forming a novel Physics Guided Neural Network (PGNN) structure as a model-based PEA pre-compensator to achieve high motion precision. Training the PGNN is challenging due to potential competition between the physics component and the neural network. The flexible nature of the neural network can easily overshadow the physical information, leading to overfitting and rendering the PGNN model ineffective. To address this, a Physics-Precision Balanced Training (PPBT) method is proposed. In the PPBT method, the physical correctness and model precision of the PGNN are mathematically defined, and these two components are balanced through a nonlinear function within the training algorithm. Experimental results show that the proposed pre-compensator based on PGNN and PPBT outperforms physics-based approaches in precision and offers greater robustness than purely data-based methods. The peak-to-peak displacement error is reduced to less than 35 nm in open-loop control. Measured by Mean Absolute Error (MAE), this method reduces displacement errors by 89 % compared to no compensation, by 77 % compared to purely neural network-based compensation, and by 73 % compared to rate-dependent Prandtl-Ishlinskii operator-based compensation.},
  archive      = {J_EAAI},
  author       = {Qin Li and Zhiwei Ruan and Chenyang Ding},
  doi          = {10.1016/j.engappai.2025.112576},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112576},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Model-based pre-compensator design for piezoelectric actuators based on physics guided neural network and physics-precision balanced training},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-to-end burst signal demodulation via adaptive masked deep learning framework. <em>EAAI</em>, <em>162</em>, 112569. (<a href='https://doi.org/10.1016/j.engappai.2025.112569'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bit error rate (BER) directly determines the quality of wireless communication transmission. Traditional demodulators are limited in operating on burst signals and exhibit poor BER performance in low signal-to-noise ratio (SNR) conditions. For real-world burst signals, symbol-by-symbol approaches fail to capture inter-symbol dependencies, and existing end-to-end frameworks cannot handle the variable output lengths required for burst signals. To address this issue, we propose an end-to-end demodulation framework based on deep learning (DL), in which detection, recognition, channel compensation, and demodulation stages were trained as a unified system, enabling the entire signal burst to be demodulated in a single operation during inference. The framework's generalization and robustness are enhanced by a proposed masking mechanism and a denoising autoencoder (DAE), respectively. The former dynamically adjusts the output bitstream length while preventing gradient flow from redundant components, and the latter compensates for channel fading effects. We further introduce a dedicated end-to-end training strategy to optimize the adaptation between these modules. Experimental results on real-world Frequency Shift Keying (FSK), Minimum Shift Keying (MSK), Phase-Shift Keying (PSK), and Quadrature Amplitude Modulation (QAM) signals demonstrate that the proposed framework achieves superior demodulation accuracy for long-sequence burst signals. Compared to existing methods, the proposed framework enables parallel demodulation, and dynamically adapts the output bit stream in terms of varying message types and lengths.},
  archive      = {J_EAAI},
  author       = {Mingdi Li and Wenzhe Fan and Yanbin Li and Chunlei Xie and Yanan Duan},
  doi          = {10.1016/j.engappai.2025.112569},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112569},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {End-to-end burst signal demodulation via adaptive masked deep learning framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-head detector with point-driven transformer and semantic-spatial gating for liquid crystal display defects. <em>EAAI</em>, <em>162</em>, 112565. (<a href='https://doi.org/10.1016/j.engappai.2025.112565'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unique structure of liquid crystal displays (LCDs) leads to defects with specific characteristics, posing a significant challenge to defect detection. These defects mainly include global slender line defects, numerous small defects, and other defects exhibiting significant variations in scale and visual complexity. To simultaneously detect slender defects and numerous small defects, we propose a novel dual-head detector (DHDet) that combines the strengths of transformer-based and convolutional neural network (CNN)-based approaches. The transformer-based line head leverages its global context modeling capability and exploits shape priors by representing line defects using discrete points. Additionally, a slender-object query selection module is introduced to generate line proposals composed of discrete points. These proposals with spatial cues provide effective initialization for the inputs of the transformer decoder. The CNN-based box head focuses on detecting prevalent small defects and other multi-scale objects. To enhance the detection of complex and large defects, we design a semantic-modulated spatial-coordinated gating module. Through semantic guidance and spatial correlations, this module adaptively gates and weights global context from the line head’s queries to optimize top-level features for the box head. Experiments on an industrial LCD defect detection dataset and two defect datasets of manufacturing domain demonstrate our detector’s superior performance in complex defect detection tasks. Our method outperforms other state-of-the-art methods on the LCD defect dataset, achieving 67.4% mean average precision (mAP) and 88.3% mAP at an intersection over union threshold of 0.5 (mAP 50 ). The code is available at .},
  archive      = {J_EAAI},
  author       = {Chaofan Zhou and Meiqin Liu and Senlin Zhang and Shanling Dong and Ronghao Zheng and Shaoyi Du},
  doi          = {10.1016/j.engappai.2025.112565},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112565},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual-head detector with point-driven transformer and semantic-spatial gating for liquid crystal display defects},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An integrated machine learning framework for the early diagnosis of hypertension disease. <em>EAAI</em>, <em>162</em>, 112564. (<a href='https://doi.org/10.1016/j.engappai.2025.112564'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypertension is a type of disease that occurs after a serious increase in blood pressure. Due to the rapid increase in the disease, efforts for its early diagnosis are increasing day by day. The use of artificial intelligence (AI) and machine learning (ML) methods in disease detection is of great importance, especially in early diagnosis. In this study, a framework for the diagnosis of hypertension is developed. Behavioral Risk Factor Surveillance System (BRFSS) and Hypertension Risk Prediction (HRP) datasets with clinical and demographic information were used to diagnose hypertension. The problem of class imbalance in the datasets was solved by Random OverSampling method. In particular, the relationship between the attributes and the target variable was analyzed with Consistency-Based Filter, Recursive Feature Elimination with Cross-Validation (RFECV), Least Absolute Shrinkage and Selection Operator (LASSO), Information gain, Relief and Correlation-based feature selection methods and the features selected for the diagnosis of hypertension disease were taken into consideration. In the experiments, Extremely Randomized Trees (Extra Trees), Adaptive Boosting (Adaboost) and Extreme Gradient Boosting (XGBoost) machine learning methods were used in five fold cross-validation. In both datasets, the most successful results were obtained with the XGBoost algorithm. Then, for this algorithm, Random Search, Grid Search, Bayes Search and Genetic Algorithm were used for model hypertuning. For the BRFSS dataset with 87.96 % accuracy and for the HRP dataset with 97.67 % accuracy were obtained. The results are obtained with evaluation metrics that the medical world considers in evaluations, and the proposed framework for hypertension disease detection provides valuable insights for healthcare applications.},
  archive      = {J_EAAI},
  author       = {Ayşe Eldem},
  doi          = {10.1016/j.engappai.2025.112564},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112564},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An integrated machine learning framework for the early diagnosis of hypertension disease},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An explainable deep learning approach for sleep staging in sleep apnea patients across all age subgroups from pulse oximetry signals. <em>EAAI</em>, <em>162</em>, 112562. (<a href='https://doi.org/10.1016/j.engappai.2025.112562'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep-learning (DL) approaches have been developed using pulse rate (PR) and blood oxygen saturation (SpO 2 ) recordings from pulse oximetry to streamline sleep staging, particularly for obstructive sleep apnea (OSA) patients. However, lack of interpretability and validation across patients from a wide range of ages (children, adolescents, adults, and elderly OSA individuals) are two major concerns. In this study, a DL model based on the U-Net framework (POxi-SleepNet) was tailored to accurately perform 4-class sleep staging (wake, light sleep, deep sleep, and rapid-eye movement sleep) in OSA patients across all age subgroups using PR and SpO 2 signals. An explainable artificial intelligence (XAI) methodology based on semantic segmentation via gradient-weighted class activation mapping (Seg-Grad-CAM) was also applied to quantitatively interpret the time and frequency characteristics of pulse oximetry recordings that influence sleep stage classification. Overnight PR and SpO 2 signals from 17303 sleep studies from six datasets encompassing children, adolescents, adults, and elderly OSA individuals were used. POxi-SleepNet showed high performance for sleep staging in the six databases, with accuracies between 81.5 % and 84.5 % and Cohen's kappa values from 0.726 to 0.779. It also demonstrated greater generalizability than previous studies. XAI analysis showed the key contributions of mean and variability in PR and SpO 2 amplitude, as well as changes in their spectral content across specific frequency bands (0.004–0.020 Hz, 0.020–0.100 Hz, and 0.180–0.400 Hz), for sleep stage classification. These findings indicate that POxi-SleepNet could effectively automate sleep staging and assist in diagnosing OSA across all age groups in clinical settings.},
  archive      = {J_EAAI},
  author       = {Fernando Vaquerizo-Villar and Gonzalo C. Gutiérrez-Tobal and Daniel Álvarez and Adrián Martín-Montero and David Gozal and Roberto Hornero},
  doi          = {10.1016/j.engappai.2025.112562},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112562},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An explainable deep learning approach for sleep staging in sleep apnea patients across all age subgroups from pulse oximetry signals},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transient electrodynamic simulation of laser beam reflection on inclined surfaces using a generative adversarial network-based deep learning model. <em>EAAI</em>, <em>162</em>, 112561. (<a href='https://doi.org/10.1016/j.engappai.2025.112561'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In laser-material interactions, the temporal dynamics of beam reflection are crucial as they affect both laser absorption and material response. Currently, electrodynamic simulation is the most accurate method for calculating transient laser reflection and absorption patterns, but it is computationally very expensive. In this study, we present the first transient electrodynamic simulation model based on a generative adversarial network, with the time information embedded as color in the input image. The model accurately predicts reflection patterns of a laser beam on inclined surfaces using an input image containing geometric and time information of the domain. The finite-difference time-domain method was used to generate 16 data by changing the surface inclination angle from 0 o to 75 o . The model was based on a generator made by stacking a deep residual network and a discriminator. Although trained on limited data, the model predicted transient beam reflection patterns without overfitting, and the average structural similarity index measure and R-squared accuracy were 96.7 % and 98.0 %, respectively. Another deep learning model was developed to predict the laser beam absorptance from a laser beam reflection image. The ground truth absorptance values were obtained from the Fresnel equations, and the average R-squared accuracy was 99.8 %. Robustness evaluation was additionally performed to examine if the model can be used to predict reflection patterns from angled and curved surfaces. Reasonably accurate results were obtained when the angle difference was not greater than 3° for angled surfaces and the normalized curvature was 0.032 or less for curved surfaces.},
  archive      = {J_EAAI},
  author       = {Myeonggyun Son and Hyungson Ki},
  doi          = {10.1016/j.engappai.2025.112561},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112561},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transient electrodynamic simulation of laser beam reflection on inclined surfaces using a generative adversarial network-based deep learning model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mechanical properties prediction of bi-metal foam sandwiches using machine learning methods and elastic deformation behaviour. <em>EAAI</em>, <em>162</em>, 112560. (<a href='https://doi.org/10.1016/j.engappai.2025.112560'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal foam sandwiches are a kind of ultra-lightweight material made from a porous metal core bonded to two face sheets. Friction stir welding (FSW) is utilised in welding bimetal foam sandwiches. It is worth mentioning that the exact relation between mechanical properties and process parameters is challenging to determine. The innovation lies in the non-destructive estimation of mechanical properties (Young's modulus, ultimate tensile strength and fracture strain) through elastic deformation data and the novel application of artificial intelligence techniques optimised by genetic algorithms, eliminating dependency on input process parameters. After proper network training, three methods are employed to estimate these mechanical properties: a decision tree, a feedforward neural network and long-short term memory. These are chosen to investigate the influence of both machine/deep learning methods in predicting the mechanical properties of the FSW final product. Moreover, a genetic algorithm is employed to find the optimal hyperparameters of the three investigated prediction models to reach the highest accuracy. The results prove the efficiency of the proposed feedforward neural network in the estimation of Young's modulus and ultimate tensile strength for the bi-metal foam sandwiches with lower mean absolute error (MAE) and higher correlation coefficient compared to the decision tree (63.9 % lower MAE and 25.50 % higher correlation coefficient) and long-short term memory (77.50 % lower MAE and 25.05 % higher correlation coefficient). In addition, the proposed decision tree model accurately predicts the fracture strain with R-square and root mean square error as 0.61429 and 1.3862 × 10 −5 , respectively.},
  archive      = {J_EAAI},
  author       = {Mohammad Reza Chalak Qazani and Mohsen Dorudgar and Mehdi Moayyedian and Abdel-Hamid I. Mourad and Moosa Sajed and S.M. Hossein Seyedkashi and Siamak Pedrammehr},
  doi          = {10.1016/j.engappai.2025.112560},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112560},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mechanical properties prediction of bi-metal foam sandwiches using machine learning methods and elastic deformation behaviour},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal unified generalization and translation network for intelligent fault diagnosis under dynamic environments. <em>EAAI</em>, <em>162</em>, 112559. (<a href='https://doi.org/10.1016/j.engappai.2025.112559'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal data fusion can generate reliable fault representations for intelligent fault diagnosis. However, simple data fusion strategies often introduce fault-irrelevant information, thereby reducing robustness against unknown domain shifts. Moreover, traditional methods generally lack adaptive mechanisms to address missing modalities, leading to considerable performance degradation under sensor failure conditions. To address these problems, this paper proposes a multimodal unified generalization and translation network. To learn invariant unified representations for resisting unknown data distribution shifts, information-enhanced concatenation first generates intra-domain and cross-domain representations. Subsequently, mutual information maximization is applied to remove fault-unrelated information from these representations. Finally, A hybrid ensemble diagnosis strategy fully leverages the interaction of multimodal information across different levels. In addition, semantic supervision investigates the relationships among different modalities and enables intermodal translation in the event of a sensor failure within the monitoring system. Extensive experimental results based on a public bearing dataset and a self-collected motor dataset indicate that the proposed method improves accuracy by 10.53 % and 8.47 % compared to the state-of-the-art methods, respectively. The code and datasets are available at https://github.com/CHAOZHAO-1/MUGTN .},
  archive      = {J_EAAI},
  author       = {Chao Zhao and Weiming Shen and Enrico Zio and Hui Ma},
  doi          = {10.1016/j.engappai.2025.112559},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112559},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodal unified generalization and translation network for intelligent fault diagnosis under dynamic environments},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FabricMamba: A fabric surface defect detection system based on large kernel attention and visual state space. <em>EAAI</em>, <em>162</em>, 112558. (<a href='https://doi.org/10.1016/j.engappai.2025.112558'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the textile manufacturing industry, fabric defect detection is essential for ensuring product quality. Traditional approaches based on Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) often encounter scalability issues, particularly due to the high computational complexity of the self-attention mechanism in ViTs. To address these limitations, this study introduces FabricMamba, a real-time defect detection framework built on the You Only Look Once version 8 (YOLOv8) CNN architecture. The model enhances detection precision and efficiency for complex fabric defects in high-resolution images while minimizing computational cost. YOLOv8 was selected as the base model due to its strong balance between accuracy and inference speed, which is critical in fast-paced textile production settings. FabricMamba extends YOLOv8 with several innovations: the Parallel Large Separable Kernel Attention (P-LSKA) mechanism for multi-scale perception, the Visual State Space Module (MVSS) for long-range dependency modeling, the lightweight DySample module for reduced resource usage, and Programmable Gradient Information (PGI) to optimize training without increasing inference complexity. Extensive evaluations were conducted using a proprietary industrial fabric defect dataset and two public benchmarks, TILDA Textile Texture Database and FDDS Object Detection Dataset. FabricMamba achieved a mean Average Precision (mAP) of 90.0 %, 97.7 %, and 39.1 % on the respective datasets, outperforming the YOLOv8 baseline by 1.8 %, 2.3 %, and 2.0 %. Compared to Mamba-YOLO, FabricMamba reduced model size and computational requirements by 36.7 % and 33.1 %, respectively, with recall improving by 2.9 %, 1.4 %, and 4.0 %. These results confirm the model effectiveness and practical potential for industrial fabric inspection tasks.},
  archive      = {J_EAAI},
  author       = {Nengsheng Bao and Jiajun Lin and Yuchen Fan and Runxuan Bao and Alessandro Simeone},
  doi          = {10.1016/j.engappai.2025.112558},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112558},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {FabricMamba: A fabric surface defect detection system based on large kernel attention and visual state space},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing performance metrics with new distance and similarity measures using control parameters of linear diophantine fuzzy sets. <em>EAAI</em>, <em>162</em>, 112557. (<a href='https://doi.org/10.1016/j.engappai.2025.112557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The control parameters (CPs) of linear Diophantine fuzzy sets (LDFSs) provide an innovative approach for information analysis in the multi-criteria decision making (MCDM), machine learning (ML), and computational intelligence (CI). The CPs give freedom to the decision-makers in evaluating feasible alternatives in measuring performance metrics. Previous fuzzy MCDM methods often meet strict limitations in handling real-world uncertainty and dynamic MCDM. To overcome these limitations, this study extends the Preference Ranking Organization Method for Enrichment of Evaluations (PROMETHEE-II) method to linear Diophantine fuzzy sets (LDFSs) for more flexible and robust MCDM approach. The proposed MCDM approach primarily evaluates performance metrics criterion, utilizing LDFSs which are robust extension of fuzzy sets (FSs), intuitionistic fuzzy sets (IFSs) as well as interval-valued intuitionistic fuzzy sets (IVIFSs). It helps decision makers to address uncertain information with membership degree (MD), non-membership degree (NMD), and CPs. For this objective, new LDFS based distance measures (DMs) and similarity measures (SMs) are developed for the construction of LDFS PROMETHEE-II technique. The proposed MCDM approach provides a structured and comprehensive framework for optimizing investment performance metrics. Its robustness is validated through sensitivity and comparative analyses.},
  archive      = {J_EAAI},
  author       = {Masooma Raza Hashmi and Muhammad Riaz and Arshid Mahmood and Muhammad Ajmaeen and Muhammad Aslam},
  doi          = {10.1016/j.engappai.2025.112557},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112557},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing performance metrics with new distance and similarity measures using control parameters of linear diophantine fuzzy sets},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamic capsule network-based physical alert monitoring system for elderly people with disabilities. <em>EAAI</em>, <em>162</em>, 112556. (<a href='https://doi.org/10.1016/j.engappai.2025.112556'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Elderly disabled people have higher health risks due to reduced mobility, delayed emergency response, and poor real-time monitoring. Existing Internet of Things (IoT) based monitoring systems frequently have static thresholds, lack personalization, and struggle to capture complex physical and physiological fluctuations, resulting in false alerts and reduced reliability. We propose a Dynamic Capsule Network-Based Physical Alert Monitoring System (DyCN-PAM) for intelligent, real-time monitoring of elderly disabled people to overcome these constraints. Compiling accelerometer, gyroscope, and heart rate readings, and utilizing capsule routing to preserve spatiotemporal hierarchies, enables the system to detect falls, seizures, and fainting. Context-aware alerts utilize capsule confidence and heart rate baselines to distinguish between typical changes and catastrophic emergencies. The DyCN-PAM system outperforms benchmark models in terms of accuracy and robustness, achieving a 5.13 % increase in F1-score, a 28.6 % increase in precision, a 45.1 % reduction in false alarms, and a 26.3 % improvement in computational efficiency. The DyCN-PAM system enhances accuracy, precision, and efficiency, making it feasible to improve safety, independence, and quality of life for older individuals with disabilities. More real-world experiments are needed to prove its use.},
  archive      = {J_EAAI},
  author       = {Shujuan Feng and Hongying Zhu and Yangkai Wu and Ziheng Zeng and Ezzeddine Touti and Jinming Wang and Amar Jain},
  doi          = {10.1016/j.engappai.2025.112556},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112556},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A dynamic capsule network-based physical alert monitoring system for elderly people with disabilities},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiple convolution and bilayer acceleration model for precise and efficient early urban fire detection in complex scenarios. <em>EAAI</em>, <em>162</em>, 112555. (<a href='https://doi.org/10.1016/j.engappai.2025.112555'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI advancement enables earlier and more effective urban fire detection, crucial for slowing fire spread. However, hardware limitations make precise and efficient detection under limited resources a major challenge. Moreover, earlier detection of fire requires the identification of smoke, which further exacerbates the difficulty of detecting algorithms since smoke's inherent low-contrast visual properties produce feature blurring from the surrounding background. In this paper, we propose a novel multiple convolutions and bilayer accelerate (MCBA) model for effective early urban fire detection in terms of precision, lightweight and efficiency, which takes advantage of the mainstream You Only Look Once version 8 (YOLOv8) to training and testing the early fire detection model. In our MCBA model, three optimization techniques have been developed to balance lightweight and precision. First, it designs a new multi-convolution (MC) structure to reduce the size of the original backbone network by avoiding complex or skipping connections. Second, the model includes a novel design of a bilayer accelerate mechanism (BAM) at the neck to minimize the interference of redundant background information in multiple scenarios. Third, we provide a precision compensation strategy (PCS) at the neck to enhance the feature extraction and aggregation capabilities, enabling effective detection of small fire areas. The experiments demonstrate that our proposed MCBA model achieves higher performance in terms of precision and efficiency compared with 17 counterpart detection models. It exhibits superior performance with minimal parameter count and the lowest computational complexity among the compared methods. The model shows strong potential for deployment in early urban fire detection across a variety of real-world scenarios.},
  archive      = {J_EAAI},
  author       = {Pei Shi and Jun Lu and Yachen Xu and Quan Wang and Yonghong Zhang and Liang Kuang and Deji Chen and Guangyan Huang},
  doi          = {10.1016/j.engappai.2025.112555},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112555},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multiple convolution and bilayer acceleration model for precise and efficient early urban fire detection in complex scenarios},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning driven prediction of dynamic stress-strain response in limestone: Insights into transient mechanical behavior under complex loadings for shield tunneling. <em>EAAI</em>, <em>162</em>, 112554. (<a href='https://doi.org/10.1016/j.engappai.2025.112554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex geological conditions pose a serious challenge to improving the rock-breaking efficiency of shield cutter machines in subway tunnel constructions. This study develops a three-axis thermal-hydraulic-mechanical (THM) coupled dynamic impact system, which is integrated with a scaled shield cutter model to generate a unique dataset of stress wave propagation under multi-field coupling. A bidirectional long short-term memory (LSTM) neural network with an attention mechanism is proposed to establish a nonlinear time mapping relationship between stress waves. The determination coefficient ( R 2 ) exceeds 0.97, the symmetric mean absolute percentage error ( sMAPE ) is less than 10 %, and the average relative uncertainty ( ARU ) is less than 4 %, confirming its high accuracy and reliability. Based on predictions and test results, the new quantitative laws for the transient dynamics of limestone are further revealed. The results reveal that loading conditions do not alter the correlation trend between loading rate and dynamic parameters but significantly influence the degree of the loading rate's effect. Axial pressure dominates energy absorption with an energy contribution rate of 60 %. Confining pressure amplified the sensitivity of loading rate by 170 %, while THM coupling suppressed the dynamic deformation modulus by over 30 %. The accurate prediction of the nonlinear response of stress waves in limestone by the LSTM neural network establishes the connection between transient dynamic observation and rock fragmentation physics mechanism, providing support for quantifying energy absorption and conversion in the rock fragmentation process, and providing key strategies for optimizing shield machine performance in extreme environments.},
  archive      = {J_EAAI},
  author       = {Baoping Zou and Kejian Xia and Jingyuan Ma and Xu Long},
  doi          = {10.1016/j.engappai.2025.112554},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112554},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning driven prediction of dynamic stress-strain response in limestone: Insights into transient mechanical behavior under complex loadings for shield tunneling},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A continuous verification mechanism for ensuring client data forgetfulness in federated unlearning. <em>EAAI</em>, <em>162</em>, 112553. (<a href='https://doi.org/10.1016/j.engappai.2025.112553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Federated Learning (FL), it is sometimes necessary to unlearn client data through Federated Unlearning (FU) methods, which help protect user privacy and recover from data poisoning. One critical task is to check the consistency of FU methods and verify if certain clients’ data has been effectively unlearned. However, none of the current FU verification methods can be performed on clients who opt out of the FL process, failing to meet the universal demand in FL, such as the user’s “right to be forgotten” (RTBF). Specifically, after clients leave the FL cooperation, they can no longer verify whether the FL model unlearns their data as the FL continues training for several rounds. To address this, we introduce a continuous verification mechanism for FL clients called Backdoor Attack-based Forgetting Verification (BAFV). The BAFV method embeds a persistent mark for clients who propose to leave, allowing them to verify FU long after leaving the FL cooperation. Extensive experiments across diverse FU environments and datasets demonstrate that our method maintains the model’s accuracy and provides clients with a continuous verification mechanism to ensure their data is unlearned. Our combinatorial marking strategy and gradient-amplified persistence mechanism represent significant advancements beyond existing verification schemes. Our code of BAFV is publicly available at: https://github.com/FuduXing/newBAFV.git .},
  archive      = {J_EAAI},
  author       = {Fudu Xing and Jun Liu and Shanshan Chen and Tianlong Yu and Yang Yang},
  doi          = {10.1016/j.engappai.2025.112553},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112553},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A continuous verification mechanism for ensuring client data forgetfulness in federated unlearning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trajectory planning of redundant parallel mechanism considering motion accuracy based on reinforcement learning. <em>EAAI</em>, <em>162</em>, 112552. (<a href='https://doi.org/10.1016/j.engappai.2025.112552'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The motion accuracy of the trajectory directly affects the reliability of parallel mechanisms in precision tasks such as micro-assembly. Thus, this paper investigates trajectory planning considering motion accuracy, and uses a (6+3)-degrees of freedom (DOF) kinematically redundant parallel mechanism (KRPM) as a case study. First, the kinematics of KRPM are analyzed, and an error model incorporating dimensional errors, driving input errors, and joint clearances is established. Then, based on the error model, the aggregate sensitivity index (ASI) and comprehensive error sensitivity (CES) are introduced to study the error properties of KRPM, along with a universal analysis process. Subsequently, reinforcement learning (RL) utilizing the twin delayed deep deterministic policy gradient (TD3) algorithm is employed to the trajectory planning of KRPM considering motion accuracy. Finally, numerical simulation is carried out based on three cases to verify the effectiveness of the proposed method, and experimental results further demonstrate its practical applicability.},
  archive      = {J_EAAI},
  author       = {Chen-dong Zeng and Zhi-cheng Qiu and Fen-hua Zhang and Xian-min Zhang},
  doi          = {10.1016/j.engappai.2025.112552},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112552},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Trajectory planning of redundant parallel mechanism considering motion accuracy based on reinforcement learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning-tuning hierarchical vehicle trajectory tracking framework based on improved kinematic model predictive control. <em>EAAI</em>, <em>162</em>, 112551. (<a href='https://doi.org/10.1016/j.engappai.2025.112551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory tracking is crucial in vehicle control, as it ensures stable driving along a predefined path. This paper proposes a deep reinforcement learning (DRL)-tuning hierarchical trajectory tracking framework, aiming to improve the tracking accuracy of traditional kinematic model predictive control (MPC) methods in uncertain environments. The proposed hierarchical vehicle trajectory tracking framework consists of two layers: the upper layer serves as a compensation layer for the vehicle side-slip angle (VSA), designed using bidirectional long short-term memory (BiLSTM); while the lower layer is the trajectory tracking layer, in which the improved kinematic MPC is enhanced by integrating the twin delayed deep deterministic policy gradient (TD3) algorithm with an external attention (EA) mechanism. The contribution in artificial intelligence is improving the TD3 algorithm with the EA mechanism, enhancing its ability to capture contextual information and improve adaptability. The contribution in engineering applications is implementing the EA-TD3-tuned hierarchical kinematic MPC framework in the field of vehicle trajectory tracking. With 95 % confidence, compared to traditional kinematic MPC controller, the proposed hierarchical vehicle trajectory tracking framework reduces the average lateral error by 33 % (confidence interval, CI: [0.0616, 0.0850]), the average heading angle error by 34 % (CI: [0.01173, 0.0157]), the average yaw rate variation by 31 % (CI: [0.0244, 0.0346]), and the average front wheel steering angle variation by 28 % (CI: [0.0244, 0.0346]).},
  archive      = {J_EAAI},
  author       = {Jiankun Peng and Xingyan Liu and Changcheng Wu and Dawei Pi and Jiaxuan Zhou},
  doi          = {10.1016/j.engappai.2025.112551},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112551},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep reinforcement learning-tuning hierarchical vehicle trajectory tracking framework based on improved kinematic model predictive control},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel decomposition-prediction hybrid model improved by dual-channel cross-attention mechanism for short-term wind speed prediction. <em>EAAI</em>, <em>162</em>, 112550. (<a href='https://doi.org/10.1016/j.engappai.2025.112550'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of wind energy is crucial for ensuring the safe operation and stability of power systems. To improve the accuracy and robustness of wind speed (WS) forecasting, a novel hybrid method based on mixture of experts (MoE), Transformer, temporal convolution network (TCN), multi-head attention (MA) mechanism, and improved by dual-channel cross-attention mechanism (DCCAM) is proposed. The wind speed data is decomposed by MoE into seasonal and trend components. The trend features are directly captured through a multi-head attention mechanism. An innovative Transformer-TCN framework associated with DCCAM is designed to handle the seasonal component, wherein the Transformer-TCN can make full use of long dependency modeling of Transformer and the local feature extraction of TCN, and DCCAM enables the information interchange and feature fusion, therefore realizing complementary advantages. Based on the proposed model, a series of experiments are conducted on multiple datasets. Ablation experiments confirm the effectiveness of the model and the role of each module in performance improvement. Experiments on seasonal datasets, including spring, summer, autumn, and winter, show that the proposed model can effectively adapt to variations in amplitude and volatility of wind speed sequences under different climatic conditions. Comparative experiments with six advanced hybrid models including decomposition and prediction modules, further demonstrate the superiority and stability of the proposed model.},
  archive      = {J_EAAI},
  author       = {Donghan Geng and Haiteng Cui and Leisen Lv and Jiamin Guo},
  doi          = {10.1016/j.engappai.2025.112550},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112550},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel decomposition-prediction hybrid model improved by dual-channel cross-attention mechanism for short-term wind speed prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysing sustainable industrial wastewater treatment technologies using circular fermatean fuzzy multi-attribute group decision making with decision experts’ confidence levels. <em>EAAI</em>, <em>162</em>, 112549. (<a href='https://doi.org/10.1016/j.engappai.2025.112549'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evaluation of sustainable industrial wastewater treatment techniques is vital for preserving environmental integrity and protecting public health. Industrial processes often generate wastewater containing toxic compounds like metal contaminants, toxic chemicals, and complex organic compounds, posing serious risks to ecosystems and human well-being. This study proposes a robust multi-attribute group decision-making framework to assess five treatment alternatives across twelve sub-criteria. The evaluation model employs circular Fermatean fuzzy numbers to capture uncertainty and imprecision in expert judgements. To enhance the accuracy of data aggregation, four novel Schweizer–Sklar weighted aggregation operators are introduced, integrating varying confidence levels. Criteria weights are determined through a hybrid approach combining the subjective Ranking Comparison (RANCOM) method and the objective Opinion Weight Criteria Method (OWCM), ensuring balanced prioritization. Alternatives are ranked using the Alternative Ranking Order Method Accounting for Two-Step Normalization (AROMAN), a novel technique for improved discrimination and consistency. Results reveal that the membrane bioreactor as the most sustainable treatment with score 0.821, outperforming activated sludge process, by 25.34%. The lowest-ranked option is chemical coagulation and flocculation, scoring 0.622. Sensitivity analysis, performed by varying three parameters, shows reasonable stability with an average correlation value of 0.71. Comparative analysis shows an average Spearman’s rank correlation of 0.86, confirming reliability. The study recommends prioritizing membrane bioreactor adoption in industrial treatment plants to enhance efficiency and water reuse. By promoting effective treatment solutions, the study contributes to reducing industrial pollution, enhancing water reuse, and advancing environmental sustainability.},
  archive      = {J_EAAI},
  author       = {Prayosi Chatterjee and Mijanur Rahaman Seikh},
  doi          = {10.1016/j.engappai.2025.112549},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112549},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Analysing sustainable industrial wastewater treatment technologies using circular fermatean fuzzy multi-attribute group decision making with decision experts’ confidence levels},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cost-effective nash-based allocation method for task distribution of multiple robots in distributed robotic networks. <em>EAAI</em>, <em>162</em>, 112548. (<a href='https://doi.org/10.1016/j.engappai.2025.112548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficiency is paramount in distributed robotic networks (DRNs), where multiple autonomous robots collaborate to perform complex tasks. In this context, the identification of the most efficient path for robots, considering both distance and cost, plays a crucial role in the development of an effective matching algorithm for addressing multirobot task allocation (MRTA) challenges. The study introduces a new cost-efficient Nash-based game framework for task allocation in a distributed robotic network. The proposed model relies on a decentralized decision-making strategy, where each robot selects a single task that optimizes its execution time at a constant speed, thereby maximizing energy harvesting and minimizing energy consumption. In this context, each robot optimizes its choices for individual benefit while also considering the collective welfare, achieving the Nash equilibrium as a nearly optimal allocation strategy in DRNs. The proposed model is tested on various MRTA scenarios involving five robots, seven robots, ten robots, fifteen robots, and twenty robots with the same number of tasks. The proposed Nash-based decentralized model outperforms the Hungarian method by significantly reducing computational costs and complexity to O ( N ) , making it more efficient for large-scale problems.},
  archive      = {J_EAAI},
  author       = {Ali Hamidoğlu and Omer Melih Gul and Seifedine Nimer Kadry and Chiranjibe Jana and Ali Elghirani and Gokhan Koray Gultekin},
  doi          = {10.1016/j.engappai.2025.112548},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112548},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A cost-effective nash-based allocation method for task distribution of multiple robots in distributed robotic networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A digital twin-assisted algorithm for diagnosis of permanent magnet synchronous generator interturn short circuit fault and converter open circuit fault in wind power systems using pearson correlation coefficient. <em>EAAI</em>, <em>162</em>, 112547. (<a href='https://doi.org/10.1016/j.engappai.2025.112547'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interturn short-circuit faults (ISCFs) in permanent magnet synchronous generators (PMSGs) and open-circuit faults (OCFs) in the machine-side converters represent two critical reliability challenges in wind power systems. Conventional fault diagnosis approaches typically rely on dedicated models for each fault type for each fault type, leading to excessive system complexity and suboptimal computational efficiency. To overcome these limitations, this paper proposes a novel unified digital twin-assisted framework capable of simultaneous diagnosis of both PMSG ISCFs and converter OCFs within a single integrated architecture. The high-fidelity digital twin model based on one-dimensional convolutional neural networks is established to generate real-time reference value of current space vector (SV) for online fault detection, while Pearson correlation coefficient analysis enables accurate differentiation between ISCF and OCF. For ISCFs, the fault severity assessment is performed based on the deviation between reference and measured current SV, with the faulty phase identified using phase current root mean square (RMS) values. In the case of converter OCFs, the proposed method introduces a dual-stage identification process: single and dual insulated-gate bipolar transistor (IGBT) open faults are differentiated through severity estimation analysis, and the faulty IGBT is identified by evaluating the effective current interval ratio (ECIR) and normalized current average (NCA). The experimental results validate the effectiveness of the proposed method, and comparative analysis further demonstrates its superior performance in terms of parameter dependency and diagnostic efficacy.},
  archive      = {J_EAAI},
  author       = {Bin Sun and Ying Zhu and Zhinong Wei},
  doi          = {10.1016/j.engappai.2025.112547},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112547},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A digital twin-assisted algorithm for diagnosis of permanent magnet synchronous generator interturn short circuit fault and converter open circuit fault in wind power systems using pearson correlation coefficient},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight self-attention metric network for bird species recognition in intelligent bird repellent equipment. <em>EAAI</em>, <em>162</em>, 112546. (<a href='https://doi.org/10.1016/j.engappai.2025.112546'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bird damages to power transmission lines pose significant operational risks, and intelligent bird repellent equipment (IBRE) requires accurate species recognition for effective long-term repellent. We propose a novel lightweight self-attention metric network (LSAM-Net) for few-shot bird species recognition in the vicinity of power transmission lines, aiming to enhance the performance of IBRE. LSAM-Net integrates a simple attention mechanism (SimAM) to emphasize critical spatial and channel features, thereby enhancing the extraction of key semantic information from bird images. Additionally, a self-correlation representation (SCR) module is employed to capture local structural patterns, effectively mitigating the impact of pseudo-features and improving the network’s capacity to learn discriminative representations. To promote the utilization of local discriminative information in few-shot classification, LSAM-Net leverages earth mover’s distance (EMD) to compute structural similarity between images. For efficient deployment, we apply knowledge distillation to further reduce model complexity. Extensive experiments conducted on Bird-65, CUB200, 2011, miniImageNet, and Fewshot-CIFAR100 demonstrate that LSAM-Net achieves superior performance compared to state-of-the-art methods, while maintaining a compact architecture. On the Bird-65 and CUB200-2011 datasets, LSAM-Net requires only 4.75 and 1.18 giga floating-point operations (GFLOPs), and achieves inference speed improvements of 52.9 % and 48.9 %, respectively, over the self-attention metric network (SAM-Net). Further optimization with TensorRT yields additional reductions in inference time by 43.6 ms and 53.7 ms, respectively. These improvements significantly support species-specific repellent strategies, thereby enhancing the long-term effectiveness of IBRE systems.},
  archive      = {J_EAAI},
  author       = {Jiangjian Xie and Shanshan Xie and Baican Li and Yujie Zhong and Chunhe Hu and Junguo Zhang and Björn W. Schuller},
  doi          = {10.1016/j.engappai.2025.112546},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112546},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight self-attention metric network for bird species recognition in intelligent bird repellent equipment},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multimodal multi-scale fusion network for leak detection in marine piping systems. <em>EAAI</em>, <em>162</em>, 112545. (<a href='https://doi.org/10.1016/j.engappai.2025.112545'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Marine system monitoring data inherently exhibit multimodal characteristics, making artificial intelligence-driven correlation and fusion essential for improving fault feature recognition. However, existing intelligent diagnosis methods mostly focus on feature fusion within homogeneous data types, such as fusing multiple time-series signals or multiple image sets, while systematic exploration of joint representation learning across heterogeneous dimensions remains under-explored. This limitation constrains the recognition capability for complex failure modes. Meanwhile, the inherent differences in physical meanings and representations of multimodal data pose significant challenges in constructing effective correlations, often limiting the performance of mainstream machine learning based fault diagnosis approaches. The proposed method enhances the fault diagnosis capability of mainstream approaches through the fusion of multi-sensor data and visual data, with its core innovation residing in a multimodal fusion framework leveraging attention mechanisms to effectively integrate cross-dimensional representations of multivariate time-series data and imaging data. Compared to existing multimodal transformer techniques, this dual-strategy architecture enables the model to simultaneously capture shared systemic behaviors and modality-unique signatures, substantially elevating diagnosis precision. Experimental validation on real-world leak detection datasets demonstrates that the proposed model achieves F1-scores consistently surpassing 90 % across diverse marine monitoring scenarios, with quantitative evaluations further confirming its superior performance over conventional multivariate time-series diagnosis methods in establishing multimodal correlations, conclusively validating both technical excellence and engineering practicability.},
  archive      = {J_EAAI},
  author       = {Peng Zhang and Chaozhe Li and Shitao Peng and Bomu Tian and Si Luo and Yuewen Zhang and Taili Du},
  doi          = {10.1016/j.engappai.2025.112545},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112545},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multimodal multi-scale fusion network for leak detection in marine piping systems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified rotating machinery health management framework leveraging large language models for diverse components, conditions, and tasks. <em>EAAI</em>, <em>162</em>, 112544. (<a href='https://doi.org/10.1016/j.engappai.2025.112544'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces the Rotating Machinery Large Language Model (RotLLM), a unified framework for rotating machinery health management that integrates deep learning with large language models (LLMs) to address diverse operational conditions, components, and health management tasks. RotLLM employs a novel Spectral Folding Network (SFN) to transform vibration spectrum into a unified feature space that preserves essential health state information. A dedicated projection layer then maps these features into the semantic domain of an LLM. The framework is trained using a three-stage strategy: first, pre-training the encoder on the Large-scale Multimodal Rotating Machinery (LMR) dataset, which comprises 237,298 vibration samples collected under hundreds of operating conditions; second, initializing the projection layer with textual health state labels; and finally, fine-tuning using parameter-efficient Low-Rank Adaptation (LoRA) with high-quality corpus for various health management tasks. Experimental evaluations demonstrate that RotLLM achieves state-of-the-art performance in fault classification, maintains strong robustness under noisy conditions, and delivers rapid multi-task inference with minimal computational overhead. The framework consistently outperforms conventional methods, enabling efficient, accurate, and context-aware health management for rotating machinery across diverse conditions and tasks. The dataset and source code are open-sourced ( https://github.com/SIA-IDE/RotLLM ), fostering collaboration, reproducibility, and broader adoption in industrial prognostics research.},
  archive      = {J_EAAI},
  author       = {Haotian Peng and Jie Gao and Jiawei Liu and Jinsong Du and Wei Wang},
  doi          = {10.1016/j.engappai.2025.112544},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112544},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A unified rotating machinery health management framework leveraging large language models for diverse components, conditions, and tasks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid neural network model for shale gas production prediction considering production plans and produced water. <em>EAAI</em>, <em>162</em>, 112543. (<a href='https://doi.org/10.1016/j.engappai.2025.112543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent neural networks have been widely applied to shale gas production prediction. However, current literature has two major flaws. Firstly, the delay issue can be observed in single-step prediction. Secondly, models that can be directly applied to newly developed wells are underresearched. This study presents a hybrid neural network combining fully connected (Dense) layers and long short-term memory (LSTM) layers to solve the two problems. In the proposed Dense-LSTM model, parameters regarding produced water and production plans are fed into the Dense layers while historical data is fed into the LSTM layers. The bottom-hole total flow rate converted from ground gas and water rates using volume factors is also included as an auxiliary parameter. The production plans made from the feature engineering can preserve the key information from shut-in periods while keeping a continuous prediction. The performance of the proposed model is demonstrated through ablation experiments and the comparison with popular decline curve models. For long-term prediction with window size w = 14 days, the proposed model’s mean cumulative error is 40.26% of that of vanilla LSTM at the end of the 3-year-long prediction interval. For window size w ′ = 100 days, the proposed model’s mean cumulative error is 77.93% of that of vanilla LSTM and 29.71% of that of the classic Arps model. The workflow of this study also sheds light on the construction of a universal prediction model for shale gas wells from different gas fields.},
  archive      = {J_EAAI},
  author       = {Yilun Dong and Youzhi Hao and Detang Lu},
  doi          = {10.1016/j.engappai.2025.112543},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112543},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid neural network model for shale gas production prediction considering production plans and produced water},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel multi-source heterogeneous data fusion based fault diagnosis framework for manufacturing processes. <em>EAAI</em>, <em>162</em>, 112542. (<a href='https://doi.org/10.1016/j.engappai.2025.112542'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis technologies are important means to ensure the production operation safety and product quality stability for manufacturing processes. After a fault occurs in the manufacturing processes, it may be characterized by high-frequency and high-dimensional structured time series data anomalies such as sensor data, or by unstructured data anomalies such as images. Traditionally, single structured sensor data is often used for constructing diagnosis models, the fault characteristics may not be adequately characterized, thus affecting the diagnosis performance. Therefore, in this paper, in order to make full use of multi-source data and obtain more comprehensive and accurate diagnosis results, a new multi-source heterogeneous data fusion based fault diagnosis framework is designed for manufacturing processes. Specifically, to solve the problem that the important information is ignored during data level fusion of multi-source data, an adaptive weight multi-source data fusion method is proposed. Furthermore, in response to the problem of feature redundancy in feature level fusion of heterogeneous data, a feature differentiation extraction and heterogeneous feature fusion method is proposed, of which a feature source discriminator is constructed for enhancing the complementarity of the extracted heterogeneous features, and feature concatenation is performed to improve the feature expression ability. Finally, the effectiveness and feasibility of the proposed framework is verified on actual datasets from the hot rolling process and the Tennessee Eastman process. Experimental results show that the proposed framework is both effective and feasible in fault diagnosis with multi-source heterogeneous data.},
  archive      = {J_EAAI},
  author       = {Liang Ma and Qikai Yang and Orestes Llanes-Santiago and Kaixiang Peng},
  doi          = {10.1016/j.engappai.2025.112542},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112542},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel multi-source heterogeneous data fusion based fault diagnosis framework for manufacturing processes},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reducing modal differences in zero-shot anomaly detection based on vision-language generation model. <em>EAAI</em>, <em>162</em>, 112541. (<a href='https://doi.org/10.1016/j.engappai.2025.112541'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot anomaly detection methods based on vision-language model rely on alignment between image and text. These methods ignore the inherent differences between different modalities, which is unfavorable for improving the alignment between modalities. This paper reduces modal differences between image and text by using guiding vision feature and text feature from the pre-trained vision-language generation model. The vision perception text embedding is constructed by adding guiding vision feature to the weight shared text prompt. The text perception vision embedding is extracted by a vision text fusion module. The fusion module is designed to promote the visual modality to perceive the textual information locally. Anomaly regions are detected by cosine similarity between cross-modal perception embeddings. Zero-shot anomaly detection performance is evaluated on five publicly available industrial anomaly detection datasets, and a real-world dataset about automotive plastic parts. Experimental results show that the proposed method achieves highly competitive anomaly detection performance on multiple evaluation metrics.},
  archive      = {J_EAAI},
  author       = {Yanan Song and Weiming Shen and Baisong Pan and Quanhui Wu and Dawei Gu},
  doi          = {10.1016/j.engappai.2025.112541},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112541},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reducing modal differences in zero-shot anomaly detection based on vision-language generation model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel short-term prediction method for distributed photovoltaic power generation considering extreme weather. <em>EAAI</em>, <em>162</em>, 112540. (<a href='https://doi.org/10.1016/j.engappai.2025.112540'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed photovoltaic power plants are often impacted by various factors such as weather conditions and geographical locations, making it challenging to fully capture the spatial correlation characteristics among multiple photovoltaic plants. Furthermore, the failure to consider meteorological factors that influence photovoltaic output results in larger prediction errors during extreme weather events. To reduce prediction errors, this paper proposes a short-term photovoltaic forecasting method that considers meteorological factors, explores spatial correlations among photovoltaic plants, and captures temporal characteristics. Firstly, a Graph Attention Network is established to obtain spatial correlations between different plants while a Convolutional Neural Network is employed to extract feature information of meteorological factors. Then, the feature information from these two sources is integrated and input into a Long Short-Term Memory network, which is enhanced based on Spiking Neural P Systems to extract temporal characteristics of photovoltaic output and complete the prediction task. Finally, real-world power station datasets are utilized for validation and comparison with several typical photovoltaic prediction models. The results clearly show that the application of artificial intelligence in this proposed method can effectively improve the accuracy of distributed photovoltaic power forecasting, demonstrating the great potential of AI in the field of photovoltaic power prediction.},
  archive      = {J_EAAI},
  author       = {Xin Guan and Xiao Han and Jun Wang and Tao Wang},
  doi          = {10.1016/j.engappai.2025.112540},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112540},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel short-term prediction method for distributed photovoltaic power generation considering extreme weather},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An innovative method of multi-view face frontalization based on receptive field-enhanced conditional generative adversarial network. <em>EAAI</em>, <em>162</em>, 112539. (<a href='https://doi.org/10.1016/j.engappai.2025.112539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A series of theoretical and experimental investigations based on deep learning were conducted to enhance the accuracy and generalizability of face frontalization models. A series of theoretical investigations and experimental verifications based on deep learning are conducted to further enhance the face frontalization model's accuracy and generalizability. To address inadequate local feature extraction and the low realism in synthesized images, a receptive field-enhanced conditional generative adversarial network (RFC-GAN) is proposed to achieve multi-view face frontalization. RFC-GAN model integrates a novel configuration of multi-scale dilated convolutions in a multi-branch generator architecture to significantly expand the receptive field and improve feature extraction. The unique integration enhances the realism and detail of the generated images. Unlike conventional approaches that focus primarily on pixel-level accuracy, RFC-GAN introduces a perceptual loss component to enhance semantic content and structural integrity at the feature level. RFC-GAN has been experimentally validated on the Karolinska Directed Emotional Faces (KDEF) and Carnegie Mellon University Multiple Pose, Illumination, and Expression Face Database (CMU Multi-PIE). The generated facial expression images from RFC-GAN exhibit a higher degree of detailed texture reproduction in critical facial features such as the eyes, nose, and mouth. On the two datasets, the Peak Signal-to-Noise Ratio (PSNR) reaches 31.5185 for KDEF and 26.1851 for Multi-PIE, the Structural Similarity Index (SSIM) reaches 0.3604 for KDEF and 0.3965 for Multi-PIE, and the Learned Perceptual Image Patch Similarity (LPIPS) reaches 0.117 for KDEF and 0.408 for Multi-PIE, respectively. Compared to existing state-of-the-art methods, RFC-GAN exhibits marked improvements in these metrics, especially in detailed texture reproduction of critical facial features such as the eyes, nose, and mouth, establishing new benchmarks in face frontalization.},
  archive      = {J_EAAI},
  author       = {Yancong Zhou and Dongdong Wang},
  doi          = {10.1016/j.engappai.2025.112539},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112539},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An innovative method of multi-view face frontalization based on receptive field-enhanced conditional generative adversarial network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced air pollution spatiotemporal forecast model using frequency domain convolution and attention mechanism. <em>EAAI</em>, <em>162</em>, 112538. (<a href='https://doi.org/10.1016/j.engappai.2025.112538'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of air pollution, which is crucial for public health and environmental management, often faces challenges in effectively capturing the complex and intertwined spatiotemporal dynamics of pollutants. Existing models frequently struggle to simultaneously account for broad periodic spatiotemporal dependencies as well as fine-grained local temporal patterns. This paper presents a novel deep learning architecture, the Fourier Convolutional Graph Transformer (FCGformer), specifically designed to overcome these limitations. FCGformer distinctively features a dual-module approach: a Global Module that constructs an integrated spatiotemporal graph and leverages Fourier transforms with frequency domain convolution to extract long-range dependencies and crucial periodicities; and a Local Module that employs inverse temporal embedding and self-attention to meticulously capture nuanced, short-term temporal variations. The key contribution of this work lies in the synergistic integration that enables FCGformer to effectively model complex pollutant behaviors, providing a more comprehensive understanding of both global contexts and local details. Extensive experiments demonstrate that FCGformer significantly outperforms state-of-the-art benchmark models in prediction accuracy, offering a promising advancement for improved air quality management.},
  archive      = {J_EAAI},
  author       = {Haiwei Yang and Ru Yang and Ling Ding and Shiqiang Du and Maozhen Li and Bo Zhang},
  doi          = {10.1016/j.engappai.2025.112538},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112538},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced air pollution spatiotemporal forecast model using frequency domain convolution and attention mechanism},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gate-guided spatial-channel reconstruction network: An efficient lightweight framework for steel surface defect detection. <em>EAAI</em>, <em>162</em>, 112537. (<a href='https://doi.org/10.1016/j.engappai.2025.112537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the limitations in You Only Look Once version 8 (YOLOv8) for steel surface defect detection, including insufficient generalization of image enhancement, constrained feature representation capability in core modules, and poor adaptability of the loss function to scale variations and sample imbalance, this paper proposes the Gate-guided Spatial-channel Reconstruction Network, an efficient and lightweight improved network. Contrast-Limited Adaptive Histogram Equalization (CLAHE) is introduced to enhance local image details and contrast while reducing noise impact. The Gating Block and the Spatial-channel Reconstruction Block are designed to replace the original C2f (cross-stage partial bottleneck with two convolutions) module in YOLOv8, thereby enhancing feature representation capability and efficiency. The loss function is optimized using Wise-IoU (WIoU) and Slide Loss (SlideLoss) to improve convergence and robustness. The proposed network was evaluated on the Northeastern University Surface Defect Detection (NEU-DET) dataset (200 × 200 pixels) and the Chinese Academy of Sciences Defect Detection (GC10-DET) dataset (2048 × 1000 pixels). It demonstrated high detection accuracy, achieving the mean Average Precision at 50 % (mAP50) of 84.7 % and 79.4 %, respectively. Furthermore, the network maintains low complexity with only 3.6 million parameters and achieves a high detection speed of up to 154 frames per second (FPS). The Gate-guided Spatial-channel Reconstruction Network effectively detects surface defects on hot-rolled steel, achieving state-of-the-art detection accuracy. It successfully meets the requirements for precise and real-time steel surface defect detection under resource-constrained industrial conditions.},
  archive      = {J_EAAI},
  author       = {Wei Zhang},
  doi          = {10.1016/j.engappai.2025.112537},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112537},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Gate-guided spatial-channel reconstruction network: An efficient lightweight framework for steel surface defect detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tensor product-fault diagnosis-transformer based wind turbine blade fault prediction method. <em>EAAI</em>, <em>162</em>, 112535. (<a href='https://doi.org/10.1016/j.engappai.2025.112535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous iterative updating of wind turbine (WT) blade fault diagnosis (FD) technology, intelligent prediction methods based on supervisory control and data acquisition (SCADA) systems have gradually become advanced mainstream technology in the industry. However, despite the many advantages of SCADA data in fault prediction, its high-dimensional characteristics and highly unstable nature still pose significant challenges for practical applications. Accordingly, this study proposes an innovative WT blade fault prediction method based on tensor product dimensionality reduction and FD-Transformer (TP-FD-Transformer) methodology, which aims to effectively solve the problem of timely and accurate prediction of WT blade faults. The TP-FD-Transformer method combines the quantum dimensionality reduction technique with the FD-Transformer model to form a new framework for data processing and analysis. The TP-FD-Transformer method adopts the tensor product-relative position matrix composite dimensionality reduction technique, which effectively reduces the dimensionality and complexity of SCADA data while preserving its features. After data processing is completed, the TP-FD-Transformer method utilizes the FD-Transformer model for deep learning training. The FD-Transformer model has been improved for complex time series data and can effectively capture potential features in the data. The experiments under the open dataset show that the TP-FD-Transformer method demonstrates excellent prediction ability in the field of WT blade FD, with an accuracy rate of 93.65 %. The research findings verify that TP-FD-Transformer method provides a feasible solution for the intelligent diagnosis of WT blade faults, with broad application prospects and significant practical significance.},
  archive      = {J_EAAI},
  author       = {Linfei Yin and Yuhan Liu and Nannan Wang},
  doi          = {10.1016/j.engappai.2025.112535},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112535},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Tensor product-fault diagnosis-transformer based wind turbine blade fault prediction method},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid physics-based and data-driven method for the rotor angle prediction. <em>EAAI</em>, <em>162</em>, 112533. (<a href='https://doi.org/10.1016/j.engappai.2025.112533'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods are widely employed for transient stability analysis in power systems. However, the prediction performance can be adversely affected by undesirable factors in the measured data. To alleviate the effect of the undesirable factors, a hybrid physics-based and data-driven prediction network of the rotor angle trajectory is proposed in this paper. The prediction model embeds the rotor equation to form a dynamic learning model that conforms to the actual physical law. The physical consistency of the prediction results is guaranteed. Meanwhile, a dynamic error derivative integral network incorporating the Runge–Kutta method is proposed to correct the final results. The accuracy of the prediction can be improved. Finally, it is tested in the IEEE 39-bus system and the East China Power Grid system. The test results show that the model significantly outperforms other comparative models. And the dependence on the quality of measured data can be alleviated effectively.},
  archive      = {J_EAAI},
  author       = {Lingzhe Zhang and Dong Huang and Huaiyuan Wang},
  doi          = {10.1016/j.engappai.2025.112533},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112533},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid physics-based and data-driven method for the rotor angle prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed machine learning for near real-time stress prediction on a structural component: Application for landing gears. <em>EAAI</em>, <em>162</em>, 112532. (<a href='https://doi.org/10.1016/j.engappai.2025.112532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lightweight design constitutes a pivotal research and development objective for next-generation landing gear systems. Nevertheless, achieving reduced weight while maintaining structural safety and reliability presents considerable challenges. The establishment of a digital twin (DT) for structural health monitoring (SHM) offers a promising approach to address these concerns across the design, testing, and operational lifecycle of landing gears. In this study, we develop a physics-informed neural network (PINN) model for near real-time stress prediction on the drag strut of a nose landing gear (NLG), specifically for an A320-type aircraft, serving as a foundational component of a DT system. The proposed PINN framework directly outputs displacement fields while deriving stresses as secondary quantities, effectively incorporating the fundamental equations of linear elasticity into the loss function. Displacement boundary conditions, informed by finite element method (FEM) simulations, are integrated as penalty terms to enhance trainability and physical consistency. The training dataset is constructed using load cases statistically representative of actual landing gear operations, with high-fidelity FEM providing corresponding displacement and stress references. The model demonstrates strong predictive accuracy, with relative errors between 5% and 7% compared to FEM results, and significantly outperforms both pure stress-output PINNs and conventional deep neural networks (DNNs). Moreover, the trained PINN achieves inference times within seconds under time-varying loads, highlighting its capability for near real-time stress monitoring. This work underscores the potential of physics-informed machine learning for enhancing DT-enabled SHM systems in safety-critical aerospace structures.},
  archive      = {J_EAAI},
  author       = {Zixuan Zhu and Yifan Zhao and Agusmian Partogi Ompusunggu},
  doi          = {10.1016/j.engappai.2025.112532},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112532},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed machine learning for near real-time stress prediction on a structural component: Application for landing gears},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced forest fire detection via dynamic multiscale fusion and contextual partial cross features. <em>EAAI</em>, <em>162</em>, 112531. (<a href='https://doi.org/10.1016/j.engappai.2025.112531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Timely and accurate detection of forest fires, particularly in the early stages when smoke and small flames are present, is crucial for minimizing ecological damage and improving the effectiveness of emergency response. However, existing methods face challenges such as missing edge information, ineffective multi-scale feature fusion, and low accuracy when identifying small or distant targets in complex forest conditions. To address these issues, a novel detection framework is proposed, called the Dynamic Contextual Shallow Network (DCSNet). This framework enhances detection performance and real-time efficiency. The proposed method incorporates three key components: (1) the Contextual Partial Cross Feature Network (CPCFNet), which employs a reparameterized non-local attention mechanism and partial channel separation to strengthen contextual representation; (2) the Dynamic Multiscale Fusion Pyramid Network (DMFPN), which uses dynamic sampling and deformable convolution to fuse multi-scale features adaptively; and (3) the Shallow Feature Detection Layer (SFDL), which refines shallow features to improve the detection of small smoke and flame targets. Experimental evaluations on visible-light and infrared remote sensing datasets collected by unmanned aerial vehicles (UAVs) demonstrate the effectiveness of DCSNet. Specifically, DCSNet achieves an average mean average precision (mAP) at 50 % intersection over union (IoU) of 76.0 %, a frame rate of 283 frames per second (FPS), and an F1-score of 71.9 % on the visible-light dataset. On the infrared dataset, the framework achieves an mAP@50 of 77.5 %, an mAP@50:95 of 45.5 %, and an F1 score of 72.9 %. These results suggest that DCSNet provides high accuracy and robustness in the real-time detection of forest fires under diverse environmental conditions. The code and datasets are available at https://github.com/Lili-wang-del/DCSNet .},
  archive      = {J_EAAI},
  author       = {Lili Wang and Lei Guo and Haiyan Li and Bingbing He and Jundong Yang and Yaqun Huang},
  doi          = {10.1016/j.engappai.2025.112531},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112531},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced forest fire detection via dynamic multiscale fusion and contextual partial cross features},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced targeted attacks on graph neural networks via average gradient and perturbation optimization. <em>EAAI</em>, <em>162</em>, 112530. (<a href='https://doi.org/10.1016/j.engappai.2025.112530'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) are vulnerable to adversarial attacks that cause performance degradation by adding small perturbations to the graph. Gradient-based attacks are among the most widely used methods and have demonstrated strong performance across various attack scenarios. However, most gradient attacks use greedy strategies to generate perturbations, which tend to fall into local optima, leading to underperformance of the attack. To address the above problem, we propose an attack (Average Gradient and Perturbation Optimization Attack, AGPOA) on GNNs, which consists of an average gradient calculation and a perturbation optimization module. In the average gradient calculation module, we compute the average of the gradient information over all moments to guide the attack to generate perturbed edges, which stabilizes the direction of the attack update and gets rid of undesirable local maxima. We use a perturbation optimization module to limit the attack budget and further improve performance. Furthermore, we demonstrate the theoretical superiority of AGPOA over traditional gradient-based attack methods through attack loss variance. The experimental results show that AGPOA improves the misclassification rate by 2%–8% compared to other state-of-the-art models in the node classification task.},
  archive      = {J_EAAI},
  author       = {Yang Chen and Bin Zhou and Haixing Zhao and Padarti Vijaya Kumar},
  doi          = {10.1016/j.engappai.2025.112530},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112530},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced targeted attacks on graph neural networks via average gradient and perturbation optimization},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-free safe deep reinforcement learning for grid-to-vehicle management considering grid constraints and transformer thermal stress. <em>EAAI</em>, <em>162</em>, 112529. (<a href='https://doi.org/10.1016/j.engappai.2025.112529'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing penetration of Electric Vehicles (EVs) presents challenges to the distribution grid, due to more volatile power profiles and higher peak demand. One key research question is how to accommodate EVs with limited-capacity grid equipment, such as transformers and lines. However, uncertainties from the EV side and the complexity of grid equipment models challenge the performance of the control strategies implemented. Moreover, the thermal loading of the transformer is often neglected. In this work, we propose a fully model-free, safe Deep Reinforcement Learning (DRL)- based grid-to-vehicle management strategy to avoid electric and thermal overloading of the transformer and power grid constraint violation. The management strategy is based on Projection-based Constraint Policy Optimization (PCPO) and takes only the observable information from the grid and vehicles. The target is to maximize energy delivery to the EV fleet while considering safe constraints, such as transformer thermal loading, voltage magnitude limits, and line loading limits. We compared the proposed strategy with conventional DRL and other safe DRL methods and investigated its robustness against higher ambient temperatures. The results show that the proposed strategy can deliver 92 % energy and reduce violations of the grid and transformers, while the other benchmarks deliver less than 80 %. The robustness test demonstrates that the proposed strategy is effective in various temperature. Moreover, the proposed strategy can effectively reduce at most 90 % of the transformer aging incurred by the thermal stress, compared with the uncontrolled charging.},
  archive      = {J_EAAI},
  author       = {Zhewei Zhang and Rémy Rigo-Mariani and Nouredine Hadjsaid and Yan Xu},
  doi          = {10.1016/j.engappai.2025.112529},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112529},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Model-free safe deep reinforcement learning for grid-to-vehicle management considering grid constraints and transformer thermal stress},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probability forecasting for multivariate urban water demand using temporal convolutional network based on quantile regression and parzen window. <em>EAAI</em>, <em>162</em>, 112528. (<a href='https://doi.org/10.1016/j.engappai.2025.112528'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probability prediction can provide more abundant information about uncertainties in future water demand, which is gaining increasing attention in building economical and reliable water resource management plans. However, most existing literature on water demand prediction focus on provide deterministic point prediction results. To overcome this problem, a novel hybrid probability forecasting model based on quantile regression temporal convolutional network and Parzen window is proposed for the probability density forecast of multivariate urban water demand. Firstly, to address the complex coupling relationship between water demand and multiple influencing factors, a random forest-based feature selection method is employed to eliminate the redundant variables. Then, a discrete wavelet transform is deployed to decompose the original series into a variety of characteristic subseries to reduce fluctuations of the original water demand series. Secondly, a quantile regression-based temporal convolutional neural network is employed to obtain the conditional quantiles of future water demand. Moreover, a probability density prediction method based on Parzen window estimation is developed to further obtain the distribution information of prediction uncertainty. Finally, a real-world multivariate dataset from a water plant in Suzhou, China, is used for comparison experiments with state-of-the-art models. The comparison results show that the proposed model has achieved an average improvement of 15.4 % and 53.3 % in interval prediction and probability density prediction, respectively. It shows that the proposed model is a reliable prediction model that can assist policymakers to optimize the management of urban water demand.},
  archive      = {J_EAAI},
  author       = {Jun Guo and Qingya Meng and Baigang Du and Hui Sun},
  doi          = {10.1016/j.engappai.2025.112528},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112528},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Probability forecasting for multivariate urban water demand using temporal convolutional network based on quantile regression and parzen window},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complex T-spherical fuzzy yager prioritized weighted aggregation for prioritizing waste management strategies: A case study from delhi. <em>EAAI</em>, <em>162</em>, 112527. (<a href='https://doi.org/10.1016/j.engappai.2025.112527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient waste management is crucial for addressing urban challenges in densely populated areas like Delhi. This study is motivated by a key research gap: the need for an advanced Multi-Criteria Decision-Making (MCDM) framework capable of handling both two-dimensional uncertainty and the prioritized nature of criteria in such complex problems. Our primary contribution is a novel framework integrating the flexibility of Complex T-Spherical Fuzzy Sets (CT-SFS) with Yager’s prioritized aggregation. Unlike traditional T-SFS, which are limited to a one-dimensional representation, CT-SFS incorporates both amplitude and phase information for Membership Degree (MD), Neutral Degree (ND), and Non-membership Degree (NMD), offering a nuanced model for expert evaluations. The framework introduces two innovative operators: the Complex T-Spherical Fuzzy Yager Prioritized Weighted Average (CT-SFYPWA) and the Complex T-Spherical Fuzzy Yager Prioritized Weighted Geometric (CT-SFYPWG). These operators uniquely incorporate Yager’s prioritized aggregation, allowing decision-makers to assign hierarchical importance to critical criteria, which is vital for effective resource allocation in urban waste management. The framework’s practical value is demonstrated through a detailed case study prioritizing waste management strategies in Delhi. Rigorous numerical analysis, sensitivity tests, and comparative evaluations confirm the framework’s robustness, adaptability, and distinct advantages over existing methods. Applying this framework to Delhi, we found that a holistic, integrated waste management system is the most promising strategy, outperforming capital-intensive projects like Waste-to-Energy. Our work offers a powerful, structured methodology for cities to make more nuanced, forward-looking decisions and advances MCDM theory by integrating prioritized aggregation within the CT-SFS environment.},
  archive      = {J_EAAI},
  author       = {Fathima Banu M. and S. Solaiappan and Subramanian Petchimuthu and Abrar Hussain},
  doi          = {10.1016/j.engappai.2025.112527},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112527},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Complex T-spherical fuzzy yager prioritized weighted aggregation for prioritizing waste management strategies: A case study from delhi},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Critical nodes detection for complex networks via knowledge-guided evolutionary framework. <em>EAAI</em>, <em>162</em>, 112526. (<a href='https://doi.org/10.1016/j.engappai.2025.112526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Critical Node Problem (CNP) focuses on identifying critical nodes within complex networks. These nodes play a crucial role in maintaining connectivity, and their removal impacts network performance. Among CNP variants, CNP-1a — which minimizes pairwise connectivity after removing a limited number of nodes — has attracted significant research attention due to its NP-hard nature and applications in diverse fields like epidemic control and infrastructure resilience. While state-of-the-art methods leverage memetic algorithms and variable populations, they fundamentally rely on random initialization that often converges to local optima. This limitation arises because traditional methods fail to capture higher-order topological dependencies. To address this gap, we propose K2GA, a knowledge-guided genetic algorithm initialized by a graph attention network (GAT). The GAT embeds networks into low-dimensional spaces, assigning topology-aware attention weights to nodes that guide population initialization. K2GA then employs a hybrid genetic algorithm with a local search process to identify an optimal set of critical nodes. The local search process utilizes a cut node-based greedy strategy. Experiments on 26 real-world networks demonstrate that K2GA outperforms state-of-the-art methods in terms of the best, median, and average objective values, establishing new upper bounds for minimization in eight cases. This work pioneers a GAT-guided evolutionary search framework, offering a novel paradigm for solving CNP.},
  archive      = {J_EAAI},
  author       = {Chanjuan Liu and Shike Ge and Zhihan Chen and Wenbin Pei and Enqiang Zhu and Hisao Ishibuchi},
  doi          = {10.1016/j.engappai.2025.112526},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112526},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Critical nodes detection for complex networks via knowledge-guided evolutionary framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient framework for general long-horizon time series forecasting with mamba and diffusion probabilistic models. <em>EAAI</em>, <em>162</em>, 112525. (<a href='https://doi.org/10.1016/j.engappai.2025.112525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting plays an essential role in supporting critical decision-making processes in risk management and resource allocation in various fields, including finance, transportation, industrial systems, etc. Conventional models can effectively capture volatility and, are proficient in handling specific patterns, such as the AutoRegressive Integrated Moving Average model (ARIMA) and the Generalized AutoRegressive Conditional Heteroskedasticity model (GARCH). Nonetheless, these models meet many challenges, such as high dimensionality, non-stationarity, and nonlinearity inherent in real-world data. Although deep learning methodologies can provide better performance, they may still suffer from long-term errors and heightened computational expenses. A novel framework named Mamba Diffusion Probabilistic Models (MambaDiffTS) is proposed, which integrates Mamba’s state space model with a frequency-aware diffusion process grounded in Denoising Diffusion Probabilistic Models (DDPM). Mamba’s selective state transitions enable linear-time modeling of long-range dependencies; at the same time, frequency-aware spectral decomposition isolates trends and seasonality through Fourier regularization. Furthermore, the implementation of spectral energy-guided noise scheduling preserves temporal fidelity. Extensive experiments on diverse benchmarks-financial volatility, industrial IoT sensor data, and climate modeling-demonstrate MambaDiffTS’s superiority. Notably, on stock forecasting tasks, MambaDiffTS reduces Mean Squared Error (MSE) by approximately 18.6% compared to the best-performing baseline, and substantially outperforms diffusion models, all while maintaining linear computational complexity. The proposed MambaDiffTS facilitates scalable forecasting over extended horizons.},
  archive      = {J_EAAI},
  author       = {Wenjing Wang and Qilei Li and Ziwu Jiang and Deqian Fu and David Camacho},
  doi          = {10.1016/j.engappai.2025.112525},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112525},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient framework for general long-horizon time series forecasting with mamba and diffusion probabilistic models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selecting after sales provider of complex product based on game and matching framework. <em>EAAI</em>, <em>162</em>, 112524. (<a href='https://doi.org/10.1016/j.engappai.2025.112524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a strategic enabler of high-end manufacturing, the high-quality evolution of complex equipment is indispensable for any nation aspiring to industrial leadership. After sales service (AS) long relegated to a support function, which has emerged as a decisive determinant of product life-cycle value and, consequently, of this transformative journey. This study therefore investigates the technological innovation of AS for complex products through a Stackelberg game that captures the collaborative dynamics between an original equipment manufacturer (OEM) and an after-sales service provider (ASP). We derive the necessary and sufficient conditions under which an ASP finds participation economically viable, then embed these conditions into a multi-criteria matching framework that links ASP capabilities with spare-part requirements. Leveraging an entropy weighted DEMATEL (Decision-making Trial and Evaluation Laboratory) hybrid and we first quantify the causal salience of matching attributes and build a parsimonious evaluation index system. Next, by explicitly encoding bilateral attribute preferences, we formulate a two-sided matching model that identifies the Pareto-optimal ASP portfolio for any given product architecture. Finally, backward induction over the integrated game-matching structure yields a prescriptive tool that not only screens ASPs but also prescribes contractual levers to sustain long-term co-innovation. The proposed framework thus unifies strategic participation incentives with operational compatibility, offering OEMs a rigorous, implementable roadmap for selecting and governing after-sales partners in the era of servitized, high-stakes manufacturing.},
  archive      = {J_EAAI},
  author       = {Xin Huang and Xiaoyan Qi and Xiaojuan Xu},
  doi          = {10.1016/j.engappai.2025.112524},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112524},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Selecting after sales provider of complex product based on game and matching framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PLDs-CNN-ridge-ELM: Interpretable lightweight waste classification framework. <em>EAAI</em>, <em>162</em>, 112522. (<a href='https://doi.org/10.1016/j.engappai.2025.112522'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accelerating global population growth and expanding economic activities have resulted in a notable increase in waste generation, necessitating accurate and efficient waste classification systems for sustainable waste management. This research presents a novel two-stage waste classification model leveraging a Lightweight Parallel Depth-wise Separable Convolutional Neural Network (PLDs-CNN), combined with a Ridge Regression Extreme Learning Machine (Ridge-ELM) classifier, using waste images as input. The proposed system efficiently classifies waste into four primary categories (hazardous, household, recyclable, and residual) in the first stage and further refines the classification into twelve subcategories in the second stage. Featuring a lightweight architecture of nine layers and about 1.09 million parameters, the PLDs-CNN model achieves high accuracy with substantially reduced computational overhead, outperforming many deeper networks. In the four-class classification stage, the system achieves an average accuracy of 99 %, with precision, recall, F1-score, and receiver operating characteristics (ROC)-area under the curve (AUC) values of 97.25 ± 0.02 %, 96 ± 0.03 %, 96.5 ± 0.01 %, and 99.28 %, respectively. In the twelve-class classification, the model continues to deliver superior results, with 96 % accuracy and equally strong precision, recall, and F1-score metrics. The system is supported by a real-time hardware architecture, featuring a user-centric Graphical User Interface (GUI), a webcam-enabled conveyor belt sorting mechanism, and a 2-axis pan-tilt system for automated waste sorting. Additionally, the model's interpretability is significantly improved through the integration of Shapley Additive Explanations (SHAP), which provides important perspectives into the decision-making process, increasing transparency and trustworthiness in real-world applications. The proposed framework not only surpasses conventional methods in both accuracy and computational efficiency but also emphasizes sustainability by facilitating cost-effective and scalable waste management solutions aimed at promoting recycling and resource reuse.},
  archive      = {J_EAAI},
  author       = {Mansura Naznine and Md. Nahiduzzaman and Md. Jawadul Karim and Md. Faysal Ahamed and Abdus Salam and Mohamed Arselene Ayari and Amith Khandakar and Azad Ashraf and Mominul Ahsan and Julfikar Haider},
  doi          = {10.1016/j.engappai.2025.112522},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112522},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {PLDs-CNN-ridge-ELM: Interpretable lightweight waste classification framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable interval prediction of dam displacement based on variational autoencoder and improved temporal fusion transformer considering solar radiation effects. <em>EAAI</em>, <em>162</em>, 112520. (<a href='https://doi.org/10.1016/j.engappai.2025.112520'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring the safety of dams is critical to maintaining national economic development and social stability, requiring the implementation of accurate displacement prediction methods for early detection of structural anomalies and effective risk mitigation. However, existing statistical models primarily focus on point predictions, failing to quantify the uncertainty in displacement variations, and often neglect the critical environmental factor of solar radiation. To address these limitations, this study proposes a novel interpretable interval prediction framework that integrates solar radiation factors into an advanced hydrostatic-temperature-time (AHTT) model. A variational autoencoder (VAE) is employed to extract robust latent features from a large volume of measured temperature data, effectively reducing temperature-related noise. Subsequently, an improved temporal fusion transformer method is introduced to probabilistic dam displacement prediction. This method uses an enhanced quantile loss function based on the Huber loss to generate both point and interval predictions that dynamically reflect the prediction uncertainty. In addition, an interpretable multi-head attention module is incorporated to quantify the contribution of each environmental factor. Hyperparameter tuning of the improved temporal fusion transformer is further optimized using Bayesian optimization based on the tree-structured Parzen estimator (TPE), which improves prediction accuracy. Engineering case studies validate that the proposed model not only achieves the highest point prediction accuracy, but also provides narrower prediction intervals with the best coverage width criterion. Ablation experiments and interpretability analyses further confirm the significant impact of solar radiation on dam displacement, providing valuable insights for the development of dam displacement prediction models and risk-informed decision making.},
  archive      = {J_EAAI},
  author       = {Taiqi Lu and Hao Gu and Chongshi Gu and Chenfei Shao and Yiming Wang and Dongyang Yuan},
  doi          = {10.1016/j.engappai.2025.112520},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112520},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interpretable interval prediction of dam displacement based on variational autoencoder and improved temporal fusion transformer considering solar radiation effects},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An undersampling method for software defect prediction based on hilbert curve mapping distance. <em>EAAI</em>, <em>162</em>, 112519. (<a href='https://doi.org/10.1016/j.engappai.2025.112519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The class imbalance problem presents a significant challenge in software defect prediction. The undersampling method enhances prediction performance by eliminating non-defective instances, thereby enabling the model to focus more on defective instances. However, the effective selection of representative non-defective instances while preserving the overall data distribution remains a critical challenge. Inspired by the space-filling property of Hilbert curves, we propose the H ilbert C urve M apping D istance U ndersampling (HCMDU) method for software defect prediction. This method first maps instances to Hamming space to ensure that similar instances are positioned closer together in the space. Instance circular domains are then partitioned based on the Hamming distance between them, which facilitates the exploration of instance variability within a localized region. Finally, the Hilbert curve mapping distance is employed to further uncover the data distribution pattern within the instance circular domains. The experimental results demonstrate that HCMDU delivers outstanding performance across 16 randomly selected software defect datasets in both Random Forest (RF) and Classification and Regression Trees (CART). Moreover, the results are further corroborated by the Friedman ranking and Nemenyi post-hoc test, which indicate that HCMDU significantly improves the performance of software defect prediction.},
  archive      = {J_EAAI},
  author       = {Yu Tang and Ye Du and Ang Li and Ming-song Yang and Yan Xia},
  doi          = {10.1016/j.engappai.2025.112519},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112519},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An undersampling method for software defect prediction based on hilbert curve mapping distance},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised fault diagnosis method for rolling bearings based on federated universal domain adaptation. <em>EAAI</em>, <em>162</em>, 112518. (<a href='https://doi.org/10.1016/j.engappai.2025.112518'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the issues of low diagnostic model accuracy caused by non-sharing of rolling bearing private data, distribution differences, and label space discrepancies across multiple clients, as well as the challenges that certain clients face in obtaining labeled data, an unsupervised fault diagnosis method is proposed for rolling bearings based on federated universal domain adaptation (FUDA). First, privacy protection during the transmission process in federated learning is ensured by implementing random mapping at local clients. Second, the central server employs the proposed mixed radial basis kernel-maximum mean discrepancy (MR-MMD) method to further mitigate distributional disparities between the feature spaces of source and target clients. This achieves unsupervised features alignment between these features. Third, margin vectors are introduced to tackle label space disparities between source and target clients, enabling effective separation of unknown class samples in the dataset of the target client. Finally, a dynamic weighted loss fusion strategy is designed to adaptively optimize the weight ratios of different losses. This enhancement facilitates the learning efficiency of the model. Experimental validation on two datasets demonstrates that the proposed approach can achieve average accuracies of 95.6 % and 87.7 % for the respective datasets. Compared with other methods, it represents improvements of 6.5 % and 8.1 %, while training time is reduced by at least 27 %. These results validate the effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Shouqiang Kang and Yulin Sun and Xinrui Li and Yujing Wang and Qingyan Wang and Xintao Liang},
  doi          = {10.1016/j.engappai.2025.112518},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112518},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised fault diagnosis method for rolling bearings based on federated universal domain adaptation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-scale feature extraction and fusion framework based on wavelet Kolmogorov–Arnold networks and parallel bi-directional gated recurrent units for electric load forecasting. <em>EAAI</em>, <em>162</em>, 112517. (<a href='https://doi.org/10.1016/j.engappai.2025.112517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term electric load forecasting remains challenged by the dual requirements of accuracy and robustness due to the combined effects of strong seasonality, multi-scale spikes, and stochastic disturbances. To address this, we propose a novel multi-scale forecasting framework, NP-WavKAN-Fusion, which integrates Neural Prophet for data decomposition and a Wavelet-based Kolmogorov–Arnold Network (WavKAN) with learnable wavelet kernels for multi-scale encoding. This fusion model utilizes a Bi-directional Gated Recurrent Unit (BiGRU) to capture long-term temporal dependencies and an adaptive feature fusion gate (AFF) to dynamically re-weight static and dynamic features for final load predictions. Extensive experiments on two public datasets from Australia and Morocco show that NP-WavKAN-Fusion consistently outperforms traditional models, reducing the mean absolute error by at least 30 %. For multi-step forecasting tasks, NP-WavKAN-Fusion maintains error inflation within 15 %, demonstrating superior performance compared to state-of-the-art long-sequence models such as Informer and PatchTST. The Diebold–Mariano test confirms that NP-WavKAN-Fusion yields statistically significant improvements, with 19 out of 20 comparisons showing lower errors. Ablation studies show that removing either the Neural Prophet component or the AFF significantly increases the forecasting error, validating the necessity of our layered denoising and fusion strategies. The proposed NP-WavKAN-Fusion framework demonstrates strong potential for real-world applications in electric load forecasting, offering robust performance under various temporal and non-stationary conditions.},
  archive      = {J_EAAI},
  author       = {Chunliang Mai and Lixin Zhang and Xuewei Chao and Xue Hu and Omar Behar},
  doi          = {10.1016/j.engappai.2025.112517},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112517},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-scale feature extraction and fusion framework based on wavelet Kolmogorov–Arnold networks and parallel bi-directional gated recurrent units for electric load forecasting},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resilient kernel-based unsupervised multi-view feature selection via compact binary hashing. <em>EAAI</em>, <em>162</em>, 112515. (<a href='https://doi.org/10.1016/j.engappai.2025.112515'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view feature selection across diverse views identifying a compact subset of the most informative feature across various data views without relying on labeled information. While most of the solutions are limited to linear multi-view data or utilize weakly-supervised single-label learning to assist in feature selection, leading to the loss of valuable semantic information, especially when dealing with complex real-world multi-view datasets. To overcome these limitations, we introduce a novel Resilient Kernel-based Unsupervised Multi-view Feature Selection via compact Binary Hashing (RKUMBH), which aims to search a robust and consistent graph representation across views, leveraging binary hashing codes to guide feature selection. Specifically, we first standardize the dimensionality of multi-view data by using non-linear kernel mapping. Then, we explore consistent graph structures across different views by fusing individual similarity graph of each view under a self-representation guidance. Moreover, the low-rank constraints are used to preserve the primary structures and patterns embedding within the data, and an unsupervised hashing feature selection framework is conducted to generate reliable hashing codes across views. Additionally, we design a customized iterative optimization method to solve the unified model. Extensive experiments on six public multi-view datasets demonstrate that our proposed method obtains state-of-the-art results compared to existing works for both clustering and feature selection tasks.},
  archive      = {J_EAAI},
  author       = {Rongyao Hu and Mengmeng Zhan and Jiangzhang Gan and Li Li and Fei Ye and Tong Liu},
  doi          = {10.1016/j.engappai.2025.112515},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112515},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Resilient kernel-based unsupervised multi-view feature selection via compact binary hashing},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncovering the geometry-dependent optical asymmetry of gold nanorods helical assemblies using artificial neural networks. <em>EAAI</em>, <em>162</em>, 112513. (<a href='https://doi.org/10.1016/j.engappai.2025.112513'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optical asymmetry of gold nanorods (Au-NRs) helical assemblies is well-documented with a wide range of applications. Nevertheless, the geometry-dependent optical asymmetry within these assemblies has not been adequately explored and quantified. The present study proposes a novel approach to predict the optical asymmetry of Au-NRs helical assemblies based on geometric characteristics using artificial neural networks (ANN). The performance of the ANN termed 3 N H L 50 N N was significantly enhanced through the optimization of the hidden layer and node, resulting in an R 2 of the outcomes exceeding 0.998 and a reduction in computational time exceeding 99.99 %. In instances where the specific geometric characteristics are needed to attain a desired optical asymmetry, a retrieval of geometric characteristics of Au-NRs helical assemblies was additionally investigated using a traversing mechanism featured particle swarm optimization (PSO) algorithm. The results of the retrieval were obtained within 6 s and demonstrate a high degree of accuracy and reliability. The combination of the 3 N H L 50 N N and the PSO algorithm is capable of accurately predicting the optical asymmetry of Au-NRs helical assemblies and the retrieval of the geometry characteristics, thereby enabling the quantitative understanding of their overall geometry-dependent optical asymmetry.},
  archive      = {J_EAAI},
  author       = {Yang Liu and Yongguang Chen and Xiyang Wei and Jianhua Shang and Lina Zhao},
  doi          = {10.1016/j.engappai.2025.112513},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112513},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Uncovering the geometry-dependent optical asymmetry of gold nanorods helical assemblies using artificial neural networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting worker loss of balance events from point cloud sequence using unsupervised motion-pose learning. <em>EAAI</em>, <em>162</em>, 112512. (<a href='https://doi.org/10.1016/j.engappai.2025.112512'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workers' loss of balance (LB), such as slip and trip, may lead to severe injuries and even fatalities. Existing methods for detecting LB typically rely on wearable sensors and focus on specific body parts. This study introduces a novel, non-contact approach utilizing light detection and ranging (LiDAR) technology to detect LB events. By capturing full-body point cloud data, the proposed method extracts both static pose and dynamic motion features across multiple body sections and detects LB events through unsupervised learning. The high-dimensional point cloud sequence is transformed into interpretable gait features, enabling effective unsupervised learning through sequence reconstruction. A two-stream network and fusion strategy are also developed to combine pose and motion features for final LB detection. Experiments with various LB events demonstrate the method's effectiveness, achieving an F1 score of 0.98 and a recall of 0.98. Our analysis reveals that integrating features from multiple body parts and the fusion of pose and motion information significantly enhances detection performance. This study offers a promising alternative to traditional methods, providing effective, non-intrusive monitoring of worker safety in dynamic construction environments.},
  archive      = {J_EAAI},
  author       = {Mingyu Zhang and Lei Wang and Yinong Hu and Shuai Han and Jiawen Zhang and Heng Li},
  doi          = {10.1016/j.engappai.2025.112512},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112512},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detecting worker loss of balance events from point cloud sequence using unsupervised motion-pose learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human motion prediction using mixture-of-branch graph convolutional network. <em>EAAI</em>, <em>162</em>, 112511. (<a href='https://doi.org/10.1016/j.engappai.2025.112511'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using the same spatio-temporal feature extraction network to predict multiple types of human motions pose a challenge for the prediction model to achieve optimal performance. To address this issue and achieve differentiated training, we propose a novel Mixture-of-Branch Graph Convolutional Network model which simultaneously inserts human motion sequences into a multi-branch human motion prediction module and a branch weight allocation module. When generating the final prediction sequence, weights are assigned to the prediction results of each branch. Mixture-of-Branch Graph Convolutional Network employs loss values to control competition rather than cooperation among branches, effectively addressing the issue of mutual influence between sequences during network training. To the best of our knowledge, this marks the inaugural utilization of a Mixture-of-Branch network in the realm of human motion prediction. To optimize the efficiency of the multi-branch model and reduce prediction complexity, we introduce a spatio-temporal feature extraction method for the human skeleton that accommodates Euclidean geometric transformations. This method liberates the Mixture-of-Branch Graph Convolutional Network from the constraints of additional branches, allowing it to handle similar motion sequences under varying degrees of translation or rotation, where feature matrices may exhibit significant differences. The proposal of Mixture-of-Branch Graph Convolutional Network and its related experiments represent our contribution to the Artificial Intelligence field, with significant potential value in engineering applications as well. Mixture-of-Branch Graph Convolutional Network is tested on the Human3.6M, Carnegie Mellon University Motion Capture, and Three-Dimensional Human Pose in the Wild datasets, achieving high performance. Particularly noteworthy is the 7% overall performance improvement in Mean Per Joints Position Error prediction on the Carnegie Mellon University Motion Capture dataset.},
  archive      = {J_EAAI},
  author       = {Xianshan Li and Ang Gao and Xingxing Ning and Fengda Zhao},
  doi          = {10.1016/j.engappai.2025.112511},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112511},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Human motion prediction using mixture-of-branch graph convolutional network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid multivariate normal boundary intersection approach with post-optimization assisted by mixture design of experiments. <em>EAAI</em>, <em>162</em>, 112510. (<a href='https://doi.org/10.1016/j.engappai.2025.112510'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a hybrid multiobjective optimization approach for identifying Pareto-optimal solutions by combining evaluation metrics. Using response surface models built from rotated factor scores, the algorithm analyzes the influence of weights on solutions through performance metrics, applying a weighted combination as a post-optimization strategy. The methodology introduces innovations such as the combination of independent functions, polynomial analysis to discover intermediate weights, and the use of prediction-based metrics. To illustrate application of the methodology, a case study was conducted on the turning process of tempered cylindrical steel bars, evaluating dimensions of reliability, quality, and economic performance. The best solution obtained included the following input variables: a cutting speed of 147.792 m per minute, a feed rate of 0.156 mm per revolution, and a depth of cut of 0.247 mm. The resulting output variables included a mean tool life of 46.316 min, mean time to failure of 47.164 min, a wear rate of 0.006 mm per minute, an average surface roughness of 0.746 μm, a total surface roughness of 3.406 μm, a process cost of 3.721 dollars, a return on investment of 0.187, and overall equipment effectiveness of 0.387. Comparisons were made with other optimization methods, revealing satisfactory performance based on key metrics. The methodology was also tested on benchmark functions to assess its robustness and adaptability to different scenarios. In addition, the method was implemented in an online quality monitoring system using the Random Forest machine learning algorithm, and results indicate that optimal conditions can be identified quickly and effectively.},
  archive      = {J_EAAI},
  author       = {Matheus Costa Pereira and Caio Tertuliano Ribeiro and Ronã Rinston Amaury Mendes and Paulo Henrique da Silva Campos and Anderson Paulo de Paiva},
  doi          = {10.1016/j.engappai.2025.112510},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112510},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid multivariate normal boundary intersection approach with post-optimization assisted by mixture design of experiments},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inverse design of particle shapes with target sphericity and packing fraction using variational autoencoders. <em>EAAI</em>, <em>162</em>, 112509. (<a href='https://doi.org/10.1016/j.engappai.2025.112509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sphericity and packing fraction are fundamental properties governing the behavior of granular materials in many engineering applications. Conventional methods for designing particles with these target properties usually suffer from limited accuracy, diversity, and interpretability due to complex relationships between particle shape and properties. To address this, we propose an inverse design framework based on deep learning. First, a rotation- and reflection-invariant variational autoencoder (VAE) parameterizes two-dimensional convex particle shapes into a low-dimensional latent space, enabling accurate reconstruction and capturing geometric interpretations such as sphericity and symmetry. Second, a conditional variational autoencoder (CVAE) facilitates inverse design by generating particle shapes corresponding to target sphericity or packing fraction, and also enables the coupling control of both properties. Trained on a dataset of over 1600 convex shapes, the framework demonstrates robustness and universality. The rotation- and reflection-invariant architecture consistently maps different orientations of the same shape to a unified representation, which enhances interpretability. The main contribution in artificial intelligence lies in developing invariant generative models that learn shape representations and enable property-driven shape generation. The engineering contribution is providing a precise and efficient tool for the inverse design of particle shapes with target properties, supporting the optimization of granular materials in engineering applications.},
  archive      = {J_EAAI},
  author       = {Yutong Qian and Shuixiang Li},
  doi          = {10.1016/j.engappai.2025.112509},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112509},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inverse design of particle shapes with target sphericity and packing fraction using variational autoencoders},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-way dynamic clustering algorithms based on generalized neighborhood relations in incomplete hybrid information systems with applications in medical decision-making. <em>EAAI</em>, <em>162</em>, 112508. (<a href='https://doi.org/10.1016/j.engappai.2025.112508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In addressing clinical challenges related to chronic diseases, the effective use of medical data in decision-making is often hindered by issues such as incompleteness, heterogeneity, and the need for continuous updates. To cope with these challenges, this study introduces a three-way dynamic clustering strategy built upon generalized neighborhood relations, aiming to enhance clustering robustness, strengthen the model’s ability to manage uncertainty, and support adaptability to dynamically evolving data. First, generalized neighborhood relations are constructed in incomplete hybrid information systems. An evaluation function is defined from two perspectives: the number of similar attributes between objects and the distance between objects, thereby optimizing similarity measurement and accurately characterizing the data structure. Second, three-way decision rules are introduced to effectively handle uncertainty in objects while maintaining classification accuracy, thereby improving the interpretability and adaptability of the clustering model. Furthermore, to accommodate the dynamic nature of medical data, a dynamic incremental clustering method based on neighborhood information is proposed to ensure that newly added patient data can be efficiently integrated into existing clusters, enhancing model real-time performance and computational efficiency. Experiments conducted on real clinical data from Chronic kidney disease (CKD) patients validate the proposed method. The results demonstrate that, compared to existing clustering algorithms, the proposed method outperforms in terms of F1-score and Rand Index evaluation metrics. It also exhibits higher applicability in patient classification, core and boundary domain partitioning, and dynamic data processing, providing effective support for precision stratified management of chronic disease patients and intelligent medical decision-making.},
  archive      = {J_EAAI},
  author       = {Haoran Sun and Bingzhen Sun and Xixuan Zhao and Qiang Bao and Xiaoli Chu},
  doi          = {10.1016/j.engappai.2025.112508},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112508},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Three-way dynamic clustering algorithms based on generalized neighborhood relations in incomplete hybrid information systems with applications in medical decision-making},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A three-stage segmentation framework for lung cancer lesion isolation in three-dimensional positron emission tomography images. <em>EAAI</em>, <em>162</em>, 112507. (<a href='https://doi.org/10.1016/j.engappai.2025.112507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background Positron emission tomography (PET) is a critical functional medical imaging modality for the early detection and diagnosis of cancers. PET imaging faces several challenges that hinder accurate interpretation including its inherently low spatial resolution, substantial variability in cancer lesions’ appearance, and difficulties distinguishing between the image background and benign lesions. Methods We propose a novel three-stage image segmentation framework to enhance the accuracy of lung cancer lesion identification and extraction from three-dimensional (3D) PET images. The first stage conducts a coarse segmentation using an encoder-decoder structure network to roughly position lesions. The second stage employs a multi-layer feature extraction network to learn the detailed characteristics of coarse segmentation results, mitigating false positives caused by localization inaccuracy. The last stage further refines the extracted features via dividing a sub-region of the lesion into foreground and background branches, reducing false positives caused by over-segmentation of edges. A novel lesion count loss function is introduced to guide the model to generate predictions during the training, ensuring that the predicted lesion counts align with the ground truth labels. Results The proposed method was evaluated on clinical 3D PET image datasets. Experimental results demonstrated a Dice Similarity Coefficient (DSC) of 85.35 %, Accuracy of 83.97 %, and Recall of 86.83 %. Compared to existing models applied to the same datasets, our method consistently achieved superior performance. Conclusion The proposed method significantly improves the segmentation performance of lung cancer lesions, implying that our method holds substantial potential for broader clinical application, even in low-resolution images.},
  archive      = {J_EAAI},
  author       = {Yusheng Wu and Qiang Lin and Jingjun Wei and Yongchun Cao and Zhengxing Man and Xiaodi Huang},
  doi          = {10.1016/j.engappai.2025.112507},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112507},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A three-stage segmentation framework for lung cancer lesion isolation in three-dimensional positron emission tomography images},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised visual assessment of railway track curvature via homography learning based on projective curvilinear geometry model. <em>EAAI</em>, <em>162</em>, 112506. (<a href='https://doi.org/10.1016/j.engappai.2025.112506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Railway track curvature monitoring is crucial for ensuring operational safety and passenger comfort. As a robust complement to the single-point physical sensor approaches, vision-based methods have recently gained increasing adoption. However, existing approaches frequently neglect the systematic exploitation of railway ego-vision geometry in two critical aspects: (1) the rail-camera kinematic coupling that relates the rail appearance in camera’s view and the track curvature during curvilinear motion, and (2) the potential of self-supervised learning to overcome annotation scarcity in this domain. This geometric oversight limits their accuracy in real-world dynamic scenarios. To address these gaps, this study proposes a novel vision-based framework that systematically exploits the railway ego vision geometry. Our methodology comprises two key innovations: First, a projective curvilinear geometry model that mathematically relates the ground-planes-induced homography to actual track curvature, thereby establishing a mapping from curvature and its variation to rail imaging curves. Second, a self-supervised curvature prediction network trained using automatically generated labels from our geometric model, eliminating the need for manual curve annotations. The self-supervision is achieved through a cyclic consistency mechanism between predicted curvatures and reprojected image features. Experimental validation using real-world railway footage demonstrates significant improvements: Our method reduces the average root mean squared error by 23.31% compared to state-of-the-art vision-based curvature estimation methods. These results underscore the effectiveness of geometry-aware computer vision for railway geometry monitoring},
  archive      = {J_EAAI},
  author       = {Peng Tang and Zhibin Yu},
  doi          = {10.1016/j.engappai.2025.112506},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112506},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-supervised visual assessment of railway track curvature via homography learning based on projective curvilinear geometry model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Saliency and correlation learning for co-salient object detection. <em>EAAI</em>, <em>162</em>, 112504. (<a href='https://doi.org/10.1016/j.engappai.2025.112504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Co-Salient object detection aims to identify common salient objects across a given group of images. However, accurately locating co-salient objects remains challenging due to the complexity of capturing the correlation representation of each group of images. To tackle this problem, we propose a saliency and correlation learning method for co-salient object detection. This method employs a saliency learning network and a correlation learning network to generate precise co-saliency maps of a group of images. Within the saliency learning network, a saliency feature grafting module is designed to refine object edges and achieve accurate detection of salient objects. Furthermore, the correlation learning network incorporates two modules, which are designed for extracting saliency correlation representation and deriving consensus correlation representation within a group of images, respectively. Guided by prior information obtained from saliency learning of images, our method significantly improves performance in co-salient object detection through correlation representation learning. Extensive experiments on all the latest benchmarks demonstrate that our method outperforms 11 state-of-the-art models, achieving a new level of technical excellence, with an average Structural Similarity Measure score of 0.845.},
  archive      = {J_EAAI},
  author       = {Ying Tong and Xiangfeng Luo and Liyan Ma and Shaorong Xie},
  doi          = {10.1016/j.engappai.2025.112504},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112504},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Saliency and correlation learning for co-salient object detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated monitoring of mycobacterium population growth in time-lapse microscopy with deep learning pseudo-supervised algorithm. <em>EAAI</em>, <em>162</em>, 112503. (<a href='https://doi.org/10.1016/j.engappai.2025.112503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The understanding of bacteria evolution through time and the analysis of their interaction with the medium is a main step in biomedical research. Bacteria cause in humans different infectious diseases, such as tuberculosis. Tuberculosis is one of the leading causes of death worldwide, caused by Mycobacterium tuberculosis ( Mtb ). Observation of Mycobacteria under a microscope provides essential information for disease-fighting. Nevertheless, Mtb presents a very particular cell division pattern characterized by a high entanglement in which the frontier between dividing cells are almost indistinguishable to the human eye, which makes the manual analysis of cultures a very challenging task, resulting in extremely long processing times. In this paper, we propose a novel approach to automatically detect bacterial cells and infer the growth rate and growth speed over a time-lapse microscopy (TLM) sequence. This method leverages a semi-supervised Deep Learning approach with a lightweight U-Net for efficient and fast processing. To reduce efforts of database construction, we deploy and exploit a mix of manually and synthetically annotated databases of two different classes of Mycobacterium , i.e. Mtb and Mycobacterium smegmatis ( Msm ). The experiments demonstrated the efficiency of the detection of both bacterial reproduction rate and bacterial death in Mycobacterium species, with the Phase-contrast (PhC) microscopy channels as a unique input. Reaching a segmentation accuracy of 96.3%, recall of 78.2%, and precision of 85.5% on Mtb detection for the model trained with a mix of manually and synthetically annotated databases. The experiments validate as well the synthetic label generation technique, which provides more conscience and accurate results than the manually segmented techniques. The mask generation workflow opens new opportunities for the microbial AI development field. The system implemented may change the paradigm in preclinical anti-mycobacteria drug development for since enables the adoption of TLM, a technology that provides extremely valuable information on drug efficacy but is seldom leveraged due to the complex image processing it involves.},
  archive      = {J_EAAI},
  author       = {Lara Visuña and Javier Garcia-Blas and Santiago Ferrer-Bazaga and Patricio Lopez-Exposito and Jesus Carretero},
  doi          = {10.1016/j.engappai.2025.112503},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112503},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automated monitoring of mycobacterium population growth in time-lapse microscopy with deep learning pseudo-supervised algorithm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reducing the estimation bias and variance in reinforcement learning via maxmean and aitken value iteration. <em>EAAI</em>, <em>162</em>, 112502. (<a href='https://doi.org/10.1016/j.engappai.2025.112502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The value-based reinforcement leaning methods suffer from overestimation bias, because of the existence of max operator, resulting in suboptimal policies. Meanwhile, variance in value estimation will cause the instability of networks. Many algorithms have been presented to solve the mentioned, but these lack the theoretical analysis about the degree of estimation bias, and the trade-off between the estimation bias and variance. Motivated by the above, in this paper, we propose a novel method based on Maxmean and Aitken value iteration, named MMAVI. The Maxmean operation allows the average of multiple state–action values (Q values) to be used as the estimated target value to mitigate the bias and variance. The Aitken value iteration is used to update Q values and improve the convergence rate. Based on the proposed method, combined with Q-learning and deep Q-network, we design two novel algorithms to adapt to different environments. To understand the effect of MMAVI, we analyze it both theoretically and empirically. In theory, we derive the closed-form expressions of reducing bias and variance, and prove that the convergence rate of our proposed method is faster than the traditional methods with Bellman equation. In addition, the convergence of our algorithms is proved in a tabular setting. Finally, we demonstrate that our proposed algorithms outperform the state-of-the-art algorithms in several environments.},
  archive      = {J_EAAI},
  author       = {Fanghui Huang and Wenqi Han and Xiang Li and Xinyang Deng and Wen Jiang},
  doi          = {10.1016/j.engappai.2025.112502},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112502},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reducing the estimation bias and variance in reinforcement learning via maxmean and aitken value iteration},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid reinforcement learning in parameterized action space via fluctuates constraint. <em>EAAI</em>, <em>162</em>, 112499. (<a href='https://doi.org/10.1016/j.engappai.2025.112499'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameterized actions in Reinforcement Learning (RL) are composed of discrete-continuous hybrid action parameters, which are widely employed in game scenarios. However, previous works have often concentrated on the network structure of RL algorithms to solve hybrid actions, neglecting the impact of fluctuations in action parameters for agent move trajectory. Due to the coupling between discrete and continuous actions, instability in discrete actions influences the selection of corresponding continuous parameters, resulting in the agent deviating from the optimal move path. In this paper, we propose a parameterized RL approach based on parameter fluctuation restriction (PFR) to address this problem, called CP-DQN. Our method effectively mitigated value fluctuation in action parameters by constraining the action parameter between adjacent time steps. Additionally, we have incorporated a supervision module to optimize the entire training process. To quantify the superiority of our approach in minimizing trajectory deviations for agents, we propose an indicator to measure the influence of parameter fluctuations on performance in hybrid action space. Our method is evaluated in three environments with hybrid action spaces, and the experiments demonstrate the superiority of our method compared to existing approaches.},
  archive      = {J_EAAI},
  author       = {Chengcheng Yan and Shujie Chen and Jiawei Xu and Xuejie Wang and Zheng Peng},
  doi          = {10.1016/j.engappai.2025.112499},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112499},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid reinforcement learning in parameterized action space via fluctuates constraint},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAVREN: A multilayered adaptive framework for deploying vision-language models on resource-constrained unmanned aerial vehicles for autonomous search and rescue. <em>EAAI</em>, <em>162</em>, 112498. (<a href='https://doi.org/10.1016/j.engappai.2025.112498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAVs) have become indispensable in autonomous search and rescue (SAR) missions, where the ability to interpret complex visual scenes in real time is critical. When equipped with artificial intelligence (AI)-empowered Vision-Language Models (VLMs), UAVs can provide rich contextual insights, interpret their findings, and even suggest next steps, but their deployment on resource-constrained UAV platforms is vastly limited by high computational demands, energy constraints, and strict latency requirements. This paper introduces MAVREN, a m ultilayered a daptive scheduler for V LM execution in re source-constrained UAV n etworks for autonomous SAR operations. Evaluations conducted on NVIDIA Jetson Orin NX using state-of-the-art VLMs such as Large Language and Vision Assistant (LLaVA) 1.6 and Vision-Language Alignment (VILA) 7B demonstrate that MAVREN achieves up to 26.11% higher throughput , 23% lower energy consumption , 13.51% reduced latency , and a 7% gain in detection accuracy compared to baseline schedulers across indoor, outdoor, and multi-UAV SAR scenarios. This is achieved through the integration of a visual encoder for lightweight feature extraction, a block floating-point quantizer for precision-efficient representation, a bit-wise computation engine for fast arithmetic execution, and a branch-and-bound optimizer for dynamic central processing unit (CPU) scheduling. These tightly coupled components allow MAVREN to optimize the energy–latency–accuracy trade-off, making it a deployable solution for vision-language reasoning in real-world SAR missions. Our findings demonstrate MAVREN’s capability to deliver rapid, energy-efficient inference, advancing the deployment of computationally intensive VLMs on resource-constrained UAV platforms.},
  archive      = {J_EAAI},
  author       = {Md Tahmid Rashid and Md Jawad Siddique and Abdus Shaqur},
  doi          = {10.1016/j.engappai.2025.112498},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112498},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MAVREN: A multilayered adaptive framework for deploying vision-language models on resource-constrained unmanned aerial vehicles for autonomous search and rescue},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rapid prediction of structural deflection based on explainable machine learning. <em>EAAI</em>, <em>162</em>, 112497. (<a href='https://doi.org/10.1016/j.engappai.2025.112497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-pressure arched air-rib membrane structures (HP-ARMS) exhibit lightweight portability and modular installation. This study proposes an explainable machine learning (ML) framework for the prediction of blast-induced HP-ARMS deflection. Firstly, compare the simulation results with the experimental data to verify the numerical method accuracy. Subsequently, a database containing 500 samples was established through numerical modeling. The input features include 6 structural parameters (air-rib pressure (X1), air-rib diameter (X2), air-rib thickness (X3), air-rib width (X4), air-rib height (X5), and air-rib bottom consolidation method (X6)) and 4 external load parameters (soil cover depth (X7), lateral explosion distance (X8), explosion equivalent (X9), and charge burial depth (X10)). Use Six ML algorithms—Light Gradient Boosting Machine (LightGBM), Random Forest (RF), Adaptive Boosting (AdaBoost), K-Nearest Neighbors (KNN), Convolutional Neural Network (CNN), and Gradient Boosting (GB)— and use four evaluation metrics to assess the accuracy of the ML model. Finally, the SHapley Additive exPlans (SHAP) method was used for interpretable analysis. The results showed that the LightGBM model had the best prediction performance. Compared with LightGBM, the Random-LightGBM (R-LightGBM) model significantly improved performance after hyperparameter optimization, with Root Mean Square Error (RMSE) reduced by 2.75 %, Mean Absolute Percentage Error (MAPE) reduced by 8.16 %, Mean Absolute Error (MAE) reduced by 5.88 %, and R-Squared (R 2 ) increased by 0.01. The SHAP method indicates that the explosion equivalent (X9) and charge burial depth (X10) are the most important parameters.},
  archive      = {J_EAAI},
  author       = {Yongtao Mi and Yushuai Zhang and Yicun Chen and Chenxi Sun and Huiqi Ren},
  doi          = {10.1016/j.engappai.2025.112497},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112497},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Rapid prediction of structural deflection based on explainable machine learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A latent-coupled neural network for multiphysics long-term forecasting in reactor transients using sparse observations. <em>EAAI</em>, <em>162</em>, 112496. (<a href='https://doi.org/10.1016/j.engappai.2025.112496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex dynamical systems in safety-critical applications like nuclear reactors involve strongly coupled physical fields evolving over space and time. Accurate prediction of these fields is vital for safety monitoring but is challenged by limited sensor placement and unobservable variables ( e.g. , xenon and iodine concentrations). This paper proposes the S parse observation to H igh-dimensional coupled physical field P rediction Network (SHPNet), a deep learning framework that predicts and reconstructs multiple physical fields directly from sparse observations.SHPNet combines a three-branch autoencoder to extract shared latent representations with a neural operator that models temporal dynamics in latent space, enabling efficient long-term forecasting. Evaluated on H ua-long P ressurized R eactor (HPR1000) under varying power and burnup conditions, SHPNet outperforms traditional frameworks and end-to-end model , achieving higher accuracy, robustness to observation sparsity, and effective reconstruction of unobservable fields. These results demonstrate SHPNet’s potential as a practical tool for real-time monitoring of complex coupled systems.},
  archive      = {J_EAAI},
  author       = {Yu-Yan Xu and Jun Luo and Deng Pan and Wei Lu and Ting Liu and Guanghui Yuan and Minxiao Zhong and Qing Li and Helin Gong},
  doi          = {10.1016/j.engappai.2025.112496},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112496},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A latent-coupled neural network for multiphysics long-term forecasting in reactor transients using sparse observations},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ESIGCF: Extremely simplified but intent-enhanced graph collaborative filtering for recommendation. <em>EAAI</em>, <em>162</em>, 112495. (<a href='https://doi.org/10.1016/j.engappai.2025.112495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) and graph contrastive learning (GCL) have substantially advanced recommender systems by modeling high-order user–item interactions and leveraging self-supervised signals. However, many existing methods overemphasize user–user or item–item similarities and rely on complex intent modeling, leading to increased complexity and limited exposure to diverse items. To address these challenges, we propose ESIGCF ( E xtremely S implified but I ntent-enhanced G raph C ollaborative F iltering) — a lightweight yet effective recommendation framework. ESIGCF explicitly defines user intent as the inner product between user and item embedding vectors and comprises two primary modules: (i) an intent-enhanced GCN that uses hybrid normalization (combining mean- and symmetric-normalization) to capture fine-grained user–item preferences without additional intent parameters, and (ii) an intent-aware GCL that aligns user–item pairs and positive and generated negative items. Negative samples are generated via a non-linear activation of item embedding interactions, promoting exposure to varied candidates without data augmentation. Experiments on three public datasets (Alibaba-iFashion, Yelp2018, Amazon-Book) show that ESIGCF consistently outperforms state-of-the-art baselines. For instance, on Alibaba-iFashion, ESIGCF achieves Recall@20 of 0.1273 versus 0.1059 for the best intent-enhanced baseline (a 20.2% relative improvement). Comprehensive experiments confirm that ESIGCF effectively captures latent user intent, mitigates popularity bias, and enhances recommendation performance with reduced complexity. Our code is available at https://github.com/Yangzhi22/ESIGCF .},
  archive      = {J_EAAI},
  author       = {Zhi Yang and Ruizhang Huang and Yanping Chen and Chuan Lin and Yongbin Qin},
  doi          = {10.1016/j.engappai.2025.112495},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112495},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ESIGCF: Extremely simplified but intent-enhanced graph collaborative filtering for recommendation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fusing spatial–temporal information into deep learning via wind propagation theory to enhance wind power prediction. <em>EAAI</em>, <em>162</em>, 112494. (<a href='https://doi.org/10.1016/j.engappai.2025.112494'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting wind power poses significant challenges because of the inherent randomness and intermittency of wind speed, thereby impeding effective wind power scheduling. This study proposes an improved deep learning model which leverages wind propagation theory to uncover spatial–temporal relationships among wind turbines to enhance the performance of wind power prediction. In addition, comprehensive theoretical and empirical analyses are conducted to justify the effectiveness of leveraging wind propagation theory for capturing spatio-temporal relationships among wind turbines. Moreover, spatio-temporal dependencies are modeled through a dual mechanism: multi-channel independent modeling for per-turbine temporal dynamics and wind propagation-based matrix computations for inter-turbine spatial relationships, which together significantly reduce computational complexity while preserving predictive performance. Data from 134 wind turbines and six comparison models were employed to validate the robustness and effectiveness of the proposed model. Empirical results indicate that the proposed model outperforms the baseline models, achieving an average improvement of 6.19% in Root Mean Square Error and 7.05% in Mean Absolute Error.},
  archive      = {J_EAAI},
  author       = {Maolin He and Jujie Wang},
  doi          = {10.1016/j.engappai.2025.112494},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112494},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fusing spatial–temporal information into deep learning via wind propagation theory to enhance wind power prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LIP-MC: Multi-constraint label independent prediction in label distribution learning. <em>EAAI</em>, <em>162</em>, 112493. (<a href='https://doi.org/10.1016/j.engappai.2025.112493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label distribution learning can resolve label ambiguity precisely by determining how well each label describes an instance. Traditional label distribution learning algorithms frequently attempt to model the complex relationships between all labels. This not only adds complexity to the model but may also reduce prediction accuracy due to label conflicts. In this paper, we propose a novel label distribution learning algorithm based on Multi-Constraint Label Independent Prediction (LIP-MC), intended to promote the rationality and accuracy of prediction results by simplifying the prediction process and combining multiple constraints. Specifically, label independent prediction values are generated for each label through sparsity constraints and weight coefficient matrices. Subsequently, a novel transformation model is designed to combine all separate label predictions and produce the final label distribution. Furthermore, smoothness constraints and logarithmic similarity constraints were introduced to enhance the model’s performance and generalization ability. On fourteen real datasets, the experiment was carried out, and the comparison results against seven advanced algorithms under seven evaluation metrics confirmed that the proposed algorithm is superior.},
  archive      = {J_EAAI},
  author       = {Gui-Lin Li and Ruili Wu and Xiaorui Qian and Qiang Zhu and Heng-Ru Zhang},
  doi          = {10.1016/j.engappai.2025.112493},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112493},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {LIP-MC: Multi-constraint label independent prediction in label distribution learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed dynamic bayesian networks for time-dependent reliability prediction of subsea wellhead sealing system with multi-states. <em>EAAI</em>, <em>162</em>, 112492. (<a href='https://doi.org/10.1016/j.engappai.2025.112492'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Subsea Wellhead Sealing System (SWSS) is crucial for the safety of deepwater operating, yet its reliability assessment faces challenges from harsh environments and multi-factor interactions. This study developed a data-driven, physics-informed reliability assessment method combining Finite Element Analysis (FEA) and Dynamic Bayesian Networks (DBN). An FEA model is established based on metal sealing theory, and a data-driven reliability model is subsequently constructed through sampling analysis, with a numerical-to-state conversion method bridging FEA and DBN. The FEA-DBN approach offers two key advantages: eliminating expert scoring subjectivity through physics-based modeling and effectively capturing multi-factor interactions and time-dependent behaviors. Results show this method can precisely quantify the evolution of SWSS reliability throughout its service lifecycle, with the probability of failure increasing from 0.64 % to 3.38 % over a 30-year service life. Case studies demonstrate its effectiveness for deep-sea equipment assessment, particularly in operating environments where real-time monitoring proves challenging, thereby demonstrating significant engineering application value.},
  archive      = {J_EAAI},
  author       = {Shengnan Wu and Han Gong and Long Yu and Aibo Zhang and Laibin Zhang and Yiliu Liu},
  doi          = {10.1016/j.engappai.2025.112492},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112492},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed dynamic bayesian networks for time-dependent reliability prediction of subsea wellhead sealing system with multi-states},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constructing a robust short-text clustering model for contrastive learning based on optimized adaptive optimal transport for pseudo-label generation. <em>EAAI</em>, <em>162</em>, 112491. (<a href='https://doi.org/10.1016/j.engappai.2025.112491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-text data often suffers from noise and class imbalances, posing challenges for effective clustering. To address these issues, we propose a Short-Text Clustering Model based on Pseudo-Labels and Contrastive Learning (SCPCL). The model comprises two key components: (1) a pseudo-label acquisition module, which introduces the optimal transport theory into short-text clustering and adopts a dynamically adjusted prior distribution to enhance the clustering of minority classes; and (2) a contrastive learning module combining a supervised clustering network, an instance contrastive head, and an anchor network. These components ensure intraclass compactness, interclass separability, and robustness to noise. Experiments on six benchmark datasets showed that SCPCL achieves an average clustering accuracy improvement of 2.61%, with a maximum gain of 6.47% for long-tailed distributions. This model provides an effective solution for clustering complex short text data.},
  archive      = {J_EAAI},
  author       = {Jiahui Liu and Chun Yan and Wei Liu and Yi Ding},
  doi          = {10.1016/j.engappai.2025.112491},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112491},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Constructing a robust short-text clustering model for contrastive learning based on optimized adaptive optimal transport for pseudo-label generation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid semantic-structural graph neural network for fault knowledge graph completion in railway operational equipment. <em>EAAI</em>, <em>162</em>, 112490. (<a href='https://doi.org/10.1016/j.engappai.2025.112490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete fault knowledge graphs in railway operational equipment hinder effective fault diagnosis, prediction, and maintenance planning. This study addresses the challenge of completing fault knowledge graph by proposing a hybrid semantic-structural graph neural network (Hybrid S-GNN) that integrates both semantic and structural information for knowledge graph completion (KGC) in railway fault scenarios. The Hybrid S-GNN comprises four key modules: a semantic encoding module that enhances textual fault data representations through contextual enhancement and dynamic weight allocation; a structural encoding module that captures graph topology using multi-view structure encoding combining local aggregation, global path encoding, and relation-aware adjustment; a semantic-structural fusion module leveraging attention mechanisms to balance semantic and structural signals; and an optimization-prediction module employing margin-based ranking loss and context-aware negative sampling for accurate triple prediction. Experiments on real-world railway fault knowledge graphs demonstrate that Hybrid S-GNN achieves a Hits@10 of 80.5 % and mean reciprocal rank (MRR) of 0.640, outperforming state-of-the-art baselines by 5.8 % and 6.1 %, respectively. Ablation studies confirm the critical contributions of each module, validating the necessity of jointly modeling semantic and structural features. This work provides an effective solution to enhance railway fault knowledge graphs and paves the way for advanced fault management applications in railway operations.},
  archive      = {J_EAAI},
  author       = {Xiaorui Yang and Honghui Li and Yi Xu and Yunhao Deng and Yanhui Bai and Shufang Liu},
  doi          = {10.1016/j.engappai.2025.112490},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112490},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid semantic-structural graph neural network for fault knowledge graph completion in railway operational equipment},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balancing efficiency and accuracy: Extreme gradient boosting and neural networks for near real-time brain deformation prediction in sports collisions. <em>EAAI</em>, <em>162</em>, 112489. (<a href='https://doi.org/10.1016/j.engappai.2025.112489'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid head motion during sports collisions can cause traumatic brain injury. Head motion can be measured with instrumented mouthguards and fed into finite element (FE) models to predict brain strain, a measure of brain deformation and injury. Due to the computational cost of FE models, deep neural networks have been developed for near real-time prediction. However, they are not used in pitch-side assessments due to their complexity and reliance on full kinematic data, which cannot be reliably transmitted in real-time. We propose an extreme gradient boosting (XGBoost) model with simple input of two kinematic features. Its accuracy and efficiency were compared with two deep learning models: a multilayer perceptron (MLP) using 20 features, and a convolutional neural network (CNN) using entire kinematics. All models were trained on 1701 rugby impacts collected with mouthguards and simulated using the Imperial brain FE model. The XGBoost model predicted strain in key brain regions, while the deep learning models predicted whole-brain strain distributions. All models showed reasonable accuracy in predicting regional strain, with R 2 values 0.764–0.851 for XGBoost, 0.721–0.876 for MLP, and 0.744–0.887 for CNN. XGBoost required orders of magnitude fewer floating-point operations, and it used simple input that can be calculated on mouthguards and reliably transmitted in real-time. This study suggests that different models can be used at different stages of brain injury assessment. We hope that the XGBoost model proposed here will lower the barriers for adopting brain strain combined with instrumented mouthguards for pitch-side assessments from elite to grassroot collision sports.},
  archive      = {J_EAAI},
  author       = {Emily Yik Kwan Chan and Xiancheng Yu and Chen Qin and Mazdak Ghajari},
  doi          = {10.1016/j.engappai.2025.112489},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112489},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Balancing efficiency and accuracy: Extreme gradient boosting and neural networks for near real-time brain deformation prediction in sports collisions},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards lensless image deblurring with prior-embedded implicit neural representations in the low-data regime. <em>EAAI</em>, <em>162</em>, 112488. (<a href='https://doi.org/10.1016/j.engappai.2025.112488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of computational imaging has witnessed a promising paradigm shift with the emergence of untrained neural networks, offering novel solutions to inverse computational imaging problems. While existing techniques have demonstrated impressive results, they often operate either in the high-data regime, leveraging Generative Adversarial Networks (GANs) as image priors, or through untrained iterative reconstruction in a data-agnostic manner. This paper delves into lensless image reconstruction, a subset of computational imaging that replaces traditional lenses with computation, enabling the development of ultra-thin and lightweight imaging systems. To the best of our knowledge, we are the first to leverage implicit neural representations for lensless image deblurring, achieving reconstructions without the requirement of prior training. We perform prior-embedded untrained iterative optimization to enhance reconstruction performance and speed up convergence, effectively bridging the gap between the no-data and high-data regimes. Through a comprehensive comparative analysis of various untrained and low-shot methods, including under-parameterized non-convolutional techniques and domain-restricted low-shot approaches, we demonstrate that our method outperforms these alternatives by a significant margin. This work paves the way for the development of resource-constrained compact imaging systems, which can be applied in fields such as biomedical microscopy and embedded vision in low-data scenarios.},
  archive      = {J_EAAI},
  author       = {Abeer Banerjee and Sanjay Singh},
  doi          = {10.1016/j.engappai.2025.112488},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112488},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards lensless image deblurring with prior-embedded implicit neural representations in the low-data regime},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive detection method for driver fatigue using facial multisource dynamic behavior fusion. <em>EAAI</em>, <em>162</em>, 112482. (<a href='https://doi.org/10.1016/j.engappai.2025.112482'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving while fatigued is a leading cause of traffic accidents. This study proposed an adaptive detection model to recognize driver fatigue based on the dynamic facial behavior information of drivers. First, drivers’ facial fatigue features were extracted to establish a general feature space, including pupil movement, eye state, and fatigue expression parameters. A differentiated feature space was then built based on individual drivers, taking into account the homogeneity, regularity, and individual variances in drivers' facial behavior at various states. A complete adaptive fatigue feature space was built by integrating the general feature space and differentiated feature space. Finally, a driver adaptive fatigue discrimination model was constructed to classify the general and adaptive fatigue feature space to detect driver fatigue states adaptively. A driver fatigue detection dataset from real scenarios had been established to validate the performance of the proposed model. Experimental results demonstrated that the proposed method significantly improved the detection accuracy of driver fatigue. In terms of artificial intelligence, this study contributes a novel adaptive feature space construction method based on multimodal dynamic feature fusion for facial fatigue recognition; in engineering application, it develops an adaptive driver fatigue detection system grounded in multimodal dynamic behaviors, which provides real-time alerts upon detecting driver fatigue and ensures driving safety.},
  archive      = {J_EAAI},
  author       = {Guoxin Zhang and Fei Yang and Xin Fang and Lili Wang and Lei Zhao and Chaoning Yu},
  doi          = {10.1016/j.engappai.2025.112482},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112482},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive detection method for driver fatigue using facial multisource dynamic behavior fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thermoeconomic optimization of climate-adaptive solar and wind multi-generation systems using artificial intelligence and thermal energy recovery. <em>EAAI</em>, <em>162</em>, 112481. (<a href='https://doi.org/10.1016/j.engappai.2025.112481'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a hybrid multi-generation energy system designed to overcome solar intermittency while meeting the global demand for integrated delivery of electricity, water, cooling, and sustainable fuels in the transition to decarbonization. The engineering application integrates solar thermal and wind energy with a modified Brayton cycle, a Steam Rankine Cycle (SRC), and a Thermoelectric Generator (TEG) to simultaneously produce electricity, fresh water via Reverse Osmosis (RO), hydrogen and oxygen via Proton Exchange Membrane Electrolyzer (PEME), and cooling (via absorption chiller) within a unified optimization framework. The system was modeled using Engineering Equation Solver (EES) and optimized via Response Surface Methodology (RSM) based on 11 decision variables. To address the complexity of optimization, a second phase applied Artificial Intelligence (AI) techniques: Adaptive Boosting (AdaBoost) for predictive modelling and Particle Swarm Optimization (PSO) for global optimization. Under optimal conditions, the Response Surface Methodology yielded an exergy efficiency of 45.8 % with a cost rate of 576.76 United States Dollars per hour (USD/h), while AI reduced costs to 211.2 USD/h with a moderate efficiency trade-off. Simulation of the optimized configuration across eight diverse climates identified Quebec as most viable, generating 22,629.6 Megawatt-hours per year (MWh/year) of electricity and avoiding 4616.4 tons of Carbon Dioxide (CO 2 ) emissions annually. Integration of wind energy stabilizes solar variability, enhancing performance. AI contributes to optimizing complex interactions, nonlinear constraints, and multiple conflicting objectives. The methodology offers a scalable, generalizable framework for designing intelligent, climate-resilient infrastructures. Future research includes AI-enabled real-time control, experimental validation, and broader deployment strategies.},
  archive      = {J_EAAI},
  author       = {Ehsanolah Assareh and Nima Izadyar and Emad Tandis and Mehdi Khiadani and Amir shahavand and Neha Agarwal and Arian Gerami and Ahmed Rezk and Minkyu Kim and Reza Kord and Tahereh Pirhoushyaran and Mehdi Hosseinzadeh and Saleh Mobayen},
  doi          = {10.1016/j.engappai.2025.112481},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112481},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thermoeconomic optimization of climate-adaptive solar and wind multi-generation systems using artificial intelligence and thermal energy recovery},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A mamba-quantum attention transformer-convolutional network for automated pest and disease detection. <em>EAAI</em>, <em>162</em>, 112480. (<a href='https://doi.org/10.1016/j.engappai.2025.112480'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses critical challenges in apple leaf disease detection, where environmental interference (climate variations, lighting conditions, growth stages), symptom similarity across diseases, and phenotypic diversity within single diseases significantly impede accurate identification. To overcome these limitations, we propose the Mamba Quantum Attention Transformer-Graph Convolutional Network (MQAT-Transformer), a novel hybrid architecture that integrates quantum-enhanced attention mechanisms with dynamic graph learning. Firstly, the Mamba-Quantum X Attention mechanism (MQXA), inspired by quantum state modeling, optimizes visual feature extraction under complex environmental conditions. Secondly, the Dynamic Graph Convolution Feature Prioritization module (DGCF) adaptively resolves heterogeneous symptom manifestations by establishing multi-scale feature dependencies through learnable graph structures. This study conducted comprehensive experiments on the AppleLeaf9 Datasets (AppleLeaf9) proposed by Northwest A&F University, Apple disease leaf images Dataset (ADLI), and PlantVillage Dataset (PlantVillage) proposed by Pennsylvania State University. The results demonstrate that the proposed method achieves competitive performance across multiple evaluation metrics (e.g., accuracy, recall, and F1-score), confirming its generalization capability in cross-species scenarios. Finally, leveraging this network architecture, we developed a lightweight mobile application for farm leaf disease detection, offering a practical and user-friendly solution for crop health monitoring in agricultural settings.},
  archive      = {J_EAAI},
  author       = {Dong Tang and Zhihuan Liu and YiRui Zeng and Zhao Xu and Wendong Su},
  doi          = {10.1016/j.engappai.2025.112480},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112480},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A mamba-quantum attention transformer-convolutional network for automated pest and disease detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-driven prior learning-based deep unrolling for underwater image enhancement. <em>EAAI</em>, <em>162</em>, 112472. (<a href='https://doi.org/10.1016/j.engappai.2025.112472'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a physics-driven prior learning-based algorithm unrolling approach for underwater image enhancement that leverages the advantages of both model- and learning-based approaches while overcoming their limitations. Model-based algorithms are theoretically robust because of prior knowledge of the underlying physics but may degrade image quality due to modeling inaccuracies. On the other hand, learning-based algorithms exhibit better adaptivity but inferior interpretability due to their black-box models and neglect of domain knowledge. In this work, we first formulate underwater image enhancement as a joint optimization problem with physics-based underwater-related priors and two learnable regularizers to compensate for modeling inaccuracies. Then, we solve the problem by reformulating it as a set of subproblems, which are then solved iteratively. Finally, we unroll the iterative algorithm into a deep neural network comprising a series of blocks, in which the optimization variables and regularizers are updated using closed-form solutions and learned deep neural networks, respectively. Experimental results on several datasets demonstrate that the proposed algorithm outperforms state-of-the-art underwater image enhancement algorithms on both quantitative and qualitative comparisons. The source code and pretrained models will be available at https://github.com/thithuypham/BLUE-Net .},
  archive      = {J_EAAI},
  author       = {Thuy Thi Pham and Hansung Yu and Truong Thanh Nhat Mai and Chul Lee},
  doi          = {10.1016/j.engappai.2025.112472},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112472},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-driven prior learning-based deep unrolling for underwater image enhancement},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explore unicin milvus optimization-based scale invariant signal interference noise loss enabled cycle generative adversarial network for audio source separation. <em>EAAI</em>, <em>162</em>, 112470. (<a href='https://doi.org/10.1016/j.engappai.2025.112470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audio Source Separation remains the major research area as noisy audio signals lack information connectivity among users. Despite the numerous important efforts for audio source separation, there are still some challenges limiting the overall performance. Specifically, the existing methods face difficulty in working with multiple input sources and ignore the spectrum information of the signals, resulting in subpar performance. Hence, the research proposes the Explore Unicin Milvus Optimization-based Scale Invariant Signal interference Noise loss enabled Cycle Generative Adversarial Network (ExUnMO-S2NC-GAN) for addressing the challenges in the existing methods. The proposed approach utilizes the Cycle Generative Adversarial Network (C-GAN) architecture to carry out the transformation and restoration while preserving the significant details, resulting in achieving the most relevant audio source as the outcome. Specifically, the proposed model exploits the Scale Invariant Signal interference noise (S2N) loss function, improving the robustness against invariant to the signal scale and deformations of the signal. Besides, the Explore Unicin Milvus Optimization (ExUnMO) algorithm, harnessing the unique traits of Red Kite and Harris Hawk, is used for fine-tuning the hyperparameters of C-GAN, leading to improved performance. Moreover, the feature extraction with the spectral parameters added more advantages to the research model to work on more specific inputs. Extensive experiments demonstrates that theproposed model obtained high-efficiency outcomes in comparison with the state-of-the-art methods, which is evaluated with the error metrics attaining the Mean Absolute Error (MAE) of 1.79, and Mean Absolute Percentage Error (MAPE) of 3.22, whereas the signal quality metrics such as Peak Signal-to-Noise Ratio (PSNR), Signal-to-Interference Ratio (SIR) and Signal-to-Artifacts Ratio (SAR) achieved the high values of 54.81 dB (dB), 39.33 dB, and 40.56 dB respectively.},
  archive      = {J_EAAI},
  author       = {Baishakhi Dutta and Chandrakant J Gaikwad},
  doi          = {10.1016/j.engappai.2025.112470},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112470},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explore unicin milvus optimization-based scale invariant signal interference noise loss enabled cycle generative adversarial network for audio source separation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep ensemble learning model for chinese spelling check. <em>EAAI</em>, <em>162</em>, 112469. (<a href='https://doi.org/10.1016/j.engappai.2025.112469'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing Chinese Spelling Check models are individual end-to-end models with different tendencies, which cannot fully cover all kinds of spelling errors and achieves advanced performance in every aspect. In this paper, a deep ensemble learning model for Chinese Spelling Check is designed, which captures the correct Chinese spelling answers proposed by most of the candidate ckeck models. Considering the phonological, visual and semantic characteristics of all candidate answers, it can even discover new correct answer which is not found by any of the candidate ckeck models. Specifically, in order to learn a hybrid representation of each input correction answer provided by each candidate ckeck model that includes phonological, visual, and semantic characteristics, a hybrid representation learner is designed and does not need to consider the compatibility of the candidate ckeck models. A deep ensemble correction network is designed to integrate all the hybrid representations and finds a final correction answer that considers all the useful information of all input correction answers. Moreover, based on the deep ensemble correction network, the deep ensemble learning model can be easily extended to involve new candidate ckeck models. Experimental results on the benchmark demonstrate that our proposed model largely outperforms any of its aggregated individual ckeck models.},
  archive      = {J_EAAI},
  author       = {Yaoyao Wu and Ruizhang Huang and Lina Ren and Ruina Bai},
  doi          = {10.1016/j.engappai.2025.112469},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112469},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep ensemble learning model for chinese spelling check},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient active flow control strategy for confined square cylinder wake using deep learning-based surrogate model and reinforcement learning. <em>EAAI</em>, <em>162</em>, 112468. (<a href='https://doi.org/10.1016/j.engappai.2025.112468'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a deep learning surrogate model-based reinforcement learning (DL–MBRL) for active control of two-dimensional (2D) wake flow past a square cylinder confined between parallel walls using antiphase jets. In the training of this framework, a proximal policy optimisation (PPO) reinforcement learning agent alternates its interaction between a deep learning-based surrogate model (DL–SM) and a computational fluid dynamics (CFD) simulation to suppress wake vortex shedding, thereby significantly reducing computational costs. The DL–SM, built with a Transformer for temporal dynamics and a multiscale enhanced super-resolution generative adversarial network (MS–ESRGAN) for spatial reconstruction, is trained on 2D direct numerical simulation wake flow data to effectively and accurately emulate complex nonlinear flow behaviours. Compared to standard model-free reinforcement learning, the DL–MBRL approach reduces training time by about 50% while maintaining or improving wake stabilisation. Specifically, it achieves approximately a 98% reduction in shedding energy and a 95% reduction in the standard deviation of the lift coefficient, demonstrating strong suppression of vortex shedding. By leveraging the inherent stochasticity of DL–SM, DL–MBRL also addresses the nonzero mean lift coefficient issue observed in model-free methods, promoting more robust exploration. These results highlight the potential of the framework for extension to practical and industrial flow control problems.},
  archive      = {J_EAAI},
  author       = {Meng Zhang and Mustafa Z. Yousif and Minze Xu and Haifeng Zhou and Linqi Yu and Hee-Chang Lim},
  doi          = {10.1016/j.engappai.2025.112468},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112468},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient active flow control strategy for confined square cylinder wake using deep learning-based surrogate model and reinforcement learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vessel behavior recognition method for preventing vessel-bridge collisions via adaptive video analytics. <em>EAAI</em>, <em>162</em>, 112467. (<a href='https://doi.org/10.1016/j.engappai.2025.112467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a comprehensive end-to-end framework for recognizing vessel behaviors aimed at preventing vessel-bridge collisions in complex maritime environments. Current monitoring approaches that rely on Automatic Identification Systems or external tracking mechanisms often suffer from class imbalance, cross-domain variability, and limited capability to detect previously unseen high-risk behaviors. To address these challenges, the proposed framework directly analyzes video streams and introduces a standardized behavioral taxonomy, classifying vessel activities into eleven categories while incorporating temporal continuity and behavior transition modeling. A robust dataset construction pipeline is established, consisting of fixed-length frame sequences and mechanisms for cross-domain generalization. The framework integrates a spatio-temporal feature extraction module based on deformable convolution and multi-scale attention, coupled with a cross-instance mutual enhancement mechanism to capture domain-invariant representations. An open-set recognition strategy, grounded in class anchor clustering, enables accurate identification of previously unobserved high-risk behaviors. Furthermore, an adaptive frame sampling strategy dynamically adjusts sampling density around behavior transitions, enhancing recall and capturing infrequent events while minimizing computational cost. Extensive evaluations on both single-domain and multi-domain benchmark datasets, as well as real-world bridge video streams, demonstrate superior performance in terms of overall accuracy, F1-score, detection of rare behaviors, and recall compared with baseline methods. Ablation studies confirm the contribution of each component, and comparisons with open-set recognition methods underscore the practical utility of the proposed approach for anomaly detection. This framework provides a scalable, artificial intelligence-driven solution for vessel behavior recognition, anomaly detection, and cross-domain generalization, supporting intelligent monitoring and early warning in safety-critical maritime operations.},
  archive      = {J_EAAI},
  author       = {Woqin Luo and Daoxin Chen and Ye Xia and Dongming Feng},
  doi          = {10.1016/j.engappai.2025.112467},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112467},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Vessel behavior recognition method for preventing vessel-bridge collisions via adaptive video analytics},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A secure architecture for intelligent internet of vehicle systems using advanced dimensionality reduction with deep ensemble models. <em>EAAI</em>, <em>162</em>, 112466. (<a href='https://doi.org/10.1016/j.engappai.2025.112466'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An intelligent transportation system (ITS) is an idea that provides a safe, protected, and smarter travelling experience to drivers. This visionary strategy aims to enable vehicles, pedestrian smartphones, roadside transportation frameworks, and additional devices to communicate with each other to offer secure and convenient services. Vehicle-to-Infrastructure (V2I) and Vehicle-to-Vehicle (V2V) communication in ITS enables the exchange of data like speed, position, and heading between vehicles and nearby networks. This improves data flow among infrastructure and vehicles, promoting road safety, traffic efficiency, reduced emissions, and ITS development. Artificial intelligence (AI) now presents smart solutions for addressing these threats effectively. This paper presents a Secure Architecture for Intelligent Vehicle Systems Using Integrated Ensemble Model and Advanced Dimensionality Reduction (SAIVS-IEMADR) model. Initially, the data pre-processing is performed to transform and organize raw data into a suitable format. The feature selection (FS) process uses five methods: Consistency, Correlation Feature Selection (CFS), information theory (InfoGain), Relief for Features (Relief-F), and Fast-Correlation Based Filter (FCBF) to identify the most relevant and informative features. Finally, an ensemble model comprising the temporal convolutional network (TCN), deep belief network (DBN), and stacked sparse auto-encoder (SSAE) is employed for classification. The SAIVS-IEMADR approach was evaluated on the Network Security Laboratory – Knowledge Discovery in Databases (NSLKDD) and Canadian Institute for Canadian Institute for Cybersecurity Intrusion Detection System (CICIDS)-2017 datasets, achieving superior accuracy of 99.55 % and 99.32 % compared to existing methods.},
  archive      = {J_EAAI},
  author       = {Amal K. Alkhalifa and Mashael M. Asiri and Reham Al-Dayil and Ahmed Alsayat and Mashail N. Alkhomsan and Mohammed A. AlAqil and Shouki A. Ebad and Mohammed Mujib Alshahrani},
  doi          = {10.1016/j.engappai.2025.112466},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112466},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A secure architecture for intelligent internet of vehicle systems using advanced dimensionality reduction with deep ensemble models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A constitutive framework for non-isothermal plasticity through micro-mechanism informed artificial neural networks. <em>EAAI</em>, <em>162</em>, 112465. (<a href='https://doi.org/10.1016/j.engappai.2025.112465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-isothermal plastic deformation creates modeling challenges for constitutive model development. Current constitutive models challenge to capture the coupled microstructural changes that occur when temperature varies during processing. The Micro-Mechanism Informed Artificial Neural Network (MMIANN) framework was developed to address these limitations using artificial intelligence (AI) and machine learning (ML) techniques. The MMIANN framework combines physics-based evolution equations for key metallurgical processes—dislocation density, grain boundary migration, and precipitation kinetics—with neural network predictions. These micro-mechanisms operate as internal state variables that guide the network's material behavior predictions. The architecture uses parallel physics-based and neural pathways, blended through adaptive coefficients. Thermodynamic constraints maintain consistency through penalty-based enforcement of the Clausius-Duhem inequality. The model was trained and validated using experimental data from simultaneous cooling and tensile deformation of AA7075 aluminum alloy. The tests replicated industrial hot forming conditions with cooling rates from 25 to 75 °C per second (°C/s). This experimental approach captures the thermal-mechanical coupling that drives microstructural evolution in practice. MMIANN achieved correlation coefficients exceeding 0.96 for stress, temperature, and grain size predictions. The framework captures thermomechanical regimes. Processing maps generated by the AI model link process parameters to microstructural outcomes. The analysis reveals an optimal processing window (40–55 °C/s cooling, 0.15–0.25 strain ( ε )) and identifies three regimes where different strengthening mechanisms dominate. By integrating metallurgical science with machine learning, this framework provides a practical tool for non-isothermal manufacturing processes. The approach bridges microstructural understanding with process control for thermal-mechanical operations through the application of artificial intelligence.},
  archive      = {J_EAAI},
  author       = {Yo-Lun Yang and Tsai-Fu Chung and Chia-Hung Liao and Liang-Yu Chen and Hsing-Yu Wu and Uthayakumar Marimuthu and Arumugaprabu Veerasimman and Sundarakannan Rajendran and Vigneshwaran Shanmugam},
  doi          = {10.1016/j.engappai.2025.112465},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112465},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A constitutive framework for non-isothermal plasticity through micro-mechanism informed artificial neural networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learnable patchmatch and self-teaching for multi-frame depth estimation in monocular endoscopy. <em>EAAI</em>, <em>162</em>, 112463. (<a href='https://doi.org/10.1016/j.engappai.2025.112463'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work delves into unsupervised monocular depth estimation in endoscopy, which leverages adjacent frames to establish supervisory signals during the training phase. For many clinical applications, e.g. , surgical navigation, temporally correlated frames are also available at test time. However, most existing monocular methods struggle to make effective use of temporal information during both training and inference, primarily due to the inherent challenges of endoscopic imagery, including low- or homogeneous-texture regions and brightness fluctuations between frames. To fully exploit the temporal information in endoscopic scenes, we propose a novel unsupervised multi-frame monocular depth estimation model. The proposed model integrates a learnable patchmatch module to adaptively increase the discriminative ability in regions with low or homogeneous textures, and enforces cross-teaching and self-teaching consistencies to provide efficacious regularizations towards brightness fluctuations. Furthermore, as a byproduct of the self-teaching paradigm, the proposed model is able to improve the depth predictions when more frames are input at test time. We conduct detailed experiments on multiple datasets, and the experimental results indicate that the proposed method exceeds prior state-of-the-art competitors. The source code and trained models will be publicly available at https://github.com/ShuweiShao/FrameDepth .},
  archive      = {J_EAAI},
  author       = {Shuwei Shao and Zhongcai Pei and Weihai Chen and Xingming Wu and Zhong Liu},
  doi          = {10.1016/j.engappai.2025.112463},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112463},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learnable patchmatch and self-teaching for multi-frame depth estimation in monocular endoscopy},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypergraph induced semi-supervised orthogonal nonnegative matrix factorization with label and constraint propagation. <em>EAAI</em>, <em>162</em>, 112462. (<a href='https://doi.org/10.1016/j.engappai.2025.112462'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a popular technology of artificial intelligence, nonnegative matrix factorization (NMF) aims at clustering and finding the differentially expressed features of each cluster. However, for complex high-dimensional sample data, it is still a challenge to design more appropriate NMF optimization models and develop more efficient algorithms to solve this model in view of enhanced theoretical properties and numerical performance. In this paper, a novel NMF optimization model with regularization is proposed such that the NMF is performed by a semi-supervised approach, as well as incorporating the strategies of hypergraph induced label propagation and constraint propagation. Specifically, different from existing NMF methods, the hypergraph structure underlying the data, together with the simple graph information, is employed to guide the pairwise constraint propagation in our built model. In recognition of sample similarity, a dataset-adaptive strategy is proposed to update the weight matrix of the graphs. By adding dual orthogonality on the factor matrices in the objective function, interpretability and feature independence of the built model are enhanced. Then, an algorithm is developed to efficiently solve this complicated model. Theoretically, it is proved that the developed algorithms are well defined and convergent. Numerically, extensive tests on the proposed model and algorithm are performed, which validate that they outperform the state-of-the-art ones in terms of different metrics of evaluating clustering performance when they are applied into solution of the problems from eight public datasets.},
  archive      = {J_EAAI},
  author       = {Jie Guo and Ting Li and Jialu Liu and Zhong Wan},
  doi          = {10.1016/j.engappai.2025.112462},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112462},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hypergraph induced semi-supervised orthogonal nonnegative matrix factorization with label and constraint propagation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel condition monitoring approach using hybrid lightweighted adaptive models for complex machinery. <em>EAAI</em>, <em>162</em>, 112461. (<a href='https://doi.org/10.1016/j.engappai.2025.112461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Condition monitoring of complex industrial systems is critical for ensuring operational reliability. Data-driven methods using artificial intelligence have advanced anomaly detection (AD) and fault diagnosis (FD), but existing approaches often treat them separately, focus on known faults, and struggle with previously unseen or rare conditions in multi-modal scenarios. This study proposes a novel condition monitoring framework that integrates AD and FD within a distributed architecture. Lightweight models—including kernel principal component analysis, support vector machines, and one-dimensional convolutional neural networks—enable efficient and scalable processing. A multilevel information fusion strategy ensures consistent detection and diagnosis while facilitating the isolation of previously unknown faults. Module test results demonstrate the effectiveness and robustness of the proposed feature extraction and adaptive modeling approaches. The overall test results for previously unknown faults vary across channels and modules. For samples with misalignment and inner blade wear, channel-level detection accuracy ranges from 0.007 to 0.989, with unknown recognition rates up to 0.933 and diagnosis probabilities from 0.508 to 0.933. For strong misalignment and fan-end inner race faults, nearly all channels achieve 100 % detection accuracy, with some diagnosis probabilities above 0.9, while unknown recognition remains minimal (mostly below 0.05). Importantly, the proposed framework integrates detection and diagnostic outputs across channels, effectively mapping previously unseen faults to similar known categories or to an unknown category. Overall, the proposed framework offers a referenced solution for condition monitoring of industrial systems like pumps, turbines, and compressors, and lays the foundation for future improvements incorporating domain knowledge and model-driven interpretability.},
  archive      = {J_EAAI},
  author       = {Yingqian Liu and Rongyong Zhang and Luigi Grossi and Zhipin Ye and Huairui Li and Rongsheng Zhu and Qiang Fu},
  doi          = {10.1016/j.engappai.2025.112461},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112461},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel condition monitoring approach using hybrid lightweighted adaptive models for complex machinery},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast and stable framework for generative adversarial imitation learning. <em>EAAI</em>, <em>162</em>, 112460. (<a href='https://doi.org/10.1016/j.engappai.2025.112460'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying reinforcement learning to complex and high-dimensional tasks encounters challenges, including the formulation of suitable reward functions, achieving sample efficiency, and developing effective exploration strategies. Adversarial imitation learning techniques address these issues by employing generative adversarial networks (GANs) to capture temporal dependencies and mitigate compounding errors. These methods exhibit enhanced efficiency relative to behavioral cloning and require fewer expert samples. Nonetheless, their complex min-max problem results in sample inefficiency and struggles with challenges such as mode collapse and training instability. This paper provides a comprehensive approach that adeptly addresses these challenges. The proposed method's design comprises three main steps. First, it uses the off-policy Twin Delayed Deep Deterministic (TD3) algorithm to enhance sample efficiency and accelerate learning. In the second step, a novel reward function based on energy-based GANs and deep regret analytic GANs is developed, which alleviates mode collapse and enhances training stability. Finally, we suggest several improvements, including the use of a pre-trained discriminator and mixed batches, to achieve a faster and more stable algorithm. The evaluation findings on continuous control tasks demonstrate that our method not only matches state-of-the-art performance but also surpasses it in both sample efficiency and stability. It achieves convergence with far fewer iterations than the compared methods.},
  archive      = {J_EAAI},
  author       = {Fateme Shahabi-Nejad and Mohammad Mehdi Ebadzadeh},
  doi          = {10.1016/j.engappai.2025.112460},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112460},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A fast and stable framework for generative adversarial imitation learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A transfer learning method of collaborating random walk and adaptive instance normalization for inscription image denoising. <em>EAAI</em>, <em>162</em>, 112458. (<a href='https://doi.org/10.1016/j.engappai.2025.112458'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mess noise hinders reading and understanding of inscriptions in images. For image restoration from noise-corrupted images, existing network-learning-based methods can construct an excellent model to generate noise patterns. However, the performance of such models is degraded owing to the lack of high-quality training data and the complex noise pattern in inscription images, e.g., mixed noise with multiple levels. Herein, we first propose a novel noise generation model that can produce more realistic synthetic noise images using the random walk algorithm. Then, we propose an explainable inscription image denoising network using a variational inference model, where the joint distribution of clean-noise image pairs is approximated in a dual adversarial manner. The proposed network exhibits improved generalizability and adaptability to different noise characteristics using an estimated noise map and adaptive instance normalization. Finally, we introduce a transfer learning scheme to migrate the network learned from the synthetic noise image domain to a real-inscription image domain with a limited number of real-inscription images. The proposed method outperforms state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Erhu Zhang and Yunjing Liu and Guangfeng Lin and Jinghong Duan},
  doi          = {10.1016/j.engappai.2025.112458},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112458},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A transfer learning method of collaborating random walk and adaptive instance normalization for inscription image denoising},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-based time series forecasting for bearing remaining useful life: Recent advances, hybrid architectures, and targeted enhancements. <em>EAAI</em>, <em>162</em>, 112457. (<a href='https://doi.org/10.1016/j.engappai.2025.112457'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a systematic review of deep learning(DL)-based time series forecasting hybrid model for bearing RUL prediction by evaluating these studies from 2020 to 2025, addressing the gap in analyzing cross-model collaboration strategies. Firstly, the general workflow and modeling framework for remaining useful life (RUL) prediction were introduced. Secondly, a comparative analysis of time dependence capture mechanisms -including Recurrent Neural Networks(RNN) and their variants and Temporal Convolutional Network(TCN), and Transformer-was conducted. The findings reveal a shift from local sequential modeling to globally contextualized frameworks, enhanced by self-supervised learning and multimodal fusion. These developments underscore the importance of aligning model selection with specific task objectives and balancing multiple dimensions to achieve optimal performance in complex industrial scenarios. Thirdly, to address common challenges in RUL prediction, such as noisy data, sparse features, high model complexity, and limited interpretability, this paper explores performance optimization strategies from the perspectives of data quality, architectural design, and decision transparency. Finally, a comprehensive review was made of the current challenges: unclear applicability of attention, limited interpretability, deployment difficulties under resource constraints, difficulties in real-time prediction, and weak generalization in a data-scarce environment. To address these issues, future research should explore more trustworthy attention evaluation, interpretable architectures, lightweight design, continuous iteration for real-time prediction, and leveraging embedding other models to complement the lack of generalization. Overall, this work provides a structured perspective to support the development of the next generation of intelligent prediction systems.},
  archive      = {J_EAAI},
  author       = {Zhenyu Tang and Dalian Yang and Linrong Tan and Liying Zeng},
  doi          = {10.1016/j.engappai.2025.112457},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112457},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning-based time series forecasting for bearing remaining useful life: Recent advances, hybrid architectures, and targeted enhancements},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite element-integrated neural network framework for spatial modal prediction in machine tool structures. <em>EAAI</em>, <em>162</em>, 112456. (<a href='https://doi.org/10.1016/j.engappai.2025.112456'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of position-dependent structural dynamics in (CNC) machine tools is critical for ensuring machining precision, avoiding resonance, and enabling real-time health monitoring. This study proposes an integrated framework combining finite element analysis (FEA), experimental modal testing, and artificial neural networks (ANNs) to model and predict position-dependent dynamics across the machine workspace. A validated FEA model of a high-rigidity vertical machining centre is developed and correlated with experimental modal analysis using a PCB 086D20 impact hammer and tri-axial accelerometer. Natural frequencies and mode shapes are extracted and compared, showing deviation under 10 %, confirming model fidelity. To capture position-dependent dynamics, modal analysis was performed at 27 spatial locations, revealing significant frequency variation across planes, indicating localized compliance zones. A multilayer ANN is trained on the modal dataset to predict frequencies based on spatial coordinates, achieving R 2 values above 0.99. The proposed hybrid approach enables real-time estimation of structural dynamics, reducing the need for repeated testing and supporting intelligent control strategies in large-format CNC systems. This work contributes a predictive foundation for dynamic stability optimization, resonance avoidance, and digital twin development in precision machining applications.},
  archive      = {J_EAAI},
  author       = {Aman Ullah and Tzu-Chi Chan and Jun-Fa Huang and Shinn-Liang Chang},
  doi          = {10.1016/j.engappai.2025.112456},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112456},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Finite element-integrated neural network framework for spatial modal prediction in machine tool structures},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-to-end go (Weiqi) game record reconstruction from live broadcast videos. <em>EAAI</em>, <em>162</em>, 112455. (<a href='https://doi.org/10.1016/j.engappai.2025.112455'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual transcription of Go (Weiqi) game records from broadcast videos creates a major bottleneck for building training data in artificial intelligence (AI). We present an end-to-end system that reconstructs complete smart game format (SGF) records from professional tournament broadcasts. The pipeline integrates four modules: (i) video-to-frame sampling; (ii) a board detector based on a detection transformer (DETR), optimized with a size-aware loss to reliably localize both main and commentary boards; (iii) a stone classifier that uses knowledge distillation from a vision transformer (ViT) teacher to an efficient grid-based student for full-board inference; and (iv) a temporal reconstruction algorithm for occlusion recovery and move-sequence consistency. When evaluated under a zero-error-tolerance video-level protocol – where a video is counted correctly only if all sampled frames match the reference – the system achieves 82.56% accuracy on 86 real tournament videos (356 h). Component analyses reveal high board localization quality with mean average precision (mAP50-95) reaching 0.99; near-teacher board-state recognition with a 67 × speedup (377.5 frames per second, FPS) and F1 score 0.988; and a 70.23% reduction of occlusion-related misdetections. Compared with you only look once (YOLO) and faster region-based convolutional neural network (Faster R-CNN) baselines, our design improves small-board recall and end-to-end robustness in dual-board and occluded settings. The system outputs SGF records suitable for large-scale dataset construction, AI-assisted analysis, education, and digital preservation, and the approach can be generalized to other grid-structured board games with minor adaptations.},
  archive      = {J_EAAI},
  author       = {Chih-Lin Lin and Hsia-Hung Ou and Lung Hung Chen and Chih-En Kuo},
  doi          = {10.1016/j.engappai.2025.112455},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112455},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {End-to-end go (Weiqi) game record reconstruction from live broadcast videos},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting code paraphrased by large language models using coding style features. <em>EAAI</em>, <em>162</em>, 112454. (<a href='https://doi.org/10.1016/j.engappai.2025.112454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent progress in large language models (LLMs) for code generation has raised serious concerns about intellectual property protection. Malicious users can exploit LLMs to produce paraphrased versions of proprietary code that closely resemble the original. While the potential for LLM-assisted code paraphrasing continues to grow, research on detecting it remains limited, underscoring an urgent need for a detection system. We respond to this need by proposing two tasks. The first task is to detect whether code generated by an LLM is a paraphrased version of original human-written code. The second task is to identify which LLM is used to paraphrase the original code. For these tasks, we construct a dataset consisting of pairs of human-written code and LLM-paraphrased code using various LLMs. We statistically confirm significant differences in the coding styles of human-written and LLM-paraphrased code, particularly in terms of naming consistency, code structure, and readability. Based on these findings, we develop a detection method that identifies paraphrase relationships between human-written and LLM-generated code, and discover which LLM is used for the paraphrasing. Our detection method outperforms the best baselines in two tasks, improving F1 scores by 2.64% and 15.17% while achieving speedups of 1,343x and 213x, respectively.},
  archive      = {J_EAAI},
  author       = {Shinwoo Park and Hyundong Jin and Jeong-won Cha and Yo-Sub Han},
  doi          = {10.1016/j.engappai.2025.112454},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112454},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detecting code paraphrased by large language models using coding style features},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cooperative neural networks for inverse design: Integrating denoising autoencoder and surrogate model for partial design variable imputation. <em>EAAI</em>, <em>162</em>, 112453. (<a href='https://doi.org/10.1016/j.engappai.2025.112453'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven inverse design is an engineering approach where target performance criteria are specified upfront, leading to the derivation of design solutions that meet these criteria. While recent research focuses on generating complete design solutions using generative models, these approaches struggle with partial design variables and constraints that predetermine certain variables. Additionally, generative models are data-intensive and prone to overfitting with limited datasets. To address these limitations, this paper proposes a Cooperative Neural Network architecture comprising two key components: the Imputation Model and the Surrogate Model. These components collaborate to optimize design solutions while adhering to predefined performance criteria. The framework’s effectiveness is demonstrated through a case study on Glass Run Channel (GRC) designs from a Korean automotive manufacturer. Results show the architecture proficiently imputes undetermined variables and ensures the designs meet desired performance metrics, achieving Mean Squared Error (MSE) reductions of up to 98 % and R-squared values of 0.997–0.999 in initial tests. It remains robust in diverse scenarios, achieving up to 95.65 % MSE reduction and R-squared values of 0.995–0.999 for cases with the most undetermined variables, and up to 94.68 % MSE reduction with R-squared values of 0.983–0.995 for the smallest training datasets. This framework reduces design cycle times and enhances engineering design efficiency, offering a robust solution to limitations in traditional methods reliant on physical prototyping and iterative testing.},
  archive      = {J_EAAI},
  author       = {Agung Nugraha and Hyerin Kwon and Gyeongho Park and Jihwan Lee},
  doi          = {10.1016/j.engappai.2025.112453},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112453},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cooperative neural networks for inverse design: Integrating denoising autoencoder and surrogate model for partial design variable imputation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge distillation via teacher-modeled sample relationships for skin cancer diagnosis. <em>EAAI</em>, <em>162</em>, 112452. (<a href='https://doi.org/10.1016/j.engappai.2025.112452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In skin cancer diagnosis, knowledge distillation can achieve model compression, which enables complex deep learning tasks to run efficiently on devices with limited resources. However, existing studies have largely overlooked explicit modeling of sample relationships during teacher model training, particularly in the context of class imbalance. Directly transferring such unrefined relational knowledge not only fails to address the bias toward majority classes but also leads to suboptimal performance for minority classes. To address this gap, we propose a novel approach that integrates a sample relationship module into the teacher model to learn relational knowledge under class imbalance, which is then transferred to the student model during distillation. Specifically, the teacher transfers two key types of knowledge: traditional logits and inter-sample relationships. During training, the student is optimized through two losses: a standard logit-matching loss to mimic classification knowledge, and relational consistency losses to enforce alignment between the student’s and teacher’s predicted inter-sample relationships to address class imbalance. We conducted extensive experiments on large-scale public skin lesion classification datasets, including ISIC2019 and HAM10000, and the results demonstrate that our method significantly outperforms current state-of-the-art approaches.},
  archive      = {J_EAAI},
  author       = {Peng Liu and Wenhua Qian and Shan Tang},
  doi          = {10.1016/j.engappai.2025.112452},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112452},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Knowledge distillation via teacher-modeled sample relationships for skin cancer diagnosis},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Region-based weighting-and-enhancement network with adaptive class weighting loss for postoperative inguinal hernia prediction. <em>EAAI</em>, <em>162</em>, 112451. (<a href='https://doi.org/10.1016/j.engappai.2025.112451'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Postoperative inguinal hernia (PIH) is a common complication after radical prostatectomy, subsequently leading to multiple potential risks (e.g., cardiovascular and cerebrovascular accidents) and increased surgical costs due to re-surgical reparation. Magnetic resonance imaging (MRI) examination is a widely used procedure before radical prostatectomy, which can investigate the muscle structures of the abdominal wall (MSAW). Recently, clinical studies have indicated that clinical parameters (e.g., thickness and width of the external oblique muscle) of MSAW are strongly related to PIH. However, automated MRI-based PIH prediction based on deep neural networks has not been studied previously. Motivated by these observations, we propose a novel region-based weighting-and-enhancement network to predict PIH before radical prostatectomy based on MRI images automatically. Specifically, we employ the well-designed Region Weighting-and-Enhancement module to capture informative context representations through region weighting and regional context enhancement, by fully leveraging the potential of clinical MSAW priori. Additionally, this paper designs an effective adaptive class weighting loss to emphasize or suppress the samples with varying levels of significance to further boost the PIH prediction performance. The extensive experiments on a clinical MRI-PIH dataset and one publicly available MRI dataset manifest the superiority of our proposed methods over state-of-the-art deep neural networks and advanced loss methods.},
  archive      = {J_EAAI},
  author       = {Jiawei Zhang and Lisheng Wu and Qiang Fang and Weidong Yu and Zhengyu Hu and Fengyun Zhang and Cheng Yang and Xiaoqing Zhang},
  doi          = {10.1016/j.engappai.2025.112451},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112451},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Region-based weighting-and-enhancement network with adaptive class weighting loss for postoperative inguinal hernia prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting thermal transport of blood-based penta-hybrid nanofluid in fin geometries using deep neural networks and finite difference approach. <em>EAAI</em>, <em>162</em>, 112450. (<a href='https://doi.org/10.1016/j.engappai.2025.112450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nanofluids have garnered significant research interest due to their enhanced heat transfer and thermal characteristics. A novel hybrid nanofluid has exhibited exceptional thermal properties, combining five nanoparticles of uniform shapes with a base fluid, such as blood. This study investigates the influence of fin thickness, varying with length, considering the implications of internal heat production, convection, and thermal radiation processes in rectangular, convex, and triangular fin descriptions. Wet scenarios are interpreted to evaluate differences in thermal energy dynamics for fin shapes like Rectangular, Convex and Triangular. Darcy's model is employed to account for the material's porous nature. A finite difference scheme, implemented using Partial Differential Equation solver (PDSolve) in Maple (2024), provides graphical insights into fin effectiveness and thermal steady-state responses across various parameters. Incorporating Penta hybrid nanofluids enhances fin performance, with rectangular fins' Nusselt numbers (up to 1.936) proving more efficient, delivering faster thermal responses than triangular fins and convex fins. Further, using the Adam Optimisation algorithm, Convolutional Neural Networks were used to validate the current model. It was observed that these networks could accurately forecast the truth values, and the two findings matched, as indicated in Table 3 As a potential biological application, this research offers insight into optimising cooling systems for biomedical devices, such as heat exchangers in artificial organs.},
  archive      = {J_EAAI},
  author       = {Maddina Dinesh Kumar and Nehad Ali Shah and Dharmaiah Gurram and Se-Jin Yook},
  doi          = {10.1016/j.engappai.2025.112450},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112450},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Predicting thermal transport of blood-based penta-hybrid nanofluid in fin geometries using deep neural networks and finite difference approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on the application of attention mechanism based multi-model fusion in food recommendation platforms. <em>EAAI</em>, <em>162</em>, 112449. (<a href='https://doi.org/10.1016/j.engappai.2025.112449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smartphone-based food ordering has greatly enhanced convenience in daily life, and the rise of recommendation systems has transformed the functionality and user experience of food delivery applications. Innovations in recommendation algorithms and models have significantly improved the efficiency of food, merchant, and advertisement recommendations on food platforms, leading to higher transaction rates and greater user satisfaction. To further enhance recommendation efficiency, this study introduces a novel multi-model fusion recommendation architecture based on the multi-head self-attention mechanism, utilizing a two-tier structure. The first-tier model (the attention-based homogeneous AutoInt model) acts as a teacher to guide the training of the second-tier Transformer model. This hierarchical approach integrates multiple models through knowledge distillation, significantly improving the accuracy of the recommendation system. The complexity and performance of the proposed architecture were analyzed and applied in a production environment. Testing on a private dataset reveals that the proposed multi-model fusion recommendation architecture significantly enhances recommendation performance across various food platform scenarios, achieving an accuracy of 0.7643, recall of 0.8262, and an F1 score of 0.7936. These results surpass the performance of current state-of-the-art models. Therefore, the proposed architecture is not only highly applicable to food recommendation systems but also has broad applicability in other fields such as retail and entertainment.},
  archive      = {J_EAAI},
  author       = {Linchao Zhang and Lei Hang},
  doi          = {10.1016/j.engappai.2025.112449},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112449},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Research on the application of attention mechanism based multi-model fusion in food recommendation platforms},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying fake reviews for refund purposes: Evaluating the effectiveness of a transfer-learning model against emerging large language models. <em>EAAI</em>, <em>162</em>, 112448. (<a href='https://doi.org/10.1016/j.engappai.2025.112448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Recently, dishonest sellers are using social platforms to advertise products that can be purchased for free through a refund mechanism, which is based on the writing of five-star fake reviews. The aim is to increase product visibility by influencing their ranking compared to similar products. This mechanism is leading to a significant distortion of e-commerce platforms, eroding trust among customers and sellers. Objective: In this paper, we address the problem of identifying fake reviews, aiming to provide an approach for mitigating fraudulent practices that compromise the integrity and transparency of e-commerce platforms. Methods: We propose a supervised model tailored for identifying fake reviews for refund purposes and compare its performance with some of the most recent generative models. Since, to the best of our knowledge, no datasets exist in the literature suitable for fake review identification in the process of Purchasing, Requesting reviews, and Refunding a product, we first proposed a new dataset of fake and genuine reviews from Amazon, collected with the help of a domain expert. Then, we defined five other new datasets containing reviews automatically generated by language models. To interact with these models, we designed new prompt approaches specifically tailored to our goal, which exploit the iterative refinement behind these models for improving classification results. Results: Experimental results demonstrated the effectiveness of the supervised model in detecting both types of fake reviews, outperforming state-of-the-art models with improvements ranging from 0.23 to 0.70 in terms of accuracy, precision, and recall.},
  archive      = {J_EAAI},
  author       = {Loredana Caruccio and Gaetano Cimino and Stefano Cirillo and Vincenzo Deufemia and Giuseppe Polese and Giandomenico Solimando},
  doi          = {10.1016/j.engappai.2025.112448},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112448},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Identifying fake reviews for refund purposes: Evaluating the effectiveness of a transfer-learning model against emerging large language models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced multi-modal emotion recognition using the feature level fusion. <em>EAAI</em>, <em>162</em>, 112447. (<a href='https://doi.org/10.1016/j.engappai.2025.112447'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal human emotion recognition is a complex process of synthesizing information from various modalities to calculate emotion states. This field faces several challenges: (1) Acoustic is an essential component of emotion expression, but it often underperforms compared to visual and text in emotion recognition. (2) Capturing the feature interaction among different modalities is usually complex. (3) Processing high-definition videos can significantly reduce the efficiency of visual analysis. In this study, we presented a learning architecture designed to recognize human emotions effectively. For the first challenge, we implemented a multi-level acoustic encoder (MLAE) that enhances the extraction of acoustic information to improve the acoustic contribution in multi-modal emotion recognition. Facing the second challenge, we introduced the cross-attention block module, which adeptly captures the inter-modal interactions. To address the third challenge, we adopted the re-parameterized visual geometry group network (RepVGG) as the visual feature encoder, employing its multi-branch learning and single-branch reasoning structure to maintain high reasoning efficiency. Our model has demonstrated the state-of-the-art performance of the interactive emotional dyadic motion capture (IEMOCAP) dataset and the multi-modal opinion sentiment and emotion intensity of the Carnegie Mellon University (CMU-MOSEI) dataset.},
  archive      = {J_EAAI},
  author       = {Aziguli Wulamu and Yuheng Wu and Xin Liu and Yao Zhang and Jinghan Xu and Yang Zhang},
  doi          = {10.1016/j.engappai.2025.112447},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112447},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced multi-modal emotion recognition using the feature level fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep adaptive wavelet autoencoder with mutually independent empirical cumulative distribution for unsupervised motor anomaly detection. <em>EAAI</em>, <em>162</em>, 112446. (<a href='https://doi.org/10.1016/j.engappai.2025.112446'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {—Permanent magnet synchronous motors (PMSMs) are widely used in industrial applications but remain vulnerable to stator faults, such as inter-coil and inter-turn short circuits. Although recent deep learning-based fault detection methods have shown promise, they typically rely on large volumes of labelled fault data for training. To address this limitation, this paper proposes a novel unsupervised fault detection framework, termed Deep Adaptive Wavelet Autoencoder (DAWA) with Mutually Independent Empirical Cumulative Distribution (MIECD), specifically designed for PMSM fault detection. DAWA utilizes convolutional neural networks to learn adaptive wavelet filters through fast discrete wavelet transform, allowing for fully learnable, threshold-free extraction of fine-grained signal patterns. The resulting latent features are then mapped by MIECD into a mutually independent space via independent component analysis (ICA). Without assuming any prior data distribution, MIECD estimates empirical cumulative distributions (ECDs), computes tail probabilities across dimensions, and aggregates them into a unified anomaly score. Experimental results on motor vibration datasets demonstrate the effectiveness of the proposed method, showing average accuracy improvements of 15.85 % for Interturn and 15.16 % for Intercoil fault detection compared to conventional data-driven baselines across various operating conditions.},
  archive      = {J_EAAI},
  author       = {Pinze Ren and Ning Zhu and Dandan Peng and Liyuan Ren and Huan Wang},
  doi          = {10.1016/j.engappai.2025.112446},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112446},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep adaptive wavelet autoencoder with mutually independent empirical cumulative distribution for unsupervised motor anomaly detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic vision-based machine vibration sensing and fault diagnosis with signal alignment and feature clustering. <em>EAAI</em>, <em>162</em>, 112445. (<a href='https://doi.org/10.1016/j.engappai.2025.112445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, intelligent fault diagnosis methods for machines have been widely developed. The contact accelerometer has been popularly used with high measurement accuracy. However, in many industrial applications, non-contact sensors are often preferred due to practical constraints. The event camera is a novel bio-visual sensing technology for asynchronously capturing pixel-wise changes in brightness. It has various advantages including high measurement rate, exceptional resolution, wide dynamic range, etc., which thus has promising prospects in non-contact monitoring and fault diagnostic tasks. Despite these advantages, the high complexity of the dynamic vision data from the event cameras poses significant processing challenges, and the extraction of machine vibration information is of great difficulties. To address these challenges, this paper proposes a novel dynamic vision-based machine vibration sensing and fault diagnosis method. First, the dynamic vision data is reconstructed into event frame sequences. Next, a deep neural network is proposed to extract the micro-vibration information with feature clustering for enhancing model robustness. A signal alignment method is further proposed where the contact sensing data are used as a reference for optimizing model performance. Finally, the intelligent fault diagnosis is implemented with the estimated vibration data. Experimental validations are conducted with real rotating machine data, which demonstrate the promising applicability of the proposed method in non-contact machine vibration sensing and fault diagnosis.},
  archive      = {J_EAAI},
  author       = {Ruiyi Guang and Xiang Li and Yaguo Lei and Bin Yang and Naipeng Li},
  doi          = {10.1016/j.engappai.2025.112445},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112445},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic vision-based machine vibration sensing and fault diagnosis with signal alignment and feature clustering},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A reliable degradation prediction method for proton exchange membrane fuel cells based on uncertainty bayesian self-attention. <em>EAAI</em>, <em>162</em>, 112444. (<a href='https://doi.org/10.1016/j.engappai.2025.112444'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health state prediction of Proton Exchange Membrane Fuel Cells (PEMFCs) is a critical technology to ensure their long-term reliable operation. Prediction accuracy directly influences the effectiveness of maintenance strategies and risk management. However, existing PEMFC degradation prediction methods based on Recurrent Neural Networks (RNNs) or Transformer architectures mostly focus on point estimation while neglecting uncertainty quantification. This limitation makes it difficult to assess the confidence level of predictions in practical engineering applications, reducing the models' reliability in decision support. To address this issue, this paper proposes a novel Bayesian Patch Time Series Transformer (B-PatchTST) method. By deeply integrating Bayesian variational inference with time series patch modeling, the method enables probabilistic prediction of PEMFC degradation trajectories and disentangled analysis of uncertainty sources. Unlike traditional Bayesian Neural Networks (BNNs) that primarily apply Bayesian modeling to fully connected layers, B-PatchTST introduces a Bayesian Self-Attention Mechanism, which models epistemic uncertainty in three stages: patch embedding, uncertainty-aware self-attention computation, and adaptive regularization. This design significantly enhances the credibility of the model. Extensive experiments on the fuel cell datasets demonstrate the proposed method's outstanding performance. It achieves an average reduction of 36.31 % in root mean square error and an average compression of 83.39 % in the 95 % confidence interval, significantly outperforming existing methods. This approach offers a trustworthy basis for predictive maintenance in PEMFC systems, promoting a shift from “experience-based maintenance” to “reliable prognostics” in hydrogen energy applications.},
  archive      = {J_EAAI},
  author       = {Mengyu Liu and Zhe Cheng and Yu Yang and Niaoqing Hu and Guoji Shen and Yi Yang},
  doi          = {10.1016/j.engappai.2025.112444},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112444},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A reliable degradation prediction method for proton exchange membrane fuel cells based on uncertainty bayesian self-attention},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-data synergy enabling zero-shot composite fault diagnosis in sucker-rod pumping systems. <em>EAAI</em>, <em>162</em>, 112443. (<a href='https://doi.org/10.1016/j.engappai.2025.112443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-Shot Learning Accurate and comprehensive fault diagnosis is critical to ensuring production efficiency and extending equipment lifespan in oilfield operations. However, most existing diagnostic methods for sucker rod pumping systems are limited to single-fault identification, while the scarcity and high acquisition cost of compound fault samples hinder the application of supervised learning. To address these challenges, this paper proposes a zero-shot compound fault diagnosis framework that integrates domain knowledge with data-driven representations, enabling the identification of unseen fault using only single-fault samples. First, a unified semantic space is constructed by jointly embedding text-based fault descriptions and capsule-encoded load features. Then, a semantics-guided weakly supervised attribute composition strategy is introduced to enhance the completeness and discriminability of the semantic space. Finally, a bidirectional contrastive learning mechanism is established between visual encodings and semantic representations, and an adaptive multi-task loss weighting strategy is employed to optimize the overall framework efficiently. Experiments on real-world oilfield data demonstrate that the proposed method achieves an F1-score of 86.15 % under the zero-shot setting and 69.08 % under the generalized zero-shot setting, offering an effective and scalable solution for compound fault diagnosis in oil wells.},
  archive      = {J_EAAI},
  author       = {Xin-yan Wang and Li-ming Zhang and Kai Zhang and Cheng Cheng},
  doi          = {10.1016/j.engappai.2025.112443},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112443},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Knowledge-data synergy enabling zero-shot composite fault diagnosis in sucker-rod pumping systems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Edge computing and server-based high-precision flood level classification system. <em>EAAI</em>, <em>162</em>, 112442. (<a href='https://doi.org/10.1016/j.engappai.2025.112442'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban flooding and the resulting road water accumulation have become a significant threat to public transportation safety and the stability of municipal infrastructure. Traditional monitoring networks based on physical water level sensors suffer from low deployment density, high maintenance costs, and lagging response times. To address these shortcomings of traditional water accumulation monitoring systems, this study proposes an edge-computing intelligent monitoring system based on collaborative inference between the edge end (You Only Look Once version 5, YOLOv5) and the server end (Transform Vision Detection, TrVDet). A dual-modal perception architecture of “edge-end triggering and server-end precise analysis” has been constructed. At the edge end, the YOLOv5 model is deployed on embedded devices to achieve efficient preliminary screening of water accumulation, reducing dependence on the central server, lowering latency, and enhancing real-time response capabilities. On the server end, multi-object segmentation is performed on the detected water accumulation images, including roads, cars, motorcycles, and bicycles. Finally, a series of logical judgments is applied to determine the water accumulation level based on reference objects within the water. Since there is no publicly available dataset for target object recognition in flooded areas, we employed professional annotators to perform pixel-level labeling on the collected and organized flood data and constructed a multi-class target flood dataset (City Flood Segmentation, CityFloodSeg). Given the scarcity of moderate and severe water accumulation samples, we optimized the instance segmentation model TrVDet under the (A Visual Representation for Neon Genesis, EVA-02) framework and applied five data augmentation methods, including Mosaic and Flip, to expand the diversity of the dataset. Moreover, based on domain expert standards, we designed a logical judgment rule algorithm for model inference of water accumulation levels to classify the levels of water accumulation. Experimental results show that the server-end processing delay is stable within 0.4 s, capable of accurately judging different water accumulation risk levels. This provides centimeter-level real-time situational awareness for urban flood control decision-making and promotes the development of intelligent municipal infrastructure towards higher reliability and universality.},
  archive      = {J_EAAI},
  author       = {Ankang Lu and Runlong Cao and Yuanbin Wang and Wenjun Hu and Yuncan Gao and Zhifeng Hu and Ying Zang},
  doi          = {10.1016/j.engappai.2025.112442},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112442},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Edge computing and server-based high-precision flood level classification system},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WeedNet-X: A lightweight field weed detection algorithm. <em>EAAI</em>, <em>162</em>, 112441. (<a href='https://doi.org/10.1016/j.engappai.2025.112441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately distinguishing field weeds from crops and locating weed positions are critical prerequisites in automated weed control operations. However, weed detection and localization in unstructured field environments with complex lighting remains challenging. Firstly, data-driven deep learning based algorithms usually have a high dependence on a large number of training samples, and there are huge differences between field weeds and crops in different regions, growth cycles, and types. In addition, the conflict between hardware performance and computation cost makes it difficult for existing weed detection algorithms to maintain both detection accuracy and speed on low-performance platforms. All these problems increase the difficulty of detection. To solve the above problems, we first construct a medium-to-large weed dataset using an open-source agricultural image dataset and collect field data. Subsequently, we have proposed a lightweight weed detection algorithm using the ShuffleNetv2 network as the backbone network, with a multi-scale pyramid network, and the overall network algorithm is named WeedNet-X. The number of model parameters and the computational volume of the algorithm are only 0.57 million and 0.48 Giga floating point operations (GFLOPs), respectively. On the two constructed datasets, the mean Average Precision (mAP) of the algorithm can reach 86.31 % and 80.98 %, respectively, which are improved by 0.61 % and 3.10 % compared to the baseline model. Finally, the hardware and software systems for weed detection verify the excellence of the proposed algorithm in terms of practical performance.},
  archive      = {J_EAAI},
  author       = {Yong Li and Ao Ke and Zhiqiang Guo and Qingji Tan and Jingchao Yang},
  doi          = {10.1016/j.engappai.2025.112441},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112441},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {WeedNet-X: A lightweight field weed detection algorithm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven robust intertwined wheat supply chain: Redesigning a viable network for long-term geopolitical conflicts. <em>EAAI</em>, <em>162</em>, 112440. (<a href='https://doi.org/10.1016/j.engappai.2025.112440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent human-made conflict in 2022 severely damaged Ukraine's infrastructure, causing significant instability in the food supply chain. This crisis was further exacerbated by trade bans imposed on another major global wheat exporter. Since wheat production and export are intrinsically linked, particularly in times of crisis, it is essential to adopt the concept of an intertwined supply chain. Accordingly, this study proposes an intertwined supply chain framework for the production and export of wheat during long-term disruptions. To enhance the viability of this intertwined system, the study introduces three key strategies. First, it addresses long-term disruptions and operational risks by employing redundancies and data-driven robust optimization techniques, where uncertainty sets are generated using a support vector clustering model. Second, the proposed supply chain accounts for freshwater resource limitations by integrating water resilience measures. Third, as the framework operates within a global context, it incorporates a comprehensive model that considers exchange rates, taxation, foreign demand points, and international trade responsibilities. To optimize these strategies, two multi-objective optimization models are developed and solved using an epsilon-constraint method. A cardinality-based measure is introduced to efficiently represent the Pareto front, offering decision-makers valuable insights into non-dominated solutions. The results are divided into analyses of wheat production, export, and their combined network. Individual analyses assess network setup, viability, and uncertainty control, while the integrated analysis examines sensitivity and interdependence. Overall, improving water use, managing risks, and designing a resilient, interconnected system can greatly strengthen the wheat supply chain during long-term crises.},
  archive      = {J_EAAI},
  author       = {Hani Gilani and Mehrdad Mohammadi and Tom Van Woensel and Hadi Sahebi},
  doi          = {10.1016/j.engappai.2025.112440},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112440},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data-driven robust intertwined wheat supply chain: Redesigning a viable network for long-term geopolitical conflicts},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multitask learning-based fault detection approach for high impedance fault in resonant distribution networks. <em>EAAI</em>, <em>162</em>, 112439. (<a href='https://doi.org/10.1016/j.engappai.2025.112439'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing high impedance faults (HIF) in resonant distribution networks remains a formidable challenge. This paper introduces a multitask learning-based approach integrated with a multitask fault detection network (MTFD-Net), employing three task-specific heads—classification, segmentation, and regression—to enable precise fault detection. MTFD-Net utilizes zero-sequence voltage data and a sliding time window to perform initial coarse classification, which allows the classification head to determine whether a permanent HIF has occurred. Upon detection, MTFD-Net proceeds to pinpoint potential fault moments through the outputs of the segmentation head. The regression head further refines these moments by predicting a reference moment and calculating the distance to each potential fault, effectively isolating the exact fault moment. An industrial prototype was developed and rigorously tested on a 10 kV system, where MTFD-Net demonstrated superior performance, achieving an accuracy of 0.976, an intersection over union of 0.984, and an absolute detection deviation of 5.20 ms. Operating efficiently with inference times ranging from 9.69 to 15.45 miliseconds on a Raspberry Pi 4B, MTFD-Net surpasses existing methods in accuracy, F1-score, sensitivity, specificity, and detection accuracy, providing a robust solution for HIF detection in resonant distribution networks.},
  archive      = {J_EAAI},
  author       = {Jian-Hong Gao and Mou-Fa Guo and Shuyue Lin and Duan-Yu Chen},
  doi          = {10.1016/j.engappai.2025.112439},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112439},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multitask learning-based fault detection approach for high impedance fault in resonant distribution networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Carbon trading price prediction with spikes: A novel hybrid model framework using heuristic multi-head attention convolutional bidirectional recurrent neural network. <em>EAAI</em>, <em>162</em>, 112438. (<a href='https://doi.org/10.1016/j.engappai.2025.112438'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of carbon trading prices (CTPs) with spikes is crucial for developing carbon emission reduction policies and planning corporate investments. However, most existing CTP approaches usually focus on designing a cutting-edge model without considering spike prediction. Therefore, this paper presents a novel heuristic optimization-based hybrid model framework for CTP prediction with spikes. First, random forest is exploited to identify the relevant features of spikes and non-spikes for CTPs, and categorical boosting is employed to predict the spike occurrences of CTPs. Then, a novel hybrid model based on multiple linear regression, categorical boosting, and two dimensions convolutional neural network and bidirectional gated recurrent unit with multi-head regularized attention mechanism (2DCNN-BiGRU-MRA) is proposed to predict spikes and non-spikes for CTPs. In this model, multiple linear regression and categorical boosting are respectively applied to capture the linear and complex nonlinear features of the CTPs, in which their prediction results and deviations are integrated into the 2DCNN-BiGRU-MRA model as relevant features. The proposed 2DCNN-BiGRU-MRA can learn the spatiotemporal features and enhance representation capabilities by introducing 2DCNN, BiGRU, and MRA, thereby improving the accuracy of CTP prediction. In addition, to construct appropriate model hyperparameters of 2DCNN-BiGRU-MRA, the strength honey badger algorithm based on the adaptive momentum estimation is proposed to optimize the hyperparameters of 2DCNN-BiGRU-MRA. Finally, the proposed framework is tested on the actual data of European Union emissions trading and the carbon market in Hubei, China, and case studies have confirmed the superiority and achievable local interpretability of the proposed hybrid model framework.},
  archive      = {J_EAAI},
  author       = {Rongquan Zhang and Siqi Bu and Gangqiang Li and Min Zhou},
  doi          = {10.1016/j.engappai.2025.112438},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112438},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Carbon trading price prediction with spikes: A novel hybrid model framework using heuristic multi-head attention convolutional bidirectional recurrent neural network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inter-graph and intra-graph: Utilizing global financial markets and constituent stocks for stock index prediction. <em>EAAI</em>, <em>162</em>, 112437. (<a href='https://doi.org/10.1016/j.engappai.2025.112437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock index prediction is a significant yet difficult undertaking due to its incorporation of complex and diverse information. Following the implementation of Graph Neural Networks in financial data analysis, numerous researchers have focused on the node-level task of forecasting individual stock movements by analyzing the relationships between stocks. However, two key challenges remain: first, realizing different speeds of feature propagation among nodes in graph representation learning; second, predicting stock indices by extracting and aggregating fluctuations from constituent stocks through graph-level tasks remains unaddressed. To tackle these challenges, this paper proposes a novel spatio-temporal prediction framework combining both node-level and graph-level tasks. The framework includes two types of graphs: inter-graph and intra-graph, which combine information from the micro, meso, and macro dimensions. For the inter-graph at the node level, we introduce the Granger causality test as an innovative node filtering method, which realizes the propagation of features between nodes with different strengths and speeds in the process of graph representation learning. For the intra-graph at the graph level, we examine various graph pooling methods and pooling proportions of stock index constituents to enhance the interpretability of the results and to provide new theoretical insights for stock index prediction. In conclusion, we develop the Graph Representation Learning-based Long Short-Term Memory (GRL-LSTM) model for forecasting stock index movements, and demonstrate the superiority of our approach on four major Chinese stock markets.},
  archive      = {J_EAAI},
  author       = {Yong Shi and Yunong Wang and Jie Wu},
  doi          = {10.1016/j.engappai.2025.112437},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112437},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inter-graph and intra-graph: Utilizing global financial markets and constituent stocks for stock index prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel data-efficient double deep Q-network framework for intelligent financial portfolio management. <em>EAAI</em>, <em>162</em>, 112436. (<a href='https://doi.org/10.1016/j.engappai.2025.112436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Navigating the complexities of dynamic and uncertain financial markets demands intelligent systems capable of learning profitable strategies amidst risk and volatility. While Deep Q-Networks (DQN) offer a foundation for such systems, they often suffer from overestimation bias, training instability, and poor generalization in noisy financial environments. To address these challenges, this work introduces Portfolio Double Deep Q-Network (PDQN), a novel architecture inspired by recent advancements in reinforcement learning. PDQN enhances portfolio management by integrating Double Q-Learning to reduce overestimation, alongside Leaky ReLU activation, Xavier initialization, Huber loss, and dropout regularization to improve learning stability and generalization. Unlike prior methods that rely on large datasets and heavy computational infrastructure, PDQN achieves competitive—and often superior—performance using substantially less training data and lightweight infrastructure, making it well-suited for real-world, resource-constrained financial applications. Distinct from conventional approaches, PDQN uses separate networks to adapt portfolio decisions across varying market conditions. Empirical results across multiple market years show that PDQN often outperforms baseline strategies, including classic DQN and Buy-and-Hold, across key metrics such as Sharpe ratio, Sterling ratio, and cumulative return. PDQN—like all data-driven models—exhibits room for improvement under highly irregular or extreme financial scenarios. These observations suggest promising directions for future refinement and increased robustness, without detracting from the model's practical effectiveness and competitive edge.},
  archive      = {J_EAAI},
  author       = {Mahshad Alidousti and Morteza Khakzar Bafruei and Amir Hosein Afshar Sedigh},
  doi          = {10.1016/j.engappai.2025.112436},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112436},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel data-efficient double deep Q-network framework for intelligent financial portfolio management},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlocking few-shot wind speed prediction through a novel end-to-end transfer learning paradigm based on decomposition and gating information fusion. <em>EAAI</em>, <em>162</em>, 112435. (<a href='https://doi.org/10.1016/j.engappai.2025.112435'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate wind speed prediction is one of the key technologies for achieving intelligent and sustainable development in the engineering field. In the field of wind speed prediction, we are confronted with a challenging few-shot prediction problem. Specifically, due to the fact that some wind turbines in wind farms are newly established or there is data loss during the data collection process, these turbines only contain a small amount of wind speed data. This scarcity of data poses great difficulties for the prediction work, and traditional prediction methods often fail to achieve the desired prediction accuracy. In order to overcome the above difficulties, we propose an novel prediction paradigm of end-to-end transfer learning based on data decomposition and gated information fusion. We use the Fourier transform to find the source domain similar to the target domain to achieve feature alignment. Then, we pre-train the model on the source domain and transfer this model to the target domain, thus solving the problem of low prediction accuracy when directly predicting the target domain. In the first step, the data is decomposed and denoised by using the Variational Mode Decomposition. According to the sample entropy, the decomposed data is reorganized into three frequency components. Each component is input as an independent channel into the end-to-end prediction model. Firstly, the features of each channel are expanded to a high-dimensional space through the Multilayer Perceptron. Then, the gating mechanism is utilized to mix the features of the three channels into the features of one channel, thus achieving information fusion. Finally, the prediction result of the end-to-end model is output through the Gated Recurrent Unit. In the second step, the model pre-trained on the source domain is transferred to the small-sample target domain. The Dynamic Time Warping and cosine similarity are used to quantify the similarity of each channel between the two domains. The parameters of the channels with high similarity are locked, and at the same time, the parameters of other channels are fine-tuned to output the final prediction result. In addition, multiple sets of comparative experiments conducted using the wind speed data from wind farms in Queensland, Australia, have demonstrated the superiority of this prediction paradigm. Our strategy outperforms various baseline models in all three sets of data. Moreover, ablation experiments have proven the effectiveness of each component in this framework in improving prediction accuracy, opening up a new path for solving the difficult problem of few-shot prediction in practical engineering.},
  archive      = {J_EAAI},
  author       = {Xiaoyue Dong and Zhirui Tian},
  doi          = {10.1016/j.engappai.2025.112435},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112435},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unlocking few-shot wind speed prediction through a novel end-to-end transfer learning paradigm based on decomposition and gating information fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hyperparameter-fusion neural networks for deposition prediction. <em>EAAI</em>, <em>162</em>, 112434. (<a href='https://doi.org/10.1016/j.engappai.2025.112434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As integrated circuit manufacturing processes develop into the nanometer scale, precise control and prediction of the deposition process have become crucial. Nanoscale manufacturing imposes unprecedentedly high demands on film quality, uniformity, and consistency, presenting significant challenges to traditional control and prediction methodologies. This study proposes a novel approach that, for the first time, formulates the thin-film deposition process as a video prediction task, enabling the use of deep learning for morphological forecasting under varying process conditions, and introduces a novel hyperparameter-fusion neural network, referred to as DepositionNet (DepoNet). Unlike conventional video prediction models, DepoNet specifically accounts for the influence of deposition parameters on the entire simulation process. We have incorporated a novel Hyper Projector that allows the model to flexibly adapt to varying deposition conditions and material characteristics. Through comprehensive comparative experimental analyses, we demonstrate that DepoNet significantly outperforms existing deep-learning models and achieves a mean squared error of 17.34, representing a 3.67% improvement over the second best model and a 1,435 × speedup over physics-based methods, thereby validating its exceptional generalization capability. Extensive experiments reveal that the model maintains high performance even under conditions of limited training data, for instance, achieving a peak signal-to-noise ratio (PSNR) of 41.516 decibels (dB) when trained with only 20% of the available data.},
  archive      = {J_EAAI},
  author       = {Li Ding and Kun Pang and Junjie Li and Hua Shao and Nan Liu and Rui Chen and Zhiqiang Li and Zhenjie Yao and Ling Li},
  doi          = {10.1016/j.engappai.2025.112434},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112434},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hyperparameter-fusion neural networks for deposition prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overcoming challenges in leveraging blockchain technology: Entropy-based q-rung orthopair fuzzy model for benchmarking application barriers. <em>EAAI</em>, <em>162</em>, 112433. (<a href='https://doi.org/10.1016/j.engappai.2025.112433'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology has emerged as a transformative solution across industries, delivering enhanced transparency, security, and operational efficiency. Nevertheless, its adoption remains hindered by significant challenges, especially in complex, data-intensive domains such as logistics. This study introduces a novel integration of the entropy-based q-rung orthopair fuzzy compromise ranking of alternatives from distance to ideal solution (CRADIS) approach to systematically evaluate and prioritize key barriers to blockchain adoption. The innovation of this work lies in applying q-rung orthopair fuzzy sets which are particularly capable of handling higher degrees of uncertainty and hesitancy, and then integrated with entropy for objective criterion weighting and CRADIS for robust decision-making. A real-world case study is presented, involving five critical barriers, lack of legal and regulatory frameworks, high implementation costs, technological scalability issues, data privacy and security concerns, and cultural resistance to change evaluated against eight decision criteria. The entropy weighting revealed regulatory clarity (0.168) and security (0.154) as the most influential factors, while the CRADIS ranking identified a lack of legal frameworks as the top barrier. This framework provides a transparent, data-driven method for decision-makers to identify and prioritize adoption challenges, particularly in uncertain and multi-faceted environments. By demonstrating the model’s applicability and precision, the study contributes to the emerging body of literature on blockchain integration and supports organizations in navigating the transition towards decentralized technologies.},
  archive      = {J_EAAI},
  author       = {Sana Shahab and Naoufel Kraiem and Ashit Kumar Dutta and Mohd Anjum and Vladimir Simic and Dragan Pamucar},
  doi          = {10.1016/j.engappai.2025.112433},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112433},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Overcoming challenges in leveraging blockchain technology: Entropy-based q-rung orthopair fuzzy model for benchmarking application barriers},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual angle magnetic arc blow estimation in keyhole tungsten inert gas welding using high dynamic range imaging and a lightweight vision transformer network with coordinate attention and multiple auxiliary branches. <em>EAAI</em>, <em>162</em>, 112432. (<a href='https://doi.org/10.1016/j.engappai.2025.112432'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In high current Keyhole Tungsten Inert Gas (K-TIG) welding, magnetic arc blow frequently causes severe defects such as lack of fusion and undercut, which seriously affect weld formation quality. Conventional visual sensing systems are limited by dynamic range, making it difficult to capture arc morphology, while single angle descriptors fail to represent nonlinear deflection and lightweight convolutional models struggle with long range dependencies. To address these challenges, this study employs a High Dynamic Range (HDR, 120 decibel [dB]) imaging system to capture detailed arc variations and proposes a lightweight Vision Transformer (ViT) network with embedded Coordinate Attention (CA) and multiple auxiliary branches for real time angle estimation. A custom magnetic excitation system enables controllable arc blow simulation and consistent data acquisition. The method introduces a dual angle representation, namely the maximum curvature angle ( θ curv ) and the equivalent deviation angle ( θ eq ), to comprehensively describe arc geometry. The Artificial Intelligence (AI) framework integrates segmentation, keypoint localization, and regression tasks to improve accuracy and robustness. Trained on a self constructed HDR dataset containing 3,191 annotated images, model achieves a mean absolute error (MAE) of 1 . 12 ° , a root mean square error (RMSE) of 2 . 84 ° , a determination coefficient ( R 2 ) of 0.96, and a per frame inference latency of 12.96 ms (ms) on an NVIDIA RTX 2080Ti graphics processing unit (GPU). These results demonstrate that AI based methods combined with HDR imaging cannot only achieve accurate monitoring of welding arc states, but also provide potential support for closed loop control in all position welding applications.},
  archive      = {J_EAAI},
  author       = {Xiyin Chen and Xiaohu Zhang and Yonghua Shi and Yuxiang Huang and Junjie Pang},
  doi          = {10.1016/j.engappai.2025.112432},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112432},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual angle magnetic arc blow estimation in keyhole tungsten inert gas welding using high dynamic range imaging and a lightweight vision transformer network with coordinate attention and multiple auxiliary branches},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Plug-and-play dynamic optimization for three-dimensional gaussian generation. <em>EAAI</em>, <em>162</em>, 112431. (<a href='https://doi.org/10.1016/j.engappai.2025.112431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in Three-Dimensional (3D) asset generation have demonstrated remarkable progress in generation efficiency, enabling transformative applications across creative industries and mission-critical domains including autonomous systems. Current 3D asset generation primarily employs Score Distillation Sampling (SDS) to derive 3D priors from Two-Dimensional (2D) diffusion models. While this contribution ensures high generation quality, it is time-consuming. Recent methods have utilized 3D Gaussian Splatting for image rendering, which, despite enhancing generation speed, compromised on quality. Our method aims to balance the quality and speed of 3D asset generation by designing a plug-and-play optimization process that combines the strengths of both methods. We propose a rapid 3D Gaussian generation framework that begins with constructing a pipeline to generate multi-view images from text input using pre-trained generative models. Then our method utilizes 3D Gaussian Splatting for quick 3D asset initialization and subsequently performs detail optimization using Gaussian Filter and SDS-based 2D diffusion model optimizer. Additionally, we have optimized the loss function for 3D Gaussian Splatting and ensured the entire optimization process is plug-and-play, offering high generation quality and speed. Our method demonstrates strong adaptability in representative single-object 3D Gaussian generation tasks, indicating promising generalization potential. Achieving high-quality 3D generation on a single Graphics Processing Unit (GPU), our framework outperforms most popular optimization-based models in generation speed (5 × speedup +). Furthermore, when juxtaposed with the latest inference-based models, our optimization architecture offers a notable enhancement in generation quality (Contrastive Language-Image Pre-Training Score 33.8 vs. 27.3) within an acceptable amount of time.},
  archive      = {J_EAAI},
  author       = {Qixuan Li and Haoyang Li and Chao Wang and Yang Zhou and Yan Peng},
  doi          = {10.1016/j.engappai.2025.112431},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112431},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Plug-and-play dynamic optimization for three-dimensional gaussian generation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A diffusion model using semantic and sketch information for anomaly detection. <em>EAAI</em>, <em>162</em>, 112430. (<a href='https://doi.org/10.1016/j.engappai.2025.112430'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In anomaly detection, methods that employ diffusion models for anomaly localization and reconstruction have demonstrated significant achievements. However, these methods face challenges such as the misclassification of multiple types of anomalies and the inability to effectively reconstruct large-scale anomalies due to the absence of semantic and sketch information from the original images. To tackle these challenges, we propose a framework, A Diffusion Model using Semantic and Sketch Information for Anomaly Detection (DSAD), which includes a semantic and sketch-guided network (SSG), a pre-trained autoencoder, and Stable Diffusion (SD). Initially, within SSG, we introduce a Semantic & Sketch Feature Fusion Module to enhance the model’s comprehension of the original images and present a Multi-scale Feature Fusion Module to maximize reconstruction accuracy. Subsequently, we connect SSG with the denoising network in SD in order to guide the network in reconstructing anomalous regions. Experiments on MVTec-AD dataset demonstrate the effectiveness of our approach which surpasses the state-of-the-art methods. The dataset and code are available at https://github.com/QinLi-STUDY/DSAD/tree/master .},
  archive      = {J_EAAI},
  author       = {Li Qin and Zhenyu Yin and Feiqing Zhang and Chunhe Song and Xiaoqiang Shi},
  doi          = {10.1016/j.engappai.2025.112430},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112430},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A diffusion model using semantic and sketch information for anomaly detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A real-time spatiotemporal error compensation framework for face gear grinding. <em>EAAI</em>, <em>162</em>, 112429. (<a href='https://doi.org/10.1016/j.engappai.2025.112429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geometric and thermal errors critically affect the precision of face gear grinding, yet current modeling approaches are computationally intensive and lack real-time adaptability. This study proposes a real-time spatiotemporal error compensation framework for face gear grinding. A closed-loop feedback mechanism is introduced to adaptively update compensation intensity based on residual error feedback, ensuring robustness and efficiency under fluctuating machining conditions. Moreover, a novel spatial-temporal thermal error model is developed by integrating Taylor-graph convolutional network and modified-long short term memory network to capture both node-level spatial fusion and long-term temporal dependencies. High-order terms in geometric error modeling are eliminated using a vector decomposition and truncation-based approach, significantly reducing computational complexity. Furthermore, a high-efficiency multi-source error-tooth flank mapping model is developed based on vector decomposition and truncation function methods, enabling accurate prediction with reduced computational cost. To identify dominant error contributors, an improved Morris-based sensitivity analysis method is integrated, distinguishing geometric and thermal errors affecting tooth flank deviation. Experimental results demonstrate sub-65 ms real-time response, 24.2 μm maximum error reduction, and robust adaptability under fluctuating machining conditions. Compared with recent gear-flank compensation studies, the proposed closed-loop framework achieves a 63.4 % reduction in maximum normal flank error under real machining and <65 ms response latency. This level is comparable to reported reductions based on grid-aggregated metrics in spiral bevel gears (76.82 % reduction of the sum of absolute grid errors), while additionally ensuring real-time, delay-aware execution. These findings validate the proposed system's potential for precision, real-time compensation in multi-axis manufacturing environments.},
  archive      = {J_EAAI},
  author       = {Jialan Liu and Chi Ma and Mingming Li and Jialong He and Giovanni Totis and Chunlei Hua and Gangwei Cui and Liang Wang and Ruijun Xue and Zhi Tan and Jun Yang and Kuo Liu and Yuansheng Zhou and Jianqiang Zhou and Xiaolei Deng and Shengbin Weng},
  doi          = {10.1016/j.engappai.2025.112429},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112429},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A real-time spatiotemporal error compensation framework for face gear grinding},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multilayer perceptron-based offspring prediction model for constrained multi-objective optimization. <em>EAAI</em>, <em>162</em>, 112428. (<a href='https://doi.org/10.1016/j.engappai.2025.112428'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multi-objective optimization problems generally have both multiple constraint violations and conflicting objective functions. Some of them not only have sparse feasible regions, but also are difficult to converge. For these problems, the evolutionary operators used in traditional constrained multi-objective evolutionary algorithms (CMOEAs) are difficult to generate solutions with ideal quality. Therefore, this paper proposes a multilayer perceptron-based offspring prediction model for constrained multi-objective optimization (MOPCMO). Specifically, an evolutionary direction guidance strategy is designed that utilizes historical populations as training data to train a multilayer perceptron, which guides the evolution of the population by predicting and generating offspring, thereby improving the overall evolutionary efficiency of the algorithm. In addition, as the population iterates, evolutionary direction guidance strategy adaptively transforms the training data of multilayer perceptron. Finally, the multilayer perceptron is intermittently updated and uses an evolutionary direction guidance strategy to generate promising offspring, guiding the algorithm to achieve efficient search. Compared with seven state-of-the-art CMOEAs on 33 benchmark test problems and 8 engineering application problems, MOPCMO achieves excellent performance.},
  archive      = {J_EAAI},
  author       = {Qianlong Dang and Ruihuan Luo and Linlin Xie and Xiaochuan Gao and Weiting Bai},
  doi          = {10.1016/j.engappai.2025.112428},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112428},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multilayer perceptron-based offspring prediction model for constrained multi-objective optimization},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault diagnosis via multi-sensor fusion with auxiliary contrastive learning and phased fine-tuning. <em>EAAI</em>, <em>162</em>, 112427. (<a href='https://doi.org/10.1016/j.engappai.2025.112427'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Typically, deep learning-based fault diagnosis models fail to fully utilize the potential information in large amounts of normal state data and encounter difficulties when learning from limited fault samples. To address these challenges, this study proposes an auxiliary contrastive learning framework designed for multi-sensor data. The framework incorporates auxiliary classifiers after each sensor-specific branch to enhance feature representation, and enables model pretraining using only normal condition data. In addition, a phased fine-tuning strategy is developed, which combines full-model fine-tuning with lightweight adapter tuning to improve the adaptability of the fine-tuning process. A novel multi-sensor data augmentation technique is also introduced to enrich the contrastive learning tasks by generating structurally diverse negative samples. By enabling the effective utilization of normal condition data in model training, the proposed framework offers a new perspective for fault diagnosis applications. Experimental results on three benchmark datasets demonstrate that the proposed method significantly improves the generalization capability of the pre-trained model. Furthermore, the phased fine-tuning strategy exhibits high adaptability to the target tasks. Compared to other data fusion methods, the proposed auxiliary contrastive learning framework achieves notable performance advantages.},
  archive      = {J_EAAI},
  author       = {Yulin Jin and Xiaochuan Luo and Xiangwei Kong and Yulin Zhang},
  doi          = {10.1016/j.engappai.2025.112427},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112427},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fault diagnosis via multi-sensor fusion with auxiliary contrastive learning and phased fine-tuning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Damage and energy dissipation prediction and multi-objective optimization design of latticed concrete-filled steel tube column-composite box girder joints based on extreme gradient boosting. <em>EAAI</em>, <em>162</em>, 112426. (<a href='https://doi.org/10.1016/j.engappai.2025.112426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To optimize joint performance, a finite element (FE) model is developed based on low-cycle reciprocating load tests of latticed concrete-filled steel tubular (CFST) column-composite box girder joints. The FE-predicted hysteresis curves are compared with test results to verify model accuracy, and a data set is established accordingly. Extreme Gradient Boosting (XGBoost) algorithm is used for training and prediction, and compared with the traditional machine learning (ML) algorithm, the superiority of the XGBoost algorithm is manifested. The XGBoost algorithm is then used to predict the damage and energy values of the joint under more different parameter combinations, with the largest ratio of damage value to energy dissipation value selected as the optimal combination of the joints within the variation range of the six parameters. The results show that the FE model correlates well with the test results and can therefore be used to generate a data set. The prediction accuracy of XGBoost algorithm has high accuracy of more than 99 % in predicting damage and energy dissipation values and can thus be used for joint prediction research. Compared with other ML algorithms, XGBoost has the best prediction performance and superiority. Within the variation range of the six parameters, the ratio of damage value to energy dissipation value is the largest when the concrete strength, longitudinal bar diameter, concrete slab thickness, box girder strength, axial compression ratio, and transverse stiffener strength are respectively 30 Mega Pascal (MPa), 12 mm (mm), 90 mm, 390 MPa, 0.3, and 455 MPa.},
  archive      = {J_EAAI},
  author       = {Zhi Huang and Xin Deng and Juan Chen and Xiang Li and Lizhong Jiang and Yohchia Frank Chen and Yuner Huang and Lin Chen},
  doi          = {10.1016/j.engappai.2025.112426},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112426},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Damage and energy dissipation prediction and multi-objective optimization design of latticed concrete-filled steel tube column-composite box girder joints based on extreme gradient boosting},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-dimensional feature fusion network design and performance optimisation for small target detection. <em>EAAI</em>, <em>162</em>, 112425. (<a href='https://doi.org/10.1016/j.engappai.2025.112425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the long distance of image acquisition, high imaging resolution, complex feature background, shooting angle, etc. The result is that there are few features available for small targets and they are easily interfered by background noise, which poses a challenge to the detection of small targets. To address the above problems, this paper proposes a target detection network (Convolution-based Small Target Detection Network, CSTDNet) with enhanced feature information, which integrates a multi-dimensional information fusion strategy for small target features. An all-round efficient feature fusion mudule (AeFusion) is introduced, which emphasises the fusion of multi-dimensional feature information, enhances the model's ability to focus on key information and suppress redundant information, and strengthens the ability to characterise local features and details, improving the effectiveness of the information and computational efficiency. In order to further enhance the location-awareness capability in cross-layer interaction, this paper introduces a novel decoupling head (Self-aware task decomposition for fine-grained feature sharing, STFS), which improves the accuracy of the small-target classification and localisation tasks through efficient detail sharing and task auto-alignment functions. And localisation tasks through efficient detail sharing and task auto-alignment. This study evaluates the effectiveness of the algorithm on five different scenarios containing small target datasets. Experimental results show that CSTDNet achieved improvements of 6.6 %, 5.8 %, 5.8 %, 5.5 %, and 5.6 % over the baseline model in terms of the mean average precision (mAP@0.5) metric on the Visdrone 2019, BDD100K, WiderPerson, SODA10M, and AppleDatas datasets, respectively, demonstrating stronger detection performance.},
  archive      = {J_EAAI},
  author       = {Xiaoyao Yang and Wenyang Zhao and Pengchao Sun and Wenda Zhao and Wenlong Yang},
  doi          = {10.1016/j.engappai.2025.112425},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112425},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-dimensional feature fusion network design and performance optimisation for small target detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FDFNet: Feature-decision dual fusion network for intelligent fault diagnosis of rotating machinery under varying speed conditions. <em>EAAI</em>, <em>162</em>, 112423. (<a href='https://doi.org/10.1016/j.engappai.2025.112423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis is a critical technique for enhancing the reliability and security of rotating machinery. Existing diagnosis methods still have restricted generalization performance under speed variations owing to inadequate utilization of multisensor information. To address this problem, a novel feature-decision dual fusion network is proposed for fault diagnosis of rotating machinery under varying speed conditions. First, for each sensor, the frequency information learner is built to simultaneously extract global and local frequency domain features using global and local feature encoders. These features are then fused through a cross-attention mechanism to generate a sensor-specific initial classification decision. Subsequently, these individual sensor-wise decisions are fed into the decision dynamic ensemble to yield final fault diagnosis result. Moreover, an adaptive optimization strategy is designed to guide model learning generalizable features by flexibly adjusting the sensor loss weights during training. Finally, the effectiveness of the proposed method is validated on bearing and gearbox datasets. Experimental results demonstrate that the proposed method exhibits superior generalization and robustness for fault diagnosis under varying speed conditions.},
  archive      = {J_EAAI},
  author       = {Qi Deng and Zuoxiu Zhang and Xuyuan Tu and Zimuzhi Wang and Jun Wu},
  doi          = {10.1016/j.engappai.2025.112423},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112423},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {FDFNet: Feature-decision dual fusion network for intelligent fault diagnosis of rotating machinery under varying speed conditions},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resource-efficient cross-subject emotion recognition from electroencephalogram via spiking domain discriminators. <em>EAAI</em>, <em>162</em>, 112422. (<a href='https://doi.org/10.1016/j.engappai.2025.112422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time emotion recognition poses a significant challenge in electroencephalogram (EEG) based emotion recognition, as it requires the immediate processing of EEG data. This necessity imposes substantial demands on the model’s resource consumption. To address this issue, this paper introduces a novel approach to EEG emotion recognition using a Cross Domain Spiking Convolutional Network (CDSCN), focusing on developments in the design of the spiking convolutional block. To address individual differences, the CDSCN incorporates Z-Score normalization at the feature level and introduces a spiking domain discriminator at the model level. These innovations aim to mitigate variations in data distribution across individuals and domains, thereby enhancing the model’s robustness and generalizability. Additionally, the CDSCN introduces a novel pooling fusion layer within the spiking convolutional block to optimize computational efficiency while preserving discriminative performance. Experimental evaluations on two publicly available datasets validate the effectiveness of the proposed CDSCN in achieving both accurate and generalized emotion recognition.},
  archive      = {J_EAAI},
  author       = {Dongdong Li and Shengyao Huang and Yujun Shen and Zhe Wang},
  doi          = {10.1016/j.engappai.2025.112422},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112422},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Resource-efficient cross-subject emotion recognition from electroencephalogram via spiking domain discriminators},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight deep learning based solar cells defect detection using electroluminescence images. <em>EAAI</em>, <em>162</em>, 112421. (<a href='https://doi.org/10.1016/j.engappai.2025.112421'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solar cells are the fundamental core energy harvesting components in photovoltaic (PV) power generation stations. In view of the capability of detecting the invisible defects, the electroluminescence (EL) imaging is broadly used in the production lines of solar cells, based on which the deep learning technique is introduced to implement automatic defect detection and classification. However, the current deep learning models feature high complexity and require much computation resources, which are difficult to deploy in edge devices for real time applications. To tackle this issue, we proposed a novel lightweight and high-precision deep learning model named Cross Stage Partial Photovoltaic-You Only Look Once (CSPV-YOLO) based on the deep learning framework You Only Look Once v5 (YOLOv5) to enable the real-time solar cell defect detection. Firstly, a new module Cross Stage Partial C5 (CSPC5) is proposed to replace the initial C3 module in the YOLOv5 network to enhance the network accuracy in recognizing different types of defects. Secondly, a novel Spatial Pyramid Pooling with Cross Stage Partial (SPPFCSP) module is designed to replace the original Spatial Pyramid Pooling Fast (SPPF), which boosts the network feature extraction capabilities from defect targets at multiple scales and facilitates a more efficient integration of multiscale features. Finally, the original loss function of YOLOv5 is replaced by the Scylla intersection over union (SIoU) function to optimize the training model. The proposed models have been validated and intensively compared with many other state-of-the-art models on two public datasets. Firstly, results of experiments on the public Pascal Visual Object Classes (PASCAL VOC) 2007 datasets demonstrate that the proposed SPPFCSP block is obviously superior to other Spatial Pyramid Pooling blocks for the most state-of-the-art YOLO detectors, which can significantly improve the detection accuracy. The comparison results of experiments on the public Photovoltaic Electroluminescence Anomaly Detection Dataset (PVEL-AD) that includes 12-class defects obviously indicate that the proposed CSPV-YOLO model is better than many state-of-the-art models and achieves 91.5 % average precision (AP) and frames per second (FPS) of 177.8 on with only 2.2 million (M) parameters. Hence, it is suitable for the deployment on edge devices for real-time applications.},
  archive      = {J_EAAI},
  author       = {Zhicong Chen and Tianxiang Chen and Haoxin Zheng and Lijun Wu and Shuying Cheng and Peijie Lin},
  doi          = {10.1016/j.engappai.2025.112421},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112421},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightweight deep learning based solar cells defect detection using electroluminescence images},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple scattering-assisted data-driven full waveform inversion for pipeline blockage detection. <em>EAAI</em>, <em>162</em>, 112420. (<a href='https://doi.org/10.1016/j.engappai.2025.112420'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockages in urban water supply systems (UWSS) cause operational inefficiencies and require timely detection and intervention. Hydraulic transients offer an efficient method for diagnosing UWSS. However, existing transient-based approaches face limitations: they either rely on gradient-descent optimization algorithms, which are prone to convergence issues due to noise, or they assume weak blockage-induced scattering that only applies to small blockages, thereby restricting their diagnostic scope. This study introduces a novel approach that leverages multiple scattering of transient wavefields to enhance full waveform inversion (FWI) for accurate pipeline blockage detection and profiling. Recognizing that blockage characteristics – such as length, size, and location – significantly alter the system’s transient response, we perturb these parameters to generate a comprehensive dataset using a numerical model. This dataset is used to train a machine learning (ML) model designed to associate multiple scattered wavefield patterns with specific blockage characteristics. The ML model performs full waveform inversion to predict spatial variations in pipeline area, thereby revealing detailed blockage profiles. We validate the effectiveness of our method through numerical simulations and experimental data, which account for multiply scattered wavefields influenced by visco-elastic and frictional damping effects. Specifically, we quantify prediction accuracy by reporting errors in key blockage parameters such as length and radial extent, which directly influence pipeline performance. Additionally, we assess the framework’s resilience to noise, a common challenge in practical applications. The proposed framework demonstrates that ML can effectively interpret complex scattered wavefield data related to pipeline defects, paving the way for advancements in diagnosing large-scale water networks.},
  archive      = {J_EAAI},
  author       = {Utban Ahmed and Muhammad Waqar and Fedi Zouari and Liyou Luo and Moez Louati and Jensen Li and Mohamed S. Ghidaoui},
  doi          = {10.1016/j.engappai.2025.112420},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112420},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiple scattering-assisted data-driven full waveform inversion for pipeline blockage detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A streaming variable neural speech codec. <em>EAAI</em>, <em>162</em>, 112418. (<a href='https://doi.org/10.1016/j.engappai.2025.112418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a variable bit rate streaming neural speech codec designed for ultra-low bit rate scenarios, based on the SoundStream network framework. The codec employs the vector quantized variational auto-encoder (VQ-VAE) algorithm to capture the temporal structure and spectral characteristics of the speech signal, and constructs a latent space codebook to facilitate the effective mapping of feature vectors to discrete vectors. Based on the harmonic characteristics of speech signals and the inherent defects of single-scale discriminators, we introduce multi-period discriminators and multi-scale discriminators. The training process uses a balanced training strategy to ensure the balance between codebook utilization and training weights, and utilizes the Short-Time Fourier Transform (STFT) spectrum that can provide more accurate time–frequency resolution to compute the reconstruction loss. We introduce codebook loss to improve the utilization rate of the codebook and accelerate the convergence of the model. In the inference process, we use a quantizer selection strategy to achieve adaptive adjustment of variable bitrate. Objective and subjective experiments demonstrate that our proposed new neural speech codec outperforms traditional classical speech codecs and existing neural speech codecs in terms of reconstructed speech naturalness and quality while maintaining the low latency characteristic of neural speech codecs. With a multi-stimulus test with hidden reference and anchor (MUSHRA) score of 87, it is highly suitable for ultra-low bit rate speech compression applications such as satellite speech communication and narrowband instant messaging. The demo has been publicly released at https://svcodec.github.io/ .},
  archive      = {J_EAAI},
  author       = {Huaifeng Zhang and Pengfei Wu and Guigeng Li and Yuan An and Hao Zhang},
  doi          = {10.1016/j.engappai.2025.112418},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112418},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A streaming variable neural speech codec},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LGP-DETR: An end-to-end object detection model for surface defect detection in light guide plates. <em>EAAI</em>, <em>162</em>, 112416. (<a href='https://doi.org/10.1016/j.engappai.2025.112416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose Light Guide Plate-DETR (LGP-DETR), an end-to-end object detection model tailored for identifying surface defects in light guide plates (LGPs). To address challenges such as low contrast, small target size, and complex backgrounds in industrial settings, LGP-DETR integrates three key components: Deformable Transformer Fusion Layer (DtransFusion), a deformable attention-based fusion module for capturing multi-scale features; Upsampling by Dynamic Sampling (DySample), a dynamic upsampling strategy for edge detail preservation; and OrthoC3, a channel attention module that suppresses background noise through orthogonal feature enhancement. We adopt FasterNet as a lightweight convolutional backbone to achieve a balance between accuracy and efficiency. Experimental results on a real-world LGP defect dataset demonstrate that LGP-DETR achieves a mean Average Precision (mAP) of 97.9 % and inference speed of 60 frames per second (FPS), significantly outperforming existing models. Furthermore, generalization tests on a fiberglass fabric defect dataset confirm the model's adaptability to different industrial domains. These findings validate the practical applicability and robustness of the proposed deep learning framework for industrial visual inspection.},
  archive      = {J_EAAI},
  author       = {Shuangning Liu and Cunling Liu and Junfeng Li},
  doi          = {10.1016/j.engappai.2025.112416},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112416},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {LGP-DETR: An end-to-end object detection model for surface defect detection in light guide plates},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards efficient stream monitoring: A systematic approach for model selection and continuous improvement in tiny machine learning applications. <em>EAAI</em>, <em>162</em>, 112415. (<a href='https://doi.org/10.1016/j.engappai.2025.112415'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring ephemeral stream flows is essential for ecological and hydrological studies. However, their intermittent nature and remote locations pose challenges for conventional monitoring methods, which often consume excessive energy to capture rare events. We address this with BODOQUE (Bimodal Observational Device for Optimizing Quantification of Ephemeral streams), a dual-mode system that leverages Tiny Machine Learning (TinyML) on low-power microcontrollers. The system remains in an energy-saving sensing state and activates high-precision measurements only when water flow is detected. We present a model selection methodology that balances detection accuracy with inference cost, enabling reliable operation within hardware constraints. To enhance adaptability in diverse environments, we developed a specialized component that facilitates dataset expansion through new field samples. This supports ongoing retraining to maintain model performance under changing conditions. A comprehensive evaluation using real-world data demonstrates that our system can achieve up to 97% annual energy savings compared to traditional continuous monitoring approaches.},
  archive      = {J_EAAI},
  author       = {Benjamín Arratia and Erika Rosas and Javier Prades and Salvador Peña-Haro and José M. Cecilia and Pietro Manzoni},
  doi          = {10.1016/j.engappai.2025.112415},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112415},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards efficient stream monitoring: A systematic approach for model selection and continuous improvement in tiny machine learning applications},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer architecture with illumination aware mechanisms for low-light image enhancement via retinex decomposition. <em>EAAI</em>, <em>162</em>, 112414. (<a href='https://doi.org/10.1016/j.engappai.2025.112414'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancing low-light images is a complex task that involves not only restoring brightness but also preserving color fidelity and reducing noise interference. In this paper, we propose a novel Retinex-based Transformer Model with Illumination Aware Mechanisms (TIMRetinex-Net), which achieves physically interpretable modeling through a decomposition network guided by Retinex theory. To adapt to light variations in different regions, we randomly apply gamma transformations to several subregions of the illumination component and use a Color Estimation Module to capture the color global distribution of the natural scene in the reflection component. By modeling the color global distribution and repairing the degraded regions collaboratively, we alleviate the issue of being highly sensitive to data usage during training and improve the model’s ability to handle unknown scenes. The Illumination and Reflection Adjustment Transformer Network (IRAT-Net) produces enhanced images, achieving a balanced enhancement of detail and color. In addition, IRAT-Net incorporates an attention mechanism into the feature extraction layer and introduces the Illumination-Guided Information Aggregation Module to adaptively estimate lighting conditions. In the field of image processing, our method based on artificial intelligence was evaluated on five datasets and compared with twelve state-of-the-art methods. The results demonstrated strong alignment with the ground truth, with our method achieving superior performance in both subjective and objective assessments.},
  archive      = {J_EAAI},
  author       = {Zixuan Wang and Gang Liu and Hanlin Xu and Yao Qian and Rui Chang and Durga Prasad Bavirisetti},
  doi          = {10.1016/j.engappai.2025.112414},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112414},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transformer architecture with illumination aware mechanisms for low-light image enhancement via retinex decomposition},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient interactive segmentation of three-dimensional gaussians with optimal view selection. <em>EAAI</em>, <em>162</em>, 112413. (<a href='https://doi.org/10.1016/j.engappai.2025.112413'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) scene representation has advanced rapidly in recent years, drawing the focus of more researchers. One of the main challenges for researchers is quickly and accurately segmenting 3D objects. Previous work has achieved excellent segmentation accuracy, but retraining requires a significant amount of time. Additionally, most methods fail to provide users with an efficient and convenient segmentation experience. To address these issues, we present Efficient Interactive Segmentation of 3D Gaussians (EISG), an efficient interactive segmentation method that eliminates the need for lengthy retraining. We first design an optimal view selection (OVS) method. This method uses 3D Gaussian entropy and image uncertainty to evaluate the quantity of view information. OVS helps users quickly select the optimal segmentation view, thereby enhancing interaction efficiency. Secondly, we use projection to find the target foreground rapidly and then segment the approximate objects using a clustering algorithm. Thirdly, we design a spatial-color background filter (SCBF) using the depth and color of 3D Gaussians. SCBF enables precise segmentation without needing retraining. Our method has been systematically tested on multiple datasets. Compared to other methods, the results demonstrate that EISG achieves ideal accuracy while significantly reducing processing time.},
  archive      = {J_EAAI},
  author       = {Yongtang Bao and Chengjie Tang and Yuze Wang and Yutong Qi and Ruijun Liu},
  doi          = {10.1016/j.engappai.2025.112413},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112413},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient interactive segmentation of three-dimensional gaussians with optimal view selection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial black-box attack and defense for convolutional neural network-based power quality disturbance classification. <em>EAAI</em>, <em>162</em>, 112411. (<a href='https://doi.org/10.1016/j.engappai.2025.112411'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correctly identifying power quality disturbance (PQD) is crucial for the proper functioning of power systems. Deep learning (DL) techniques have been widely used for PQD classification due to their excellent performance. However, DL models are susceptible to adversarial attacks, posing a serious security threat to DL-based PQD classification systems. This issue has received limited attention in current research. In this study, we first utilize a convolutional neural network (CNN) to recognize various types of PQD signals. To evaluate model robustness, we introduce a black-box attack method for PQD classification based on the variance-tuning momentum iterative fast gradient sign method (VMI-FGSM). VMI-FGSM integrates a variance tuning method into the iterative process of the momentum iterative fast gradient sign method (MI-FGSM) , thereby producing more transferable adversarial PQD signals. To defend against such attacks, we propose a perturbation removal defense based on a generative adversarial network (PRD-GAN). This approach is capable of removing perturbations from adversarial PQD signals before they are recognized by the target classification model. Experiments demonstrate that VMI-FGSM produces adversarial perturbations that are nearly identical to those of the advanced MI-FGSM, but its adversarial examples are significantly more effective at misleading the target CNN model. Furthermore, the proposed PRD-GAN effectively reconstructs adversarial PQD signals into clean forms under various black-box attack intensities and outperforms the multi-level denoising autoencoder (ML-DAE) in defense performance due to its superior reconstruction capability.},
  archive      = {J_EAAI},
  author       = {Xiudong Zhang and Congmei Jiang and Mingbiao Yu and Xiankui Wen and Jing Zhang and Na Rong and Song Han},
  doi          = {10.1016/j.engappai.2025.112411},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112411},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adversarial black-box attack and defense for convolutional neural network-based power quality disturbance classification},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An intrusion detection system for critical infrastructures: Modbus approach. <em>EAAI</em>, <em>162</em>, 112410. (<a href='https://doi.org/10.1016/j.engappai.2025.112410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to develop an Intrusion Detection System (IDS) using deep learning and machine learning algorithms to detect cyber attacks in the network traffic of critical infrastructures using an artificial intelligence-based approach. The research investigates various machine learning algorithms, datasets, and performance evaluations to detect the security vulnerabilities commonly found in industrial networks. Implemented in Python, the system has been tested on hybrid dataset, demonstrating the performance of different algorithms in terms of accuracy, precision, and other metrics. From artificial intelligence perspective, this study contributes machine learning and deep learning in cybersecurity, showing how normal and ensemble models can effectively detect complex threats, with fewer features but more relevant. The research employs supervised learning techniques, leveraging labeled datasets to train models that can accurately classify network traffic as either normal or attack, ensuring high detection accuracy. From an engineering standpoint, the system’s Python implementation addresses the practical challenges of real-world deployment in industrial control systems (ICS) and facilitates integration with existing infrastructures. Additionally, the custom dataset and post-dissector code contribute to the field of industrial cybersecurity, providing engineers with tools for testing, validating, and optimizing IDS solutions. As cyber–physical systems are increasingly integrated into ICS, the proposed IDS provides a crucial layer of defense against cyber threats, safeguarding both the digital and physical components of critical infrastructure. The findings reveal that the proposed system exhibits high performance in terms of detection accuracy. The results show that the system provides an effective and reliable detection mechanism using artificial intelligence techniques.},
  archive      = {J_EAAI},
  author       = {Murat Varol and Murat İskefiyeli},
  doi          = {10.1016/j.engappai.2025.112410},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112410},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An intrusion detection system for critical infrastructures: Modbus approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive resource management in dynamic Cyber–Physical systems using artificial intelligence. <em>EAAI</em>, <em>162</em>, 112409. (<a href='https://doi.org/10.1016/j.engappai.2025.112409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective resource management is crucial for the operation of dynamic Cyber–Physical Systems (CPS), yet traditional static or rule-based approaches often fail to handle their inherent complexity. This paper presents a novel Artificial Intelligence (AI)-driven framework for adaptive resource management, defined as the capability to autonomously adjust resource allocation by proactively forecasting future demands and dynamically optimizing decisions in real-time. The framework integrates a suite of AI techniques, including time-series models like Long Short-Term Memory (LSTM), chosen for their ability to capture complex temporal dependencies, for demand prediction. For resource allocation, it employs advanced actor–critic reinforcement learning (RL) algorithms like Proximal Policy Optimization (PPO) and Deep Deterministic Policy Gradient (DDPG), selected for their stability and efficiency in complex decision-making tasks. Performance was rigorously evaluated in a simulated dynamic environment. Experimental results demonstrate that combinations leveraging LSTM’s predictive accuracy with the robust optimization of PPO and DDPG achieve superior performance and stability. Specifically, the LSTM+DDPG and LSTM+PPO configurations yielded the highest average rewards (0.964 and 0.942, respectively), significantly outperforming the fixed-strategy baseline (0.497) and other AI pairings. Furthermore, the feasibility of training prediction models in a distributed manner via Federated Learning (FL) is successfully demonstrated. This research highlights that a synergistic integration of suitable AI predictors and advanced RL agents provides a powerful and resilient solution for resource management in dynamic CPS.},
  archive      = {J_EAAI},
  author       = {Xiaofei Zhao and Fangling Guo and Amin Huang and Jieqiong Ding and Chi Yan and Wei Yuan and Yunqi Su and Quanzhou Li and Qianggang Zhang},
  doi          = {10.1016/j.engappai.2025.112409},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112409},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive resource management in dynamic Cyber–Physical systems using artificial intelligence},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel prior knowledge-based and texture-enhanced network for few-shot industrial defect segmentation. <em>EAAI</em>, <em>162</em>, 112408. (<a href='https://doi.org/10.1016/j.engappai.2025.112408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based segmentation techniques have demonstrated significant potential in defect detection, which is vital for product quality. However, the existing models tend to specialize in detecting specific defect types, reducing their adaptability to a wider range of product defects, most existing methods rely on multi-scale or prototype learning to extract defect features, but still struggle with complex backgrounds, various interferences, and large intra-class variations. Additionally, the rarity of certain defects limits the availability of training samples. Herein, an innovative segmentation network, the Prior Knowledge-based and Texture-Enhanced Network (PTNet), is designed for few-shot industrial segmentation. The model is mainly composed of a self-guidance branch, a cross-guidance branch, and a texture enhancement module, enabling generalization across defect types with minimal labeled samples. Self-guidance extracts prior knowledge from the query image, while the cross-guidance branch extracts prior and prototype features from the masked support image. The texture information in the low-level features of the backbone is then enhanced by proposed texture enhancement module (TEM). Finally, the enhanced low-level texture information are fused with high-level semantic features, allowing the network to fully exploit both local details and global context before being decoded to restore the original image size. This enables the model to handle complex textures and generalize to unseen defect types. Extensive experimental results validate the effectiveness of the proposed modules. State-of-the-art performance is achieved in few-shot defect segmentation, with notable improvements in mean Intersection over Union (mIoU) of 46.05 % and 46.98 % under 1-shot and 5-shot conditions, respectively.},
  archive      = {J_EAAI},
  author       = {Xingyue Liu and Qian Wu and Yahui Cheng and Guojun Wen},
  doi          = {10.1016/j.engappai.2025.112408},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112408},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel prior knowledge-based and texture-enhanced network for few-shot industrial defect segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel reinforcement learning-based approach for optimal control: An application to multi-tank water systems. <em>EAAI</em>, <em>162</em>, 112407. (<a href='https://doi.org/10.1016/j.engappai.2025.112407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization of control actions is a critical challenge in industrial systems, especially when dealing with complex and unknown dynamics. Data collected from the environment enables the application of reinforcement learning techniques, which let the controller learn a policy based on data. This work proposes a novel model-free reinforcement learning approach that consists of a value iteration algorithm based on separate policy evaluation and policy improvement phases to provide an accurate control policy estimation. The proposed approach addresses tracking control for quadruple-tank water systems while obtaining minor tracking errors and faster transient responses. The results from the case study reveal better accurate estimation of the value function, up to 86.13% mean improvement in tracking accuracy and faster responses compared to existing methods. Therefore, the proposed approach demonstrates advantages in optimizing control performance and stands as a promising control method for industrial applications.},
  archive      = {J_EAAI},
  author       = {Eva Masero and Giacomo Mussita and Alessio La Bella and Riccardo Scattolini},
  doi          = {10.1016/j.engappai.2025.112407},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112407},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel reinforcement learning-based approach for optimal control: An application to multi-tank water systems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic weighted ensemble learning for ballast resistance estimation driven by vehicle-ground information fusion. <em>EAAI</em>, <em>162</em>, 112406. (<a href='https://doi.org/10.1016/j.engappai.2025.112406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health management of transmission parameters for railway signal equipment is a key link between intelligent operation and maintenance. As a core parameter of track circuits, ballast resistance significantly affects signal transmission. To accurately and reliably assess its health state, an ensemble learning algorithm (ELA) is introduced, tackling deviations of appraisal decision boundaries. Focusing on issues of complex weight calculation, model homogenization, and severe overfitting in ELA, an integration model based on an automatic weight allocation strategy (AWAS) is innovatively proposed, constructing a method for resistance estimations driven by information fusion, while maximizing its generalization ability. Firstly, for deterioration mechanism analysis of ballast resistance, a transmission state model for vehicle-ground collaboration is established, completing extractions of evolutionary rules. Secondly, the improved ELA leverages heterogeneous classifier optimization and automatic weighted soft voting, with its core ensemble strategy employing a secondary learner to map the fused datasets. Then, by means of data mining techniques, interpolation and denoising algorithms are applied to implement data preprocessing, facilitating the effective fusion of heterogeneous vehicle-ground information. Finally, based on occurrence of adverse conditions, an appropriate particle size is set to achieve state warning. The results indicate that the proposed AWAS for ballast resistance calculations can achieve 98.52 % testing accuracy and outperforms others.},
  archive      = {J_EAAI},
  author       = {Conghui Wang and Shiwu Yang and Chang Liu},
  doi          = {10.1016/j.engappai.2025.112406},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112406},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automatic weighted ensemble learning for ballast resistance estimation driven by vehicle-ground information fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Future of humanity in an artificial intelligence centric world. <em>EAAI</em>, <em>162</em>, 112405. (<a href='https://doi.org/10.1016/j.engappai.2025.112405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This scholarly article rigorously investigates the transformative and disruptive roles of artificial intelligence (AI) in influencing the trajectory of human society. By concentrating on three fundamental sectors—healthcare, finance, and education—it evaluates the ways in which AI augments operational efficiency, facilitates intricate decision-making processes, and introduces innovative capabilities such as personalized medicine and automated financial systems. Concurrently, the analysis underscores urgent ethical dilemmas, encompassing algorithmic bias, accountability deficiencies, data privacy vulnerabilities, and workforce displacement. Employing real-world examples such as Deepfakes, and Neuralink, the article contextualizes emerging challenges within a dynamic socio-technical framework. The research offers a cohesive conceptual model that amalgamates technical, ethical, and governance aspects of AI, while presenting policy recommendations designed to promote transparency, equity, and human-centered AI development. The study emphasizes the necessity for reliable AI systems that humans can trust. The conclusions accentuate the immediate necessity for robust regulatory frameworks and sector-specific ethical supervision to ensure that advancements in AI are harmonized with the well-being of society.},
  archive      = {J_EAAI},
  author       = {Sunil Baloda and Monika Sharma and Mukesh Kumar},
  doi          = {10.1016/j.engappai.2025.112405},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112405},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Future of humanity in an artificial intelligence centric world},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel federated deep learning for intrusion detection in smart grid cyber-physical systems. <em>EAAI</em>, <em>162</em>, 112404. (<a href='https://doi.org/10.1016/j.engappai.2025.112404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fusion of sophisticated computational, communicative, and physical elements in Smart Grid Cyber-Physical Systems (SGCPS) has greatly improved the efficiency and reliability of power grids. However, this complexity introduces enhanced cybersecurity risks, evidenced by significant cyberattacks on the Ukrainian power grid during 2015 and 2016. Despite progress in Artificial Intelligence (AI)-driven security solutions for SGCPS, practical deployment of these technologies is often limited due to a lack of high-quality attack data and owners’ hesitance to distribute sensitive details. This paper introduces an innovative strategy to fortify SGCPS against diverse network threats via a comprehensive intrusion detection system. We present a deep learning model leveraging a temporal convolutional network with multi-feature integration, aimed at robust threat identification. We also propose a federated learning framework enabling various SGCPS to jointly develop an extensive intrusion detection model, ensuring data privacy. Moreover, we incorporate a gradient compression technique utilizing the Long Short Term Memory- β -Total Correlation Variational Autoencoder (LSTM- β -TCVAE) model to enhance and secure model parameters throughout the training phase. Thorough experimental validations confirm the efficacy of our method in recognizing multiple cyber threat types to SGCPS and its advantages over current methods.},
  archive      = {J_EAAI},
  author       = {Rong Xie and Bin Wang and Xin Xu},
  doi          = {10.1016/j.engappai.2025.112404},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112404},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel federated deep learning for intrusion detection in smart grid cyber-physical systems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tunnel-YOLO: An improved you only look once algorithm for real-time shield tunnel lining leakage detection. <em>EAAI</em>, <em>162</em>, 112403. (<a href='https://doi.org/10.1016/j.engappai.2025.112403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting crack leakages in shield tunnels is crucial for ensuring structural safety and extending service life, as traditional detection methods are limited by high subjectivity and low accuracy. To address these limitations, this paper proposes Tunnel-YOLO, an improved object detection algorithm based on You Only Look Once version 8 (YOLOv8). This algorithm replaces standard convolutional blocks with a novel Receptive Field Channel Attention Convolution (RFCAConv) module, which leverages dynamic receptive fields to enhance feature capture at different scales. We also introduce a C2f_SGE module, integrating the Spatial Group-wise Enhance (SGE) attention mechanism into the C2f (CSPNet with 2 convolutions) block to significantly improve feature extraction while suppressing background interference. Furthermore, an Edge Feature Enhancement Detection Head (EFE-Head) incorporates deconvolution layers to enhance fine-grained details for more precise boundary localization. To better accommodate the shape-sensitive detection task, our LeShape-IoU (Intersection over Union) loss function is designed to focus on the shape and scale characteristics of target bounding boxes. Experimental results on a public, real-world dataset demonstrate that Tunnel-YOLO significantly outperforms the baseline, increasing Recall, Precision, and mean Average Precision at 0.5 IoU (mAP50) by 15.7%, 10.3%, and 14.8%, respectively. Comparative analysis with other mainstream algorithms further validates the effectiveness and superiority of the proposed Tunnel-YOLO.},
  archive      = {J_EAAI},
  author       = {Ruijun Yang and Hao Zhang},
  doi          = {10.1016/j.engappai.2025.112403},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112403},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Tunnel-YOLO: An improved you only look once algorithm for real-time shield tunnel lining leakage detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of data-driven predictive model and enhanced multiobjective optimization to improve the excavation performance of large-diameter slurry shields. <em>EAAI</em>, <em>162</em>, 112402. (<a href='https://doi.org/10.1016/j.engappai.2025.112402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safety, efficiency and energy consumption are important aspects for evaluating the performance of large-diameter slurry shield, and improving the performance of shield is crucial for safe and efficient excavation. To this end, a data-driven hybrid method is developed to improve the excavation performance of large-diameter slurry shields by intelligence regulating shield parameters. This method combines Bayesian Optimization with categorical boosting (BO-CatBoost) and enhanced multiobjective evolutionary algorithm based on decomposition (EMOEA/D). The method uses surface settlement, penetration and specific energy as output targets and employs the expert knowledge to select the input parameters. Subsequently, the trained BO-CatBoost model is employed to fit the input-output relationship. On this basis, the multiobjective optimization process was performed using EMOEA/D, with the important parameters determined by Shapley Additive exPlanations as decision variables and the nonlinear relationship fitted by BO-CatBoost as the objective function. Finally, the technique for order preference similarity to ideal solution is applied to obtain optimal operational parameters, thereby enhancing the excavation performance of large-diameter slurry shield. The proposed method is applied to a Wuhan rail transit line to verify the effectiveness, and the result shows that: (1) Our method can accurately predict the three targets with goodness of fit ranging from 0.938 to 0.988, respectively. (2) The proposed method can effectively improve the excavation performance of the large-diameter slurry shield, and reaches 13.88 %, 5.21 %, and 10.88 %, respectively. (3) An adaptive decision-making system for setting operational parameters is constructed, which is valuable for formulating of operational control strategies for large-diameter slurry shields.},
  archive      = {J_EAAI},
  author       = {Feiming Su and Xianguo Wu and Tiejun Li and Yang Liu},
  doi          = {10.1016/j.engappai.2025.112402},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112402},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development of data-driven predictive model and enhanced multiobjective optimization to improve the excavation performance of large-diameter slurry shields},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive active adaptive partial label learning under class distribution mismatch. <em>EAAI</em>, <em>162</em>, 112401. (<a href='https://doi.org/10.1016/j.engappai.2025.112401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial label learning is an important learning framework where each training sample is associated with a candidate label set and its ground-truth label is included in the candidate label set. Active partial label learning is a variation where training data consists of both labeled and unlabeled samples. However, there exists the problem of class distribution mismatch, wherein the unlabeled sample set contains many instances out of the target categories. In this paper, a contrastive active adaptive partial label learning method under class distribution mismatch which combines active partial label learning with contrastive coding is proposed. A novel active sample selection strategy is first established to use label propagation ability to measure the optimization ability of unlabeled samples to partially labeled samples. Furthermore, to solve the problem of class distribution mismatch, a joint query score based on contrastive coding is utilized to reduce the queries of unlabeled samples out of target categories. Finally, the above two indicators are combined adaptively to select the most valuable unlabeled samples in target categories for manual labeling and the selected samples will be added to the training sample set to train the new classifier. The effectiveness and efficiency of the method are evaluated by performing experiments on the datasets CIFAR10 and CIFAR100.},
  archive      = {J_EAAI},
  author       = {Aohan Zhang and Kezhen Dong and Hongying Zhang},
  doi          = {10.1016/j.engappai.2025.112401},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112401},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Contrastive active adaptive partial label learning under class distribution mismatch},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A framework for photovoltaic power forecasting based on hybrid data reconstruction, neural network models fusion, and multi-objective optimization. <em>EAAI</em>, <em>162</em>, 112400. (<a href='https://doi.org/10.1016/j.engappai.2025.112400'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intermittency of photovoltaic power seriously affects the safety and operation of the power grid. Accurate photovoltaic power forecasting is critical for a safe connection of large-scale solar energy to the grid. Despite the efforts of many researchers, current forecasting methodologies remain inadequate. To bridge this gap, leveraging the recent advancements in artificial intelligence algorithms, this work combines cutting-edge deep learning techniques and data preprocessing strategies to develop a forecasting system that comprehensively considers various influencing factors and integrates multiple deep learning neural networks. The framework enables deterministic forecasting and uncertainty analysis, providing reliable supporting information for accurate forecasting through hybrid decomposition data preprocessing and feature selection modules. Then, closed-form continuous-time (Cfc) neural networks are introduced as one of the core forecasting components. Theoretically, the validity of the combined model and the Pareto optimization process are proved. Practically, the multi-objective African vultures optimization (MoAvo) is employed to identify the Pareto optimal solution, integrate four models, and improve the model's adaptability to external environmental changes. The experimental results show that the average mean absolute percentage error (MAPE) of the designed combined system for 1–3 steps forecasting on the Yulara are 6.09 %, 8.15 %, and 10.03 %, respectively. The results demonstrate that the framework fully considers the influence of candidate variables on forecasting, offering significant advantages over comparison models.},
  archive      = {J_EAAI},
  author       = {Menggang Kou and Jianzhou Wang and Jingrui Li and Runze Li and Zhiwu Li},
  doi          = {10.1016/j.engappai.2025.112400},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112400},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A framework for photovoltaic power forecasting based on hybrid data reconstruction, neural network models fusion, and multi-objective optimization},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A binary particle swarm optimization with dual encoding mechanism for feature selection. <em>EAAI</em>, <em>162</em>, 112397. (<a href='https://doi.org/10.1016/j.engappai.2025.112397'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a crucial machine learning preprocessing stage with numerous practical uses. Numerous algorithms are created to tackle the task. However, these algorithms still suffer from several challenges. This study introduces a novel binary particle swarm optimization with dual encoding mechanism, named DEBPSO, to solve feature selection problems. A new transfer function, called an inverse S-shaped function, and a Boolean encoding mechanism are employed to enhance the exploration performance of DEBPSO. In addition, to better balance exploration and exploitation, a new game mechanism is proposed to find the best solution. In order to verify the performance of DEBPSO, a comprehensive experimental is designed. The experimental results on 27 well-known datasets show that DEBPSO significantly outperforms the compared algorithms on 17, 14, 13, 17, 16, 21, 14, 23, 20 datasets in terms of classification error rate, highlighting its efficiency in reducing the classification error rate and irrelevant features.},
  archive      = {J_EAAI},
  author       = {Chong Zhou and Rumeng Liang and Qi Liu and Sirui Niu},
  doi          = {10.1016/j.engappai.2025.112397},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112397},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A binary particle swarm optimization with dual encoding mechanism for feature selection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel weight-optimized machine-learning hybrid model for daily river runoff prediction. <em>EAAI</em>, <em>162</em>, 112396. (<a href='https://doi.org/10.1016/j.engappai.2025.112396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The daily runoff process has been characterized as nonlinear and unsteady due to the impacts of watershed precipitation and evaporation, vegetation coverage rate, reservoir operations and other human activities. In recent years, machine-learning (ML) models have been widely applied in the daily runoff predictions, but the robustness and effectiveness of individual ML model is always limited. A novel weight optimization scheme has been introduced to ML models to obtain accurate predictions of daily river runoff. Variational modal decomposition method is adopted in the dataset preprocessing, and the runoff prediction performance of various classic ML models, including Genetic Algorithm-Back Propagation neural network (GA-BP), Long Short-Term Memory network (LSTM), Elman neural network (Elman) and Genetic Algorithm-Support Vector Machine (GA-SVM) are subsequently evaluated. A particle swarm optimization (PSO) based weight optimization strategy is proposed to combine different types of ML models, thus more accurate and robust results could be obtained. The ten-fold cross-validation method has been adopted and the performance of the optimized hybrid models are further evaluated for different schemes. A case study at Hankou hydrological station demonstrates that root mean square error (RMSE) and mean absolute percentage error (MAPE) is improved by 35.7 %, 75.8 % respectively for the optimized hybrid model. The present study shares useful insights to the comprehensive optimization of various ML models in the intelligent management of water resources.},
  archive      = {J_EAAI},
  author       = {Zhonglian Jiang and Jianglong Ying and Zhen Yu and Xiao Chu and Chengqiang Yu},
  doi          = {10.1016/j.engappai.2025.112396},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112396},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel weight-optimized machine-learning hybrid model for daily river runoff prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent assessment of habitat quality based on multiple machine learning fusion methods. <em>EAAI</em>, <em>162</em>, 112395. (<a href='https://doi.org/10.1016/j.engappai.2025.112395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating habitat quality can help balance the relationship between economic development and biodiversity conservation, and it serves as a foundation for constructing an ecological security pattern. However, research on the intelligent construction of habitat quality is limited. This study develops a comprehensive framework to assess habitat quality based on optimized machine learning methods. The findings of the research are as follows: (1) From the perspective of human-machine interactive interpretation, ensemble learning is used to enhance the performance of basic classifiers, resulting in a classification map with high precision and recall. (2) The particle swarm optimization (PSO) algorithm can improve the goodness of fit of the Extreme Gradient Boosting (XGBoost) inversion model by 4–5 %. (3) The habitat quality inversion method based on XGBoost-PSO has high credibility and application value, with its texture structure being the result of both expert experience and image information interaction. (4) The model demonstrates certain application potential in downscaling; under the seven-band perspective, the blue and near-infrared bands are the most important, while in the four-band perspective, green and near-infrared bands take precedence.},
  archive      = {J_EAAI},
  author       = {Kui Yang and Dongge Cui and Chengrui Wang and Qi Tang and Linguang Miao},
  doi          = {10.1016/j.engappai.2025.112395},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112395},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent assessment of habitat quality based on multiple machine learning fusion methods},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical semantics guided multi-scale correlation network for alignment-free red-green-blue and thermal salient object detection. <em>EAAI</em>, <em>162</em>, 112394. (<a href='https://doi.org/10.1016/j.engappai.2025.112394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGBT (red-green-blue and thermal) salient object detection (SOD) aims to identify and highlight the most visually salient objects in an image by leveraging the complementary information from both RGB and thermal (TIR) modalities. It is particularly effective for 24/7 intelligent surveillance and autonomous perception in smart city security and traffic monitoring, especially under low light and adverse weather. However, existing methods primarily rely on manually aligned datasets, which are limited in handling the challenges posed by unaligned multi-modal data in real-world applications. Furthermore, these methods usually extract complementary information from both modalities using fixed-size windows (Liuet al., 2022, Wanget al., 2024b). However, such fixed-size windows are not effective in dealing with unaligned multi-modal images due to spatial inconsistencies. Additionally, existing methods often use single-layer high-level feature to represent semantic information, which fails to fully exploit the complementary benefits of multi-level features, thereby reducing the effectiveness of semantic guidance. To address these challenges, we propose a Hierarchical Semantics guided Multi-scale correlation Network (HSMNet) for alignment-free RGBT SOD. A Hierarchical Semantic Fusion Module (HSFM) dynamically assigns weights to features from multiple levels, enabling adaptive fusion of multi-level semantic information. A Multi-scale Asymmetric Correlation Module (MACM) employs windows of various sizes to capture asymmetric correlations between unaligned multi-modal data, enhancing cross-modal complementary information extraction even when data are not perfectly aligned. We conduct extensive experiments on unaligned, weakly aligned and aligned RGBT SOD datasets, with results demonstrating that our method outperforms state-of-the-art algorithms, achieving superior accuracy and robustness in both unaligned and weakly aligned RGBT SOD scenarios.},
  archive      = {J_EAAI},
  author       = {Chengmei Han and Lei Liu and Kunpeng Wang and Fei Xie and Bing Wei},
  doi          = {10.1016/j.engappai.2025.112394},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112394},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical semantics guided multi-scale correlation network for alignment-free red-green-blue and thermal salient object detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear dynamic modeling of turbojet engines using combined convolutional and long short-term memory networks. <em>EAAI</em>, <em>162</em>, 112393. (<a href='https://doi.org/10.1016/j.engappai.2025.112393'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Turbojet engines are widely used in small-scale aerial vehicles, but their nonlinear and time-varying dynamics present significant challenges for accurate modeling and control. Traditional system identification methods often struggle to capture these complex behaviors, particularly under limited data conditions. This study proposes a novel hybrid neural network architecture that combines convolutional neural networks and long short-term memory units. The model is specifically designed for small-sample scenarios, enabling robust learning and precise engine speed prediction from real input-output sequences. The input vector comprises the current engine speed, the next-step pulse-width modulation command, and its increment, enhancing the model’s responsiveness and reducing phase-lag effects. The proposed model is trained and evaluated on a real-world dataset containing 38,257 samples, with 80 % used for training and 20 % for testing. Its predictive performance is assessed using step input responses and three evaluation metrics: mean absolute error, root mean square error, and Pearson correlation coefficient. Experimental results demonstrate that the proposed hybrid architecture outperforms other recurrent models in capturing transient dynamics and accurately reproducing real engine behavior. These findings highlight the model’s effectiveness in modeling nonlinear engine dynamics and its potential as a data-efficient alternative to traditional identification techniques for small-scale turbojet applications.},
  archive      = {J_EAAI},
  author       = {Chen Lei and Dong Wei and Su Hang and Chi Yutian and Tian Congling and Gao Yongzhuo and Wu Dongmei and Dong Hui},
  doi          = {10.1016/j.engappai.2025.112393},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112393},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Nonlinear dynamic modeling of turbojet engines using combined convolutional and long short-term memory networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scientific machine learning for generic compact model parameter extraction of nanoscale transistors. <em>EAAI</em>, <em>162</em>, 112392. (<a href='https://doi.org/10.1016/j.engappai.2025.112392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a framework to automate modelcard extraction of industry-standard compact models. This framework presents a Scientific Machine Learning (ScML) approach capable of inverse modeling. It integrates a random forest model with an artificial neural network to produce efficient and precise regression results. This new method is used for parameter extraction in the standard compact models of the semiconductor device industry. Modeling of a multi-gate Field Effective Transistor (FET) with an industry-standard compact model like Berkeley Short-channel Insulated-Gate Field-Effect Transistor Model – Common Multi-Gate (BSIM-CMG) is taken as an example to illustrate and describe the framework and highlight its key advantages. Proposed framework is useful in numerous aspects; it holds vital principles of physics, avoids depending on massive datasets, and has a sparse architecture while avoiding accuracy trade-offs. The framework is tested on production-level experimental devices to evaluate the real-world performance. This framework significantly reduces the time and cost of parameter extraction for the Process Design Kits (PDKs) development. Therefore, this is of immediate importance for fabrication and Electronic Design Automation (EDA) industries.},
  archive      = {J_EAAI},
  author       = {Kumar Sheelvardhan and Surila Guglani and Abhilash Dubey and Shashank Dubey and Sindhu Ramaswamy and Vaidy Subramanian and Kassandra Anderson and Glenn Workman and Sourajeet Roy and Avirup Dasgupta},
  doi          = {10.1016/j.engappai.2025.112392},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112392},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Scientific machine learning for generic compact model parameter extraction of nanoscale transistors},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed graph neural network for 3D spatiotemporal structural response modeling of flexible pavements. <em>EAAI</em>, <em>162</em>, 112391. (<a href='https://doi.org/10.1016/j.engappai.2025.112391'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantifying pavement damage is crucial for roadway agencies' maintenance planning. This study proposed a Physics-informed Graph Neural Network-based Pavement Simulator (PhyGPS) to predict three-dimensional (3D) asphalt concrete pavement responses, building upon an established data-driven Graph Neural Network-based Pavement Simulator (GPS) model. The key innovation lies in integrating knowledge graphs and mechanics equations to create a physics loss function, distinguishing it from its data-driven counterpart. The physics loss function comprises strain-displacement and stress loss components derived from 3D strain-displacement relations and stress equilibrium principles. A thorough 3D finite element (FE) pavement database supported the model development. The 3D FE pavement data was transformed into graph format where nodes and edges represent 3D FE pavement models’ nodes and node connections, respectively. Performance evaluation employed two case studies: “OneStep” for assessing short-term predictive capabilities and “Rollout” for examining long-term prediction accuracy under practical conditions. Results demonstrated that the physics-informed GPS model showed superior long-term predictive capability and robustness while maintaining excellent short-term accuracy compared to the data-driven model. Both models achieve rollout time under 8 s per FE simulation case, a dramatic improvement over the 12-h runtime of traditional 3D FE pavement models. The PhyGPS model successfully integrates physics principles, spatial relationships between structural components, temporal correlations in structural data, and complex material properties, offering an accurate, robust, and computationally efficient solution for predicting 3D pavement responses.},
  archive      = {J_EAAI},
  author       = {Fangyu Liu and Imad L. Al-Qadi},
  doi          = {10.1016/j.engappai.2025.112391},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112391},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed graph neural network for 3D spatiotemporal structural response modeling of flexible pavements},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Health state estimation of retired batteries based on physical constraints. <em>EAAI</em>, <em>162</em>, 112390. (<a href='https://doi.org/10.1016/j.engappai.2025.112390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing use of retired lithium-ion batteries, accurately monitoring their health status has become increasingly important. This study proposed a method to estimate the health of retired batteries by embedding their capacity degradation characteristics directly into the loss function of a Bidirectional Long Short-Term Memory (BiLSTM) network, combined with a Physically Informed Neural Network (PINN) model. The model is developed by incorporating the dynamics of the solid electrolyte interface (SEI) membrane, which evolves as the lithium-ion poles of the retired battery move. By combining these dynamics with the governing equations of motion, a partial differential equation (PDE) is derived. This approach integrates physical constraints, data-driven learning, and PDEs into a composite loss function. The proposed method is validated on two different datasets under varying operating temperatures. The results show that the PINN-BiLSTM model achieves a Root Mean Square Percentage Error (RMSPE) of 0.024, representing a 9.67 % improvement over the PINN-LSTM. This adaptive PINN method offers highly accurate health state predictions across temperature variations, thus supporting the sustainable use of retired batteries in secondary applications and helping to mitigate energy scarcity.},
  archive      = {J_EAAI},
  author       = {Fei Xia and Qianwen Dong and Lin Xia and Zhenyi An and Ziyang Xia and Chunyang Gong},
  doi          = {10.1016/j.engappai.2025.112390},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112390},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Health state estimation of retired batteries based on physical constraints},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive cybersecurity in bio-medical modules: A dynamic programming neural network-based protection for markov-chain fabricated data attacks. <em>EAAI</em>, <em>162</em>, 112389. (<a href='https://doi.org/10.1016/j.engappai.2025.112389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advances in communication technologies, remote monitoring and control of drug delivery are becoming prevalent in bio-medical engineering. In a chemotherapy system, the measurement signals can be wirelessly transferred to the control center by communication networks. Nevertheless, the avenues of communication might be jeopardized by false data injection (FDI), which poses significant risks to the security and stability of biomedical systems. In this work, a defense mechanism is developed to tackle the effect of FDI threats in the networked chemotherapy system. In particular, the effect of FDI attacks on the chemotherapy system is modeled by the Markov chain process. The proposed defense mechanism is designed in two parts: i ) a data-driven sliding mode observer (DDSMO) is utilized to identify the occurrence of cyber attacks in the tumor signals measured by the bio-sensor, and ii ) a mitigation scheme based on a dynamic rejection compensator (DRC) to compensate for the impact of cyber threats. In the mitigation phase, a goal representation heuristic dynamic programming (GrHDP) is adopted to adaptively adjust the parameters of DRC and to dynamically handle the cyber threats. The designed mitigation mechanism not only regulates the cancerous cells against cyber threats but also minimizes the side effects of drug delivery by regulating the output of normal cell and immune cell. Compared to prevalent methodologies, the proposed approach yields significant performance, including a 60.23 % improvement over the without protection, 37.48 % over the DDSMO-based model predictive controller (MPC), 35.95 % over the reinforcement learning (RL) based Kalman filter, and 70.44 % over the proportional integral (PI) based Kalman filter.},
  archive      = {J_EAAI},
  author       = {Mostafa Taheri and Juliang Yin and Zahra Rasooli Berardehi},
  doi          = {10.1016/j.engappai.2025.112389},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112389},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive cybersecurity in bio-medical modules: A dynamic programming neural network-based protection for markov-chain fabricated data attacks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted multi-source domain unsupervised adaptive network for rotating machinery fault diagnosis based on dual adversarial. <em>EAAI</em>, <em>162</em>, 112386. (<a href='https://doi.org/10.1016/j.engappai.2025.112386'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-domain adaptive methods are becoming a growing focus of fault diagnosis, which can provide enhanced data support for models using the feature information from various source domains. As a most commonly used method, unsupervised multi-domain adaptive methods (UMA) can eliminate the requirement for the label of the target domain samples. However, the neglect of contributions from different source domains to the target domain and insufficient utilization of diagnostic information from multiple source domains are the widely limitation of UMA. Therefore, a dual-adversarial weighted multi-source domain unsupervised adaptive network (DAWMUN) is proposed to utilize diagnostic information from multi-source domains and consider the contribution of different source domains. Firstly, the shared feature extractor and dual adversarial training with the domain adversarial modules between multi-source domains and source-target domains are used to enhance domain confusion between multi-source and target domains (MSTD). Secondly, based on Multiple Kernel Maximum Mean Discrepancy (MK-MMD), a novel weighting mechanism and the corresponding training framework are constructed to effectively reduce negative transfer. Finally, a novel weighted classifier is proposed to merge the outputs of multiple classifiers and synthesize the impact of each source domain. The performance of the DAWMUN is validated using a rotating machinery dataset across various transfer tasks under different rotational speed and load conditions. The experimental results demonstrate that the diagnostic accuracy using the proposed DAWMUN is superior to existing SSDA and MSDA methods, with the average accuracies of 98.53 % and 98.23 % across six tasks in two separate experimental setups. The comparison to the existing methods results that the DAWMUN still demonstrates superior performance with improvements of 2.54 % and 2.86 %, respectively.},
  archive      = {J_EAAI},
  author       = {Wenqi Wang and Zongzhen Zhang and Jinrui Wang and Baokun Han and Huaiqian Bao and Zhikang Fan and Rongkang Ge},
  doi          = {10.1016/j.engappai.2025.112386},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112386},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Weighted multi-source domain unsupervised adaptive network for rotating machinery fault diagnosis based on dual adversarial},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Twin-stream network: Enhancing wave prediction by capturing spatiotemporal information. <em>EAAI</em>, <em>162</em>, 112385. (<a href='https://doi.org/10.1016/j.engappai.2025.112385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wave prediction is a critical challenge in ocean and coastal engineering, particularly for understanding and mitigating the effects of sea waves on structures such as ships, offshore platforms, and coastal defenses. A novel machine learning model, Twin-Stream Network (TSNet), is proposed to enhance wave prediction accuracy by leveraging temporal and spatial dependencies in historical data. The TSNet model along with other baseline models are evaluated, in both single-point and multi-point forecasting tasks, by various performance metrics across different datasets including one-dimensional-linear, one-dimensional-nonlinear, two-dimensional-linear and two-dimensional-nonlinear water waves. The comprehensive comparative analysis demonstrates that the TSNet model outperforms others, especially in the multi-point forecasting task. This study provides a valuable insight into the effectiveness of machine learning approaches and highlights the potential of the accuracy improvement for wave prediction.},
  archive      = {J_EAAI},
  author       = {Junhao Xu and Zhongying Feng and Zhan Wang and Kun Zheng and Ruipeng Li},
  doi          = {10.1016/j.engappai.2025.112385},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112385},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Twin-stream network: Enhancing wave prediction by capturing spatiotemporal information},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clean-sample guided cross-modal retrieval with adaptive weighted contrastive learning. <em>EAAI</em>, <em>162</em>, 112383. (<a href='https://doi.org/10.1016/j.engappai.2025.112383'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal retrieval enables efficient integration of information by linking different data modalities, such as images and text. As data volumes increase rapidly, the need for effective cross-modal interaction grows. Cross-modal hashing is favored for its low storage requirements and fast retrieval speed, but many existing methods depend on accurately labeled data, which can be subjective and expensive to obtain. To address this limitation, we propose Clean-guided Adaptive Weighted Contrastive Hashing (CAWCH), a novel framework designed to improve robustness against noisy labels. CAWCH incorporates two main components: a Gaussian Mixture Model (GMM)-based noise purifier that identifies reliable and noisy samples by modeling sample loss, and a contrastive learning strategy that selectively chooses positive samples and adaptively assigns weights based on multi-label similarity, considering both intra- and inter-modal relationships. Extensive experiments demonstrate that CAWCH significantly outperforms existing methods under noisy label conditions, highlighting its effectiveness and potential for real-world cross-modal retrieval applications.},
  archive      = {J_EAAI},
  author       = {Shuni Jiang and Zhixin Li},
  doi          = {10.1016/j.engappai.2025.112383},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112383},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Clean-sample guided cross-modal retrieval with adaptive weighted contrastive learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Denoising of the magnetic flux leakage signal using dynamic feature fusion and a multi-scale autoencoder network. <em>EAAI</em>, <em>162</em>, 112382. (<a href='https://doi.org/10.1016/j.engappai.2025.112382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic flux leakage (MFL) signal denoising is essential for the nondestructive inspection of oil and gas pipelines, where complex noise interference can severely degrade defect quantification accuracy. Traditional approaches such as mean filtering and wavelet transform offer limited suppression of multi-type mixed noise and often distort critical features, including defect peaks and valleys. Even deep learning–based MFL denoising methods struggle in scenarios with substantial signal-noise overlap due to inadequate feature extraction and limited adaptability.This work presents an advanced denoising framework that combines dynamic feature fusion with a multi-scale autoencoder network. The framework jointly exploits time- and frequency-domain signal components, employing an adaptive weighting mechanism for dynamic feature fusion. Parallel convolutional branches extract multi-scale features, improving the capture of both global structures and fine-grained details, while a Squeeze-and-Excitation (SE) channel attention mechanism enhances defect-sensitive features and suppresses noise. Extensive experiments demonstrate that the proposed model outperforms mean filtering, wavelet denoising, and a baseline autoencoder, achieving notable gains in signal-to-noise ratio (SNR), mean squared error (MSE), and signal similarity. Beyond superior noise suppression, the method preserves critical defect characteristics, providing a robust and reliable foundation for precise defect quantification in pipeline MFL inspection.},
  archive      = {J_EAAI},
  author       = {Lushuai Xu and Shaohua Dong and Haotian Wei and Feng Li and Pengkun Zhang and Cong Zuo and Mingxing Guo and Penghui Liao},
  doi          = {10.1016/j.engappai.2025.112382},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112382},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Denoising of the magnetic flux leakage signal using dynamic feature fusion and a multi-scale autoencoder network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optimisation approach guided by crack variation mechanism in the informer prediction model. <em>EAAI</em>, <em>162</em>, 112381. (<a href='https://doi.org/10.1016/j.engappai.2025.112381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural health monitoring (SHM) faces a fundamental challenge in reconciling predictive performance with physical interpretability for infrastructure diagnostics. Conventional deep learning (DL) approaches neglect essential mechanisms governing crack width variation—including thermal gradients, hysteretic responses, and phase-shifted correlations—limiting their reliability in real-world applications. To bridge this gap, we propose a mechanism-guided optimization (MGO) framework that integrates domain knowledge into the Informer architecture through physics-informed enhancements: auto-correlation modeling for capturing temperature-crack hysteresis, static gated fusion for multi-feature integration, and adaptive elastic net regularization for feature selection. Validated on cable-stayed bridge monitoring data, our framework achieves significant mean absolute error reductions (MAE) (5 %–60 %) and root mean square error reductions (RMSE) (10 %–55 %) versus baseline Informer across all cracks and prediction horizons, with diebold-mariano (DM) tests confirming statistical superiority in most cases. Crucially, it demonstrates superior precision relative to six state-of-the-art benchmarks across all evaluation scenarios. The ordinary least squares (OLS)-enhanced variant further delivers volatility reduction, while sensor failure tests establish quantifiable robustness benchmarks through MAE progression from 0.013 mm to 0.391 mm. This work establishes an interpretable, physics-grounded paradigm that explicitly links environmental drivers to structural degradation.},
  archive      = {J_EAAI},
  author       = {Xujia Liu and Youliang Ding and Fei Xu and Yichao Xu and Kang Yang},
  doi          = {10.1016/j.engappai.2025.112381},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112381},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An optimisation approach guided by crack variation mechanism in the informer prediction model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight segmentation model based on segment anything model for tongue image segmentation. <em>EAAI</em>, <em>162</em>, 112379. (<a href='https://doi.org/10.1016/j.engappai.2025.112379'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tongue image segmentation plays a crucial role in intelligent of diagnosis of Traditional Chinese Medicine. Accurate, efficient, and lightweight tongue segmentation significantly improves both the quality and practical applicability of intelligent disease diagnosis models. To address this challenge, we propose TongueSAM_Lite, a lightweight and fully automated tongue image segmentation model. Based on the Segment Anything Model. Our approach employs knowledge distillation and parameter-efficient fine-tuning to develop a novel lightweight image encoder, high-parameter modules in the Vision Transformer are partially replaced with lightweight image modules, which facilitate the transfer of its feature extraction capabilities while accelerating inference speed and reducing computational resource requirements. Additionally, to eliminate manual annotation of tongue region bounding boxes, we integrate a YOLOX-based automatic Box-prompt generator, enabling end-to-end fully automated prompting and segmentation of tongue images. To validate our approach, various experiments were conducted in three datasets. The results show that compared to the original large-scale model of the Segment Anything Model, TongueSAM_Lite reduces the size of the model by 42.7% and shortens the inference time to 45.43% while retaining the near-complete segmentation accuracy of few-shot learning. TongueSAM_Lite achieves Mean Intersection over Union scores of 96.48%, 98.36%, and 97.53% in the three datasets, respectively, outperforming state-of-the-art segmentation methods. Further validation confirms that the YOLOX-based prompt encoder yields optimal performance for the generation of tongue image bounding boxes. Our proposed approach provides new research insights to advance tongue diagnosis technology of Traditional Chinese Medicine. All codes in this article are available at https://github.com/ruanqunsheng/TongueSAM_Lite .},
  archive      = {J_EAAI},
  author       = {Qunsheng Ruan and Shan Cao and Zhirong Luo},
  doi          = {10.1016/j.engappai.2025.112379},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112379},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight segmentation model based on segment anything model for tongue image segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring cross-branch information for semi-supervised remote sensing object detection. <em>EAAI</em>, <em>162</em>, 112378. (<a href='https://doi.org/10.1016/j.engappai.2025.112378'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised object detection (SSOD) provides a promising solution to mitigate the annotation costs in remote sensing applications. Mainstream teacher-student based SSOD methods leverage unlabeled images through pseudo labeling, and their effectiveness is fundamentally limited by the inevitable noise in pseudo labels, particularly for remote sensing (RS) scenarios with complex backgrounds and dense, multi-scale and oriented objects. Current methods primarily focus on reducing pseudo label noise through category, scale and Intersection over Union information mining, as well as designing fine-grained confidence thresholding strategies. However, the inherent discrepancy between classification and localization reliability is neglected. In this study, with analyzing the characteristic discrepancies between the classification and localization branches, We propose artificial intelligence (AI) methodological innovation method named cross-branch information incorporation method (i.e., CBI-SSOD) to utilize these discrepancies to assist the training of the classification branch, and thus improve the performance of SSOD methods. Specifically, our method present two key AI innovations. Firstly, we propose a pretext task to extract cross-branch information, which can improve the classification ability by reinforce the consistent predictions between the classification branch and the pretext task. Besides, we propose a pseudo label reassignment approach to adjust the soft classification pseudo labels, and thus suppress pseudo label noise and improve the detection performance. Extensive experiments on Dataset for Object Detection in Aerial Images (DOTAv1.0) and DOTAv1.5 datasets validate the effectiveness and superiority of our method, and demonstrate the practical engineering impact of our method on RS applications and interpretation systems.},
  archive      = {J_EAAI},
  author       = {Shitian He and Huanxin Zou and Yingqian Wang and Xu Cao and Hao Chen and Ning Jing},
  doi          = {10.1016/j.engappai.2025.112378},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112378},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Exploring cross-branch information for semi-supervised remote sensing object detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightning risk assessment of offshore wind farms considering tropical cyclone impacts based on an improved gradient boosting algorithm. <em>EAAI</em>, <em>162</em>, 112376. (<a href='https://doi.org/10.1016/j.engappai.2025.112376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, global climate warming has led to a significant increase in both the frequency and intensity of tropical cyclones (TCs). The development of TCs is often accompanied by frequent lightning activities. The risk of lightning strikes to high offshore wind turbines is substantially elevated. This study evaluates the lightning risk faced by offshore wind farms influenced by tropical cyclones. Firstly, TC paths are analyzed in both spatial and temporal dimensions by linking them with lightning data to examine the distribution of TC-related lightning, and the lightning strike characteristics of offshore wind turbines are investigated. Secondly, a Bayesian Optimization (BO)-based eXtreme Gradient Boosting (XGBoost) model for lightning risk assessment is proposed, incorporating characteristics of TC lightning and offshore wind farms as input variables. The proposed BO-XGBoost model outperforms XGBoost, Bidirectional Long Short-Term Memory (Bi-LSTM), Support Vector Machine (SVM) and Neural Network (NN), achieving a precision of 98.9 % and a recall of 98.9 % on the test set. Additionally, SHapley Additive exPlanations (SHAP) value analysis indicates that TC lightning characteristics and offshore wind farm characteristics significantly impact the model output, enhancing the accuracy of the model. The assessment outcomes provide a theoretical basis for future offshore wind farm planning and guidance for lightning protection measures in offshore wind farms.},
  archive      = {J_EAAI},
  author       = {Qibin Zhou and Kehan Chen and Xiaoyan Bian and Shangjie Chen and Gaopeng Lu},
  doi          = {10.1016/j.engappai.2025.112376},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112376},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightning risk assessment of offshore wind farms considering tropical cyclone impacts based on an improved gradient boosting algorithm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond trial-and-error: Predicting user abandonment after a moderation intervention. <em>EAAI</em>, <em>162</em>, 112375. (<a href='https://doi.org/10.1016/j.engappai.2025.112375'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current content moderation follows a reactive, trial-and-error approach, where interventions are applied and their effects are only measured post-hoc. In contrast, we introduce a proactive, predictive approach that enables moderators to anticipate the impact of their actions before implementation. We propose and tackle the new task of predicting user abandonment following a moderation intervention. We study the reactions of 16,540 users to a massive ban of online communities on Reddit, training a set of binary classifiers to identify those users who would abandon the platform after the intervention—a problem of great practical relevance. We leverage a dataset of 13.8 million posts to compute a large and diverse set of 142 features, which convey information about the activity, toxicity, relations, and writing style of the users. We obtain promising results, with the best-performing model achieving micro F1-score = 0 . 914 . Our model shows robust generalizability when applied to users from previously unseen communities. Furthermore, we identify activity features as the most informative predictors, followed by relational and toxicity features, while writing style features exhibit limited utility. Theoretically, our results demonstrate the feasibility of adopting a predictive machine learning approach to estimate the effects of moderation interventions. Practically, this work marks a fundamental shift from reactive to predictive moderation, equipping platform administrators with intelligent tools to strategically plan interventions, minimize unintended consequences, and optimize user engagement.},
  archive      = {J_EAAI},
  author       = {Benedetta Tessa and Lorenzo Cima and Amaury Trujillo and Marco Avvenuti and Stefano Cresci},
  doi          = {10.1016/j.engappai.2025.112375},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112375},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Beyond trial-and-error: Predicting user abandonment after a moderation intervention},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A sampling interval-adaptive transformer for industrial time sequence modeling with heterogeneou s sampling rates in quality prediction. <em>EAAI</em>, <em>162</em>, 112374. (<a href='https://doi.org/10.1016/j.engappai.2025.112374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The industrial data sequences frequently exhibit irregular sampling frequencies, which pose a number of difficulties for data analysis and modeling. The traditional dynamic models like Recurrent Neural Network (RNN) and Transformer are difficult to model such data sequences. The main reason is that these models assume that data sampling frequency should be constant. To this end, a Sampling Interval-Adaptive Transformer (SIA-Trans) is proposed in this paper to adaptively model the temporal information for heterogeneous sampling sequences in industrial processes. The SIA-Trans uses the sampling interval and position embedding block to address the problem of unequal time intervals and rectify the temporal correlations in time series. Then, the interval-aware self-attention net is designed for dynamic data relationship modeling, taking the processed data through the self-attention mechanism. Finally, the predicted output is obtained after the point-wise feed-forward layer. The proposed SIA-Trans is validated on a real-world hydrocracking process to predict the content of hydrocarbon mixture with five carbon atoms (C5) hydrocarbons in light naphtha, as well as the final boiling point of jet fuel.},
  archive      = {J_EAAI},
  author       = {Zijian Xu and Nuo Xu and Kai Wang and Xiaofeng Yuan and Yalin Wang and Chunhua Yang and Weihua Gui and Shuqiao Cheng and Lingjian Ye},
  doi          = {10.1016/j.engappai.2025.112374},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112374},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A sampling interval-adaptive transformer for industrial time sequence modeling with heterogeneou s sampling rates in quality prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modality complementary learning network with cross-modality interaction and adaptive fusion for face forgery detection. <em>EAAI</em>, <em>162</em>, 112373. (<a href='https://doi.org/10.1016/j.engappai.2025.112373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of face forgery technology, many forged faces threaten information security. Although existing face forgery detection methods obtain better detection performance on intra-dataset evaluation, the generalization of cross-dataset detection and the robustness against image post-processing operations still need to be improved. To address these issues, we propose a multi-modality complementary learning network with cross-modality interaction and adaptive fusion for face forgery detection. Specifically, a two-branch architecture is designed to extract spatial and frequency features. To realize the interaction and communication of spatial and frequency information, the cross-modality interaction module is designed to explore the inter-modality correlation by applying across self-attention. Subsequently, a multi-scale feature enhancement module is introduced in the spatial branch to enhance the texture and semantic information of spatial features, improving the robustness of tackling image post-processing operations. In addition, to exploit the complementary relationship between the spatial and frequency features, an adaptive fusion module is designed to establish forged feature dependencies by leveraging spatial self-attention, while learning discriminative feature representations by fusing spatial and frequency features in an adaptive weighted manner. Extensive experimental results on four public datasets demonstrate that the proposed method outperforms other state-of-the-art methods for intra-dataset, cross-dataset, and perturbed dataset evaluations.},
  archive      = {J_EAAI},
  author       = {Chunyin Shi and Chengyou Wang and Xiao Zhou and Zhiliang Qin},
  doi          = {10.1016/j.engappai.2025.112373},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112373},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-modality complementary learning network with cross-modality interaction and adaptive fusion for face forgery detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive neural network tracking control for unknown high-order nonlinear systems: A constructive approximation set based approach. <em>EAAI</em>, <em>162</em>, 112371. (<a href='https://doi.org/10.1016/j.engappai.2025.112371'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the problem of adaptive neural network (NN) tracking control for unknown high-order nonlinear systems, with a focus on accurately constructing NN approximation sets. To guarantee the local approximation capabilities of NNs, it is crucial that their input signals remain within corresponding compact sets. However, the unknown functions and powers in high-order nonlinear systems make it difficult to determine these sets accurately. To solve this, we introduce a novel adaptive NN tracking control strategy that integrates signal substitution technique, barrier functions (BFs), and NNs. Specifically, the signal substitution technique converts the original system states into state error variables, along with the desired reference signal and its time derivatives, which serve as part of the NN input. BFs are employed to constrain the state errors, while NNs approximate the transformed unknown system functions. This approach enables precise calculation of bounds for the NN weight estimators, ensuring that the NN approximation sets are constructed. Unlike existing methods, our approach not only proves the existence of NN approximation sets but also provides a constructive design strategy, significantly enhancing the approximation accuracy for unknown nonlinear functions. Simulation results demonstrate the effectiveness and advantages of the proposed method.},
  archive      = {J_EAAI},
  author       = {Yu-Fa Liu and Yong-Hua Liu and Jin-Wa Wu and Jie Tao and Ming Lin and Chun-Yi Su and Renquan Lu},
  doi          = {10.1016/j.engappai.2025.112371},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112371},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive neural network tracking control for unknown high-order nonlinear systems: A constructive approximation set based approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic correlation graph convolution network with embedded temporal correlation extraction for stock price forecasting. <em>EAAI</em>, <em>162</em>, 112370. (<a href='https://doi.org/10.1016/j.engappai.2025.112370'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock price forecasting has become a significant and complex research area within financial technology. The dynamic correlations among stocks and the inherent noise in price volatility present considerable challenges in accurately forecasting stock prices and enhancing investment returns. This paper introduces a novel Dynamic Correlation Graph Convolution Network (DyCGCN) with embedded temporal correlation extraction. First, we propose a dual-scale dynamic graph generation method to capture the topological relationships among stocks. Second, we develop a dynamic correlation-temporal convolution module that extracts high-level temporal correlations. Third, we introduce a prospect theory-guided multi-strategy loss function that accommodates the diverse risk preferences of investors. Furthermore, we present a joint regression-classification learning method to extract and leverage stock trend information. Experiments conducted on four real-world datasets demonstrate the superiority of DyCGCN, achieving an average 24.7% reduction in prediction error and a 10.5% improvement in predictive accuracy over baseline models, underscoring its strong potential for practical stock price forecasting.},
  archive      = {J_EAAI},
  author       = {Fang He and Wei Yin and Yilun Jin and Zhengyang Chen},
  doi          = {10.1016/j.engappai.2025.112370},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112370},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic correlation graph convolution network with embedded temporal correlation extraction for stock price forecasting},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective deployment optimization for integrated sensing and communication-enabled unmanned aerial vehicle swarm. <em>EAAI</em>, <em>162</em>, 112368. (<a href='https://doi.org/10.1016/j.engappai.2025.112368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the convergence of mobile communication, sensing, and computational networks in sixth-generation technology, the integration of sensing and communication with unmanned aerial vehicles (UAVs) is promising. This paper focuses on the contribution of artificial intelligence in optimizing the deployment of UAV swarms for multi-objective target detection applications in sixth-generation networks. Specifically, the artificial intelligence contribution lies in the development of an improved multi-objective particle swarm optimization (IMOPSO) algorithm for solving a complex multi-objective deployment problem. The problem aims to simultaneously optimize communication rate, sensing quality, and energy consumption in the deployment of UAV swarms. To address this, the proposed IMOPSO incorporates chaotic initialization, Lévy flight mutation, dynamic mutation rate, and an elimination mechanism based on opposition-based learning. These innovations are designed to enhance the algorithm’s ability to explore the solution space effectively, overcome premature convergence to local solutions, and improve solution quality. In terms of engineering applications, the IMOPSO is applied to the deployment of UAV swarms for target detection, demonstrating its ability to enhance communication and sensing performance while reducing energy consumption in practical scenarios. Through extensive simulations, we show that the IMOPSO outperforms traditional optimization methods and other baseline algorithms, achieving superior results across all optimization objectives. Specifically, the IMOPSO achieves approximately 5% higher transmission data rate, 9% better sensing quality, and 19% lower energy consumption compared to baseline algorithms across multiple test scenarios. Furthermore, the solutions obtained are not only closer to the optimal front but also more concentrated, indicating higher-quality results.},
  archive      = {J_EAAI},
  author       = {Hongjuan Li and Haiyuan Chen and Miao Wang and Jiahui Li and Hui Kang and Yuzhuo Guan and Xu Lin},
  doi          = {10.1016/j.engappai.2025.112368},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112368},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective deployment optimization for integrated sensing and communication-enabled unmanned aerial vehicle swarm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive semi-supervised learning for specific emitter identification: An iterative clustering and pseudo-label refinement approach. <em>EAAI</em>, <em>162</em>, 112361. (<a href='https://doi.org/10.1016/j.engappai.2025.112361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Specific Emitter Identification (SEI) distinguishes radio-frequency (RF) devices by exploiting hardware-induced signal fingerprints, thereby strengthening wireless-layer security. Existing deep learning-based SEI methods depend heavily on labeled data and fixed confidence thresholds for pseudo-labeling, which limits their effectiveness under label scarcity or open-set conditions. To overcome these issues, we propose a progressive semi-supervised learning (ProSSL) method for SEI that combines iterative clustering with contrastive learning to generate adaptive pseudo-labels. ProSSL introduces an “uncertain” class and employs a dual-constraint selector—prediction stability and class diversity—to suppress noisy pseudo-labels and ensure robust propagation. Experiments on the public real-world long range(LoRa) RF-fingerprint dataset show that ProSSL gains 2.90%–6.01% absolute accuracy over state-of-the-art baselines, reaching 96.48% accuracy with 90% labels and 59.88% with only 5% labels. While on the public automatic dependent surveillance-broadcast(ADS-B) Top-10 dataset, ProSSL achieves 84.40% accuracy with 5% labeled data and 99.40% accuracy with 90%labeled data, again outperforming all competing methods. Open-set evaluations further demonstrate that overall accuracy rises from 18.81% when only two classes are known to 62.25% when eight classes are known, confirming strong generalization to unseen emitters and validating ProSSL’s robustness and practicality in realistic wireless environments.},
  archive      = {J_EAAI},
  author       = {Yiting Gao and Ke Wang and Hao Huang and Jiao Wang and Jiaxu Liu and Yao Zheng and Jianqing Li},
  doi          = {10.1016/j.engappai.2025.112361},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112361},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Progressive semi-supervised learning for specific emitter identification: An iterative clustering and pseudo-label refinement approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing scene text image super-resolution via gradient-based graph attention network. <em>EAAI</em>, <em>162</em>, 112360. (<a href='https://doi.org/10.1016/j.engappai.2025.112360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene text image super-resolution is crucial for enhancing text recognition in low-resolution real-world images. Existing methods usually overlook the structured and repetitive layout of text, which can serve as powerful prior knowledge for guiding reconstruction. In this work, we propose a novel framework that incorporates gradient-based graph attention to explicitly model patch-level text layout. The architecture combines a non-local group-wise attention module, a cascaded channel attention module, and a gradient-guided graph attention module to capture both global and local structural dependencies. This design enables more accurate restoration of text contours and layout consistency. Extensive experiments on the benchmark dataset demonstrate that our method achieves superior performance in both image quality and recognition accuracy, outperforming state-of-the-art methods. The code is available at: https://github.com/cvzxy/TSANv2 .},
  archive      = {J_EAAI},
  author       = {Xiangyuan Zhu and Xuchong Liu and Kehua Guo and Wei Zhao},
  doi          = {10.1016/j.engappai.2025.112360},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112360},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing scene text image super-resolution via gradient-based graph attention network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A consistency regularization-based approach integrating anatomical structural relationships and organ category representations for multi-organ segmentation in pigs. <em>EAAI</em>, <em>162</em>, 112359. (<a href='https://doi.org/10.1016/j.engappai.2025.112359'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern biomedical research and livestock management, accurate multi-organ segmentation in pigs is essential for breeding programs. However, current methods face challenges due to low imaging contrast, size disparities, and organ shape variability. Additionally, the manual annotation of computed tomography (CT) scans is labor-intensive and costly, limiting available labeled samples. To address these issues, we propose a consistency regularization-based network guided by anatomical structural relationships and global organ category representations, specifically designed for multi-organ segmentation using a limited number of annotated CT scan samples from pigs. Specifically, we designed the SpatialLink Gated Recurrent Unit (GRU) module to extract anatomical structural information and capture dynamic spatial relationships between organs, thereby minimizing segmentation biases caused by organ shape variations. Moreover, we developed the Organ Category Coding module and Guidance module, which integrate consistency regularization and attention mechanisms, enabling the network to accurately extract global organ category representations during the decoding phase, even with a small number of labeled samples, significantly improving segmentation consistency across organs of different sizes. Additionally, We are the first to apply the Visual State Space block to multi-organ segmentation in pigs, using it to extract contextual information. Experiments on 60 pigs demonstrate that our method achieves state-of-the-art results, with significant improvements in segmentation accuracy for the gallbladder and bladder, including a 9.8% and 4.2% Dice score increase, respectively, and a 12.4% and 6.2% boost in Jaccard scores compared to compared with a selection of published methods.},
  archive      = {J_EAAI},
  author       = {Xiang Pan and Hang Fan and Jianlan Wang and Yan Fu and Wei Chu and Weipeng Tai and Jing Gu and Jianming Ni},
  doi          = {10.1016/j.engappai.2025.112359},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112359},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A consistency regularization-based approach integrating anatomical structural relationships and organ category representations for multi-organ segmentation in pigs},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable chest X-ray localization using principal component-based feature selection in deep learning. <em>EAAI</em>, <em>162</em>, 112358. (<a href='https://doi.org/10.1016/j.engappai.2025.112358'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification and localization of diseases in chest X-ray (CXR) images are crucial for early diagnosis and timely medical intervention. Traditional localization techniques like Class Activation Mapping (CAM), depend on Global Average Pooling (GAP) layers, restricting their flexibility, while gradient-based methods like Grad-CAM involve computational overhead and limited interpretability. To address these limitations, this study introduces a novel Principal Component Analysis (PCA)-based localization method that eliminates reliance on GAP layers and gradient computations. Utilizing publicly available Kaggle datasets, namely the COVID-19 Radiography Dataset and Tuberculosis (TB) Chest X-ray Database. The proposed approach employs PCA to compress high-dimensional convolutional feature maps extracted from the pretrained VGG16 model into a lower-dimensional, spatially meaningful representation. This enables rapid, interpretable heatmap generation highlighting precise abnormal regions. Experimental results demonstrate that the proposed method achieved an average training loss of 0 . 0835 ± 0 . 1830 and validation loss of 0 . 1385 ± 0 . 0741 across 5-fold cross-validation. In addition, it achieved an impressive accuracy of 97.5%, sensitivity of 98.2%, specificity of 99.4%, a Dice Similarity Coefficient (DSC) of 97.5%, and an Intersection-over-Union (IoU) of 95.1%. Compared to CAM, and Grad-CAM, PCA-based localization significantly reduces inference time, enhances interpretability, and provides robust multi-class localization performance suitable for clinical deployment.},
  archive      = {J_EAAI},
  author       = {Diwakar Diwakar and Deepa Raj},
  doi          = {10.1016/j.engappai.2025.112358},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112358},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interpretable chest X-ray localization using principal component-based feature selection in deep learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast simulation for scattering muography applications using generative adversarial neural networks. <em>EAAI</em>, <em>162</em>, 112357. (<a href='https://doi.org/10.1016/j.engappai.2025.112357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Muography is an emergent non-destructive testing technique that uses cosmic muons to probe the interior of objects and structures. This technique can be employed to perform preventive maintenance of critical equipment in the industry in order to test the structural integrity of the facility. Several muography imaging algorithms based on machine learning methods are being developed in the recent years. These algorithms make exhaustive use of simulated data, usually using packages such as GEANT4 (GEometry ANd Tracking), that exhaustively simulate the detector, to produce training samples. This work presents a faster alternative for the generation of simulated samples based on generative adversarial neural networks. A speed up factor of 80 is observed with this system without any significant degradation of the quality of the simulation.},
  archive      = {J_EAAI},
  author       = {Rubén López Ruiz and Celia Fernández Madrazo and Sergio Sánchez Cruz and Lara Lloret Iglesias and Pablo Martínez Ruiz del Árbol},
  doi          = {10.1016/j.engappai.2025.112357},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112357},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fast simulation for scattering muography applications using generative adversarial neural networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on lightweight network for real-time detection of steel structure corrosion based on knowledge distillation. <em>EAAI</em>, <em>162</em>, 112356. (<a href='https://doi.org/10.1016/j.engappai.2025.112356'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regular and real-time monitoring of corrosion is crucial for ensuring structural safety and extending the service life of infrastructure. With the continuous development of advanced structural health monitoring technologies, intelligent corrosion detection has become an inevitable trend. This study addresses the issues of low accuracy, incomplete detail processing, and missed or false detections in complex scenarios in steel structure corrosion detection, as well as the challenges of high complexity and insufficient real-time performance in deep learning models. We propose a high-performance, lightweight, real-time corrosion detection model, Real-Time Detection Transformer for Corrosion (RT-DETR-Corrosion), based on knowledge distillation. By incorporating lightweight optimization on the RT-DETR-R18 baseline model and a hybrid knowledge distillation approach, the model significantly improves real-time performance and detection accuracy, meeting the application requirements for efficiency and precision in steel structure corrosion detection. Experimental results show that the model exhibits excellent optimization effects in terms of localization accuracy, classification accuracy, and position regression error on both the training and validation sets, while also demonstrating strong generalization ability. In extreme weather conditions (such as rain, fog, snow, and strong light) and complex scenarios (such as occlusion, blur, and low-light environments), the model maintains stable Precision, Recall, and mAP metrics, validating its reliability and applicability in diverse real-world engineering environments. Moreover, visualized heatmap analysis of detection results for different scenarios further confirms the model's precise attention to corrosion regions and its generalization ability, providing essential technical support for steel structure corrosion risk assessment and intelligent monitoring, with significant potential for engineering applications.},
  archive      = {J_EAAI},
  author       = {Jia Hou and Wei Chen and Zhen Duan and Hang Li and Mingyu Yu},
  doi          = {10.1016/j.engappai.2025.112356},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112356},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Research on lightweight network for real-time detection of steel structure corrosion based on knowledge distillation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Function structures of information measures for n-polygonal interval-valued intuitionistic fuzzy sets and their application in location selection strategy. <em>EAAI</em>, <em>162</em>, 112355. (<a href='https://doi.org/10.1016/j.engappai.2025.112355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interval-valued intuitionistic fuzzy set (IVIFS) represents an organic integration of interval-valued fuzzy sets and intuitionistic fuzzy sets, but it fails to meet the requirements of linearity and closure in arithmetic operations, rendering its computations relatively intricate. Consequently, this paper employs an interval partitioning strategy to mitigate the complexity of arithmetic operations, thereby constructing a novel fuzzy set structure characterized by efficient piecewise linear approximation capabilities. Furthermore, the paper presents the structural form of arithmetic operations for the IVIFS with piecewise linear approximation and demonstrates the simplicity of these operations by an numerical example. In addition, we extend the findings on information measures for polygonal interval-valued intuitionistic fuzzy set pertaining to abstract functions that fulfill particular criteria. Furthermore, we delve into the transformation relationships among these information measures, from which a range of structural formats for information measures can be deduced based on functional expressions and transformation relationships. Finally, similarity measures are applied to company site selection. The validity, practicality and stability of proposed measures have been proven through sensitivity analysis and comparative analysis.},
  archive      = {J_EAAI},
  author       = {Le Fu and Chunfeng Suo},
  doi          = {10.1016/j.engappai.2025.112355},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112355},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Function structures of information measures for n-polygonal interval-valued intuitionistic fuzzy sets and their application in location selection strategy},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-dimensional refined composite multi-scale revised ensemble dispersion entropy and its application to fault diagnosis of rolling bearing. <em>EAAI</em>, <em>162</em>, 112354. (<a href='https://doi.org/10.1016/j.engappai.2025.112354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-dimensional ensemble dispersion entropy (EDE 1D ) can effectively characterize the nonlinear dynamic characteristics of one-dimensional time series, but the complexity of two-dimensional space is not reflected, and only single-scale features can be captured. Firstly, to comprehensively capture the feature information of two-dimensional space, the symmetrized dot pattern (SDP) is introduced to overcome the shortcomings of the ordinary images lack of physical meaning and the time-frequency distribution methods exhibit incomplete information representation, etc. Simultaneously, the amplitude and frequency information are intuitively expressed by a two-dimensional mirror snowflake symmetrized image (MSSI 2D ). Secondly, to overcome the shortcomings of single-scale and traditional coarse-graining, a two-dimensional refined composite multi-scale coarse-graining method is proposed, which improves the accuracy of feature extraction and reduces the calculation deviation. After that, a new feature extraction method namely two-dimensional refined composite multi-scale revised ensemble dispersion entropy (RCMREDE 2D ) is proposed, whose parameter stability and performance are explored through simulation analysis. The results demonstrate that the RCMREDE 2D exhibits excellent stability and anti-noise interference ability. Based on the advantages of RCMREDE 2D , a novel fault diagnosis method for rolling bearings is developed by integrating RCMREDE 2D and a firefly algorithm optimized support vector machine (FA-SVM) multi-fault classifier for pattern recognition. The proposed method is further validated through two measured bearing data sets and five comparative methods, and the results indicate that the RCMREDE 2D and FA-SVM achieve the highest recognition accuracy while demonstrating superior stability.},
  archive      = {J_EAAI},
  author       = {Wenqing Ding and Jinde Zheng and Haiyang Pan and Jian Cheng and Jinyu Tong},
  doi          = {10.1016/j.engappai.2025.112354},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112354},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Two-dimensional refined composite multi-scale revised ensemble dispersion entropy and its application to fault diagnosis of rolling bearing},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse and robust elastic net support vector machine with bounded concave loss for large-scale problems. <em>EAAI</em>, <em>162</em>, 112352. (<a href='https://doi.org/10.1016/j.engappai.2025.112352'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The elastic net support vector machine is an extensively employed method for addressing a range of classification tasks. Nevertheless, a significant drawback of the elastic net support vector machine is its high computational cost when dealing with large-scale classification problems. To address this drawback, we first introduce an innovative non-convex elastic net support vector machine model that employs our newly created bounded concave loss function, which effectively attains both sparsity and robustness. Based on proximal stationary point, we have effectively constructed an innovative optimality theory tailored for our newly created elastic net support vector machine model. By leveraging the innovative optimality theory, we have successfully developed a new and exceptionally effective algorithm designed to enhance computational efficiency through the division of the entire dataset into two distinct categories: working sets and non-working sets. During each learning cycle, the parameters associated with the non-working set remain unchanged. In contrast, the parameters related to the working set are subject to updates. Consequently, our new algorithm facilitates quicker modifications on smaller datasets, improving runtime efficiency and lowering computational complexity. Numerical experiments have demonstrated significant efficiency, particularly regarding computational speed, the number of support vectors, and classification accuracy, surpassing eleven other leading solvers.},
  archive      = {J_EAAI},
  author       = {Huajun Wang and Wenqian Li},
  doi          = {10.1016/j.engappai.2025.112352},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112352},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sparse and robust elastic net support vector machine with bounded concave loss for large-scale problems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review of speaker verification: Methods, network architectures, tasks and challenges. <em>EAAI</em>, <em>162</em>, 112351. (<a href='https://doi.org/10.1016/j.engappai.2025.112351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speaker verification is an important branch of biometric recognition, with wide applications in identity authentication, audio monitoring, and other fields. In recent years, deep learning and meta-learning have made remarkable advancements in the field of speaker verification. Therefore, it is necessary to update existing reviews of speaker verification to reflect the latest research developments. We review literature from the past decade to provide a timely and comprehensive survey of the field. First, we outline the concept and system process of speaker verification. Then, we analyze the speech preprocessing process and common acoustic features used in the systems. Next, we present an overview of speaker modeling approaches, covering traditional probabilistic methods, deep learning-based speaker methods, and meta-learning-based speaker methods, focusing on the latter two methods. We provide an in-depth analysis and summary of the characteristics and the latest network architectures of these methods, focusing on the development of Transformer and large-scale pre-trained Transformer. Furthermore, we introduce the datasets and evaluation metrics used in speaker verification systems, focusing on a detailed and fair comparison of the performance of text-dependent and text-independent speaker verification systems. Finally, we explore the challenges faced by speaker verification systems and discuss future research opportunities.},
  archive      = {J_EAAI},
  author       = {Weijie Wang and Hong Zhao and Yikun Yang and Yongjuan Yang},
  doi          = {10.1016/j.engappai.2025.112351},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112351},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A review of speaker verification: Methods, network architectures, tasks and challenges},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-cost and sparsity for continual semantic segmentation. <em>EAAI</em>, <em>162</em>, 112350. (<a href='https://doi.org/10.1016/j.engappai.2025.112350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have contributed to significant progress in semantic segmentation tasks. However, deep neural networks exhibit a critical drop in performance due to catastrophic forgetting when they are required to learn new tasks incrementally. The more plastic the network is, the easier it can learn new tasks. Whereas, for continual semantic segmentation, it is more reliable to preserve the knowledge it has learned from previous tasks. Here, gated 0-1 Bernoulli variable is used as a regularization method to optimize performance by enhancing network sparsity. Then, the special case of gated 0-1 Bernoulli variable is applied in the replay-based method of continual semantic segmentation. Specifically, when the value of the sub-network sampling rate reaches 0.5, the network reaches the strongest stability. Finally, the gated 0-1 Bernoulli variable improves the network’s performance in complex scenarios and reduces cost under similar performance. Experimental results indicate that in using 100% samples for incremental training, the Mean Intersection over Union(mIoU) of the old classes improves by up to 4.6% and 5.5% compared to the baseline at the end of the overall training in continual semantic segmentation scenarios 10-1 and 10-2. Furthermore, in using 60% samples for incremental training, the performance for the old tasks only drops by less than a percentage, while the time cost to complete the full setup decreases by 22%.},
  archive      = {J_EAAI},
  author       = {Qing Ji and Bin Li and Shaobo Li and Hongchao An and Jing Yang},
  doi          = {10.1016/j.engappai.2025.112350},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112350},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Low-cost and sparsity for continual semantic segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Promoting sustainability-oriented brand activist campaigns: A spherical fuzzy decision support framework for evaluating activist advertising videos. <em>EAAI</em>, <em>162</em>, 112349. (<a href='https://doi.org/10.1016/j.engappai.2025.112349'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Activist video advertisements represent a strategic form of brand communication in which companies express their stance on social or environmental issues through emotionally driven storytelling and slogan-based narratives. Despite their growing prevalence, there is a notable lack of systematic and quantitative methods for evaluating their performance or comparing their effectiveness across competing brands. This research addresses that gap by proposing a comprehensive decision support system (DSS) designed to assess the performance of activist video advertisements in a structured and reproducible manner. The study introduces a novel hybrid multi-criteria decision-making (MCDM) framework: the spherical cubic fuzzy (SCF)–Aczel-Alsina–ranking comparison (RANCOM)–method based on the removal effects of criteria (MEREC)–deviation-based pairwise assessment ratio technique (DEPART). This methodology integrates subjective weights obtained via SCF–RANCOM and objective weights derived through SCF–MEREC, with both sets of weights combined using SCF-based aggregation operators that incorporate Aczel-Alsina t-norm and t-conorm functions. Performance rankings are then generated using the SCF–DEPART method. To demonstrate the model's applicability, a real-world case study involving eight sustainability-oriented activist video advertisements released in Türkiye was conducted. Evaluations were based on input from ten domain experts across eleven criteria. The analysis identified “convincingness and credibility” as the most critical factor, with “The Voice of Nature” campaign achieving the highest performance rating. The model's robustness was confirmed through scenario-based sensitivity analyses, and its consistency was validated by benchmarking against thirteen alternative MCDM approaches. The findings offer meaningful implications for both academic research and advertising practice.},
  archive      = {J_EAAI},
  author       = {Galip Cihan Yalçın and Karahan Kara and Gülcan Işık and Esra Serdar Tekeli and Vladimir Simic and Abdullah Ballı and Dragan Pamucar},
  doi          = {10.1016/j.engappai.2025.112349},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112349},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Promoting sustainability-oriented brand activist campaigns: A spherical fuzzy decision support framework for evaluating activist advertising videos},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated clustering with mutual knowledge distillation for traffic flow prediction. <em>EAAI</em>, <em>162</em>, 112347. (<a href='https://doi.org/10.1016/j.engappai.2025.112347'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction plays a critical role in intelligent transportation systems. Conventional traffic flow prediction methods primarily rely on centralized training, which poses a risk of privacy leakage. Federated learning, a privacy-preserving framework to machine learning, enables distributed participants to jointly train a shared model without sharing local private data. However, traffic flow is typically collected from different devices and contains different temporal patterns, leading to non-independent and identically distributed. To address these challenges, we propose a traffic flow prediction method based on federated clustering with mutual knowledge distillation. We first perform temporal decomposition on the traffic flow data and use mutual learning with adaptive distillation loss to facilitate mutual knowledge transfer among local models during training. Then, we apply spectral clustering to cluster clients based on the cosine similarity of model parameters at the server and design a global model aggregation method to improve the performance of federated learning. Finally, the proposed method is evaluated on two real-world traffic datasets, and the experiment results show significant improvements over traditional federated learning approaches and also outperform federated mutual learning. The results demonstrate that the proposed method effectively captures temporal information and mitigates the effect of non-independent and identically distributed issues.},
  archive      = {J_EAAI},
  author       = {Yao Lin and Shengwu Xiong},
  doi          = {10.1016/j.engappai.2025.112347},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112347},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Federated clustering with mutual knowledge distillation for traffic flow prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantifying hybrid failure mode in cyclic-loaded reinforced concrete shear walls: Integrating unsupervised and supervised learning techniques. <em>EAAI</em>, <em>162</em>, 112346. (<a href='https://doi.org/10.1016/j.engappai.2025.112346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to identify failure types in Reinforced Concrete Shear Walls (RCSWs) by quantifying the contributions of shear and flexural modes in the force-deformation response of the walls. The supporting research database includes images, cyclic curve backbones, and geometric and mechanical characteristics of 253 RCSWs. Initially, the database is manually classified into shear, flexure, and shear-flexure failure modes based on observations of surface damage and the cyclic response of the wall. Subsequently, unsupervised clustering and supervised learning algorithms are employed to probabilistically quantify and predict the participation of flexural and shear modes in the overall seismic response of the walls, respectively. The unsupervised model, utilizing the K-means algorithm, identifies the primary failure modes of the walls, achieving over 90 % concordance with manual expert labeling. Based on the results of unsupervised clustering, a hybridity index is proposed to demonstrate the contributions of shear and flexure failure modes to the overall seismic response. Supervised learning is then used to predict hybridity indices from wall characteristics, with the Extremely Randomized Trees (Extra Trees) model achieving the best results based on a balanced evaluation of multiple performance metrics. SHapley Additive exPlanations (SHAP), a tool for exploring model sensitivity, highlights the aspect ratio as the key influencing factor on failure mode, in accordance with relevant structural engineering codes and standards. Implementation of the proposed framework in exploring the behaviors of four unseen case studies reveals a significant correlation between the predicted hybridity indices and observed damage, consistent with existing guidelines.},
  archive      = {J_EAAI},
  author       = {Pouya Ebrahimi and Amir Hossein Asjodi and Kiarash M. Dolatshahi},
  doi          = {10.1016/j.engappai.2025.112346},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112346},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Quantifying hybrid failure mode in cyclic-loaded reinforced concrete shear walls: Integrating unsupervised and supervised learning techniques},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-path multiple attention-guided feature interaction network for camouflaged object detection. <em>EAAI</em>, <em>162</em>, 112345. (<a href='https://doi.org/10.1016/j.engappai.2025.112345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing Camouflaged Object Detection (COD) methods rely on features from a pre-trained backbone with a single-encoder structure, leading to initial features biased towards global or local preferences. This affects subsequent feature modeling and degrades COD performance. Some studies use modular or auxiliary flow structures to balance feature preferences but often focus only on interactions between hierarchical features or information flows, ignoring potential redundancy or noise within aggregated features. Therefore, we propose a novel dual-path multiple attention-guided feature interaction network (DMAFI-Net) for COD, which contains four main components: global and local features interaction module (GLFI), intra-feature interaction module (IFI), multi-scale feature enhancement module (MFE), and two decoders including neighbor connection decoder based feature aggregation (NFA) and refine decoder. Specifically, the GLFI is designed to implement the interaction and combination of global and local features, and the combined features will be sent to IFI to mine intra-feature information. Besides, the MFE is introduced to further enrich the extracted features obtained in the IFI. In the feature decoding stage, the NFA module utilizes neighbor connection decoder to fuse multi-scale features and ultimately generates a coarse prediction. Finally, the refine decoder leverages multiple attention modules to refine the initial prediction with the combined features as auxiliary cues and obtain the final camouflaged map. Extensive experiments on four COD benchmark datasets demonstrate the superiority of the proposed framework when compared to 24 state-of-the-art (SOTA) methods in terms of five widely used evaluation metrics. Furthermore, the ablation studies show the effectiveness of main components of our DMAFI-Net.},
  archive      = {J_EAAI},
  author       = {Anzhi Wang and Jintao Wu and Shuang Zhao and Yun Liu},
  doi          = {10.1016/j.engappai.2025.112345},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112345},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual-path multiple attention-guided feature interaction network for camouflaged object detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TFCTL: Time–Frequency calibrated transfer learning for cross domain depression detection. <em>EAAI</em>, <em>162</em>, 112344. (<a href='https://doi.org/10.1016/j.engappai.2025.112344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the application of speech-based depression detection systems expands, differences in cross-domain data distribution pose significant challenges. This paper proposes the framework of Time–Frequency Calibrated Transfer Learning (TFCTL). This framework first introduces Frequency-Delay Neural Network (FDNN), inspired by Time-Delay Neural Network (TDNN), extending the concept of temporal feature extraction using sliding windows and weight sharing from the time domain to the frequency domain. A multi-level information aggregation module then integrates features of varying abstraction levels from both time-delay and frequency-delay neural networks, balancing global and local speech information. Finally, TFCTL uses transfer learning to calibrate the distribution of the aggregated time–frequency embedding vectors, uncovering commonalities of depression features across different domains. Cross-speaker and cross-corpus experiments were conducted using the Chinese Multimodal Depression Corpus (CMDC) and the Distress Analysis Interview Corpus Wizard-of-Oz (DAIC-WOZ). In cross-speaker scenarios, TFCTL achieved F1 scores of 0.7324 on DAIC and 0.9660 on CMDC, outperforming other methods. In cross-corpus scenarios, TFCTL achieved F1 scores of 0.6743 on DAIC and 0.6879 on CMDC, demonstrating its robustness in addressing domain mismatch issues. The source code used in the paper is available at https://anonymous.4open.science/r/TFCTL-A545/ .},
  archive      = {J_EAAI},
  author       = {Dongdong Li and Li Ding and Zuo Yang and Zhe Wang and Ke Zhao},
  doi          = {10.1016/j.engappai.2025.112344},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112344},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TFCTL: Time–Frequency calibrated transfer learning for cross domain depression detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mutual information guided invertible image hiding network. <em>EAAI</em>, <em>162</em>, 112343. (<a href='https://doi.org/10.1016/j.engappai.2025.112343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image hiding techniques are commonly used for secure communication, copyright protection, and visual privacy. Invertible neural network (INN) have emerged as a promising approach for image steganography, enabling the concealment and recovery of secret images through forward and backward mappings within the network. However, existing methods often face limitations in the accuracy of recovered images due to challenges in estimating the lost information during the forward process. To address this issue, we propose a Mutual Information Guided Invertible Image Hiding Network (MIGIIHNet), which leverages mutual information estimation between the lost information and the stego image in the forward process to guide the backward mapping for reconstruction. Specifically, we propose a lightweight INN with a channel attention feature aggregation module (CAFAM), integrating a channel attention mechanism to optimize the multi-scale aggregation of both low-level and high-level features in a single forward pass. Also, an association learning module (ALM) is designed to model the mutual information between the stego image and the lost information during the forward hiding process. Then, the mutual information is utilized to reconstruct the secret image with high accuracy. Extensive experimental results show that MIGIIHNet outperforms existing state-of-the-art methods in terms of invisibility, security, and recovery accuracy, while maintaining low computational complexity.},
  archive      = {J_EAAI},
  author       = {Kehan Zhang and Fen Xiao and Jingwen Cai and Xieping Gao},
  doi          = {10.1016/j.engappai.2025.112343},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112343},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mutual information guided invertible image hiding network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-tailed detection and classification of wafer defects from scanning electron microscope images robust to diverse image backgrounds and defect scales. <em>EAAI</em>, <em>162</em>, 112342. (<a href='https://doi.org/10.1016/j.engappai.2025.112342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In semiconductor engineering, high yield of wafers relies on accurate detection and classification of wafer defects. The dataset for detecting wafer defects presents three primary challenges: (i) different background types, (ii) variable image or defect scales, and (iii) imbalanced data with a long-tailed distribution of defect types. These challenges create significant limitations for traditional classification techniques. To address these issues, we propose a stratified framework called Wafer Detection and Classification (WaferDC), designed specifically for detecting and classifying wafer defects from scanning electron microscope (SEM) images. Our framework achieves high defect detection performance on SEM wafer images by utilizing a multi-cluster memory bank, which effectively handles the challenges of (i) variable background types and (ii) differing image or defect scales. Building on this robust detection, we propose Segmentation and Mix (SegMix), a novel defect augmentation technique based on anomaly heatmaps, which enhances the reliability of defect detection and classification in a (iii) long-tailed imbalanced environment. Finally, we pass defect-classified images through a parameter-efficient fine-tuning (PEFT)-based classifier (Shiet al., 2023) utilizing a vision transformer (ViT) architecture, further improving overall defect detection and classification performance. We rigorously tested WaferDC on a proprietary SEM wafer dataset and the public Describable Textures Dataset-Synthetic (DTD-Synthetic) and Magnetic Tile Defect (MTD) datasets. The results confirm the effectiveness of our method in improving defect detection and classification in wafer manufacturing. Our code is available at https://github.com/SpatialAILab/WaferDC .},
  archive      = {J_EAAI},
  author       = {Taekyeong Park and Yongho Son and Sanghyuk Moon and Seungju Han and Je Hyeong Hong},
  doi          = {10.1016/j.engappai.2025.112342},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112342},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Long-tailed detection and classification of wafer defects from scanning electron microscope images robust to diverse image backgrounds and defect scales},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast trajectory planner with a reinforcement learning-based controller for robotic manipulators. <em>EAAI</em>, <em>162</em>, 112341. (<a href='https://doi.org/10.1016/j.engappai.2025.112341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating obstacle-free trajectories for robotic manipulators in unstructured and cluttered environments remains a significant challenge. Existing motion planning methods often require additional computational effort to generate the final trajectory by solving kinematic or dynamic equations. This paper highlights the strong potential of model-free reinforcement learning methods over model-based approaches for obstacle-free trajectory planning in joint space. We propose a fast trajectory planning system for manipulators that combines vision-based path planning in task space with reinforcement learning-based obstacle avoidance in joint space. We divide the framework into two key components. The first introduces an innovative vision-based trajectory planner in task space, leveraging the large-scale fast segment anything (FSA) model in conjunction with basis spline (B-spline)-optimized kinodynamic path searching. The second component enhances the proximal policy optimization (PPO) algorithm by integrating action ensembles (AE) and policy feedback (PF), which greatly improve precision and stability in goal-reaching and obstacle avoidance within joint space. These proximal policy optimization (PPO) enhancements increase the algorithm’s adaptability across diverse robotic tasks, ensuring consistent execution of commands from the first component by the manipulator, while also enhancing both obstacle avoidance efficiency and reaching accuracy. The experimental results demonstrated the effectiveness of proximal policy optimization (PPO) enhancements, as well as simulation-to-simulation (Sim-to-Sim) and simulation-to-reality (Sim-to-Real) transfer, in improving model robustness and planner efficiency in complex scenarios. These enhancements allowed the robot to perform obstacle avoidance and real-time trajectory planning in obstructed environments. https://sites.google.com/view/ftp4rm/home},
  archive      = {J_EAAI},
  author       = {Yongliang Wang and Hamidreza Kasaei},
  doi          = {10.1016/j.engappai.2025.112341},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112341},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fast trajectory planner with a reinforcement learning-based controller for robotic manipulators},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bi-level location-routing problem with time windows for mixed-load recycling of heterogeneous batteries: A transformer-based improved deep reinforcement learning algorithm. <em>EAAI</em>, <em>162</em>, 112340. (<a href='https://doi.org/10.1016/j.engappai.2025.112340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the urgency, timeliness and uncertainty of power batteries recycling, we extend a novel network model for retired battery recycling systems, bi-level capacitated location-routing problem with time windows for heterogeneous battery mixed-load (CLRPTW-HBM). Firstly, the expected interval and linear weighting methods are used to transform and process the lower-level multi-objective function that contains fuzzy variables. Secondly, a Transformer-based improved deep reinforcement learning algorithm (Transformer-IDRL) is proposed. (1) The bi-level CLRPTW-HBM is modeled as Markov decision process, and a policy network model with dual-layer encoder-decoder structure is designed based on Transformer architecture. (2) Randomly generate instance data, and the asynchronous advantage Actor-Critic with adaptive dynamic parameter tuning strategy is employed for training. (3) The action sampling strategy based on roulette reverse selection mechanism, and local search strategy incorporating problem characteristics are introduced to improve solution quality. Finally, extensive experiments are conducted on benchmark datasets and actual cases, and the results demonstrate superior performance of Transformer-IDRL, with an average Gap of 0.22 % and 0.19 %, a 5.30 % reduction in recycling cost, and a 6.06 % reduction in battery exposure risk. These satisfactory results highlight the feasibility and efficiency of the proposed model and method. Additionally, sensitivity analysis of model parameters shows that under different decision-maker preferences and vehicle loading capacity, the sensitivity range of path cost is [5.77 %, 39.85 %] and [16.04 %, 35.54 %], while that of exposure risk is [1.40 %, 3.39 %] and [1.35 %, 5.54 %], indicating that parameter variations significant influence the layout of recycling network and overall path cost. Therefore, decision-makers should flexibly adjust key parameters to balance economic benefits and sustainable development in battery recycling.},
  archive      = {J_EAAI},
  author       = {Mengna Zhao and Shiping Chen},
  doi          = {10.1016/j.engappai.2025.112340},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112340},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Bi-level location-routing problem with time windows for mixed-load recycling of heterogeneous batteries: A transformer-based improved deep reinforcement learning algorithm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Instantaneous power prediction for industrial robots using tree-based machine learning methods. <em>EAAI</em>, <em>162</em>, 112339. (<a href='https://doi.org/10.1016/j.engappai.2025.112339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a tree-based machine learning methodology for instantaneous power prediction designed, tested and validated using data from an articulated industrial robot. The proposed methodology for instantaneous power prediction materializes through a generic system architecture with functionalities consisting of data acquisition, time alignment of data samples, storage, model learning, instantaneous power prediction and integration in time to evaluate energy consumption at robot operation level. This methodology is designed to evaluate offsite energy consumption of robotized workstations for different layouts characterized by relative position of the robot with respect to the serviced and fly-by points. This is important both for offline virtual commissioning of robotized workstations (determine layout) and for online operation for maintenance purposes (determine energy spikes different from normal model). The analyzed operation is the linear motion of the robot Tool Control Point in Cartesian space, characterized by the complexity of the kinematic model: each joint operates in coordinated motion, adjusting its velocity and acceleration continuously to ensure a straight path with constant speed. A custom Internet of things (IoT) device enables synchronized energy and motion data logging for robots, ensuring consistent values for sampled trajectories. Justification for the usage of tree-based methods and experimental results are provided.},
  archive      = {J_EAAI},
  author       = {Ionuţ Lenţoiu and Silviu Răileanu and Theodor Borangiu and Mihnea Constantinescu and Octavian Morariu},
  doi          = {10.1016/j.engappai.2025.112339},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112339},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Instantaneous power prediction for industrial robots using tree-based machine learning methods},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward sustainable wastewater treatment: Transformer ensembles and multitask learning for energy consumption and quality management. <em>EAAI</em>, <em>162</em>, 112338. (<a href='https://doi.org/10.1016/j.engappai.2025.112338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wastewater treatment plants (WWTPs) are among the most energy-intensive components of urban infrastructure and bear strict regulatory responsibilities for wastewater quality. These dual challenges, minimizing energy consumption and maintaining environmental compliance, are deeply interrelated and must be managed simultaneously to achieve sustainable plant operation. This study proposes a framework that comprises two customized components. The first component employs a voting ensemble model based on transformer architecture to predict energy consumption. It processes heterogeneous feature domains — including hydraulic, wastewater, and climatic variables — through parallel attention-driven streams. The outputs from these streams are then aggregated using a weighted voting mechanism to produce the final prediction. Second, a multitask Bidirectional Gated Recurrent Unit (Bi-GRU) forecasts wastewater quality indicators concurrently (ammonia, Biochemical Oxygen Demand (BOD), and Chemical Oxygen Demand (COD)), capturing shared temporal dependencies and reducing model complexity. A hybrid preprocessing strategy is applied, incorporating domain-aware outlier detection (z-score and Interquartile Range (IQR)), K-Nearest Neighbors (KNN) Imputation, and feature selection using Extreme Gradient Boosting (XGBoost). Experimental results showed that. The voting ensemble model achieved the best results for energy consumption prediction with 31.61 of Root Mean Squared Error (RMSE). The multitask Bi-GRU achieved the best results for wastewater quality indicators with RMSE at 6.1689, 48.0323, and 88.2214 for ammonia, BOD, and COD, respectively. This work is among the first to integrate transformer ensembles and multitask learning in a unified WWTP forecasting system. Simultaneously addressing energy efficiency and water quality assurance, this offers a practical, scalable, and intelligent decision-support tool for sustainable wastewater management.},
  archive      = {J_EAAI},
  author       = {Hager Saleh and Sherif Mostafa and Shaker El-Sappagh and Abdulaziz AlMohimeed and Michael McCann and Saeed Hamood Alsamhi and Niall O’Brolchain and John G. Breslin and Marwa E. Saleh},
  doi          = {10.1016/j.engappai.2025.112338},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112338},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Toward sustainable wastewater treatment: Transformer ensembles and multitask learning for energy consumption and quality management},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complete information extraction for monocular depth estimation using a dual framework. <em>EAAI</em>, <em>162</em>, 112337. (<a href='https://doi.org/10.1016/j.engappai.2025.112337'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to address the problem of efficient extraction of complete multi-scale information for supervised monocular depth estimation. Most of the existing depth estimation methods are based on Convolutional Neural Network (CNN). By gradually exploring the contextual and semantic features, they have achieved good results in scene depth estimation. However, with the expansion of the receptive field, global information limited by the local induction bias is gradually suppressed, resulting in the performance cannot be further improved. Recently, Transformer-based methods have been widely used to model the global correlation between features. Nevertheless, since the Transformer networks are not spatially aware enough, they usually lose local details and have no clear mechanism for reusing features when processing images. The Transformer networks perform self-attention mechanism at each location and cannot directly obtain information from other locations for features. Therefore, we propose a novel dual framework called as Transformer-CNN, which includes the Transformer-branch and the CNN-branch for monocular depth estimation. Specifically, the Transformer-branch is able to model the global contextual information and the CNN-branch can capture local spatial relationships in images. However, simply fusing these two independent branches may result in insufficient feature aggregation. To this end, we design a Parallel Feature Interaction Module (PFIM), which contains a Self-Attention Module (SAM) and a Cross-Attention Module (CAM), so as to highlight features from the Transformer-branch and the CNN-branch respectively and extract complementary information between the two branches. Meanwhile, in order to make full use of the low-level features with low quality in the scene, we propose a Low-level Information Acquisition Module (LIAM) to capture texture-related information and preserve texture details in the CNN-branch. Finally, to address the lack of multi-scale contextual information in Vision Transformer (ViT), we introduce a Wide Area Multi-scale Decoder (WAMD), which incorporates the multi-scale feature representations into the decoder part via a Wide Area Attention (WAA). Extensive experiments on benchmark datasets collected in the outdoor and indoor environments demonstrate the competitive results of the proposed method, compared with the state-of-the-art monocular depth estimation methods.},
  archive      = {J_EAAI},
  author       = {Bin Li and Dazheng Zhou and Xianjie Gao and Mingliang Zhang},
  doi          = {10.1016/j.engappai.2025.112337},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112337},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Complete information extraction for monocular depth estimation using a dual framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards non-visual bowel cancer diagnosis: A certainty-aware data-driven method of lesion characterisation using a vibrating capsule. <em>EAAI</em>, <em>162</em>, 112336. (<a href='https://doi.org/10.1016/j.engappai.2025.112336'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in miniaturised, dynamically actuated robots have opened new pathways for non-visual, in-situ disease diagnosis. This study explores a novel method for early bowel cancer detection using a self-propelled robotic capsule that navigates the bowel and detects lesions based on variations in tissue stiffness. The approach capitalises on the sensitivity of the capsule’s dynamic responses to surrounding tissue properties. A dual-phase machine learning framework is proposed. The first phase uses regression models including multilayer perceptron (MLP), support vector regression (SVR), and Gaussian process regression (GPR) to predict tissue stiffness from displacement signal features. The second phase uses a Gaussian mixture model (GMM) to cluster the predicted stiffness values into different categories. Unlike our previous work, this study emphasises the robustness of the models under varying data conditions using both accuracy and reliability-oriented metrics. Based on our studies, MLP provided the most reliable regression results for simulated data and downstream clustering, though GPR performed better on experimental datasets. SVR consistently underperformed, especially on experimental data. The GMM achieved over 89% clustering accuracy across both simulated and experimental datasets, with improved results when predictions from more accurate regression models are used as the inputs. This work demonstrates a promising step toward dynamic, in-situ lesion characterisation and highlights the potential for integrating lesion biomechanics into future endoscopic diagnosis.},
  archive      = {J_EAAI},
  author       = {Kenneth Omokhagbo Afebu and Yang Liu and Evangelos Papatheou and Shyam Prasad},
  doi          = {10.1016/j.engappai.2025.112336},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112336},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards non-visual bowel cancer diagnosis: A certainty-aware data-driven method of lesion characterisation using a vibrating capsule},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond the horizon: A comprehensive analysis of artificial intelligence-based weather forecasting models. <em>EAAI</em>, <em>162</em>, 112335. (<a href='https://doi.org/10.1016/j.engappai.2025.112335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of Artificial Intelligence (AI)-based weather forecasting is growing rapidly, with continuous progress in model development, techniques, and performance improvements. This paper provides a comprehensive overview of AI-based weather forecasting models, focusing on their current status, challenges, and directions for further development. A review of more than 40 models, primarily proposed after 2015, underscores the importance of critically examining various aspects of AI-based forecasting. Unlike previous reviews that targeted only a limited number of models or features, this study addresses a complete set of aspects and analyzes existing challenges from multiple perspectives. These aspects include the Machine Learning (ML) and Deep Learning (DL) methods used, datasets, predictand parameters, overfitting, and capability for forecasting extreme weather, lead time, spatiotemporal scale, performance criteria, overfitting, data assimilation, data-driven models, and the analysis of state-of-the-art (SOTA) models such as FengWu, ClimaX, Pangu-Weather, FourCastNet, GraphCast, GenCast, and Artificial Intelligence Forecasting System (AIFS) from various viewpoints. The review also discusses current challenges, including limited historical data and data quality, small-scale weather forecasting, model explainability, uncertainty, extreme weather prediction, physical constraints, temporal adaptation, and generalization, and outlines potential future directions.},
  archive      = {J_EAAI},
  author       = {Saeid Haji-Aghajany and Witold Rohm and Piotr Lipinski and Maciej Kryza},
  doi          = {10.1016/j.engappai.2025.112335},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112335},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Beyond the horizon: A comprehensive analysis of artificial intelligence-based weather forecasting models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural model of the adaptive tuned particle impact damper. <em>EAAI</em>, <em>162</em>, 112334. (<a href='https://doi.org/10.1016/j.engappai.2025.112334'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents a novel approach for the modeling of the Adaptive Tuned Particle Impact Damper (ATPID) using Multilayer Perceptron (MLP). The main motivation was the recognition that such an approach can support the development of novel neural modeling and the optimal determination of damper parameters in terms of mechanical vibration attenuation. The training data were obtained using a theoretical model validated experimentally. The optimally selected MLP was compared with other regression models using 10 different metrics. A hyperparameter tuning of the determined neural network architecture was conducted based on the input parameters such as excitation amplitude, grain mass, and ATPID damper height. The analyses show that the proposed neural network could quickly and accurately estimate the system’s vibration amplitude and efficiently predict the optimal damper height. The ability to effectively determine the correct optimal height is crucial for ATPID damper control. The high efficiency in predicting the system’s vibration amplitude allows for the replacement of the theoretical model with applied time-consuming contact forces. The MLP accurately estimated vibration amplitudes with 1%–10% error for interpolated data and up to 15% for extrapolated cases. The issue raised is particularly important from the perspective of real-time damper control. It was found that computing a single case using the artificial neural network is more than ten times faster compared to the theoretical model. Therefore, the proposed ATPID damper model based on a neural network forms the basis for further considerations and scientific research to finally propose a control algorithm in the future.},
  archive      = {J_EAAI},
  author       = {Mateusz Żurawski and Karolina Grabska and Robert Zalewski and Adam Kulawik},
  doi          = {10.1016/j.engappai.2025.112334},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112334},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural model of the adaptive tuned particle impact damper},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive hybrid machine reading comprehension framework for multimodal emotion-cause pair extraction in conversations. <em>EAAI</em>, <em>162</em>, 112333. (<a href='https://doi.org/10.1016/j.engappai.2025.112333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal emotion-cause pair extraction in conversations (MECPEC) has gradually evolved into an emerging task aimed at discovering deeper causal relationships between emotions and their corresponding causes in conversational contexts. It has widespread application in fields such as human–computer interaction, social media analysis, customer feedback management, and empathetic companion, among others. However, the challenges posed by the oversimplified multimodal feature fusion mechanism and the failure to account for the relative positional relationship between emotions and causes still hinder the performance of MECPEC. In this study, we propose an adaptive hybrid machine reading comprehension (AHMRC) framework to extract potential emotion-cause pairs inherent in conversations. The MECPEC task is first transformed into a two-round hybrid machine reading comprehension task that sequentially enforces the global emotion query and the local cause query with the goal of exploring the relative position constraint specific to conversations. Subsequently, an adaptive multimodal attention module is designed by incorporating features extracted from text, video, and audio modalities, and adaptively fusing them according to their contributions. Extensive experiments were carried out on the benchmark datasets to demonstrate the effectiveness of the proposed AHMRC framework in comparison to other state-of-the-art methods in the literature.},
  archive      = {J_EAAI},
  author       = {Guorui Li and Xufeng Duan and Cong Wang and Sancheng Peng},
  doi          = {10.1016/j.engappai.2025.112333},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112333},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An adaptive hybrid machine reading comprehension framework for multimodal emotion-cause pair extraction in conversations},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analytical and machine learning approaches for three-dimensional orthotropic functionally graded cylindrical structure in steady heat conduction. <em>EAAI</em>, <em>162</em>, 112332. (<a href='https://doi.org/10.1016/j.engappai.2025.112332'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Theoretical and computational modelling of heat conduction in a functionally graded cylinder has been rigorously investigated in prior studies, owing to its critical significance in high-stakes engineering applications such as nuclear reactor design, aerospace structural systems, and pressure vessel technology. Despite this extensive body of work, the majority of these studies have mostly focused on simplified two-dimensional models, frequently presuming idealized thermal parameters such as isotropic thermal conductivity, constant convection coefficients, and spatially uniform ambient temperatures. These simplifications overlook the crucial role of spatially varying thermal characteristics and three-dimensional (3D) temperature distributions, which are essential for accurately simulating the complex heat conduction behaviors found in real-world engineering. Unlike prior research, this study presents an analytical solution for heat conduction under non-homogeneous generalized Robin boundary conditions, capturing 3D thermal conductivity inhomogeneities along three orthogonal directions using Sturm-Liouville theory and finite integral transforms. However, while such analytical methods are highly accurate for simpler geometries, they often encounter significant challenges when extended to scenarios involving complex material gradients and irregular domains. A gradient-enhanced physics-informed neural network (g-PINN) framework is proposed to tackle these challenges, utilizing neural networks that incorporate physical laws and gradient information to enhance its applicability to complex configurations. This combined approach presents a novel framework that integrates classical theory with machine learning, facilitating precise modelling of thermal phenomena in functionally graded cylinders. The findings indicate that both the analytical and machine learning approaches (g-PINN) align closely with presented solutions, precisely capturing the energy equation and more complex boundary conditions.},
  archive      = {J_EAAI},
  author       = {Palash Das and Md Ashraful Islam and Dipayan Mondal},
  doi          = {10.1016/j.engappai.2025.112332},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112332},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Analytical and machine learning approaches for three-dimensional orthotropic functionally graded cylindrical structure in steady heat conduction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust spurious drug–drug interaction detection via chi-square-guided bidirectional attention mechanism. <em>EAAI</em>, <em>162</em>, 112331. (<a href='https://doi.org/10.1016/j.engappai.2025.112331'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spurious drug–drug interactions arising from experimental biases can compromise treatment safety and hinder effective clinical decision-making for patients. However, current molecular representation learning methods still face significant challenges in addressing this problem. First, most graph neural network-based approaches consider only single-direction interactive semantic extraction between drug molecules, failing to capture more granular relationships between drugs fully. Moreover, during training, they are vulnerable to noise from negative sampling and cannot sufficiently leverage the complete drug–drug interaction annotations, resulting in reduced robustness and accuracy in downstream tasks. To this end, we propose a robust spurious DDI detection framework that employs chi-square-guided bidirectional attention to capture fine-grained and bidirectional interaction patterns. First, considering their mutual information flow, a two-way cross-attention mechanism is introduced for a more granular extraction of cross-drug molecular interaction semantic representations through bidirectionally perceiving interactive features between drugs. Second, on the basis of robust minimum covariance determinant theory, we propose a chi-square distribution-based spurious detection method to approximate the correctly annotated drug–drug interactive feature space to a chi-square distribution for a complete feature representation. Extensive experiments on benchmark datasets further validate our method’s effectiveness over state-of-the-art methods, particularly in noisy interference scenarios. Our code is available at https://github.com/AlexCostra/cd .},
  archive      = {J_EAAI},
  author       = {Wei-Yu Shi and Yi-Jia Zhang and Jin-Zhong Ning},
  doi          = {10.1016/j.engappai.2025.112331},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112331},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust spurious drug–drug interaction detection via chi-square-guided bidirectional attention mechanism},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A domain adaptation method to defend chinese textual adversarial attacks via prompt-tuning. <em>EAAI</em>, <em>162</em>, 112330. (<a href='https://doi.org/10.1016/j.engappai.2025.112330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The textual adversarial attack aims to fool existing models into making erroneous predictions by adding strategic perturbations to normal data without affecting the user’s understanding. Recently, methods based on Pre-trained Language Models (PLMs) and Large Language Models (LLMs) have shown promising performance in various Natural Language Processing (NLP) downstream tasks. However, due to significant deviations between the original and perturbed texts, these methods struggle to achieve satisfactory results in defending against textual adversarial attacks, especially in Chinese, which has unique syntactic structures. To address this issue, we propose a domain adaptation method for defending against Chinese textual adversarial attacks through a prompt-tuning model, which effectively mitigates the discrepancy between different domains. Specifically, the original and perturbed texts are treated as the source and target domains, respectively, with the textual adversarial defense task framed as a cross-domain classification problem. The soft prompt-tuning model trained in the source domain is iteratively adapted to uncover the true label information in the target domain. The graph attention network is incorporated to integrate Chinese syntactic structure information with semantic features. Through a voting mechanism on predicted labels generated by the iterative model, soft prompt-tuning is further optimized for cross-domain classification tasks. Extensive experimental results demonstrate the superior effectiveness of our method in Chinese textual adversarial defense tasks compared to baseline methods, including the state-of-the-art fine-tuning approaches for PLMs and LLMs.},
  archive      = {J_EAAI},
  author       = {Yi Zhu and Zhenglong Li and Yun Li and Yunhao Yuan and Jipeng Qiang},
  doi          = {10.1016/j.engappai.2025.112330},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112330},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A domain adaptation method to defend chinese textual adversarial attacks via prompt-tuning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel high-accuracy graph neural network-based rumor detection method. <em>EAAI</em>, <em>162</em>, 112329. (<a href='https://doi.org/10.1016/j.engappai.2025.112329'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rumors spreading on social media platforms result in potential damages. A precise rumor detection mechanism can help form a healthy public opinion environment. In recent years, deep learning-based rumor detection methods, especially graph model-based ones, have risen and reached promising performance. However, there are several defects in existing methods, which limit models from efficiently utilizing the propagation structure. In this paper, we propose a novel rumor detection model, which has high accuracy and reaches state-of-the-art performance. First, we design a powerful comprehensive rumor feature extractor that explicitly overcomes the restriction of previous Graph Neural Networks-based models. Then, by introducing Kernel Subtree features, our model acquires the capability to learn crucial local features from important nodes. Comparative experiments performed on two real-world social media platforms demonstrate that our work reaches state-of-the-art performance, which outperforms the best baseline with 1.6% and 1.9% in accuracy respectively.},
  archive      = {J_EAAI},
  author       = {Xi Xiao and Zeming Wu and Chengzong Cai and Tian Bian and Guangwu Hu and Qing Li and Cheng Huang},
  doi          = {10.1016/j.engappai.2025.112329},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112329},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel high-accuracy graph neural network-based rumor detection method},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Committee of multi-scale nonlinear learning frameworks for accurate stock price forecasting. <em>EAAI</em>, <em>162</em>, 112325. (<a href='https://doi.org/10.1016/j.engappai.2025.112325'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dependable stock price predictions are vital for optimizing economic policies and investment strategies in both national and corporate settings. However, the intrinsic volatility and intricacy of stock prices pose considerable challenges. Thus, this paper introduces a novel Committee of Multi-scale Nonlinear Learning Frameworks (CoML) that employs a three-stage model: decomposition, reconstruction, and prediction. First, a complete ensemble empirical mode decomposition with adaptive noise is adopted to decompose the original stock prices into multiple intrinsic mode functions. Secondly, a fine-to-coarse algorithm is applied to reconstruct the intrinsic mode functions, so as to effectively extract short-term fluctuations and long-term trends. Finally, an ensemble of nonlinear models including bidirectional long short-term memory (BiLSTM), support vector regression (SVR) and multi-layer perceptron (MLP) is used to learn and forecast features extracted to obtain high performance. Experimental results indicate that the model performs exceptionally well in both emerging and developed markets highlighting the innovative capabilities of CoML in highly complex and volatile financial markets. The proposed model is further validated using Model Confidence Set and the results indicate that the model is statistically significant.},
  archive      = {J_EAAI},
  author       = {Qian He and Yanhui Liang and Yu Lin and Dazhi Pan and Yuying Yue},
  doi          = {10.1016/j.engappai.2025.112325},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112325},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Committee of multi-scale nonlinear learning frameworks for accurate stock price forecasting},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning robust brain tumor segmentation under label corruption and data scarcity. <em>EAAI</em>, <em>162</em>, 112322. (<a href='https://doi.org/10.1016/j.engappai.2025.112322'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models for medical image segmentation often struggle with performance issues when datasets are affected by label noise or annotation errors, commonly introduced during manual process or lack of proficiency. These noisy annotations disrupt the loss function, leading to "partially incorrect" gradients that impair the model's learning and overall performance. Additionally, the limited availability of scanned data for training often makes it challenging to develop a robust model. A common approach to address this issue is to leverage similar large annotated datasets. However, differences in dataset distributions can also lead to inconsistencies, introducing erroneous gradients during training and further impacting model performance. To address these challenges, we propose MGR-DAS (Meta-Gradient Reweighting via Direction-Aware Similarity), a novel meta-learning-based approach that can automatically evaluate the reliability of training samples during training using a small, clean subset easily curated from the noisy dataset. Our method quantifies reliability by measuring the cosine similarity between the gradients of noisy training samples and those of the clean subset. Samples with higher gradient alignment are assigned greater weights during training, effectively reducing the impact of noisy labels and improving model robustness. We evaluate our method using three standard metrics for medical image segmentation: the Dice Similarity Coefficient (DSC), the 95th percentile Hausdorff Distance (HD95), and Intersection over Union (IoU). The proposed MGR-DAS achieved an overall 2.4 % improvement in the DSC on the brain tumor segmentation (BraTS, 2021) dataset. Remarkably, even with only 10 clean annotations used in the reweighting algorithm, our method yielded a 28.7 % gain in DSC. In real-world, data-scarce scenarios, our proposed MGR-DAS also improved the overall DSC score by 2.6 % on BraTS pediatric (BraTS-PEDs) and by 1.0 % on BraTS-Africa, demonstrating strong generalizability and robustness. Experimental results confirm that the proposed method reliably identifies noisy data, prioritizes clean data through adaptive weighting, and outperforms existing fine-tuning, curriculum learning techniques, and other meta-learning frameworks commonly employed in classification tasks.},
  archive      = {J_EAAI},
  author       = {Abdulkhalek Al-Fakih and Abbas Mohamed Rezk and Abdullah Shazly and Kanghyun Ryu and Mohammed A. Al-masni},
  doi          = {10.1016/j.engappai.2025.112322},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112322},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning robust brain tumor segmentation under label corruption and data scarcity},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-shot learning augmented slow feature analysis for semantic-aware industrial process fault detection. <em>EAAI</em>, <em>162</em>, 112321. (<a href='https://doi.org/10.1016/j.engappai.2025.112321'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Slow Feature Analysis (SFA) has shown considerable success in the field of industrial process fault detection. Nonetheless, due to its unsupervised nature, SFA relies solely on the normal training data and overlooks the incorporation of prior process knowledge, which consequently diminishes its efficacy in early fault detection. To mitigate this limitation, this paper introduces the concept of Zero-Shot Learning (ZSL) and proposes an improved SFA approach, referred to as ZSL-SFA. This novel method leverages fault semantic representations as auxiliary knowledge to enhance fault detection sensitivity in industrial process monitoring. The ZSL-SFA framework implements a dual-model collaborative monitoring system: (1) a primary SFA model is developed using normal operational data to capture the dynamic characteristics of the process; and (2) a semantic encoding mechanism, grounded in expert knowledge, is devised to build the auxiliary model, where a probabilistic attribute learner adaptively extracts semantic information from fault attribute descriptions, facilitating effective fault knowledge transfer through similarity analysis. The monitoring outcomes from both the primary and auxiliary models are integrated using a Bayesian fusion strategy, culminating in a comprehensive ZSL-SFA monitoring system. The main advantage of this method is its ability to fully exploit prior process knowledge to enhance the basic SFA model without the need for additional labeled fault samples. Experimental validations on the Tennessee-Eastman process simulation platform are performed to indicate that the proposed ZSL-SFA method surpasses the basic SFA method in terms of fault detection performance.},
  archive      = {J_EAAI},
  author       = {Wenjie Yang and Xiaogang Deng and Lumeng Huang and Yuping Cao},
  doi          = {10.1016/j.engappai.2025.112321},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112321},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Zero-shot learning augmented slow feature analysis for semantic-aware industrial process fault detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale embedding with guided attention for medical image analysis. <em>EAAI</em>, <em>162</em>, 112319. (<a href='https://doi.org/10.1016/j.engappai.2025.112319'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate classification of medical images is pivotal for enhancing diagnostic accuracy and optimizing treatment strategies. Traditional methods encounter challenges in delineating clear inter-class boundaries within high-dimensional feature spaces affected by class overlap. This study introduces a Multi-Scale Embedding with Guided Attention (MSEGA) framework based on deep learning autoencoders that integrates innovative guided attention learning mechanisms without explicit target mask supervision for tumor detection and classification. The framework incorporates Multi-scale Feature Extraction Blocks and Depthwise Separable Convolution Blocks to comprehensively capture image features. Through Channel Attention and Spatial Attention mechanisms, the MSEGA method prioritizes critical tumor regions across scales. We also propose a novel interpretable embedding learning loss function to optimize image embeddings, highlighting crucial regions and refining category distinctions. Empirical evaluations on two brain tumor Magnetic Resonance Imaging (MRI) datasets demonstrate our approach surpasses conventional methods including Convolutional Neural Networks and Vision Transformers in classification accuracy and generalizability. These results underscore the framework’s potential as a versatile artificial intelligence-powered tool in medical image analysis.},
  archive      = {J_EAAI},
  author       = {Zeyan Li and Yifei Peng and Yizun Lin},
  doi          = {10.1016/j.engappai.2025.112319},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112319},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-scale embedding with guided attention for medical image analysis},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodality based deep learning method for cancer-related T-cell receptor sequence prediction. <em>EAAI</em>, <em>162</em>, 112318. (<a href='https://doi.org/10.1016/j.engappai.2025.112318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {T-cell receptor sequences (TCR-seq) are closely related to cancers, and in particular, cancer-related TCR-seq are crucial in cancer diagnosis and treatment. Current prediction methods for cancer-related TCR-seq often focus solely on the sequence structure, neglecting its spatial structure. Therefore, we propose a multimodal deep learning method based on parallel and residual structures (MDPR) for the detection of cancer-related TCR-seq. MDPR can effectively integrate the spatial and sequence structure of TCR-seq for accurately identifying cancer-related sequences. First, we introduce a TCR-seq encoding method based on atomic three-dimensional spatial coordinates, allowing for more effective extraction of the spatial structural features of TCR-seq. Second, we use high-dimensional word vectors instead of the amino acid feature vectors traditionally used by other researchers. Third, we pretrain the spatial feature extraction module and then conduct joint training with the sequence feature extraction module. This approach allows the model to better consider the relationship between the two modalities, thereby improving prediction accuracy. Finally, MDPR achieved an area under the curve (AUC) of 0.971 after ten rounds of three-fold cross-validation on the dataset. The AUC of MDPR is 5% higher than that of the previous best method. In short, we propose an artificial intelligence method called MDPR, and apply it to the biomedical field. MDPR can be obtained from https://github.com/biomg/MDPR .},
  archive      = {J_EAAI},
  author       = {Junjiang Liu and Shusen Zhou and Mujun Zang and Chanjuan Liu and Tong Liu and Qingjun Wang},
  doi          = {10.1016/j.engappai.2025.112318},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112318},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodality based deep learning method for cancer-related T-cell receptor sequence prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A combined perspective self-supervised contrastive learning framework for human activity recognition integrating instance prediction and clustering. <em>EAAI</em>, <em>162</em>, 112317. (<a href='https://doi.org/10.1016/j.engappai.2025.112317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) is a significant application for wearable devices, which primarily identifies current human activities by analyzing sequential sensor data. The real-time data recording of wearable devices enables the collection of vast amount of unlabeled data. Utilizing this data for self-supervised contrastive pre-training of HAR models presents a feasible solution to the decline in recognition performance due to limited labeled data. However, traditional contrastive learning frameworks are primarily designed based on positive and negative sample pairs in the image domain. The relatively simple sequence data of HAR is prone to generating incorrect negative pairs, thus pre-training HAR models solely in this manner is unsatisfactory. Given the phenomena described above, this paper proposes an Instance Prediction and Clustering Self-supervised Contrastive Learning Framework (IPCSC) for HAR, considering the characteristics of human activity data. IPCSC circumvents negative sample pairs, instead extracting contrastive information at the instance perspective by prediction tasks among various augmented views of samples and integrating clustering concepts for contrastive learning from a holistic perspective. The primary objective is to enable the model to discern critical information within human activity data and distinguishable features between different activities, thereby improving the model’s pre-training efficacy and enhancing its downstream activity recognition performance. Numerous experimental analyses demonstrate that IPCSC outperforms other self-supervised methods, achieving an average F1-Score performance improvement of 5.65%, 4.11%, and 7.99% over supervised baselines on the UCI-HAR, MobiAct, and MotionSense datasets, respectively, with only 1% of the labeled data.},
  archive      = {J_EAAI},
  author       = {Zhixuan Yang and Kewen Li and Zongchao Huang and Zhifeng Xu and Xinyuan Zhu and Yuan Xiao},
  doi          = {10.1016/j.engappai.2025.112317},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112317},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A combined perspective self-supervised contrastive learning framework for human activity recognition integrating instance prediction and clustering},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised method for learning path-augmented knowledge graph embedding. <em>EAAI</em>, <em>162</em>, 112315. (<a href='https://doi.org/10.1016/j.engappai.2025.112315'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) consist of factual triples that describe relations between entities in the real world. Knowledge graph embedding (KGE) aims to map entities and relations into constantly low-dimensional vectors, which is important for lots of downstream tasks (e.g., KG completion and information retrieval). Current KGE methods primarily rely on explicit structural patterns, neglecting latent contextual semantics behind those structures and resulting in sub-optimal performance. While some methods incorporate additional data (e.g., textual descriptions), such dependencies limit applicability due to additional data requirements. Furthermore, most KGE models suffer from limited supervision with sparse labeled triples, restricting their capacity to learn comprehensive semantic features. Inspired by the simple but effective self-supervised language model word2vec, one interesting question is: Can KGE be performed as a simple self-supervised language model ? To achieve this, we innovatively propose a self-supervised KGE framework that learns entity and relation embeddings by adapting word2vec’s skip-gram objective to path sequences extracted from KGs. Our framework employs separate embedding spaces for entities and relations with an entity-relation mapping mechanism for effective interaction between the two embedding spaces. Further, to enhance the training efficiency, we introduce a markov chain-based negative sampling strategy, which generates semantically meaningful negative samples by preserving the structural contexts along KG paths. Our framework, which is the first attempt to follow the context-based self-supervised idea of language models to conduct KGE tasks, addresses the constraints of label-dependent supervised KGE techniques and obviates the requirement for external information, while simultaneously enabling effective extraction of the implicit contextual semantics inherent in triple structures. Experiments on two widely-used KGE datasets show state-of-the-art performance, demonstrating our framework’s ability to learn semantically rich representations solely from graph structure.},
  archive      = {J_EAAI},
  author       = {Tong Shen and Fu Zhang and Jingwei Cheng},
  doi          = {10.1016/j.engappai.2025.112315},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112315},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A self-supervised method for learning path-augmented knowledge graph embedding},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A single-cell RNA sequencing data imputation method based on non-negative matrix factorization and multi-kernel similarity network fusion. <em>EAAI</em>, <em>162</em>, 112313. (<a href='https://doi.org/10.1016/j.engappai.2025.112313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence-based single-cell RNA sequencing (scRNA-seq) technology is widely used in cell type identification and disease research, but its data often contain a large number of missing values and zero values due to technical limitations and biological differences. These zero values not only affect downstream analysis, but also make it difficult to distinguish technical zero values from biological zero values. Therefore, this paper proposes a scRNA-seq data interpolation method (sc-MKNMF) based on non-negative matrix factorization and multi-kernel similarity network fusion for the first time. This method improves the accuracy of cell clustering by accurately filling some zero values. First, sc-MKNMF uses gene-cell dual-level analysis to distinguish technical zero values from biological zero values, and then calculates the similarity network of multi-kernel fusion of genes and cells respectively. Then, this method uses non-negative matrix factorization combined with similarity network to construct the objective function, and introduces sparse regularization terms to ensure the similarity between genes and cells and improve stability. In addition, sc-MKNMF is also equipped with an efficient optimization algorithm to promote its convergence by continuously updating the objective function. Finally, the verification and comparative experiments on 12 scRNA-seq datasets show that the sc-MKNMF method outperforms other advanced data interpolation methods. In addition, the extension of sc-MKNMF to the two tasks of cell trajectory inference and differentially expressed gene analysis showed significant improvement and excellent versatility.},
  archive      = {J_EAAI},
  author       = {Pei Liu and Cheng Chen and Hao Liu and Jin Gu and Xinya Chen and Ying Su and Zhiyuan Cheng and Xiaoyi Lv and Chen Chen},
  doi          = {10.1016/j.engappai.2025.112313},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112313},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A single-cell RNA sequencing data imputation method based on non-negative matrix factorization and multi-kernel similarity network fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel object detection model for sugar beet cercospora leaf spot in field scenarios based on large kernel decomposition and spatial channel interaction attention. <em>EAAI</em>, <em>162</em>, 112311. (<a href='https://doi.org/10.1016/j.engappai.2025.112311'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cercospora leaf spot (CLS) is a widespread disease that seriously threatens beet yield and sugar quality. Timely detection enables farmers to take early control measures and reduce economic losses. Although artificial intelligence (AI)-based methods are replacing manual inspection in agriculture, CLS detection in complex field environments remains highly challenging due to subtle early-stage symptoms and severe occlusions caused by overlapping leaves and weeds. To address these challenges, this paper presents Cercospora Leaf Spot–You Only Look Once (CLS–YOLO), an enhanced detection model built upon You Only Look Once version 11 (YOLOv11), incorporating novel modules specifically designed for accurate CLS detection under challenging field conditions. To improve the detection of weak and early-stage symptoms, we design the Multi-Scale Large Kernel Decomposition (MSLKD) module, which enhances feature extraction for subtle lesions. Furthermore, we develop the Spatial-Channel Interaction Attention (SCIA) module to mitigate detection errors arising from occlusion and fragmented disease patterns by refining multi-scale feature representations. Experimental results demonstrate CLS–YOLO achieves superior performance, reaching an mAP@0.5 of 73.6% ± 0.2% and an mAP@0.5:0.95 of 40.6% ± 0.3% over five independent runs, outperforming twelve mainstream object detection algorithms while maintaining lightweight efficiency. To validate generalization capability across scenarios, crops, and diseases, we conducted comparative experiments on two public crop disease datasets, where our method achieved superior overall performance. In summary, this study provides an effective AI-driven solution for precise crop disease detection, contributing to the practical advancement of intelligent agriculture.},
  archive      = {J_EAAI},
  author       = {Hualong Dong and Yi Lu and Yurong Qian and Xuefei Ning and Ting Chen and Ke Tang},
  doi          = {10.1016/j.engappai.2025.112311},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112311},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel object detection model for sugar beet cercospora leaf spot in field scenarios based on large kernel decomposition and spatial channel interaction attention},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ElecBench: A large language model benchmark in electric power domain. <em>EAAI</em>, <em>162</em>, 112310. (<a href='https://doi.org/10.1016/j.engappai.2025.112310'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have made substantial advancements in the field of natural language processing, necessitating the development of new benchmarks to accurately track their progress. In this paper, we introduce ElecBench, the first benchmark specifically designed for the electric power domain. ElecBench comprises 24 datasets spanning different scenarios, covering general electric power knowledge and four specific business applications, with a total of 34,030 data entries. Furthermore, we evaluate the performance of a series of open-source Chinese LLMs on ElecBench. Our experiments demonstrate that ElecBench serves as an effective benchmark for electric power scenarios and highlight that existing LLMs require further optimization to gain domain-specific knowledge and achieve better performance.},
  archive      = {J_EAAI},
  author       = {Sai Zhang and Qiaochu Huang and Qiang Zhang and Xiao Liang and Weiwei Liu and Kunlun Gao and Fei Zhou and Congcong Shi},
  doi          = {10.1016/j.engappai.2025.112310},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112310},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ElecBench: A large language model benchmark in electric power domain},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning-based trajectory tracking optimal control for underactuated unmanned surface vehicles under asymmetric input saturation. <em>EAAI</em>, <em>162</em>, 112307. (<a href='https://doi.org/10.1016/j.engappai.2025.112307'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For underactuated unmanned surface vehicles (USVs) under asymmetric input saturation caused by thrust-limit characteristics, as well as unknown dynamics and ocean environmental disturbances, a trajectory tracking optimal control (TTOC) scheme is proposed using the reinforcement learning (RL) method. Through coordinate transformations and mathematical derivation, an underactuated USV motion model is transformed into the standard affine nonlinear form. To address the asymmetric input saturation of underactuated USVs, a new inverse hyperbolic tangent-type penalty function is designed for control inputs, relaxing the assumption of input saturation limits being symmetric. Based on RL methods and adaptive neural networks (NNs), an actor-critic NN framework is developed, with weight update laws designed for NNs. This framework learns the TTOC law for underactuated USVs through the online interaction of actor and critic NNs while adapting to unknown dynamics and disturbances. In particular, a robustifying term is designed and added to the output of an actor NN to compensate for the adverse effects of a lumped residual term, which enhances the robustness of the TTOC law and thereby achieves asymptotic regulation of trajectory tracking errors. Theoretical analyses and simulation results indicate that the proposed TTOC scheme enables underactuated USVs to asymptotically track the desired trajectory.},
  archive      = {J_EAAI},
  author       = {Ziping Wei and Jialu Du},
  doi          = {10.1016/j.engappai.2025.112307},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112307},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reinforcement learning-based trajectory tracking optimal control for underactuated unmanned surface vehicles under asymmetric input saturation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature-enhanced edge-INverse attention network for skin lesion segmentation. <em>EAAI</em>, <em>162</em>, 112306. (<a href='https://doi.org/10.1016/j.engappai.2025.112306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer, particularly melanoma, is one of the most aggressive and deadly forms of cancer with its incidence rising globally. Early detection is crucial for improving survival rates, but the traditional dermatoscopy method is a highly time-consuming and subjective process. To resolve this issue, we propose a novel Feature-Enhanced Edge-INverse attention network (FEEINnet) model that helps to segment the skin lesion region more accurately. FEEINnet consists of three sub-networks: Feature Enhanced Mechanism (FEM) learns and extracts the fine-grained enhanced features from informative channels, the Edge Attention Mechanism (EAM) helps to precisely identify the edges of the lesion region and the INverse Attention Mechanism (INAM) generates inverse attention maps which emphasize the less confident or ambiguous regions thereby increasing the segmentation accuracy iteratively. These three sub-networks collectively help to improve feature extraction, enhance boundary detection, and refine segmentation maps, even in challenging scenarios with varying lesion sizes, shapes and pigmentation. FEEINnet consistently outperforms existing models, achieving a F1-score of 95.55%, 95.53%, and 94.52%; Intersection over Union (IoU) of 92.76%, 92.43%, and 91.34%; and Structural Similarity Index Measure (SSIM) of 94.63%, 93.51%, and 91.85% on the Human Against Machine 10000 (HAM10000), Pedro Hispano Hospital ( P H 2 ), and International Skin Imaging Collaboration 2018 (ISIC2018) datasets, respectively. The obtained results demonstrate that the proposed model has a greater ability to segment complex skin lesions more accurately.},
  archive      = {J_EAAI},
  author       = {Shivamm Warambhey and Aravindkumar Sekar},
  doi          = {10.1016/j.engappai.2025.112306},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112306},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature-enhanced edge-INverse attention network for skin lesion segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A severity indicator for unsupervised fault severity shift detection of heating, ventilation, and air conditioning sub-system faults using a novel adaptive feature weighing method. <em>EAAI</em>, <em>162</em>, 112305. (<a href='https://doi.org/10.1016/j.engappai.2025.112305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault-free functioning of Heating, Ventilation, and Air Conditioning (HVAC) systems is essential for reducing energy waste in modern-day buildings. Hence, data-driven approaches for HVAC fault detection have gained popularity. Faults become more severe with time. Fault detection reveals the presence of an anomaly, but it does not convey how critical the fault severity is. Fault severity indication provides this essential context, enabling urgent resource allocation to more severe faults, adding practical significance. However, faults being rare, obtaining substantial data at different severity levels to train supervised Machine Learning models is a realistic challenge. Therefore, we propose a method for estimating fault severity in an unsupervised setting. We define a robust Severity Indicator (SI) that reflects the shift in the severity levels of a fault. First, we define a healthy domain boundary for fault-free data using One-Class Support Vector Machines. SI scores are then computed using a novel adaptive feature weighing algorithm that assigns weights to individual features, adaptively, for every fault. We focus on detecting the shift in severity, rather than quantifying it. The study of the robustness of SI for different faults in HVAC subsystems, chillers, and air handling units (AHUs) yields consistently promising results. Our comparative analysis shows that our method outperforms the unweighted approach and existing state-of-the-art techniques for fault severity estimation. Notably, our method excels in detecting low-severity faults, addressing a common limitation in current methods.},
  archive      = {J_EAAI},
  author       = {Ramnath V. Prabhu Bam and Rajesh S. Prabhu Gaonkar and Clint Pazhayidam George},
  doi          = {10.1016/j.engappai.2025.112305},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112305},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A severity indicator for unsupervised fault severity shift detection of heating, ventilation, and air conditioning sub-system faults using a novel adaptive feature weighing method},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient anchor-free model for ore particle size detection. <em>EAAI</em>, <em>162</em>, 112304. (<a href='https://doi.org/10.1016/j.engappai.2025.112304'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate detection of ore size is crucial in mineral processing, directly impacting equipment efficiency and product quality. However, traditional anchor-based models often struggle with the irregular shapes and varying scales of ore particles, resulting in limited performance. To overcome these challenges, an anchor-free detection framework was proposed. It incorporates a cross-stage partial bottleneck and a spatial pyramid pooling cross-stage partial connections (SPPCSCP-DualConv), both enhanced with dual convolution, to improve feature extraction and multi-scale fusion. In the backbone, the dual convolution module combines group convolution with heterogeneous convolution to improve feature diversity. The SPPCSCP-DualConv module further enhances feature representation in complex backgrounds. Additionally, a simplified path aggregation network (simPANet) feature fusion module is employed in the neck to refine the integration of multi-scale features. The proposed model was trained using a combination of binary cross-entropy, complete intersection over union (IoU), and distribution focal loss to optimize detection accuracy. The proposed model achieved a mean average precision of 86.80 % at an IoU threshold of .5 and 78.50 % across IoU thresholds from .5 to .95, surpassing existing methods while maintaining a lightweight architecture with only 10.10 million parameters and 89.45 giga floating point operations per second. Ablation studies confirmed the effectiveness of the simPANet and SPPCSPC-DualConv modules in enhancing feature representation. Generalization tests across mining sites with similar distributions demonstrated strong performance, although limitations remain for exceptionally large ore blocks due to dataset bias. The proposed model significantly improved the accuracy and efficiency of ore particle size detection, providing reliable real-time insights to improve grinding control and mineral processing operations.},
  archive      = {J_EAAI},
  author       = {Kanghui Zhang and Qingkai Wang and Guobin Zou and Jiawei Yang and Tao Song and Yang Liu and Daoxi Liu},
  doi          = {10.1016/j.engappai.2025.112304},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112304},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient anchor-free model for ore particle size detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Propeller fault-detection method for electric-propulsion aircraft using motor signals and generative model-based semi-supervised learning. <em>EAAI</em>, <em>162</em>, 112301. (<a href='https://doi.org/10.1016/j.engappai.2025.112301'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failures in propulsion components, such as propellers, can critically affect flight safety; thus, early failure detection, preferably before flight, is essential. Traditional fault-diagnosis methods typically rely on additional sensors or operational data, which may not be available or practical in all situations. This study addresses these challenges by introducing motor-electric-signal-based fault diagnosis that is independent of airframe configuration and can detect faults, even when the aircraft is not in operation. However, difficulties arise owing to poor class variance in motor-electric-signal data and the challenge of obtaining fault data. To overcome these issues, a semi-supervised learning model based on a modified variational autoencoder-generative adversarial network (VAE-GAN) is proposed, which predicts faults using only normal motor-electric-signal data. Additionally, a new preprocessing method and patch-based ensemble inference technique are introduced to improve the poor class-variance characteristics of the data, thereby enhancing the prediction performance. This work demonstrates that propeller faults can be successfully diagnosed using motor-electric signals without the need for additional sensors or fault-data acquisition.},
  archive      = {J_EAAI},
  author       = {Sanga Lee and Dohyeong Kim and Minkyun Noh and Shinkyu Jeong and Jikang Kong and Youngjun Yoo},
  doi          = {10.1016/j.engappai.2025.112301},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112301},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Propeller fault-detection method for electric-propulsion aircraft using motor signals and generative model-based semi-supervised learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight wood defect segmentation network via multi-dimension boundary perception and guidance. <em>EAAI</em>, <em>162</em>, 112300. (<a href='https://doi.org/10.1016/j.engappai.2025.112300'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wood surface defect segmentation is extremely critical for defect refinement and quality control of wooden products. However, it is a challenging task to develop an efficient method with current algorithms due to the complicated characteristics of wood defects with obscure boundary, intraclass difference and interclass similarity. To address these issues, a lightweight network via multi-dimension boundary perception and guidance is proposed for precise segmentation of wood defects. At first, based on the Segformer, a boundary prediction branch is added to enrich detailed boundary information in the encoder, and supervised by the Gaussian signal and cosine similarity, to balance the effect of the boundary gradient information. Then, a double-flow enhancing module is designed to integrate the adjacent level features, by embedding two enhancing paths, to adaptively generate discriminative information of the defects. Finally, a binary segmentation head following the predicted map is introduced to strengthen the penalty for the false prediction results of the boundary. Experimental results demonstrate the proposed method outperforms the state-of-the-arts on our wood surface defect dataset, as well as on three public datasets.},
  archive      = {J_EAAI},
  author       = {Yuhang Zhu and Ye Lin and Zhezhuang Xu and Dan Chen and Kunxin Zheng and Yazhou Yuan},
  doi          = {10.1016/j.engappai.2025.112300},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112300},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight wood defect segmentation network via multi-dimension boundary perception and guidance},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse view tomographic reconstruction of elongated objects using learned primal-dual networks. <em>EAAI</em>, <em>162</em>, 112295. (<a href='https://doi.org/10.1016/j.engappai.2025.112295'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the wood industry, logs are commonly quality screened by discrete X-ray scans on a moving conveyor belt from a few source positions. Typically, the measurements are obtained in a single two-dimensional (2D) plane (a “slice”) by a sequential scanning geometry. The data from each slice alone does not carry sufficient information for a three-dimensional tomographic reconstruction in which biological features of interest in the log are well preserved. In the present work, we propose a learned iterative reconstruction method based on the Learned Primal-Dual neural network, suited for sequential scanning geometries. Our method accumulates information between neighbouring slices, instead of only accounting for single slices during reconstruction. Evaluations were performed by training U-Nets on segmentation of knots (branches), which are crucial features in wood processing. Our quantitative and qualitative evaluations show that with as few as five source positions our method yields reconstructions of logs that are sufficiently accurate to identify biological features like knots (branches), heartwood and sapwood.},
  archive      = {J_EAAI},
  author       = {Buda Bajić and Johannes A.J. Huber and Benedikt Neyses and Linus Olofsson and Ozan Öktem},
  doi          = {10.1016/j.engappai.2025.112295},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112295},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sparse view tomographic reconstruction of elongated objects using learned primal-dual networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep Q-network-driven multi-objective evolutionary algorithm for distributed heterogeneous hybrid flow shop scheduling with worker fatigue. <em>EAAI</em>, <em>162</em>, 112292. (<a href='https://doi.org/10.1016/j.engappai.2025.112292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hybrid flow shop scheduling problem (HFSP) is a prominent challenge in advanced manufacturing systems. Existing research often overlooks the impact of workers in production shops or treats worker fatigue as a static parameter, failing to capture its nonlinear accumulation and recovery effects on processing efficiency. However, with the advent of Industry 5.0, there has been a growing emphasis on the critical role of human factors in production scheduling. As a result, designing an effective algorithm for HFSP that considers human factors has become a prominent research focus. In this paper, an extended distributed heterogeneous hybrid flow shop scheduling problem with the dynamic effects of worker fatigue (DHHFSP-WF) is investigated. To address this problem, a Deep Q-Network-based multi-objective optimization algorithm (DQNMOEA) is designed to minimize makespan, total energy consumption (TEC), and total worker idle time (WIT). In DQNMOEA, a four-dimensional vector encoding scheme considering worker allocation represents solution, and a reconstruction strategy ensures initial population quality and diversity. Moreover, an improved order crossover, two-point crossover, and a segment-based recombination mutation method are proposed to enhance the global search performance of the algorithm. Then, a problem-specific local search strategy is designed for each layer of the vector, allowing the Deep Q-Network (DQN)-based adaptive decision-making mechanism to perform local perturbations on the current non-dominated solutions in the most suitable dimensions. Finally, seven algorithms are adopted to make a comparison on 36 sets of instances, the experimental results indicate that DQNMOEA exhibits competitive performance in solving DHHFSP-WF.},
  archive      = {J_EAAI},
  author       = {Jianlin Zhang and Longbin Ma and Wu Zhao and Jie Cao and Zuohan Chen and Tianpeng Xu},
  doi          = {10.1016/j.engappai.2025.112292},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112292},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep Q-network-driven multi-objective evolutionary algorithm for distributed heterogeneous hybrid flow shop scheduling with worker fatigue},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An angle-enhanced deep learning framework for thermal defect diagnosis in overhead transmission line composite insulators. <em>EAAI</em>, <em>162</em>, 112285. (<a href='https://doi.org/10.1016/j.engappai.2025.112285'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to long-term outdoor exposure, composite insulators are susceptible to degradation and abnormal temperature rise, making Unmanned Aerial Vehicle (UAV)-based infrared inspections essential for effective monitoring. However, traditional manual interpretation of these images is inefficient and subjective. To improve detection automation and accuracy, we propose an intelligent detection method for composite insulators in infrared images based on an improved You Only Look Once version 11 (YOLOv11) model. The proposed approach introduces Oriented Bounding Boxes (OBBs) for annotation and designs an Angle-Enhanced Probabilistic Intersection over Union (AE-ProbIoU) loss function to enhance the model's ability to detect rotated objects. Experimental results demonstrate that the proposed Angle-Enhanced You Only Look Once (AE-YOLO) model achieves a mAP50:95 of 94.0 % and an angle prediction accuracy of 94.3 %. In addition, a temperature extraction module based on the OBBs is developed to accurately derive the temperature profile of the insulator core rod. This method significantly enhances the intelligence level of infrared image analysis for composite insulators and provides technical support for condition assessment and fault prediction in power transmission lines.},
  archive      = {J_EAAI},
  author       = {Xinzhe Yu and Zhenan Zhou and Yu Deng and Kun Zhang and Chen Gu and Zheyuan Liu and Songsong Zhou},
  doi          = {10.1016/j.engappai.2025.112285},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112285},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An angle-enhanced deep learning framework for thermal defect diagnosis in overhead transmission line composite insulators},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian bidirectional long short-term memory-based kinematics-dynamics fusion for fault-tolerant vehicle state estimation under yaw rate sensor failures. <em>EAAI</em>, <em>162</em>, 112283. (<a href='https://doi.org/10.1016/j.engappai.2025.112283'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate estimation of vehicle states is a fundamental component of vehicle stability control systems. To address the issue of inaccurate estimation of vehicle state parameters resulting from yaw rate sensor failures, this study proposes a three-mode collaborative fault-tolerant state estimation method based on Bayesian Bidirectional Long Short-Term Memory (BiLSTM) kinematics-dynamics fusion. First, the kinematics-based method is established using the kinematics model. Second, the dynamics-based method is designed by integrating the Unscented Kalman Filter (UKF) with the dynamics model. Subsequently, a BiLSTM network fusion model based on Bayesian optimization is presented. The model utilizes estimates from kinematic and kinetic methods as a priori inputs and combines the bidirectional information capturing capability of BiLSTM with hyperparameter tuning from Bayesian optimization. The results indicate that when the yaw rate sensor fails, the proposed method achieves an average Root Mean Square Error (RMSE) of 0.0276 km per hour (km/h) for longitudinal speed, 0.0008 radian (rad) for side slip angle, and 0.0072 radian per second (rad/s) for yaw rate across all scenarios. This performance demonstrates a superiority over various maneuvers. This paper combines kinematics, dynamics, and deep learning to provide a reliable solution for fault-tolerant estimation of vehicle states.},
  archive      = {J_EAAI},
  author       = {Min Gao and Jiaqi Li and Wei Wang and Renguang Wang and Jin Luo and Jing Li},
  doi          = {10.1016/j.engappai.2025.112283},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112283},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Bayesian bidirectional long short-term memory-based kinematics-dynamics fusion for fault-tolerant vehicle state estimation under yaw rate sensor failures},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical binary diffing with inductive code representation learning with graph sampling-and-aggregate. <em>EAAI</em>, <em>162</em>, 112279. (<a href='https://doi.org/10.1016/j.engappai.2025.112279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary program diffing, or simply binary diffing, is a type of program analysis technique that quantifies the similarity between two binary programs to derive their differences. In particular, binary diffing is an essential technique for uncovering vulnerabilities and potential attack vectors in industrial control systems, where patch deployment is complicated by closed and restricted environments. Studies on binary diffing can be broadly categorized into dynamic analysis-based, static analysis-based, and neural network-based approaches. Each category of existing studies has its shortcomings, including limited coverage, low accuracy, and issues with on-demand learning. In this paper, we propose the binary diffing with sampling-and-aggregate, a hierarchical binary diffing model that generates inductive code representations based on graph sampling-and-aggregate. Our model sequentially produces instruction-level embedding, block-level embedding, and function-level embedding from the inter-procedural control flow graph of a given program, and then performs hierarchical code diffing based on these embeddings. We formally define the detailed models and present the algorithm of hierarchical binary diffing. Additionally, we conduct a thorough analysis of this algorithm, deriving several advantages. We implemented a prototype and evaluated it on a large-scale dataset in a cross-version, cross-optimization, and obfuscation settings. Our prototype showed F1-scores up to 0.96 and 0.968 in cross-version setting for function and basic block diffing, respectively. Also, our method demonstrated its robustness over several binary obfuscations. In conclusion, our proposal, which generates basic block- and function-level embedding by considering the control flow, has solid advantages on binary diffing and shows the robustness on the binary tampering.},
  archive      = {J_EAAI},
  author       = {Seungho Jeon and Kijong Koo and Daesung Moon and Jung Taek Seo},
  doi          = {10.1016/j.engappai.2025.112279},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112279},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical binary diffing with inductive code representation learning with graph sampling-and-aggregate},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear excavation load prediction of hydraulic excavator based on gated recurrent unit neural network. <em>EAAI</em>, <em>162</em>, 112278. (<a href='https://doi.org/10.1016/j.engappai.2025.112278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Excavator arms are integral to the mining and construction industries, where real-time excavation load prediction is a critical element for the advancement of automated excavation technology. This study presents a novel Physics-guided Neural Network (PGNN) designed to predict the excavating force of hydraulic cylinders used in earthwork excavation. The PGNN model synergizes the physical load model of excavators with a Gated Recurrent Unit (GRU) neural network and is optimized using the Hyperband algorithm to attain both high-speed and precise forecasting. Through comparative experiments, the study validates the PGNN model's ability to achieve optimal response speed and precision in predicting excavation loads. Additionally, the predictive performance of the PGNN model is assessed via a Hardware-in-the-loop (HIL) test, conducted within the context of an actual excavation experiment. This research introduces a promising approach that seamlessly integrates physics-based modeling with machine learning techniques, facilitating real-time load forecasting for excavators. The findings pave the way for more efficient and precise excavation processes, with implications for the broader fields of mining and construction automation.},
  archive      = {J_EAAI},
  author       = {Jinshi Chen and Yue Yu and Dongyang Huo and Han Zhang and Jingyan Wang},
  doi          = {10.1016/j.engappai.2025.112278},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112278},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Nonlinear excavation load prediction of hydraulic excavator based on gated recurrent unit neural network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Plug-and-play fine grained neural cognitive diagnosis framework. <em>EAAI</em>, <em>162</em>, 112276. (<a href='https://doi.org/10.1016/j.engappai.2025.112276'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive diagnosis (CD) is a core task in intelligent education, which accurately assesses students’ mastery of specific knowledge concepts (KCs) by analyzing their answer records. However, existing methods mainly rely on explicit interaction data and use diagnostic models for automatic knowledge proficiency inference. These methods lack systematic optimization for fine-grained knowledge level representation, making it difficult to fully reflect students’ true learning status. To address this, this paper introduces a Plug-and-Play F ine Grained N eural C ognitive D iagnosis Framework (FNCD) with Knowledge-Level Constraint Awareness . The framework combines a knowledge proficiency evaluation module with students’ answer records and a Q-matrix to statically assess knowledge mastery. It uses a student similarity construction method based on random grouping to reveal latent learning pattern associations. Additionally, it employs a multi-scale relational learning strategy and a Top-k attention-enhanced graph network mechanism to dynamically adjust the student similarity relationship network, accurately modeling the complex learning relationships between students. Ultimately, a joint training mechanism is used to optimize the outputs of each module, significantly improving the rationality, interpretability, and accuracy of CD. The experimental results demonstrate that FNCD, as an artificial intelligence-driven plug-and-play module, can be effectively integrated into existing CD models to enhance the modeling of fine-grained knowledge mastery and improve diagnostic accuracy, showcasing the application potential of artificial intelligence in personalized education.},
  archive      = {J_EAAI},
  author       = {Xinjie Sun and Qi Liu and Kai Zhang and Weiyin Gong and Shuanghong Shen and Fei Wang and Yan Zhuang and Meikai Bao and Shijin Wang and Yuling Ma and Enhong Chen},
  doi          = {10.1016/j.engappai.2025.112276},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112276},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Plug-and-play fine grained neural cognitive diagnosis framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Open-vocabulary object detection via neighboring region attention alignment. <em>EAAI</em>, <em>162</em>, 112270. (<a href='https://doi.org/10.1016/j.engappai.2025.112270'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nature of diversity in real-world environments necessitates neural network models to expand from closed category settings to accommodate novel emerging categories. In this paper, we study open-vocabulary object detection (OVD), which facilitates the detection of novel object classes under the supervision of only base annotations and open-vocabulary knowledge. However, we find that the inadequacy of distilled information from the detector head during the alignment process inevitably constrains the performance of recent distillation-based OVD strategies. To this end, we propose Neighboring Region Attention Alignment (NRAA), which performs alignment within the attention mechanism to boost the open-vocabulary inference. Specifically, for a given proposal region, we randomly explore the neighboring boxes to capture the surrounding contextual vocabulary knowledge. Then, a set of regional token features, encompassing both the proposal and neighboring regions, utilize our proposed Neighboring Region Attention (NRA) to extract interaction information. Finally, this information is seamlessly provided to the distillation procedure to assist the alignment between the detector and the pre-trained vision-language models (VLMs). Extensive experiments validate that our proposed model exhibits superior performance on open-vocabulary benchmarks.},
  archive      = {J_EAAI},
  author       = {Sunyuan Qiang and Xianfei Li and Yanyan Liang and Wenlong Liao and Tao He and Pai Peng},
  doi          = {10.1016/j.engappai.2025.112270},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112270},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Open-vocabulary object detection via neighboring region attention alignment},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A time and frequency convolutional autoencoder for anomaly detection in industrial robots based on inertial measurement unit error calibration. <em>EAAI</em>, <em>162</em>, 112269. (<a href='https://doi.org/10.1016/j.engappai.2025.112269'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of industrial robots, ensuring operational reliability and Long-Term Autonomy hinges on the accurate detection of anomalies. However, this sample difference due to noise, joint random errors and sensor errors increases the challenge of robot anomaly detection. To address this problem, an unsupervised deep learning method based on inertial measurement unit (IMU) error calibration is proposed. Firstly, the attitude signals acquired by the IMU from the end of the robot were calibrated using Kalman filtering. The three dimensional (3D) free acceleration was corrected based on the calibrated attitude signal and the calibrated 3D free acceleration signal was used as a signal sample. Secondly, a time and frequency convolutional autoencoder model (TFCAE) is proposed. And the distribution of the different component signals is fitted by stacking multiple encoder modules and 3D-TFCAE is used for 3D free acceleration signal reconstruction model. Then, the error sphere radius is calculated based on the reconstruction error of the 3D free acceleration signal. And the error sphere radius is used as the anomaly detection threshold to realize the robust detection of different types of anomalies. The model was evaluated on a constructed anomaly dataset. This study contributes an innovative 3D-TFCAE architecture, integrating Kalman filtering with time-frequency feature fusion, markedly enhancing anomaly detection in complex signal environments. Experimental findings reveal that 3D-TFCAE significantly outperforms 18 baseline models, improving detection accuracy by about 20 %–40 %, offering an effective solution for high-precision anomaly detection in industrial robots. The code for this project is available at https://github.com/LJlong977/3DTFCAE .},
  archive      = {J_EAAI},
  author       = {Jianlong Li and Xiaoqin Liu and Xing Wu and Dongxiao Wang and Kai Xu and Yashan Li},
  doi          = {10.1016/j.engappai.2025.112269},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112269},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A time and frequency convolutional autoencoder for anomaly detection in industrial robots based on inertial measurement unit error calibration},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight citrus detection and counting method based on deep learning model. <em>EAAI</em>, <em>162</em>, 112268. (<a href='https://doi.org/10.1016/j.engappai.2025.112268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Picking robots have become an important development direction of smart agriculture, and the accurate detection, counting and lightweight deployment of fruits are the technical basis for realizing robot picking. However, due to complex weather conditions and the possible mutual occlusion between branches and citrus, it is challenging to accurately detect and count citrus in orchards. This study proposes a lightweight small target detection model for detecting and counting citrus, and deploys it on the citrus detection platform. The model first introduces FasterNet Block into the cross-stage partial feature fusion module of the backbone network to reduce the number of parameters and calculations while improving the detection accuracy of the network. Secondly, a multi-scale attention mechanism is added to the backbone network to enhance the feature extraction ability of the network. Finally, a bounding box loss function based on a dynamic non-monotonic focusing mechanism is used to increase the model convergence speed and further improve the model accuracy. Experimental results show that the model has an accuracy of 92.7%, an average precision of 91.7%, and a model size of only 5.37 megabytes. The lightweight model is applied to the citrus detection platform. Based on this application, a citrus counting method is proposed, which obtains a mean absolute error (MAE) of 0.92, a root mean square error (RMSE) of 1.28, a determination coefficient ( R 2 ) of 0.98, and a frame rate of 80.6 per second, which meets the requirements of real-time citrus detection and counting. This provides technical support for the subsequent deployment and counting research of picking robots.},
  archive      = {J_EAAI},
  author       = {Jiqing Chen and Mingchang Zhang and Bin Lu and Quan Chen and Zhiwu Jiang and Peilin Li and Jingyao Gai},
  doi          = {10.1016/j.engappai.2025.112268},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112268},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight citrus detection and counting method based on deep learning model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Medical image fusion for high-level analysis: A mutual enhancement framework for unaligned photoacoustic tomography and magnetic resonance imaging. <em>EAAI</em>, <em>162</em>, 112259. (<a href='https://doi.org/10.1016/j.engappai.2025.112259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photoacoustic tomography (PAT) offers optical contrast, whereas magnetic resonance imaging (MRI) excels in imaging soft tissue and organ anatomy. The fusion of PAT with MRI holds promising application prospects due to their complementary advantages. Existing image fusion has made considerable progress in pre-registered images, yet spatial deformations are difficult to avoid in medical imaging scenarios. More importantly, current algorithms focus on visual quality and statistical metrics, thus overlooking the requirements of high-level tasks. To address these challenges, we propose an unsupervised fusion model, termed PAMRFuse+, which integrates image generation and registration. Specifically, a cross-modal style transfer network is introduced to simplify cross-modal registration to single-modal registration. Subsequently, a multi-level registration network is employed to predict displacement vector fields. Furthermore, a dual-branch feature decomposition fusion network is proposed to address the challenges of cross-modal feature modeling and decomposition by integrating modality-specific and modality-shared features. PAMRFuse+ achieves satisfactory results in registering and fusing unaligned PAT–MRI datasets. Moreover, for the first time, we evaluate the performance of medical image fusion with multi-organ instance segmentation. Extensive experimental demonstrations reveal the advantages of PAMRFuse+ in improving the performance of medical image analysis tasks.},
  archive      = {J_EAAI},
  author       = {Yutian Zhong and Jinchuan He and Zhichao Liang and Shuangyang Zhang and Qianjin Feng and Lijun Lu and Li Qi},
  doi          = {10.1016/j.engappai.2025.112259},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112259},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Medical image fusion for high-level analysis: A mutual enhancement framework for unaligned photoacoustic tomography and magnetic resonance imaging},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Max–Min pooling and squeeze excitation lightweight bidirectional mamba for image classification. <em>EAAI</em>, <em>162</em>, 112246. (<a href='https://doi.org/10.1016/j.engappai.2025.112246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address challenges stemming from the quadratic computational complexity, slow execution speed, and high memory consumption of Transformer models, we propose a novel image classification method: Max–Min Pooling and Squeeze Excitation Lightweight Bidirectional Mamba(MMPSELMamba). The core artificial intelligence innovations include: (1) We design a max–min pooling mechanism that synergistically preserves high-activation foreground features through max-pooling and low-intensity contextual details via min-pooling. This approach addresses the information loss problem in conventional single-mode pooling methods; (2) Inspired by squeeze-enhanced Axial Transformer(SeaFormer), we design an axial squeeze excitation module that compresses redundant features along both vertical and horizontal dimensions while enhancing discriminative feature refinement; (3) Building upon recent advances in sequence modeling, we replace self-attention with a bidirectional Mamba architecture based on state space models (SSM), achieving linear complexity in the model of long-range dependencies; (4) Our novel multi-scale integration unit combines upsampling, concatenation, and downsampling operations to optimize feature fusion while minimizing computational overhead. For engineering applications, MMPSELMamba is specifically designed for resource-constrained environments such as edge devices and mobile vision systems. By integrating depthwise separable convolutions and lightweight SSM operations, it achieves a 36% parameter reduction and a 16% lower computational load compared to SeaFormer, while maintaining competitive accuracy. Experiments on public datasets validate its deployment potential in real-world scenarios like autonomous drones and embedded surveillance. Confusion matrices and heatmap visualizations further confirm the superior performance of the MMPSELMamba method. Our code can be gained from: https://github.com/yalemitter/MMPSELMamba-main .},
  archive      = {J_EAAI},
  author       = {Senlin Chi and Zhiwen Wang and Lianyuan Jang and Mengsi Gong},
  doi          = {10.1016/j.engappai.2025.112246},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112246},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Max–Min pooling and squeeze excitation lightweight bidirectional mamba for image classification},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stacked machine learning-based probabilistic seismic demand and risk assessment of railway embankments with variable slopes. <em>EAAI</em>, <em>162</em>, 112245. (<a href='https://doi.org/10.1016/j.engappai.2025.112245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate seismic risk assessment of railway embankments is critical for risk mitigation, seismic design, and emergency planning. However, conventional methods often suffer from computational inefficiency and complexity. This study proposes a novel machine learning (ML) framework to rapidly and accurately evaluate probabilistic seismic demand and risk for railway embankments. Latin hypercube sampling is utilised to generate representative soil parameter samples to construct numerical models for simulating dynamic responses under near-fault pulse-like ground motions. The peak permanent settlement (PPS) of the embankment surface is used as the key performance metric. Multiple ML models, including decision trees, random forests (RFs), extreme gradient boosting (XGBoost), artificial neural networks (ANNs), and a stacked ML model that integrates RFs, XGBoost, and ANNs, are trained and compared. The stacked ML model outperforms the other models and achieves the highest predictive accuracy for the PPS. SHapley Additive exPlanations are used to identify the velocity spectrum intensity (VSI) and the internal friction angle of the embankment as the most influential factors. Seismic fragility and risk curves are subsequently developed. The VSI and a power-law seismic hazard function are combined to estimate the annual exceedance probabilities for three seismic design criteria levels. The proposed ML framework significantly enhances the efficiency of seismic risk analysis while maintaining high precision, thereby providing a transformative approach for the seismic assessment of railway embankments.},
  archive      = {J_EAAI},
  author       = {Pan Si and Liang Tang and Shuang Tian and Xianzhang Ling and Yanfang Liu},
  doi          = {10.1016/j.engappai.2025.112245},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112245},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Stacked machine learning-based probabilistic seismic demand and risk assessment of railway embankments with variable slopes},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantization-based deep diversified ensemble for medical image segmentation. <em>EAAI</em>, <em>162</em>, 112242. (<a href='https://doi.org/10.1016/j.engappai.2025.112242'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in fully convolutional networks (FCNs) have significantly improved medical image segmentation. Ensemble methods are often used to further enhance performance, with diversity among learners being a critical factor. However, many current approaches focus on diversifying training samples or predictions while overlooking the diversity of internal multi-scale features. This oversight can lead to high correlations among features across different learners, limiting overall effectiveness. Additionally, traditional quantization methods aim to minimize accuracy loss by maintaining a rigid quantization process. This rigidity can eliminate the randomness introduced by quantization, further reducing ensemble diversity and effectiveness. In this paper, we propose a novel approach called Quantization-based Deep Diversified Ensemble (QDD-Ens) for medical image segmentation. Our method enhances the diversity of internal features among ensemble learners through two mechanisms: deep diversified loss, which focuses on feature diversity rather than segmentation accuracy, and deep diversified quantization, which preserves beneficial randomness in quantization process. Furthermore, QDD-Ens facilitates a deeper form of ensemble learning by employing a meta-learner to integrate diversified features at multiple resolution levels from various base learners, which are diversified by two above diversify enhancement mechanisms. Extensive experiments on five public medical image segmentation datasets show that our method significantly improves segmentation accuracy and outperforms existing ensemble techniques. The source code is publicly available to support future research. ( https://github.com/JerRuy/QDD-Ens )},
  archive      = {J_EAAI},
  author       = {Jiawei Zhang and Jialin Wang and Qi Wang and Yanchun Zhang and Weihong Han and Yangyang Mei and Yiyu Shi and Jian Zhuang and Meiping Huang and Xiaowei Xu},
  doi          = {10.1016/j.engappai.2025.112242},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112242},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Quantization-based deep diversified ensemble for medical image segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning methods comparison by using statistical tests in solar energy forecasting based on weather features. <em>EAAI</em>, <em>162</em>, 112239. (<a href='https://doi.org/10.1016/j.engappai.2025.112239'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Climate change necessitates precise solar forecasting due to its weather-dependent intermittency. Key parameters - temperature, visibility, altitude, pressure, and wind speed - were analyzed using non-parametric tests. We prioritized short-term weather patterns over random data splitting for enhanced accuracy.Non-parametric tests, such as the Kolmogorov-Smirnov test, were used to assess data normality and select highly correlated features. Principal Component Analysis (PCA) reduces dataset dimensionality while preserving critical trends. Various machine learning approaches were evaluated, including: weighted linear regression (both with and without dimensionality reduction), boosted regression trees, and deep learning architectures-comprising both fundamental models (Convolutional Neural Networks [CNNs] and Recurrent Neural Networks [RNNs]) and advanced hybrid architectures (Temporal Convolutional Networks (TCN) Convolutional Neural Network-Long Short-Term Memory network (CNN-LSTM). All models were optimized through systematic hyperparameter tuning to enhance predictive performance, reduce computational complexity, and improve learning convergence rates. Special attention was given to addressing vanishing gradient problems in deep neural network implementations. Results show TCN outperform other deep learning models, achieving lower training and testing errors with fewer parameters and reduced time complexity. CNN-LSTM models, designed for spatial-sequence prediction, perform well but require more parameters and computational time. The lowest test and training errors belong to CNN-LSTM and TCN, with approximately 9 % and 2 % lower than the maximum amount, respectively. A trade-off between model complexity, error rates, and computational efficiency must be considered when selecting the optimal approach. Since relevant weather features vary by location, the proposed methodology serves as an adaptable algorithm for solar energy prediction in diverse geographical regions.},
  archive      = {J_EAAI},
  author       = {Mohammadreza pourmir and Seyedeh Mohadeseh Miri},
  doi          = {10.1016/j.engappai.2025.112239},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112239},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning methods comparison by using statistical tests in solar energy forecasting based on weather features},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive chemical industrial processes fault detection model based on sparse filtering-based improved mixed-gaussian probabilistic principal component analysis considering low-probability events. <em>EAAI</em>, <em>162</em>, 112236. (<a href='https://doi.org/10.1016/j.engappai.2025.112236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic Principal Component Analysis (PPCA) is widely used in process monitoring. However, its underlying assumption that data follows a Gaussian distribution limits its effectiveness in handling Low Probability Events (LPEs), which often deviate from this assumption. To address this challenge, we propose a novel method called Sparse Filtering-based Improved Mixed-Gaussian Probabilistic Principal Component Analysis (SFIMPPCA) for enhanced LPEs detection. First, a Sparse Filtering (SF) preprocessing technique with an incremental structure is employed to extract the most discriminative features. Second, to address the distortion caused by LPEs, a dynamic ratio correction mechanism based on statistical variability is introduced, followed by a newly designed Mixed-Gaussian Probabilistic Principal Component Analysis (MPPCA). Third, a Bayesian Optimization Algorithm (BOA) is applied to automatically adjust control limits, enhancing the accuracy and reliability of fault detection. The effectiveness of the proposed method is validated using the Tennessee Eastman (TE) process and the Tin Chemical Process (TCP). Experimental results demonstrate that the proposed method significantly improves performance under LPEs conditions, achieving a 10%–12% improvement in most cases.},
  archive      = {J_EAAI},
  author       = {Chuangyan Yang and Jiande Wu and Peng Li and Xun Lang and Mingxi Ai and Hancheng Wang},
  doi          = {10.1016/j.engappai.2025.112236},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112236},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive chemical industrial processes fault detection model based on sparse filtering-based improved mixed-gaussian probabilistic principal component analysis considering low-probability events},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic graph neural network with historic-sequential information representation. <em>EAAI</em>, <em>162</em>, 112234. (<a href='https://doi.org/10.1016/j.engappai.2025.112234'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s interconnected world, networks, whether social, technological, or biological, are constantly evolving, with relationships forming, shifting, and dissolving over time. Traditional models struggle to capture this fluidity, treating networks as static snapshots rather than living systems. While existing research has made strides in analyzing either spatial–temporal patterns or temporal sequences separately, these approaches often fall short in scalability and fail to unify discrete and continuous-time perspectives. To bridge this gap, we introduce DyGHS (Dynamic Graph Historical-Sequential), an innovative framework that harnesses dynamic graph neural networks to model how nodes, edges, and their historical interactions evolve together. By seamlessly integrating discrete-time and continuous-time graph representations, DyGHS not only captures the richness of real-world networks but also efficiently predicts future connections and node behaviors. Our experiments reveal that combining continuous-time Fourier transform (CTFT) with graph neural networks significantly boosts prediction accuracy, outperforming current methods in tasks like link prediction and node classification. This advancement opens new doors for understanding and anticipating the ever-changing tapestry of networked systems.},
  archive      = {J_EAAI},
  author       = {Adam Abakar Hamid and Anping Zhao and Alladoumbaye Ngueilbaye},
  doi          = {10.1016/j.engappai.2025.112234},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112234},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic graph neural network with historic-sequential information representation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAE-diff: Masked-AutoEncoder-guided diffusion framework for source-free domain adaptive medical image segmentation. <em>EAAI</em>, <em>162</em>, 112219. (<a href='https://doi.org/10.1016/j.engappai.2025.112219'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain gaps can often cause dramatic performance deterioration when applying medical image segmentation models trained on the source domain to the target domain. Although unsupervised domain adaptation methods can address the domain gap challenge to some extent, their reliance on accessing source images largely hampers their practical applicability, as source data are often inaccessible due to privacy concerns. Moreover, the low-quality characteristic of medical images can further degrade the domain adaptation performance of segmentation models. To address these issues, we propose the Masked-AutoEncoder-guided Diffusion (MAE-Diff) framework for source-free domain adaptive medical image segmentation. MAE-Diff mainly consists of a Masked AutoEncoder (MAE) Module for effective feature extraction and domain adaptation, and a Diffusion Module for effective segmentation of low-quality medical images. On source images, the MAE encoder is trained to extract image-specific features, and the Diffusion Module is trained to generate segmentation maps following a gradual denoising strategy, under the guidance of features extracted by the MAE encoder. Training on the target domain involves only fine-tuning MAE (trained on the source images) with target images, allowing MAE-Diff to adapt to the target domain distribution. Inference on target images can then be made by the source-based Diffusion Module, under the guidance of features extracted by the MAE encoder fine-tuned on the target images. Extensive experiments on three datasets demonstrate the effectiveness of the proposed framework for source-free domain-adaptive medical image segmentation. The code of MAE-Diff is available at https://github.com/xuss804/MAEDiff .},
  archive      = {J_EAAI},
  author       = {Shanshan Xu and Le Xu and Yeqing Yang and Lixia Tian},
  doi          = {10.1016/j.engappai.2025.112219},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112219},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MAE-diff: Masked-AutoEncoder-guided diffusion framework for source-free domain adaptive medical image segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hierarchical reinforcement learning framework with imitation learning and bayesian Actor–Critic for distributed unmanned underwater vehicle encirclement in dynamic maritime environments. <em>EAAI</em>, <em>162</em>, 112214. (<a href='https://doi.org/10.1016/j.engappai.2025.112214'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of Unmanned Underwater Vehicles (UUVs) has introduced potential threats to critical infrastructure, with existing methods facing challenges in multi-agent collaboration and dynamic environment adaptation. To address these challenges, we propose HRL-IL-BAC—a Hierarchical Reinforcement Learning framework equipped with an Imitation-Learning (IL) high-level policy and a Bayesian Actor–Critic (BAC) low-level controller. The framework decomposes the encirclement mission into four sequential phases: submergence, interception, encirclement, and standoff tracking. At the high level, multi-agent collaboration and long-horizon autonomous decision-making are orchestrated by the IL-guided policy, whereby strategy convergence is accelerated and phase selection is rendered more precise. At the low level, environmental and model uncertainties are explicitly modeled by the BAC controller, so that adaptability and control accuracy are markedly boosted under dynamic ocean conditions. Validation through simulations and physical experiments demonstrates that the HRL-IL-BAC framework achieves 23.6% faster encirclement efficiency and 52.0% enhanced system stability compared to conventional methods, while maintaining superior adaptability to dynamic maritime conditions. This work provides an innovative and effective solution for underwater defense and marine security, offering new insights into multi-agent systems for complex maritime operations.},
  archive      = {J_EAAI},
  author       = {Hanbin Zhang and Wenchuan Zang and Peng Yao and Jiangli Cao and Dalei Song},
  doi          = {10.1016/j.engappai.2025.112214},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112214},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hierarchical reinforcement learning framework with imitation learning and bayesian Actor–Critic for distributed unmanned underwater vehicle encirclement in dynamic maritime environments},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic-static siamese Takagi–Sugeno-kang fuzzy system with inductive-reflection deep fuzzy rule. <em>EAAI</em>, <em>162</em>, 112199. (<a href='https://doi.org/10.1016/j.engappai.2025.112199'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The first-order Takagi–Sugeno–Kang (TSK) fuzzy classifiers are famous for their high computational efficiency and strong interpretability, but they often struggle to learn from complex and large-scale datasets, and perform not very well compared to higher-order TSK fuzzy classifiers. To address this issue, in this paper we propose a novel Dynamic-Static Siamese TSK Fuzzy classifier with Inductive-Reflection Deep Fuzzy rule. It aims to enhance the model’s self-learning capabilities by utilizing Siamese network to integrate deep fuzzy knowledge and fine-grained knowledge without the need for a teacher model. The innovations of this study are as follows: (1) The deep fuzzy rules in the proposed classifier are enriched with an “Inductive-Reflection” process, which reduces constraints on traditional basic fuzzy rule and aligns rule acquisition more closely with general human thinking manners; (2) The proposed method includes a mechanism for self-learning and improvement from both deep and fine-grained fuzzy knowledge, eliminating the complexity of retraining a new teacher model; (3) An adaptive learning function is developed to effectively adjust the learning process, adapting to tasks with different complexities. Extensive experiments results on benchmark datasets, as well as two real-world datasets, demonstrate the effectiveness of the proposed classifier in terms of classification accuracy and weighted F1-score.},
  archive      = {J_EAAI},
  author       = {Xiongtao Zhang and Qihuan Shi and Yunliang Jiang and Qing Shen and Jungang Lou and Ruiqin Wang},
  doi          = {10.1016/j.engappai.2025.112199},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112199},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic-static siamese Takagi–Sugeno-kang fuzzy system with inductive-reflection deep fuzzy rule},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing anomaly detection with few-shot fine-tuned long text-to-image models. <em>EAAI</em>, <em>162</em>, 112174. (<a href='https://doi.org/10.1016/j.engappai.2025.112174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial anomaly detection plays a crucial role in the industrial manufacturing field. Currently, utilizing generated data to improve the performance of the anomaly detection model is an effective approach. However, most existing methods often rely on mask-guided synthesis, where the distribution of the generated defects is limited by masks that are typically random or learned by a model. In addition, the scarcity of real anomalous samples makes it difficult for generative models to capture genuine defect patterns and align with the real anomaly distribution. To tackle these issues, we propose DefectGen, the first long-text-guided few-shot text-to-image data generation pipeline for industrial anomaly detection. To improve distribution alignment under limited anomaly samples, DefectGen incorporates a Prompt Generation and Variation Module, which uses MLLMs (Multimodal Large Language Models) to expand few-shot image–text pairs into diverse and semantically rich prompts, and DoKr (Weight- D ecomposed L o w-Rank Adaptation with Kr onecker product), a lightweight fine-tuning strategy with structured low-rank adaptation. To ensure the quality of synthetic data, DefectGen further introduces the Real-Guided Clustering Filter, which selects high-quality generated samples by comparing their features with those of real anomalies. Experiments on the MVTec AD(MVTec AnomalyDetection) dataset show that DefectGen generates more diverse and realistic synthetic anomalies and achieves a 5.58% average improvement in anomaly classification accuracy compared to state-of-the-art methods. Code and data are available at: https://anonymous.4open.science/r/DefectGen-CD04/ .},
  archive      = {J_EAAI},
  author       = {Jiachen Liu and Jiajia An and Junbin Lu and Zhuoqin Yang and Jinbao Wang and Ping Lu and Yuying Wang and Linlin Shen},
  doi          = {10.1016/j.engappai.2025.112174},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112174},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing anomaly detection with few-shot fine-tuned long text-to-image models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A database of dentition images of indian breed cattle and estimation of cattle’s age using deep learning algorithms. <em>EAAI</em>, <em>162</em>, 112172. (<a href='https://doi.org/10.1016/j.engappai.2025.112172'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate age estimation in livestock is crucial in agricultural management, influencing breeding, healthcare, and production planning. The primary method entails visually inspecting the teeth, a procedure susceptible to human fallibility. Recent deep learning (DL) algorithms are highly efficient in automating age prediction based on dentition images, offering faster and more accurate results. To our knowledge, no dataset exists for Indian livestock, hindering DL algorithm development for teeth segmentation and age estimation. Therefore, we created a database of dentition images for Indian livestock, covering an age range of 1 to 15 years, using 2,883 subjects. In this research, we employed a hybrid model based on You Only Look Once version 8 (YOLOv8) for instance segmentation of raw dentition images. Segmentation achieved 73.59% mean Average Precision (mAP) 50 and 56.44% mAP50–90, indicating strong performance in varying localization thresholds. These segmented images were then used in various DL algorithms, including convolutional neural network (CNN)-based transformers and vision transformers (ViTs), to develop DL models for age estimation. We conducted three age estimation experiments with increasing granularity: four age groups (4-year intervals), seven age groups (2-year intervals), and fifteen age groups (1-year intervals). InceptionV3 achieved the highest accuracy in the first two experiments with 73.72% and 62.41%, respectively. In the third experiment, MobileNet performed best with an accuracy of 43.87%. Our results demonstrate the effectiveness of these intricate DL models in enhancing livestock age estimation, making the process more streamlined and reliable. The study may assist farmers in making informed and efficient agricultural management decisions.},
  archive      = {J_EAAI},
  author       = {Chinmay Vijay Patil and Ankit Ashokrao Bhurane and Preeti Ghasad and Vipin Kamble and Manish Sharma and Anand Singh and Nareshkumar Nandeshwar and Ru-San Tan and Rajendra Acharya},
  doi          = {10.1016/j.engappai.2025.112172},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112172},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A database of dentition images of indian breed cattle and estimation of cattle’s age using deep learning algorithms},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed fine-tuning for physics discovery from random and sparse data. <em>EAAI</em>, <em>162</em>, 112132. (<a href='https://doi.org/10.1016/j.engappai.2025.112132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although significant advances have been made in both numerical methods and machine learning approaches for solving differential equations across various scientific sectors, these methods often rely on complete information about the differential equations, including precise parameter values, which are not easily obtainable in real-world scenarios. To address this challenge, data-driven methods for discovering differential equations have gained growing popularity in recent years. However, many existing approaches demand unrealistic prerequisites, such as extensive high-fidelity data or carefully designed low-fidelity data and functions. In this paper, we propose a novel method: P hysics- I nformed F ine- T uning ( PIFT ) to discover the unknown parameters in differential equations when only randomly distributed sparse data points are available. PIFT consists of three stages; (i) generating low fidelity data from prior knowledge under realistic settings, (ii) pre-training a single neural network with the generated low fidelity data, and (iii) fine-tuning the pre-trained model using physics-informed loss function. PIFT is evaluated on seven scientific problems including five ordinary differential equations and two partial differential equations. We also demonstrate the robustness and generalizability of PIFT to out-of-distribution tasks. PIFT exhibits high accuracy and robustness in discovering unknown parameters of differential equations from randomly distributed sparse data points.},
  archive      = {J_EAAI},
  author       = {Yong Jin Jeong and Taesup Moon},
  doi          = {10.1016/j.engappai.2025.112132},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112132},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed fine-tuning for physics discovery from random and sparse data},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep Q-learning with feature extraction and prioritized experience replay for edge node overload in edge computing. <em>EAAI</em>, <em>162</em>, 112124. (<a href='https://doi.org/10.1016/j.engappai.2025.112124'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keeping track of the edge nodes’ status information is crucial, which is the condition of their available compute capacity as measured by their Age-of-Information. In Internet of Things-oriented edge computing systems, the computational and software-defined infrastructure resources are heterogeneous and subject to rapid change. Edge computing systems often face dynamic workloads and limited computational resources, leading to frequent node overload scenarios. These overloads degrade system responsiveness and service availability, especially in latency-sensitive applications. The scheduling of computation tasks would consider both current resource availability and predicted overload risks. An intelligent, adaptive method that learns optimal task allocation under resource constraints has the potential to boost the operational efficiency of Internet of Things-oriented edge computing systems. Addressing edge node overload is critical for the sustainable and scalable deployment of edge-based infrastructures. This research designs a resource-overloaded detection model specifically for diverse workloads in edge computing systems. The proposed Deep Reinforcement Learning model explores two significant challenges: the selection of pertinent feature sets from the workload resource utilization storage, and their classification of overload and detection of fatal failure of edge computing nodes. We propose a Deep-Q Network with a prioritized experience replay framework for edge node resource overload. The framework relies on feature learning using Linear Discriminant Analysis and Deep Q Network with a prioritized experience replay to efficiently indicate the overload status of edge nodes and reward the system with actions that enhance edge resources allocation. Deep-Q Network is well-suited for sequential decision-making in dynamic environments, while prioritized experience replay improves sample efficiency by focusing on updating on high-priority transitions with larger temporal-difference errors. Features are learned automatically from the edge node resource profiling data generated on a real edge-based container infrastructure. Linear Discriminant Analysis reduces the high-dimensional state space by emphasizing the most discriminative features for scheduling decisions. The infrastructure executes an intelligent inference of containerized applications considered as resource-intensive applications. When the feature extraction is added to the proposed deep reinforcement learning model, the overload classifier’s performance is improved. Comparing the model with selection to the one without it, the total accuracy and F1-score were improved by 1.3% and 1.4%, respectively.},
  archive      = {J_EAAI},
  author       = {Lionel Nkenyereye and Boon Giin Lee and Wan-Young Chung},
  doi          = {10.1016/j.engappai.2025.112124},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112124},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep Q-learning with feature extraction and prioritized experience replay for edge node overload in edge computing},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STEval: A framework for evaluating spatio-temporal crime prediction models. <em>EAAI</em>, <em>162</em>, 112123. (<a href='https://doi.org/10.1016/j.engappai.2025.112123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-Temporal predictive models are crucial for forecasting where and when crimes will occur, aiding public security organizations in resource allocation and crime prevention. Despite numerous literature proposals, a lack of standardized evaluation criteria hinders comparability and reliability. To address this, we propose STEval, a comprehensive and flexible evaluation framework for spatio-temporal predictive models. STEval consists of four modules: data preparation, spatial structure definition, model training, and model evaluation. The framework’s robustness was demonstrated using a 40-million-record crime dataset from Minas Gerais State (Brazil) across five experimental scenarios, including variations in temporal granularity, spatial resolution, and distribution shifts. Results demonstrate that no single model is universally superior, and the most appropriate model depends on the specific application context. For instance, Spatio-Temporal Kernel Density Estimation (STKDE) consistently achieved high Hit Rates (HR), often exceeding 0.98 in fine spatial resolutions (e.g., 100-square meters grid) for violent crimes, while Spatial-Temporal Autoregressive Integrated Moving Average (STARIMA) demonstrated strong performance in temporal granularity tests, reaching HRs of up to 0.65 for theft predictions. Conversely, Extra Tree Regressor, though exhibiting significantly lower HRs (e.g., as low as 0.02 in some spatial tests), consistently provided the fastest execution times, often under 5 s, contrasting with STKDE’s execution times that could extend to thousands of seconds in dense spatial grids. The framework’s detailed analysis provides important insights for informed model selection and optimization, revealing each model’s strengths and limitations, and providing a robust foundation for future advancements in spatio-temporal crime prediction research, leveraging Machine Learning (ML) techniques.},
  archive      = {J_EAAI},
  author       = {Gabriel Amarante and Matheus Pimenta and Yan Andrade and Matheus Senna and Rainer Menezes and Antônio Hot Faria and Marcelo Vilas-Boas and Frederico Martins de Paula Neto and João Paulo da Silva and Everton Renato de Sousa and Jamicel da Silva and Wagner Meira Jr. and George Teodoro and Leonardo Rocha and Renato Ferreira},
  doi          = {10.1016/j.engappai.2025.112123},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112123},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {STEval: A framework for evaluating spatio-temporal crime prediction models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new design of arithmetic and logic unit for enhancing the security of future internet of things devices using quantum-dot technology. <em>EAAI</em>, <em>162</em>, 112113. (<a href='https://doi.org/10.1016/j.engappai.2025.112113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) is a network of interconnected devices that collect, monitor, analyze, and exchange data. This technology plays a crucial role in the smart city infrastructure by seamlessly interconnecting various nodes. The extensive application and recognition of IoT across multiple city domains, such as healthcare, transportation, energy, education, and agriculture, bring significant challenges, with security among the most pressing. Traditional hardware technologies like Complementary Metal Oxide Semiconductor (CMOS) and Very Large Scale Integration (VLSI) suffer from limitations such as high power consumption and insufficient scalability, which hinder secure and sustainable IoT deployment. Such limitations have prompted the need to seek other technologies that would serve the dual purpose of providing security as well as energy. Quantum-based technologies can become adequate candidates offering promising solutions to make IoT devices and sustainable systems more secured. Quantum-dot Cellular Automata (QCA) has been proposed as a nanotechnology with the potential of consuming ultra-low powers, less area, and high-speed operation. QCA enhances security through sustainable computing objectives by minimizing energy usage. To improve the future security and efficiency of IoT hardware, this paper suggests a QCA-based Arithmetic Logic Unit (ALU). This ALU can generate more than 12 logical and arithmetic operations. Designed together with the majority gates, XOR gates, multiplexers, and full adders, the ALU is simulated using the QCA-Designer 2.0.3. Simulated results indicate improvements in the number of cells and reduced occupied area relative to the earlier designs. These results indicate the potential of QCA technology in enabling secure, energy-efficient, and compact computing architecture applicable in the future IoT.},
  archive      = {J_EAAI},
  author       = {Maryam Zaker and Seyed Sajad Ahmadpour and Nima Jafari Navimipour and Muhammad Zohaib and Neeraj Kumar Misra and Sankit Kassa and Ahmad Habibizad Navin and Arash Heidari and Mehdi Hosseinzadeh and Omar I. Alsaleh},
  doi          = {10.1016/j.engappai.2025.112113},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112113},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new design of arithmetic and logic unit for enhancing the security of future internet of things devices using quantum-dot technology},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prescribed-time convergence noise-tolerant zeroing neural network for multi-robot position management and coordination. <em>EAAI</em>, <em>162</em>, 112072. (<a href='https://doi.org/10.1016/j.engappai.2025.112072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A zeroing neural network (ZNN) model with prescribed-time convergence and noise tolerance is constructed for the first time to address multi-robot position planning (MPP) tasks. Unlike traditional ZNN models, which converge within finite, fixed, or predefined times, this model ensures that system errors converge precisely within the predefined time T p . Furthermore, it significantly enhances noise tolerance while maintaining excellent convergence performance. Through rigorous mathematical analysis and detailed numerical simulations, the proposed model demonstrates exceptional convergence and robustness, even under noise disturbances. In a noise-free environment, the convergence time accuracy (CTA) of this model when solving the MPP task reach over 90%, which is approximately 30% higher than traditional predefined-time convergence neural networks.},
  archive      = {J_EAAI},
  author       = {Tinglei Wang and Yufei Wang and Cheng Hua and Xinwei Cao and Bolin Liao and Shuai Li},
  doi          = {10.1016/j.engappai.2025.112072},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112072},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prescribed-time convergence noise-tolerant zeroing neural network for multi-robot position management and coordination},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inland waterway object detection in multi-environment: Dataset and approach. <em>EAAI</em>, <em>162</em>, 111994. (<a href='https://doi.org/10.1016/j.engappai.2025.111994'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has advanced intelligent ship visual perception, but the scarcity of dedicated inland waterway vessels dataset limits system adaptability in complex environments. Narrow waterways, variable weather, and urban interference challenge the robustness of existing object detection systems. To address these issues, this paper constructs the Multi-environment Inland Waterway Vessels Dataset (MEIWVD), comprising 32,478 high-quality images from diverse Yangtze River basin scenarios, including sunny, rainy, foggy, and artificially lit conditions. The diversity and multi-scale characteristics of MEIWVD establish it as a rigorous benchmark for vessel detection. To leverage the characteristics of the MEIWVD, this paper proposes a scene-guided image enhancement module for multi-environment scenarios, which adaptively enhances water surface images based on environmental conditions to improve detector performance in complex scenarios. Additionally, a parameter-limited dilated convolution is introduced to enhance the representation of salient features of inland waterway vessels by leveraging their geometric characteristics. Finally, a multi-scale dilated residual fusion method is proposed to effectively integrate multi-scale features and improve the detection of multi-scale objects. Comprehensive statistical analysis and experiments on the MEIWVD demonstrate that it poses higher demands on object detection algorithms compared to existing water surface datasets, owing to its diverse and challenging scenarios. The proposed methods, including scene-guided image enhancement, parameter-limited dilated convolution, and multi-scale dilated residual fusion, advance research in multi-environment dataset, achieving a mean average precision over intersection over union thresholds from 0.5 to 0.95 of 81.6 % on the MEIWVD, outperforming state-of-the-art object detection algorithms.},
  archive      = {J_EAAI},
  author       = {Shanshan Wang and Haixiang Xu and Hui Feng and Xiaoqian Wang and Pei Song and Sijie Liu and Jianhua He},
  doi          = {10.1016/j.engappai.2025.111994},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111994},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inland waterway object detection in multi-environment: Dataset and approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
