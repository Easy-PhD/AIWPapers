<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EAAI</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="eaai">EAAI - 29</h2>
<ul>
<li><details>
<summary>
(2025). A novel weight-optimized machine-learning hybrid model for daily river runoff prediction. <em>EAAI</em>, <em>162</em>, 112396. (<a href='https://doi.org/10.1016/j.engappai.2025.112396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The daily runoff process has been characterized as nonlinear and unsteady due to the impacts of watershed precipitation and evaporation, vegetation coverage rate, reservoir operations and other human activities. In recent years, machine-learning (ML) models have been widely applied in the daily runoff predictions, but the robustness and effectiveness of individual ML model is always limited. A novel weight optimization scheme has been introduced to ML models to obtain accurate predictions of daily river runoff. Variational modal decomposition method is adopted in the dataset preprocessing, and the runoff prediction performance of various classic ML models, including Genetic Algorithm-Back Propagation neural network (GA-BP), Long Short-Term Memory network (LSTM), Elman neural network (Elman) and Genetic Algorithm-Support Vector Machine (GA-SVM) are subsequently evaluated. A particle swarm optimization (PSO) based weight optimization strategy is proposed to combine different types of ML models, thus more accurate and robust results could be obtained. The ten-fold cross-validation method has been adopted and the performance of the optimized hybrid models are further evaluated for different schemes. A case study at Hankou hydrological station demonstrates that root mean square error (RMSE) and mean absolute percentage error (MAPE) is improved by 35.7 %, 75.8 % respectively for the optimized hybrid model. The present study shares useful insights to the comprehensive optimization of various ML models in the intelligent management of water resources.},
  archive      = {J_EAAI},
  author       = {Zhonglian Jiang and Jianglong Ying and Zhen Yu and Xiao Chu and Chengqiang Yu},
  doi          = {10.1016/j.engappai.2025.112396},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112396},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel weight-optimized machine-learning hybrid model for daily river runoff prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent assessment of habitat quality based on multiple machine learning fusion methods. <em>EAAI</em>, <em>162</em>, 112395. (<a href='https://doi.org/10.1016/j.engappai.2025.112395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating habitat quality can help balance the relationship between economic development and biodiversity conservation, and it serves as a foundation for constructing an ecological security pattern. However, research on the intelligent construction of habitat quality is limited. This study develops a comprehensive framework to assess habitat quality based on optimized machine learning methods. The findings of the research are as follows: (1) From the perspective of human-machine interactive interpretation, ensemble learning is used to enhance the performance of basic classifiers, resulting in a classification map with high precision and recall. (2) The particle swarm optimization (PSO) algorithm can improve the goodness of fit of the Extreme Gradient Boosting (XGBoost) inversion model by 4–5 %. (3) The habitat quality inversion method based on XGBoost-PSO has high credibility and application value, with its texture structure being the result of both expert experience and image information interaction. (4) The model demonstrates certain application potential in downscaling; under the seven-band perspective, the blue and near-infrared bands are the most important, while in the four-band perspective, green and near-infrared bands take precedence.},
  archive      = {J_EAAI},
  author       = {Kui Yang and Dongge Cui and Chengrui Wang and Qi Tang and Linguang Miao},
  doi          = {10.1016/j.engappai.2025.112395},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112395},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent assessment of habitat quality based on multiple machine learning fusion methods},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Health state estimation of retired batteries based on physical constraints. <em>EAAI</em>, <em>162</em>, 112390. (<a href='https://doi.org/10.1016/j.engappai.2025.112390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing use of retired lithium-ion batteries, accurately monitoring their health status has become increasingly important. This study proposed a method to estimate the health of retired batteries by embedding their capacity degradation characteristics directly into the loss function of a Bidirectional Long Short-Term Memory (BiLSTM) network, combined with a Physically Informed Neural Network (PINN) model. The model is developed by incorporating the dynamics of the solid electrolyte interface (SEI) membrane, which evolves as the lithium-ion poles of the retired battery move. By combining these dynamics with the governing equations of motion, a partial differential equation (PDE) is derived. This approach integrates physical constraints, data-driven learning, and PDEs into a composite loss function. The proposed method is validated on two different datasets under varying operating temperatures. The results show that the PINN-BiLSTM model achieves a Root Mean Square Percentage Error (RMSPE) of 0.024, representing a 9.67 % improvement over the PINN-LSTM. This adaptive PINN method offers highly accurate health state predictions across temperature variations, thus supporting the sustainable use of retired batteries in secondary applications and helping to mitigate energy scarcity.},
  archive      = {J_EAAI},
  author       = {Fei Xia and Qianwen Dong and Lin Xia and Zhenyi An and Ziyang Xia and Chunyang Gong},
  doi          = {10.1016/j.engappai.2025.112390},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112390},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Health state estimation of retired batteries based on physical constraints},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optimisation approach guided by crack variation mechanism in the informer prediction model. <em>EAAI</em>, <em>162</em>, 112381. (<a href='https://doi.org/10.1016/j.engappai.2025.112381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural health monitoring (SHM) faces a fundamental challenge in reconciling predictive performance with physical interpretability for infrastructure diagnostics. Conventional deep learning (DL) approaches neglect essential mechanisms governing crack width variation—including thermal gradients, hysteretic responses, and phase-shifted correlations—limiting their reliability in real-world applications. To bridge this gap, we propose a mechanism-guided optimization (MGO) framework that integrates domain knowledge into the Informer architecture through physics-informed enhancements: auto-correlation modeling for capturing temperature-crack hysteresis, static gated fusion for multi-feature integration, and adaptive elastic net regularization for feature selection. Validated on cable-stayed bridge monitoring data, our framework achieves significant mean absolute error reductions (MAE) (5 %–60 %) and root mean square error reductions (RMSE) (10 %–55 %) versus baseline Informer across all cracks and prediction horizons, with diebold-mariano (DM) tests confirming statistical superiority in most cases. Crucially, it demonstrates superior precision relative to six state-of-the-art benchmarks across all evaluation scenarios. The ordinary least squares (OLS)-enhanced variant further delivers volatility reduction, while sensor failure tests establish quantifiable robustness benchmarks through MAE progression from 0.013 mm to 0.391 mm. This work establishes an interpretable, physics-grounded paradigm that explicitly links environmental drivers to structural degradation.},
  archive      = {J_EAAI},
  author       = {Xujia Liu and Youliang Ding and Fei Xu and Yichao Xu and Kang Yang},
  doi          = {10.1016/j.engappai.2025.112381},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112381},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An optimisation approach guided by crack variation mechanism in the informer prediction model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightning risk assessment of offshore wind farms considering tropical cyclone impacts based on an improved gradient boosting algorithm. <em>EAAI</em>, <em>162</em>, 112376. (<a href='https://doi.org/10.1016/j.engappai.2025.112376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, global climate warming has led to a significant increase in both the frequency and intensity of tropical cyclones (TCs). The development of TCs is often accompanied by frequent lightning activities. The risk of lightning strikes to high offshore wind turbines is substantially elevated. This study evaluates the lightning risk faced by offshore wind farms influenced by tropical cyclones. Firstly, TC paths are analyzed in both spatial and temporal dimensions by linking them with lightning data to examine the distribution of TC-related lightning, and the lightning strike characteristics of offshore wind turbines are investigated. Secondly, a Bayesian Optimization (BO)-based eXtreme Gradient Boosting (XGBoost) model for lightning risk assessment is proposed, incorporating characteristics of TC lightning and offshore wind farms as input variables. The proposed BO-XGBoost model outperforms XGBoost, Bidirectional Long Short-Term Memory (Bi-LSTM), Support Vector Machine (SVM) and Neural Network (NN), achieving a precision of 98.9 % and a recall of 98.9 % on the test set. Additionally, SHapley Additive exPlanations (SHAP) value analysis indicates that TC lightning characteristics and offshore wind farm characteristics significantly impact the model output, enhancing the accuracy of the model. The assessment outcomes provide a theoretical basis for future offshore wind farm planning and guidance for lightning protection measures in offshore wind farms.},
  archive      = {J_EAAI},
  author       = {Qibin Zhou and Kehan Chen and Xiaoyan Bian and Shangjie Chen and Gaopeng Lu},
  doi          = {10.1016/j.engappai.2025.112376},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112376},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightning risk assessment of offshore wind farms considering tropical cyclone impacts based on an improved gradient boosting algorithm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective deployment optimization for integrated sensing and communication-enabled unmanned aerial vehicle swarm. <em>EAAI</em>, <em>162</em>, 112368. (<a href='https://doi.org/10.1016/j.engappai.2025.112368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the convergence of mobile communication, sensing, and computational networks in sixth-generation technology, the integration of sensing and communication with unmanned aerial vehicles (UAVs) is promising. This paper focuses on the contribution of artificial intelligence in optimizing the deployment of UAV swarms for multi-objective target detection applications in sixth-generation networks. Specifically, the artificial intelligence contribution lies in the development of an improved multi-objective particle swarm optimization (IMOPSO) algorithm for solving a complex multi-objective deployment problem. The problem aims to simultaneously optimize communication rate, sensing quality, and energy consumption in the deployment of UAV swarms. To address this, the proposed IMOPSO incorporates chaotic initialization, Lévy flight mutation, dynamic mutation rate, and an elimination mechanism based on opposition-based learning. These innovations are designed to enhance the algorithm’s ability to explore the solution space effectively, overcome premature convergence to local solutions, and improve solution quality. In terms of engineering applications, the IMOPSO is applied to the deployment of UAV swarms for target detection, demonstrating its ability to enhance communication and sensing performance while reducing energy consumption in practical scenarios. Through extensive simulations, we show that the IMOPSO outperforms traditional optimization methods and other baseline algorithms, achieving superior results across all optimization objectives. Specifically, the IMOPSO achieves approximately 5% higher transmission data rate, 9% better sensing quality, and 19% lower energy consumption compared to baseline algorithms across multiple test scenarios. Furthermore, the solutions obtained are not only closer to the optimal front but also more concentrated, indicating higher-quality results.},
  archive      = {J_EAAI},
  author       = {Hongjuan Li and Haiyuan Chen and Miao Wang and Jiahui Li and Hui Kang and Yuzhuo Guan and Xu Lin},
  doi          = {10.1016/j.engappai.2025.112368},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112368},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective deployment optimization for integrated sensing and communication-enabled unmanned aerial vehicle swarm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complete information extraction for monocular depth estimation using a dual framework. <em>EAAI</em>, <em>162</em>, 112337. (<a href='https://doi.org/10.1016/j.engappai.2025.112337'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to address the problem of efficient extraction of complete multi-scale information for supervised monocular depth estimation. Most of the existing depth estimation methods are based on Convolutional Neural Network (CNN). By gradually exploring the contextual and semantic features, they have achieved good results in scene depth estimation. However, with the expansion of the receptive field, global information limited by the local induction bias is gradually suppressed, resulting in the performance cannot be further improved. Recently, Transformer-based methods have been widely used to model the global correlation between features. Nevertheless, since the Transformer networks are not spatially aware enough, they usually lose local details and have no clear mechanism for reusing features when processing images. The Transformer networks perform self-attention mechanism at each location and cannot directly obtain information from other locations for features. Therefore, we propose a novel dual framework called as Transformer-CNN, which includes the Transformer-branch and the CNN-branch for monocular depth estimation. Specifically, the Transformer-branch is able to model the global contextual information and the CNN-branch can capture local spatial relationships in images. However, simply fusing these two independent branches may result in insufficient feature aggregation. To this end, we design a Parallel Feature Interaction Module (PFIM), which contains a Self-Attention Module (SAM) and a Cross-Attention Module (CAM), so as to highlight features from the Transformer-branch and the CNN-branch respectively and extract complementary information between the two branches. Meanwhile, in order to make full use of the low-level features with low quality in the scene, we propose a Low-level Information Acquisition Module (LIAM) to capture texture-related information and preserve texture details in the CNN-branch. Finally, to address the lack of multi-scale contextual information in Vision Transformer (ViT), we introduce a Wide Area Multi-scale Decoder (WAMD), which incorporates the multi-scale feature representations into the decoder part via a Wide Area Attention (WAA). Extensive experiments on benchmark datasets collected in the outdoor and indoor environments demonstrate the competitive results of the proposed method, compared with the state-of-the-art monocular depth estimation methods.},
  archive      = {J_EAAI},
  author       = {Bin Li and Dazheng Zhou and Xianjie Gao and Mingliang Zhang},
  doi          = {10.1016/j.engappai.2025.112337},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112337},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Complete information extraction for monocular depth estimation using a dual framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond the horizon: A comprehensive analysis of artificial intelligence-based weather forecasting models. <em>EAAI</em>, <em>162</em>, 112335. (<a href='https://doi.org/10.1016/j.engappai.2025.112335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of Artificial Intelligence (AI)-based weather forecasting is growing rapidly, with continuous progress in model development, techniques, and performance improvements. This paper provides a comprehensive overview of AI-based weather forecasting models, focusing on their current status, challenges, and directions for further development. A review of more than 40 models, primarily proposed after 2015, underscores the importance of critically examining various aspects of AI-based forecasting. Unlike previous reviews that targeted only a limited number of models or features, this study addresses a complete set of aspects and analyzes existing challenges from multiple perspectives. These aspects include the Machine Learning (ML) and Deep Learning (DL) methods used, datasets, predictand parameters, overfitting, and capability for forecasting extreme weather, lead time, spatiotemporal scale, performance criteria, overfitting, data assimilation, data-driven models, and the analysis of state-of-the-art (SOTA) models such as FengWu, ClimaX, Pangu-Weather, FourCastNet, GraphCast, GenCast, and Artificial Intelligence Forecasting System (AIFS) from various viewpoints. The review also discusses current challenges, including limited historical data and data quality, small-scale weather forecasting, model explainability, uncertainty, extreme weather prediction, physical constraints, temporal adaptation, and generalization, and outlines potential future directions.},
  archive      = {J_EAAI},
  author       = {Saeid Haji-Aghajany and Witold Rohm and Piotr Lipinski and Maciej Kryza},
  doi          = {10.1016/j.engappai.2025.112335},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112335},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Beyond the horizon: A comprehensive analysis of artificial intelligence-based weather forecasting models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A domain adaptation method to defend chinese textual adversarial attacks via prompt-tuning. <em>EAAI</em>, <em>162</em>, 112330. (<a href='https://doi.org/10.1016/j.engappai.2025.112330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The textual adversarial attack aims to fool existing models into making erroneous predictions by adding strategic perturbations to normal data without affecting the user’s understanding. Recently, methods based on Pre-trained Language Models (PLMs) and Large Language Models (LLMs) have shown promising performance in various Natural Language Processing (NLP) downstream tasks. However, due to significant deviations between the original and perturbed texts, these methods struggle to achieve satisfactory results in defending against textual adversarial attacks, especially in Chinese, which has unique syntactic structures. To address this issue, we propose a domain adaptation method for defending against Chinese textual adversarial attacks through a prompt-tuning model, which effectively mitigates the discrepancy between different domains. Specifically, the original and perturbed texts are treated as the source and target domains, respectively, with the textual adversarial defense task framed as a cross-domain classification problem. The soft prompt-tuning model trained in the source domain is iteratively adapted to uncover the true label information in the target domain. The graph attention network is incorporated to integrate Chinese syntactic structure information with semantic features. Through a voting mechanism on predicted labels generated by the iterative model, soft prompt-tuning is further optimized for cross-domain classification tasks. Extensive experimental results demonstrate the superior effectiveness of our method in Chinese textual adversarial defense tasks compared to baseline methods, including the state-of-the-art fine-tuning approaches for PLMs and LLMs.},
  archive      = {J_EAAI},
  author       = {Yi Zhu and Zhenglong Li and Yun Li and Yunhao Yuan and Jipeng Qiang},
  doi          = {10.1016/j.engappai.2025.112330},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112330},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A domain adaptation method to defend chinese textual adversarial attacks via prompt-tuning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-shot learning augmented slow feature analysis for semantic-aware industrial process fault detection. <em>EAAI</em>, <em>162</em>, 112321. (<a href='https://doi.org/10.1016/j.engappai.2025.112321'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Slow Feature Analysis (SFA) has shown considerable success in the field of industrial process fault detection. Nonetheless, due to its unsupervised nature, SFA relies solely on the normal training data and overlooks the incorporation of prior process knowledge, which consequently diminishes its efficacy in early fault detection. To mitigate this limitation, this paper introduces the concept of Zero-Shot Learning (ZSL) and proposes an improved SFA approach, referred to as ZSL-SFA. This novel method leverages fault semantic representations as auxiliary knowledge to enhance fault detection sensitivity in industrial process monitoring. The ZSL-SFA framework implements a dual-model collaborative monitoring system: (1) a primary SFA model is developed using normal operational data to capture the dynamic characteristics of the process; and (2) a semantic encoding mechanism, grounded in expert knowledge, is devised to build the auxiliary model, where a probabilistic attribute learner adaptively extracts semantic information from fault attribute descriptions, facilitating effective fault knowledge transfer through similarity analysis. The monitoring outcomes from both the primary and auxiliary models are integrated using a Bayesian fusion strategy, culminating in a comprehensive ZSL-SFA monitoring system. The main advantage of this method is its ability to fully exploit prior process knowledge to enhance the basic SFA model without the need for additional labeled fault samples. Experimental validations on the Tennessee-Eastman process simulation platform are performed to indicate that the proposed ZSL-SFA method surpasses the basic SFA method in terms of fault detection performance.},
  archive      = {J_EAAI},
  author       = {Wenjie Yang and Xiaogang Deng and Lumeng Huang and Yuping Cao},
  doi          = {10.1016/j.engappai.2025.112321},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112321},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Zero-shot learning augmented slow feature analysis for semantic-aware industrial process fault detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodality based deep learning method for cancer-related T-cell receptor sequence prediction. <em>EAAI</em>, <em>162</em>, 112318. (<a href='https://doi.org/10.1016/j.engappai.2025.112318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {T-cell receptor sequences (TCR-seq) are closely related to cancers, and in particular, cancer-related TCR-seq are crucial in cancer diagnosis and treatment. Current prediction methods for cancer-related TCR-seq often focus solely on the sequence structure, neglecting its spatial structure. Therefore, we propose a multimodal deep learning method based on parallel and residual structures (MDPR) for the detection of cancer-related TCR-seq. MDPR can effectively integrate the spatial and sequence structure of TCR-seq for accurately identifying cancer-related sequences. First, we introduce a TCR-seq encoding method based on atomic three-dimensional spatial coordinates, allowing for more effective extraction of the spatial structural features of TCR-seq. Second, we use high-dimensional word vectors instead of the amino acid feature vectors traditionally used by other researchers. Third, we pretrain the spatial feature extraction module and then conduct joint training with the sequence feature extraction module. This approach allows the model to better consider the relationship between the two modalities, thereby improving prediction accuracy. Finally, MDPR achieved an area under the curve (AUC) of 0.971 after ten rounds of three-fold cross-validation on the dataset. The AUC of MDPR is 5% higher than that of the previous best method. In short, we propose an artificial intelligence method called MDPR, and apply it to the biomedical field. MDPR can be obtained from https://github.com/biomg/MDPR .},
  archive      = {J_EAAI},
  author       = {Junjiang Liu and Shusen Zhou and Mujun Zang and Chanjuan Liu and Tong Liu and Qingjun Wang},
  doi          = {10.1016/j.engappai.2025.112318},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112318},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodality based deep learning method for cancer-related T-cell receptor sequence prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A combined perspective self-supervised contrastive learning framework for human activity recognition integrating instance prediction and clustering. <em>EAAI</em>, <em>162</em>, 112317. (<a href='https://doi.org/10.1016/j.engappai.2025.112317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) is a significant application for wearable devices, which primarily identifies current human activities by analyzing sequential sensor data. The real-time data recording of wearable devices enables the collection of vast amount of unlabeled data. Utilizing this data for self-supervised contrastive pre-training of HAR models presents a feasible solution to the decline in recognition performance due to limited labeled data. However, traditional contrastive learning frameworks are primarily designed based on positive and negative sample pairs in the image domain. The relatively simple sequence data of HAR is prone to generating incorrect negative pairs, thus pre-training HAR models solely in this manner is unsatisfactory. Given the phenomena described above, this paper proposes an Instance Prediction and Clustering Self-supervised Contrastive Learning Framework (IPCSC) for HAR, considering the characteristics of human activity data. IPCSC circumvents negative sample pairs, instead extracting contrastive information at the instance perspective by prediction tasks among various augmented views of samples and integrating clustering concepts for contrastive learning from a holistic perspective. The primary objective is to enable the model to discern critical information within human activity data and distinguishable features between different activities, thereby improving the model’s pre-training efficacy and enhancing its downstream activity recognition performance. Numerous experimental analyses demonstrate that IPCSC outperforms other self-supervised methods, achieving an average F1-Score performance improvement of 5.65%, 4.11%, and 7.99% over supervised baselines on the UCI-HAR, MobiAct, and MotionSense datasets, respectively, with only 1% of the labeled data.},
  archive      = {J_EAAI},
  author       = {Zhixuan Yang and Kewen Li and Zongchao Huang and Zhifeng Xu and Xinyuan Zhu and Yuan Xiao},
  doi          = {10.1016/j.engappai.2025.112317},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112317},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A combined perspective self-supervised contrastive learning framework for human activity recognition integrating instance prediction and clustering},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised method for learning path-augmented knowledge graph embedding. <em>EAAI</em>, <em>162</em>, 112315. (<a href='https://doi.org/10.1016/j.engappai.2025.112315'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) consist of factual triples that describe relations between entities in the real world. Knowledge graph embedding (KGE) aims to map entities and relations into constantly low-dimensional vectors, which is important for lots of downstream tasks (e.g., KG completion and information retrieval). Current KGE methods primarily rely on explicit structural patterns, neglecting latent contextual semantics behind those structures and resulting in sub-optimal performance. While some methods incorporate additional data (e.g., textual descriptions), such dependencies limit applicability due to additional data requirements. Furthermore, most KGE models suffer from limited supervision with sparse labeled triples, restricting their capacity to learn comprehensive semantic features. Inspired by the simple but effective self-supervised language model word2vec, one interesting question is: Can KGE be performed as a simple self-supervised language model ? To achieve this, we innovatively propose a self-supervised KGE framework that learns entity and relation embeddings by adapting word2vec’s skip-gram objective to path sequences extracted from KGs. Our framework employs separate embedding spaces for entities and relations with an entity-relation mapping mechanism for effective interaction between the two embedding spaces. Further, to enhance the training efficiency, we introduce a markov chain-based negative sampling strategy, which generates semantically meaningful negative samples by preserving the structural contexts along KG paths. Our framework, which is the first attempt to follow the context-based self-supervised idea of language models to conduct KGE tasks, addresses the constraints of label-dependent supervised KGE techniques and obviates the requirement for external information, while simultaneously enabling effective extraction of the implicit contextual semantics inherent in triple structures. Experiments on two widely-used KGE datasets show state-of-the-art performance, demonstrating our framework’s ability to learn semantically rich representations solely from graph structure.},
  archive      = {J_EAAI},
  author       = {Tong Shen and Fu Zhang and Jingwei Cheng},
  doi          = {10.1016/j.engappai.2025.112315},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112315},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A self-supervised method for learning path-augmented knowledge graph embedding},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A single-cell RNA sequencing data imputation method based on non-negative matrix factorization and multi-kernel similarity network fusion. <em>EAAI</em>, <em>162</em>, 112313. (<a href='https://doi.org/10.1016/j.engappai.2025.112313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence-based single-cell RNA sequencing (scRNA-seq) technology is widely used in cell type identification and disease research, but its data often contain a large number of missing values and zero values due to technical limitations and biological differences. These zero values not only affect downstream analysis, but also make it difficult to distinguish technical zero values from biological zero values. Therefore, this paper proposes a scRNA-seq data interpolation method (sc-MKNMF) based on non-negative matrix factorization and multi-kernel similarity network fusion for the first time. This method improves the accuracy of cell clustering by accurately filling some zero values. First, sc-MKNMF uses gene-cell dual-level analysis to distinguish technical zero values from biological zero values, and then calculates the similarity network of multi-kernel fusion of genes and cells respectively. Then, this method uses non-negative matrix factorization combined with similarity network to construct the objective function, and introduces sparse regularization terms to ensure the similarity between genes and cells and improve stability. In addition, sc-MKNMF is also equipped with an efficient optimization algorithm to promote its convergence by continuously updating the objective function. Finally, the verification and comparative experiments on 12 scRNA-seq datasets show that the sc-MKNMF method outperforms other advanced data interpolation methods. In addition, the extension of sc-MKNMF to the two tasks of cell trajectory inference and differentially expressed gene analysis showed significant improvement and excellent versatility.},
  archive      = {J_EAAI},
  author       = {Pei Liu and Cheng Chen and Hao Liu and Jin Gu and Xinya Chen and Ying Su and Zhiyuan Cheng and Xiaoyi Lv and Chen Chen},
  doi          = {10.1016/j.engappai.2025.112313},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112313},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A single-cell RNA sequencing data imputation method based on non-negative matrix factorization and multi-kernel similarity network fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel object detection model for sugar beet cercospora leaf spot in field scenarios based on large kernel decomposition and spatial channel interaction attention. <em>EAAI</em>, <em>162</em>, 112311. (<a href='https://doi.org/10.1016/j.engappai.2025.112311'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cercospora leaf spot (CLS) is a widespread disease that seriously threatens beet yield and sugar quality. Timely detection enables farmers to take early control measures and reduce economic losses. Although artificial intelligence (AI)-based methods are replacing manual inspection in agriculture, CLS detection in complex field environments remains highly challenging due to subtle early-stage symptoms and severe occlusions caused by overlapping leaves and weeds. To address these challenges, this paper presents Cercospora Leaf Spot–You Only Look Once (CLS–YOLO), an enhanced detection model built upon You Only Look Once version 11 (YOLOv11), incorporating novel modules specifically designed for accurate CLS detection under challenging field conditions. To improve the detection of weak and early-stage symptoms, we design the Multi-Scale Large Kernel Decomposition (MSLKD) module, which enhances feature extraction for subtle lesions. Furthermore, we develop the Spatial-Channel Interaction Attention (SCIA) module to mitigate detection errors arising from occlusion and fragmented disease patterns by refining multi-scale feature representations. Experimental results demonstrate CLS–YOLO achieves superior performance, reaching an mAP@0.5 of 73.6% ± 0.2% and an mAP@0.5:0.95 of 40.6% ± 0.3% over five independent runs, outperforming twelve mainstream object detection algorithms while maintaining lightweight efficiency. To validate generalization capability across scenarios, crops, and diseases, we conducted comparative experiments on two public crop disease datasets, where our method achieved superior overall performance. In summary, this study provides an effective AI-driven solution for precise crop disease detection, contributing to the practical advancement of intelligent agriculture.},
  archive      = {J_EAAI},
  author       = {Hualong Dong and Yi Lu and Yurong Qian and Xuefei Ning and Ting Chen and Ke Tang},
  doi          = {10.1016/j.engappai.2025.112311},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112311},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel object detection model for sugar beet cercospora leaf spot in field scenarios based on large kernel decomposition and spatial channel interaction attention},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ElecBench: A large language model benchmark in electric power domain. <em>EAAI</em>, <em>162</em>, 112310. (<a href='https://doi.org/10.1016/j.engappai.2025.112310'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have made substantial advancements in the field of natural language processing, necessitating the development of new benchmarks to accurately track their progress. In this paper, we introduce ElecBench, the first benchmark specifically designed for the electric power domain. ElecBench comprises 24 datasets spanning different scenarios, covering general electric power knowledge and four specific business applications, with a total of 34,030 data entries. Furthermore, we evaluate the performance of a series of open-source Chinese LLMs on ElecBench. Our experiments demonstrate that ElecBench serves as an effective benchmark for electric power scenarios and highlight that existing LLMs require further optimization to gain domain-specific knowledge and achieve better performance.},
  archive      = {J_EAAI},
  author       = {Sai Zhang and Qiaochu Huang and Qiang Zhang and Xiao Liang and Weiwei Liu and Kunlun Gao and Fei Zhou and Congcong Shi},
  doi          = {10.1016/j.engappai.2025.112310},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112310},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ElecBench: A large language model benchmark in electric power domain},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature-enhanced edge-INverse attention network for skin lesion segmentation. <em>EAAI</em>, <em>162</em>, 112306. (<a href='https://doi.org/10.1016/j.engappai.2025.112306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer, particularly melanoma, is one of the most aggressive and deadly forms of cancer with its incidence rising globally. Early detection is crucial for improving survival rates, but the traditional dermatoscopy method is a highly time-consuming and subjective process. To resolve this issue, we propose a novel Feature-Enhanced Edge-INverse attention network (FEEINnet) model that helps to segment the skin lesion region more accurately. FEEINnet consists of three sub-networks: Feature Enhanced Mechanism (FEM) learns and extracts the fine-grained enhanced features from informative channels, the Edge Attention Mechanism (EAM) helps to precisely identify the edges of the lesion region and the INverse Attention Mechanism (INAM) generates inverse attention maps which emphasize the less confident or ambiguous regions thereby increasing the segmentation accuracy iteratively. These three sub-networks collectively help to improve feature extraction, enhance boundary detection, and refine segmentation maps, even in challenging scenarios with varying lesion sizes, shapes and pigmentation. FEEINnet consistently outperforms existing models, achieving a F1-score of 95.55%, 95.53%, and 94.52%; Intersection over Union (IoU) of 92.76%, 92.43%, and 91.34%; and Structural Similarity Index Measure (SSIM) of 94.63%, 93.51%, and 91.85% on the Human Against Machine 10000 (HAM10000), Pedro Hispano Hospital ( P H 2 ), and International Skin Imaging Collaboration 2018 (ISIC2018) datasets, respectively. The obtained results demonstrate that the proposed model has a greater ability to segment complex skin lesions more accurately.},
  archive      = {J_EAAI},
  author       = {Shivamm Warambhey and Aravindkumar Sekar},
  doi          = {10.1016/j.engappai.2025.112306},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112306},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature-enhanced edge-INverse attention network for skin lesion segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A severity indicator for unsupervised fault severity shift detection of heating, ventilation, and air conditioning sub-system faults using a novel adaptive feature weighing method. <em>EAAI</em>, <em>162</em>, 112305. (<a href='https://doi.org/10.1016/j.engappai.2025.112305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault-free functioning of Heating, Ventilation, and Air Conditioning (HVAC) systems is essential for reducing energy waste in modern-day buildings. Hence, data-driven approaches for HVAC fault detection have gained popularity. Faults become more severe with time. Fault detection reveals the presence of an anomaly, but it does not convey how critical the fault severity is. Fault severity indication provides this essential context, enabling urgent resource allocation to more severe faults, adding practical significance. However, faults being rare, obtaining substantial data at different severity levels to train supervised Machine Learning models is a realistic challenge. Therefore, we propose a method for estimating fault severity in an unsupervised setting. We define a robust Severity Indicator (SI) that reflects the shift in the severity levels of a fault. First, we define a healthy domain boundary for fault-free data using One-Class Support Vector Machines. SI scores are then computed using a novel adaptive feature weighing algorithm that assigns weights to individual features, adaptively, for every fault. We focus on detecting the shift in severity, rather than quantifying it. The study of the robustness of SI for different faults in HVAC subsystems, chillers, and air handling units (AHUs) yields consistently promising results. Our comparative analysis shows that our method outperforms the unweighted approach and existing state-of-the-art techniques for fault severity estimation. Notably, our method excels in detecting low-severity faults, addressing a common limitation in current methods.},
  archive      = {J_EAAI},
  author       = {Ramnath V. Prabhu Bam and Rajesh S. Prabhu Gaonkar and Clint Pazhayidam George},
  doi          = {10.1016/j.engappai.2025.112305},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112305},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A severity indicator for unsupervised fault severity shift detection of heating, ventilation, and air conditioning sub-system faults using a novel adaptive feature weighing method},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Propeller fault-detection method for electric-propulsion aircraft using motor signals and generative model-based semi-supervised learning. <em>EAAI</em>, <em>162</em>, 112301. (<a href='https://doi.org/10.1016/j.engappai.2025.112301'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failures in propulsion components, such as propellers, can critically affect flight safety; thus, early failure detection, preferably before flight, is essential. Traditional fault-diagnosis methods typically rely on additional sensors or operational data, which may not be available or practical in all situations. This study addresses these challenges by introducing motor-electric-signal-based fault diagnosis that is independent of airframe configuration and can detect faults, even when the aircraft is not in operation. However, difficulties arise owing to poor class variance in motor-electric-signal data and the challenge of obtaining fault data. To overcome these issues, a semi-supervised learning model based on a modified variational autoencoder-generative adversarial network (VAE-GAN) is proposed, which predicts faults using only normal motor-electric-signal data. Additionally, a new preprocessing method and patch-based ensemble inference technique are introduced to improve the poor class-variance characteristics of the data, thereby enhancing the prediction performance. This work demonstrates that propeller faults can be successfully diagnosed using motor-electric signals without the need for additional sensors or fault-data acquisition.},
  archive      = {J_EAAI},
  author       = {Sanga Lee and Dohyeong Kim and Minkyun Noh and Shinkyu Jeong and Jikang Kong and Youngjun Yoo},
  doi          = {10.1016/j.engappai.2025.112301},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112301},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Propeller fault-detection method for electric-propulsion aircraft using motor signals and generative model-based semi-supervised learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep Q-network-driven multi-objective evolutionary algorithm for distributed heterogeneous hybrid flow shop scheduling with worker fatigue. <em>EAAI</em>, <em>162</em>, 112292. (<a href='https://doi.org/10.1016/j.engappai.2025.112292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hybrid flow shop scheduling problem (HFSP) is a prominent challenge in advanced manufacturing systems. Existing research often overlooks the impact of workers in production shops or treats worker fatigue as a static parameter, failing to capture its nonlinear accumulation and recovery effects on processing efficiency. However, with the advent of Industry 5.0, there has been a growing emphasis on the critical role of human factors in production scheduling. As a result, designing an effective algorithm for HFSP that considers human factors has become a prominent research focus. In this paper, an extended distributed heterogeneous hybrid flow shop scheduling problem with the dynamic effects of worker fatigue (DHHFSP-WF) is investigated. To address this problem, a Deep Q-Network-based multi-objective optimization algorithm (DQNMOEA) is designed to minimize makespan, total energy consumption (TEC), and total worker idle time (WIT). In DQNMOEA, a four-dimensional vector encoding scheme considering worker allocation represents solution, and a reconstruction strategy ensures initial population quality and diversity. Moreover, an improved order crossover, two-point crossover, and a segment-based recombination mutation method are proposed to enhance the global search performance of the algorithm. Then, a problem-specific local search strategy is designed for each layer of the vector, allowing the Deep Q-Network (DQN)-based adaptive decision-making mechanism to perform local perturbations on the current non-dominated solutions in the most suitable dimensions. Finally, seven algorithms are adopted to make a comparison on 36 sets of instances, the experimental results indicate that DQNMOEA exhibits competitive performance in solving DHHFSP-WF.},
  archive      = {J_EAAI},
  author       = {Jianlin Zhang and Longbin Ma and Wu Zhao and Jie Cao and Zuohan Chen and Tianpeng Xu},
  doi          = {10.1016/j.engappai.2025.112292},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112292},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep Q-network-driven multi-objective evolutionary algorithm for distributed heterogeneous hybrid flow shop scheduling with worker fatigue},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical binary diffing with inductive code representation learning with graph sampling-and-aggregate. <em>EAAI</em>, <em>162</em>, 112279. (<a href='https://doi.org/10.1016/j.engappai.2025.112279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary program diffing, or simply binary diffing, is a type of program analysis technique that quantifies the similarity between two binary programs to derive their differences. In particular, binary diffing is an essential technique for uncovering vulnerabilities and potential attack vectors in industrial control systems, where patch deployment is complicated by closed and restricted environments. Studies on binary diffing can be broadly categorized into dynamic analysis-based, static analysis-based, and neural network-based approaches. Each category of existing studies has its shortcomings, including limited coverage, low accuracy, and issues with on-demand learning. In this paper, we propose the binary diffing with sampling-and-aggregate, a hierarchical binary diffing model that generates inductive code representations based on graph sampling-and-aggregate. Our model sequentially produces instruction-level embedding, block-level embedding, and function-level embedding from the inter-procedural control flow graph of a given program, and then performs hierarchical code diffing based on these embeddings. We formally define the detailed models and present the algorithm of hierarchical binary diffing. Additionally, we conduct a thorough analysis of this algorithm, deriving several advantages. We implemented a prototype and evaluated it on a large-scale dataset in a cross-version, cross-optimization, and obfuscation settings. Our prototype showed F1-scores up to 0.96 and 0.968 in cross-version setting for function and basic block diffing, respectively. Also, our method demonstrated its robustness over several binary obfuscations. In conclusion, our proposal, which generates basic block- and function-level embedding by considering the control flow, has solid advantages on binary diffing and shows the robustness on the binary tampering.},
  archive      = {J_EAAI},
  author       = {Seungho Jeon and Kijong Koo and Daesung Moon and Jung Taek Seo},
  doi          = {10.1016/j.engappai.2025.112279},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112279},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical binary diffing with inductive code representation learning with graph sampling-and-aggregate},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear excavation load prediction of hydraulic excavator based on gated recurrent unit neural network. <em>EAAI</em>, <em>162</em>, 112278. (<a href='https://doi.org/10.1016/j.engappai.2025.112278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Excavator arms are integral to the mining and construction industries, where real-time excavation load prediction is a critical element for the advancement of automated excavation technology. This study presents a novel Physics-guided Neural Network (PGNN) designed to predict the excavating force of hydraulic cylinders used in earthwork excavation. The PGNN model synergizes the physical load model of excavators with a Gated Recurrent Unit (GRU) neural network and is optimized using the Hyperband algorithm to attain both high-speed and precise forecasting. Through comparative experiments, the study validates the PGNN model's ability to achieve optimal response speed and precision in predicting excavation loads. Additionally, the predictive performance of the PGNN model is assessed via a Hardware-in-the-loop (HIL) test, conducted within the context of an actual excavation experiment. This research introduces a promising approach that seamlessly integrates physics-based modeling with machine learning techniques, facilitating real-time load forecasting for excavators. The findings pave the way for more efficient and precise excavation processes, with implications for the broader fields of mining and construction automation.},
  archive      = {J_EAAI},
  author       = {Jinshi Chen and Yue Yu and Dongyang Huo and Han Zhang and Jingyan Wang},
  doi          = {10.1016/j.engappai.2025.112278},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112278},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Nonlinear excavation load prediction of hydraulic excavator based on gated recurrent unit neural network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Plug-and-play fine grained neural cognitive diagnosis framework. <em>EAAI</em>, <em>162</em>, 112276. (<a href='https://doi.org/10.1016/j.engappai.2025.112276'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive diagnosis (CD) is a core task in intelligent education, which accurately assesses students’ mastery of specific knowledge concepts (KCs) by analyzing their answer records. However, existing methods mainly rely on explicit interaction data and use diagnostic models for automatic knowledge proficiency inference. These methods lack systematic optimization for fine-grained knowledge level representation, making it difficult to fully reflect students’ true learning status. To address this, this paper introduces a Plug-and-Play F ine Grained N eural C ognitive D iagnosis Framework (FNCD) with Knowledge-Level Constraint Awareness . The framework combines a knowledge proficiency evaluation module with students’ answer records and a Q-matrix to statically assess knowledge mastery. It uses a student similarity construction method based on random grouping to reveal latent learning pattern associations. Additionally, it employs a multi-scale relational learning strategy and a Top-k attention-enhanced graph network mechanism to dynamically adjust the student similarity relationship network, accurately modeling the complex learning relationships between students. Ultimately, a joint training mechanism is used to optimize the outputs of each module, significantly improving the rationality, interpretability, and accuracy of CD. The experimental results demonstrate that FNCD, as an artificial intelligence-driven plug-and-play module, can be effectively integrated into existing CD models to enhance the modeling of fine-grained knowledge mastery and improve diagnostic accuracy, showcasing the application potential of artificial intelligence in personalized education.},
  archive      = {J_EAAI},
  author       = {Xinjie Sun and Qi Liu and Kai Zhang and Weiyin Gong and Shuanghong Shen and Fei Wang and Yan Zhuang and Meikai Bao and Shijin Wang and Yuling Ma and Enhong Chen},
  doi          = {10.1016/j.engappai.2025.112276},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112276},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Plug-and-play fine grained neural cognitive diagnosis framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight citrus detection and counting method based on deep learning model. <em>EAAI</em>, <em>162</em>, 112268. (<a href='https://doi.org/10.1016/j.engappai.2025.112268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Picking robots have become an important development direction of smart agriculture, and the accurate detection, counting and lightweight deployment of fruits are the technical basis for realizing robot picking. However, due to complex weather conditions and the possible mutual occlusion between branches and citrus, it is challenging to accurately detect and count citrus in orchards. This study proposes a lightweight small target detection model for detecting and counting citrus, and deploys it on the citrus detection platform. The model first introduces FasterNet Block into the cross-stage partial feature fusion module of the backbone network to reduce the number of parameters and calculations while improving the detection accuracy of the network. Secondly, a multi-scale attention mechanism is added to the backbone network to enhance the feature extraction ability of the network. Finally, a bounding box loss function based on a dynamic non-monotonic focusing mechanism is used to increase the model convergence speed and further improve the model accuracy. Experimental results show that the model has an accuracy of 92.7%, an average precision of 91.7%, and a model size of only 5.37 megabytes. The lightweight model is applied to the citrus detection platform. Based on this application, a citrus counting method is proposed, which obtains a mean absolute error (MAE) of 0.92, a root mean square error (RMSE) of 1.28, a determination coefficient ( R 2 ) of 0.98, and a frame rate of 80.6 per second, which meets the requirements of real-time citrus detection and counting. This provides technical support for the subsequent deployment and counting research of picking robots.},
  archive      = {J_EAAI},
  author       = {Jiqing Chen and Mingchang Zhang and Bin Lu and Quan Chen and Zhiwu Jiang and Peilin Li and Jingyao Gai},
  doi          = {10.1016/j.engappai.2025.112268},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112268},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight citrus detection and counting method based on deep learning model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stacked machine learning-based probabilistic seismic demand and risk assessment of railway embankments with variable slopes. <em>EAAI</em>, <em>162</em>, 112245. (<a href='https://doi.org/10.1016/j.engappai.2025.112245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate seismic risk assessment of railway embankments is critical for risk mitigation, seismic design, and emergency planning. However, conventional methods often suffer from computational inefficiency and complexity. This study proposes a novel machine learning (ML) framework to rapidly and accurately evaluate probabilistic seismic demand and risk for railway embankments. Latin hypercube sampling is utilised to generate representative soil parameter samples to construct numerical models for simulating dynamic responses under near-fault pulse-like ground motions. The peak permanent settlement (PPS) of the embankment surface is used as the key performance metric. Multiple ML models, including decision trees, random forests (RFs), extreme gradient boosting (XGBoost), artificial neural networks (ANNs), and a stacked ML model that integrates RFs, XGBoost, and ANNs, are trained and compared. The stacked ML model outperforms the other models and achieves the highest predictive accuracy for the PPS. SHapley Additive exPlanations are used to identify the velocity spectrum intensity (VSI) and the internal friction angle of the embankment as the most influential factors. Seismic fragility and risk curves are subsequently developed. The VSI and a power-law seismic hazard function are combined to estimate the annual exceedance probabilities for three seismic design criteria levels. The proposed ML framework significantly enhances the efficiency of seismic risk analysis while maintaining high precision, thereby providing a transformative approach for the seismic assessment of railway embankments.},
  archive      = {J_EAAI},
  author       = {Pan Si and Liang Tang and Shuang Tian and Xianzhang Ling and Yanfang Liu},
  doi          = {10.1016/j.engappai.2025.112245},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112245},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Stacked machine learning-based probabilistic seismic demand and risk assessment of railway embankments with variable slopes},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive chemical industrial processes fault detection model based on sparse filtering-based improved mixed-gaussian probabilistic principal component analysis considering low-probability events. <em>EAAI</em>, <em>162</em>, 112236. (<a href='https://doi.org/10.1016/j.engappai.2025.112236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic Principal Component Analysis (PPCA) is widely used in process monitoring. However, its underlying assumption that data follows a Gaussian distribution limits its effectiveness in handling Low Probability Events (LPEs), which often deviate from this assumption. To address this challenge, we propose a novel method called Sparse Filtering-based Improved Mixed-Gaussian Probabilistic Principal Component Analysis (SFIMPPCA) for enhanced LPEs detection. First, a Sparse Filtering (SF) preprocessing technique with an incremental structure is employed to extract the most discriminative features. Second, to address the distortion caused by LPEs, a dynamic ratio correction mechanism based on statistical variability is introduced, followed by a newly designed Mixed-Gaussian Probabilistic Principal Component Analysis (MPPCA). Third, a Bayesian Optimization Algorithm (BOA) is applied to automatically adjust control limits, enhancing the accuracy and reliability of fault detection. The effectiveness of the proposed method is validated using the Tennessee Eastman (TE) process and the Tin Chemical Process (TCP). Experimental results demonstrate that the proposed method significantly improves performance under LPEs conditions, achieving a 10%–12% improvement in most cases.},
  archive      = {J_EAAI},
  author       = {Chuangyan Yang and Jiande Wu and Peng Li and Xun Lang and Mingxi Ai and Hancheng Wang},
  doi          = {10.1016/j.engappai.2025.112236},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112236},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive chemical industrial processes fault detection model based on sparse filtering-based improved mixed-gaussian probabilistic principal component analysis considering low-probability events},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAE-diff: Masked-AutoEncoder-guided diffusion framework for source-free domain adaptive medical image segmentation. <em>EAAI</em>, <em>162</em>, 112219. (<a href='https://doi.org/10.1016/j.engappai.2025.112219'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain gaps can often cause dramatic performance deterioration when applying medical image segmentation models trained on the source domain to the target domain. Although unsupervised domain adaptation methods can address the domain gap challenge to some extent, their reliance on accessing source images largely hampers their practical applicability, as source data are often inaccessible due to privacy concerns. Moreover, the low-quality characteristic of medical images can further degrade the domain adaptation performance of segmentation models. To address these issues, we propose the Masked-AutoEncoder-guided Diffusion (MAE-Diff) framework for source-free domain adaptive medical image segmentation. MAE-Diff mainly consists of a Masked AutoEncoder (MAE) Module for effective feature extraction and domain adaptation, and a Diffusion Module for effective segmentation of low-quality medical images. On source images, the MAE encoder is trained to extract image-specific features, and the Diffusion Module is trained to generate segmentation maps following a gradual denoising strategy, under the guidance of features extracted by the MAE encoder. Training on the target domain involves only fine-tuning MAE (trained on the source images) with target images, allowing MAE-Diff to adapt to the target domain distribution. Inference on target images can then be made by the source-based Diffusion Module, under the guidance of features extracted by the MAE encoder fine-tuned on the target images. Extensive experiments on three datasets demonstrate the effectiveness of the proposed framework for source-free domain-adaptive medical image segmentation. The code of MAE-Diff is available at https://github.com/xuss804/MAEDiff .},
  archive      = {J_EAAI},
  author       = {Shanshan Xu and Le Xu and Yeqing Yang and Lixia Tian},
  doi          = {10.1016/j.engappai.2025.112219},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112219},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MAE-diff: Masked-AutoEncoder-guided diffusion framework for source-free domain adaptive medical image segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic-static siamese Takagi–Sugeno-kang fuzzy system with inductive-reflection deep fuzzy rule. <em>EAAI</em>, <em>162</em>, 112199. (<a href='https://doi.org/10.1016/j.engappai.2025.112199'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The first-order Takagi–Sugeno–Kang (TSK) fuzzy classifiers are famous for their high computational efficiency and strong interpretability, but they often struggle to learn from complex and large-scale datasets, and perform not very well compared to higher-order TSK fuzzy classifiers. To address this issue, in this paper we propose a novel Dynamic-Static Siamese TSK Fuzzy classifier with Inductive-Reflection Deep Fuzzy rule. It aims to enhance the model’s self-learning capabilities by utilizing Siamese network to integrate deep fuzzy knowledge and fine-grained knowledge without the need for a teacher model. The innovations of this study are as follows: (1) The deep fuzzy rules in the proposed classifier are enriched with an “Inductive-Reflection” process, which reduces constraints on traditional basic fuzzy rule and aligns rule acquisition more closely with general human thinking manners; (2) The proposed method includes a mechanism for self-learning and improvement from both deep and fine-grained fuzzy knowledge, eliminating the complexity of retraining a new teacher model; (3) An adaptive learning function is developed to effectively adjust the learning process, adapting to tasks with different complexities. Extensive experiments results on benchmark datasets, as well as two real-world datasets, demonstrate the effectiveness of the proposed classifier in terms of classification accuracy and weighted F1-score.},
  archive      = {J_EAAI},
  author       = {Xiongtao Zhang and Qihuan Shi and Yunliang Jiang and Qing Shen and Jungang Lou and Ruiqin Wang},
  doi          = {10.1016/j.engappai.2025.112199},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112199},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic-static siamese Takagi–Sugeno-kang fuzzy system with inductive-reflection deep fuzzy rule},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new design of arithmetic and logic unit for enhancing the security of future internet of things devices using quantum-dot technology. <em>EAAI</em>, <em>162</em>, 112113. (<a href='https://doi.org/10.1016/j.engappai.2025.112113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) is a network of interconnected devices that collect, monitor, analyze, and exchange data. This technology plays a crucial role in the smart city infrastructure by seamlessly interconnecting various nodes. The extensive application and recognition of IoT across multiple city domains, such as healthcare, transportation, energy, education, and agriculture, bring significant challenges, with security among the most pressing. Traditional hardware technologies like Complementary Metal Oxide Semiconductor (CMOS) and Very Large Scale Integration (VLSI) suffer from limitations such as high power consumption and insufficient scalability, which hinder secure and sustainable IoT deployment. Such limitations have prompted the need to seek other technologies that would serve the dual purpose of providing security as well as energy. Quantum-based technologies can become adequate candidates offering promising solutions to make IoT devices and sustainable systems more secured. Quantum-dot Cellular Automata (QCA) has been proposed as a nanotechnology with the potential of consuming ultra-low powers, less area, and high-speed operation. QCA enhances security through sustainable computing objectives by minimizing energy usage. To improve the future security and efficiency of IoT hardware, this paper suggests a QCA-based Arithmetic Logic Unit (ALU). This ALU can generate more than 12 logical and arithmetic operations. Designed together with the majority gates, XOR gates, multiplexers, and full adders, the ALU is simulated using the QCA-Designer 2.0.3. Simulated results indicate improvements in the number of cells and reduced occupied area relative to the earlier designs. These results indicate the potential of QCA technology in enabling secure, energy-efficient, and compact computing architecture applicable in the future IoT.},
  archive      = {J_EAAI},
  author       = {Maryam Zaker and Seyed Sajad Ahmadpour and Nima Jafari Navimipour and Muhammad Zohaib and Neeraj Kumar Misra and Sankit Kassa and Ahmad Habibizad Navin and Arash Heidari and Mehdi Hosseinzadeh and Omar I. Alsaleh},
  doi          = {10.1016/j.engappai.2025.112113},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112113},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new design of arithmetic and logic unit for enhancing the security of future internet of things devices using quantum-dot technology},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
