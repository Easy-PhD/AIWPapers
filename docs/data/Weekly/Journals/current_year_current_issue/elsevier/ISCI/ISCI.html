<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ISCI</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="isci">ISCI - 27</h2>
<ul>
<li><details>
<summary>
(2026). Robust watermarking for diffusion model generated images. <em>ISCI</em>, <em>723</em>, 122686. (<a href='https://doi.org/10.1016/j.ins.2025.122686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the wide application of diffusion models in the field of image generation, image copyright protection and traceability have become increasingly complex and challenging. To address these problems, this paper proposes a robust watermarking method for diffusion model generated images to achieve their copyright protection and traceability. The method designs an invertible mapping module to replicate and cryptographically map the watermark information into an approximately Gaussian distributed noise, which is highly consistent with the distribution of the original generation model. The mapped watermark noise serves as the latent space vector of the generative model, preserving both image generation quality and model performance. In the watermark extraction stage, the original watermark information can be accurately recovered from the generated image through the reverse extraction and voting mechanism. Experimental results show that the proposed method demonstrates excellent performance in terms of image watermark extraction accuracy, robustness and watermark image generation quality. It can still maintain 99 % true positive rate and 97.5 % bit accuracy under various attacks, and the overall performance in the detection and traceability scenarios is significantly better than the existing baseline methods.},
  archive      = {J_ISCI},
  author       = {Ziqi Liu and Yuan Guo and Liansuo Wei},
  doi          = {10.1016/j.ins.2025.122686},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122686},
  shortjournal = {Inf. Sci.},
  title        = {Robust watermarking for diffusion model generated images},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SEAD-MGFE-net: Schrödinger equation-based adaptive dropout multi-granular feature enhancement network for conversational aspect-based sentiment quadruple analysis. <em>ISCI</em>, <em>723</em>, 122684. (<a href='https://doi.org/10.1016/j.ins.2025.122684'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research focuses on enhancing the extraction of sentiment quadruples consisting of target, aspect, opinion, and sentiment from multi-turn dialogs, which remains a challenging problem in conversational sentiment analysis. Existing methods frequently encounter challenges with complex sentence structures, presence of multiple sentiment quadruples, and interference from irrelevant contextual information. These challenges often result in suboptimal performance. These limitations are addressed by introducing Schrödinger equation-based adaptive dropout multi-granular feature enhancement network (SEAD-MGFE-Net), a novel framework that synergizes multigranular feature extraction with quantum-inspired adaptive regularization. The proposed methodology incorporates a multi-layer tree structure to segment sentences into semantically coherent fragments, thereby improving the alignment between aspect and opinion terms while simultaneously mitigating noise impact. Moreover, we engineer a multi-angle dynamic adjacency learning enhancement module that adeptly captures both local and global features inherent in graph-structured representations. Additionally, we devise an adaptive dropout mechanism based on the Schrödinger equation, facilitating automatic modulation of the regularization strength throughout training. Extensive evaluations on benchmark datasets in both Chinese and English validate the state-of-the-art effectiveness of our proposed SEAD-MGFE-Net model, achieving Micro-F1 scores of 46.53 % (Chinese) and 40.97 % (English), surpassing the strongest baseline models by 2.04 % and 1.57 %, respectively. SEAD-MGFE-Net exhibits efficacy in extracting cross-utterance quadruples and managing long-range dependencies. These findings confirm the effectiveness and broad applicability of SEAD-MGFE-Net for conversational sentiment analysis.},
  archive      = {J_ISCI},
  author       = {Wei Liu and Xiaoliang Chen and Duoqian Miao and Hongyun Zhang and Xiaolin Qin and Shangyi Du and Peng Lu},
  doi          = {10.1016/j.ins.2025.122684},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122684},
  shortjournal = {Inf. Sci.},
  title        = {SEAD-MGFE-net: Schrödinger equation-based adaptive dropout multi-granular feature enhancement network for conversational aspect-based sentiment quadruple analysis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Byzantine-resilient federated learning with dynamic scoring matrix and variant PBFT consensus under differential privacy. <em>ISCI</em>, <em>723</em>, 122682. (<a href='https://doi.org/10.1016/j.ins.2025.122682'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing concerns regarding data privacy exacerbate the challenges associated with “data silos”. Federated learning (FL) effectively addresses these issues by facilitating distributed machine learning without necessitating direct data exchange. However, the dependence on a central server in conventional FL architectures exacerbates privacy risks and limits cross-domain data sharing. Existing blockchain-based FL frameworks often employ static consensus protocols, such as classical Practical Byzantine Fault Tolerance (PBFT), which typically rely on fixed weight aggregation strategies. While these methods simplify implementation, they fail to adaptively adjust aggregation weights according to heterogeneous privacy budgets. Attempts to implement adaptive weight aggregation often require achieving consensus for each individual weight, significantly reducing efficiency and creating scalability challenges in large-scale networks. To address these gaps, we propose DSM-PBFT, a variant PBFT consensus enhanced with dynamic scoring matrices (DSM), which enables parallelized validation of multiple models while adaptively adjusting aggregation weights based on differential privacy budgets. Our noise-aware aggregation mechanism dynamically reweights models through cross-validation of accuracy, F1 score, and loss-transformed metrics, effectively decoupling privacy guarantees from model utility degradation. Security analyses affirm the robustness of this framework against Byzantine attacks, with experimental results on MNIST, FashionMNIST and CIFAR-10 demonstrating superior model accuracy across diverse privacy budgets while effectively curbing accuracy degradation under attack scenarios.},
  archive      = {J_ISCI},
  author       = {Wentai Yang and Xian Xu and Kai Yu and Guoqiang Li},
  doi          = {10.1016/j.ins.2025.122682},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122682},
  shortjournal = {Inf. Sci.},
  title        = {Byzantine-resilient federated learning with dynamic scoring matrix and variant PBFT consensus under differential privacy},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Subsequence heterogeneity contrastive learning for time series anomaly detection. <em>ISCI</em>, <em>723</em>, 122680. (<a href='https://doi.org/10.1016/j.ins.2025.122680'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series anomaly detection is widely applied across various real-world scenarios. Recently, contrastive learning has shown remarkable ability in learning discriminative representations for detecting anomalies. However, most existing contrastive-based methods rely on complex contrastive mechanisms and specially designed model architectures, which make it difficult to maintain efficiency and flexibility across various application scenarios. To address this limitation, we introduce Subsequence-Heterogeneity that defined as the discrepancies in variation patterns and statistical characteristics between subsequences obtained through fixed-interval sampling, which are more pronounced in anomalous sequences than in normal ones. It can serve as a natural discrimination criterion and eliminate the need for complex contrastive mechanisms and specialized model architectures. Specifically, we adopt an efficient temporal hierarchical masking strategy with linear complexity to construct two branches for learning representations at different granularities. The Subsequence-Heterogeneity Contrastive Learning (SHCL) is implemented with different neural networks and enables flexible application to anomaly detection across diverse scenarios. Experiments on eight benchmark datasets demonstrate that SHCL not only achieves state-of-the-art performance with reduced time and resource costs but also significantly improves the ability of different neural networks to distinguish normal from anomalous patterns. The source code is publicly available at https://github.com/Zhangzzbzzb/SHCL/ .},
  archive      = {J_ISCI},
  author       = {Zhibin Zhang and Xiaohong Zhang and Qiang Li and Chun Huang and Tao Yin and Meng Yan},
  doi          = {10.1016/j.ins.2025.122680},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122680},
  shortjournal = {Inf. Sci.},
  title        = {Subsequence heterogeneity contrastive learning for time series anomaly detection},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Escrow-free attribute based signature with constant-size for the internet of things. <em>ISCI</em>, <em>723</em>, 122679. (<a href='https://doi.org/10.1016/j.ins.2025.122679'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute based signature (ABS) provides a promising solution for anonymous authentication. However, numerous prevailing ABS algorithms are ill-suited for anonymous authentication in the Internet of Things (IoT), due to problems such as key escrow, high computational overhead, inflexible access policies, and vulnerability to collusion attacks. Considering these shortcomings, we present an escrow-free attribute based signature with constant-size signature for IoT. Our proposal uses the linear secret-sharing scheme (LSSS) and the notion of certificateless cryptography to restrict the authorities of each attribute authority and the system authority. In addition, it generates a constant-size signature and achieves high verification efficiency by aggregating attribute keys. Theoretical analyses demonstrate that our proposal achieves anonymous authentication and is provably secure under the standard model. Simulation experiments show that the execution time of our algorithm is less than 50 ms to run during both the signature and verification phases, making it well-suited for applications with limited resources.},
  archive      = {J_ISCI},
  author       = {Xudong Liu and Xiaojun Tong and Yihui Wang},
  doi          = {10.1016/j.ins.2025.122679},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122679},
  shortjournal = {Inf. Sci.},
  title        = {Escrow-free attribute based signature with constant-size for the internet of things},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep dual contrastive learning for multi-view subspace clustering. <em>ISCI</em>, <em>723</em>, 122678. (<a href='https://doi.org/10.1016/j.ins.2025.122678'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering (MVSC) aims to learn a consistent shared self-representation by utilizing the consistency and complementarity of all views, numerous MVSC algorithms have attempted to obtain the optimal representation directly from raw features. However, they might overlook the noisy or redundant information in raw feature space, resulting in learning suboptimal self-representation and poor performance. To address this limitation, an intuitive idea is introducing deep neural networks to eliminate the noise and redundancy, yielding a potential embedding space. Nevertheless, existing deep MVSC methods merely focus on either the embeddings or self-expressions to explore the complementary information, which hinders subspace learning. In this paper, we present a deep multi-view dual contrastive subspace clustering framework to exploit the complementarity to learn latent self-representations effectively. Specifically, multi-view encoders are constructed to eliminate noise and redundancy of the original features and capture low-dimensional subspace embeddings, from which the self-representations are learned. Moreover, two diverse specific fusion methods are conducted on the latent subspace embeddings and the self-expressions to learn shared self-representations, and dual contrastive constraints are proposed to fully exploit the complementarity among views. Extensive experiments are conducted to verify the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Xincan Lin and Jie Lian and Zhihao Wu and Jielong Lu and Shiping Wang},
  doi          = {10.1016/j.ins.2025.122678},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122678},
  shortjournal = {Inf. Sci.},
  title        = {Deep dual contrastive learning for multi-view subspace clustering},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Parameter-free discrete clustering via adaptive hypergraph fusion. <em>ISCI</em>, <em>723</em>, 122677. (<a href='https://doi.org/10.1016/j.ins.2025.122677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based clustering has garnered significant attention due to its outstanding performance in uncovering sample structures. However, existing graph-based methods face two major challenges: 1) In graph construction, they typically focus only on direct connections between samples or an exact high-order relationship, neglecting the impact of hidden complex relationships on clustering performance; 2) The separation of spectral analysis and category acquisition into two distinct stages often results in a loss of effectiveness. To handle these problems, we propose a parameter-free discrete clustering method, called parameter-free discrete clustering via adaptive hypergraph fusion (DCAHF). Specifically, DCAHF first produces multiple different hypergraphs, each serving as a biased approximation of the data's intrinsic manifold. These complementary approximations capture distinct local-to-global geometric patterns. Then, it introduces an adaptive fusion strategy that learns optimal weights to combine them into a single consensus hypergraph on manifold space, effectively reconstructing the real manifold structure with reduced bias and improved integrity. Finally, discrete spectral analysis is performed directly on the consensus hypergraph to generate discrete sample categories, thereby avoiding the performance loss associated with two-stage approaches. Thus, DCAHF is a high-performance, parameter-free clustering model that can flexibly adapt to various clustering tasks. Since the DCAHF model cannot be solved using gradient descent methods, we develop a coordinate descent-based optimization algorithm to efficiently solve the model. Extensive experimental results demonstrate that DCAHF significantly enhances clustering effectiveness while maintaining comparable efficiency to state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Yu Zhou and Ben Yang and Xuetao Zhang and Badong Chen},
  doi          = {10.1016/j.ins.2025.122677},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122677},
  shortjournal = {Inf. Sci.},
  title        = {Parameter-free discrete clustering via adaptive hypergraph fusion},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-branch semantic alignment for few-shot image classification. <em>ISCI</em>, <em>723</em>, 122676. (<a href='https://doi.org/10.1016/j.ins.2025.122676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remarkable progress of deep learning in computer vision has significantly stimulated research interest in few-shot image classification. This field aims to transfer knowledge from previous experiences to recognize new concepts with limited samples. However, most existing approaches primarily concentrate on aligning semantic information at high-level features, neglecting the importance of middle-level or low-level feature representations. In this paper, we propose a novel approach called Multi-Branch Semantic Alignment (MBSA) for few-shot image classification, with the objective of investigating the role of multi-level features. Instead of using standard convolutional layers, we employ diverse convolutional layers to generate enhanced representations in each branch. These representations are then utilized by a dense classifier, which is supervised by a powerful guidance mechanism to incorporate semantic information into their spatial locations. During the inference stage, the multi-branch semantic alignment is designed to align multi-level features between query images and support images. This alignment process effectively establishes semantic correspondences between representations at different levels, thereby enhancing the ability to recognize novel categories. Comprehensive experiments are conducted on various few-shot benchmarks to demonstrate the superiority of our approach compared to those of several previous approaches, and ablation studies are performed to analyze the impact of different components.},
  archive      = {J_ISCI},
  author       = {Zijun Zheng and Heng Wu and Laishui Lv and Changchun Zhang and Hongcheng Guo and Shanzhou Niu and Gaohang Yu},
  doi          = {10.1016/j.ins.2025.122676},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122676},
  shortjournal = {Inf. Sci.},
  title        = {Multi-branch semantic alignment for few-shot image classification},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Partition-based differentially private synthetic data generation. <em>ISCI</em>, <em>723</em>, 122675. (<a href='https://doi.org/10.1016/j.ins.2025.122675'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Private synthetic data sharing is beneficial as it better retains the distribution and nuances of the original data compared to summary statistics such as means and frequencies. Current state-of-the-art methods follow a select-measure-generate paradigm, but measuring large-domain marginals often leads to significant errors, and managing the privacy budget poses challenges. Our partition-based approach addresses these issues, effectively reducing errors and improving the quality of synthetic data, even with a limited privacy budget. Experimental results show that our method outperforms existing approaches, yielding synthetic data with enhanced quality and utility, making it a preferred option for private data sharing.},
  archive      = {J_ISCI},
  author       = {Meifan Zhang and Dihang Deng and Lihua Yin},
  doi          = {10.1016/j.ins.2025.122675},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122675},
  shortjournal = {Inf. Sci.},
  title        = {Partition-based differentially private synthetic data generation},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Transferable adversarial attacks on human pose estimation: A regularization and pruning framework. <em>ISCI</em>, <em>723</em>, 122674. (<a href='https://doi.org/10.1016/j.ins.2025.122674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Pose Estimation (HPE) is a core component in real-time decision systems, supporting critical applications such as healthcare monitoring, autonomous driving, and sports analytics. While deep learning models—particularly CNNs and Transformer-based architectures—have significantly improved HPE accuracy, they remain vulnerable to adversarial perturbations that subtly distort keypoint localization, thereby undermining system reliability. To address this challenge, we propose regularization and pruning transferable adversarial attack (RPA), a novel framework designed to enhance the transferability of adversarial samples in Transformer-based HPE models. RPA integrates two synergistic strategies: gradient regularization, which suppresses dominant feature correlations to reduce overfitting, and adaptive weight pruning, which removes redundant parameters to reduce model-specific noise. This dual mechanism enables the generation of transferable adversarial attacks that are effective across diverse model architectures. Extensive experiments on state-of-the-art HPE networks demonstrate that RPA consistently outperforms existing attack methods. In white-box settings, RPA reduces average precision (AP) by 0.05-0.30; in black-box scenarios, it yields AP drops of 0.01-0.04. These findings expose critical vulnerabilities in IoT-enabled HPE applications and establish a new benchmark for evaluating adversarial robustness in real-time perception systems.},
  archive      = {J_ISCI},
  author       = {Renguang Chen and Xuechao Yang and Xun Yi and Zhide Chen and Chen Feng and Xu Yang and Kexin Zhu and Iqbal Gondal},
  doi          = {10.1016/j.ins.2025.122674},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122674},
  shortjournal = {Inf. Sci.},
  title        = {Transferable adversarial attacks on human pose estimation: A regularization and pruning framework},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CF2M-net: Cross-feature fusion and memory-constraint network for video anomaly detection. <em>ISCI</em>, <em>723</em>, 122673. (<a href='https://doi.org/10.1016/j.ins.2025.122673'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection (VAD) aims to automatically identify anomalous events in surveillance videos that are significantly different from the normal pattern. Most existing methods learn the spatial-temporal distribution of normal features and detect deviations as anomalies. Typically, they employ autoencoders to independently learn appearance and motion features, but this separate learning limits the exploitation of their interrelation in real-world scenarios. To enhance the representation of normal patterns by capturing feature interrelation, we propose a cross-feature fusion and memory-constraint network (CF 2 M-Net) for VAD. Specifically, inspired by the representational ability of cross-attention in multimodal fusion, we design a cross-attention and memory-constraint (CM) module to enrich appearance features with motion information. To prevent overfitting to anomalous events, the memory-constraint module further constrains fused features within the distribution of normal patterns. We design an attention fusion (AF) decoder to predict normal features closer to the normal distribution, enhancing their separability from anomalies. By jointly modeling appearance and motion through feature fusion and memory constraints, CF 2 M-Net provides more discriminative normal representations for anomaly detection. Experimental evaluations on three benchmark datasets show that the CF 2 M-Net performs comparably with leading approaches. Moreover, the detailed evaluations indicate the effectiveness of normal representation based appearance-motion fusion features for VAD.},
  archive      = {J_ISCI},
  author       = {Qiming Ma and Chengyou Wang and Xiao Zhou},
  doi          = {10.1016/j.ins.2025.122673},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122673},
  shortjournal = {Inf. Sci.},
  title        = {CF2M-net: Cross-feature fusion and memory-constraint network for video anomaly detection},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed data-driven event-triggered secure consensus control of MASs: A global preset-time performance constraint method. <em>ISCI</em>, <em>723</em>, 122672. (<a href='https://doi.org/10.1016/j.ins.2025.122672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the distributed data-driven event-triggered secure consensus control issue for model-free multi-agent systems (MASs) under sensor faults and denial-of-service (DoS) attacks, while satisfying prescribed performance constraints. First, a global preset-time performance function (PTPF) is constructed to guarantee the global stability of model-free MASs within the preset time. The proposed PTPF ensures that the preset time remains unaffected by variations in the sampling period. Second, a proportional-integral-derivative (PID) sliding surface is designed to enhance MAS performance regulation, while a novel generalized fuzzy hyperbolic model (GFHM) is constructed to eliminate the dependency on fault information and achieve high-accuracy estimation of unknown fault signals. Third, a hybrid event-triggered mechanism integrating both dynamic and memory features is developed to optimize communication resource utilization while guaranteeing robust performance at extremes. Furthermore, an event-triggered secure control scheme leveraging the memory feature is proposed to reduce communication overhead while avoiding the dangerous open-loop scenario, where control inputs must be zeroed under DoS attacks as in the existing methods. Finally, the stability proof together with simulations confirms the feasibility of the control strategy.},
  archive      = {J_ISCI},
  author       = {Run-Ze Chen and Xiang-Gui Guo and Yuan-Xin Li},
  doi          = {10.1016/j.ins.2025.122672},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122672},
  shortjournal = {Inf. Sci.},
  title        = {Distributed data-driven event-triggered secure consensus control of MASs: A global preset-time performance constraint method},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MPCMO: An improved multi-population co-evolutionary algorithm for many-objective optimization. <em>ISCI</em>, <em>723</em>, 122671. (<a href='https://doi.org/10.1016/j.ins.2025.122671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many-objective optimization problems (MaOPs) are widely used in scientific research and engineering practices, which mainly consider joint optimization of multiple objectives simultaneously. Despite the numerous multi-objective evolutionary algorithms proposed in recent years, they often struggle with challenges in fitness assignment arising from objective conflicts. Meanwhile, they tend to perform well in only one aspect of convergence, diversity, and computational complexity. To address these issues, this paper proposes an improved multi-population co-evolutionary algorithm for many-objective optimization (termed MPCMO), which leverages the advantages of multi-population co-evolutionary techniques. The primary objective of MPCMO is to achieve a more balanced performance across convergence, diversity, and complexity. MPCMO comprises three essential components. Initially, an adaptive evolutionary strategy is employed to dynamically allocate evolutionary opportunities to subpopulations so as to conserve computational resources and enhance convergence. Subsequently, a migration strategy is developed to ensure a more global approximation of whole Pareto front. Additionally, an archive update-truncation strategy, based on angle selection and shift-based density estimation, is adopted to enhance diversity. We conduct comprehensive comparative experiments on a variety of many-objective benchmark problems with complicated characteristics. Experimental results demonstrate that the proposed method outperforms existing state-of-the-art algorithms in terms of both diversity and convergence.},
  archive      = {J_ISCI},
  author       = {Weichao Ding and Jiahao Liu and Wenbo Dong and Fei Luo and Chunhua Gu},
  doi          = {10.1016/j.ins.2025.122671},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122671},
  shortjournal = {Inf. Sci.},
  title        = {MPCMO: An improved multi-population co-evolutionary algorithm for many-objective optimization},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reinforced heterogeneous graphlet design for knowledge graph representation learning. <em>ISCI</em>, <em>723</em>, 122670. (<a href='https://doi.org/10.1016/j.ins.2025.122670'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) are practical tools that represent and integrate plentiful structural and semantic information in mainstream industrial scenarios. Despite their potential, the heterogeneity and complexity of KGs pose a formidable obstacle, especially for graph representation learning. Most existing KG embedding models omit dynamic high-order connectivity patterns to gain insights into heterogeneous networks and heavily rely on handcrafted patterns to handle complex semantic relationships, which limits their capability to adaptively capture the nuanced and intricate relationships of KGs in different tasks. To fill this gap, we present Reinforced Heterogeneous Graphlet Design (ReHGD)—a model designed for KGs that focuses on the adaptive design of typed graphlets (heterogeneous chains and motifs) through a cooperative multi-agent reinforcement learning algorithm. This task-driven approach can learn discriminative graph representations tailored to specific downstream tasks. Specifically, ReHGD engages in the creation of typed graphlets through a two-stage process: it (1) establishes a reinforced chain design module to generate chains without predefined rules and (2) employs a buffer-aware sampling technique to derive episodic chains from prior experiences. Subsequently, motifs are deduced through the application of commute count and Hadamard product operations to the episodic chain-based subgraphs. In the final step toward learning graph representations, ReHGD undertakes chain and motif aggregations. Experimental results and analyses reveal that ReHGD outperforms strong baselines on three real-world graph data and practical tasks.},
  archive      = {J_ISCI},
  author       = {Jibing Gong and Yuting Lin and Yi Zhao and Tianyu Lin and Xiaohan Fang and Xinchao Feng and Jiquan Peng},
  doi          = {10.1016/j.ins.2025.122670},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122670},
  shortjournal = {Inf. Sci.},
  title        = {Reinforced heterogeneous graphlet design for knowledge graph representation learning},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatio-frequency texture analysis using wavelet increment entropy: Methodology and application to MRI in multiple sclerosis. <em>ISCI</em>, <em>723</em>, 122669. (<a href='https://doi.org/10.1016/j.ins.2025.122669'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Texture analysis is crucial for understanding images by extracting features that define spatial patterns. Recently, bi-dimensional extensions of entropy measures have gained attention due to their simplicity and strong theoretical foundations. However, existing methods primarily operate in the spatial domain and thus overlook frequency-domain and multiscale information. To address this, we introduce bidimensional wavelet increment entropy (wavelet IncrEn 2 D ). A one-level discrete wavelet transform (DWT) with the Haar wavelet decomposes each image into approximation (low-frequency) and, for some neuroimaging data, detail (high-frequency) subbands; IncrEn 2 D is then applied both to capture global structural patterns and fine, detailed texture variations. We evaluated wavelet IncrEn 2 D on synthetic and real datasets, demonstrating its effectiveness in distinguishing between different noise types (white Gaussian, salt-and-pepper, and speckle noise). Comparisons between periodic and synthesized images revealed lower wavelet IncrEn 2 D values for periodic textures. Tests on real texture datasets highlight the method's ability to differentiate various patterns. In particular, wavelet IncrEn 2 D achieved 86.69% accuracy in distinguishing MRI images of healthy versus multiple sclerosis–affected brains. Overall, wavelet IncrEn 2 D offers a robust, frequency-aware descriptor that outperforms existing 2D entropy methods.},
  archive      = {J_ISCI},
  author       = {Muqaddas Abid and Muhammad Suzuri Hitam and Rozniza Ali and Hamed Azami and Anne Humeau-Heurtier},
  doi          = {10.1016/j.ins.2025.122669},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122669},
  shortjournal = {Inf. Sci.},
  title        = {Spatio-frequency texture analysis using wavelet increment entropy: Methodology and application to MRI in multiple sclerosis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved query specialization for transformer-based visual relationship detection. <em>ISCI</em>, <em>723</em>, 122668. (<a href='https://doi.org/10.1016/j.ins.2025.122668'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Relationship Detection (VRD) has significantly advanced with Transformer-based architectures. However, we identify two fundamental drawbacks in conventional label assignment methods used for training Transformer-based VRD models, where ground-truth (GT) annotations are matched to model predictions. In conventional assignment, queries are trained to detect all relations rather than specializing in specific ones, resulting in ‘unspecialized’ queries. Also, each ground-truth (GT) annotation is assigned to only one prediction under conventional assignment, suppressing other near-correct predictions by labeling them as ‘no relation’. To address these issues, we introduce a novel method called Groupwise Query Spe ci a lization and Q uality-Aware Multi-Assignment (SpeaQ). Groupwise Query Specialization clusters queries and relations into exclusive groups, promoting specialization by assigning a set of relations only to a corresponding query group. Quality-Aware Multi-Assignment enhances training signals by allowing multiple predictions closely matching the GT to be positively assigned. Additionally, we introduce dynamic query reallocation, which transfers queries from high- to low-performing groups for balanced training. Experimental results demonstrate that SpeaQ+, combining SpeaQ with dynamic query reallocation, consistently improves performance across seven baseline models on five benchmarks without additional inference cost.},
  archive      = {J_ISCI},
  author       = {Jongha Kim and Jihwan Park and Jinyoung Park and Jinyoung Kim and Sehyung Kim and Hyunwoo J. Kim},
  doi          = {10.1016/j.ins.2025.122668},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122668},
  shortjournal = {Inf. Sci.},
  title        = {Improved query specialization for transformer-based visual relationship detection},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ConvDiff: Multi-scale spatio-temporal convolutional networks with latent diffusion models for dynamic system modeling. <em>ISCI</em>, <em>723</em>, 122656. (<a href='https://doi.org/10.1016/j.ins.2025.122656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the modeling of spatio-temporal dynamic systems, tasks such as fluid dynamics, weather forecasting, and traffic flow prediction face highly complex spatio-temporal dependencies and nonlinear dynamics. These characteristics make it challenging for traditional physical models and data-driven methods to balance accuracy and computational efficiency. To address these challenges, we propose a multi-scale spatio-temporal convolutional network named ConvDiff, optimized specifically for dynamic system modeling tasks by integrating a latent space denoising diffusion model. ConvDiff effectively captures complex spatio-temporal features and handles uncertainties in physical systems by introducing multi-scale convolutional modules combined with a physics-guided diffusion mechanism. Specifically, our model incorporates eight temporal modules and four spatial modules, using a hierarchical convolutional and diffusion structure to capture the intricate dynamics of physical systems. The experiments involved different spatio-temporal data, such as those from TaxiBJ and the Navier-Stokes dataset. According to the findings, ConvDiff demonstrates substantial improvements in essential performance indicators. For example, in the TaxiBJ dataset, ConvDiff obtained a mean squared deviation of 0.29 and a PSNR value of 40.31, outperforming the best-performing models. Moreover, on the Navier-Stokes dataset, ConvDiff reduced the MSE by 51.15% compared to the best baseline model. These results indicate that ConvDiff effectively captures complex spatio-temporal dependencies and improves prediction accuracy, particularly in physics-driven dynamic systems. Our code is available at https://github.com/Ray-zyy/ConvDiff .},
  archive      = {J_ISCI},
  author       = {Yuyang Zhao and Yuhan Wu and Yongmei Wang},
  doi          = {10.1016/j.ins.2025.122656},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122656},
  shortjournal = {Inf. Sci.},
  title        = {ConvDiff: Multi-scale spatio-temporal convolutional networks with latent diffusion models for dynamic system modeling},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A semi-heterogeneous ensemble forecasting method for stock returns based on sentiment analysis. <em>ISCI</em>, <em>723</em>, 122655. (<a href='https://doi.org/10.1016/j.ins.2025.122655'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing influence of investor sentiment on market dynamics, sentiment analysis has emerged as an effective tool for enhancing financial forecasting models. This study proposes a diversity-enhanced semi-heterogeneous ensemble forecasting framework that integrates sentiment analysis into the forecasting of stock index returns. A supervised stock market sentiment index set is constructed, in which prior knowledge regarding term importance is integrated into the data augmentation process. This enables higher weights to be assigned to sentiment-related terms with superior predictive capacity, thereby allowing the model to prioritize more informative features and enhance its forecasting performance. A series of diverse base models are generated through the integration of multiple attention-PCA techniques and forecasting algorithms based on variable perturbation strategies. These base models are subsequently combined through a suite of ensemble strategies, forming a semi-heterogeneous ensemble model for forecasting S&P 500 returns. The experiment results demonstrate that the proposed approaches significantly outperform benchmark methods, with notable improvements in both accuracy and diversity.},
  archive      = {J_ISCI},
  author       = {Xiao Zhang and Peide Liu and Jing Feng},
  doi          = {10.1016/j.ins.2025.122655},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122655},
  shortjournal = {Inf. Sci.},
  title        = {A semi-heterogeneous ensemble forecasting method for stock returns based on sentiment analysis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Energy-related controllability of corona product networks. <em>ISCI</em>, <em>723</em>, 122654. (<a href='https://doi.org/10.1016/j.ins.2025.122654'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the energy-related controllability for a category of ‘large’ composite networks generated by ‘small’ simple factor networks with Laplacian dynamics under a leader-follower framework via corona product. Different from most existing literature on network controllability, this work characterizes the controllability of corona product networks (CPNs) from an energy point of view. This can quantify the difficulty of controlling CPNs based on controllability Gramian measures, involving average controllability and volumetric control energy, etc., where the energy is triggered by the leaders. The energy-related controllability of a CPN can be explored from the eigenvalues and eigenvectors of its factor networks. An algorithm for solving the maximum average controllability is provided, which can help one select the leaders to optimize network control and be applied in practice.},
  archive      = {J_ISCI},
  author       = {Qiang Zhang and Junjie Huang and Bo Liu and Housheng Su and Alatancang Chen},
  doi          = {10.1016/j.ins.2025.122654},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122654},
  shortjournal = {Inf. Sci.},
  title        = {Energy-related controllability of corona product networks},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SeqRFM: Fast RFM analysis in sequence data. <em>ISCI</em>, <em>723</em>, 122652. (<a href='https://doi.org/10.1016/j.ins.2025.122652'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, data mining technologies have been well applied to many domains, including e-commerce. In customer relationship management (CRM), the Recency-Frequency-Monetary (RFM) analysis model is one of the most effective approaches to increase the profits of major enterprises. However, with the rapid development of e-commerce, the diversity and abundance of e-commerce data pose a challenge to mining efficiency. Moreover, in actual market transactions, the chronological order of transactions reflects customer behavior and preferences. To address these challenges, we develop an effective algorithm called SeqRFM, which combines sequential pattern mining with RFM models. SeqRFM considers each customer's R, F, and M scores to represent the significance of the customer and identifies sequences with high recency, high frequency, and high monetary value. A series of experiments demonstrates the superiority and effectiveness of the SeqRFM algorithm compared to the most advanced RFM algorithms based on sequential pattern mining. Moreover, another algorithm named MSeqRFM is developed to compress the result of SeqRFM. The experiments demonstrate the effectiveness of MSeqRFM in compressing sequences. The source code and datasets are available at GitHub https://github.com/DSI-Lab1/SeqRFM .},
  archive      = {J_ISCI},
  author       = {Yanxin Zheng and Wensheng Gan and Zefeng Chen and Pinlyu Zhou and Philippe Fournier-Viger},
  doi          = {10.1016/j.ins.2025.122652},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122652},
  shortjournal = {Inf. Sci.},
  title        = {SeqRFM: Fast RFM analysis in sequence data},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic event-triggered finite-time actor-critic-identifier-based approximate optimal control for unknown nonlinear drifted systems. <em>ISCI</em>, <em>723</em>, 122651. (<a href='https://doi.org/10.1016/j.ins.2025.122651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a finite-time dynamic event-triggered actor-critic-identifier (FT-DET-ACI) framework for the optimal control problem of nonlinear systems with uncertain drift dynamics. A theoretical foundation is established by reformulating the value function within a finite-time stable space, which facilitates system state stabilization within predetermined temporal constraints. The proposed approach derives finite-time optimal controllers through a transformed Hamilton-Jacobi-Bellman (HJB) equation. To address unknown system dynamics, an integrated actor-critic-identifier architecture is constructed to concurrently approximate the value function, synthesize the finite-time optimal controller, and identify system parameters. A dynamic event-triggering rule is designed to reduce computational and communication loads by selectively updating the control signal. Lyapunov stability analysis is provided to demonstrate the finite-time convergence properties of the closed-loop system. Numerical experiments are conducted to validate the efficacy of the proposed FT-DET-ACI methodology.},
  archive      = {J_ISCI},
  author       = {Shuangsi Xue and Junkai Tan and Zihang Guo and Qingshu Guan and Hui Cao and Badong Chen},
  doi          = {10.1016/j.ins.2025.122651},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122651},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic event-triggered finite-time actor-critic-identifier-based approximate optimal control for unknown nonlinear drifted systems},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Set membership filter with nonlinear state inequality constraints. <em>ISCI</em>, <em>723</em>, 122650. (<a href='https://doi.org/10.1016/j.ins.2025.122650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Set membership filter is a promising method to provide a bounding estimation containing the true state for dynamic systems with unknown but bounded noises. In this paper, we investigate the state bounding estimation problem of nonlinear dynamic systems with nonlinear state inequality constraints. Three types of ellipsoidal state bounding estimation methods are proposed by incorporating nonlinear state inequality constraints into nonlinear set membership filter. They are called model reduction method, system measurement method, and constraint dimension reduction method, respectively. We analyze the computation complexity of the three methods, which decrease in the order of model reduction method, system measurement method, and constraint dimension reduction method. Due to the nonlinearity of the dynamic systems, all the three methods are approximation algorithms and the state estimation accuracy cannot be analyzed explicitly. Consequently, a typical illustrative numerical experiment is conducted to compare the performance of the three methods. The results show that the accuracy increases in the order of the model reduction method, the constraint dimension reduction method, and the system measurement method.},
  archive      = {J_ISCI},
  author       = {Xiaowei Li and Xuqi Zhang and Zhiguo Wang and Xiaojing Shen},
  doi          = {10.1016/j.ins.2025.122650},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122650},
  shortjournal = {Inf. Sci.},
  title        = {Set membership filter with nonlinear state inequality constraints},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Bi-objective optimization for electric vehicle scheduling under vehicle-to-grid integration. <em>ISCI</em>, <em>723</em>, 122649. (<a href='https://doi.org/10.1016/j.ins.2025.122649'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle-to-grid (V2G) technology leverages the distributed energy-storage potential of electric vehicles (EVs), transforming the challenges of large-scale EV integration into opportunities to enhance grid flexibility and reliability. This study investigates the optimization of EV charging-discharging schedules by exploiting V2G capabilities. First, considering the spatiotemporal distribution of EVs, a Markov chain is constructed to describe probabilistic transitions between spatiotemporal states, which is then embedded in a traffic-network-based path decision model. Second, a dynamic battery energy consumption model is established, incorporating multiple factors that influence battery performance. Using Monte Carlo simulation results, a bi-objective optimization model is formulated to schedule charging and discharging, simultaneously minimizing (i) total cost — including user recharging time and battery degradation — and (ii) grid-load fluctuation. Given the NP-hard nature of the problem, an improved multi-objective bitterling fish optimization (IMOBFO) algorithm is developed to balance global exploration and local exploitation. Empirical studies in a region of Shanghai compare three strategies: disordered charging, ordered charging, and the proposed optimized charging–discharging strategy. Experimental results confirm the feasibility of the proposed model and the effectiveness of IMOBFO. Comparative analysis with seven other algorithms further validates the superior performance and stability of IMOBFO according to multiple multi-objective evaluation metrics.},
  archive      = {J_ISCI},
  author       = {Bing Yu and Yong Liu and Liang Ma},
  doi          = {10.1016/j.ins.2025.122649},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122649},
  shortjournal = {Inf. Sci.},
  title        = {Bi-objective optimization for electric vehicle scheduling under vehicle-to-grid integration},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unified graph-based framework for visual explainability in convolutional neural networks. <em>ISCI</em>, <em>723</em>, 122648. (<a href='https://doi.org/10.1016/j.ins.2025.122648'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In deep learning, understanding the decision-making processes of complex models is essential for advancing interpretability and trust in artificial intelligence systems. We introduce Causal Relational Attribution Graph (C-RAG), designed to deliver comprehensive, multi-perspective explanations of convolutional neural networks (CNNs) via a graph representation. C-RAG integrates gradient-based local attribution with global feature importance by constructing a graph-based representation that captures hierarchical feature inter-dependencies. In this framework, feature clusters are represented as graph nodes, and their interactions are quantified through combined localized and global attribution metrics, ensuring interpretable insights into model behavior. We evaluate C-RAG across diverse benchmark datasets (ImageNet, CIFAR-10, MNIST) and CNN architectures (ResNet18, VGG19, DenseNet201, LeNet), demonstrating significant advancements over state-of-the-art explainability methods in faithfulness, robustness, and computational efficiency. The proposed approach facilitates accurate spatial feature localization, robust dependency mapping, and efficient explanation generation, making it a valuable tool for critical applications such as medical imaging and autonomous systems. We provide a novel graph-based explainability framework, which bridges the gap between local and global interpretability, C-RAG addresses key limitations in existing methods, establishing a robust foundation for explainable AI in computer vision.},
  archive      = {J_ISCI},
  author       = {Basim Azam and Pubudu Sanjeewani and Brijesh Verma and Ashfaqur Rahman and Lipo Wang},
  doi          = {10.1016/j.ins.2025.122648},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122648},
  shortjournal = {Inf. Sci.},
  title        = {Unified graph-based framework for visual explainability in convolutional neural networks},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attention-based spatial-temporal interactive couple neural networks for multivariate time series forecasting. <em>ISCI</em>, <em>723</em>, 122647. (<a href='https://doi.org/10.1016/j.ins.2025.122647'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series forecasting (MTSF) has been a significant research focus across various domains. Recent studies have utilized deep neural networks to identify pattern relationships in MTSF. Despite these developments, accurately forecasting multivariate time series remains challenging due to the trend of time series and spatial-temporal heterogeneity. In this paper, we propose a unified multivariate time series forecasting framework for long-term, short-term, and spatial-temporal forecasting with attention-based spatial-temporal interactive coupled neural networks (ASTIC). Specifically, we proposed a spatial-temporal interactive couple block that contains both temporal and spatial branches to investigate the relationships between global and local patterns in temporal and spatial perspectives. In the temporal branch, we design a hybrid network module capable of enhancing representation learning using convolution and attention mechanisms, which dynamically capture the local trendiness and long-term time dependence implicit in time series. In the spatial branch, a novel dynamic graph learners are designed to learn global and local spatial patterns. Then a novel interactive coupling method is proposed to link the two branches together. ASTIC predicts time series effectively by using a multilevel structure to model the trendiness of the series and mining the spatial-temporal heterogeneity. Experimental results show that our method outperforms state-of-the-art baseline methods on nine real-world datasets.},
  archive      = {J_ISCI},
  author       = {Bingsheng Wei and Yonghua Hei and Yuan Wan},
  doi          = {10.1016/j.ins.2025.122647},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122647},
  shortjournal = {Inf. Sci.},
  title        = {Attention-based spatial-temporal interactive couple neural networks for multivariate time series forecasting},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). New solutions based on the generalized eigenvalue problem for the data collaboration analysis. <em>ISCI</em>, <em>723</em>, 122642. (<a href='https://doi.org/10.1016/j.ins.2025.122642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the data collaboration (DC) analysis, a privacy-preserving method for analyzing decentralized datasets held by multiple parties. In this method, privacy-preserving intermediate representations of original datasets are collected from multiple parties and then converted into collaboration representations for collaborative data analysis. However, conventional methods for creating collaboration representations suffer from several challenges; namely, the optimization problem being considered is not well defined, and the process of solving it is very difficult to understand. We thus propose a new solution for creating high-quality collaboration representations for the DC analysis. Specifically, we formulate a revised optimization problem for creating collaboration representations and then transform this optimization problem into a generalized eigenvalue problem. We also propose a reduction of the generalized eigenvalue problem to a singular value decomposition through the QR decomposition. Computational experiments using publicly available datasets demonstrate that our method can outperform the conventional methods for the DC analysis in terms of both prediction accuracy and computational efficiency.},
  archive      = {J_ISCI},
  author       = {Yuta Kawakami and Yuichi Takano and Akira Imakura},
  doi          = {10.1016/j.ins.2025.122642},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122642},
  shortjournal = {Inf. Sci.},
  title        = {New solutions based on the generalized eigenvalue problem for the data collaboration analysis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interpretable, multidimensional evaluation framework for causal discovery from observational i.i.d. data. <em>ISCI</em>, <em>723</em>, 122641. (<a href='https://doi.org/10.1016/j.ins.2025.122641'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear causal discovery from observational data imposes strict identifiability assumptions on the formulation of structural equations utilized in the data-generating process. However, in real-life settings, the ground-truth mechanism responsible for cause-effect transformations is unknown. Thus, it is impossible to verify its identifiability. This is the first research to assess the performance of structure learning algorithms from seven different families in non-identifiable settings with an increasing degree of nonlinearity. The evaluation of structure learning methods under assumption violations requires a rigorous and interpretable approach that quantifies both the structural similarity of the estimation with the ground truth and the capacity of the discovered graphs to be used for causal inference. Motivated by the lack of a unified performance assessment indicator, we propose an interpretable, multidimensional evaluation framework, specifically tailored to the field of causal discovery from i.i.d. data. In particular, we introduce a six-dimensional evaluation metric, called distance to the optimal solution, which aims at providing a holistic overview of the performance of structure learning techniques. Our large-scale simulation study, which incorporates seven experimental factors, shows that hybrid Bayesian networks outperform most recently introduced continuous optimization techniques under certain conditions. Additionally, causal order-based methods yield results with comparatively high proximity to the optimal solution.},
  archive      = {J_ISCI},
  author       = {Georg Velev and Stefan Lessmann},
  doi          = {10.1016/j.ins.2025.122641},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122641},
  shortjournal = {Inf. Sci.},
  title        = {Interpretable, multidimensional evaluation framework for causal discovery from observational i.i.d. data},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

</body>
</html>
