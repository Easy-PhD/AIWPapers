<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ISCI</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="isci">ISCI - 37</h2>
<ul>
<li><details>
<summary>
(2026). Robust partial 3D point cloud registration via confidence estimation under global context. <em>ISCI</em>, <em>723</em>, 122705. (<a href='https://doi.org/10.1016/j.ins.2025.122705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial point cloud registration is essential for autonomous perception and 3D scene understanding, yet it remains challenging owing to structural ambiguity, partial visibility, and noise. We address these issues by proposing Confidence Estimation under Global Context (CEGC), a unified, confidence-driven framework for robust partial 3D registration. CEGC enables accurate alignment in complex scenes by jointly modeling overlap confidence and correspondence reliability within a shared global context. Specifically, the hybrid overlap confidence estimation module integrates semantic descriptors and geometric similarity to detect overlapping regions and suppress outliers early. The context-aware matching strategy mitigates ambiguity by employing global attention to assign soft confidence scores to correspondences, improving robustness. These scores guide a differentiable weighted singular value decomposition solver to compute precise transformations. This tightly coupled pipeline adaptively down-weights uncertain regions and emphasizes contextually reliable matches. Experiments on ModelNet40, ScanObjectNN, and 7Scenes 3D vision datasets demonstrate that CEGC outperforms state-of-the-art methods in accuracy, robustness, and generalization. Overall, CEGC offers an interpretable and scalable solution to partial point cloud registration under challenging conditions.},
  archive      = {J_ISCI},
  author       = {Yongqiang Wang and Weigang Li and Wenping Liu and Zhe Xu and Zhiqiang Tian},
  doi          = {10.1016/j.ins.2025.122705},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122705},
  shortjournal = {Inf. Sci.},
  title        = {Robust partial 3D point cloud registration via confidence estimation under global context},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Long- and short-term preferences modeling based on dual-frequency self-attention network for sequential recommendation. <em>ISCI</em>, <em>723</em>, 122700. (<a href='https://doi.org/10.1016/j.ins.2025.122700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation aims to analyze users’ interaction sequences to capture their sustained long-term preferences and dynamically changing short-term preferences for the next item recommendation. Recent studies have shifted their focus to the frequency domain to further mine users’ complex historical interaction behaviors. However, most existing frequency-based methods cannot explicitly distinguish the low-frequency information associated with long-term preferences from the high-frequency information associated with short-term preferences in user sequences. Consequently, they are unable to accurately model these preferences, thereby limiting the performance of the models. To this end, we propose a novel yet simple model based on Dual-Frequency Self-Attention Network (DFSNet) for sequential recommendation. DFSNet comprises low- and high-frequency self-attention modules that separately extract the corresponding components from user sequences to model long- and short-term preferences. Additionally, considering the limited frequency information available within sequences, we introduce contrastive learning to generate self-supervised signals from the preference representations produced by DFSNet. This approach further strengthens the modeling of both long-term and short-term preferences without disrupting the sequence structure, thereby positively impacting the recommendation performance. Extensive experiments on four public datasets indicate that DFSNet outperforms strong baselines while balancing accuracy and efficiency, confirming its effectiveness.},
  archive      = {J_ISCI},
  author       = {Kaiwei Xu and Yongquan Fan and Jing Tang and Xianyong Li and Yajun Du and Xiaomin Wang},
  doi          = {10.1016/j.ins.2025.122700},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122700},
  shortjournal = {Inf. Sci.},
  title        = {Long- and short-term preferences modeling based on dual-frequency self-attention network for sequential recommendation},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FedWAPR: Bridging theory and practice in probability-driven weighted aggregation for federated learning. <em>ISCI</em>, <em>723</em>, 122697. (<a href='https://doi.org/10.1016/j.ins.2025.122697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a machine learning paradigm emphasizing data privacy, widely adopted for handling sensitive data. Federated Averaging (FedAvg) is the most commonly implemented FL aggregation technique due to its simplicity and effectiveness. However, FedAvg suffers from information loss during the aggregation stage. This study theoretically and empirically analyzes the Weighted Aggregation via Probability-based Ranking (FedWAPR) technique, an enhancement to FedAvg that retains its simplicity while addressing its limitations. FedWAPR employs a weighted aggregation strategy based on Log-Cauchy and Exponential probability density functions, assigning weights to local models based on their performance. This approach ensures accurate aggregation that reflects the contributions of individual clients. FedWAPR was tested across various model architectures, including Dense Neural Networks, Long Short-Term Memory networks, and Convolutional Neural Networks with results showing performance equal to or surpassing FedAvg. The Log-Cauchy and Exponential distribution functions allow customization of aggregation based on the number of participating clients, with exponential distribution excelling in smaller client setups and Log-Cauchy in larger ones. FedWAPR’s ability to integrate with advanced aggregation techniques like FedProx, makes it a robust solution to enhance FL. Additionally, a theoretical analysis confirms the convergence of FedWAPR under standard FL assumptions and thereby ensuring method’s robustness and reliability.},
  archive      = {J_ISCI},
  author       = {Abdullah Abdul Sattar Shaikh and M.S. Bhargavi and Pavan Kumar C},
  doi          = {10.1016/j.ins.2025.122697},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122697},
  shortjournal = {Inf. Sci.},
  title        = {FedWAPR: Bridging theory and practice in probability-driven weighted aggregation for federated learning},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DPRO-GNN: Bridging differential privacy and advanced optimization for privacy-preserving graph learning. <em>ISCI</em>, <em>723</em>, 122695. (<a href='https://doi.org/10.1016/j.ins.2025.122695'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have demonstrated exceptional performance in modeling structured data, yet their application in sensitive domains inevitably raises privacy concerns. Existing Differentially Private GNN (DPGNN) frameworks primarily rely on Differentially Private Stochastic Gradient Descent (DP-SGD) to enforce privacy guarantees. However, DP-SGD inherits its inherent limitations, such as training instability and slow convergence, which are particularly problematic for complex graph learning tasks. Although advanced optimizers like Ranger offer a promising alternative, their naive integration into DPGNN frameworks introduces bias, specifically in the second-moment estimation, due to the additive noise required for DP. To address this challenge, we propose the Differentially Private Ranger-Optimized Graph Neural Network (DPRO-GNN) to protect users’ sensitive data when training the GNN tasks. To mitigate DP noise and capture multi-scale structure, DPRO-GNN applies hierarchical pooling to aggregate nodes into progressively coarser subgraphs, yielding robust, multi-resolution embeddings. Meanwhile, our approach introduces DP-RangerBC, a bias-corrected variant of the Ranger optimizer that mitigates the noise-induced bias in second-order moment estimation, thereby enabling more stable and efficient training under DP constraints. Furthermore, the theoretical analysis of DPRO-GNN, including its correctness and security, is also provided. Extensive experiments on real-world datasets demonstrate that DPRO-GNN achieves superior performance in terms of classification accuracy and convergence speed, compared to state-of-the-art DPGNN methods. The code of DPRO-GNN is available at the following link: https://github.com/Silbermondlel/DPRO-GNN .},
  archive      = {J_ISCI},
  author       = {Yanan Bai and Liji Xiao and Hongbo Zhao and Xiaoyu Shi},
  doi          = {10.1016/j.ins.2025.122695},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122695},
  shortjournal = {Inf. Sci.},
  title        = {DPRO-GNN: Bridging differential privacy and advanced optimization for privacy-preserving graph learning},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PUWR-TSSG: A CMAB-based post-unknown worker recruitment scheme for three-stage stackelberg games in mobile crowd sensing. <em>ISCI</em>, <em>723</em>, 122693. (<a href='https://doi.org/10.1016/j.ins.2025.122693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous Three-Stage Stackelberg Games (TSSG) have been proposed to model the strategic interactions among the requesters, the platform, and the workers in Mobile Crowd Sensing (MCS). However, most existing studies unrealistically assume that the platform possesses prior knowledge of the workers’ credibility either beforehand or after receiving their data. Conversely, in practical scenarios, the credibility of workers remains uncertain even after the submission of their data, which is known as the Post-Unknown Worker Recruitment (PUWR) problem. Given this context, conventional models designed for TSSG cannot be applied to real-world MCS. In this paper, we present the PUWR-TSSG scheme for quality-enhanced worker recruitment in TSSG. Specifically, we avoid the unreasonable assumption in previous works and propose a Double-level Credibility Discovery (DCD) approach with bipartite graph-based matrix completion for accurate credibility verification. Subsequently, based on the DCD approach, we further propose a meticulously designed combinatorial multi-armed bandit mechanism to solve the exploration–exploitation dilemma in untrusted environments. Furthermore, we formulate the payment computation issue as a TSSG, while simultaneously considering the workers’ credibility and verification costs incurred by the PUWR problem. Theoretical analyses validate the existence of Stackelberg Equilibrium in our scheme, ensuring that no participant has an incentive to unilaterally deviate from its optimal strategy. Extensive simulations on a real-world dataset validate the effectiveness of our proposed PUWR-TSSG scheme, significantly enhancing the overall data quality and leading to a remarkable average reduction in regret of up to 85.9% compared to baseline methods.},
  archive      = {J_ISCI},
  author       = {Kejia Fan and Jianheng Tang and Yaohui Han and Yuhao Zheng and Yajiang Huang and Anfeng Liu and Neal N. Xiong and Shaobo Zhang and Tian Wang and Mianxiong Dong},
  doi          = {10.1016/j.ins.2025.122693},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122693},
  shortjournal = {Inf. Sci.},
  title        = {PUWR-TSSG: A CMAB-based post-unknown worker recruitment scheme for three-stage stackelberg games in mobile crowd sensing},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel approach for shortest optimal reduct computation. <em>ISCI</em>, <em>723</em>, 122692. (<a href='https://doi.org/10.1016/j.ins.2025.122692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough set theory has emerged as a robust soft computing paradigm for feature selection, commonly known as reduct computation. A decision system may contain multiple reducts of varying sizes, all offering equivalent classification capabilities. However, when model performance is a critical factor, the shortest reduct is generally preferred due to its simplicity and interpretability. The discernibility matrix method is a widely used technique for computing such reducts. Despite its effectiveness, this method is computationally intensive and classified as NP-hard, limiting its scalability for datasets where discernibility matrix computation becomes infeasible. This study addresses the limitations of traditional discernibility matrix-based approaches by introducing a novel method that combines a Breadth-First Search control strategy with an incremental approach to compute the absorbed discernibility matrix. The Breadth First Search strategy enables efficient exploration of the search space to identify the shortest optimal reduct early, while the incremental absorbed discernibility matrix enhances the computational scalability of the algorithm. To validate the proposed method, an experimental evaluation was conducted against two state-of-the-art algorithms: Breadth-First Search, representing the discernibility matrix-based strategy, and MinReduct, a benchmark for absorbed discernibility matrix-based approaches. Results demonstrate superior computational performance and earlier discovery of shortest reducts without compromising correctness or optimality.},
  archive      = {J_ISCI},
  author       = {G.Y. Phani Kumar and Abhimanyu Bar and P.S.V.S. Sai Prasad},
  doi          = {10.1016/j.ins.2025.122692},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122692},
  shortjournal = {Inf. Sci.},
  title        = {A novel approach for shortest optimal reduct computation},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Existence of nash equilibrium in single-leader multiple-follower games with min-max interval payoffs. <em>ISCI</em>, <em>723</em>, 122691. (<a href='https://doi.org/10.1016/j.ins.2025.122691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In decision-making problems with hierarchical structures, leader–follower games are highly prevalent. As a core concept in game theory, the existence of Nash equilibrium is crucial. However, in reality, complex uncertainties often lead to imprecise game outcomes, and interval representations are an effective tool for capturing such uncertainties. To address the issue of imprecise payoffs in complex environments, this paper proposes the concept of min-max interval (for short, MMI) and studies the existence of Nash equilibrium in single-leader multiple-follower (for short, SLMF) games with MMI payoffs. MMI is an appropriate extension of the traditional interval-providing a more flexible tool for representing uncertain payoffs. We propose an MMI expected payoff ranking method to address the issue of players ranking MMIs. Based on this, operational rules for MMIs and concepts such as limits, continuity, and concavity of MMI-valued functions (for short, MIVFs) are defined. After extending key theorems of real-valued functions to the case of MIVFs, we combine these extended theorems with set-valued mapping theory and Kakutani’s fixed point theorem to prove the existence of Nash equilibrium in SLMF MMI-valued games. Additionally, we compare existing works to verify the innovativeness of the proposed method and provide numerical examples to demonstrate its applicability.},
  archive      = {J_ISCI},
  author       = {Daping Zhang and Yanlong Yang and Xicai Deng},
  doi          = {10.1016/j.ins.2025.122691},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122691},
  shortjournal = {Inf. Sci.},
  title        = {Existence of nash equilibrium in single-leader multiple-follower games with min-max interval payoffs},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Data stream clustering via fuzzy similarity and diffusion-enhanced contextual affinity. <em>ISCI</em>, <em>723</em>, 122690. (<a href='https://doi.org/10.1016/j.ins.2025.122690'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data stream clustering provides an effective method for recognizing underlying patterns in potentially unbounded sequences of data objects. Existing data stream clustering methods primarily encounter two key issues: (1) the inadequate evaluation of relationships between data objects within fixed-size landmark windows, leading to degraded clustering quality; and (2) the absence of efficient mechanisms for transferring useful knowledge from previous windows to the current window, weakening the model’s adaptability to data stream evolution. To address these issues, a data stream clustering method based on axiomatic fuzzy set theory via a diffusion process is first proposed. First, the proposed method employs axiomatic fuzzy set theory to measure the relationships between data objects within the window, capturing similarity information to more accurately reveal the underlying data distribution. Second, an efficient diffusion process enhances pairwise affinities through contextual propagation, which significantly improves connectivity within clusters. Finally, the learned affinity matrix is applied to spectral clustering for data stream clustering. Over time, we update the dynamic set according to the distance between data objects and cluster centers. This dynamic set retains representative data objects and effectively transfers previously learned knowledge to the current landmark window. Experimental results on four datasets and seven algorithms demonstrate the effectiveness and robustness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Yao Li and Ming Chi and Wei Lu and Xiaodong Liu and Witold Pedrycz},
  doi          = {10.1016/j.ins.2025.122690},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122690},
  shortjournal = {Inf. Sci.},
  title        = {Data stream clustering via fuzzy similarity and diffusion-enhanced contextual affinity},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Large language model assisted hierarchical reinforcement learning training. <em>ISCI</em>, <em>723</em>, 122688. (<a href='https://doi.org/10.1016/j.ins.2025.122688'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional reinforcement learning (RL) cannot solve complex long-sequence decision tasks, especially when the environment rewards are sparse. Large language models (LLMs) can perform well in long-sequence decision tasks by leveraging their powerful inference capabilities. Although LLMs possess a large amount of general knowledge, LLM-based agents lack expertise in solving specific target problems. Considering that reinforcement learning models are smaller than LLMs and can be trained specifically to perform well on specific tasks, this paper proposes a hierarchical reinforcement learning framework assisted by a large language model, called LLMHRL. In this framework, the LLM acts as a teacher agent to guide the exploration of high-level policy in hierarchical reinforcement learning. The low-level policy consists of a library of selection-based policies. The agent executes specific actions based on the low-level policy chosen by the high-level policy. Furthermore, to reduce the action space of high-level policy, this paper decomposes it into skill options and target options. The two types of options are combined to obtain a high-level policy. This paper evaluates LLMHRL against baseline methods using both public and custom-built harder tasks across three environments: MiniGrid for key-door pairing, ManiSkill for tabletop sorting, and real-world scenarios. The results show that LLMHRL outperforms existing methods in success rate, convergence speed, and average return.},
  archive      = {J_ISCI},
  author       = {Qianxi Li and Bao Pang and Yong Song and Hongze Fu and Qingyang Xu and Xianfeng Yuan and Xiaolong Xu and Chengjin Zhang},
  doi          = {10.1016/j.ins.2025.122688},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122688},
  shortjournal = {Inf. Sci.},
  title        = {Large language model assisted hierarchical reinforcement learning training},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A relation classification and aggregation algorithm for bipartite-type multi-relational heterogeneous graphs. <em>ISCI</em>, <em>723</em>, 122687. (<a href='https://doi.org/10.1016/j.ins.2025.122687'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing Heterogeneous Graph Neural Networks (HGNNs) are multi-oriented and single-relational heterogeneous graphs, and cannot effectively function on Bipartite-type Multi-relational Heterogeneous Graphs (BMHGs) with multiple relationships. At the same time, existing meta-path-based HGNNs cannot fully consider the differences between meta-paths during the aggregation process, and this difference is even more prominent in BMHGs. The main manifestation is that the number of neighbor nodes connected by various meta-relation paths differs significantly, causing some paths to carry too much noise information, which affects the algorithm performance. In order to solve the problem of the complex relationships in BMHG and the significant disparity in the number of neighbors between paths, this paper proposes a Relation Classification and Aggregation Algorithm for Bipartite-type Multi-Relational Heterogeneous Graphs (RCAA-BMHG). The RCAA-BMHG algorithm consists of three modules: the same-type aggregation module, the across-type aggregation module, and the cross-category feature aggregation layer, which perform differentiated processing of different types of association information between nodes in a Bipartite-type Multi-relational Heterogeneous Graph. Specifically, the same-type aggregation module first introduces a same-type node association filter to distinguish between the densely coupled path and the sparsely coupled path, and then uses a global average strategy and an adaptive weight allocation method to aggregate the information of the two types of coupled paths. The across-type aggregation module is filtered by an across-type node association filter, and then the weighted sum mechanism and the neighborhood feature propagation technology are used to aggregate the information of the two types of coupled paths. Finally, RCAA-BMHG uses a category-level attention mechanism to fuse the semantic and feature information of the same and cross types to generate the final node embedding for downstream tasks. Experimental verification shows that RCAA-BMHG not only performs feature aggregation and classification tasks when processing complex heterogeneous graph data, but also shows significant advantages over existing HGNNs algorithms on multiple evaluation metrics. The complete reproducible code and data have been published at: https://github.com/Dylanwsd24/RCAA-BMHG .},
  archive      = {J_ISCI},
  author       = {Hua Duan and Shiduo Wang and Yufei Zhao and Hua Liu and Xiaotong Li},
  doi          = {10.1016/j.ins.2025.122687},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122687},
  shortjournal = {Inf. Sci.},
  title        = {A relation classification and aggregation algorithm for bipartite-type multi-relational heterogeneous graphs},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust watermarking for diffusion model generated images. <em>ISCI</em>, <em>723</em>, 122686. (<a href='https://doi.org/10.1016/j.ins.2025.122686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the wide application of diffusion models in the field of image generation, image copyright protection and traceability have become increasingly complex and challenging. To address these problems, this paper proposes a robust watermarking method for diffusion model generated images to achieve their copyright protection and traceability. The method designs an invertible mapping module to replicate and cryptographically map the watermark information into an approximately Gaussian distributed noise, which is highly consistent with the distribution of the original generation model. The mapped watermark noise serves as the latent space vector of the generative model, preserving both image generation quality and model performance. In the watermark extraction stage, the original watermark information can be accurately recovered from the generated image through the reverse extraction and voting mechanism. Experimental results show that the proposed method demonstrates excellent performance in terms of image watermark extraction accuracy, robustness and watermark image generation quality. It can still maintain 99 % true positive rate and 97.5 % bit accuracy under various attacks, and the overall performance in the detection and traceability scenarios is significantly better than the existing baseline methods.},
  archive      = {J_ISCI},
  author       = {Ziqi Liu and Yuan Guo and Liansuo Wei},
  doi          = {10.1016/j.ins.2025.122686},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122686},
  shortjournal = {Inf. Sci.},
  title        = {Robust watermarking for diffusion model generated images},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SEAD-MGFE-net: Schrödinger equation-based adaptive dropout multi-granular feature enhancement network for conversational aspect-based sentiment quadruple analysis. <em>ISCI</em>, <em>723</em>, 122684. (<a href='https://doi.org/10.1016/j.ins.2025.122684'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research focuses on enhancing the extraction of sentiment quadruples consisting of target, aspect, opinion, and sentiment from multi-turn dialogs, which remains a challenging problem in conversational sentiment analysis. Existing methods frequently encounter challenges with complex sentence structures, presence of multiple sentiment quadruples, and interference from irrelevant contextual information. These challenges often result in suboptimal performance. These limitations are addressed by introducing Schrödinger equation-based adaptive dropout multi-granular feature enhancement network (SEAD-MGFE-Net), a novel framework that synergizes multigranular feature extraction with quantum-inspired adaptive regularization. The proposed methodology incorporates a multi-layer tree structure to segment sentences into semantically coherent fragments, thereby improving the alignment between aspect and opinion terms while simultaneously mitigating noise impact. Moreover, we engineer a multi-angle dynamic adjacency learning enhancement module that adeptly captures both local and global features inherent in graph-structured representations. Additionally, we devise an adaptive dropout mechanism based on the Schrödinger equation, facilitating automatic modulation of the regularization strength throughout training. Extensive evaluations on benchmark datasets in both Chinese and English validate the state-of-the-art effectiveness of our proposed SEAD-MGFE-Net model, achieving Micro-F1 scores of 46.53 % (Chinese) and 40.97 % (English), surpassing the strongest baseline models by 2.04 % and 1.57 %, respectively. SEAD-MGFE-Net exhibits efficacy in extracting cross-utterance quadruples and managing long-range dependencies. These findings confirm the effectiveness and broad applicability of SEAD-MGFE-Net for conversational sentiment analysis.},
  archive      = {J_ISCI},
  author       = {Wei Liu and Xiaoliang Chen and Duoqian Miao and Hongyun Zhang and Xiaolin Qin and Shangyi Du and Peng Lu},
  doi          = {10.1016/j.ins.2025.122684},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122684},
  shortjournal = {Inf. Sci.},
  title        = {SEAD-MGFE-net: Schrödinger equation-based adaptive dropout multi-granular feature enhancement network for conversational aspect-based sentiment quadruple analysis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Byzantine-resilient federated learning with dynamic scoring matrix and variant PBFT consensus under differential privacy. <em>ISCI</em>, <em>723</em>, 122682. (<a href='https://doi.org/10.1016/j.ins.2025.122682'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing concerns regarding data privacy exacerbate the challenges associated with “data silos”. Federated learning (FL) effectively addresses these issues by facilitating distributed machine learning without necessitating direct data exchange. However, the dependence on a central server in conventional FL architectures exacerbates privacy risks and limits cross-domain data sharing. Existing blockchain-based FL frameworks often employ static consensus protocols, such as classical Practical Byzantine Fault Tolerance (PBFT), which typically rely on fixed weight aggregation strategies. While these methods simplify implementation, they fail to adaptively adjust aggregation weights according to heterogeneous privacy budgets. Attempts to implement adaptive weight aggregation often require achieving consensus for each individual weight, significantly reducing efficiency and creating scalability challenges in large-scale networks. To address these gaps, we propose DSM-PBFT, a variant PBFT consensus enhanced with dynamic scoring matrices (DSM), which enables parallelized validation of multiple models while adaptively adjusting aggregation weights based on differential privacy budgets. Our noise-aware aggregation mechanism dynamically reweights models through cross-validation of accuracy, F1 score, and loss-transformed metrics, effectively decoupling privacy guarantees from model utility degradation. Security analyses affirm the robustness of this framework against Byzantine attacks, with experimental results on MNIST, FashionMNIST and CIFAR-10 demonstrating superior model accuracy across diverse privacy budgets while effectively curbing accuracy degradation under attack scenarios.},
  archive      = {J_ISCI},
  author       = {Wentai Yang and Xian Xu and Kai Yu and Guoqiang Li},
  doi          = {10.1016/j.ins.2025.122682},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122682},
  shortjournal = {Inf. Sci.},
  title        = {Byzantine-resilient federated learning with dynamic scoring matrix and variant PBFT consensus under differential privacy},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Subsequence heterogeneity contrastive learning for time series anomaly detection. <em>ISCI</em>, <em>723</em>, 122680. (<a href='https://doi.org/10.1016/j.ins.2025.122680'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series anomaly detection is widely applied across various real-world scenarios. Recently, contrastive learning has shown remarkable ability in learning discriminative representations for detecting anomalies. However, most existing contrastive-based methods rely on complex contrastive mechanisms and specially designed model architectures, which make it difficult to maintain efficiency and flexibility across various application scenarios. To address this limitation, we introduce Subsequence-Heterogeneity that defined as the discrepancies in variation patterns and statistical characteristics between subsequences obtained through fixed-interval sampling, which are more pronounced in anomalous sequences than in normal ones. It can serve as a natural discrimination criterion and eliminate the need for complex contrastive mechanisms and specialized model architectures. Specifically, we adopt an efficient temporal hierarchical masking strategy with linear complexity to construct two branches for learning representations at different granularities. The Subsequence-Heterogeneity Contrastive Learning (SHCL) is implemented with different neural networks and enables flexible application to anomaly detection across diverse scenarios. Experiments on eight benchmark datasets demonstrate that SHCL not only achieves state-of-the-art performance with reduced time and resource costs but also significantly improves the ability of different neural networks to distinguish normal from anomalous patterns. The source code is publicly available at https://github.com/Zhangzzbzzb/SHCL/ .},
  archive      = {J_ISCI},
  author       = {Zhibin Zhang and Xiaohong Zhang and Qiang Li and Chun Huang and Tao Yin and Meng Yan},
  doi          = {10.1016/j.ins.2025.122680},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122680},
  shortjournal = {Inf. Sci.},
  title        = {Subsequence heterogeneity contrastive learning for time series anomaly detection},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Escrow-free attribute based signature with constant-size for the internet of things. <em>ISCI</em>, <em>723</em>, 122679. (<a href='https://doi.org/10.1016/j.ins.2025.122679'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute based signature (ABS) provides a promising solution for anonymous authentication. However, numerous prevailing ABS algorithms are ill-suited for anonymous authentication in the Internet of Things (IoT), due to problems such as key escrow, high computational overhead, inflexible access policies, and vulnerability to collusion attacks. Considering these shortcomings, we present an escrow-free attribute based signature with constant-size signature for IoT. Our proposal uses the linear secret-sharing scheme (LSSS) and the notion of certificateless cryptography to restrict the authorities of each attribute authority and the system authority. In addition, it generates a constant-size signature and achieves high verification efficiency by aggregating attribute keys. Theoretical analyses demonstrate that our proposal achieves anonymous authentication and is provably secure under the standard model. Simulation experiments show that the execution time of our algorithm is less than 50 ms to run during both the signature and verification phases, making it well-suited for applications with limited resources.},
  archive      = {J_ISCI},
  author       = {Xudong Liu and Xiaojun Tong and Yihui Wang},
  doi          = {10.1016/j.ins.2025.122679},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122679},
  shortjournal = {Inf. Sci.},
  title        = {Escrow-free attribute based signature with constant-size for the internet of things},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep dual contrastive learning for multi-view subspace clustering. <em>ISCI</em>, <em>723</em>, 122678. (<a href='https://doi.org/10.1016/j.ins.2025.122678'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering (MVSC) aims to learn a consistent shared self-representation by utilizing the consistency and complementarity of all views, numerous MVSC algorithms have attempted to obtain the optimal representation directly from raw features. However, they might overlook the noisy or redundant information in raw feature space, resulting in learning suboptimal self-representation and poor performance. To address this limitation, an intuitive idea is introducing deep neural networks to eliminate the noise and redundancy, yielding a potential embedding space. Nevertheless, existing deep MVSC methods merely focus on either the embeddings or self-expressions to explore the complementary information, which hinders subspace learning. In this paper, we present a deep multi-view dual contrastive subspace clustering framework to exploit the complementarity to learn latent self-representations effectively. Specifically, multi-view encoders are constructed to eliminate noise and redundancy of the original features and capture low-dimensional subspace embeddings, from which the self-representations are learned. Moreover, two diverse specific fusion methods are conducted on the latent subspace embeddings and the self-expressions to learn shared self-representations, and dual contrastive constraints are proposed to fully exploit the complementarity among views. Extensive experiments are conducted to verify the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Xincan Lin and Jie Lian and Zhihao Wu and Jielong Lu and Shiping Wang},
  doi          = {10.1016/j.ins.2025.122678},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122678},
  shortjournal = {Inf. Sci.},
  title        = {Deep dual contrastive learning for multi-view subspace clustering},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Parameter-free discrete clustering via adaptive hypergraph fusion. <em>ISCI</em>, <em>723</em>, 122677. (<a href='https://doi.org/10.1016/j.ins.2025.122677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based clustering has garnered significant attention due to its outstanding performance in uncovering sample structures. However, existing graph-based methods face two major challenges: 1) In graph construction, they typically focus only on direct connections between samples or an exact high-order relationship, neglecting the impact of hidden complex relationships on clustering performance; 2) The separation of spectral analysis and category acquisition into two distinct stages often results in a loss of effectiveness. To handle these problems, we propose a parameter-free discrete clustering method, called parameter-free discrete clustering via adaptive hypergraph fusion (DCAHF). Specifically, DCAHF first produces multiple different hypergraphs, each serving as a biased approximation of the data's intrinsic manifold. These complementary approximations capture distinct local-to-global geometric patterns. Then, it introduces an adaptive fusion strategy that learns optimal weights to combine them into a single consensus hypergraph on manifold space, effectively reconstructing the real manifold structure with reduced bias and improved integrity. Finally, discrete spectral analysis is performed directly on the consensus hypergraph to generate discrete sample categories, thereby avoiding the performance loss associated with two-stage approaches. Thus, DCAHF is a high-performance, parameter-free clustering model that can flexibly adapt to various clustering tasks. Since the DCAHF model cannot be solved using gradient descent methods, we develop a coordinate descent-based optimization algorithm to efficiently solve the model. Extensive experimental results demonstrate that DCAHF significantly enhances clustering effectiveness while maintaining comparable efficiency to state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Yu Zhou and Ben Yang and Xuetao Zhang and Badong Chen},
  doi          = {10.1016/j.ins.2025.122677},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122677},
  shortjournal = {Inf. Sci.},
  title        = {Parameter-free discrete clustering via adaptive hypergraph fusion},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-branch semantic alignment for few-shot image classification. <em>ISCI</em>, <em>723</em>, 122676. (<a href='https://doi.org/10.1016/j.ins.2025.122676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remarkable progress of deep learning in computer vision has significantly stimulated research interest in few-shot image classification. This field aims to transfer knowledge from previous experiences to recognize new concepts with limited samples. However, most existing approaches primarily concentrate on aligning semantic information at high-level features, neglecting the importance of middle-level or low-level feature representations. In this paper, we propose a novel approach called Multi-Branch Semantic Alignment (MBSA) for few-shot image classification, with the objective of investigating the role of multi-level features. Instead of using standard convolutional layers, we employ diverse convolutional layers to generate enhanced representations in each branch. These representations are then utilized by a dense classifier, which is supervised by a powerful guidance mechanism to incorporate semantic information into their spatial locations. During the inference stage, the multi-branch semantic alignment is designed to align multi-level features between query images and support images. This alignment process effectively establishes semantic correspondences between representations at different levels, thereby enhancing the ability to recognize novel categories. Comprehensive experiments are conducted on various few-shot benchmarks to demonstrate the superiority of our approach compared to those of several previous approaches, and ablation studies are performed to analyze the impact of different components.},
  archive      = {J_ISCI},
  author       = {Zijun Zheng and Heng Wu and Laishui Lv and Changchun Zhang and Hongcheng Guo and Shanzhou Niu and Gaohang Yu},
  doi          = {10.1016/j.ins.2025.122676},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122676},
  shortjournal = {Inf. Sci.},
  title        = {Multi-branch semantic alignment for few-shot image classification},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Partition-based differentially private synthetic data generation. <em>ISCI</em>, <em>723</em>, 122675. (<a href='https://doi.org/10.1016/j.ins.2025.122675'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Private synthetic data sharing is beneficial as it better retains the distribution and nuances of the original data compared to summary statistics such as means and frequencies. Current state-of-the-art methods follow a select-measure-generate paradigm, but measuring large-domain marginals often leads to significant errors, and managing the privacy budget poses challenges. Our partition-based approach addresses these issues, effectively reducing errors and improving the quality of synthetic data, even with a limited privacy budget. Experimental results show that our method outperforms existing approaches, yielding synthetic data with enhanced quality and utility, making it a preferred option for private data sharing.},
  archive      = {J_ISCI},
  author       = {Meifan Zhang and Dihang Deng and Lihua Yin},
  doi          = {10.1016/j.ins.2025.122675},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122675},
  shortjournal = {Inf. Sci.},
  title        = {Partition-based differentially private synthetic data generation},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Transferable adversarial attacks on human pose estimation: A regularization and pruning framework. <em>ISCI</em>, <em>723</em>, 122674. (<a href='https://doi.org/10.1016/j.ins.2025.122674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Pose Estimation (HPE) is a core component in real-time decision systems, supporting critical applications such as healthcare monitoring, autonomous driving, and sports analytics. While deep learning models—particularly CNNs and Transformer-based architectures—have significantly improved HPE accuracy, they remain vulnerable to adversarial perturbations that subtly distort keypoint localization, thereby undermining system reliability. To address this challenge, we propose regularization and pruning transferable adversarial attack (RPA), a novel framework designed to enhance the transferability of adversarial samples in Transformer-based HPE models. RPA integrates two synergistic strategies: gradient regularization, which suppresses dominant feature correlations to reduce overfitting, and adaptive weight pruning, which removes redundant parameters to reduce model-specific noise. This dual mechanism enables the generation of transferable adversarial attacks that are effective across diverse model architectures. Extensive experiments on state-of-the-art HPE networks demonstrate that RPA consistently outperforms existing attack methods. In white-box settings, RPA reduces average precision (AP) by 0.05-0.30; in black-box scenarios, it yields AP drops of 0.01-0.04. These findings expose critical vulnerabilities in IoT-enabled HPE applications and establish a new benchmark for evaluating adversarial robustness in real-time perception systems.},
  archive      = {J_ISCI},
  author       = {Renguang Chen and Xuechao Yang and Xun Yi and Zhide Chen and Chen Feng and Xu Yang and Kexin Zhu and Iqbal Gondal},
  doi          = {10.1016/j.ins.2025.122674},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122674},
  shortjournal = {Inf. Sci.},
  title        = {Transferable adversarial attacks on human pose estimation: A regularization and pruning framework},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CF2M-net: Cross-feature fusion and memory-constraint network for video anomaly detection. <em>ISCI</em>, <em>723</em>, 122673. (<a href='https://doi.org/10.1016/j.ins.2025.122673'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection (VAD) aims to automatically identify anomalous events in surveillance videos that are significantly different from the normal pattern. Most existing methods learn the spatial-temporal distribution of normal features and detect deviations as anomalies. Typically, they employ autoencoders to independently learn appearance and motion features, but this separate learning limits the exploitation of their interrelation in real-world scenarios. To enhance the representation of normal patterns by capturing feature interrelation, we propose a cross-feature fusion and memory-constraint network (CF 2 M-Net) for VAD. Specifically, inspired by the representational ability of cross-attention in multimodal fusion, we design a cross-attention and memory-constraint (CM) module to enrich appearance features with motion information. To prevent overfitting to anomalous events, the memory-constraint module further constrains fused features within the distribution of normal patterns. We design an attention fusion (AF) decoder to predict normal features closer to the normal distribution, enhancing their separability from anomalies. By jointly modeling appearance and motion through feature fusion and memory constraints, CF 2 M-Net provides more discriminative normal representations for anomaly detection. Experimental evaluations on three benchmark datasets show that the CF 2 M-Net performs comparably with leading approaches. Moreover, the detailed evaluations indicate the effectiveness of normal representation based appearance-motion fusion features for VAD.},
  archive      = {J_ISCI},
  author       = {Qiming Ma and Chengyou Wang and Xiao Zhou},
  doi          = {10.1016/j.ins.2025.122673},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122673},
  shortjournal = {Inf. Sci.},
  title        = {CF2M-net: Cross-feature fusion and memory-constraint network for video anomaly detection},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed data-driven event-triggered secure consensus control of MASs: A global preset-time performance constraint method. <em>ISCI</em>, <em>723</em>, 122672. (<a href='https://doi.org/10.1016/j.ins.2025.122672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the distributed data-driven event-triggered secure consensus control issue for model-free multi-agent systems (MASs) under sensor faults and denial-of-service (DoS) attacks, while satisfying prescribed performance constraints. First, a global preset-time performance function (PTPF) is constructed to guarantee the global stability of model-free MASs within the preset time. The proposed PTPF ensures that the preset time remains unaffected by variations in the sampling period. Second, a proportional-integral-derivative (PID) sliding surface is designed to enhance MAS performance regulation, while a novel generalized fuzzy hyperbolic model (GFHM) is constructed to eliminate the dependency on fault information and achieve high-accuracy estimation of unknown fault signals. Third, a hybrid event-triggered mechanism integrating both dynamic and memory features is developed to optimize communication resource utilization while guaranteeing robust performance at extremes. Furthermore, an event-triggered secure control scheme leveraging the memory feature is proposed to reduce communication overhead while avoiding the dangerous open-loop scenario, where control inputs must be zeroed under DoS attacks as in the existing methods. Finally, the stability proof together with simulations confirms the feasibility of the control strategy.},
  archive      = {J_ISCI},
  author       = {Run-Ze Chen and Xiang-Gui Guo and Yuan-Xin Li},
  doi          = {10.1016/j.ins.2025.122672},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122672},
  shortjournal = {Inf. Sci.},
  title        = {Distributed data-driven event-triggered secure consensus control of MASs: A global preset-time performance constraint method},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MPCMO: An improved multi-population co-evolutionary algorithm for many-objective optimization. <em>ISCI</em>, <em>723</em>, 122671. (<a href='https://doi.org/10.1016/j.ins.2025.122671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many-objective optimization problems (MaOPs) are widely used in scientific research and engineering practices, which mainly consider joint optimization of multiple objectives simultaneously. Despite the numerous multi-objective evolutionary algorithms proposed in recent years, they often struggle with challenges in fitness assignment arising from objective conflicts. Meanwhile, they tend to perform well in only one aspect of convergence, diversity, and computational complexity. To address these issues, this paper proposes an improved multi-population co-evolutionary algorithm for many-objective optimization (termed MPCMO), which leverages the advantages of multi-population co-evolutionary techniques. The primary objective of MPCMO is to achieve a more balanced performance across convergence, diversity, and complexity. MPCMO comprises three essential components. Initially, an adaptive evolutionary strategy is employed to dynamically allocate evolutionary opportunities to subpopulations so as to conserve computational resources and enhance convergence. Subsequently, a migration strategy is developed to ensure a more global approximation of whole Pareto front. Additionally, an archive update-truncation strategy, based on angle selection and shift-based density estimation, is adopted to enhance diversity. We conduct comprehensive comparative experiments on a variety of many-objective benchmark problems with complicated characteristics. Experimental results demonstrate that the proposed method outperforms existing state-of-the-art algorithms in terms of both diversity and convergence.},
  archive      = {J_ISCI},
  author       = {Weichao Ding and Jiahao Liu and Wenbo Dong and Fei Luo and Chunhua Gu},
  doi          = {10.1016/j.ins.2025.122671},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122671},
  shortjournal = {Inf. Sci.},
  title        = {MPCMO: An improved multi-population co-evolutionary algorithm for many-objective optimization},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reinforced heterogeneous graphlet design for knowledge graph representation learning. <em>ISCI</em>, <em>723</em>, 122670. (<a href='https://doi.org/10.1016/j.ins.2025.122670'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) are practical tools that represent and integrate plentiful structural and semantic information in mainstream industrial scenarios. Despite their potential, the heterogeneity and complexity of KGs pose a formidable obstacle, especially for graph representation learning. Most existing KG embedding models omit dynamic high-order connectivity patterns to gain insights into heterogeneous networks and heavily rely on handcrafted patterns to handle complex semantic relationships, which limits their capability to adaptively capture the nuanced and intricate relationships of KGs in different tasks. To fill this gap, we present Reinforced Heterogeneous Graphlet Design (ReHGD)—a model designed for KGs that focuses on the adaptive design of typed graphlets (heterogeneous chains and motifs) through a cooperative multi-agent reinforcement learning algorithm. This task-driven approach can learn discriminative graph representations tailored to specific downstream tasks. Specifically, ReHGD engages in the creation of typed graphlets through a two-stage process: it (1) establishes a reinforced chain design module to generate chains without predefined rules and (2) employs a buffer-aware sampling technique to derive episodic chains from prior experiences. Subsequently, motifs are deduced through the application of commute count and Hadamard product operations to the episodic chain-based subgraphs. In the final step toward learning graph representations, ReHGD undertakes chain and motif aggregations. Experimental results and analyses reveal that ReHGD outperforms strong baselines on three real-world graph data and practical tasks.},
  archive      = {J_ISCI},
  author       = {Jibing Gong and Yuting Lin and Yi Zhao and Tianyu Lin and Xiaohan Fang and Xinchao Feng and Jiquan Peng},
  doi          = {10.1016/j.ins.2025.122670},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122670},
  shortjournal = {Inf. Sci.},
  title        = {Reinforced heterogeneous graphlet design for knowledge graph representation learning},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatio-frequency texture analysis using wavelet increment entropy: Methodology and application to MRI in multiple sclerosis. <em>ISCI</em>, <em>723</em>, 122669. (<a href='https://doi.org/10.1016/j.ins.2025.122669'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Texture analysis is crucial for understanding images by extracting features that define spatial patterns. Recently, bi-dimensional extensions of entropy measures have gained attention due to their simplicity and strong theoretical foundations. However, existing methods primarily operate in the spatial domain and thus overlook frequency-domain and multiscale information. To address this, we introduce bidimensional wavelet increment entropy (wavelet IncrEn 2 D ). A one-level discrete wavelet transform (DWT) with the Haar wavelet decomposes each image into approximation (low-frequency) and, for some neuroimaging data, detail (high-frequency) subbands; IncrEn 2 D is then applied both to capture global structural patterns and fine, detailed texture variations. We evaluated wavelet IncrEn 2 D on synthetic and real datasets, demonstrating its effectiveness in distinguishing between different noise types (white Gaussian, salt-and-pepper, and speckle noise). Comparisons between periodic and synthesized images revealed lower wavelet IncrEn 2 D values for periodic textures. Tests on real texture datasets highlight the method's ability to differentiate various patterns. In particular, wavelet IncrEn 2 D achieved 86.69% accuracy in distinguishing MRI images of healthy versus multiple sclerosis–affected brains. Overall, wavelet IncrEn 2 D offers a robust, frequency-aware descriptor that outperforms existing 2D entropy methods.},
  archive      = {J_ISCI},
  author       = {Muqaddas Abid and Muhammad Suzuri Hitam and Rozniza Ali and Hamed Azami and Anne Humeau-Heurtier},
  doi          = {10.1016/j.ins.2025.122669},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122669},
  shortjournal = {Inf. Sci.},
  title        = {Spatio-frequency texture analysis using wavelet increment entropy: Methodology and application to MRI in multiple sclerosis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved query specialization for transformer-based visual relationship detection. <em>ISCI</em>, <em>723</em>, 122668. (<a href='https://doi.org/10.1016/j.ins.2025.122668'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Relationship Detection (VRD) has significantly advanced with Transformer-based architectures. However, we identify two fundamental drawbacks in conventional label assignment methods used for training Transformer-based VRD models, where ground-truth (GT) annotations are matched to model predictions. In conventional assignment, queries are trained to detect all relations rather than specializing in specific ones, resulting in ‘unspecialized’ queries. Also, each ground-truth (GT) annotation is assigned to only one prediction under conventional assignment, suppressing other near-correct predictions by labeling them as ‘no relation’. To address these issues, we introduce a novel method called Groupwise Query Spe ci a lization and Q uality-Aware Multi-Assignment (SpeaQ). Groupwise Query Specialization clusters queries and relations into exclusive groups, promoting specialization by assigning a set of relations only to a corresponding query group. Quality-Aware Multi-Assignment enhances training signals by allowing multiple predictions closely matching the GT to be positively assigned. Additionally, we introduce dynamic query reallocation, which transfers queries from high- to low-performing groups for balanced training. Experimental results demonstrate that SpeaQ+, combining SpeaQ with dynamic query reallocation, consistently improves performance across seven baseline models on five benchmarks without additional inference cost.},
  archive      = {J_ISCI},
  author       = {Jongha Kim and Jihwan Park and Jinyoung Park and Jinyoung Kim and Sehyung Kim and Hyunwoo J. Kim},
  doi          = {10.1016/j.ins.2025.122668},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122668},
  shortjournal = {Inf. Sci.},
  title        = {Improved query specialization for transformer-based visual relationship detection},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ConvDiff: Multi-scale spatio-temporal convolutional networks with latent diffusion models for dynamic system modeling. <em>ISCI</em>, <em>723</em>, 122656. (<a href='https://doi.org/10.1016/j.ins.2025.122656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the modeling of spatio-temporal dynamic systems, tasks such as fluid dynamics, weather forecasting, and traffic flow prediction face highly complex spatio-temporal dependencies and nonlinear dynamics. These characteristics make it challenging for traditional physical models and data-driven methods to balance accuracy and computational efficiency. To address these challenges, we propose a multi-scale spatio-temporal convolutional network named ConvDiff, optimized specifically for dynamic system modeling tasks by integrating a latent space denoising diffusion model. ConvDiff effectively captures complex spatio-temporal features and handles uncertainties in physical systems by introducing multi-scale convolutional modules combined with a physics-guided diffusion mechanism. Specifically, our model incorporates eight temporal modules and four spatial modules, using a hierarchical convolutional and diffusion structure to capture the intricate dynamics of physical systems. The experiments involved different spatio-temporal data, such as those from TaxiBJ and the Navier-Stokes dataset. According to the findings, ConvDiff demonstrates substantial improvements in essential performance indicators. For example, in the TaxiBJ dataset, ConvDiff obtained a mean squared deviation of 0.29 and a PSNR value of 40.31, outperforming the best-performing models. Moreover, on the Navier-Stokes dataset, ConvDiff reduced the MSE by 51.15% compared to the best baseline model. These results indicate that ConvDiff effectively captures complex spatio-temporal dependencies and improves prediction accuracy, particularly in physics-driven dynamic systems. Our code is available at https://github.com/Ray-zyy/ConvDiff .},
  archive      = {J_ISCI},
  author       = {Yuyang Zhao and Yuhan Wu and Yongmei Wang},
  doi          = {10.1016/j.ins.2025.122656},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122656},
  shortjournal = {Inf. Sci.},
  title        = {ConvDiff: Multi-scale spatio-temporal convolutional networks with latent diffusion models for dynamic system modeling},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A semi-heterogeneous ensemble forecasting method for stock returns based on sentiment analysis. <em>ISCI</em>, <em>723</em>, 122655. (<a href='https://doi.org/10.1016/j.ins.2025.122655'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing influence of investor sentiment on market dynamics, sentiment analysis has emerged as an effective tool for enhancing financial forecasting models. This study proposes a diversity-enhanced semi-heterogeneous ensemble forecasting framework that integrates sentiment analysis into the forecasting of stock index returns. A supervised stock market sentiment index set is constructed, in which prior knowledge regarding term importance is integrated into the data augmentation process. This enables higher weights to be assigned to sentiment-related terms with superior predictive capacity, thereby allowing the model to prioritize more informative features and enhance its forecasting performance. A series of diverse base models are generated through the integration of multiple attention-PCA techniques and forecasting algorithms based on variable perturbation strategies. These base models are subsequently combined through a suite of ensemble strategies, forming a semi-heterogeneous ensemble model for forecasting S&P 500 returns. The experiment results demonstrate that the proposed approaches significantly outperform benchmark methods, with notable improvements in both accuracy and diversity.},
  archive      = {J_ISCI},
  author       = {Xiao Zhang and Peide Liu and Jing Feng},
  doi          = {10.1016/j.ins.2025.122655},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122655},
  shortjournal = {Inf. Sci.},
  title        = {A semi-heterogeneous ensemble forecasting method for stock returns based on sentiment analysis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Energy-related controllability of corona product networks. <em>ISCI</em>, <em>723</em>, 122654. (<a href='https://doi.org/10.1016/j.ins.2025.122654'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the energy-related controllability for a category of ‘large’ composite networks generated by ‘small’ simple factor networks with Laplacian dynamics under a leader-follower framework via corona product. Different from most existing literature on network controllability, this work characterizes the controllability of corona product networks (CPNs) from an energy point of view. This can quantify the difficulty of controlling CPNs based on controllability Gramian measures, involving average controllability and volumetric control energy, etc., where the energy is triggered by the leaders. The energy-related controllability of a CPN can be explored from the eigenvalues and eigenvectors of its factor networks. An algorithm for solving the maximum average controllability is provided, which can help one select the leaders to optimize network control and be applied in practice.},
  archive      = {J_ISCI},
  author       = {Qiang Zhang and Junjie Huang and Bo Liu and Housheng Su and Alatancang Chen},
  doi          = {10.1016/j.ins.2025.122654},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122654},
  shortjournal = {Inf. Sci.},
  title        = {Energy-related controllability of corona product networks},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SeqRFM: Fast RFM analysis in sequence data. <em>ISCI</em>, <em>723</em>, 122652. (<a href='https://doi.org/10.1016/j.ins.2025.122652'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, data mining technologies have been well applied to many domains, including e-commerce. In customer relationship management (CRM), the Recency-Frequency-Monetary (RFM) analysis model is one of the most effective approaches to increase the profits of major enterprises. However, with the rapid development of e-commerce, the diversity and abundance of e-commerce data pose a challenge to mining efficiency. Moreover, in actual market transactions, the chronological order of transactions reflects customer behavior and preferences. To address these challenges, we develop an effective algorithm called SeqRFM, which combines sequential pattern mining with RFM models. SeqRFM considers each customer's R, F, and M scores to represent the significance of the customer and identifies sequences with high recency, high frequency, and high monetary value. A series of experiments demonstrates the superiority and effectiveness of the SeqRFM algorithm compared to the most advanced RFM algorithms based on sequential pattern mining. Moreover, another algorithm named MSeqRFM is developed to compress the result of SeqRFM. The experiments demonstrate the effectiveness of MSeqRFM in compressing sequences. The source code and datasets are available at GitHub https://github.com/DSI-Lab1/SeqRFM .},
  archive      = {J_ISCI},
  author       = {Yanxin Zheng and Wensheng Gan and Zefeng Chen and Pinlyu Zhou and Philippe Fournier-Viger},
  doi          = {10.1016/j.ins.2025.122652},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122652},
  shortjournal = {Inf. Sci.},
  title        = {SeqRFM: Fast RFM analysis in sequence data},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic event-triggered finite-time actor-critic-identifier-based approximate optimal control for unknown nonlinear drifted systems. <em>ISCI</em>, <em>723</em>, 122651. (<a href='https://doi.org/10.1016/j.ins.2025.122651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a finite-time dynamic event-triggered actor-critic-identifier (FT-DET-ACI) framework for the optimal control problem of nonlinear systems with uncertain drift dynamics. A theoretical foundation is established by reformulating the value function within a finite-time stable space, which facilitates system state stabilization within predetermined temporal constraints. The proposed approach derives finite-time optimal controllers through a transformed Hamilton-Jacobi-Bellman (HJB) equation. To address unknown system dynamics, an integrated actor-critic-identifier architecture is constructed to concurrently approximate the value function, synthesize the finite-time optimal controller, and identify system parameters. A dynamic event-triggering rule is designed to reduce computational and communication loads by selectively updating the control signal. Lyapunov stability analysis is provided to demonstrate the finite-time convergence properties of the closed-loop system. Numerical experiments are conducted to validate the efficacy of the proposed FT-DET-ACI methodology.},
  archive      = {J_ISCI},
  author       = {Shuangsi Xue and Junkai Tan and Zihang Guo and Qingshu Guan and Hui Cao and Badong Chen},
  doi          = {10.1016/j.ins.2025.122651},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122651},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic event-triggered finite-time actor-critic-identifier-based approximate optimal control for unknown nonlinear drifted systems},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Set membership filter with nonlinear state inequality constraints. <em>ISCI</em>, <em>723</em>, 122650. (<a href='https://doi.org/10.1016/j.ins.2025.122650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Set membership filter is a promising method to provide a bounding estimation containing the true state for dynamic systems with unknown but bounded noises. In this paper, we investigate the state bounding estimation problem of nonlinear dynamic systems with nonlinear state inequality constraints. Three types of ellipsoidal state bounding estimation methods are proposed by incorporating nonlinear state inequality constraints into nonlinear set membership filter. They are called model reduction method, system measurement method, and constraint dimension reduction method, respectively. We analyze the computation complexity of the three methods, which decrease in the order of model reduction method, system measurement method, and constraint dimension reduction method. Due to the nonlinearity of the dynamic systems, all the three methods are approximation algorithms and the state estimation accuracy cannot be analyzed explicitly. Consequently, a typical illustrative numerical experiment is conducted to compare the performance of the three methods. The results show that the accuracy increases in the order of the model reduction method, the constraint dimension reduction method, and the system measurement method.},
  archive      = {J_ISCI},
  author       = {Xiaowei Li and Xuqi Zhang and Zhiguo Wang and Xiaojing Shen},
  doi          = {10.1016/j.ins.2025.122650},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122650},
  shortjournal = {Inf. Sci.},
  title        = {Set membership filter with nonlinear state inequality constraints},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Bi-objective optimization for electric vehicle scheduling under vehicle-to-grid integration. <em>ISCI</em>, <em>723</em>, 122649. (<a href='https://doi.org/10.1016/j.ins.2025.122649'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle-to-grid (V2G) technology leverages the distributed energy-storage potential of electric vehicles (EVs), transforming the challenges of large-scale EV integration into opportunities to enhance grid flexibility and reliability. This study investigates the optimization of EV charging-discharging schedules by exploiting V2G capabilities. First, considering the spatiotemporal distribution of EVs, a Markov chain is constructed to describe probabilistic transitions between spatiotemporal states, which is then embedded in a traffic-network-based path decision model. Second, a dynamic battery energy consumption model is established, incorporating multiple factors that influence battery performance. Using Monte Carlo simulation results, a bi-objective optimization model is formulated to schedule charging and discharging, simultaneously minimizing (i) total cost — including user recharging time and battery degradation — and (ii) grid-load fluctuation. Given the NP-hard nature of the problem, an improved multi-objective bitterling fish optimization (IMOBFO) algorithm is developed to balance global exploration and local exploitation. Empirical studies in a region of Shanghai compare three strategies: disordered charging, ordered charging, and the proposed optimized charging–discharging strategy. Experimental results confirm the feasibility of the proposed model and the effectiveness of IMOBFO. Comparative analysis with seven other algorithms further validates the superior performance and stability of IMOBFO according to multiple multi-objective evaluation metrics.},
  archive      = {J_ISCI},
  author       = {Bing Yu and Yong Liu and Liang Ma},
  doi          = {10.1016/j.ins.2025.122649},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122649},
  shortjournal = {Inf. Sci.},
  title        = {Bi-objective optimization for electric vehicle scheduling under vehicle-to-grid integration},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unified graph-based framework for visual explainability in convolutional neural networks. <em>ISCI</em>, <em>723</em>, 122648. (<a href='https://doi.org/10.1016/j.ins.2025.122648'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In deep learning, understanding the decision-making processes of complex models is essential for advancing interpretability and trust in artificial intelligence systems. We introduce Causal Relational Attribution Graph (C-RAG), designed to deliver comprehensive, multi-perspective explanations of convolutional neural networks (CNNs) via a graph representation. C-RAG integrates gradient-based local attribution with global feature importance by constructing a graph-based representation that captures hierarchical feature inter-dependencies. In this framework, feature clusters are represented as graph nodes, and their interactions are quantified through combined localized and global attribution metrics, ensuring interpretable insights into model behavior. We evaluate C-RAG across diverse benchmark datasets (ImageNet, CIFAR-10, MNIST) and CNN architectures (ResNet18, VGG19, DenseNet201, LeNet), demonstrating significant advancements over state-of-the-art explainability methods in faithfulness, robustness, and computational efficiency. The proposed approach facilitates accurate spatial feature localization, robust dependency mapping, and efficient explanation generation, making it a valuable tool for critical applications such as medical imaging and autonomous systems. We provide a novel graph-based explainability framework, which bridges the gap between local and global interpretability, C-RAG addresses key limitations in existing methods, establishing a robust foundation for explainable AI in computer vision.},
  archive      = {J_ISCI},
  author       = {Basim Azam and Pubudu Sanjeewani and Brijesh Verma and Ashfaqur Rahman and Lipo Wang},
  doi          = {10.1016/j.ins.2025.122648},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122648},
  shortjournal = {Inf. Sci.},
  title        = {Unified graph-based framework for visual explainability in convolutional neural networks},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attention-based spatial-temporal interactive couple neural networks for multivariate time series forecasting. <em>ISCI</em>, <em>723</em>, 122647. (<a href='https://doi.org/10.1016/j.ins.2025.122647'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series forecasting (MTSF) has been a significant research focus across various domains. Recent studies have utilized deep neural networks to identify pattern relationships in MTSF. Despite these developments, accurately forecasting multivariate time series remains challenging due to the trend of time series and spatial-temporal heterogeneity. In this paper, we propose a unified multivariate time series forecasting framework for long-term, short-term, and spatial-temporal forecasting with attention-based spatial-temporal interactive coupled neural networks (ASTIC). Specifically, we proposed a spatial-temporal interactive couple block that contains both temporal and spatial branches to investigate the relationships between global and local patterns in temporal and spatial perspectives. In the temporal branch, we design a hybrid network module capable of enhancing representation learning using convolution and attention mechanisms, which dynamically capture the local trendiness and long-term time dependence implicit in time series. In the spatial branch, a novel dynamic graph learners are designed to learn global and local spatial patterns. Then a novel interactive coupling method is proposed to link the two branches together. ASTIC predicts time series effectively by using a multilevel structure to model the trendiness of the series and mining the spatial-temporal heterogeneity. Experimental results show that our method outperforms state-of-the-art baseline methods on nine real-world datasets.},
  archive      = {J_ISCI},
  author       = {Bingsheng Wei and Yonghua Hei and Yuan Wan},
  doi          = {10.1016/j.ins.2025.122647},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122647},
  shortjournal = {Inf. Sci.},
  title        = {Attention-based spatial-temporal interactive couple neural networks for multivariate time series forecasting},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). New solutions based on the generalized eigenvalue problem for the data collaboration analysis. <em>ISCI</em>, <em>723</em>, 122642. (<a href='https://doi.org/10.1016/j.ins.2025.122642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the data collaboration (DC) analysis, a privacy-preserving method for analyzing decentralized datasets held by multiple parties. In this method, privacy-preserving intermediate representations of original datasets are collected from multiple parties and then converted into collaboration representations for collaborative data analysis. However, conventional methods for creating collaboration representations suffer from several challenges; namely, the optimization problem being considered is not well defined, and the process of solving it is very difficult to understand. We thus propose a new solution for creating high-quality collaboration representations for the DC analysis. Specifically, we formulate a revised optimization problem for creating collaboration representations and then transform this optimization problem into a generalized eigenvalue problem. We also propose a reduction of the generalized eigenvalue problem to a singular value decomposition through the QR decomposition. Computational experiments using publicly available datasets demonstrate that our method can outperform the conventional methods for the DC analysis in terms of both prediction accuracy and computational efficiency.},
  archive      = {J_ISCI},
  author       = {Yuta Kawakami and Yuichi Takano and Akira Imakura},
  doi          = {10.1016/j.ins.2025.122642},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122642},
  shortjournal = {Inf. Sci.},
  title        = {New solutions based on the generalized eigenvalue problem for the data collaboration analysis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interpretable, multidimensional evaluation framework for causal discovery from observational i.i.d. data. <em>ISCI</em>, <em>723</em>, 122641. (<a href='https://doi.org/10.1016/j.ins.2025.122641'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear causal discovery from observational data imposes strict identifiability assumptions on the formulation of structural equations utilized in the data-generating process. However, in real-life settings, the ground-truth mechanism responsible for cause-effect transformations is unknown. Thus, it is impossible to verify its identifiability. This is the first research to assess the performance of structure learning algorithms from seven different families in non-identifiable settings with an increasing degree of nonlinearity. The evaluation of structure learning methods under assumption violations requires a rigorous and interpretable approach that quantifies both the structural similarity of the estimation with the ground truth and the capacity of the discovered graphs to be used for causal inference. Motivated by the lack of a unified performance assessment indicator, we propose an interpretable, multidimensional evaluation framework, specifically tailored to the field of causal discovery from i.i.d. data. In particular, we introduce a six-dimensional evaluation metric, called distance to the optimal solution, which aims at providing a holistic overview of the performance of structure learning techniques. Our large-scale simulation study, which incorporates seven experimental factors, shows that hybrid Bayesian networks outperform most recently introduced continuous optimization techniques under certain conditions. Additionally, causal order-based methods yield results with comparatively high proximity to the optimal solution.},
  archive      = {J_ISCI},
  author       = {Georg Velev and Stefan Lessmann},
  doi          = {10.1016/j.ins.2025.122641},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122641},
  shortjournal = {Inf. Sci.},
  title        = {Interpretable, multidimensional evaluation framework for causal discovery from observational i.i.d. data},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

</body>
</html>
